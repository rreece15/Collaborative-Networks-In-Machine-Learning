FN Clarivate Analytics Web of Science
VR 1.0
PT C
AU Shalf, J
AF Shalf, John
GP IEEE
TI HPC Interconnects at the End of Moore's Law
SO 2019 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC)
DT Proceedings Paper
CT Optical Fiber Communications Conference and Exhibition (OFC)
CY MAR 03-07, 2019
CL San Diego, CA
AB The tapering of lithography advances that have been associated with Moore's Law will substantially change requirements for future interconnect architectures for large-scale datacenters and HPC systems. Architectural specialization is creating new datacenter requirements such as emerging accelerator technologies for machine learning workloads and rack disaggregation strategies will push the limits of current interconnect technologies. Whereas photonic technologies are often sold on the basis of higher bandwidth and energy efficiency (e.g. lower picojoules per bit), these emerging workloads and technology trends will shift the emphasis to other metrics such as bandwidth density (as opposed to bandwidth alone) and reduced latency, and performance consistency. Such metrics cannot be accomplished with device improvements alone, but require a systems view of photonics in datacenters.
C1 [Shalf, John] Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.
RP Shalf, J (corresponding author), Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.
EM jshalf@lbl.gov
CR [Anonymous], ELECTRONICS
   [Anonymous], 2005, P ACMIEEE SC2005 C H
   Jouppi N. P., 2017, ISCA 17
   Lavin A., 2015, FAST ALGORITHMS CONV
   Putnam A., 2017, GLSVLSI 17
   Shalf JM, 2015, COMPUTER, V48, P14, DOI 10.1109/MC.2015.374
   Wan YT, 2018, PHOTONICS RES, V6, P776, DOI 10.1364/PRJ.6.000776
   Wen K, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P166, DOI 10.1109/SC.2016.14
NR 8
TC 15
Z9 15
U1 0
U2 3
PY 2019
UT WOS:000469837300238
DA 2023-11-16
ER

PT J
AU Hu, RL
   Pierce, D
   Shafi, Y
   Boral, A
   Anisimov, V
   Nevo, S
   Chen, YF
AF Hu, R. Lily
   Pierce, Damien
   Shafi, Yusef
   Boral, Anudhyan
   Anisimov, Vladimir
   Nevo, Sella
   Chen, Yi-fan
TI Accelerating physics simulations with tensor processing units: An
   inundation modeling example
SO INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS
DT Article
DE CFD; computational fluid dynamics; distributed computing; flood
   forecasting; flood modeling; inundation modeling; large scale
   simulations; parallel computing; tensor processing units
AB Recent advancements in hardware accelerators such as Tensor Processing Units (TPUs) speed up computation time relative to Central Processing Units (CPUs) not only for machine learning but, as demonstrated here, also for scientific modeling and computer simulations. To study TPU hardware for distributed scientific computing, we solve partial differential equations (PDEs) for the physics simulation of fluids to model riverine floods. We demonstrate that TPUs achieve a two orders of magnitude speedup over CPUs. Running physics simulations on TPUs is publicly accessible via the Google Cloud Platform, and we release a Python interactive notebook version of the simulation.
C1 [Hu, R. Lily; Pierce, Damien; Shafi, Yusef; Boral, Anudhyan; Anisimov, Vladimir; Nevo, Sella; Chen, Yi-fan] Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.
RP Hu, RL; Pierce, D (corresponding author), Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.
EM rlhu@google.com; dmpierce@google.com
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Afshari S, 2018, J HYDROL, V556, P539, DOI 10.1016/j.jhydrol.2017.11.036
   Akan A.O., 2011, OPEN CHANNEL HYDRAUL
   [Anonymous], 2019, SUSTAIN DEV GOALS RE
   Bates PD, 2010, J HYDROL, V387, P33, DOI 10.1016/j.jhydrol.2010.03.027
   Bates PD, 2000, J HYDROL, V236, P54, DOI 10.1016/S0022-1694(00)00278-X
   Belletti F., 2019, P 2020 SIAM C PARALL
   Bradbury James, 2018, JAX COMPOSABLE TRANS
   CRED, 2017, NAT DIS 2017
   de Almeida GAM, 2012, WATER RESOUR RES, V48, DOI 10.1029/2011WR011570
   Guennebaud G., 2010, EIGEN V3
   Jonkman SN, 2005, NAT HAZARDS, V34, P151, DOI 10.1007/s11069-004-8891-3
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kundzewicz ZW, 2014, HYDROLOG SCI J, V59, P1, DOI 10.1080/02626667.2013.857411
   Lewis JM., 2019, PEAK STREAMFLOW STAG
   Lu T., 2020, PREPRINT
   LU T, 2021, 18 INT S BIOMED IMAG
   Lu TJ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286192
   Meesuk V, 2015, ADV WATER RESOUR, V75, P105, DOI 10.1016/j.advwatres.2014.11.008
   Microway, DET SPEC CAS LAK SP
   Nevo S., 2019, ARXIV PREPRINT ARXIV
   Pilon P. J., 2002, GUIDELINES REDUCING
   Rogers D, 2010, GLOBAL ASSESSMENT RE
   Shastry A, 2019, FRONT EARTH SC-SWITZ, V6, DOI 10.3389/feart.2018.00243
   Smith B. F., 1997, PARALLEL NUMERICAL A, P225, DOI [DOI 10.1007/978-94-011-5412-3_8, DOI 10.1007/978-94-011-5412-38]
   Teng J, 2017, ENVIRON MODELL SOFTW, V90, P201, DOI 10.1016/j.envsoft.2017.01.006
   UNISDR, 2015, HUM COST WEATH REL D
   USGS, 2017, 3DEP DOWNL DIG EL MO
   Vreugdenhil C.B., 1994, NUMERICAL METHODS SH
   World Health Organization, 2014, GLOB REP DROWN PREV, DOI DOI 10.3390/IJERPH140808755
   Yang K, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356149
   Zhang JQ, 2018, J AM WATER RESOUR AS, V54, P820, DOI 10.1111/1752-1688.12623
NR 32
TC 2
Z9 2
U1 0
U2 4
PD JUL
PY 2022
VL 36
IS 4
BP 510
EP 523
AR 10943420221102873
DI 10.1177/10943420221102873
EA JUN 2022
UT WOS:000808121000001
DA 2023-11-16
ER

PT C
AU Minarik, M
   Sekanina, L
AF Minarik, Milos
   Sekanina, Lukas
BE McDermott, J
   Castelli, M
   Sekanina, L
   Haasdijk, E
   GarciaSanchez, P
TI On Evolutionary Approximation of Sigmoid Function for HW/SW Embedded
   Systems
SO GENETIC PROGRAMMING, EUROGP 2017
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 20th European Conference on Genetic Programming (EuroGP)
CY APR 19-21, 2017
CL Amsterdam, NETHERLANDS
DE Sigmoid; Linear genetic programming; HW/SW co-design
ID HARDWARE-SOFTWARE COSYNTHESIS
AB Providing machine learning capabilities on low cost electronic devices is a challenging goal especially in the context of the Internet of Things paradigm. In order to deliver high performance machine intelligence on low power devices, suitable hardware accelerators have to be introduced. In this paper, we developed a method enabling to evolve a hardware implementation together with a corresponding software controller for key components of smart embedded systems. The proposed approach is based on a multi-objective design space exploration conducted by means of extended linear genetic programming. The approach was evaluated in the task of approximate sigmoid function design which is an important component of hardware implementations of neural networks. During these experiments, we automatically re-discovered some approximate sigmoid functions known from the literature. The method was implemented as an extension of an existing platform supporting concurrent evolution of hardware and software of embedded systems.
C1 [Minarik, Milos; Sekanina, Lukas] Brno Univ Technol, Ctr Excellence IT4Innovat, Fac Informat Technol, Brno, Czech Republic.
RP Minarik, M (corresponding author), Brno Univ Technol, Ctr Excellence IT4Innovat, Fac Informat Technol, Brno, Czech Republic.
EM iminarikm@fit.vutbr.cz; sekanina@fit.vutbr.cz
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   [Anonymous], 2007, LINEAR GENETIC PROGR
   [Anonymous], 6 TURK AI NN S TAINN
   Cheang SM, 2006, EVOL COMPUT, V14, P129, DOI 10.1162/evco.2006.14.2.129
   Deniziak S, 2008, LECT NOTES COMPUT SC, V5216, P83
   Dick RP, 1998, IEEE T COMPUT AID D, V17, P920, DOI 10.1109/43.728914
   Koza JR., 1994, GENETIC PROGRAMMING
   Leung KS, 2003, LECT NOTES COMPUT SC, V2610, P107
   MCCLUSKEY EJ, 1956, BELL SYST TECH J, V35, P1417, DOI 10.1002/j.1538-7305.1956.tb03835.x
   Minarik Milos, 2014, Genetic Programming. 17th European Conference (EuroGP 2014). Revised Selected Papers: LNCS 8599, P112, DOI 10.1007/978-3-662-44303-3_10
   Minarik M, 2013, PROCEEDINGS OF THE 2013 IEEE INTERNATIONAL CONFERENCE ON EVOLVABLE SYSTEMS (ICES), P43, DOI 10.1109/ICES.2013.6613281
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Parhami B., 2010, COMPUTER ARITHMETIC
   Poli R, 1999, FROM ANIM ANIMAT, P301
   Shang L, 2007, IEEE T COMPUT AID D, V26, P508, DOI 10.1109/TCAD.2006.883909
   Tempesti G, 2006, AHS 2006: FIRST NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P129
   Tommiska MT, 2003, IEE P-COMPUT DIG T, V150, P403, DOI 10.1049/ip-cdt:20030965
   Zhang M, 1996, IEEE T COMPUT, V45, P1045, DOI 10.1109/12.537127
NR 18
TC 0
Z9 0
U1 0
U2 1
PY 2017
VL 10196
BP 343
EP 358
DI 10.1007/978-3-319-55696-3_22
UT WOS:000413012200022
DA 2023-11-16
ER

PT J
AU Han, W
   Heo, J
   Kim, J
   Lim, S
   Kim, JY
AF Han, Wontak
   Heo, Jaehoon
   Kim, Junsoo
   Lim, Sukbin
   Kim, Joo-Young
TI Design of Processing-in-Memory With Triple Computational Path and
   Sparsity Handling for Energy-Efficient DNN Training
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Training; Computational modeling; Computer architecture; Deep learning;
   Circuits and systems; Power demand; Neurons; Accelerator architecture;
   machine learning; processing-in-memory architecture; bit-serial
   operation; inference; training; sparsity handling; SRAM;
   energy-efficient architecture
ID DEEP NEURAL-NETWORKS; SRAM; ACCELERATOR; MACRO
AB As machine learning (ML) and artificial intelligence (AI) have become mainstream technologies, many accelerators have been proposed to cope with their computation kernels. However, they access the external memory frequently due to the large size of deep neural network model, suffering from the von Neumann bottleneck. Moreover, as privacy issue is becoming more critical, on-device training is emerging as its solution. However, on-device training is challenging because it should perform the training under a limited power budget, which requires a lot more computations and memory accesses than the inference. In this paper, we present an energy-efficient processing-in-memory (PIM) architecture supporting end-to-end on-device training named T-PIM. Its macro design includes an 8T-SRAM cell-based PIM block to compute in-memory AND operation and three computational datapaths for end-to-end training. Each of three computational paths integrates arithmetic units for forward propagation, backward propagation, and gradient calculation and weight update, respectively, allowing the weight data stored in the memory stationary. T-PIM also supports variable bit precision to cover various ML scenarios. It can use fully variable input bit precision and 2-bit, 4-bit, 8-bit, and 16-bit weight bit precision for the forward propagation and the same input bit precision and 16-bit weight bit precision for the backward propagation. In addition, T-PIM implements sparsity handling schemes that skip the computation for input data and turn off the arithmetic units for weight data to reduce both unnecessary computations and leakage power. Finally, we fabricate the T-PIM chip on a 5.04mm(2) die in a 28-nm CMOS logic process. It operates at 50-280MHz with the supply voltage of 0.75-1.05V, dissipating 5.25-51.23mW power in inference and 6.10-37.75mW in training. As a result, it achieves 17.90-161.08TOPS/W energy efficiency for the inference of 1-bit activation and 2-bit weight data, and 0.84-7.59TOPS/W for the training of 8-bit activation/error and 16-bit weight data. In conclusion, T-PIM is the first PIM chip that supports end-to-end training, demonstrating 2.02 times performance improvement over the latest PIM that partially supports training.
C1 [Han, Wontak; Heo, Jaehoon; Kim, Junsoo; Lim, Sukbin; Kim, Joo-Young] Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 34141, South Korea.
RP Han, W; Kim, JY (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 34141, South Korea.
EM 11tak@kaist.ac.kr; jooyoung1203@kaist.ac.kr
CR Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Choi S, 2020, IEEE J SOLID-ST CIRC, V55, P2691, DOI 10.1109/JSSC.2020.3005786
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Jiang HW, 2020, IEEE T COMPUT, V69, P944, DOI 10.1109/TC.2020.2980533
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim JH, 2021, IEEE J SOLID-ST CIRC, V56, P1093, DOI 10.1109/JSSC.2020.3039206
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Lee J, 2022, IEEE MICRO, V42, P99, DOI 10.1109/MM.2021.3096236
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   LING H, 1981, IBM J RES DEV, V25, P156, DOI 10.1147/rd.252.0156
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ICPHM.2017.7998297, 10.1109/ATNAC.2017.8215431]
   Ruck DW., 1990, J NEURAL NETWORK COM, V2, P40
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Sünderhauf N, 2018, INT J ROBOT RES, V37, P405, DOI 10.1177/0278364918770733
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yuan Z, 2020, IEEE J SOLID-ST CIRC, V55, P465, DOI 10.1109/JSSC.2019.2946771
   Yue JS, 2021, ISSCC DIG TECH PAP I, V64, P238, DOI 10.1109/ISSCC42613.2021.9365958
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang X, 2020, P IEEECVF C COMPUTER, P2330
NR 37
TC 1
Z9 1
U1 1
U2 5
PD JUN
PY 2022
VL 12
IS 2
BP 354
EP 366
DI 10.1109/JETCAS.2022.3168852
UT WOS:000811585100006
DA 2023-11-16
ER

PT C
AU Kunas, CA
   Serpa, MS
   Bez, JL
   Padoin, EL
   Navaux, POA
AF Kunas, Cristiano A.
   Serpa, Matheus S.
   Bez, Jean Luca
   Padoin, Edson L.
   Navaux, Philippe O. A.
GP IEEE COMP SOC
TI Offloading the Training of an I/O Access Pattern Detector to the Cloud
SO 2021 IEEE 33RD INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH
   PERFORMANCE COMPUTING WORKSHOPS (SBAC-PADW 2021)
DT Proceedings Paper
CT 33rd IEEE International Symposium on Computer Architecture and High
   Performance Computing (SBAC-PAD)
CY OCT 26-29, 2021
CL ELECTR NETWORK
DE high-performance computing; access pattern detection; classification;
   TPU; cloud
ID NORMALITY
AB I/O operations are a bottleneck for numerous applications, so optimizing the performance of these operations is of paramount importance. Many techniques explore and apply optimizations to different layers of the I/O stack to improve performance. The difficulty that arises is that the workload changes constantly. So detecting access patterns correctly, at run-time, becomes essential for systems that seek to self-adjust their parameters. Furthermore, the I/O pattern detection techniques should represent minimal overhead and should be able to perform detection as quickly as possible. This paper approaches a machine learning technique for detecting the I/O access patterns and proposes offloading the local training workload to the cloud using a TPU accelerator. Such an approach does not interfere with classifier accuracy (reaching up to 99% accuracy). Still, it allows the training to be asynchronous, enabling the local machine to allocate its computing resources to scientific applications while the model is trained or updated in the cloud.
C1 [Kunas, Cristiano A.; Serpa, Matheus S.; Navaux, Philippe O. A.] Fed Univ Rio Grande do Sul UFRGS, Inst Informat, Porto Alegre, RS, Brazil.
   [Padoin, Edson L.] Reg Univ Northwestern Rio Grande do Sul UNIJUI, Ijui, Brazil.
   [Bez, Jean Luca] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
RP Kunas, CA (corresponding author), Fed Univ Rio Grande do Sul UFRGS, Inst Informat, Porto Alegre, RS, Brazil.
EM cakunas@inf.ufrgs.br; msserpa@inf.ufrgs.br; jlbez@lbl.gov;
   padoin@unijui.edu.br; navaux@inf.ufrgs.br
CR Abadi M., 2016, PROC 12 USENIX C OPE
   Bez JL, 2019, INT SYM COMP ARCHIT, P80, DOI 10.1109/SBAC-PAD.2019.00025
   Boito FZ, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3152891
   Boito FZ, 2016, CONCURR COMP-PRACT E, V28, P2457, DOI 10.1002/cpe.3606
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Carns PH, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE 4TH ANNUAL LINUX SHOWCASE AND CONFERENCE, ATLANTA, P317
   Congiu G, 2016, IEEE INT C CL COMP, P120, DOI 10.1109/CLUSTER.2016.37
   Dorier M, 2014, INT CONF HIGH PERFOR, P623, DOI 10.1109/SC.2014.56
   Google, 2021, CLOUD TPU PERF GUID
   Google, 2021, CLOUD TPU SYST ARCH
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Kim TK, 2015, KOREAN J ANESTHESIOL, V68, P540, DOI 10.4097/kjae.2015.68.6.540
   Kumar S, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503252
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Ma X., 2014, P 12 USENIX C FILE S, P213
   Microsystem S., 2007, LUSTR FIL SYST HIGH
   Moolayil J., 2019, LEARN KERAS DEEP NEU, P1
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Rong Ge, 2012, Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid 2012), P204, DOI 10.1109/CCGrid.2012.39
   Song HM, 2011, HPDC 11: PROCEEDINGS OF THE 20TH INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, P37
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Tang HJ, 2014, LECT NOTES COMPUT SC, V8632, P246, DOI 10.1007/978-3-319-09873-9_21
   Tessier F, 2017, IEEE INT C CL COMP, P70, DOI 10.1109/CLUSTER.2017.80
   Wang Y. E., 2019, ARXIV190710701
   Wang ZX, 2014, IEEE ACM INT SYMP, P287, DOI 10.1109/CCGrid.2014.61
   Yeo IK, 2000, BIOMETRIKA, V87, P954, DOI 10.1093/biomet/87.4.954
   You Y, 2019, IEEE T PARALL DISTR, V30, P2449, DOI 10.1109/TPDS.2019.2913833
NR 27
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 15
EP 19
DI 10.1109/SBAC-PADW53941.2021.00013
UT WOS:000748927600003
DA 2023-11-16
ER

PT J
AU Bennett, CH
   Parmar, V
   Calvet, LE
   Klein, JO
   Suri, M
   Marinella, MJ
   Querlioz, AD
AF Bennett, Christopher H.
   Parmar, Vivek
   Calvet, Laurie E.
   Klein, Jacques-Olivier
   Suri, Manan
   Marinella, Matthew J.
   Querlioz, And Damien
TI Contrasting Advantages of Learning With Random Weights and
   Backpropagation in Non-Volatile Memory Neural Networks
SO IEEE ACCESS
DT Article
DE Hardware neural networks; memristive devices; online learning; edge
   computing
ID REPRESENTATIONS; ALGORITHM; SYNAPSES; CIRCUITS; CROSSBAR; MACHINE;
   ONLINE; DEVICE
AB Recently, a Cambrian explosion of a novel, non-volatile memory (NVM) devices known as memristive devices have inspired effort in building hardware neural networks that learn like the brain. Early experimental prototypes built simple perceptrons from nanosynapses, and recently, fully-connected multi-layer perceptron (MLP) learning systems have been realized. However, while backpropagating learning systems pair well with high-precision computer memories and achieve state-of-the-art performances, this typically comes with a massive energy budget. For future Internet of Things/peripheral use cases, system energy footprint will be a major constraint, and emerging NVM devices may fill the gap by sacrificing high bit precision for lower energy. In this paper, we contrast the well-known MLP approach with the extreme learning machine (ELM) or NoProp approach, which uses a large layer of random weights to improve the separability of high-dimensional tasks, and is usually considered inferior in a software context. However, we find that when taking the device non-linearity into account, NoProp manages to equal hardware MLP system in terms of accuracy. While also using a sign-based adaptation of the delta rule for energy-savings, we find that NoProp can learn effectively with four to six 'bits' of device analog capacity, while MLP requires eight-bit capacity with the same rule. This may allow the requirements for memristive devices to be relaxed in the context of online learning. By comparing the energy footprint of these systems for several candidate nanosynapses and realistic peripherals, we confirm that memristive NoProp systems save energy compared with MLP systems. Lastly, we show that ELM/NoProp systems can achieve better generalization abilities than nanosynaptic MLP systems when paired with pre-processing layers (which do not require backpropagated error). Collectively, these advantages make such systems worthy of consideration in future accelerators or embedded hardware.
C1 [Bennett, Christopher H.; Calvet, Laurie E.; Klein, Jacques-Olivier; Querlioz, And Damien] Univ Paris Saclay, Univ Paris Sud, Ctr Nanosci & Nanotechnol, F-91120 Palaiseau, France.
   [Parmar, Vivek; Suri, Manan] IIT Delhi, Dept Elect Engn, New Delhi 110016, India.
   [Bennett, Christopher H.; Marinella, Matthew J.] Sandia Natl Labs, Albuquerque, NM 87185 USA.
RP Bennett, CH (corresponding author), Univ Paris Saclay, Univ Paris Sud, Ctr Nanosci & Nanotechnol, F-91120 Palaiseau, France.; Bennett, CH (corresponding author), Sandia Natl Labs, Albuquerque, NM 87185 USA.
EM cbennett10@gmail.com
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Agarwal S, 2017, S VLSI TECH, pT174, DOI 10.23919/VLSIT.2017.7998164
   Agarwal S, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00484
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2015, ARXIV150502495
   [Anonymous], 2015, 2015 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2015.7280669
   Bengio, 2016, ABS160202830 CORR
   Bennett CH, 2016, IEEE IJCNN, P947, DOI 10.1109/IJCNN.2016.7727300
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Chabi D, 2015, IEEE T NANOTECHNOL, V14, P954, DOI 10.1109/TNANO.2015.2448554
   Chabi D, 2015, ACM J EMERG TECH COM, V11, DOI 10.1145/2629503
   Chanthbouala A, 2012, NAT MATER, V11, P860, DOI [10.1038/NMAT3415, 10.1038/nmat3415]
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Elfadel IM, 1994, ADV NEURAL INFORMATI, V6, P882
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Gao LG, 2012, IEEE INT CONF VLSI, P87, DOI 10.1109/VLSI-SoC.2012.6379011
   Hasler J, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00118
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jiang H, 2016, SCI REP-UK, V6, DOI 10.1038/srep19547
   Jo S.H., 2014, IEDM
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Joost M, 1998, INT J UNCERTAIN FUZZ, V6, P117, DOI 10.1142/S0218488598000100
   Kataeva I., 2015, 2015 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2015.7280785, DOI 10.1109/IJCNN.2015.7280785]
   Kavehei O., 2011, Proceedings of the 2011 Seventh International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), P137, DOI 10.1109/ISSNIP.2011.6146610
   Keene ST, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aabe70
   Khodabandehloo G, 2012, IEEE T VLSI SYST, V20, P750, DOI 10.1109/TVLSI.2011.2109404
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Y, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P25, DOI 10.1109/VLSIT.2018.8510648
   Li Y, 2013, SCI REP-UK, V3, DOI 10.1038/srep01619
   Lin YP, 2016, SCI REP-UK, V6, DOI 10.1038/srep31932
   Liu CC, 2017, ASIA S PACIF DES AUT, P647, DOI 10.1109/ASPDAC.2017.7858397
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Negrov D, 2017, NEUROCOMPUTING, V237, P193, DOI 10.1016/j.neucom.2016.10.061
   Park S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10123
   Parmar V, 2018, PR GR LAK SYMP VLSI, P391, DOI 10.1145/3194554.3194614
   Pershin YV, 2010, IEEE T CIRCUITS-I, V57, P1857, DOI 10.1109/TCSI.2009.2038539
   Pfeil T, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00090
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Querlioz D., 2011, 2011 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH), P150, DOI 10.1109/NANOARCH.2011.5941497
   Rajendran B, 2015, I CONF VLSI DESIGN, P1, DOI 10.1109/VLSID.2015.109
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saïghi S, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00051
   Salakhutdinov R., 2009, ARTIF INTELL, P448
   SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0
   Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X
   Shamsi J, 2015, IEEE INT SYMP CIRC S, P581, DOI 10.1109/ISCAS.2015.7168700
   Shelby RM, 2015, INT RELIAB PHY SYM
   Sidler S, 2016, PROC EUR S-STATE DEV, P440, DOI 10.1109/ESSDERC.2016.7599680
   Soudry D, 2015, IEEE T NEUR NET LEAR, V26, P2408, DOI 10.1109/TNNLS.2014.2383395
   Stathopoulos S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17785-1
   Strachan JP, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/50/505402
   Sun XL, 2020, INT J OCCUP SAF ERGO, V26, P740, DOI 10.1080/10803548.2018.1486528
   Suri M, 2015, IEEE T NANOTECHNOL, V14, P963, DOI 10.1109/TNANO.2015.2441112
   Suri M, 2012, J APPL PHYS, V112, DOI 10.1063/1.4749411
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502
   Ueda M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112659
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/NMAT4856, 10.1038/nmat4856]
   van Schaik A, 2015, NEUROCOMPUTING, V149, P233, DOI 10.1016/j.neucom.2014.01.071
   Vanhoucke Vincent, 2011, DEEP LEARNING UNSUPE
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang WJ, 2012, SCI REP-UK, V2, DOI 10.1038/srep00360
   Wang YH, 2015, IEEE T NANOTECHNOL, V14, P998, DOI 10.1109/TNANO.2015.2447531
   Widrow B, 2013, NEURAL NETWORKS, V37, P180, DOI 10.1016/j.neunet.2012.09.020
   Woo J, 2016, IEEE ELECTR DEVICE L, V37, P994, DOI 10.1109/LED.2016.2582859
   Woods W, 2015, IEEE T NANOTECHNOL, V14, P945, DOI 10.1109/TNANO.2015.2449835
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhang QT, 2018, NEURAL NETWORKS, V108, P217, DOI 10.1016/j.neunet.2018.08.012
   Zunino RF, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P117
NR 78
TC 7
Z9 7
U1 0
U2 5
PY 2019
VL 7
BP 73938
EP 73953
DI 10.1109/ACCESS.2019.2920076
UT WOS:000472777600001
DA 2023-11-16
ER

PT J
AU Esmaeilzadeh, H
   Sampson, A
   Ceze, L
   Burger, D
AF Esmaeilzadeh, Hadi
   Sampson, Adrian
   Ceze, Luis
   Burger, Doug
TI Neural Acceleration for General-Purpose Approximate Programs
SO COMMUNICATIONS OF THE ACM
DT Article
AB As improvements in per-transistor speed and energy efficiency diminish, radical departures from conventional approaches are needed to continue improvements in the performance and energy efficiency of general-purpose processors. One such departure is approximate computing, where error in computation is acceptable and the traditional robust digital abstraction of near-perfect accuracy is relaxed. Conventional techniques in energy-efficient computing navigate a design space defined by the two dimensions of performance and energy, and traditionally trade one for the other. General-purpose approximate computing explores a third dimension-error-and trades the accuracy of computation for gains in both energy and performance. Techniques to harvest large savings from small errors have proven elusive. This paper describes a new approach that uses machine learning-based transformations to accelerate approximation-tolerant programs. The core idea is to train a learning model how an approximable region of code-code that can produce imprecise but acceptable results-behaves and replace the original code region with an efficient computation of the learned model. We use neural networks to learn code behavior and approximate it. We describe the Parrot algorithmic transformation, which leverages a simple programmer annotation ("approximable") to transform a code region from a von Neumann model to a neural model. After the learning phase, the compiler replaces the original code with an invocation of a low-power accelerator called a neural processing unit (NPU). The NPU is tightly coupled to the processor pipeline to permit profitable acceleration even when small regions of code are transformed. Offloading approximable code regions to NPUs is faster and more energy efficient than executing the original code. For a set of diverse applications, NPU acceleration provides whole-application speedup of 2.3x and energy savings of 3.0x on average with average quality loss of at most 9.6%. NPUs form a new class of accelerators and show that significant gains in both performance and efficiency are achievable when the traditional abstraction of near-perfect accuracy is relaxed in general-purpose computing.
C1 [Esmaeilzadeh, Hadi] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Sampson, Adrian; Ceze, Luis] Univ Washington, Seattle, WA 98195 USA.
   [Burger, Doug] Microsoft Res, Redmond, WA USA.
RP Esmaeilzadeh, H (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM hadi@cc.gatech.edu; asampson@cs.washington.edu;
   luisceze@cs.washington.edu; dburger@microsoft.com
CR [Anonymous], 2010, ISCA
   [Anonymous], 2009, MICRO
   [Anonymous], 2012, INT S MICR MICRO
   [Anonymous], 2010, PLDI
   Chakrapani Lakshmi N., 2006, DATE
   Chen T., 2012, IISWC
   de Kruijf M., 2010, ISCA
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Esmaeilzadeh H., 2006, ISCAS
   Esmaeilzadeh H., 2012, ASPLOS
   Esmaeilzadeh H, 2013, COMMUN ACM, V56, P93, DOI 10.1145/2408776.2408797
   Galal S, 2011, IEEE T COMPUT, V60, P913, DOI 10.1109/TC.2010.121
   Govindaraju V., 2011, HPCA
   Gupta Shantanu, 2011, MICRO
   Guzhva A., 2009, ICANN
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Hashmi A., 2011, ISCA
   Joubert A., 2012, IJCNN
   Liu S., 2011, ASPLOS
   Muralimanohar N., 2007, MICRO
   Narayanan S., 2010, DATE
   Patel A., 2011, DAC
   Putnam Andrew R., 2008, FPGA
   Razdan R., 1994, MICRO
   Rumelhart D.E., 1987, LEARNING INTERNAL RE, P318
   Sampson A., 2011, PLDI
   Sidiroglou-Douskos  S., 2011, FSE
   Temam O., 2012, ISCA
   Venkatesh G., 2010, ASPLOS
   Zhu J., 2003, FPL
NR 30
TC 25
Z9 27
U1 1
U2 12
PD JAN
PY 2015
VL 58
IS 1
BP 105
EP 115
DI 10.1145/2589750
UT WOS:000348302400029
DA 2023-11-16
ER

PT J
AU Sivabhaskar, S
   Li, RQ
   Roy, A
   Kirby, N
   Fakhreddine, M
   Papanikolaou, N
AF Sivabhaskar, Sruthi
   Li, Ruiqi
   Roy, Arkajyoti
   Kirby, Neil
   Fakhreddine, Mohamad
   Papanikolaou, Nikos
TI Machine learning models to predict the delivered positions of Elekta
   multileaf collimator leaves for volumetric modulated arc therapy
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE Elekta; log files; machine learning; MLC positional deviations; VMAT
ID MLC LEAF POSITION; IMRT DELIVERY; ERRORS; PLANS; PERFORMANCE;
   COMPLEXITY; ACCURACY; IMPACT; ANGLE
AB Purpose Accurate positioning of multileaf collimator (MLC) leaves during volumetric modulated arc therapy (VMAT) is essential for accurate treatment delivery. We developed a linear regression, support vector machine, random forest, extreme gradient boosting (XGBoost), and an artificial neural network (ANN) for predicting the delivered leaf positions for VMAT plans. Methods For this study, 160 MLC log files from 80 VMAT plans were obtained from a single institution treated on 3 Elekta Versa HD linear accelerators. The gravity vector, X1 and X2 jaw positions, leaf gap, leaf position, leaf velocity, and leaf acceleration were extracted and used as model inputs. The models were trained using 70% of the log files and tested on the remaining 30%. Mean absolute error (MAE), root mean square error (RMSE), the coefficient of determination R-2, and fitted line plots showing the relationship between delivered and predicted leaf positions were used to evaluate model performance. Results The models achieved the following errors: linear regression (MAE = 0.158 mm, RMSE = 0.225 mm), support vector machine (MAE = 0.141 mm, RMSE = 0.199 mm), random forest (MAE = 0.161 mm, RMSE = 0.229 mm), XGBoost (MAE = 0.185 mm, RMSE = 0.273 mm), and ANN (MAE = 0.361 mm, RMSE = 0.521 mm). A significant correlation between a plan's gamma passing rate (GPR) and the prediction errors of linear regression, support vector machine, and random forest is seen (p < 0.045). Conclusions We examined various models to predict the delivered MLC positions for VMAT plans treated with Elekta linacs. Linear regression, support vector machine, random forest, and XGBoost achieved lower errors than ANN. Models that can accurately predict the individual leaf positions during treatment can help identify leaves that are deviating from the planned position, which can improve a plan's GPR.
C1 [Sivabhaskar, Sruthi; Li, Ruiqi; Kirby, Neil; Fakhreddine, Mohamad; Papanikolaou, Nikos] Univ Texas Hlth Sci Ctr San Antonio, Dept Radiat Oncol, 7979 Wurzbach Rd, San Antonio, TX 78229 USA.
   [Roy, Arkajyoti] Univ Texas Hlth Sci Ctr San Antonio, Dept Management Sci & Stat, San Antonio, TX 78229 USA.
RP Papanikolaou, N (corresponding author), Univ Texas Hlth Sci Ctr San Antonio, Dept Radiat Oncol, 7979 Wurzbach Rd, San Antonio, TX 78229 USA.
EM papanikolaou@uthscsa.edu
CR Alexopoulos EC, 2010, HIPPOKRATIA, V14, P23
   Bai S, 2013, MED DOSIM, V38, P143, DOI 10.1016/j.meddos.2012.10.002
   Basak D., 2007, EFFICIENT LEARNING M, V11, P203
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brown G, 2010, ENCY MACHINE LEARNIN, V312, DOI [DOI 10.1007/978-0-387-30164-8_252, 10.1007/978-0-387-30164-8_252]
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chuang KC, 2021, MED PHYS, V48, P978, DOI 10.1002/mp.14670
   Chuang KC, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/abc86c
   El Naqa I, 2018, MED PHYS, V45, pE834, DOI 10.1002/mp.12811
   Galvin J., 2001, BASIC APPL MULTILEAF
   Galvin J. M., 1999, P AAPM ANN M NASHV T
   Huq MS, 2002, PHYS MED BIOL, V47, pN159, DOI 10.1088/0031-9155/47/12/401
   Ju S, 2014, MED PHYS, V41, P267, DOI 10.1118/1.4888525
   Kabat CN, 2019, MED PHYS, V46, P1397, DOI 10.1002/mp.13374
   Kamperis E, 2020, INT J RADIAT ONCOL, V106, P182, DOI 10.1016/j.ijrobp.2019.09.003
   Kimura Y, 2021, MED PHYS, V48, P4769, DOI 10.1002/mp.15031
   Krenker A, 2011, ARTIFICIAL NEURAL NETWORKS - METHODOLOGICAL ADVANCES AND BIOMEDICAL APPLICATIONS, P3, DOI 10.5772/15751
   Kumari K., 2018, J PRACT CARDIOVASC S, V4, P33, DOI DOI 10.4103/JPCS.JPCS_8_18
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Ling CC, 2008, INT J RADIAT ONCOL, V72, P575, DOI 10.1016/j.ijrobp.2008.05.060
   Liu C, 2008, INT J RADIAT ONCOL, V71, pS89, DOI 10.1016/j.ijrobp.2007.07.2392
   Losasso T, 2008, INT J RADIAT ONCOL, V71, pS85, DOI 10.1016/j.ijrobp.2007.06.082
   Mu G, 2008, PHYS MED BIOL, V53, P77, DOI 10.1088/0031-9155/53/1/005
   Nithiyanantham K, 2015, J APPL CLIN MED PHYS, V16, P296, DOI 10.1120/jacmp.v16i5.5515
   Oliver M, 2010, RADIOTHER ONCOL, V97, P554, DOI 10.1016/j.radonc.2010.06.013
   Osman AFI, 2020, MED PHYS, V47, P1421, DOI 10.1002/mp.14014
   Park JM, 2019, RADIAT ONCOL, V14, DOI 10.1186/s13014-019-1441-7
   Potter NJ, 2020, MED PHYS, V47, P4711, DOI 10.1002/mp.14416
   Probst P, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1301
   Puchades-Puchades V, 2015, J RADIOTHER PRACT, V14, P323, DOI 10.1017/S1460396915000217
   Rangel A, 2009, MED PHYS, V36, P3304, DOI 10.1118/1.3134244
   Schneider A, 2010, DTSCH ARZTEBL INT, V107, P776, DOI [10.3238/arztebl.2010.0776, 10.3238/arztebl.2010.0799]
   Tatsumi D, 2011, PHYS MED BIOL, V56, pN237, DOI 10.1088/0031-9155/56/20/N03
   Tripepi G, 2008, KIDNEY INT, V73, P806, DOI 10.1038/sj.ki.5002787
   Wijesooriya K, 2012, MED PHYS, V39, P1846, DOI 10.1118/1.3690464
   Xu ZZ, 2016, RADIOL ONCOL, V50, P121, DOI 10.1515/raon-2016-0008
   Younge KC, 2016, J APPL CLIN MED PHYS, V17, P124, DOI 10.1120/jacmp.v17i4.6241
NR 38
TC 1
Z9 1
U1 1
U2 5
PD AUG
PY 2022
VL 23
IS 8
AR e13667
DI 10.1002/acm2.13667
EA JUN 2022
UT WOS:000806966000001
DA 2023-11-16
ER

PT C
AU Chen, Y
   Long, X
   He, J
   Chen, YH
   Tan, HS
   Zhang, ZX
   Winslett, M
   Chen, DM
AF Chen, Yao
   Long, Xin
   He, Jiong
   Chen, Yuhang
   Tan, Hongshi
   Zhang, Zhenxiang
   Winslett, Marianne
   Chen, Deming
GP IEEE Comp Soc
TI HaoCL: Harnessing Large-scale Heterogeneous Processors Made Easy
SO 2020 IEEE 40TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS)
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 40th IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY NOV 29-DEC 01, 2020
CL ELECTR NETWORK
DE heterogeneous cluster; distributed computing; OpenCL; machine learning;
   deep learning
AB The pervasive adoption of Deep Learning (DL) and Graph Processing (GP) makes it a de facto requirement to build large-scale clusters of heterogeneous accelerators including GPUs and FPGAs. The OpenCL programming framework can be used on the individual nodes of such clusters but is not intended for deployment in a distributed manner. Fortunately, the original OpenCL semantics naturally fit into the programming environment of heterogeneous clusters. In this paper, we propose a heterogeneity-aware OpenCL-like (HaoCL) programming framework to facilitate the programming of a wide range of scientific applications including DL and GP workloads on large-scale heterogeneous clusters. With HaoCL, existing applications can be directly deployed on heterogeneous clusters without any modifications to the original OpenCL source code and without awareness of the underlying hardware topologies and configurations. Our experiments show that HaoCL imposes a negligible overhead in a distributed environment, and provides near-liner speedups on standard benchmarks when computation or data size exceeds the capacity of a single node. The system design and the evaluations are presented in this demo paper.
C1 [Chen, Yao; Chen, Yuhang; Winslett, Marianne] Adv Digital Sci Ctr, Singapore, Singapore.
   [Long, Xin; Zhang, Zhenxiang] Alibaba Grp, Shenzhen, Guangdong, Peoples R China.
   [He, Jiong] ASTAR, Inst High Performance Comp, Singapore, Singapore.
   [Tan, Hongshi] Natl Univ Singapore, Singapore, Singapore.
   [Winslett, Marianne; Chen, Deming] Univ Illinois, Champaign, IL USA.
RP Chen, Y (corresponding author), Adv Digital Sci Ctr, Singapore, Singapore.
CR [Anonymous], 2010, GPGPU
   [Anonymous], 2003, BOOST C LIB
   [Anonymous], 2009, IISWC
   [Anonymous], 2009, 2009 IEEE 7 S APPL S, DOI DOI 10.1109/SASP.2009.5226333
   Barak A., 2010, CLUST WORKSH
   Chen D., 2010, IEEE T VERY LARGE SC, P564
   CHEN W, 2005, SRC TECHCON, V5, DOI DOI 10.1166/JNN.2005.301
   Chen X., 2019, FPL
   Duato J., 2009, EURO PAR
   eral Y. Chcn, 2019, FPGA
   He J., 2018, ICDCS
   Kim J., 2016, PLDI
   Kim J., 2012, ICS
NR 13
TC 1
Z9 1
U1 0
U2 1
PY 2020
BP 1231
EP 1234
DI 10.1109/ICDCS47774.2020.00120
UT WOS:000667971400134
DA 2023-11-16
ER

PT C
AU Zheng, SZ
   Liang, Y
   Wang, S
   Chen, RZ
   Sheng, KW
AF Zheng, Size
   Liang, Yun
   Wang, Shuo
   Chen, Renze
   Sheng, Kaiwen
GP ACM
TI FlexTensor: An Automatic Schedule Exploration and Optimization Framework
   for Tensor Computation on Heterogeneous System
SO TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR
   PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV)
DT Proceedings Paper
CT 25th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY MAR 16-20, 2020
CL Lausanne, SWITZERLAND
DE code generation; compiler optimization; heterogeneous systems; machine
   learning
AB Tensor computation plays a paramount role in a broad range of domains, including machine learning, data analytics, and scientific computing. The wide adoption of tensor computation and its huge computation cost has led to high demand for flexible, portable, and high-performance library implementation on heterogeneous hardware accelerators such as GPUs and FPGAs. However, the current tensor library implementation mainly requires programmers to manually design low-level implementation and optimize from the algorithm, architecture, and compilation perspectives. Such a manual development process often takes months or even years, which falls far behind the rapid evolution of the application algorithms.
   In this paper, we introduce FlexTensor, which is a schedule exploration and optimization framework for tensor computation on heterogeneous systems. FlexTensor can optimize tensor computation programs without human interference, allowing programmers to only work on high-level programming abstraction without considering the hardware platform details. FlexTensor systematically explores the optimization design spaces that are composed of many different schedules for different hardware. Then, FlexTensor combines different exploration techniques, including heuristic method and machine learning method to find the optimized schedule configuration. Finally, based on the results of exploration, customized schedules are automatically generated for different hardware. In the experiments, we test 12 different kinds of tensor computations with totally hundreds of test cases and FlexTensor achieves average 1.83x performance speedup on NVIDIA V100 GPU compared to cuDNN; 1.72x performance speedup on Intel Xeon CPU compared to MKL-DNN for 2D convolution; 1.5x performance speedup on Xilinx VU9P FPGA compared to OpenCL baselines; 2.21x speedup on NVIDIA V100 GPU compared to the state-of-the-art.
C1 [Zheng, Size; Liang, Yun; Wang, Shuo; Chen, Renze; Sheng, Kaiwen] Peking Univ, Dept CS, CECA, Beijing, Peoples R China.
RP Liang, Y (corresponding author), Peking Univ, Dept CS, CECA, Beijing, Peoples R China.
EM zhengsz@pku.edu.cn; ericlyun@pku.edu.cn; shvowang@pku.edu.cn;
   crz@pku.edu.cn; sheng_kaiwen@pku.edu.cn
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Agarap AF, 2018, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1803.08375
   [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   [Anonymous], 2015, ICLR
   Belter G, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Bondhugula U, 2008, PLDI'08: PROCEEDINGS OF THE 2008 SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN & IMPLEMENTATION, P101, DOI 10.1145/1375581.1375595
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TQ, 2018, ADV NEUR IN, V31
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cong J, 2011, IEEE T COMPUT AID D, V30, P939, DOI 10.1109/TCAD.2011.2106370
   Dagum Leonardo, 1988, COMPUTATIONAL SCI EN, V5, P1
   De Matteis Tiziano, 2019, ABS190707929 CORR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Farooqui Naila, 2014, 2014 C TIM RES OP SY
   Frigo M, 1998, INT CONF ACOUST SPEE, P1381, DOI 10.1109/ICASSP.1998.681704
   Georganas E., 2018, P INT C HIGH PED COM
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karmani RK., 2011, ENCY PARALLEL COMPUT, P95
   Kim DaeGon, 2007, SC 07 P 2007 ACMIEEE, DOI 10.1145/1362622.1362691
   Kim Y, 2014, CONVOLUTIONAL NEURAL, DOI 10.3115/v1/D14-1181
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Lavin A., 2015, FAST ALGORITHMS CONV
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li B, 2018, PR IEEE SEN ARRAY, P578, DOI 10.1109/SAM.2018.8448770
   Li XQ, 2019, ADV MATER SCI ENG, V2019, DOI 10.1155/2019/6384360
   Liang Y, 2018, IEEE T COMPUT, V67, P1750, DOI 10.1109/TC.2018.2840686
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Mathieu Michael, 2013, ARXIV13125851
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI [10.1145/2694344.2694364, 10.1145/2775054.2694364]
   Nakatsuji M, 2017, IEEE T COMPUT SOC SY, V4, P207, DOI 10.1109/TCSS.2017.2732685
   NVIDIA(R), CUBLAS LIB
   Papalexakis EE, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2915921
   Paszke A., 2019, ADV NEURAL INFORM PR
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91
   Roesch Jared, 2019, ABS190408368 CORR
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sermanet Pierre, 2014, P 2 INT C LEARN REPR
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Vasilache N., 2018, CORR
   Venkat A, 2019, INT J HIGH PERFORM C, V33, P1275, DOI 10.1177/1094342019866247
   Verdoolaege Sven, 2013, ACM T ARCHIT CODE OP, V9, DOI [10.1145/2400682.2400713, DOI 10.1145/2400682.2400713]
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xie XL, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P195, DOI 10.1145/3307681.3325407
   Xie XL, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P395, DOI 10.1145/2830772.2830813
   Zeiler M.D., 2012, ADADELTA ADAPTIVE LE
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang KX, 2018, DESTECH TRANS ECON, P32
NR 62
TC 65
Z9 69
U1 1
U2 7
PY 2020
BP 859
EP 873
DI 10.1145/3373376.3378508
UT WOS:000541369300055
DA 2023-11-16
ER

PT C
AU Amiraski, M
   Werner, D
   Hankin, A
   Sebot, J
   Vaidyanathan, K
   Hempstead, M
AF Amiraski, Maziar
   Werner, David
   Hankin, Alexander
   Sebot, Julien
   Vaidyanathan, Kaushik
   Hempstead, Mark
GP IEEE
TI Boreas: A Cost-Effective Mitigation Method for Advanced Hotspots using
   Machine Learning and Hardware Telemetry
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE, ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY APR 23-25, 2023
CL Raleigh, NC
ID MANAGEMENT
AB Managing advanced hotspots on modern microprocessors is a critical and worsening issue, affecting performance, product reliability, and device lifetime. Many thermal management techniques focus primarily on remaining below a critical temperature, and while they are successful to that end, they come with a significant performance cost. This cost stems from the large temperature guardbands that are needed to ensure device safety and correct IC operation. These guardbands must be sized to account for multiple factors including 1) control-loop latency, 2) thermal sensor delay, 3) thermal gradients inside timing paths that could result in timing violations, and 4) the instantaneous temperature delta between a temperature sensor and the true peak temperature on the IC.
   This work demonstrates the need for novel hotspot avoidance techniques that can react quickly and simultaneously account for each of these concerns in order to safely maximize performance. Recently introduced hotspot metrics-Hotspot-Severity and Maximum Local Temperature Difference (MLTD)-are used in order to allow model designers to have a single optimization target that accounts for each of these thermal concerns simultaneously. We present Boreas, a novel hotspot mitigation technique that uses a Machine Learning model implemented in an on-chip specialized hardware accelerator that leverages micro-architectural performance counters. Boreas outperforms existing thermal management techniques while remaining lightweight and well-suited for implementation in hardware. Even with a conservative thermal sensor delay, Boreas is able to predict severity with high precision, resulting in effective hotspot mitigation on unseen workloads. These machine learning models were, therefore, able to select a frequency that was 4.5% better than thermal only models on average, and up to 9.6% higher in the best case, while having the same reliability budget as the thermal models.
C1 [Amiraski, Maziar; Werner, David; Hempstead, Mark] Tufts Univ, Medford, MA 02155 USA.
   [Sebot, Julien] Intel Corp, Hillsboro, OR USA.
   [Vaidyanathan, Kaushik] Google Inc, Sunnyvale, CA USA.
   [Hankin, Alexander] Harvard Univ, Cambridge, MA 02138 USA.
   [Hankin, Alexander] Intel Labs, Hillsboro, OR USA.
RP Amiraski, M (corresponding author), Tufts Univ, Medford, MA 02155 USA.
EM maziar.mehdizadehamiraski@tufts.edu; david.werner@tufts.edu
CR [Anonymous], 2015, P ACM GREAT LAKES S
   Bakhshalipour M, 2019, INT S HIGH PERF COMP, P399, DOI 10.1109/HPCA.2019.00053
   Bar-Cohen A, 2006, P IEEE, V94, P1549, DOI 10.1109/JPROC.2006.879791
   Bartolini A, 2011, DES AUT TEST EUROPE, P830
   Bartolini A, 2013, IEEE T PARALL DISTR, V24, P170, DOI 10.1109/TPDS.2012.117
   Bera R., 2021, MICRO54 54 ANN IEEEA, P1121
   Cao LP, 1998, IEEE T COMPON PACK A, V21, P113, DOI 10.1109/95.679040
   Ching-Han Tsai, 1999, Proceedings. 1999 International Symposium on Physical Design, P179, DOI 10.1145/299996.300067
   Cochran R, 2010, DES AUT CON, P62
   Das A, 2014, DES AUT CON, DOI 10.1145/2593069.2593199
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Hankin A, 2021, I S WORKL CHAR PROC, P163, DOI 10.1109/IISWC53511.2021.00025
   Iranfar A, 2015, I SYMPOS LOW POWER E, P291, DOI 10.1109/ISLPED.2015.7273529
   Jiménez DA, 2001, HPCA: SEVENTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTING ARCHITECTURE, PROCEEDINGS, P197, DOI 10.1109/HPCA.2001.903263
   Jung-Chang Wang, 2009, 2009 4th International Microsystems, Packaging, Assembly and Circuits Technology Conference (IMPACT), P364, DOI 10.1109/IMPACT.2009.5382193
   Kondguli S, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3170433
   Lee PS, 2005, HEAT TRANSF DIV ASME, V376-1, P643
   Lee YJ, 2013, IEEE T COMP PACK MAN, V3, P1332, DOI 10.1109/TCPMT.2013.2244164
   Lo D, 2014, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2014.6835969
   Lyons MJ, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086727
   Mukherjee R, 2005, DES AUT CON, P196
   Pagani S, 2020, IEEE T COMPUT AID D, V39, P101, DOI 10.1109/TCAD.2018.2878168
   Schafer BC, 2009, IET COMPUT DIGIT TEC, V3, P62, DOI 10.1049/iet-cdt:20070159
   Schafer BC, 2008, IEEE T VLSI SYST, V16, P1475, DOI 10.1109/TVLSI.2008.2001140
   Shi Z, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P413, DOI 10.1145/3352460.3358319
   Teran E, 2016, INT SYMP MICROARCH
   wikichip, M1 APPLE
   Wu Q, 2005, INT SYMP MICROARCH, P271
   Ye R, 2012, ASIA S PACIF DES AUT, P115, DOI 10.1109/ASPDAC.2012.6164929
   Yu SJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188428
NR 30
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 295
EP 305
DI 10.1109/ISPASS57527.2023.00036
UT WOS:001017781500027
DA 2023-11-16
ER

PT J
AU Naito, YI
   Yamane, M
   Kitagawa, H
AF Naito, Yuichi I.
   Yamane, Masako
   Kitagawa, Hiroyuki
TI A protocol for using attenuated total reflection Fourier-transform
   infrared spectroscopy for pre-screening ancient bone collagen prior to
   radiocarbon dating
SO RAPID COMMUNICATIONS IN MASS SPECTROMETRY
DT Article
ID PRESERVATION; EXTRACTION; INDICATORS; DIAGENESIS; SURFACES; SAMPLES;
   RATIOS; CARBON; AGE
AB Rationale Pre-screening of bone collagen quality is important to reduce the cost for analyses such as radiocarbon (C-14) dating with accelerator mass spectrometry in archaeological studies. We developed a pre-screening protocol based on attenuated total reflection (ATR) Fourier-transform infrared spectroscopy (FTIR) for assessing the chemical composition and mineralogy of ancient bone samples.
   Methods ATR-FTIR measurements were performed on bulk bones of diverse origin and age before collagen extraction. The percentage nitrogen of bulk bones, as well as the weight percentage, and the percentage carbon and nitrogen of extracted organic matter were noted. Several machine learning algorithms were applied to the spectral data and compared for their efficacy in screening for well preserved collagen.
   Results The results showed that (a) the first derivative of the spectral data was better suited to screening than the raw FTIR data, especially for a wider spectral range and (b) certain classification algorithms [e.g. gradient boosting machine (GBM)] were able to efficiently predict the degree of preservation in bone samples.
   Conclusions This pre-screening protocol can serve as a fast, concise and inexpensive pre-screening tool for determining relative degrees of preservation before collagen extraction and subsequent C-14 dating. The screening power based on the machine learning techniques can be further improved by accumulating the FTIR spectral data of bones.
C1 [Naito, Yuichi I.] Nagoya Univ, Nagoya Univ Museum, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Yamane, Masako; Kitagawa, Hiroyuki] Nagoya Univ, Inst Space Earth Environm Res ISEE, Chikusa Ku, Furo Cho, Nagoya, Aichi, Japan.
RP Naito, YI (corresponding author), Nagoya Univ, Nagoya Univ Museum, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM ynaito@num.nagoya-u.ac.jp
CR ABE Y, 1972, BIOPOLYMERS, V11, P1817, DOI 10.1002/bip.1972.360110905
   AMBROSE SH, 1990, J ARCHAEOL SCI, V17, P431, DOI 10.1016/0305-4403(90)90007-R
   [Anonymous], 2006, MACLA
   [Anonymous], R LANG ENV STAT COMP
   Bocherens H, 1997, QUATERNARY RES, V48, P370, DOI 10.1006/qres.1997.1927
   Bocherens H, 2005, ANTHROPOLOGIE, V109, P557, DOI 10.1016/j.anthro.2005.06.005
   Bocherens H, 2008, PALAEOGEOGR PALAEOCL, V266, P220, DOI 10.1016/j.palaeo.2008.03.023
   Brock F, 2010, J ARCHAEOL SCI, V37, P855, DOI 10.1016/j.jas.2009.11.015
   Brock F, 2012, RADIOCARBON, V54, P879, DOI 10.1017/S0033822200047524
   Cersoy S, 2017, RADIOCARBON, V59, P679, DOI 10.1017/RDC.2016.82
   Chen T., 2016, KDD16 P 22 ACM, P785, DOI [DOI 10.1145/2939672.2939785, 10.1145/2939672.2939785]
   Crann CA, 2019, J ARCHAEOL SCI-REP, V24, P1059, DOI 10.1016/j.jasrep.2019.03.023
   DENIRO MJ, 1988, GEOCHIM COSMOCHIM AC, V52, P2197, DOI 10.1016/0016-7037(88)90122-6
   DENIRO MJ, 1985, NATURE, V317, P806, DOI 10.1038/317806a0
   Grunenwald A, 2014, ANAL BIOANAL CHEM, V406, P4691, DOI 10.1007/s00216-014-7863-z
   Harvey VL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150650
   HEDGES REM, 1995, J ARCHAEOL SCI, V22, P201, DOI 10.1006/jasc.1995.0022
   Higham T, 2014, NATURE, V512, P306, DOI 10.1038/nature13621
   KITAGAWA H, 1993, RADIOCARBON, V35, P295, DOI 10.1017/S0033822200064973
   Kuhn M, 2013, APPL PREDICTIVE MODE
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Lebon M, 2016, RADIOCARBON, V58, P131, DOI 10.1017/RDC.2015.11
   Lebon M, 2014, PALAEOGEOGR PALAEOCL, V416, P110, DOI 10.1016/j.palaeo.2014.08.001
   Lebon M, 2011, J ANAL ATOM SPECTROM, V26, P922, DOI 10.1039/c0ja00250j
   LONGIN R, 1971, NATURE, V230, P241, DOI 10.1038/230241a0
   Nakamura T, 2016, QUATERN INT, V397, P250, DOI 10.1016/j.quaint.2015.04.014
   Nielsen-Marsh CM, 2000, J ARCHAEOL SCI, V27, P1139, DOI 10.1006/jasc.1999.0537
   Pestle WJ, 2015, J ARCHAEOL SCI, V58, P113, DOI 10.1016/j.jas.2015.03.027
   Seelenbinder J, 2011, SPECTROSCOPY-US, P10
   Sponheimer M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50443-2
   Trueman CNG, 2004, J ARCHAEOL SCI, V31, P721, DOI 10.1016/j.jas.2003.11.003
   Vaiglova P, 2014, RAPID COMMUN MASS SP, V28, P2497, DOI 10.1002/rcm.7044
   Van Klinken GJ, 1999, J ARCHAEOL SCI, V26, P687, DOI 10.1006/jasc.1998.0385
   Vincke D, 2014, TALANTA, V125, P181, DOI 10.1016/j.talanta.2014.02.044
   WEINER S, 1990, J ARCHAEOL SCI, V17, P187, DOI 10.1016/0305-4403(90)90058-D
NR 35
TC 4
Z9 4
U1 1
U2 10
PD MAY 30
PY 2020
VL 34
IS 10
AR e8720
DI 10.1002/rcm.8720
UT WOS:000529873700015
DA 2023-11-16
ER

PT J
AU Gokmen, T
   Vlasov, Y
AF Gokmen, Tayfun
   Vlasov, Yurii
TI Acceleration of Deep Neural Network Training with Resistive Cross-Point
   Devices: Design Considerations
SO FRONTIERS IN NEUROSCIENCE
DT Article
DE deep neural network training; synaptic device; machine learning;
   artificial neural networks; nanotechnology; materials engineering;
   electronic devices; memristive devices
ID ON-CHIP; ARRAY
AB In recent years, deep neural networks (DNN) have demonstrated significant business impact in large scale analysis and classification tasks such as speech recognition, visual object detection, pattern extraction, etc. Training of large DNNs, however, is universally considered as time consuming and computationally intensive task that demands datacenter-scale computational resources recruited for many days. Here we propose a concept of resistive processing unit (RPU) devices that can potentially accelerate DNN training by orders of magnitude while using much less power. The proposed RPU device can store and update the weight values locally thus minimizing data movement during training and allowing to fully exploit the locality and the parallelism of the training algorithm. We evaluate the effect of various RPU device features/non-idealities and system parameters on performance in order to derive the device and system level specifications for implementation of an accelerator chip for DNN training in a realistic CMOS-compatible technology. For large DNNs with about 1 billion weights this massively parallel RPU architecture can achieve acceleration factors of 30, 000x compared to state-of-the-art microprocessors while providing power efficiency of 84, 000 GigaOps/s/W. Problems that currently require days of training on a datacenter-size cluster with thousands of machines can be addressed within hours on a single RPU accelerator. A system consisting of a cluster of RPU accelerators will be able to tackle Big Data problems with trillions of parameters that is impossible to address today like, for example, natural speech recognition and translation between all world languages, real-time analytics on large streams of business and scientific data, integration, and analysis of multimodal sensory data flows from a massive number of IoT (Internet of Things) sensors.
C1 [Gokmen, Tayfun; Vlasov, Yurii] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
   [Vlasov, Yurii] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL USA.
RP Gokmen, T (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
EM tgokmen@us.ibm.com
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   [Anonymous], 2015, P 3 INT C LEARN REPR
   [Anonymous], 2012, NVIDIAS NEXT GEN CUD
   [Anonymous], DEEP LEARNING COTS H
   [Anonymous], ARXIV150102876CSCV
   Arima Y., 1991, IEEE J SOLID-ST CIRC, V26, P1637
   Bi GQ, 1998, J NEUROSCI, V18, P10464, DOI 10.1523/jneurosci.18-24-10464.1998
   Burr G., 2015, IEDM INT EL DEV M WA
   Burr G. W., 2014, 2014 IEEE INT EL DEV
   Chen G, 2014, ISSCC DIG TECH PAP I, V57, P276, DOI 10.1109/ISSCC.2014.6757432
   Chen Y., 2014, 2014 47 ANN IEEE ACM, P609
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Gaines B. R., 1967, PROC AFIPS SPRING JO, P149, DOI [10.1145/1465482.1465505, DOI 10.1145/1465482.1465505]
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gupta S., 2015, ARXIV150202551CSLG
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Indiveri G, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/384010
   Jackson BL, 2013, ACM J EMERG TECH COM, V9, DOI 10.1145/2463585.2463588
   Jensen K., 2013, INT C NOIS FLUCT MON
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jonsson B. E., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P560, DOI 10.1109/ECCTD.2011.6043595
   Jonsson B.E., 2011, PROC 2011 IMEKO IWAD, P132
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuzum D, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/382001
   Le Q.V., 2012, ICML, P507
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LEHMANN C, 1993, IEEE T NEURAL NETWOR, V4, P400, DOI 10.1109/72.217181
   Li B., 2014, 19 AS S PAC DES AUT
   Merkel C, 2014, IEEE INT SOC CONF, P359, DOI 10.1109/SOCC.2014.6948954
   Poppelbaum W., 1967, P NOV 14 16 1967 FAL
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saïghi S, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00051
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Soudry D, 2015, IEEE T NEUR NET LEAR, V26, P2408, DOI 10.1109/TNNLS.2014.2383395
   STEINBUCH K, 1961, KYBERNETIK, V1, P36, DOI 10.1007/BF00293853
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Stuecheli J, 2013, HOT CHIPS C PAL ALT
   Szegedy C., 2015 IEEE C COMPUTER, P1
   Welling M., 2016, ARXIV160208323CSNE
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
   Yu S., 2015, IEDM, P451, DOI 10.1109/IEDM.2015.7409718
   Yu SM, 2013, ADV MATER, V25, P1774, DOI 10.1002/adma.201203680
NR 44
TC 296
Z9 335
U1 5
U2 123
PD JUL 21
PY 2016
VL 10
AR 333
DI 10.3389/fnins.2016.00333
UT WOS:000379996100001
DA 2023-11-16
ER

PT C
AU Pal, S
   Beaumont, J
   Park, DH
   Amarnath, A
   Feng, SY
   Chakrabarti, C
   Kim, HS
   Blaauw, D
   Mudge, T
   Dreslinski, R
AF Pal, Subhankar
   Beaumont, Jonathan
   Park, Dong-Hyeon
   Amarnath, Aporva
   Feng, Siying
   Chakrabarti, Chaitali
   Kim, Hun-Seok
   Blaauw, David
   Mudge, Trevor
   Dreslinski, Ronald
GP IEEE
TI OuterSPACE: An Outer Product based Sparse Matrix Multiplication
   Accelerator
SO 2018 24TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 24th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 24-28, 2018
CL Vienna, AUSTRIA
DE Sparse matrix processing; application-specific hardware; parallel
   computer architecture; hardware-software codesign; hardware accelerators
ID ALGEBRA; PERFORMANCE
AB Sparse matrices are widely used in graph and data analytics, machine learning, engineering and scientific applications. This paper describes and analyzes OuterSPACE, an accelerator targeted at applications that involve large sparse matrices. OuterSPACE is a highly-scalable, energy-efficient, reconfigurable design, consisting of massively parallel Single Program, Multiple Data (SPMD)style processing units, distributed memories, high-speed crossbars and High Bandwidth Memory (HBM).
   We identify redundant memory accesses to non-zeros as a key bottleneck in traditional sparse matrix-matrix multiplication algorithms. To ameliorate this, we implement an outer product based matrix multiplication technique that eliminates redundant accesses by decoupling multiplication from accumulation. We demonstrate that traditional architectures, due to limitations in their memory hierarchies and ability to harness parallelism in the algorithm, are unable to take advantage of this reduction without incurring significant overheads. OuterSPACE is designed to specifically overcome these challenges.
   We simulate the key components of our architecture using gem5 on a diverse set of matrices from the University of Florida's SuiteSparse collection and the Stanford Network Analysis Project and show a mean speedup of 7.9x over Intel Math Kernel Library on a Xeon CPU, 13.0x against cuSPARSE and 14.0x against CUSP when run on an NVIDIA K40 GPU, while achieving an average throughput of 2.9 GFLOPS within a 24 W power budget in an area of 87 mm2.
C1 [Pal, Subhankar; Beaumont, Jonathan; Park, Dong-Hyeon; Amarnath, Aporva; Feng, Siying; Kim, Hun-Seok; Blaauw, David; Mudge, Trevor; Dreslinski, Ronald] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Chakrabarti, Chaitali] Arizona State Univ, Tempe, AZ USA.
RP Pal, S (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM subh@umich.edu; jbbeau@umich.edu; dohypark@umich.edu; aporvaa@umich.edu;
   fengsy@umich.edu; chaitali@asu.edu; hunseok@umich.edu; blaauw@umich.edu;
   tnm@umich.edu; rdreslin@umich.edu
CR A. Tech, 2013, NVIDIA LAUNCH TESL K
   Acer S., 2016, PARALLEL COMPUTING, V59
   Akbudak K., 2017, EXPLOITING LOCALITY
   Alfano M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2624284
   Alvarez L, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P720, DOI 10.1145/2749469.2750411
   [Anonymous], 2013, 2013 IEEE HIGH PERFO
   [Anonymous], CACTI 6 0 TOOL MODEL
   [Anonymous], 2016, 7 GREEN GRAPH 500 LI
   [Anonymous], 2016, JEDEC PUBLISHES HBM2
   [Anonymous], 2019, 6 NEW FACTS FACEBOOK
   [Anonymous], 2012, NVIDIAS NEXT GEN CUD
   [Anonymous], CORR
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Bell N., 2011, SIAM J SCI COMPUT
   Bell Nathan, 2008, NVR2008004 NVIDIA CO
   Bender MA, 2010, THEOR COMPUT SYST, V47, P934, DOI 10.1007/s00224-010-9285-4
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Brin S., 1998, 7 INT WWW C
   Buluc A., INT J HIGH PERFORMAN
   Buluç A, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P1876
   Byn Choi, 2011, Proceedings 2011 International Conference on Parallel Architectures and Compilation Techniques (PACT), P155, DOI 10.1109/PACT.2011.21
   Chapanond A., 2005, Computational & Mathematical Organization Theory, V11, P265, DOI 10.1007/s10588-005-5381-4
   Dalton S, 2015, CUSP GENERIC PARALLE
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Gilbert J. R., COMPUTING SCI ENG, V10, P20
   Gilbert J. R., 2006, P INT WORKSH APPL PA
   Goumas G., 2008, PDP 08
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Hapla V., 2013, USE DIRECT SOLVERS T, P192
   Heinecke A. F., 2008, THESIS
   Intel Corporation, 2011, INT 64 IA 32 ARCH OP
   ITOH S, 1995, COMPUT PHYS COMMUN, V88, P173, DOI 10.1016/0010-4655(95)00031-A
   JOHNSON RW, 1991, J SUPERCOMPUT, V5, P189, DOI 10.1007/BF00127843
   Jouppi N. P., 1990, ISCA 90
   Kaplan H., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P52, DOI 10.1145/1137856.1137866
   Karypis G., 1994, Proceedings Supercomputing '94 (Cat. No.94CH34819), P204, DOI 10.1109/SUPERC.1994.344280
   Kaxiras S., 2012, 2012 IEEE 25th International SOC Conference (SOCC), P230, DOI 10.1109/SOCC.2012.6398353
   Kaxiras S, 2010, IEEE MICRO, V30, P54, DOI 10.1109/MM.2010.82
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Lee E, 2016, IEEE T COMPUT, V65, P1145, DOI 10.1109/TC.2014.2349525
   Leskovec J., SNAP DATASETS STANFO
   Lin C. Y., 2010, P INT C FIELD PROGR, P369
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Matam K., 2012, HIGH PERFORMANCE COM, P1
   Mishra AK, 2017, ASIA S PACIF DES AUT, P635, DOI 10.1109/ASPDAC.2017.7858395
   Murphy Richard C, 2010, INTRO GRAPH 500, V19, P45
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   Penn G, 2006, THEOR COMPUT SCI, V354, P72, DOI 10.1016/j.tcs.2005.11.008
   RABIN MO, 1989, J ALGORITHM, V10, P557, DOI 10.1016/0196-6774(89)90005-9
   Rupp K, 2016, SIAM J SCI COMPUT, V38, pS412, DOI 10.1137/15M1026419
   Satish N, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P979, DOI 10.1145/2588555.2610518
   Sewell K, 2012, IEEE J EM SEL TOP C, V2, P278, DOI 10.1109/JETCAS.2012.2193936
   Shah V, 2007, THESIS
   Sulatycke PD, 1998, FIRST MERGED INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM & SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, P117, DOI 10.1109/IPPS.1998.669899
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Van De Geijn R. A., SUMMA SCALABLE UNIVE
   Van Dongen S., 2000, THESIS, V10, P1
   Vuduc RW., 2005, FAST SPARSE MATRIX V
   Yamazaki I, 2011, LECT NOTES COMPUT SC, V6449, P421, DOI 10.1007/978-3-642-19328-6_38
   Yavits Leonid, 2017, CORR
   Yuster R., 2004, SODA 04, V4, P254
NR 64
TC 109
Z9 110
U1 1
U2 4
PY 2018
BP 724
EP 736
DI 10.1109/HPCA.2018.00067
UT WOS:000440297700057
DA 2023-11-16
ER

PT C
AU Dev, S
   Lo, D
   Cheng, LQ
   Ranganathan, P
AF Dev, Sundar
   Lo, David
   Cheng, Liqun
   Ranganathan, Parthasarathy
GP IEEE
TI Autonomous Warehouse-Scale Computers
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
DE WSC; heterogeneity; machine learning; automation
AB Modern Warehouse-Scale Computers (WSCs), composed of many generations of servers and a myriad of domain specific accelerators, are becoming increasingly heterogeneous. Meanwhile, WSC workloads are also becoming incredibly diverse with different communication patterns, latency requirements, and service level objectives (SLOs). Insufficient understanding of the interactions between workload characteristics and the underlying machine architecture leads to resource over-provisioning, thereby significantly impacting the utilization of WSCs.
   We present Autonomous Warehouse-Scale Computers, a new WSC design that leverages machine learning techniques and automation to improve job scheduling, resource management, and hardware-software co-optimization to address the increasing heterogeneity in WSC hardware and workloads. Our new design introduces two new layers in the WSC stack, namely: (a) a Software-Defined Server (SDS) Abstraction Layer which redefines the hardware-software boundary and provides greater control of the hardware to higher layers of the software stack through stable abstractions; and (b) a WSC Efficiency Layer which regularly monitors the resource usage of workloads on different hardware types, autonomously quantifies the performance sensitivity of workloads to key system configurations, and continuously improves scheduling decisions and hardware resource QoS policies to maximize cluster level performance. Our new WSC design has been successfully deployed across all WSCs at Google for several years now. The new WSC design improves throughput of workloads (by 7-10%, on average), increases utilization of hardware resources (up to 2x), and reduces performance variance for critical workloads (up to 25%).
C1 [Dev, Sundar; Lo, David; Cheng, Liqun; Ranganathan, Parthasarathy] Google, Mountain View, CA 94043 USA.
RP Dev, S (corresponding author), Google, Mountain View, CA 94043 USA.
EM sundarjdev@google.com; davidlo@google.com; liquncheng@google.com;
   parthas@google.com
CR [Anonymous], 2018, SYNTHESIS LECT COMPU
   Asanovic K, 2009, COMMUN ACM, V52, P56, DOI 10.1145/1562764.1562783
   Ayers G, 2018, INT S HIGH PERF COMP, P643, DOI 10.1109/HPCA.2018.00061
   Delimitrou C, 2018, COMMUN ACM, V61, P65, DOI 10.1145/3232559
   Delimitrou C, 2013, ACM T COMPUT SYST, V31, DOI 10.1145/2556583
   Haque ME, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P625, DOI 10.1145/3123939.3123956
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kanev S, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P158, DOI 10.1145/2749469.2750392
   Kasture H, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P598, DOI 10.1145/2830772.2830797
   Lo D, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P450, DOI 10.1145/2749469.2749475
   Lo D, 2014, CONF PROC INT SYMP C, P301, DOI 10.1109/ISCA.2014.6853237
   Lottarini A, 2018, ACM SIGPLAN NOTICES, V53, P797, DOI [10.1145/3296957.3173207, 10.1145/3173162.3173207]
   Prekas G, 2015, ACM SOCC'15: PROCEEDINGS OF THE SIXTH ACM SYMPOSIUM ON CLOUD COMPUTING, P342, DOI 10.1145/2806777.2806848
   Sriraman A, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P513, DOI 10.1145/3307650.3322227
   Volos S, 2017, IEEE MICRO, V37, P90, DOI 10.1109/MM.2017.32
   Weaver V., PERF EVENT PROGRAMMI
NR 16
TC 1
Z9 1
U1 0
U2 0
PY 2020
AR 76.1
DI 10.1109/dac18072.2020.9218509
UT WOS:000628528400021
DA 2023-11-16
ER

PT J
AU Gulfidan, G
   Beklen, H
   Arga, KY
AF Gulfidan, Gizem
   Beklen, Hande
   Arga, Kazim Yalcin
TI Artificial Intelligence as Accelerator for Genomic Medicine and
   Planetary Health
SO OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY
DT Review
DE artificial intelligence; machine learning; deep learning; genomic
   medicine; planetary health; One Health; ecology
ID INTERNET; THINGS; DISCOVERY; GUIDE; OMICS
AB Genomic medicine has made important strides over the past several decades, but as new insights and technologies emerge, the applications of genomics in medicine and planetary health continue to evolve and expand. An important grand challenge is harnessing and making sense of the genomic big data in ways that best serve public and planetary health. Because human health is inextricably intertwined with the health of planetary ecosystems and nonhuman animals, genomic medicine is in need of high throughput bioinformatics analyses to harness and integrate human and ecological multiomics big data. It is in this overarching context that artificial intelligence (AI), particularly machine learning and deep learning, offers enormous potentials to advance genomic medicine in a spirit of One Health. This expert review offers an analysis of the rapidly emerging role of AI in genomic medicine, including its current drivers, levers, opportunities, and challenges. The scope of AI applications in genomic medicine is broad, ranging from efficient and automated data analysis to drug repurposing and precision medicine, as with its challenges such as veracity of the big data that AI sorely depends on, social biases that the AI-driven algorithms can introduce, and how best to incorporate AI with human intelligence. The road ahead for AI in genomic medicine is complex and arduous and yet worthy of cautious optimism as we face future pandemics and ecological crises in the 21st century. Now is a good time to think about the role of AI in genomic medicine and planetary health.
C1 [Gulfidan, Gizem; Beklen, Hande; Arga, Kazim Yalcin] Marmara Univ, Dept Bioengn, Istanbul, Turkey.
RP Arga, KY (corresponding author), Marmara Univ, Fac Engn, Dept Bioengn, Bldg D,Off 405, TR-34722 Istanbul, Turkey.
EM kazim.arga@marmara.edu.tr
CR Arga KY, 2021, J PERS MED, V11, DOI 10.3390/jpm11040271
   Arga KY, 2020, OMICS, V24, P512, DOI 10.1089/omi.2020.0093
   Arga KY, 2019, OMICS, V23, P460, DOI 10.1089/omi.2019.0131
   Baldoni J., 2020, J COMMERCIAL BIOTECH, V25, P42
   Char DS, 2018, NEW ENGL J MED, V378, P981, DOI 10.1056/NEJMp1714229
   Crandall SG, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237975
   Demirci DK, 2021, OMICS, V25, P431, DOI 10.1089/omi.2021.0081
   Dias R, 2019, GENOME MED, V11, DOI 10.1186/s13073-019-0689-8
   Ekins S, 2019, NAT MATER, V18, P435, DOI 10.1038/s41563-019-0338-z
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Gov E, 2016, IET SYST BIOL, V10, P219, DOI 10.1049/iet-syb.2016.0001
   Gulfidan G, 2021, OMICS, V25, P495, DOI 10.1089/omi.2021.0085
   Hasin Y, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1215-1
   Ho DSW, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00267
   Hutson M, 2018, SCIENCE, V359, P725, DOI 10.1126/science.359.6377.725
   Karczewski KJ, 2018, NAT REV GENET, V19, P299, DOI 10.1038/nrg.2018.4
   Kim HK, 2018, NAT BIOTECHNOL, V36, P239, DOI 10.1038/nbt.4061
   Ko Gunhwan, 2020, Genomics & Informatics, V18, pe8, DOI 10.5808/GI.2020.18.1.e8
   Koh EJ, 2019, MOL CELL TOXICOL, V15, P1, DOI 10.1007/s13273-019-0001-4
   Koromina M, 2019, OMICS, V23, P539, DOI 10.1089/omi.2019.0151
   Leenay RT, 2019, NAT BIOTECHNOL, V37, P1034, DOI 10.1038/s41587-019-0203-2
   Leung MKK, 2016, P IEEE, V104, P176, DOI 10.1109/JPROC.2015.2494198
   Lin BY, 2022, OMICS, V26, P77, DOI 10.1089/omi.2021.0037
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Norgeot B, 2019, NAT MED, V25, P14, DOI 10.1038/s41591-018-0320-3
   OIE, 2020, ONE HEALTH-AMSTERDAM, V1
   Özdemir V, 2020, TRANSL APPL GENOM, P275, DOI 10.1016/B978-0-12-813695-9.00015-7
   Özdemir V, 2019, OMICS, V23, P308, DOI 10.1089/omi.2019.0069
   Özdemir V, 2019, OMICS, V23, P67, DOI 10.1089/omi.2019.0003
   Özdemir V, 2018, OMICS, V22, P65, DOI 10.1089/omi.2017.0194
   Ozer ME, 2020, OMICS, V24, P241, DOI 10.1089/omi.2020.0001
   Sahraeian SME, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09027-x
   Shen MW, 2018, NATURE, V563, P646, DOI 10.1038/s41586-018-0686-x
   Shendure J, 2019, CELL, V177, P45, DOI 10.1016/j.cell.2019.02.003
   Sundaram L, 2018, NAT GENET, V50, P1161, DOI 10.1038/s41588-018-0167-z
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Turanli B, 2021, SEMIN CANCER BIOL, V68, P47, DOI 10.1016/j.semcancer.2019.09.020
   Turanli B, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00420
   Turanli B, 2018, CURR PHARM DESIGN, V24, P3778, DOI 10.2174/1381612824666181106095959
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   Way GP, 2018, NAT METHODS, V15, P1009, DOI 10.1038/s41592-018-0230-9
   Zafeiris D, 2018, COMPUT STRUCT BIOTEC, V16, P77, DOI 10.1016/j.csbj.2018.02.001
   Zitnik M, 2019, INFORM FUSION, V50, P71, DOI 10.1016/j.inffus.2018.09.012
NR 43
TC 5
Z9 5
U1 3
U2 18
PD DEC 21
PY 2021
VL 25
IS 12
BP 745
EP 749
DI 10.1089/omi.2021.0170
EA NOV 2021
UT WOS:000719332700001
DA 2023-11-16
ER

PT C
AU Langguth, J
   Cai, X
   Sourouri, M
AF Langguth, Johannes
   Cai, Xing
   Sourouri, Mohammed
GP IEEE
TI Memory Bandwidth Contention: Communication vs Computation Tradeoffs in
   Supercomputers with Multicore Architectures
SO 2018 IEEE 24TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED
   SYSTEMS (ICPADS 2018)
SE International Conference on Parallel and Distributed Systems -
   Proceedings
DT Proceedings Paper
CT 24th IEEE International Conference on Parallel and Distributed Systems
   (ICPADS)
CY DEC 11-13, 2018
CL Singapore, SINGAPORE
ID PERFORMANCE-MODEL; ROOFLINE
AB We study the problem of contention for memory bandwidth between computation and communication in super-computers that feature multicore CPUs. The problem arises when communication and computation are overlapped, and both operations compete for the same memory bandwidth. This contention is most visible at the limits of scalability, when communication and computation take similar amounts of time, and thus must be taken into account in order to reach maximum scalability in memory bandwidth bound applications. Typical examples of codes affected by the memory bandwidth contention problem are sparse matrix-vector computations, graph algorithms, and many machine learning problems, as they typically exhibit a high demand for both memory bandwidth and inter-node communication, while performing a relatively low number of arithmetic operations.
   The problem is even more relevant in truly heterogeneous computations where CPUs and accelerators are used in concert. In that case it can lead to mispredictions of expected performance and consequently to suboptimal load balancing between CPU and accelerator, which in turn can lead to idling of powerful accelerators and thus to a large decrease in performance.
   We propose a simple benchmark in order to quantify the loss of performance due to memory bandwidth contention. Based on that, we derive a theoretical model to determine the impact of the phenomenon on parallel memory-bound applications. We test the model on scientific computations, discuss the practical relevance of the problem and suggest possible techniques to remedy it.
C1 [Langguth, Johannes; Cai, Xing] Simula Res Lab, Dept High Performance Comp, Oslo, Norway.
   [Sourouri, Mohammed] Acando Norway, Oslo, Norway.
RP Langguth, J (corresponding author), Simula Res Lab, Dept High Performance Comp, Oslo, Norway.
EM langguth@simula.no; xingca@simula.no; mohammed.sourouri@acando.no
CR Bardhan S, 2015, IEEE T COMPUT, V64, P2279, DOI 10.1109/TC.2014.2361511
   Catalyurek U. V., 1995, P INT C HIGH PERF CO
   Choi J., 2014, P WORKSH GEN PURP PR
   Dauwe D, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P434, DOI 10.1109/IPDPSW.2015.38
   Doerfler D, 2016, LECT NOTES COMPUT SC, V9945, P339, DOI 10.1007/978-3-319-46079-6_24
   Kaiser T. H., 2001, Scientific Programming, V9, P73
   Langguth J, 2015, J PARALLEL DISTR COM, V76, P120, DOI 10.1016/j.jpdc.2014.10.005
   Langguth J, 2015, IEEE MICRO, V35, P6, DOI 10.1109/MM.2015.70
   Langguth J, 2014, INT C PAR DISTRIB SY, P191, DOI 10.1109/PADSW.2014.7097808
   Liu JX, 2004, IEEE MICRO, V24, P42, DOI 10.1109/MM.2004.1268994
   McCalpin J. D., 1995, IEEE COMPUTER SOC TE, V1995, P19
   Pfister G., 2001, INTRO INFINIBAND ARC
   Putigny B, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P943, DOI 10.1109/HPCSim.2014.6903790
   Rupp K., CPU GPU MIC HARDWARE
   Sanders Peter, 2013, Experimental Algorithms 12th International Symposium, SEA 2013. Proceedings, P164, DOI 10.1007/978-3-642-38527-8_16
   Shimokawabe T., 2011, P 2011 INT C HIGH PE, P3, DOI 10.1145/2063384.2063388
   Si M, 2015, INT PARALL DISTRIB P, P665, DOI 10.1109/IPDPS.2015.35
   Sourouri M, 2017, INT J PARALLEL PROG, V45, P711, DOI 10.1007/s10766-016-0454-1
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wu XF, 2013, J COMPUT SYST SCI, V79, P1256, DOI 10.1016/j.jcss.2013.02.005
   Zhou J, 2013, PROCEDIA COMPUT SCI, V18, P1255, DOI 10.1016/j.procs.2013.05.292
NR 21
TC 7
Z9 7
U1 1
U2 4
PY 2018
BP 497
EP 506
DI 10.1109/ICPADS.2018.00072
UT WOS:000462962600061
DA 2023-11-16
ER

PT J
AU Hasse, K
   Scholey, J
   Ziemer, BP
   Natsuaki, Y
   Morin, O
   Solberg, TD
   Hirata, E
   Valdes, G
   Witztum, A
AF Hasse, K.
   Scholey, J.
   Ziemer, B. P.
   Natsuaki, Y.
   Morin, O.
   Solberg, T. D.
   Hirata, E.
   Valdes, G.
   Witztum, A.
TI Use of Receiver Operating Curve Analysis and Machine Learning With an
   Independent Dose Calculation System Reduces the Number of Physical Dose
   Measurements Required for Patient-Specific Quality Assurance
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
DT Article
ID IMRT QA; RADIATION ONCOLOGY
AB Purpose: Our purpose was to assess the use of machine learning methods and Mobius 3D (M3D) dose calculation software to reduce the number of physical ion chamber (IC) dose measurements required for patient-specific quality assurance during corona virus disease 2019.
   Methods and Materials: In this study, 1464 inversely planned treatments using Pinnacle or Raystation treatment planning software (TPS) were delivered using Elekta Versa HD and Varian Truebeam and Truebeam STx linear accelerators between June 2018 and November 2019. For each plan, an independent dose calculation was performed using M3D, and an absolute dose measurement was taken using a Pinpoint IC inside the Mobius phantom. The point dose differences between the TPS and M3D calculation and between TPS and IC measurements were calculated. Agreement between the TPS and IC was used to define the ground truth plan failure. To reduce the on-site personnel during the pandemic, 2 methods of receiver operating characteristic analysis (n = 1464) and machine learning (n = 603) were used to identify patient plans that would require physical dose measurements.
   Results: In the receiver operating characteristic analysis, a predelivery M3D difference threshold of 3% identified plans that failed an IC measurement at a 4% threshold with 100% sensitivity and 76.3% specificity. This indicates that fewer than 25% of plans required a physical dose measurement. A threshold of 1% on a machine learning model was able to identify plans that failed an IC measurement at a 3% threshold with 100% sensitivity and 54.3% specificity, leading to fewer than 50% of plans that required a physical dose measurement.
   Conclusions: It is possible to identify plans that are more likely to fail IC patient-specific quality assurance measurements before delivery. This possibly allows for a reduction of physical measurements taken, freeing up significant clinical resources and reducing the required amount of on-site personnel while maintaining patient safety. Published by Elsevier Inc.
C1 [Hasse, K.; Scholey, J.; Ziemer, B. P.; Natsuaki, Y.; Morin, O.; Hirata, E.; Valdes, G.; Witztum, A.] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.
   [Solberg, T. D.] US FDA, Washington, DC 20204 USA.
RP Hasse, K (corresponding author), Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.
EM Katelyn.hasse@ucsf.edu
CR Breiman L, 2017, CLASSIFICATION REGRE, DOI DOI 10.1201/9781315139470
   DeLuca PM, 2008, J ICRU, V8
   Dunn L, 2018, J APPL CLIN MED PHYS, V19, P739, DOI 10.1002/acm2.12396
   Friedman J, RULEFIT R
   Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010
   Hernandez V, 2018, PHYS IMAG RADIAT ONC, V5, P37, DOI 10.1016/j.phro.2018.02.002
   Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890
   Japkowicz N., 2015, MACHINE LEARNING RAD, DOI 10.1007/978-3-319-18305-3_4
   Kerns JR, 2017, INT J RADIAT ONCOL, V98, P1197, DOI 10.1016/j.ijrobp.2017.03.049
   Kry SF, 2019, MED PHYS, V46, P3700, DOI 10.1002/mp.13638
   KUTCHER GJ, 1994, MED PHYS, V21, P581, DOI 10.1118/1.597316
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Luna JM, 2019, P NATL ACAD SCI USA, V116, P19887, DOI 10.1073/pnas.1816748116
   Nakaguchi Y, 2019, RADIOL PHYS TECHNOL, V12, P126, DOI 10.1007/s12194-019-00499-6
   Potter NJ, 2020, MED PHYS, V47, P4711, DOI 10.1002/mp.14416
   Schroeder L.D., 1986, UNDERSTANDING REGRES
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Valdes G, 2017, J APPL CLIN MED PHYS, V18, P279, DOI 10.1002/acm2.12161
   Valdes G, 2016, SCI REP-UK, V6, DOI 10.1038/srep37854
NR 20
TC 5
Z9 5
U1 0
U2 9
PD MAR 15
PY 2021
VL 109
IS 4
BP 1086
EP 1095
DI 10.1016/j.ijrobp.2020.10.035
EA FEB 2021
UT WOS:000632008000028
DA 2023-11-16
ER

PT J
AU Zhou, XY
   An, K
   Ma, WJ
AF Zhou, Xiangyu
   An, Kun
   Ma, Wanjing
TI Data-Driven Approach for Estimating Energy Consumption of Electric Buses
   under On-Road Operation Conditions
SO JOURNAL OF TRANSPORTATION ENGINEERING PART A-SYSTEMS
DT Article
DE Electric buses; Energy consumption; Four states; Instantaneous power
ID CARBON EMISSIONS; VEHICLE; SIMULATION; MODEL
AB The transformation of diesel buses into battery-powered electric buses for public transportation has become a global trend. The ability to evaluate the energy consumption of electric buses is critical in bus scheduling for alleviating range anxiety. In this study, an energy consumption estimation model for electric buses was proposed based on actual bus operation data. The operating states of an electric bus were categorized into four types: depressed accelerator pedal, depressed brake pedal, vehicle sliding, and vehicle idle states. Based on the bus state, two models were constructed to estimate the energy consumption. A multivariate linear model based on vehicle speed, accelerator pedal position, and instantaneous power was constructed to estimate the energy consumption of buses in the depressed accelerator pedal state. Combining that model with a long short-term memory (LSTM) algorithm, machine learning algorithms were calibrated to estimate bus energy consumption in the other three states over the four seasons. A comparative analysis was conducted for the different algorithms. The root-mean-square errors of the estimation results based on LSTM for vehicles in the depressed brake pedal, vehicle sliding, and vehicle idle states were 0.12%, 0.03%, and 27.27% lower than those of the artificial neural network, respectively. Accurate estimations of bus energy consumption during the four seasons allow bus operation companies to adjust the bus charging schedule to reduce the operating costs.
C1 [Zhou, Xiangyu; An, Kun; Ma, Wanjing] Tongji Univ, Key Lab Rd & Traff Engn, Minist Educ, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
RP An, K (corresponding author), Tongji Univ, Key Lab Rd & Traff Engn, Minist Educ, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
EM 2010796@tongji.edu.cn; kunan@tongji.edu.cn; mawanjing@tongji.edu.cn
CR Abdelaty H, 2021, TRANSPORT RES D-TR E, V96, DOI 10.1016/j.trd.2021.102868
   Al-Ogaili AS, 2020, APPL ENERG, V280, DOI 10.1016/j.apenergy.2020.115873
   Al-Wreikat Y, 2021, APPL ENERG, V297, DOI 10.1016/j.apenergy.2021.117096
   Badin F, 1996, SCI TOTAL ENVIRON, V189, P125, DOI 10.1016/0048-9697(96)05200-X
   Chen YC, 2021, TRANSPORT RES D-TR E, V98, DOI 10.1016/j.trd.2021.102969
   Duarte GO, 2015, ENERG CONVERS MANAGE, V92, P251, DOI 10.1016/j.enconman.2014.12.042
   Ercan T, 2022, TRANSPORT RES D-TR E, V112, DOI 10.1016/j.trd.2022.103472
   Gallet M, 2018, APPL ENERG, V230, P344, DOI 10.1016/j.apenergy.2018.08.086
   Gao ZM, 2017, ENERGY, V122, P588, DOI 10.1016/j.energy.2017.01.101
   Genikomsakis KN, 2017, TRANSPORT RES D-TR E, V50, P98, DOI 10.1016/j.trd.2016.10.014
   Hao X, 2020, J CLEAN PROD, V249, DOI 10.1016/j.jclepro.2019.119403
   Hjelkrem OA, 2021, TRANSPORT RES D-TR E, V94, DOI 10.1016/j.trd.2021.102804
   Hu XS, 2020, PROG ENERG COMBUST, V77, DOI 10.1016/j.pecs.2019.100806
   IEA (International Energy Agency), 2022, IMPR SUST PASS FREIG
   Jiang JY, 2023, ENERGY, V263, DOI 10.1016/j.energy.2022.125866
   Klingler AL, 2018, ENERGY, V161, P1064, DOI 10.1016/j.energy.2018.07.210
   Li PS, 2021, APPL ENERG, V298, DOI 10.1016/j.apenergy.2021.117204
   Liu K, 2018, APPL ENERG, V227, P324, DOI 10.1016/j.apenergy.2017.08.074
   Luna TF, 2020, TRANSPORT RES D-TR E, V79, DOI 10.1016/j.trd.2020.102226
   Ma XL, 2021, ENERGY, V216, DOI 10.1016/j.energy.2020.119196
   Mamarikas S, 2022, TRANSPORT RES D-TR E, V105, DOI 10.1016/j.trd.2022.103231
   McGrath T, 2022, TRANSPORT RES D-TR E, V109, DOI 10.1016/j.trd.2022.103373
   Mohamed M, 2017, ELECTR POW SYST RES, V142, P163, DOI 10.1016/j.epsr.2016.09.032
   Moro A, 2018, TRANSPORT RES D-TR E, V64, P5, DOI 10.1016/j.trd.2017.07.012
   Nan SR, 2022, ENERGY, V261, DOI 10.1016/j.energy.2022.125188
   Qi XW, 2018, TRANSPORT RES D-TR E, V64, P36, DOI 10.1016/j.trd.2017.08.008
   Ritter A, 2021, IEEE T VEH TECHNOL, V70, P5483, DOI 10.1109/TVT.2021.3077063
   Song YL, 2022, APPL ENERG, V305, DOI 10.1016/j.apenergy.2021.117830
   Sun J, 2021, TRANSPORT RES C-EMER, V128, DOI 10.1016/j.trc.2021.103114
   Szilassy PA, 2022, ENERGY, V261, DOI 10.1016/j.energy.2022.125080
   Wang H, 2020, TRANSPORT RES A-POL, V132, P30, DOI 10.1016/j.tra.2019.10.010
   Xie YK, 2020, APPL ENERG, V267, DOI 10.1016/j.apenergy.2020.115081
   Xu XD, 2019, TRANSPORT RES D-TR E, V75, P249, DOI 10.1016/j.trd.2019.09.001
   Yuan XM, 2017, ENERGY, V141, P1955, DOI 10.1016/j.energy.2017.11.134
   Zhang J, 2020, APPL ENERG, V275, DOI 10.1016/j.apenergy.2020.115408
   Zhang R, 2015, TRANSPORT RES D-TR E, V41, P177, DOI 10.1016/j.trd.2015.10.010
   Zhang ZQ, 2017, APPL THERM ENG, V125, P567, DOI 10.1016/j.applthermaleng.2017.07.032
NR 37
TC 0
Z9 0
U1 6
U2 6
PD SEP 1
PY 2023
VL 149
IS 9
AR 04023089
DI 10.1061/JTEPBS.TEENG-7901
UT WOS:001030372500007
DA 2023-11-16
ER

PT J
AU Kljucaric, L
   George, AD
AF Kljucaric, Luke
   George, Alan D.
TI Deep Learning Inferencing with High-performance Hardware Accelerators
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
DT Article
DE Neural networks; machine learning; FPGA; inference
AB As computer architectures continue to integrate application-specific hardware, it is critical to understand the relative performance of devices for maximum app acceleration. The goal of benchmarking suites, such as MLPerf for analyzing machine learning (ML) hardware performance, is to standardize a fair comparison of different hardware architectures. However, there are many apps that are not well represented by these standards that require different workloads, such asMLmodels and datasets, to achieve similar goals. Additionally, many apps, like real-time video processing, are focused on latency of computations rather than strictly on throughput. This research analyzes multiple compute architectures that featureML-specific hardware on a case study of handwritten Chinese character recognition. Specifically, AlexNet and a custom version of GoogLeNet are benchmarked in terms of their streaming latency and maximum throughput for optical character recognition. Considering that these models are composed of fundamental neural network operations yet architecturally different from each other, these models can stress devices in different yet insightful ways that generalizations of the performance of other models can be drawn from. Many devices featuring ML-specific hardware and optimizations are analyzed including Intel and AMD CPUs, Xilinx and Intel FPGAs, NVIDIA GPUs, and Google TPUs. Overall, ML-oriented hardware added to the Intel Xeon CPUs helps to boost throughput by 3.7x and to reduce latency by up to 34.7x, which makes the latency of Intel Xeon CPUs competitive on more parallel models. The TPU devices were limited in terms of throughput due to large data transfer times and not competitive in terms of latency. The FPGA frameworks showcase the lowest latency on the Xilinx Alveo U200 FPGA achieving 0.48 ms on AlexNet using Mipsology Zebra and 0.39 ms on GoogLeNet using Vitis-AI. Through their custom acceleration datapaths coupled with high-performance SRAM, the FPGAs are able to keep critical model data closer to processing elements for lower latency. The massively parallel and high-memory GPU devices with Tensor Core accelerators achieve the best throughput. The NVIDIA Tesla A100 GPU showcases the highest throughput at 42,513 and 52,484 images/second for AlexNet and GoogLeNet, respectively.
C1 [Kljucaric, Luke; George, Alan D.] Univ Pittsburgh, ECE Dept, NSF SHREC Ctr, 4420 Bayard St,Suite 560, Pittsburgh, PA 15213 USA.
RP Kljucaric, L (corresponding author), Univ Pittsburgh, ECE Dept, NSF SHREC Ctr, 4420 Bayard St,Suite 560, Pittsburgh, PA 15213 USA.
EM kljucaricu@pitt.edu; alan.george@pitt.edu
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   Abadi M, 2015, TENSORFLOW LARGE SCA
   AMD, 2022, 2 GEN AMD EPYC 7702
   Delaye Elliot, 2018, INTEGRATING AI YOUR
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Fowers J., 2012, ACM SIGDA INT S FIEL
   Glorot X., 2011, INT C ART INT STAT P, V14
   Google, 2022, TROUBL TENSORFLOW TP
   Google Cloud, 2022, CLOUD TPU SYST ARCH
   Google Cloud, 2022, CLOUD TPU BREAKS SCA
   Intel, 2022, ONEDNN V2 7 0 DOC
   Intel, 2022, INT STRAT 10 NX 2100
   Intel, 2022, INT FPGA DEEP LEARN
   Intel, 2022, INT XEON PLAT 8180 P
   Intel, 2022, ENH ART INT AI WORKL
   Intel, 2022, INT PROGR ACC CARD P
   Intel, 2022, OPENVINO DOC
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Judd P, 2016, Arxiv, DOI arXiv:1511.05236
   Kljucaric L, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286209
   Kljucaric L, 2019, IEEE HIGH PERF EXTR
   Kochura Y, 2018, Arxiv, DOI arXiv:1812.11731
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lai SX, 2017, PATTERN RECOGN LETT, V89, P60, DOI 10.1016/j.patrec.2017.02.011
   Lane ND, 2017, IEEE PERVAS COMPUT, V16, P82, DOI 10.1109/MPRV.2017.2940968
   Langerman D, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286182
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S, 2020, MULTIMED TOOLS APPL, V79, P34195, DOI 10.1007/s11042-020-09054-7
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Mipsology, 2022, ZEBRA ACCELERATES MA
   Morgan T. P., 2018, TEASINGOUT BANG BUCK
   NVIDIA, 2022, DEEP LEARN FRAM DOC
   NVIDIA, 2022, NVIDIA TENSORRT DOC
   NVIDIA, 2022, NVIDIA TESL V100 GPU
   NVIDIA, 2022, NVIDIA A10 TENS COR
   NVIDIA, 2022, NVIDIA T4 TENS COR G
   NVIDIA, 2022, NVIDIA A100 TENS COR
   NVIDIA, 2022, NVIDIA AMP GPU ARCH
   Ovtcharov K., 2015, MICROSOFT RES WHITEP, V2, P1
   Pang B, 2020, J EDUC BEHAV STAT, V45, P227, DOI 10.3102/1076998619872761
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TensorFlow, 2022, EST TPU SUPP
   Tsochatzidis L, 2019, J IMAGING, V5, DOI 10.3390/jimaging5030037
   Wang N., 2018, C NEURAL INFORM PROC
   Wang S., 2022, BFLOAT16 SECRET HIGH
   Wenfei Liu, 2020, 2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA), P587, DOI 10.1109/AEECA49918.2020.9213482
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Xie XF, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3417709
   Xilinx, 2022, AI INF ACC
   Xilinx, 2022, ALV U200 U250 DAT CT
   Xilinx, 2022, XIL POW EST XPE
   Xilinx, 2022, VIT AI US GUID UG141
   Yang CT, 2021, J SUPERCOMPUT, V77, P2486, DOI 10.1007/s11227-020-03362-3
   Yip MYT, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0247-1
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
NR 63
TC 0
Z9 0
U1 0
U2 0
PD AUG
PY 2023
VL 14
IS 4
AR 68
DI 10.1145/3594221
UT WOS:001056362600011
DA 2023-11-16
ER

PT C
AU Pan, ZX
   Mishra, P
AF Pan, Zhixin
   Mishra, Prabhat
BE Bolchini, C
   Verbauwhede, I
   Vatajelu, I
TI Hardware Acceleration of Explainable Machine Learning
SO PROCEEDINGS OF THE 2022 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2022)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 25th Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 14-23, 2022
CL ELECTR NETWORK
AB Machine learning (ML) is successful in achieving human-level performance in various fields. However, it lacks the ability to explain an outcome due to its black-box nature. While recent efforts on explainable ML has received significant attention, the existing solutions are not applicable in real-time systems since they map interpretability as an optimization problem, which leads to numerous iterations of time-consuming complex computations. To make matters worse, existing implementations are not amenable for hardware-based acceleration. In this paper, we propose an efficient framework to enable acceleration of explainable ML procedure with hardware accelerators. We explore the effectiveness of both Tensor Processing Unit (TPU) and Graphics Processing Unit (GPU) based architectures in accelerating explainable ML. Specifically, this paper makes three important contributions. (1) To the best of our knowledge, our proposed work is the first attempt in enabling hardware acceleration of explainable ML. (2) Our proposed solution exploits the synergy between matrix convolution and Fourier transform, and therefore, it takes full advantage of TPU's inherent ability in accelerating matrix computations. (3) Our proposed approach can lead to real-time outcome interpretation. Extensive experimental evaluation demonstrates that proposed approach deployed on TPU can provide drastic improvement in interpretation time (39x on average) as well as energy efficiency (69x on average) compared to existing acceleration techniques.
C1 [Pan, Zhixin; Mishra, Prabhat] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
RP Pan, ZX (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
CR [Anonymous], 2017, RESIDUAL SQUEEZE VGG
   Civit-Masot J, 2019, IEEE ACCESS, V7, P142379, DOI 10.1109/ACCESS.2019.2944692
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lu T., 2020, ACCELERATING MRI REC
   Lu T., 2020, LARGE SCALE DISCRETE
   Lu TJ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286192
   Pan Z., 2021, DESIGN AUTOMA TION T
   Pan Z., 2021, HOST
   Pan Z., 2020, 2020 IEEE INT C HIGH, P1
   Pan ZX, 2021, ASIA S PACIF DES AUT, P408, DOI 10.1145/3394885.3431595
   Pan ZX, 2020, PR IEEE COMP DESIGN, P663, DOI 10.1109/ICCD50377.2020.00113
   Paszke A, 2019, ADV NEUR IN, V32
   Sato K, 2017, IN DEPTH LOOK GOOGLE
   Sengupta J, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P134, DOI [10.1109/AICAS48895.2020.9073867, 10.1109/aicas48895.2020.9073867]
   Sidea D., 2021, IEEE ACCESS, V9
   Yazdanbakhsh A., 2021, ARXIV PREPRINT ARXIV
NR 17
TC 4
Z9 4
U1 0
U2 0
PY 2022
BP 1127
EP 1130
UT WOS:000819484300210
DA 2023-11-16
ER

PT J
AU Tan, GM
   Liu, JH
   Li, JJ
AF Tan, Guangming
   Liu, Junhong
   Li, Jiajia
TI Design and Implementation of Adaptive SpMV Library for Multicore and
   Many-Core Architecture
SO ACM TRANSACTIONS ON MATHEMATICAL SOFTWARE
DT Article
DE Sparse matrix vector multiplication; auto-tuning; multicore; machine
   learning
ID MATRIX-VECTOR MULTIPLICATION; OPTIMIZATION; FORMAT
AB Sparse matrix vector multiplication (SpMV) is an important computational kernel in traditional highperformance computing and emerging data-intensive applications. Previous SpMV libraries are optimized by either application-specific or architecture-specific approaches but present difficulties for use in real applications. In this work, we develop an auto-tuning system (SMATER) to bridge the gap between specific optimizations and general-purpose use. SMATER provides programmers a unified interface based on the compressed sparse row (CSR) sparse matrix format by implicitly choosing the best format and fastest implementation for any input sparse matrix during runtime. SMATER leverages a machine-learning model and retargetable back-end library to quickly predict the optimal combination. Performance parameters are extracted from 2,386 matrices in the SuiteSparse matrix collection. The experiments show that SMATER achieves good performance (up to 10 times that of the Intel Math Kernel Library (MKL) on Intel E5-2680 v3) while being portable on state-of-the-art x86 multicore processors, NVIDIA GPUs, and Intel Xeon Phi accelerators. Compared with the Intel MKL library, SMATER runs faster by more than 2.5 times on average. We further demonstrate its adaptivity in an algebraic multigrid solver from the Hypre library and report greater than 20% performance improvement.
C1 [Tan, Guangming; Liu, Junhong] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Li, Jiajia] Georgia Inst Technol, Computat Sci & Engn, Atlanta, GA 30332 USA.
   [Tan, Guangming; Liu, Junhong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
RP Tan, GM (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
EM tgm@ict.ac.cn; liujunhong@ncic.ac.cn; jiajiali@gatech.edu
CR [Anonymous], 2012, P 26 ACM INT C SUP I
   [Anonymous], 1994, TECHNICAL REPORT
   [Anonymous], 2016, P 2016 INT C SUP SER
   Ansel J, 2009, PLDI'09 PROCEEDINGS OF THE 2009 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P38, DOI 10.1145/1542476.1542481
   Anzt H, 2014, UTEECS14727
   Armstrong W, 2008, IEEE INT C CL COMP, P411, DOI 10.1109/CLUSTR.2008.4663802
   Beamer S, 2017, INT PARALL DISTRIB P, P820, DOI 10.1109/IPDPS.2017.112
   Bell Nathan, 2008, NVR2008004 NVIDIA CO
   Belter G., 2009, 2009 SC Conference on High Performance Computing Networking, Storage and Analysis, DOI 10.1145/1654059.1654119
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Brown Jed, 2012, ANL9511
   Buluc A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P721, DOI 10.1109/IPDPS.2011.73
   Byun J.-H., 2012, TECHNICAL REPORT
   Choi JW, 2010, PPOPP 2010: PROCEEDINGS OF THE 2010 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P115, DOI 10.1145/1693453.1693471
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Falgout RD, 2002, LECT NOTES COMPUT SC, V2331, P632
   Falgout RD, 2006, COMPUT SCI ENG, V8, P24, DOI 10.1109/MCSE.2006.105
   Filippone S, 2017, ACM T MATH SOFTWARE, V43, DOI 10.1145/3017994
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Grewe D., 2011, GPGPU 4 P 4 WORKSHOP, P12
   Heroux MA, 2005, ACM T MATH SOFTWARE, V31, P397, DOI 10.1145/1089014.1089021
   Hill M. D. Adam, 2005, INT THERMONUCLEAR EX
   Hou K., 2017, ICS 17
   Im EJ, 2004, INT J HIGH PERFORM C, V18, P135, DOI 10.1177/1094342004041296
   Intel, 2017, INT MATH KERN LIB
   Khairoutdinov MF, 2001, GEOPHYS RES LETT, V28, P3617, DOI 10.1029/2001GL013552
   Kourtis K, 2011, ACM SIGPLAN NOTICES, V46, P247, DOI 10.1145/2038037.1941587
   Kreutzer M, 2014, SIAM J SCI COMPUT, V36, pC401, DOI 10.1137/130930352
   Li JJ, 2017, INT PARALL DISTRIB P, P1048, DOI 10.1109/IPDPS.2017.80
   Li JJ, 2013, ACM SIGPLAN NOTICES, V48, P117, DOI 10.1145/2499370.2462181
   Li JF, 2015, ACSR ADV COMPUT, V24, P76
   Liu CX, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P363, DOI 10.1145/3205289.3205313
   Liu J., 2018, ACM T PARALLEL COMPU
   Liu JH, 2018, ACM SIGPLAN NOTICES, V53, P407, DOI 10.1145/3200691.3178529
   Liu WF, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4244
   Liu WF, 2015, PARALLEL COMPUT, V49, P179, DOI 10.1016/j.parco.2015.04.004
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Liu WF, 2015, J PARALLEL DISTR COM, V85, P47, DOI 10.1016/j.jpdc.2015.06.010
   Liu Weifeng, 2015, THESIS
   Liu Xing, 2013, P 27 INT ACM C INT C, P273, DOI [DOI 10.1145/2464996.2465013, 10.1145/2464996.2465013]
   Maggioni M, 2016, J PARALLEL DISTR COM, V93-94, P66, DOI 10.1016/j.jpdc.2016.03.011
   Monakov A, 2010, LECT NOTES COMPUT SC, V5952, P111, DOI 10.1007/978-3-642-11515-8_10
   Nagar KK, 2011, ANN IEEE SYM FIELD P, P1, DOI 10.1109/FCCM.2011.60
   Nagasaka Y, 2016, PROCEDIA COMPUT SCI, V80, P131, DOI 10.1016/j.procs.2016.05.304
   Neelima B., 2014, 2014 IEEE 28th International Parallel & Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P1427, DOI 10.1109/IPDPSW.2014.160
   NVIDIA, 2010, CUDA CUSPARSE LIB
   Püschel M, 2005, P IEEE, V93, P232, DOI 10.1109/JPROC.2004.840306
   RuleQuest Research, 2012, DAT MIN TOOLS SEE5 C
   Sedaghati N, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P99, DOI 10.1145/2751205.2751244
   Spirin N., 2012, ACM SIGKDD EXPLOR NE, V13, P50, DOI [DOI 10.1145/2207243.2207252, 10.1145/2207243.2207252]
   Srinivasa Avinash, 2012, P 2012 S HIGH PERF C
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Sun XZ, 2011, LECT NOTES COMPUT SC, V6853, P316, DOI 10.1007/978-3-642-23397-5_32
   Vuduc R, 2005, J PHYS CONF SER, V16, P521, DOI 10.1088/1742-6596/16/1/071
   Vuduc RW, 2005, LECT NOTES COMPUT SC, V3726, P807
   Wang XL, 2018, ACM SIGPLAN NOTICES, V53, P338, DOI 10.1145/3200691.3178513
   Whaley R. C., 1998, PROC IEEEACM C SUPER, P38, DOI [10.5555/509058.509096, DOI 10.1109/SC.1998.10004]
   Williams S, 2009, PARALLEL COMPUT, V35, P178, DOI 10.1016/j.parco.2008.12.006
   Xie BW, 2018, INT SYM CODE GENER, P149, DOI 10.1145/3168818
   Yan SG, 2014, ACM SIGPLAN NOTICES, V49, P107, DOI [10.1145/2555243.2555255, 10.1145/2692916.2555255]
   Yang XT, 2011, PROC VLDB ENDOW, V4, P231, DOI 10.14778/1938545.1938548
   Yotov K, 2005, P IEEE, V93, P358, DOI 10.1109/JPROC.2004.840444
   Zhao Y, 2018, ACM SIGPLAN NOTICES, V53, P94, DOI 10.1145/3200691.3178495
NR 63
TC 23
Z9 23
U1 1
U2 21
PD AUG
PY 2018
VL 44
IS 4
AR 46
DI 10.1145/3218823
UT WOS:000445637100010
DA 2023-11-16
ER

PT J
AU Zhu, ZY
   Ulseth, J
   Li, GF
   Pang, S
AF Zhu, Zheyuan
   Ulseth, Joseph
   Li, Guifang
   Pang, Shuo
TI Training of Mixed-Signal Optical Convolutional Neural Networks With
   Reduced Quantization Levels
SO IEEE ACCESS
DT Article
DE Training; Tensors; Quantization (signal); Convolution; Computational
   modeling; Acceleration; Digital computers; Neural network; mixed-signal
   training; analog computation
AB Analog computing paradigms are promising solutions to the growing computational demands of machine learning applications. Despite being susceptible to errors, analog and mixed-signal platforms have the potential to achieve higher speed and power efficiency for artificial neural network (ANN) applications than digital computers. Driven by the development of digital fixed-point ANN accelerators, low-precision ANN models have proven to be successful in compressing the size of ANNs and conforming the models to the data format of digital accelerators. While the inputs and weights of these digital, fixed-point ANN models can have low bit widths, the intermediate results (e.g., activations) must be preserved in high precision. As a result, these digital fixed-point models and training algorithms cannot be migrated easily to analog accelerators, because the analog intermediate results typically suffer from reduced precision due to noises and device imperfections. Here, we report on a training method for mixed-signal ANNs that considers two types of analog impairments, namely, random noise and distortion (deterministic in nature). The results show that mixed-signal ANN trained with our method can achieve the same classification accuracy as the digital fixed-point model with noise levels up to 50% of the ideal quantization step size. We demonstrate our training method on a mixed-signal, convolutional neural network based on diffractive optics.
C1 [Zhu, Zheyuan; Ulseth, Joseph; Li, Guifang; Pang, Shuo] Univ Cent Florida, CREOL, Coll Opt & Photon, Orlando, FL 32816 USA.
RP Zhu, ZY (corresponding author), Univ Cent Florida, CREOL, Coll Opt & Photon, Orlando, FL 32816 USA.
EM zyzhu@knights.ucf.edu
CR [Anonymous], 2017, ARXIV170709870
   Bengio Yoshua, 2013, ESTIMATING PROPAGATI
   BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108
   Cai Y, 2018, ASIA S PACIF DES AUT, P117, DOI 10.1109/ASPDAC.2018.8297292
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Cheng M, 2019, IEEE T COMPUT AID D, V38, P834, DOI 10.1109/TCAD.2018.2824304
   Choi J., 2018, ARXIV PREPRINT ARXIV
   Collobert R, 2008, P 25 ICML, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Fan Angela, 2020, ARXIV200407320
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hubara I, 2018, J MACH LEARN RES, V18
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   Mellempudi N., 2017, ARXIV170501462
   Mendlovic D, 1997, APPL OPTICS, V36, P8427, DOI 10.1364/AO.36.008427
   Moon S, 2019, IEEE T VLSI SYST, V27, P1455, DOI 10.1109/TVLSI.2019.2893256
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Saleh B. E. A., 2007, FUNDAMENTALS PHOTONI
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Simonyan K., 2015, ARXIV
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Yan T, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.023901
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Zhou Shuchang, 2016, ARXIV160606160
NR 33
TC 0
Z9 0
U1 0
U2 4
PY 2021
VL 9
BP 56645
EP 56652
DI 10.1109/ACCESS.2021.3072193
UT WOS:000641938700001
DA 2023-11-16
ER

PT J
AU Hayat, A
   Khalid, YN
   Rathore, MS
   Nadir, MN
AF Hayat, Asad
   Khalid, Yasir Noman
   Rathore, Muhammad Siraj
   Nadir, Muhammad Nadeem
TI A machine learning-based resource-efficient task scheduler for
   heterogeneous computer systems
SO JOURNAL OF SUPERCOMPUTING
DT Article
DE Heterogeneous computing; Machine learning; Gradient boosting; Work
   stealing; OpenCL
ID TIME
AB Heterogeneous computer systems are becoming mainstream due to their disparate processing and performance capabilities. These systems consist of different types of devices, i.e., central processing units (CPUs), accelerators, and graphics processing units (GPUs). In the heterogeneous computing environment, if one device is more powerful in terms of computing capability, the scheduling schemes generally favor the powerful device, and that device becomes overloaded, while the other device is underutilized. This load imbalance problem results in increased execution time. In this research, we propose load-balanced task scheduler combined with machine learning-based device predictor. The device predictor is used to predict execution time both on CPU and GPU devices, and a device with shorter predicted execution time is considered as a suitable device for that particular task. However, it may happen that a high fraction of tasks map only on one type of device since that device is considered as a suitable device for them. It is due to the fact that a task is mapped to one device (with lower predicted execution time), although it can be executed on the other device as well. In this context, one device may become overloaded, while the other device may be underutilized. To solve this problem of load imbalance, we use work-stealing-based task scheduler as part of our solution that allows an idle device to process tasks from the queue of another's device. In this way, we can avoid load imbalance, minimize the overall execution time of tasks, and maximize the device utilization and throughput. We evaluate the performance of our proposed solution into two stages. Firstly, we measure the error rate of our machine learning predictor using three different algorithms (i.e., random forest, gradient boosting, and multiple linear regression). We demonstrate that random forest performs better with marginal error rate. Secondly, we compare the performance of work-stealing task scheduler with other scheduling alternatives. Our results show that the proposed solution reduces execution time by 65.63%, increased resource utilization by 93.3%, and throughput by 65.5% in comparison with baseline scheduling schemes.
C1 [Rathore, Muhammad Siraj] Capital Univ Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.
   [Nadir, Muhammad Nadeem] Univ Lahore, Dept Comp Sci, Lahore, Pakistan.
   [Khalid, Yasir Noman] Hitech Univ, Dept Comp Sci, Taxila, Pakistan.
   [Hayat, Asad] Lahore Leads Univ, Dept Comp Sci, Lahore, Pakistan.
RP Rathore, MS (corresponding author), Capital Univ Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.
EM asad.cs@leads.edu.pk; yasir.noman.khalid@hitecuni.edu.pk;
   muhammad.siraj@cust.edu.pk; nadeem.nadir@cs.uol.edu.pk
CR Agostini M, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404433
   Ahmed U, 2021, SOFT COMPUT, V25, P407, DOI 10.1007/s00500-020-05152-8
   Alsubaihi S, 2017, IEEE SYM PARA DISTR, P994, DOI 10.1109/IPDPSW.2017.19
   Becchi M, 2010, SPAA '10: PROCEEDINGS OF THE TWENTY-SECOND ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P82
   Belviranli ME, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400716
   Boyer M, 2013, LOAD BALANCING CHANG, DOI [10.1145/2482767.2482794, DOI 10.1145/2482767.2482794]
   Choi HJ, 2013, J SUPERCOMPUT, V65, P886, DOI 10.1007/s11227-013-0870-6
   Chose A, 2017, PARALLEL PROCESS LET, V27, DOI 10.1142/S0129626417500086
   Daga M., 2011, Proceedings of the 2011 Symposium on Application Accelerators in High-Performance Computing (SAAHPC 2011), P141, DOI 10.1109/SAAHPC.2011.29
   Grewe D, 2011, LECT NOTES COMPUT SC, V6601, P286, DOI 10.1007/978-3-642-19861-8_16
   Huchant P, 2016, LECT NOTES COMPUT SC, V9833, P684, DOI 10.1007/978-3-319-43659-3_50
   Kaleem R, 2014, INT CONFER PARA, P151, DOI 10.1145/2628071.2628088
   Khalid YN, 2019, J PARALLEL DISTR COM, V132, P79, DOI 10.1016/j.jpdc.2019.05.015
   Khalid YN, 2018, J SUPERCOMPUT, V74, P5399, DOI 10.1007/s11227-018-2435-1
   Kreiliger Flavio, 2019, OSPERT, P23
   Kumar Varun, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370304
   Lee J, 2015, INT CONFER PARA, P355, DOI 10.1109/PACT.2015.14
   Lee J, 2015, ACM T COMPUT SYST, V33, DOI 10.1145/2798725
   Liu X, 2020, J AMB INTEL HUM COMP, V11, P2309, DOI 10.1007/s12652-019-01357-4
   Manathunga M, 2023, J CHEM INF MODEL, DOI 10.1021/acs.jcim.2c01505
   Memeti S, 2021, COMPUTING, V103, P2943, DOI 10.1007/s00607-021-01017-6
   Memeti S, 2018, IEEE INT C COMPUT, P138, DOI 10.1109/CSE.2018.00026
   Moren K, 2018, LECT NOTES COMPUT SC, V10861, P301, DOI 10.1007/978-3-319-93701-4_23
   Munshi A., 2009, 2009 IEEE HOT CHIPS, P1
   Noman Khalid Y, CONCURR COMP-PRACT E, DOI [10.1002/cpe.5606, DOI 10.1002/CPE.5606]
   Nozal R, 2020, FUTURE GENER COMP SY, V107, P522, DOI 10.1016/j.future.2020.02.016
   Öz I, 2022, J SUPERCOMPUT, V78, P4095, DOI 10.1007/s11227-021-04026-6
   Rahmani TA, 2022, 2022 INT C INN INT I, P674, DOI [10.1109/3ICT56508.2022.9990623, DOI 10.1109/3ICT56508.2022.9990623]
   Taylor B, 2017, ACM SIGPLAN NOTICES, V52, P11, DOI [10.1145/3078633.3081040, 10.1145/3140582.3081040]
   Tsog N, 2019, IEEE IND ELEC, P4516, DOI 10.1109/IECON.2019.8926767
   Wang Y, 2013, WORK STEALING SCHEDU, DOI [10.7873/date.2013.150, DOI 10.7873/DATE.2013.150]
   Wang YQ, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P103
   WANG Z, 2018, MACHINE LEARNING COM, DOI DOI 10.1109/JPROC.2018.2817118
   Weinhardt M, 2022, IEEE SYM PARA DISTR, P647, DOI 10.1109/IPDPSW55747.2022.00114
   Wen Y, 2014, SMART MULTI TASK SCH, DOI [10.1109/HiPC.2014.7116910, DOI 10.1109/HIPC.2014.7116910]
   Wen Y, 2017, PROCEEDINGS OF THE GENERAL PURPOSE GPUS (GPGPU-10), P22, DOI 10.1145/3038228.3038235
   Wenjie T, 2017, WORK STEALING BASED, DOI [10.1109/WSC.2017.8247833, DOI 10.1109/WSC.2017.8247833]
NR 37
TC 0
Z9 0
U1 0
U2 1
PD SEP
PY 2023
VL 79
IS 14
BP 15700
EP 15728
DI 10.1007/s11227-023-05266-4
EA APR 2023
UT WOS:000972344900001
DA 2023-11-16
ER

PT C
AU Yuan, YF
   Huang, JH
   Sun, Y
   Wang, TC
   Nelson, J
   Ports, DRK
   Wang, YP
   Wang, R
   Tai, C
   Kim, NS
AF Yuan, Yifan
   Huang, Jinghan
   Sun, Yan
   Wang, Tianchen
   Nelson, Jacob
   Ports, Dan R. K.
   Wang, Yipeng
   Wang, Ren
   Tai, Charlie
   Kim, Nam Sung
GP IEEE
TI RAMBDA: RDMA-driven Acceleration Framework for Memory-intensive
   <i>μ</i>s-scale Datacenter Applications
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
DE cache-coherent interconnects and accelerators; RDMA; heterogeneous and
   disaggregated memory; datacenters
AB Responding to the "datacenter tax" and "killer microseconds" problems for memory-intensive datacenter applications, diverse solutions including Smart NIC-based ones have been proposed. Nonetheless, they often suffer from high overhead of communications over network and/or PCIe links. To tackle the limitations of the current solutions, this paper proposes RAMBDA, a holistic network and architecture co-design solution that leverages current RDMA and emerging cache-coherent off-chip interconnect technologies. Specifically, RAMBDA consists of four hardware and software components: (1) unified abstraction of inter- and intra-machine communications synergistically managed by one-sided RDMA write and cache-coherent memory write; (2) efficient notification of requests to accelerators assisted by cache coherence; (3) cache-coherent accelerator architecture directly interacting with NIC; and (4) adaptive device-to-host data transfer for modern server memory systems comprising both DRAM and NVM exploiting state-of-the-art features in CPUs and PCIe. We prototype RAMBDA with a commercial system and evaluate three popular datacenter applications: (1) in-memory key-value store, (2) chain replication-based distributed transaction system, and (3) deep learning recommendation model inference. The evaluation shows that RAMBDA provides 30.1 similar to 69.1% lower latency, 0.2 similar to 2.5x throughput, and similar to 3x higher energy efficiency than the current state-of-the-art solutions, including Smart NIC. For those cases where RAMBDA performs poorly, we also envision future architecture to improve it.
C1 [Yuan, Yifan; Huang, Jinghan; Sun, Yan; Wang, Tianchen; Kim, Nam Sung] Univ Illinois, Champaign, IL 61820 USA.
   [Yuan, Yifan; Wang, Yipeng; Wang, Ren; Tai, Charlie] Intel Labs, Santa Clara, CA 95054 USA.
   [Nelson, Jacob; Ports, Dan R. K.] Microsoft Res, New York, NY USA.
RP Yuan, YF (corresponding author), Univ Illinois, Champaign, IL 61820 USA.; Yuan, YF (corresponding author), Intel Labs, Santa Clara, CA 95054 USA.
EM yifan.yuan@intel.com; jinghan4@illinois.edu; yans3@illinois.edu;
   tw12@illinois.edu; jacob.nelson@microsoft.com; dan.ports@microsoft.com;
   yipeng1.wang@intel.com; ren.wang@intel.com; charlie.tai@intel.com;
   nskim@illinois.edu
CR Acun B, 2021, INT S HIGH PERF COMP, P802, DOI 10.1109/HPCA51647.2021.00072
   Alian M, 2020, INT SYM PERFORM ANAL, P160, DOI 10.1109/ISPASS48437.2020.00031
   Alian M, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P699, DOI 10.1145/3352460.3358278
   Almeida S., 2013, P 8 ACM EUROPEAN C C
   Alshboul M, 2021, INT S HIGH PERF COMP, P111, DOI 10.1109/HPCA51647.2021.00019
   Amaro Emmanuel, 2020, HotNets '20: Proceedings of the 19th Workshop on Hot Topics in Networks, P38, DOI 10.1145/3422604.3425923
   Andersen DG, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P1
   [Anonymous], INT 64 IA 32 ARCH SO
   [Anonymous], 2021, COMMUNICATION
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   AWS, EL FABR AD RUN HPC M
   Bablani G., 2019, INTRO NEW PRODUCT IN
   Balakrishnan M, 2012, 9 USENIX S NETWORKED
   Barroso L, 2017, COMMUN ACM, V60, P47, DOI 10.1145/3015146
   Barroso LA, 2007, COMPUTER, V40, P33, DOI 10.1109/MC.2007.443
   Belay Adam, 2014, P USENIX S OP SYST D
   Blanas S., 2020, FLOPS IOPS NEW BOTTL
   Blott Michaela, 2013, 5 USENIX WORKSHOP HO
   Boden Nan, 2018, AVAILABLE 1 GOOGLE C
   Burke Matthew, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P228, DOI 10.1145/3477132.3483587
   Cai QZ, 2021, SIGCOMM '21: PROCEEDINGS OF THE 2021 ACM SIGCOMM 2021 CONFERENCE, P65, DOI 10.1145/3452296.3472888
   Calciu I, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P79, DOI 10.1145/3445814.3446713
   Calder B., 2011, P 23 ACM S OPERATING
   Caminal Y., 2022, P 49 ANN INT S COMPU
   Caulfield AM, 2016, INT SYMP MICROARCH
   CCIX Consortium, CCIX
   Chen SJ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2900, DOI 10.1145/3394486.3403341
   Chen YZ, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901349
   Chen YM, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303968
   Choi YK, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3294054
   Cock D, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P434, DOI 10.1145/3503222.3507742
   Corporation, INT ARR 10 GX 1150 F
   Cutress I., 2021, INTEL LAUNCH NEXT GE
   Cutress I., 2021, USING PCIE SLOT INST
   CXL Consortium, COMP EXPR LINK CXL
   Daglis A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P35, DOI 10.1145/3297858.3304070
   Daglis A, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P567, DOI 10.1145/2749469.2750415
   Dang H. T., 2016, USIINFTR201603
   Dang H. T., 2018, USIINFTR201801
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Dragojevic A., 2014, 11 USENIX S NETWORKE, P401
   Eisenman A., 2019, P 2 SYSML C SYSML 19
   Eran M., 2022, P 27 ACM INT C ARCHI
   Eryilmaz Z. F., 2021, INT C DAT ENG ICDE
   Escriva R, 2012, ACM SIGCOMM COMP COM, V42, P25, DOI 10.1145/2377677.2377681
   Facebook, ROCKSDB PERS KEY VAL
   Falsafi B, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P393
   Farshin A, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P673
   Farshin A, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303977
   Flajslik M., 2013, P 2013 USENIX ANN TE
   Gao Y., 2021, P 18 USENIX S NETWOR
   Geng Y., 2013, USENIX ATC
   Ghemawat S., 2003, Operating Systems Review, V37, P29, DOI 10.1145/1165389.945450
   Glasser S. D., 2013, US Patent, Patent No. [20130173837A1, 20130173837]
   Golestani H, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P337, DOI 10.1145/3357223.3362737
   Gope D, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P507, DOI 10.1145/3079856.3080234
   Gouk Donghyun, 2022, P 2022 USENIX ANN TE
   Guo CX, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P202
   Guo ZY, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P417, DOI 10.1145/3503222.3507762
   Gupta A, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P357, DOI 10.1145/3230543.3230555
   Gupta U., 2020, P 2020 IEEE INT S HI
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Hwang R, 2020, ANN I S COM, P968, DOI 10.1109/ISCA45697.2020.00083
   Ibanez S, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P239
   Intel Corporation, INT XEON GOLD 6138P
   Intel Corporation, INT STRAT 10 DX FPGA
   Intel Corporation, DAT PLAN DEV KIT DPD
   Intel Corporation, INT DAT DIR I O DDIO
   Intel Corporation, EADR NEW OPP PERS ME
   Intel Corporation, INT OPT PERS MEM
   Jeong E., 2014, 11 USENIX S NETW SYS, P489
   Jin X, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P35
   Jin X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P121, DOI 10.1145/3132747.3132764
   Jongyul Kim, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P756, DOI 10.1145/3477132.3483565
   Kalia Anuj, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P105, DOI 10.1145/3419111.3421294
   Kalia A, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P1
   Kalia A, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P185
   Kalia A, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P437
   Kalia A, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P295, DOI [10.1145/2619239.2626299, 10.1145/2740070.2626299]
   Kanev S., 2015, P 42 IEEEACM INT S C
   Ke L., 2020, P ACMIEEE 47 ANN INT
   Kim D, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P90, DOI 10.1145/3387514.3405855
   Kim D, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P297, DOI 10.1145/3230543.3230572
   Kocberber Onur, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P468, DOI 10.1145/2540708.2540748
   Kung H. T., 1994, Computer Communication Review, V24, P101, DOI 10.1145/190809.190324
   Kurth M, 2020, P IEEE S SECUR PRIV, P20, DOI 10.1109/SP40000.2020.00082
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lazarev N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P36, DOI 10.1145/3445814.3446696
   Le Y., 2019, P 3 ASIA PACIC WORKS
   Lee S. -s., 2021, P ACM SIGOPS 28 S OP
   Lee Y., 2021, P 26 INT C ARCHITECT
   Lerner R. Hussein, 2019, P 9 BIENNIAL C INNOV
   Li BJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P137, DOI 10.1145/3132747.3132756
   Li JL, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P387
   Li JL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P104, DOI 10.1145/3132747.3132751
   Li JL, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P467
   Lim H., 2014, P 11 USENIX S NETW S
   Lim K., 2013, P 40 ANN INT S COMP
   Liu M., 2017, P 22 INT C ARCHITECT
   Liu M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P363
   Liu M, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P318, DOI 10.1145/3341302.3342079
   Lockerman E, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P417, DOI 10.1145/3373376.3378497
   Ma J., 2020, P 25 INT C ARCHITECT
   Manousis Antonis, 2020, P 2020 ACM SIGCOMM C, P270, DOI 10.1145/3387514.3405868
   Mellanox, MELL SCAL HIER AGGR
   Mellanox, MELL AD PROGR REF MA
   Memaripour A, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P499, DOI 10.1145/3064176.3064215
   Mirhosseini A, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P852, DOI 10.1109/MICRO50266.2020.00074
   Mirhosseini A, 2019, INT S HIGH PERF COMP, P185, DOI 10.1109/HPCA.2019.00037
   Mitchell C, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P451
   Monga Sumit Kumar, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P212, DOI 10.1145/3477132.3483576
   mongoDB, MONGODB MAN MAN CHAI
   Naumov Maxim, 2019, ARXIV
   ndikar C., 2021, P 54 ANN IEEEACM INT
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Novakovic S, 2019, SYSTOR '19: PROCEEDINGS OF THE 12TH ACM INTERNATIONAL SYSTEMS AND STORAGE CONFERENCE, P97, DOI 10.1145/3319647.3325827
   Novakovic S, 2014, ACM SIGPLAN NOTICES, V49, P3, DOI 10.1145/2541940.2541965
   NVIDIA Corporation, NVIDIA BLUEFIELD 2 D
   NVIDIA Corporation, 2021, NVIDIA EXT DAT CTR I
   NVIDIA Corporation, RDMA AW NETW PROGR U
   Oboril F, 2012, I C DEPEND SYS NETWO
   Ohara H., 2014, REVISIT DCA PCIE TPH
   Ongaro D, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P29
   Optocrypto, INT SAPPH RAP HBM2E
   Owaida M., P 2017 IEEE 25 ANN I, P201
   Pandruvada Srinivas, RUNNING AVERAGE POWE
   Park J., 2021, P 54 ANN IEEEACM INT
   Phanishayee A., 2012, P 2012 WORKSHOP MANA
   Phothilimthana PM, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P663
   Pismenny B, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P1130, DOI 10.1145/3503222.3507711
   PLDA, LIGHTW NOT
   Pontarelli S, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P531
   Ports D. R. K., 2015, P 12 USENIX S NETW S
   Pourhabibi A., 2021, P 54 ANN IEEEACM INT
   Reda W., 2022, P 19 USENIX S NETWOR
   Romanovsky L., MLX5DV LINUX MANUAL
   SAP, 2017, PERF SYST REPL SAP H
   Sapio A, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P785
   Sapio A, 2017, HOTNETS-XVI: PROCEEDINGS OF THE 16TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P150, DOI 10.1145/3152434.3152461
   Schuh Henry N., 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P740, DOI 10.1145/3477132.3483555
   Seemakhupt K., 2021, P 48 IEEEACM INT S C
   Shalev L, 2020, IEEE MICRO, V40, P67, DOI 10.1109/MM.2020.3016891
   Sidler D, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387519
   Sidler D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P403, DOI 10.1145/3035918.3035954
   Singhvi A., 2020, P 2020 ACM SIGCOMM C
   Sriraman A, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P733, DOI 10.1145/3373376.3378450
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Sutherland M, 2020, ANN I S COM, P199, DOI 10.1109/ISCA45697.2020.00027
   Tai A, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P337
   Talpey T., 2019, RDMA PERSISTENT MEOR
   Terrace Jeff, 2009, P 2009 USENIX ANN TE
   Tootoonchian A, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P283
   Tork M, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P117, DOI 10.1145/3373376.3378528
   Tsai SY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P306, DOI 10.1145/3132747.3132762
   van Renesse R, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P91
   Wang Q, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P277
   Wang ZK, 2020, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM48280.2020.00024
   Wang ZL, 2023, PROCEEDINGS OF THE 20TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, NSDI 2023, P1
   Wei X., 2021, P 2021 USENIX ANN TE
   Wei XD, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P233
   Wei XD, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P87, DOI 10.1145/2815400.2815419
   WikiChip, SKYLAKE SERV MICR IN
   Xilinx, ALVEO U280 DAT CTR A
   Xilinx, XILINX VIRT 7 FPGA V
   Xue JC, 2020, IEEE ACM T NETWORK, V28, P322, DOI 10.1109/TNET.2019.2961671
   Yang J, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P169
   Ye C., 2021, P 2021 IEEE INT S HI
   Yu Z., P 2020 ACM SIGCOMM C
   Yuan Y., 2021, P 2021 IEEE INT S HI
   Yuan YF, 2021, CONF PROC INT SYMP C, P112, DOI 10.1109/ISCA52012.2021.00018
   Zeng C., 2022, P 16 USENIX S OPERAT
   Zeng C., 2022, P 19 USENIX S NETWOR
   Zha Y, 2021, CONF PROC INT SYMP C, P470, DOI 10.1109/ISCA52012.2021.00044
   Zhao W., 2020, P 3 C MACHINE LEARNI
   Zhao WJ, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P319, DOI 10.1145/3357384.3358045
   Zhou D, 2013, PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT '13), P97, DOI 10.1145/2535372.2535379
   Zhou SY, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P687
   Zhu H, 2019, PROC VLDB ENDOW, V13, P376, DOI 10.14778/3368289.3368301
   Zhu YB, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P523, DOI 10.1145/2785956.2787484
NR 180
TC 0
Z9 0
U1 4
U2 4
PY 2023
BP 499
EP 515
DI 10.1109/HPCA56546.2023.10071127
UT WOS:000982303200037
DA 2023-11-16
ER

PT C
AU Tiemann, T
   Weissman, Z
   Eisenbarth, T
   Sunar, B
AF Tiemann, Thore
   Weissman, Zane
   Eisenbarth, Thomas
   Sunar, Berk
GP ACM
TI IOTLB-SC: An Accelerator-Independent Leakage Source in Modern Cloud
   Systems
SO PROCEEDINGS OF THE 2023 ACM ASIA CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY, ASIA CCS 2023
DT Proceedings Paper
CT 18th ACM ASIA Conference on Computer and Communications Security (ASIA
   CCS)
CY JUL 10-14, 2023
CL Melbourne, AUSTRALIA
DE cloud; FPGA; side-channel; peripheral; IOMMU
ID CACHE ATTACKS
AB Hardware peripherals such as GPUs and FPGAs are commonly available in server-grade computing to accelerate specific compute tasks, from database queries to machine learning. CSPs have integrated these accelerators into their infrastructure and let tenants combine and configure these components flexibly, based on their needs. Securing I/O interfaces is critical to ensure proper isolation between tenants in these highly complex, heterogeneous, yet shared server systems, especially in the cloud, where some peripherals may be under control of a malicious tenant.
   In this work, we investigate the interfaces that connect peripheral hardware components to each other and the rest of the system. We show that the I/O memory management units (IOMMUs) - intended to ensure proper isolation of peripherals - are the source of a new attack surface: the I/O translation look-aside buffer (IOTLB). We show that by using an FPGA accelerator card one can gain precise information over IOTLB activity. That information can be used for covert communication between peripherals without bothering CPU or to directly extract leakage from neighboring accelerated compute jobs such as GPU-accelerated databases. We present the first qualitative and quantitative analysis of this newly uncovered attack surface before fine-grained channels become widely viable with the introduction of CXL and PCIe 5.0. In addition, we propose possible countermeasures that software developers, hardware designers, and system administrators can use to suppress the observed side-channel leakages and analyze their implicit costs.
C1 [Tiemann, Thore; Eisenbarth, Thomas] Univ Lubeck, Lubeck, SH, Germany.
   [Weissman, Zane; Sunar, Berk] Worcester Polytech Inst, Worcester, MA USA.
RP Tiemann, T (corresponding author), Univ Lubeck, Lubeck, SH, Germany.
EM t.tiemann@uni-luebeck.de; zweissman@wpi.edu;
   thomas.eisenbarth@uni-luebeck.de; sunar@wpi.edu
CR Alibaba Cloud, 2019, FPGA BAS COMP OPT IN
   Alibaba Cloud ECS, 2020, INTR 6 GEN AL CLOUDS
   Almeida JB, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P53
   Amazon AWS, 2018, AWS NITR SYST
   Amazon AWS, 2017, AM EC2 F1 INST
   AMD, 2021, AMD I O VIRT TECHN I
   AMD, 2022, OFF UNM PERF LEAD EN
   [Anonymous], 2016, INT 64 IA 32 ARCH OP
   Barthe G, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1267, DOI 10.1145/2660267.2660283
   Blazy S, 2018, LECT NOTES COMPUT SC, V10492, P260, DOI 10.1007/978-3-319-66402-6_16
   Borrello P, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3917
   Chor B, 1998, J ACM, V45, P965, DOI 10.1145/293347.293350
   Cojocar L, 2019, P IEEE S SECUR PRIV, P55, DOI 10.1109/SP.2019.00089
   Disselkoen C, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P51
   Firestone D, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P51
   Frigo P, 2020, P IEEE S SECUR PRIV, P747, DOI 10.1109/SP40000.2020.00090
   Frigo P, 2018, P IEEE S SECUR PRIV, P195, DOI 10.1109/SP.2018.00022
   Gianelli Silvia E., 2017, XILINX ANNOUNCES GEN
   Gras B, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23271
   Gras B, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P955
   Gruss Daniel, 2016, Detection of Intrusions and Malware, and Vulnerability Assessment. 13th International Conference, DIMVA 2016. Proceedings: LNCS 9721, P279, DOI 10.1007/978-3-319-40667-1_14
   Gruss D, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P217
   Hayata Junichiro, 2020, Computer Security - ESORICS 2020. 25th European Symposium on Research in Computer Security, ESORICS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12309), P674, DOI 10.1007/978-3-030-59013-0_33
   Hund R, 2013, P IEEE S SECUR PRIV, P191, DOI 10.1109/SP.2013.23
   Inci MS, 2016, LECT NOTES COMPUT SC, V9813, P368, DOI 10.1007/978-3-662-53140-2_18
   Inci MS, 2016, LECT NOTES COMPUT SC, V9689, P19, DOI 10.1007/978-3-319-43283-0_2
   Intel, 2012, INT DAT DIR I O TECH
   Intel Corporation, 2019, INTEL VIRTUALIZATION, V1
   Irazoqui G, 2015, 2015 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P629, DOI 10.1109/DSD.2015.56
   Khaliq SA, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622848
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Kurth M, 2020, P IEEE S SECUR PRIV, P20, DOI 10.1109/SP40000.2020.00082
   Kushilevitz E, 1997, ANN IEEE SYMP FOUND, P364
   Lipp M, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P973
   Liu F, 2016, INT S HIGH PERF COMP, P406, DOI 10.1109/HPCA.2016.7446082
   Liu FF, 2015, P IEEE S SECUR PRIV, P605, DOI 10.1109/SP.2015.43
   Markettos AT, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23194
   Maurice C, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23294
   Mingtian Tan, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P322, DOI 10.1109/SP40001.2021.00059
   MITRE, 2018, CVE201812126
   MITRE, 2018, CVE201812127
   Morgan Benoit, 2018, Journal of the Brazilian Computer Society, V24, DOI 10.1186/s13173-017-0066-7
   Morgan B, 2016, LAT-AM SYMP DEP COMP, P145, DOI 10.1109/LADC.2016.31
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Nguyen K. T., 2016, USAGE MODELS CACHE A
   Oren Y, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1406, DOI 10.1145/2810103.2813708
   Osvik DA, 2006, LECT NOTES COMPUT SC, V3860, P1
   PCI-SIG, 2006, PCI EXPRESS BASE SPE
   PCI-SIG, 2009, ADDR TRANSL SERV
   Peglow Christoph, 2020, THESIS U LUBECK
   Pessl P, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P565
   Purnal A, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3647
   Purnal A, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2906, DOI 10.1145/3460120.3484816
   RedHat Inc., 2014, SYS CLASS IOMM IOMM
   Ristenpart T, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P199
   Sanchez D, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P57, DOI 10.1145/2024723.2000073
   Schwarz Michael, 2019, CCS '19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, P753, DOI 10.1145/3319535.3354252
   Sharma Debendra Das, 2019, COMPUTE EXPRESS LINK
   Shilov Anton, 2022, INTELS SAPPHIRE RAPI
   SIBERT O, 1995, P IEEE S SECUR PRIV, P211, DOI 10.1109/SECPRI.1995.398934
   Tatar A, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P989
   van Schaik S, 2019, P IEEE S SECUR PRIV, P88, DOI 10.1109/SP.2019.00087
   Vila P, 2019, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2019.00042
   Weissman Z., 2020, IACR T CRYPTOGR HARD, P169, DOI DOI 10.13154/TCHES.V2020.I3.169-195
   Wichelmann J, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P161, DOI 10.1145/3274694.3274741
   Yarom Y, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P719
   Ye Y, 2014, INT CONFER PARA, P381, DOI 10.1145/2628071.2628104
   Zhang YQ, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P990, DOI 10.1145/2660267.2660356
NR 68
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 827
EP 840
DI 10.1145/3579856.3582838
UT WOS:001053857900065
DA 2023-11-16
ER

PT C
AU Zhou, MX
   Xu, WH
   Kang, J
   Rosing, T
AF Zhou, Minxuan
   Xu, Weihong
   Kang, Jaeyoung
   Rosing, Tajana
GP IEEE Comp Soc
TI TransPIM: A Memory-based Acceleration via Software-Hardware Co-Design
   for Transformer
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE Processing in-memory; Near-data processing; Transformer; Domain-specific
   acceleration; Software-hardware co-design
ID DRAM
AB Transformer-based models are state-of-the-art for many machine learning (ML) tasks. Executing Transformer usually requires a long execution time due to the large memory footprint and the low data reuse rate, stressing the memory system while under-utilizing the computing resources. Memory-based processing technologies, including processing in-memory (PIM) and near-memory computing (NMC), are promising to accelerate Transformer since they provide high memory bandwidth utilization and extensive computation parallelism. However, the previous memory-based ML accelerators mainly target at optimizing dataflow and hardware for compute-intensive ML models (e.g., CNNs), which do not fit the memory-intensive characteristics of Transformer. In this work, we propose TransPIM, a memory-based acceleration for Transformer using software and hardware co-design. In the software-level, TransPIM adopts a token-based dataflow to avoid the expensive inter-layer data movements introduced by previous layer-based dataflow. In the hardware-level, TransPIM introduces lightweight modifications in the conventional high bandwidth memory (HBM) architecture to support PIM-NMC hybrid processing and efficient data communication for accelerating Transformer-based models. Our experiments show that TransPIM is 3.7x to 9.1x faster than existing memory-based acceleration. As compared to conventional accelerators, TransPIM is 22.1x to 114.9x faster than GPUs and provides 2.0x more throughput than existing ASIC-based accelerators.
C1 [Zhou, Minxuan; Xu, Weihong; Kang, Jaeyoung; Rosing, Tajana] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Zhou, MX (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM miz087@ucsd.edu; wexu@ucsd.edu; j5kang@ucsd.edu; tajana@ucsd.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ali ME, 2020, IEEE T CIRCUITS-I, V67, P155, DOI 10.1109/TCSI.2019.2945617
   [Anonymous], 2013, JESD235 JEDEC
   BATCHER KE, 1982, IEEE T COMPUT, V31, P377, DOI 10.1109/TC.1982.1676015
   Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150
   Bertasius G., ARXIV210205095, V2, P813
   Lipton ZC, 2015, Arxiv, DOI [arXiv:1506.00019, DOI 10.48550/ARXIV.1506.00019]
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen K, 2012, DES AUT TEST EUROPE, P33
   Choi Young-Kyu, 2021, FPGA, V2021, P116, DOI 10.1145/3431920.3439301
   Cohan A., 2018, P 2018 C N AM CHAPTE, V2, P615, DOI [10.18653/v1/n18-2097, DOI 10.18653/V1/N18-2097]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Imani M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P356, DOI 10.1109/MICRO50266.2020.00039
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214
   Jiarui Fang, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P389, DOI 10.1145/3437801.3441578
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kara K, 2020, I C FIELD PROG LOGIC, P1, DOI 10.1109/FPL50879.2020.00013
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kitaev N., 2020, P INT C LEARNING REP
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Lee CC, 2016, ELEC COMP C, P1439, DOI 10.1109/ECTC.2016.348
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Maas A., 2011, P 49 ANN M ASS COMPU
   Minxuan Zhou, 2021, 2021 30th International Conference on Parallel Architectures and Compilation Techniques (PACT), DOI 10.1109/PACT52795.2021.00021
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Oh CS, 2020, ISSCC DIG TECH PAP I, P330, DOI 10.1109/isscc19947.2020.9063110
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Radford A., 2019, OPENAI BLOG, V1, P9
   Ramanathan AK, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P88, DOI 10.1109/MICRO50266.2020.00020
   Seshadri Vivek, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P185, DOI 10.1145/2540708.2540725
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shin H, 2018, IEEE T COMPUT AID D, V37, P2613, DOI 10.1109/TCAD.2018.2857044
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Wang H., 2020, ARXIV
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P811, DOI 10.1109/MICRO50266.2020.00071
   Zaheer M, 2021, Arxiv, DOI arXiv:2007.14062
   Zhou MX, 2021, DES AUT CON, P25, DOI 10.1109/DAC18074.2021.9586212
   Zhou MX, 2021, INT CONFER PARA, P199, DOI 10.1109/PACT52795.2021.00022
   Zhou MX, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P591, DOI 10.1145/3287624.3287711
   Zhu MH, 2018, IEEE T VLSI SYST, V26, P831, DOI 10.1109/TVLSI.2018.2791442
NR 50
TC 8
Z9 8
U1 1
U2 5
PY 2022
BP 1071
EP 1085
DI 10.1109/HPCA53966.2022.00082
UT WOS:000838704300074
DA 2023-11-16
ER

PT C
AU Yuan, Y
   Alama, O
   Fei, J
   Nelson, J
   Ports, DRK
   Sapio, A
   Canini, M
   Kim, NS
AF Yuan, Yifan
   Alama, Omar
   Fei, Jiawei
   Nelson, Jacob
   Ports, Dan R. K.
   Sapio, Amedeo
   Canini, Marco
   Kim, Nam Sung
GP USENIX ASSOC
TI Unlocking the Power of Inline Floating-Point Operations on Programmable
   Switches
SO PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND
   IMPLEMENTATION (NSDI '22)
DT Proceedings Paper
CT 19th USENIX Symposium on Networked Systems Design and Implementation
   (NSDI)
CY APR 04-06, 2022
CL Renton, WA
ID IMPLEMENTATION
AB The advent of switches with programmable dataplanes has enabled the rapid development of newnetwork functionality, as well as providing a platform for acceleration of a broad range of application-level functionality. However, existing switch hardware was not designed with application acceleration in mind, and thus applications requiring operations or datatypes not used in traditional network protocols must resort to expensive workarounds. Applications involving floating point data, including distributed training for machine learning and distributed query processing, are key examples.
   In this paper, we propose FPISA, a floating point representation designed to work efficiently in programmable switches. We first implement FPISA on an Intel Tofino switch, but find that it has limitations that impact throughput and accuracy. We then propose hardware changes to address these limitations based on the open-source Banzai switch architecture, and synthesize them in a 15-nm standard-cell library to demonstrate their feasibility. Finally, we use FPISA to implement accelerators for training for machine learning as an example application, and evaluate its performance on a switch implementing our changes using emulation. We find that FPISA allows distributed training to use one to three fewer CPU cores and provide up to 85.9% better throughput than SwitchML in a CPU-constrained environment.
C1 [Yuan, Yifan; Kim, Nam Sung] UIUC, Champaign, IL 61820 USA.
   [Alama, Omar; Fei, Jiawei; Canini, Marco] KAUST, Thuwal, Saudi Arabia.
   [Fei, Jiawei] NUDT, Changsha, Peoples R China.
   [Nelson, Jacob; Ports, Dan R. K.] Microsoft Res, Redmond, WA USA.
   [Sapio, Amedeo] Intel, Santa Clara, CA USA.
RP Yuan, Y (corresponding author), UIUC, Champaign, IL 61820 USA.
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Alachiotis N., 2010, P 2010 IEEE INT S PA
   Alizadeh M, 2014, ACM SIGCOMM COMP COM, V44, P503, DOI 10.1145/2740070.2626316
   [Anonymous], 2018, RFC
   [Anonymous], 2002, P ACM IEEE C SUP, DOI DOI 10.1109/SC.2002.10017
   [Anonymous], INTEL CORPORATION
   [Anonymous], 2007, THESIS STANFORD U
   Arista, 7130 FPGA ENABLED NE
   BARNETT M, 1994, PROCEEDINGS OF THE SCALABLE HIGH-PERFORMANCE COMPUTING CONFERENCE, P357, DOI 10.1109/SHPCC.1994.296665
   Ben Basat R., 2020, P 2020 ACM SIGMOD IN
   Ben Basat R, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P662, DOI 10.1145/3387514.3405894
   Bosshart P, 2014, ACM SIGCOMM COMP COM, V44, P87, DOI 10.1145/2656877.2656890
   Bosshart P, 2013, ACM SIGCOMM COMP COM, V43, P99, DOI 10.1145/2534169.2486011
   Broadcom, TRIDENT4 BCM56880 SE
   Broadcom, NPL OPEN HIGH LEVEL
   Chilimbi T., 2014, P 11 USENIX S OP SYS, P571, DOI DOI 10.1108/01439911111122716
   Chole S, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P1, DOI 10.1145/3098822.3098823
   Courbariaux M, 2015, Arxiv, DOI arXiv:1412.7024
   Cui PL, 2021, I C NETWORK PROTOCOL, DOI 10.1109/ICNP52444.2021.9651946
   Dang HT, 2020, IEEE ACM T NETWORK, V28, P1726, DOI 10.1109/TNET.2020.2992106
   De Sensi Daniele, 2021, ARXIV
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Deng W, 2021, Arxiv, DOI arXiv:2002.06987
   Devarakonda A, 2017, ADABATCH ADAPTIVE BA
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Drumond M., 2018, ADV NEURAL INFORM PR
   Gebara N., 2021, P 4 MLSYS CONFRENCE
   Geng JJ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030280
   Google Cloud, USING BFLOAT16 TENSO
   Graham R. L., 2016, P 1 WORKSHOP OPTIMIZ
   Graham R. L., 2020, P 35 INT C HIGH PERF
   Gu JC, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P485
   Gupta A, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P357, DOI 10.1145/3230543.3230555
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Hauser Frederik, 2021, SURVEY DATA PLANE PR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho Qirong, 2013, Adv Neural Inf Process Syst, V2013, P1223
   Horvath S, 2020, Arxiv, DOI arXiv:1905.10988
   Hwang CH, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P721
   Iandola FN, 2016, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR.2016.284
   Intel Corporation, INTEL TOFINO2
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jepsen T., 2018, P ACM SIGCOMM 2018 W
   Jia XY, 2018, Arxiv, DOI arXiv:1807.11205
   Jiang YM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P463
   Jin X, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P35
   Jin X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P121, DOI 10.1145/3132747.3132764
   Johnson J, 2018, Arxiv, DOI arXiv:1811.01721
   Jose M, 2021, 2021 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2021), P358
   Jozefowicz R, 2016, Arxiv, DOI arXiv:1602.02410
   Kalamkar D, 2019, Arxiv, DOI [arXiv:1905.12322, DOI 10.48550/ARXIV.1905.12322]
   Katabi D, 2002, ACM SIGCOMM COMP COM, V32, P89, DOI 10.1145/964725.633035
   Katta N, 2016, SYMPOSIUM ON SOFTWARE DEFINED NETWORKING (SDN) RESEARCH (SOSR'16), DOI 10.1145/2890955.2890968
   Kim D, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P90, DOI 10.1145/3387514.3405855
   Klenk B, 2020, ANN I S COM, P996, DOI 10.1109/ISCA45697.2020.00085
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Krizhevsky A., THE CIFAR 10 DATASET
   Kundel R, 2018, 2018 IEEE CONFERENCE ON NETWORK FUNCTION VIRTUALIZATION AND SOFTWARE DEFINED NETWORKS (NFV-SDN)
   Lao ChonLam, 2021, P 18 USENIX S NETWOR
   Leon AS, 2007, IEEE J SOLID-ST CIRC, V42, P7, DOI 10.1109/JSSC.2006.885049
   Lerner, 2020, P 19 ACM WORKSH HOT
   Lerner A., 2019, P 9 BIENNIAL C INNOV
   Li JL, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P387
   Li JL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P104, DOI 10.1145/3132747.3132751
   Li JL, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P467
   Li M., 2014, P 11 USENIX S OPERAT
   Li Y., 2019, P 46 INT S COMPUTER
   Li YM, 1997, 5TH ANNUAL IEEE SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM COMPUTING MACHINES, P226, DOI 10.1109/FPGA.1997.624623
   Li YJ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P175, DOI 10.1109/MICRO.2018.00023
   Liu ZX, 2019, PROCEEDINGS OF THE 17TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P143
   Lo D., 2020, ADV NEURAL INFORM PR
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   Mathew SK, 2005, IEEE J SOLID-ST CIRC, V40, P44, DOI 10.1109/JSSC.2004.838019
   Mellanox, QM8700 MELLANOX QUAN
   Mellanox, MELLANOX SCALABLE HI
   Menth M, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11070159
   Miao R, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P15, DOI 10.1145/3098822.3098824
   Micikevicius Paulius, 2017, MIXED PRECISION TRAI, DOI DOI 10.48550/ARXIV.1710.03740
   MLCommons, MLPERF BENCHMARK
   Moritz P, 2016, Arxiv, DOI arXiv:1511.06051
   Nemirovski A, 2009, SIAM J OPTIMIZ, V19, P1574, DOI 10.1137/070704277
   Nemirovskij A. S., 1983, PROBLEM COMPLEXITY M
   NVIDIA, AP TOOLS EAS MIX PRE
   NVIDIA blog, TENSORFLOAT 32 A100
   Oberman SF, 1999, P S COMP ARITHM, P106, DOI 10.1109/ARITH.1999.762835
   OpenSwitch, CAVIUM XPLIANT FAMIL
   Paszke A, 2019, ADV NEUR IN, V32
   Patarasuk P, 2009, J PARALLEL DISTR COM, V69, P117, DOI 10.1016/j.jpdc.2008.09.002
   Peng YH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P16, DOI 10.1145/3341301.3359642
   Piasetzky Y., 2018, P 2018 IEEE 26 INT C
   Ports D. R. K., 2015, P 12 USENIX S NETWOR
   Ports DRK, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P209, DOI 10.1145/3317550.3321439
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Sa CD, 2018, Arxiv, DOI arXiv:1803.03383
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sapio A, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P785
   Sapio A, 2017, HOTNETS-XVI: PROCEEDINGS OF THE 16TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P150, DOI 10.1145/3152434.3152461
   Sharma N. K., 2018, P 15 USENIX S NETWOR
   Sharma NK, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P67
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaraman A, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P44, DOI 10.1145/2934872.2934899
   Sivaraman A, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P15, DOI 10.1145/2934872.2934900
   Soderquist P, 1996, ACM COMPUT SURV, V28, P518, DOI 10.1145/243439.243481
   Sonchack J, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190558
   Svyatkovskiy A., 2017, P MACHINE LEARNING H
   synopsys, DESIGN COMPILER GRAP
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TANG PTP, 1990, ACM T MATH SOFTWARE, V16, P378, DOI 10.1145/98267.98294
   Tokusashi Y, 2018, Arxiv, DOI arXiv:1805.11344
   Tokusashi Y, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303979
   Venkataraman S., 2013, P 8 ACM EUROPEAN C C
   Voogel M., 2020, HOTCHIPS 20 VIRTUAL
   Wang Naigang, 2018, ADV NEURAL INFORM PR
   Yangrui Chen, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P507, DOI 10.1145/3419111.3421307
   Yu ZL, 2021, SIGCOMM '21: PROCEEDINGS OF THE 2021 ACM SIGCOMM 2021 CONFERENCE, P179, DOI 10.1145/3452296.3472887
   Yu ZL, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P126, DOI 10.1145/3387514.3405857
   Zhen Zhang, 2020, NetAI '20: Proceedings of the Workshop on Network Meets AI & ML, P8, DOI 10.1145/3405671.3405810
   Zhou Y, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P76, DOI 10.1145/3387514.3406214
   Zhu H, 2019, PROC VLDB ENDOW, V13, P376, DOI 10.14778/3368289.3368301
NR 120
TC 9
Z9 9
U1 0
U2 0
PY 2022
BP 683
EP 700
UT WOS:000876762200040
DA 2023-11-16
ER

PT C
AU Liu, XY
   Tyagin, I
   Ushijima-Mwesigwa, H
   Ghosh, I
   Safro, I
AF Liu, Xiaoyuan
   Tyagin, Ilya
   Ushijima-Mwesigwa, Hayato
   Ghosh, Indradeep
   Safro, Ilya
BE Candan, KS
   Dinh, TN
   Thai, MT
   Washio, T
TI Towards Practical Explainability with Cluster Descriptors
SO 2022 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW
SE International Conference on Data Mining Workshops
DT Proceedings Paper
CT 22nd IEEE International Conference on Data Mining (ICDM)
CY NOV 28-DEC 01, 2022
CL Orlando, FL
DE explainability; clustering; machine learning; Ising model; combinatorial
   optimization
ID OPTIMIZATION
AB With the rapid development of machine learning, improving its explainability has become a crucial research goal. We study the problem of making the clusters more explainable by investigating the cluster descriptors. Given a set of objects S, a clustering of these objects pi, and a set of tags T that have not participated in the clustering algorithm. Each object in S is associated with a subset of T. The goal is to find a representative set of tags for each cluster, referred to as the cluster descriptors, with the constraint that these descriptors we find are pairwise disjoint, and the total size of all the descriptors is minimized. In general, this problem is NP-hard. We propose a novel explainability model that reinforces the previous models in such a way that tags that do not contribute to explainability and do not sufficiently distinguish between clusters are not added to the optimal descriptors. The proposed model is formulated as a quadratic unconstrained binary optimization problem which makes it suitable for solving on modern optimization hardware accelerators. We experimentally demonstrate how a proposed explainability model can be solved on specialized hardware for accelerating combinatorial optimization, the Fujitsu Digital Annealer, and use real-life Twitter and PubMed datasets for use cases. Reproducibility materials: Link
C1 [Liu, Xiaoyuan; Ushijima-Mwesigwa, Hayato; Ghosh, Indradeep] Fujitsu Res Amer Inc, Sunnyvale, CA 94085 USA.
   [Tyagin, Ilya; Safro, Ilya] Univ Delaware, Newark, DE USA.
RP Liu, XY (corresponding author), Fujitsu Res Amer Inc, Sunnyvale, CA 94085 USA.
EM xliu@fujitsu.com; tyagin@udel.edu; hayato@fujitsu.com;
   ighosh@fujitsu.com; isafro@udel.edu
CR Aramon M, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00048
   BARAHONA F, 1988, OPER RES, V36, P493, DOI 10.1287/opre.36.3.493
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boros E., 1991, Annals of Operations Research, V33, P151, DOI 10.1007/BF02115753
   Chen HH, 2020, CHAOS, V30, DOI 10.1063/5.0004983
   Coffrin C, 2019, LECT NOTES COMPUT SC, V11494, P163, DOI 10.1007/978-3-030-19212-9_11
   Comarela G., 2011, P WORKSHOP LANGUAGES, P58
   Davidson I., 2018, ADV NEURAL INFORM PR
   Farhi E, 2014, Arxiv, DOI [arXiv:1411.4028, DOI 10.48550/ARXIV.1411.4028]
   Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265
   Fujitsu, 2022, FUJITSU DIGITAL ANNE
   GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5
   Glover F, 2019, Arxiv, DOI arXiv:1811.11538
   Inagaki T, 2016, SCIENCE, V354, P603, DOI 10.1126/science.aah4243
   Johnson MW, 2011, NATURE, V473, P194, DOI 10.1038/nature10012
   Kochenberger G, 2014, J COMB OPTIM, V28, P58, DOI 10.1007/s10878-014-9734-0
   Langley P., 1996, ELEMENTS MACHINE LEA
   Liu XY, 2022, COMPUT OPTIM APPL, V82, P1, DOI 10.1007/s10589-022-00354-2
   Liu XM, 2023, IEEE T IND ELECTRON, V70, P10902, DOI [10.1109/TQE.2021.3140190, 10.1109/TIE.2022.3225860, 10.1109/TVT.2022.3204310]
   Lucas A, 2014, FRONT PHYS-LAUSANNE, V2, DOI 10.3389/fphy.2014.00005
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   PARDALOS PM, 1994, J GLOBAL OPTIM, V4, P301, DOI 10.1007/BF01098364
   Hoffman RR, 2019, Arxiv, DOI [arXiv:1812.04608, DOI 10.48550/ARXIV.1812.04608]
   Ramage D., 2009, P 2009 C EMP METH NA, DOI DOI 10.3115/1699510.1699543
   Rosenfeld A., 2021, AAMAS 21 20 INT C AU, P45
   Sambaturu P, 2020, AAAI CONF ARTIF INTE, V34, P1636
   Schaller RR, 1997, IEEE SPECTRUM, V34, P52, DOI 10.1109/6.591665
   Shaydulin R., 2018, 3 INT WORKSHOP POSTM
   Shaydulin R, 2019, ADV QUANTUM TECHNOL, V2, DOI 10.1002/qute.201900029
   Shaydulin R, 2019, COMPUTER, V52, P18, DOI 10.1109/MC.2019.2908942
   Sybrandt J, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2757, DOI 10.1145/3340531.3412684
   Sybrandt J, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1633, DOI 10.1145/3097983.3098057
   Ushijima-Mwesigwa H, 2021, ACM T QUANTUM COMPUT, V2, DOI 10.1145/3425607
   Ushijima-Mwesigwa H, 2017, PROCEEDINGS OF 2ND INTERNATIONAL WORKSHOP ON POST MOORE'S ERA SUPERCOMPUTING (PMES 2017), P22, DOI 10.1145/3149526.3149531
   Wang HJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017243
NR 35
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 206
EP 215
DI 10.1109/ICDMW58026.2022.00036
UT WOS:000971492200027
DA 2023-11-16
ER

PT J
AU Liao, YM
   Yu, NM
   Tian, D
   Wang, C
   Li, SJ
   Li, ZP
AF Liao, Yumin
   Yu, Ningmei
   Tian, Dian
   Wang, Chen
   Li, Shuaijun
   Li, Zhengpeng
TI An Intelligent Low-Power Low-Cost Mobile Lab-On-Chip Yeast Cell Culture
   Platform
SO IEEE ACCESS
DT Article
DE Microfluidics; Batteries; Monitoring; Machine learning; Neural networks;
   Optimization; Power demand; Microfluidic channel; yeast culture;
   portable cell culture platform; intelligent; low-power; lab-on-chip
ID CAPILLARY-ELECTROPHORESIS; MICROFLUIDIC PLATFORM; EXPRESSION; PHENOTYPE;
   INTEGRATION; MICROCHIP
AB Cells are the fundamental unit of life activities, and the basis of studying life phenomena. It is very important to observe the growth state of yeast cells for exploring the law of life movement, diagnosis and treatment of diseases, drug screening and so on. This study proposes a kind of intelligent low-cost portable cell culture platform using the microfluidic channel and the special machine learning circuit. The platform can independently complete the whole work of living cell culture and monitoring. For realizing the reusable and low-power deep learning circuit, a complement optimization neural network algorithm for hardware optimization and corresponding multi-clock-domain reusable multi-level precision neural network accelerator circuit were proposed, which can reduce the circuit area and power of convolution operation in all precisions by average 18.11% and 23.5% respectively. Besides, a dynamic multi-level precision control method based on the battery level is proposed to dynamically adjust the precision of machine learning operation, in order to balance the working time and segmentation accuracy of the culture platform. In addition, a microcolumns-based three-port input microfluidic structure was designed for better yeast culture effect. The experiment showed that the culture platform can realize yeast cell culture and achieve almost the same segmentation accuracy as the large biological laboratory with low-power and low-cost. Compared with the previous work, the cost of mass production was reduced by 88.95%, and the equipment volume was 27.1% smaller. At the same time, it can achieve the best balance of working time and working accuracy under the condition of limited power of equipment according to the needs of users.
C1 [Liao, Yumin; Yu, Ningmei; Tian, Dian; Wang, Chen; Li, Shuaijun; Li, Zhengpeng] Xian Univ Technol, Sch Automat & Informat Engn, Xian 710000, Peoples R China.
RP Yu, NM (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, Xian 710000, Peoples R China.
EM yunm@xaut.edu.cn
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], 2016, ARXIV160305279
   [Anonymous], 2016, RISTRETTO HARDWARE O
   Applegate RW, 2006, LAB CHIP, V6, P422, DOI 10.1039/b512576f
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chiem N, 1997, ANAL CHEM, V69, P373, DOI 10.1021/ac9606620
   CHOWDHURY S, 1992, J CELL BIOL, V118, P561, DOI 10.1083/jcb.118.3.561
   Chuppa S, 1997, BIOTECHNOL BIOENG, V55, P328, DOI 10.1002/(SICI)1097-0290(19970720)55:2<328::AID-BIT10>3.0.CO;2-D
   Dannemiller K, 2015, INT CONF ELECTRO INF, P361, DOI 10.1109/EIT.2015.7293369
   Feizi A, 2016, LAB CHIP, V16, P4350, DOI 10.1039/c6lc00976j
   Göröcs Z, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0067-0
   Gourley PL, 2007, J BIOMED OPT, V12, DOI 10.1117/1.2799198
   Haab BB, 1999, ANAL CHEM, V71, P5137, DOI 10.1021/ac990644t
   Handfield LF, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003085
   Huang XW, 2015, IEEE DES TEST, V32, P32, DOI 10.1109/MDAT.2015.2424418
   Iyer VR, 2001, NATURE, V409, P533, DOI 10.1038/35054095
   Jung US, 1999, MOL MICROBIOL, V34, P1049, DOI 10.1046/j.1365-2958.1999.01667.x
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Li Nianzhen, 2003, Crit Rev Biomed Eng, V31, P423, DOI 10.1615/CritRevBiomedEng.v31.i56.20
   LORINCZ AT, 1984, NATURE, V307, P183, DOI 10.1038/307183a0
   Lu AX, 2019, BIOINFORMATICS, V35, P4525, DOI 10.1093/bioinformatics/btz402
   Marcoux N, 1998, MOL MICROBIOL, V29, P515, DOI 10.1046/j.1365-2958.1998.00944.x
   MUTOH E, 1995, J BACTERIOL, V177, P5383, DOI 10.1128/jb.177.18.5383-5386.1995
   Ng CL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040912
   Park TH, 2003, BIOTECHNOL PROGR, V19, P243, DOI 10.1021/bp020143k
   Price AK, 2004, ANAL CHEM, V76, P4849, DOI 10.1021/ac0495992
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rustici G, 2004, NAT GENET, V36, P809, DOI 10.1038/ng1377
   Schilling EA, 2002, ANAL CHEM, V74, P1798, DOI 10.1021/ac015640e
   Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taylor RJ, 2009, P NATL ACAD SCI USA, V106, P3758, DOI 10.1073/pnas.0813416106
   Tourovskaia A, 2005, LAB CHIP, V5, P14, DOI 10.1039/b405719h
   van der Putten P, 2007, PROC SPIE, V6506, DOI 10.1117/12.714072
   Vickerman V, 2008, LAB CHIP, V8, P1468, DOI 10.1039/b802395f
   Wang CC, 2011, LAB CHIP, V11, P695, DOI 10.1039/c0lc00155d
   Wang RY, 2019, EURASIP J ADV SIG PR, V2019, DOI 10.1186/s13634-019-0649-x
   Yang J, 1999, ANAL CHEM, V71, P911, DOI 10.1021/ac981250p
   Yang N., 2015, J ENG THERMOPHYS, V5, P1042
   Zabzdyr JL, 2001, TRAC-TREND ANAL CHEM, V20, P467, DOI 10.1016/S0165-9936(01)00051-6
NR 42
TC 5
Z9 6
U1 1
U2 16
PY 2020
VL 8
BP 70733
EP 70745
DI 10.1109/ACCESS.2020.2987206
UT WOS:000530809000003
DA 2023-11-16
ER

PT C
AU Gorgin, S
   Gholamrezaei, M
   Javaheri, D
   Lee, JA
AF Gorgin, Saeid
   Gholamrezaei, MohammadHosein
   Javaheri, Danial
   Lee, Jeong-A
GP IEEE
BE Sezer, S
   Buchner, T
   Becker, J
   Marshall, A
   Siddiqui, F
   Harbaum, T
   McLaughlin, K
TI <i>k</i>NN-MSDF: A Hardware Accelerator for <i>k</i>-Nearest Neighbors
   Using Most Significant Digit First Computation
SO 2022 IEEE 35TH INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (IEEE SOCC 2022)
SE IEEE International SOC Conference
DT Proceedings Paper
CT 35th IEEE International System-on-Chip Conference (SOCC)
CY SEP 05-08, 2022
CL Belfast, NORTH IRELAND
DE k-Nearest Neighbors; Most Significant Digit First; machine learning;
   early termination; FPGA
AB k-Nearest Neighbors (k-NN) is a well-established algorithm for classification widely used in various machine learning applications. Although k-NN has many advantages, it suffers severely from high latency and low throughput due to its computation-intensive nature. This paper suggests a novel, highly parallel approach based on Most Significant Digit First (MSDF) computing to accelerate k-NN algorithm where the Euclidean distance is used as the distance metric. The proposed method consists of three phases; in the first phase, subtract, and square functions are done on serially coming input data and provide the Most Significant Digit (MSD) of the distances. Then, the processed serially MSDF data are sorted, and finally, the label of test data is determined by majority voting. Having the value of MSD in advance provides the possibility of early termination of unnecessary computations. This approach leads to significantly higher performance and lower power consumption. Moreover, serial computation causes a lower area and memory footprint that paves the way to take advantage of the maximum number of parallel processing elements. The experimental results on an SoC platform indicate up to 88.3% improvement in terms of performance and energy consumption compared to the best previous designs.
C1 [Gorgin, Saeid; Gholamrezaei, MohammadHosein; Javaheri, Danial; Lee, Jeong-A] Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
RP Gorgin, S (corresponding author), Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
EM gorgin@chosun.ac.kr; gholamrezaei@chosun.kr; javaheri@chosun.ac.kr;
   jalee@chosun.ac.kr
CR Ahmadzadeh Armin, 2014, 2014 Twelfth ACM/IEEE Conference on Formal Methods and Models for Codesign (MEMOCODE), P205, DOI 10.1109/MEMCOD.2014.6961863
   Ali M, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113374
   Avizienis A, 1961, IRE T ELECT COMPUTER, VEC-10, P389
   Boutros A, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242898
   Chen YW, 2019, INFORM SCIENCES, V472, P145, DOI 10.1016/j.ins.2018.09.012
   Duarte Javier, 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0027-2
   Ercegovac M.D., 2004, DIGITAL ARITHMETIC
   Ercegovac MD, 2020, CONF REC ASILOMAR C, P524, DOI 10.1109/IEEECONF51394.2020.9443576
   Ercegovac MD, 2017, CONF REC ASILOMAR C, P750, DOI 10.1109/ACSSC.2017.8335445
   Gao X, 2020, IEEE ACCESS, V8, P112922, DOI 10.1109/ACCESS.2020.3003086
   Gavahi M., 2015, 2015 INT S COMPUTER, P1, DOI [10.1109/CSICSSE.2015.7369240, DOI 10.1109/CSICSSE.2015.7369240]
   Jaberipur G, 2005, IEEE T CIRCUITS-I, V52, P1348, DOI 10.1109/TCSI.2005.851679
   Jamma D, 2017, INT C MICROELECTRON, P330
   Javaheri D, 2021, IEEE ACCESS, V9, P69951, DOI 10.1109/ACCESS.2021.3077295
   Lu A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P139, DOI 10.1109/ICFPT51103.2020.00027
   Saidi A, 2021, INTEGRATION, V81, P280, DOI 10.1016/j.vlsi.2021.08.004
   Uribe-Hurtado AL, 2020, COMPUT IND, V122, DOI 10.1016/j.compind.2020.103260
   Vieira J, 2019, IEEE ACCESS, V7, P170864, DOI 10.1109/ACCESS.2019.2955864
   Moreno JV, 2012, IEEE T COMPUT, V61, P790, DOI 10.1109/TC.2011.97
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Younes H, 2021, IEEE OPEN J CIRCUITS, V2, P534, DOI [10.1109/OJCAS.2021.3108835, 10.1109/OJCAS.20213108835]
   Zhang F, 2019, IEEE T IND INFORM, V15, P4362, DOI 10.1109/TII.2019.2891261
   Zhao Y, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P69, DOI 10.1109/FPT.2016.7929191
NR 23
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 65
EP 70
DI 10.1109/SOCC56010.2022.9908102
UT WOS:000885041700014
DA 2023-11-16
ER

PT C
AU Rahman, A
   Lee, J
   Choi, K
AF Rahman, Atul
   Lee, Jongeun
   Choi, Kiyoung
GP IEEE
TI Efficient FPGA Acceleration of Convolutional Neural Networks Using
   Logical-3D Compute Array
SO PROCEEDINGS OF THE 2016 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 14-18, 2016
CL Dresden, GERMANY
ID COPROCESSOR
AB Convolutional Deep Neural Networks (DNNs) are reported to show outstanding recognition performance in many image-related machine learning tasks. DNNs have a very high computational requirement, making accelerators a very attractive option. These DNNs have many convolutional layers with different parameters in terms of input/output/kernel sizes as well as input stride. Design constraints usually require a single design for all layers of a given DNN. Thus a key challenge is how to design a common architecture that can perform well for all convolutional layers of a DNN, which can be quite diverse and complex. In this paper we present a flexible yet highly efficient 3D neuron array architecture that is a natural fit for convolutional layers. We also present our technique to optimize its parameters including onchip buffer sizes for a given set of resource constraint for modern FPGAs. Our experimental results targeting a Virtex-7 FPGA demonstrate that our proposed technique can generate DNN accelerators that can outperform the state-of-the-art solutions, by 22% for 32-bit floating-point MAC implementations, and are far more scalable in terms of compute resources and DNN size.
C1 [Rahman, Atul; Lee, Jongeun] UNIST Ulsan Natl Inst Sci & Technol, Ulsan, South Korea.
   [Choi, Kiyoung] Seoul Natl Univ, Seoul, South Korea.
RP Lee, J (corresponding author), UNIST Ulsan Natl Inst Sci & Technol, Ulsan, South Korea.
EM jlee@unist.ac.kr
CR [Anonymous], 2011, P 22 INT JOINT C ART
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Zhang C, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P161, DOI 10.1109/SPAWDA.2015.7364463
NR 8
TC 70
Z9 83
U1 0
U2 12
PY 2016
BP 1393
EP 1398
UT WOS:000382679200256
DA 2023-11-16
ER

PT J
AU Kim, SH
   Shin, SG
   Han, S
   Kim, MH
   Pyeon, CH
AF Kim, Song Hyun
   Shin, Sung Gyun
   Han, Sangsoo
   Kim, Moo Hwan
   Pyeon, Cheol Ho
TI Feasibility study on application of an artificial neural network for
   automatic design of a reactor core at the Kyoto University Critical
   Assembly
SO PROGRESS IN NUCLEAR ENERGY
DT Article
DE KUCA; Artificial neural network; Reactor core design; Research reactor;
   Optimization
ID ACCELERATOR-DRIVEN SYSTEM; NEUTRON SOURCE; PROTONS; RATES
AB Designing reactor cores by means of an artificial neural network is a difficult challenge, because there are many variables in the core configuration. Especially, for designing a new type of reactor core with an artificial neural network, little (if any) previous data exists, and the appropriate number of results, such as multiplication factors and neutron fluxes, which require a large computational time for a single calculation, should be previously obtained for training the machine learning of the artificial neural network. This paper presents a feasibility study on the automatic design of a research reactor core (a simplified core based on the Kyoto University Critical Assembly) using an artificial neural network. By imitating conventional design procedure, a way to design the core is developed by means of the artificial neural network and automatic machine learning. After setting a design goal of the reactor core, the fuel assembly and core are designed by the proposed method and compared with those designed by conventional design procedure. The results reveal that the reactor core designed by the proposed method performs well and will, therefore, provide a clue to innovation in future reactor design with artificial intelligence.
C1 [Kim, Song Hyun; Shin, Sung Gyun; Han, Sangsoo; Kim, Moo Hwan] Pohang Univ Sci & Technol, Div Adv Nucl Engn, Pohang 37673, South Korea.
   [Pyeon, Cheol Ho] Kyoto Univ, Res Reactor Inst, Nucl Engn Sci Div, Kumatori, Osaka 5900494, Japan.
RP Kim, SH (corresponding author), Pohang Univ Sci & Technol, Div Adv Nucl Engn, Pohang 37673, South Korea.
EM songhyunkim@postech.ac.kr; shinsg@postech.ac.kr;
   sshan1214@postech.ac.kr; mhkim@postech.ac.kr; pyeon@rri.kyoto-u.ac.jp
CR Bryson A.E., 1969, APPL OPTICAL CONTROL
   Filho L.P., 2013, 2013 INT NUCL ATL C
   Gencel O, 2009, INT J PHYS SCI, V4, P743
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Kim S.H., 2018, T KOR NUCL SOC SPRIN
   Kim SH, 2017, ENRGY PROCED, V131, P77, DOI 10.1016/j.egypro.2017.09.478
   Kim SH, 2018, ANN NUCL ENERGY, V112, P337, DOI 10.1016/j.anucene.2017.10.030
   Kim SH, 2017, PROG NUCL ENERG, V100, P60, DOI 10.1016/j.pnucene.2017.05.029
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Montes J.L., 2007, JOINT INT TOP M MATH
   Nozaki N, 2017, FUJITSU SCI TECH J, V53, P43
   Pelowitz Denise B, 2013, MCNP6 USERS MANUAL V
   Persson CM, 2008, ANN NUCL ENERGY, V35, P2357, DOI 10.1016/j.anucene.2008.07.011
   Poteralski A, 2016, IOP CONF SER-MAT SCI, V161, DOI 10.1088/1757-899X/161/1/012040
   Pyeon CH, 2016, J NUCL SCI TECHNOL, V53, P602, DOI 10.1080/00223131.2015.1068716
   Pyeon CH, 2015, NUCL TECHNOL, V192, P181, DOI 10.13182/NT14-111
   Pyeon CH, 2012, ANN NUCL ENERGY, V40, P229, DOI 10.1016/j.anucene.2011.10.011
   Pyeon CH, 2009, J NUCL SCI TECHNOL, V46, P1091, DOI 10.3327/jnst.46.1091
   Ueki T., 2002, Transactions of the American Nuclear Society, V87, P156
   Yamanaka M, 2016, NUCL SCI ENG, V183, P96, DOI 10.13182/NSE15-51
   Ziver A.K., 2002, USE ARTIFICIAL NEURA, V2002
NR 21
TC 2
Z9 2
U1 0
U2 8
PD JAN
PY 2020
VL 119
AR 103183
DI 10.1016/j.pnucene.2019.103183
UT WOS:000508745700030
DA 2023-11-16
ER

PT C
AU Bogdan, P
   Chen, F
   Deshwal, A
   Doppa, JR
   Joardar, BK
   Li, H
   Nazarian, S
   Song, LH
   Xiao, Y
AF Bogdan, Paul
   Chen, Fan
   Deshwal, Aryan
   Doppa, Janardhan Rao
   Joardar, Biresh Kumar
   Li, Hai (Helen)
   Nazarian, Shahin
   Song, Linghao
   Xiao, Yao
GP ACM
TI Taming Extreme Heterogeneity via Machine Learning based Design of
   Autonomous Manycore Systems Special Session Paper
SO INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURE, AND SYNTHESIS FOR
   EMBEDDED SYSTEMS (CODES +ISSS) 2019
SE International Conference on Compilers Architecture and Synthesis for
   Embedded Systems
DT Proceedings Paper
CT Embedded Systems Week / Int Conf on Compilers, Architecture, and
   Synthesis for Embedded Systems (CASES) / International Conference on
   Hardware/Software Codesign and System Synthesis (CODES+ISSS) / Int Conf
   on Embedded Software (EMSOFT)
CY OCT 13-18, 2019
CL New York City, NY
DE Model of computation; self-programming computing architectures; manycore
   systems; machine learning; ReRAM; processing-in-memory; autonomous
   design optimization
ID ENERGY-EFFICIENT; SELF-AWARENESS; OPTIMIZATION; ACCELERATOR; ALGORITHM
AB To avoid rewriting software code for new computer architectures and to take advantage of the extreme heterogeneous processing, communication and storage technologies, there is an urgent need for determining the right amount and type of specialization while making a heterogeneous system as programmable and flexible as possible. To enable both programmability and flexibility in the heterogeneous computing era, we propose a novel complex network inspired model of computation and efficient optimization algorithms for determining the optimal degree of parallelization from old software code. This mathematical framework allows us to determine the required number and type of processing elements, the amount and type of deep memory hierarchy, and the degree of reconfiguration for the communication infrastructure, thus opening new avenues to performance and energy efficiency. Our framework enables heterogeneous manycore systems to autonomously adapt from traditional switching techniques to network coding strategies in order to sustain on-chip communication in the order of terabytes. While this new programming model enables the design of self-programmable autonomous heterogeneous manycore systems, a number of open challenges will be discussed.
C1 [Bogdan, Paul; Nazarian, Shahin; Xiao, Yao] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Deshwal, Aryan; Doppa, Janardhan Rao; Joardar, Biresh Kumar] Washington State Univ, Pullman, WA 99164 USA.
   [Chen, Fan; Li, Hai (Helen); Song, Linghao] Duke Univ, Durham, NC 27706 USA.
RP Bogdan, P (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM pbogdan@usc.edu; fan.chen@duke.edu; aryan.deshwal@wsu.edu;
   jana.doppa@wsu.edu; biresh.joardar@wsu.edu; hai.li@duke.edu;
   shahin@usc.edu; ls334@duke.edu; xiaoyao@usc.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], 2016, 2016 IEEE GLOB COMM
   Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Bandyopadhyay S, 2008, IEEE T EVOLUT COMPUT, V12, P269, DOI 10.1109/TEVC.2007.900837
   CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898
   Chen F, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240805
   Chen F, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317936
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Das S, 2017, PR IEEE COMP DESIGN, P233, DOI 10.1109/ICCD.2017.43
   Das S, 2017, IEEE T COMPUT AID D, V36, P719, DOI 10.1109/TCAD.2016.2604288
   Das S, 2015, ICCAD-IEEE ACM INT, P705, DOI 10.1109/ICCAD.2015.7372639
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deshwal A, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358206
   Dutt N, 2016, ACM T EMBED COMPUT S, V15, DOI 10.1145/2872936
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Greer M, 2019, IEEE INT SYMP CIRC S
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Jantsch A, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2017.2757143
   Joardar BK, 2019, DES AUT TEST EUROPE, P138, DOI [10.23919/date.2019.8714832, 10.23919/DATE.2019.8714832]
   Joardar BK, 2019, DES AUT TEST EUROPE, P522, DOI [10.23919/date.2019.8714802, 10.23919/DATE.2019.8714802]
   Joardar BK, 2019, IEEE T COMPUT, V68, P852, DOI 10.1109/TC.2018.2889053
   Joardar Biresh Kumar, 2018, P INT C COMP AID DES, DOI [10.1145/3240765.3243480, DOI 10.1145/3240765.3243480]
   Kanev S, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P158, DOI 10.1145/2749469.2750392
   Kim RG, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243483
   Kim RG, 2018, COMPUTER, V51, P66, DOI 10.1109/MC.2018.3011040
   Kim RG, 2017, IEEE T VLSI SYST, V25, P2458, DOI 10.1109/TVLSI.2017.2700726
   Krizhevsky A., 2014, ABS14045997 CORR
   Kumar V., 2002, INTRO PARALLEL COMPU
   Lee D, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3357158
   Lee D, 2018, ACM T DES AUTOMAT EL, V23, DOI 10.1145/3223046
   Li M., 2014, ADV NEURAL INFORM PR, P19
   Liu XX, 2015, DES AUT CON, DOI 10.1145/2744769.2744900
   Lukasiewycz M, 2007, IEEE C EVOL COMPUTAT, P935, DOI 10.1109/CEC.2007.4424570
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Pandiyan D, 2014, I S WORKL CHAR PROC, P171, DOI 10.1109/IISWC.2014.6983056
   Panerati J., 2017, HDB HARDWARESOFTWARE, P189, DOI 10.1007/978-94-017-7267-97
   Preden JS, 2015, COMPUTER, V48, P37, DOI 10.1109/MC.2015.207
   Rabenseifner R, 2009, EUROMICRO WORKSHOP P, P427, DOI [10.1109/.42, 10.1109/PDP.2009.43]
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sia J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46079-x
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Xiao Y, 2017, ICCAD-IEEE ACM INT, P217, DOI 10.1109/ICCAD.2017.8203781
   Xiao Y, 2019, IEEE T VLSI SYST, V27, P1416, DOI 10.1109/TVLSI.2019.2897650
   Xiao Y, 2018, DES AUT TEST EUROPE, P1387, DOI 10.23919/DATE.2018.8342229
   Xue Y., 2015, P PCIM EUR 2015 INT, P1
   Xue YK, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09774-x
   Xue YK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07209-5
   Xue YK, 2017, ACM T DES AUTOMAT EL, V22, DOI 10.1145/3001934
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
NR 63
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1145/3349567.3357376
UT WOS:000693947700020
DA 2023-11-16
ER

PT C
AU Zhang, XY
   Bashizade, R
   LaBoda, C
   Dwyer, C
   Lebeck, AR
AF Zhang, Xiangyu
   Bashizade, Ramin
   LaBoda, Craig
   Dwyer, Chris
   Lebeck, Alvin R.
GP IEEE
TI Architecting a Stochastic Computing Unit with Molecular Optical Devices
SO 2018 ACM/IEEE 45TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 45th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 01-06, 2018
CL Los Angeles, CA
DE accelerator; machine learning; Bayesian Inference; Markov Chain Monte
   Carlo; Markov Random Field; emerging technology; Resonance Energy
   Transfer
ID IMAGE SENSOR; SEGMENTATION; NETWORK
AB The increasing difficulty in leveraging CMOS scaling for improved performance requires exploring alternative technologies. A promising technique is to exploit the physical properties of devices to specialize certain computations. A recently proposed approach uses molecular-scale optical devices to construct a Resonance Energy based Sampling Unit (RSU) to accelerate sampling from parameterized probability distributions. Sampling is an important component of many algorithms, including statistical machine learning.
   This paper explores the relationship between application result quality and RSU design. The previously proposed RSU-G focuses on Gibbs sampling using Markov Chain Monte Carlo (MCMC) solvers for Markov Random Field (MRF) Bayesian Inference. By quantitatively analyzing the result quality across three computer vision applications, we find that the previously proposed RSU-G lacks both sufficient precision and dynamic range in key design parameters, which limits the overall result quality compared to software-only MCMC implementations. Naively scaling the problematic parameters to increase precision and dynamic range consumes too much area and power. Therefore, we introduce a new RSU-G microarchitecture that exploits an alternative approach to increase precision that incurs 1.27 x power and equivalent area, while maintaining the significant speedups of the previous design and supporting a wider set of applications.
C1 [Zhang, Xiangyu; Bashizade, Ramin; LaBoda, Craig; Lebeck, Alvin R.] Duke Univ, Durham, NC 27706 USA.
   [Dwyer, Chris] Parabon Labs, Reston, VA USA.
RP Zhang, XY (corresponding author), Duke Univ, Durham, NC 27706 USA.
EM xiangyu.zhang@duke.edu; ramin.bashizade@duke.edu; craig.laboda@duke.edu;
   cdwyer@gmail.com; alvy@cs.duke.edu
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   [Anonymous], HP LAB
   [Anonymous], 1994, MARKOV RANDOM FIELD
   [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], INT DIG RAND NUMB GE
   [Anonymous], IPSJ SIG NOTES
   [Anonymous], 2009, THESIS
   [Anonymous], 2014, ARXIV14024914
   [Anonymous], 2016, ACM COMPUT SURV, DOI DOI 10.1145/2893356
   [Anonymous], 2012, MACHINE LEARNING PRO
   Aono M, 2013, LANGMUIR, V29, P7557, DOI 10.1021/la400301p
   Assefa S, 2010, NATURE, V464, P80, DOI 10.1038/nature08813
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chakrapani LN, 2006, DES AUT TEST EUROPE, P1110
   Chang-Yen DA, 2003, LAB CHIP, V3, P297, DOI 10.1039/b305358j
   Chen RL, 2012, IEEE T CIRCUITS-II, V59, P746, DOI 10.1109/TCSII.2012.2220696
   Cheng L, 2007, COMPUT VIS IMAGE UND, V106, P85, DOI 10.1016/j.cviu.2005.09.009
   Devroye L, 2006, HBK OPERAT RES MANAG, V13, P83, DOI 10.1016/S0927-0507(06)13004-2
   Field RM, 2014, IEEE J SOLID-ST CIRC, V49, P867, DOI 10.1109/JSSC.2013.2293777
   Grivas C, 2012, LASER PHOTONICS REV, V6, P419, DOI 10.1002/lpor.201100034
   Hill MT, 2014, NAT PHOTONICS, V8, P908, DOI 10.1038/nphoton.2014.239
   Ismail YI, 2000, IEEE T VLSI SYST, V8, P195, DOI 10.1109/92.831439
   Joshi A, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P124, DOI 10.1109/NOCS.2009.5071460
   Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074
   Khasanvis S, 2015, COMPUTER, V48, P54, DOI 10.1109/MC.2015.367
   Khasanvis S, 2015, IEEE T NANOTECHNOL, V14, P980, DOI 10.1109/TNANO.2015.2439618
   KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350
   LaBoda C, 2014, ACCOUNTS CHEM RES, V47, P1816, DOI 10.1021/ar500054u
   Liu Chenchen, 2015, 2015 52 ACMEDACIEEE, P1
   Luan L, 2008, IEEE SENS J, V8, P628, DOI 10.1109/JSEN.2008.918717
   Luan L, 2012, IEEE SENS J, V12, P1794, DOI 10.1109/JSEN.2011.2179027
   Mandai S, 2012, OPT EXPRESS, V20, P5849, DOI 10.1364/OE.20.005849
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Mitzenmacher M., 2005, PROBABILITY COMPUTIN
   Naruse M, 2013, IEICE T COMMUN, VE96B, P2724, DOI 10.1587/transcom.E96.B.2724
   Niclass C, 2005, IEEE J SOLID-ST CIRC, V40, P1847, DOI 10.1109/JSSC.2005.848173
   Niclass C, 2008, IEEE J SOLID-ST CIRC, V43, P2977, DOI 10.1109/JSSC.2008.2006445
   Ow H, 2005, NANO LETT, V5, P113, DOI 10.1012/nl0482478
   Palem KV, 2005, IEEE T COMPUT, V54, P1123, DOI 10.1109/TC.2005.145
   Palubiak D, 2011, IEEE SENS J, V11, P2401, DOI 10.1109/JSEN.2011.2123090
   Pan Y., 2010, HPCA 16 2010 16 INT, P1
   Pang J, 2015, ACM SIGPLAN NOTICES, V50, P283, DOI 10.1145/2694344.2694377
   Pistol C, 2007, NANOTECHNOLOGY, V18, DOI 10.1088/0957-4484/18/12/125305
   Pistol C, 2010, IEEE MICRO, V30, P110, DOI 10.1109/MM.2010.9
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shambat G, 2012, IEEE J SEL TOP QUANT, V18, P1700, DOI 10.1109/JSTQE.2012.2193666
   Song T, 2014, ISSCC DIG TECH PAP I, V57, P232, DOI 10.1109/ISSCC.2014.6757413
   Stipcevic M, 2014, OPEN PROBLEMS MATH C, P275
   Szirányi T, 2000, REAL-TIME IMAGING, V6, P195, DOI 10.1006/rtim.1998.0159
   Valeur B., 2013, MOL FLUORESCENCE PRI
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Wang SY, 2015, IEEE MICRO, V35, P72, DOI 10.1109/MM.2015.124
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
NR 58
TC 5
Z9 5
U1 0
U2 0
PY 2018
BP 301
EP 314
DI 10.1109/ISCA.2018.00034
UT WOS:000458810500023
DA 2023-11-16
ER

PT C
AU Metz, CA
   Goli, M
   Drechsler, R
AF Metz, Christopher A.
   Goli, Mehran
   Drechsler, Rolf
BE Kubatova, H
   Steininger, A
   Jenihhin, M
   Garbolino, T
   Fiser, P
   Belohoubek, J
   Borecky, J
TI ML-based Power Estimation of Convolutional Neural Networks on GPGPUs
SO 2022 25TH INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS AND SYSTEMS (DDECS)
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 25th International Symposium on Design and Diagnostics of Electronic
   Circuits and Systems (DDECS)
CY APR 06-08, 2022
CL Prague, CZECH REPUBLIC
ID MODEL
AB The increasing application of Machine Learning (ML) techniques on the Internet of Things (IoTs) has led to the leverage of ML accelerators like General Purpose Computing on Graphics Processing Units (GPGPUs) in such devices. However, selecting the most appropriate accelerator for IoT devices is very challenging as they commonly have tight constraints e.g., low power consumption, latency, and cost of the final product. Hence, the design of such application-specific IoT devices becomes a time-consuming and effort-hungry process, that poses the need for accurate and effective automated assisting methods.
   In this paper, we present a novel approach to estimate the power consumption of CUDA-based Convolutional Neural Networks (CNNs) on GPGPUs in the early design phases. The proposed approach takes advantage of a hybrid technique where static analysis is used for features extraction and the K-Nearest Neighbor (K-NN) regression analysis is utilized for power estimation model generation. Using K-NN analysis, the power estimation model can even be created with small training datasets. Experimental results demonstrate that the proposed approach is able to predict CNNs power consumption up to a Absolute Percentage Error of 0.0003% in comparison to the real hardware.
C1 [Metz, Christopher A.; Goli, Mehran; Drechsler, Rolf] Univ Bremen, Inst Comp Sci, D-28359 Bremen, Germany.
   [Goli, Mehran; Drechsler, Rolf] DFKI GmbH, Cyber Phys Syst, D-28359 Bremen, Germany.
RP Metz, CA (corresponding author), Univ Bremen, Inst Comp Sci, D-28359 Bremen, Germany.
EM cmetz@uni-bremen.de; mehran@uni-bremen.de; drechsler@uni-bremen.de
CR [Anonymous], 2017, NVIDIA TESLA V100 GP
   Arafa Y, 2019, IEEE COMPUT ARCHIT L, V18, P55, DOI 10.1109/LCA.2019.2904497
   Ardalani N, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P725, DOI 10.1145/2830772.2830780
   Baldini Ioana, 2014, 2014 IEEE 26th International Symposium on Computer Architecture and High-Performance Computing (SBAC-PAD), P254, DOI 10.1109/SBAC-PAD.2014.30
   Braun L, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3431731
   Busia P, 2021, IEEE ACCESS, V9, P133289, DOI 10.1109/ACCESS.2021.3115243
   Carroll TC, 2017, INT CONF PARA PROC, P113, DOI 10.1109/ICPPW.2017.28
   Chen J., 2011, P 2011 INT GREEN COM, P1, DOI 10.1109/IGCC.2011.6008582
   Cui LZ, 2018, INT J MACH LEARN CYB, V9, P1399, DOI 10.1007/s13042-018-0834-5
   Djenouri Y, 2021, IEEE T IND INFORM, V17, P2947, DOI 10.1109/TII.2020.3001493
   Fingeroff M, MACHINE LEARNING EDG
   Goli M, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3388140
   Goli M, 2018, P IEEE RAP SYST PROT, P97, DOI 10.1109/RSP.2018.8631997
   Guerreiro J, 2019, IEEE T PARALL DISTR, V30, P2494, DOI 10.1109/TPDS.2019.2917181
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Imandoust Sadegh Bafandeh, 2013, THEORETICAL BACKGROU, V3, P605, DOI DOI 10.1016/J.JTBI.2009.08.004
   Lechner M., 2021, IEEE ACCESS
   Metz C. A., 2021, ARXIV
   Metz CA, 2021, 2021 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS 2021), P29, DOI 10.1145/3478684.3479255
   Nagasaka H., 2010, 2010 International Conference on Green Computing (Green Comp), P115, DOI 10.1109/GREENCOMP.2010.5598315
   Nvidia, NVID TUR GPU ARCH
   nvidia, CUDA TOOLK DOC
   Qiang Wang, 2017, ACM SIGMETRICS Performance Evaluation Review, V45, P73, DOI 10.1145/3152042.3152066
   Song SW, 2013, INT PARALL DISTRIB P, P673, DOI 10.1109/IPDPS.2013.73
   Tensorflow, TENS GPU
   Wang Q, 2020, IEEE T PARALL DISTR, V31, P2865, DOI 10.1109/TPDS.2020.3004623
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
NR 27
TC 2
Z9 2
U1 0
U2 1
PY 2022
BP 166
EP 171
UT WOS:000835725500029
DA 2023-11-16
ER

PT C
AU Li, HM
   Fan, XT
   Jiao, L
   Cao, W
   Zhou, XG
   Wang, LL
AF Li, Huimin
   Fan, Xitian
   Jiao, Li
   Cao, Wei
   Zhou, Xuegong
   Wang, Lingli
GP IEEE
TI A High Performance FPGA-based Accelerator for Large-Scale Convolutional
   Neural Networks
SO 2016 26TH INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 26th International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2016
CL Ecole Polytechnique Federale de Lausanne, Lausanne, SWITZERLAND
HO Ecole Polytechnique Federale de Lausanne
DE convolutional neural networks; pipeline; AlexNet; parallelism; memory
   bandwidth
ID COPROCESSOR
AB In recent years, convolutional neural networks (CNNs) based machine learning algorithms have been widely applied in computer vision applications. However, for large-scale CNNs, the computation-intensive, memory-intensive and resource-consuming features have brought many challenges to CNN implementations. This work proposes an end-to-end FPGA-based CNN accelerator with all the layers mapped on one chip so that different layers can work concurrently in a pipelined structure to increase the throughput. A methodology which can find the optimized parallelism strategy for each layer is proposed to achieve high throughput and high resource utilization. In addition, a batch-based computing method is implemented and applied on fully connected layers (FC layers) to increase the memory bandwidth utilization due to the memory-intensive feature. Further, by applying two different computing patterns on FC layers, the required on-chip buffers can be reduced significantly. As a case study, a state-of-the-art large-scale CNN, AlexNet, is implemented on Xilinx VC709. It can achieve a peak performance of 565.94 GOP/s and 391 FPS under 156MHz clock frequency which outperforms previous approaches.
C1 [Li, Huimin; Fan, Xitian; Jiao, Li; Cao, Wei; Zhou, Xuegong; Wang, Lingli] Fudan Univ, State Key Lab ASIC & Syst, Shanghai, Peoples R China.
RP Cao, W (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai, Peoples R China.
EM caow@fudan.edu.cn
CR Abdel-Hamid O., 2014, AUDIO SPEECH LANGUAG
   [Anonymous], 2015, ARXIV150202551
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], P IEEE
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Du Z., 2015, ACM INT S COMP ARCH
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qiu J., 2016, ACM INT S FIELD PROG
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Simonyan K., 2014, EPRINT ARXIV
   Suda N., 2016, ACM INT S FIELD PROG
   Sun Y., 2014, NEURIPS, P1988
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 23
TC 132
Z9 149
U1 3
U2 30
PY 2016
DI 10.1109/FPL.2016.7577308
UT WOS:000386610400010
DA 2023-11-16
ER

PT J
AU De, SYD
   Shafique, M
   Corporaal, H
AF De, Sayandip
   Shafique, Muhammad
   Corporaal, Henk
TI Delay Prediction for ASIC HLS: Comparing Graph-Based and Nongraph-Based
   Learning Models
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Delay timing prediction; electronic design automation (EDA); graph
   neural networks; high-level synthesis (HLS); logic synthesis (LS);
   machine learning (ML)
ID NEURAL-NETWORKS
AB While high-level synthesis (HLS) tools offer faster design of hardware accelerators with different area versus delay tradeoffs, HLS-based delay estimates often deviate significantly from results obtained from ASIC logic synthesis (LS) tools. Current HLS tools rely on simple additive delay models which fail to capture the downstream optimizations performed during LS and technology mapping. Inaccurate delay estimates prevent fast and accurate design-space exploration without performing timeconsuming LS tasks. In this work, we exploit different machine learning models which automatically learn to map the different downstream optimizations onto the HLS critical paths. In particular, we compare graph-based and nongraph-based learning models to investigate their efficacy, devise hybrid models to get the best of the both worlds. To carry out our learning-assisted methodology, we create a dataset of different HLS benchmarks and develop an automated framework, which extends a commercial HLS toolchain, to extract essential information from LS critical path and automatically matches this information to HLS path. This is a nontrivial task to perform manually due to difference in level of abstractions. Finally, we train the proposed hybrid models through inductive learning and integrate them in the commercial HLS toolchain to improve delay prediction accuracy. Experimental results demonstrate significant improvements in delay estimation accuracy across a wide variety of benchmark designs. We demonstrate that the graph-based models can infer essential structural features from the input design, while incorporating them into traditional nongraph-based models can significantly improve the model accuracy. Such "hybrid" models can improve delay prediction accuracy by 93% compared to simple additive models and provide 175x speedup compared to LS. Furthermore, we discuss key insights from our experiments, identifying the influence of different HLS features on model performance.
C1 [De, Sayandip; Corporaal, Henk] Eindhoven Univ Technol, Dept Elect Engn, NL-5600 MB Eindhoven, Netherlands.
   [Shafique, Muhammad] New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
RP De, SYD (corresponding author), Eindhoven Univ Technol, Dept Elect Engn, NL-5600 MB Eindhoven, Netherlands.
EM sayandip.de@tue.nl; muhammad.shafique@nyu.edu; h.corporaal@tue.nl
CR Alawieh Mohamed Baker, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P26, DOI 10.1109/ASP-DAC47756.2020.9045178
   [Anonymous], 2011, JMLR, V12, P2825
   cadence, GEN SYNTH SOL
   cadence, STRAT HIGH LEV SYNTH
   Cong J, 2006, DES AUT CON, P433, DOI 10.1109/DAC.2006.229228
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Licht JD, 2021, IEEE T PARALL DISTR, V32, P1014, DOI 10.1109/TPDS.2020.3039409
   Ellouz S, 2006, INT TEST CONF P, P123
   Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, DOI 10.48550/ARXIV.1903.02428]
   Haaswijk W, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351885
   Hamilton W., 2017, P ADV NEURAL INFORM, P1024
   Hastie T., 2009, ELEMENTS STAT LEARNI
   He ZL, 2020, PR IEEE COMP DESIGN, P324, DOI 10.1109/ICCD50377.2020.00061
   Hosny Abdelrahman, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P581, DOI 10.1109/ASP-DAC47756.2020.9045559
   Huang GY, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3451179
   Jiang DJ, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-020-00479-8
   Katz Y, 2011, DES AUT CON, P848
   Liu ZX, 2019, 2019 34RD YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P1, DOI [10.1109/YAC.2019.8787629, 10.1109/yac.2019.8787629, 10.1109/ldia.2019.8770977]
   Lu Y, 2019, INT C INDOOR POSIT, DOI 10.1109/ipin.2019.8911785
   Lundberg SM, 2017, ADV NEUR IN, V30
   Maarouf D, 2018, I C FIELD PROG LOGIC, P427, DOI 10.1109/FPL.2018.00079
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   Mantovani P, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415753
   Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Neto WL, 2019, ICCAD-IEEE ACM INT
   networkx, NETW AN PYTH
   stanford, DEEPSN
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Thost Veronika, 2021, INT C LEARN REPR
   Ustun E, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415657
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Velickovic P., 2018, GRAPH ATTENTION NETW, P1
   Wang FC, 2018, PR GR LAK SYMP VLSI, P207, DOI 10.1145/3194554.3194561
   Welling M., 2016, P INT C LEARN REPR
   Wu N., 2021, P 2021 GREAT LAK S V, P39, DOI DOI 10.1145/3453688.3461495
   [谢志鹏 Xie Zhipeng], 2018, [高分子通报, Polymer Bulletin], P1
   xilinx, XIL VIV DES SUIT
   Yu CX, 2018, DES AUT CON, DOI 10.1145/3195970.3196026
NR 39
TC 2
Z9 2
U1 1
U2 1
PD APR
PY 2023
VL 42
IS 4
BP 1133
EP 1146
DI 10.1109/TCAD.2022.3197977
UT WOS:001006891800009
DA 2023-11-16
ER

PT C
AU Panchbhaiyye, V
   Ogunfunmi, T
AF Panchbhaiyye, Vineet
   Ogunfunmi, Tokunbo
GP IEEE
TI A FIFO BASED ACCELERATOR FOR CONVOLUTIONAL NEURAL NETWORKS
SO 2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
DT Proceedings Paper
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 04-08, 2020
CL Barcelona, SPAIN
DE Convolution Neural Networks; FPGA; Dataflow Processing; Hardware
   Implementation; Machine Learning
AB In recent years, Deep Neural Networks (DNNs) have achieved state-of-the-art results in various fields like Computer Vision, Natural Language Processing and Speech Recognition. Of all the DNN architectures, Convolutional Neural Networks (CNNs) have been most effective in tasks like image classification and object detection. The high performance of the CNNs comes at the cost of computational complexity. Currently Graphics Processing Units (GPUs) are used to accelerate CNN training and inference on workstations and data servers. Though popular, GPUs are not suitable for embedded applications because they are not energy efficient. ASIC and FPGA accelerators have the potential to run CNNs that are optimized for energy and performance.
   In this paper we present an architecture which takes a novel approach to compute convolution results using row-wise inputs as opposed to traditional tile-based processing. We are able to exceed the results of state of the art architectures when implemented on an inexpensive PYNQ Z1 board running at 100Mhz. The total latency to run the convolution layers in the VGG16 benchmark is nearly 1.5x lower for our architecture than state of the art architectures.
C1 [Panchbhaiyye, Vineet; Ogunfunmi, Tokunbo] Santa Clara Univ, Dept Elect Engn, Santa Clara, CA 95053 USA.
RP Panchbhaiyye, V (corresponding author), Santa Clara Univ, Dept Elect Engn, Santa Clara, CA 95053 USA.
CR Ansari A, 2017, CONF REC ASILOMAR C, P1337, DOI 10.1109/ACSSC.2017.8335571
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Digilent Inc, 2019, PYNQ Z1 REF MAN
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Kim Y., 2014, P EMP METH NAT LANG, P1746, DOI [10.3115/v1/d14-1181, DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Nair V., 2010, ICML, P807
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang SH, 2017, DES AUT TEST EUROPE, P1032, DOI 10.23919/DATE.2017.7927142
   Xilinx Inc, 2018, PYNQ PYTH LIB V2 4
NR 12
TC 3
Z9 3
U1 0
U2 4
PY 2020
BP 1758
EP 1762
DI 10.1109/icassp40776.2020.9053228
UT WOS:000615970401199
DA 2023-11-16
ER

PT J
AU Nakanoya, M
   Narasimhan, SS
   Bhat, S
   Anemogiannis, A
   Datta, A
   Katti, S
   Chinchali, S
   Pavone, M
AF Nakanoya, Manabu
   Narasimhan, Sai Shankar
   Bhat, Sharachchandra
   Anemogiannis, Alexandros
   Datta, Akul
   Katti, Sachin
   Chinchali, Sandeep
   Pavone, Marco
TI Co-design of communication and machine inference for cloud robotics
SO AUTONOMOUS ROBOTS
DT Article
AB Today, even the most compute-and-power constrained robots can measure complex, high data-rate video and LIDAR sensory streams. Often, such robots, ranging from low-power drones to space and subterranean rovers, need to transmit high-bitrate sensory data to a remote compute server if they are uncertain or cannot scalably run complex perception or mapping tasks locally. However, today's representations for sensory data are mostly designed for human, not robotic, perception and thus often waste precious compute or wireless network resources to transmit unimportant parts of a scene that are unnecessary for a high-level robotic task. This paper presents an algorithm to learn task-relevant representations of sensory data that are co-designed with a pre-trained robotic perception model's ultimate objective. Our algorithm aggressively compresses robotic sensory data by up to 11x more than competing methods. Further, it achieves high accuracy and robust generalization on diverse tasks including Mars terrain classification with low-power deep learning accelerators, neural motion planning, and environmental timeseries classification.
C1 [Nakanoya, Manabu] NEC Corp Ltd, Tokyo, Japan.
   [Narasimhan, Sai Shankar; Bhat, Sharachchandra; Chinchali, Sandeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
   [Anemogiannis, Alexandros] VMware, Palo Alto, CA USA.
   [Datta, Akul] Univ Illinois, Dept Comp Sci, Champaign, IL USA.
   [Katti, Sachin; Pavone, Marco] Stanford Univ, Dept Comp Sci, Stanford, CA USA.
RP Narasimhan, SS (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM nakanoya@nec.com; nsaishankar@utexas.edu; sharachchandra@utexas.edu;
   skatti@stanford.edu; sandeepc@utexas.edu; pavone@stanford.edu
CR Akcin O., 2022, 6 ANN C ROB LEARN
   [Anonymous], 2022, SEMANTIC DISTORTION
   [Anonymous], 2019, EDGE TPU
   [Anonymous], 2010, IEEE RAS INT C HUM R
   Cheng Yu, 2017, ARXIV171009282
   Chinchali S., 2019, ARXIV
   Chinchali SP, 2018, HOTNETS-XVII: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P50, DOI 10.1145/3286062.3286070
   Crawshaw M., 2020, ARXIV
   Devlin J., 2018, ARXIV, DOI 10.18653/v1/N19-1423
   Emmons J, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HOT TOPICS IN VIDEO ANALYTICS AND INTELLIGENT EDGES (HOTEDGEVIDEO '19), P27, DOI 10.1145/3349614.3356023
   Engstrom L., 2019, ARXIV
   Engstrom Logan, 2019, ROBUSTNESS PYTHON LI
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   Kang YP, 2017, ACM SIGPLAN NOTICES, V52, P615, DOI 10.1145/3093336.3037698
   Karaman S, 2011, IEEE INT CONF ROBOT, P1478
   Kassir A, 2015, INT J ROBOT RES, V34, P173, DOI 10.1177/0278364914556911
   KeckInstitute for spacestudies, 2020, VIRT WORKSH NEB DE 2
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Kehoe B, 2013, IEEE INT CONF ROBOT, P4263, DOI 10.1109/ICRA.2013.6631180
   Kingma Diederik, 2014, P 2014 INT C LEARNIN
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   LeCun Y., 1998, MNIST DATABASE HANDW
   Li PS, 2018, IEEE INT CON AUTO SC, P1420, DOI 10.1109/COASE.2018.8560447
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Manchester Z., 2013, KICKSAT CROWD FUNDED
   Mars reconnaissance orbiter, 2020, COMM EARTH
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P423, DOI 10.1109/TASE.2015.2408456
   Nakanoya M, 2021, ROBOT SCI SYS
   Nenci F, 2014, IEEE INT C INT ROBOT, P3794, DOI 10.1109/IROS.2014.6943095
   Pacelli V., 2020, ARXIV
   Pacelli V, 2019, IEEE INT CONF ROBOT, P2061, DOI [10.1109/icra.2019.8794213, 10.1109/ICRA.2019.8794213]
   Qureshi AH, 2019, IEEE INT CONF ROBOT, P2118, DOI [10.1109/icra.2019.8793889, 10.1109/ICRA.2019.8793889]
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sonar A., 2020, ARXIV
   Tan M, 2019, ARXIV
   Tanwani AK, 2020, IEEE ROBOT AUTOM LET, V5, P4423, DOI 10.1109/LRA.2020.2998414
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   Tsipras D., 2018, ARXIV
   Tu CX, 2019, IEEE INT CONF ROBOT, P3274, DOI [10.1109/icra.2019.8794264, 10.1109/ICRA.2019.8794264]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van der Merwe JR, 2020, 2020 EUROPEAN NAVIGATION CONFERENCE (ENC), DOI 10.23919/enc48637.2020.9317518
   Weber M., 2019, ARXIV
NR 43
TC 0
Z9 0
U1 2
U2 5
PD JUN
PY 2023
VL 47
IS 5
SI SI
BP 579
EP 594
DI 10.1007/s10514-023-10093-w
EA MAR 2023
UT WOS:000956214700001
DA 2023-11-16
ER

PT J
AU Kim, S
   Kim, J
   Jang, Y
   Kung, J
   Lee, S
AF Kim, Sejin
   Kim, Jungwoo
   Jang, Yongjoo
   Kung, Jaeha
   Lee, Sungjin
TI SEMS: Scalable Embedding Memory System for Accelerating Embedding-Based
   DNNs
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE DNN accelerators; embeddings; recommender systems; system for machine
   learning
AB Embedding layers, which are widely used in various deep learning (DL) applications, are very large in size and are increasing. We propose scalable embedding memory system (SEMS) to deal with the inference of DL applications with a large embedding layer. SEMS is built using scalable embedding memory (SEM) modules, which include FPGA for acceleration. In SEMS, PCIe bus, which is scalable and versatile, is used to expand the system memory and processing in SEMs reduces the amount of data transferred from SEMs to host, improving the effective bandwidth of PCIe. In order to achieve better performance, we apply various optimization techniques at different levels. We develop SEMlib, a Python library to provide convenience in using SEMS. We implement a proof-of-concept prototype of SEMS and using SEMS yields DLRM execution time that is 32.85x faster than that of a CPU-based system when there is a lack of DRAM to hold the entire embedding layer.
C1 [Kim, Sejin; Kim, Jungwoo; Jang, Yongjoo; Kung, Jaeha; Lee, Sungjin] DGIST, Dept Elect Engn & Comp Sci, Daegu 42988, South Korea.
RP Lee, S (corresponding author), DGIST, Dept Elect Engn & Comp Sci, Daegu 42988, South Korea.
EM sejink06@dgist.ac.kr; jungwoo@dgist.ac.kr; dracol@dgist.ac.kr;
   jhkung@dgist.ac.kr; sungjin.lee@dgist.ac.kr
CR Ardestani EK, 2021, Arxiv, DOI arXiv:2110.11489
   BittWare, 2022, 250 M2D M 2 ACC MOD
   Carballo-Hernandez Walther, 2021, ARXIV
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Kaggle, 2014, CRIT DISPL ADV CHALL
   Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070
   Naumov Maxim, 2019, ARXIV
   Park J, 2018, Arxiv, DOI arXiv:1811.09886
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Xilinx Inc, 2021, ALV U200 U250 DAT CT
NR 10
TC 0
Z9 0
U1 0
U2 0
PD JUL-DEC
PY 2022
VL 21
IS 2
BP 157
EP 160
DI 10.1109/LCA.2022.3227560
UT WOS:000903542800002
DA 2023-11-16
ER

PT C
AU Carmichael, Z
   Langroudi, HF
   Khazanov, C
   Lillie, J
   Gustafson, JL
   Kudithipudi, D
AF Carmichael, Zachariah
   Langroudi, Hamed F.
   Khazanov, Char
   Lillie, Jeffrey
   Gustafson, John L.
   Kudithipudi, Dhireesha
GP IEEE
TI Deep Positron: A Deep Neural Network Using the Posit Number System
SO 2019 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 22nd Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 25-29, 2019
CL Florence, ITALY
DE deep neural networks; machine learning; DNN accelerators; posits;
   floating point; tapered precision; low-precision
AB The recent surge of interest in Deep Neural Networks (DNNs) has led to increasingly complex networks that tax computational and memory resources. Many DNNs presently use 16-bit or 32-bit floating point operations. Significant performance and power gains can be obtained when DNN accelerators support low-precision numerical formats. Despite considerable research, there is still a knowledge gap on how low-precision operations can be realized for both DNN training and inference. In this work, we propose a DNN architecture, Deep Positron, with posit numerical format operating successfully at <= 8 bits for inference. We propose a precision-adaptable FPGA soft core for exact multiply-and-accumulate for uniform comparison across three numerical formats, fixed, floating-point and posit. Preliminary results demonstrate that 8-bit posit has better accuracy than 8-bit fixed or floating-point for three different low-dimensional datasets. Moreover, the accuracy is comparable to 32-bit floating-point on a Xilinx Virtex-7 FPGA device. The trade-offs between DNN performance and hardware resources, i.e. latency, power, and resource utilization, show that posit outperforms in accuracy and latency at 8-bit and below.
C1 [Carmichael, Zachariah; Langroudi, Hamed F.; Khazanov, Char; Lillie, Jeffrey; Kudithipudi, Dhireesha] Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
   [Gustafson, John L.] Natl Univ Singapore, Singapore, Singapore.
RP Carmichael, Z (corresponding author), Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
CR [Anonymous], 2014, CORR
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cococcioni M, 2018, 2018 INTERNATIONAL CONFERENCE OF ELECTRICAL AND ELECTRONIC TECHNOLOGIES FOR AUTOMOTIVE
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Hammerstrom D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P537, DOI 10.1109/IJCNN.1990.137621
   Han Song, 2016, ICLR
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Iwata A., 1989, IJCNN, V2, P171
   Johnson J., 2018, ARXIV181101721
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kulisch U., 2013, COMPUTER ARITHMETIC, V33
   Langroudi SHF, 2018, 2018 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2), P19, DOI 10.1109/EMC2.2018.00012
   Mishra A., 2018, ARXIV180300227
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Schlimmer JC, 1987, CONCEPT ACQUISITION
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shazeer Noam, 2017, 5 INT C LEARN REPR I
   STREET WN, 1993, P SOC PHOTO-OPT INS, V1905, P861, DOI 10.1117/12.148698
   Tichy W., 2016, UBIQUITY, V2016, P1
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
NR 23
TC 52
Z9 52
U1 0
U2 3
PY 2019
BP 1421
EP 1426
DI 10.23919/date.2019.8715262
UT WOS:000470666100262
DA 2023-11-16
ER

PT J
AU Jinguji, A
   Sato, S
   Nakahara, H
AF Jinguji, Akira
   Sato, Shimpei
   Nakahara, Hiroki
TI An FPGA Realization of a Random Forest with <i>k</i>-Means Clustering
   Using a High-Level Synthesis Design
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
DT Article
DE machine learning; random forest; k-means clustering; FPGA
AB A random forest (RF) is a kind of ensemble machine learning algorithm used for a classification and a regression. It consists of multiple decision trees that are built from randomly sampled data. The RF has a simple, fast learning, and identification capability compared with other machine learning algorithms. It is widely used for application to various recognition systems. Since it is necessary to un-balanced trace for each tree and requires communication for all the ones, the random forest is not suitable in SIMD architectures such as GPUs. Although the accelerators using the FPGA have been proposed, such implementations were based on HDL design. Thus, they required longer design time than the soft-ware based realizations. In the previous work, we showed the high-level synthesis design of the RF including the fully pipelined architecture and the all-toall communication. In this paper, to further reduce the amount of hardware, we use k-means clustering to share comparators of the branch nodes on the decision tree. Also, we develop the krange tool flow, which generates the bitstream with a few number of hyper parameters. Since the proposed tool flow is based on the high-level synthesis design, we can obtain the high performance RF with short design time compared with the conventional HDL design. We implemented the RF on the Xilinx Inc. ZC702 evaluation board. Compared with the CPU (Intel Xeon (R) E5607 Processor) and the GPU (NVidia Geforce Titan) implementations, as for the performance, the FPGA realization was 8.4 times faster than the CPU one, and it was 62.8 times faster than the GPU one. As for the power consumption efficiency, the FPGA realization was 7.8 times better than the CPU one, and it was 385.9 times better than the GPU one.
C1 [Jinguji, Akira; Sato, Shimpei; Nakahara, Hiroki] Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
RP Jinguji, A (corresponding author), Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
EM jinguji@eda.ict.e.titech.ac.jp; satos@eda.ict.e.titech.ac.jp;
   nakahara@ict.e.titech.ac.jp
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], 2010, CVPR
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], INT SDK OPENCL
   [Anonymous], INT WORKSH OPENCL 20
   [Anonymous], BMVC
   [Anonymous], IEEE ANN INT S FIELD
   [Anonymous], 2000, ICML
   [Anonymous], COMP VIS LOW POW REC
   [Anonymous], INT C FIELD PROGR TE
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Le HA, 2008, ANN IEEE SYM FIELD P, P33, DOI 10.1109/FCCM.2008.9
   Lo WT, 2014, SCI WORLD J, DOI 10.1155/2014/745640
   MacQueen J., 1967, P 5 BERKELEY S MATH
   Narayanan R, 2007, DES AUT TEST EUROPE, P189
   Oberg J., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P330, DOI 10.1109/FPL.2012.6339226
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
NR 19
TC 8
Z9 8
U1 0
U2 7
PD FEB
PY 2018
VL E101D
IS 2
BP 354
EP 362
DI 10.1587/transinf.2017RCP0006
UT WOS:000431762500009
DA 2023-11-16
ER

PT J
AU Shoaib, M
   Jha, NK
   Verma, N
AF Shoaib, Mohammed
   Jha, Niraj K.
   Verma, Naveen
TI Algorithm-Driven Architectural Design Space Exploration of
   Domain-Specific Medical-Sensor Processors
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Biomedical sensor processors; classification accelerators; embedded
   machine learning; low-energy design by voltage and precision scaling;
   structured hardware specialization; support-vector machines
ID SYNTHESIS METHODOLOGY; CUSTOM-INSTRUCTION; MACHINE; CLASSIFICATION;
   COPROCESSOR; PERFORMANCE; BIOMARKERS; DIAGNOSIS; CIRCUIT; ECG
AB Data-driven machine-learning techniques enable the modeling and interpretation of complex physiological signals. The energy consumption of these techniques, however, can be excessive, due to the complexity of the models required. In this paper, we study the tradeoffs and limitations imposed by the energy consumption of high-order detection models implemented in devices designed for intelligent biomedical sensing. Based on the flexibility and efficiency needs at various processing stages in data-driven biomedical algorithms, we explore options for hardware specialization through architectures based on custom instruction and coprocessor computations. We identify the limitations in the former, and propose a coprocessor-based platform that exploits parallelism in computation as well as voltage scaling to operate at a subthreshold minimum-energy point. We present results from post-layout simulation of cardiac arrhythmia detection with patient data from the MIT-BIH database. After wavelet-based feature extraction, which consumes 12.28 mu J, we demonstrate classification computations in the 12.00-120.05 mu J range using 10 000-100 000 support vectors. This represents 1170x lower energy than that of a low-power processor with custom instructions alone. After morphological feature extraction, which consumes 8.65 mu J of energy, the corresponding energy numbers are 10.24-24.51 mu J, which is 1548x smaller than one based on a custom-instruction design. Results correspond to V-dd = 0.4 V and a data precision of 8 b.
C1 [Shoaib, Mohammed; Jha, Niraj K.; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Shoaib, M (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM mshoaib@princeton.edu; jha@princeton.edu; nverma@princeton.edu
CR AbuKhater IS, 1996, IEEE J SOLID-ST CIRC, V31, P1535, DOI 10.1109/4.540066
   [Anonymous], P ACM IEEE INT S LOW
   [Anonymous], P 12 ANN INT C IEEE
   Avestruz AT, 2008, IEEE J SOLID-ST CIRC, V43, P3006, DOI 10.1109/JSSC.2008.2006460
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Chandrakasan AP, 2008, ANNU REV BIOMED ENG, V10, P247, DOI 10.1146/annurev.bioeng.10.061807.160547
   Chapelle O, 2000, ADV NEUR IN, V12, P230
   Chen TW, 2010, IEEE J SOLID-ST CIRC, V45, P2321, DOI 10.1109/JSSC.2010.2067910
   Csavoy A, 2009, SYMP VLSI CIRCUITS, P4
   de Chazal P, 2000, COMPUT CARDIOL, V27, P327, DOI 10.1109/CIC.2000.898523
   de Chazal P, 2004, IEEE T BIO-MED ENG, V51, P1196, DOI 10.1109/TBME.2004.827359
   Dishman E, 2004, COMPUTER, V37, P34, DOI 10.1109/MC.2004.1297237
   Gyselinckx B, 2006, IFIP VLSI-SOC 2006: IFIP WG 10.5 INTERNATIONAL CONFERENCE ON VERY LARGE SCALE INTEGRATION & SYSTEM-ON-CHIP, P175
   Hau D., 1994, P AAAI S ART INT MED, VSS-94-01, P67
   Jaffe AS, 2006, J AM COLL CARDIOL, V48, P1, DOI 10.1016/j.jacc.2006.02.056
   Joachims T., 2010, SVM LIGHT SUPPORT VE
   Kim H, 2009, IEEE ENG MED BIO, P5409, DOI 10.1109/IEMBS.2009.5332815
   Krupa N, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-6
   Kwong J, 2011, IEEE J SOLID-ST CIRC, V46, P1742, DOI 10.1109/JSSC.2011.2144450
   LAGUNA P, 1990, MED BIOL ENG COMPUT, V28, P67, DOI 10.1007/BF02441680
   Lee KH, 2011, INT CONF ACOUST SPEE, P1597
   Manne U, 2005, DRUG DISCOV TODAY, V10, P965, DOI 10.1016/S1359-6446(05)03487-2
   MENDELSON WB, 1987, PSYCHIAT RES, V21, P89, DOI 10.1016/0165-1781(87)90067-9
   Meyfroidt G, 2009, BEST PRAC RES-CL ANA, V23, P127, DOI 10.1016/j.bpa.2008.09.003
   Nie ZD, 2009, IEEE ENG MED BIO, P2559, DOI 10.1109/IEMBS.2009.5335295
   Osowski S, 2001, IEEE T BIO-MED ENG, V48, P1265, DOI 10.1109/10.959322
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Physionet, 2012, MIT BIH PHYS DAT
   Sajda P, 2006, ANNU REV BIOMED ENG, V8, P537, DOI 10.1146/annurev.bioeng.8.061505.095802
   Schleif F.-M., 2007, COMPUT VIS SCI, V4, P189
   Seiler L, 2009, IEEE MICRO, V29, P10, DOI 10.1109/MM.2009.9
   SENHADJI L, 1995, IEEE ENG MED BIOL, V14, P167, DOI 10.1109/51.376755
   Shoaib M, 2011, DES AUT CON, P591
   Shoeb A. H., 2009, THESIS MIT BOSTON
   Shoeb A, 2005, P ANN INT IEEE EMBS, P3546, DOI 10.1109/IEMBS.2005.1617245
   Shoeb A, 2009, IEEE ENG MED BIO, P4202, DOI 10.1109/IEMBS.2009.5333790
   Somorjai RL, 2004, COMPU BIOL, V5, P67
   Sridhara SR, 2010, SYMP VLSI CIRCUITS, P15, DOI 10.1109/VLSIC.2010.5560251
   Sun F, 2004, IEEE T COMPUT AID D, V23, P216, DOI 10.1109/TCAD.2003.822133
   Sun F, 2007, IEEE T COMPUT AID D, V26, P2035, DOI 10.1109/TCAD.2007.906457
   Sun F, 2006, IEEE T VLSI SYST, V14, P1175, DOI 10.1109/TVLSI.2006.886410
   Sun F, 2006, IEEE T COMPUT AID D, V25, P1589, DOI 10.1109/TCAD.2005.858269
   Sunderland T, 2005, BIOL PSYCHIAT, V58, P272, DOI 10.1016/j.biopsych.2005.05.016
   Tang CHH, 2010, PHYSIOL MEAS, V31, P775, DOI 10.1088/0967-3334/31/6/004
   Tensilica Inc, 2012, XTENS PROC
   Übeyli ED, 2007, DIGIT SIGNAL PROCESS, V17, P675, DOI 10.1016/j.dsp.2006.11.009
   Verma N, 2009, SYMP VLSI CIRCUITS, P62
   Vitale SA, 2010, P IEEE, V98, P333, DOI 10.1109/JPROC.2009.2034476
   Wang A, 2005, IEEE J SOLID-ST CIRC, V40, P310, DOI 10.1109/JSSC.2004.837945
NR 49
TC 6
Z9 6
U1 0
U2 14
PD OCT
PY 2013
VL 21
IS 10
BP 1849
EP 1862
DI 10.1109/TVLSI.2012.2220161
UT WOS:000324650300007
DA 2023-11-16
ER

PT J
AU Hanuka, A
   Huang, X
   Shtalenkova, J
   Kennedy, D
   Edelen, A
   Zhang, Z
   Lalchand, VR
   Ratner, D
   Duris, J
AF Hanuka, Adi
   Huang, X.
   Shtalenkova, J.
   Kennedy, D.
   Edelen, A.
   Zhang, Z.
   Lalchand, V. R.
   Ratner, D.
   Duris, J.
TI Physics model-informed Gaussian process for online optimization of
   particle accelerators
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
ID BAYESIAN OPTIMIZATION
AB High-dimensional optimization is a critical challenge for operating large-scale scientific facilities. We apply a physics-informed Gaussian process (GP) optimizer to tune a complex system. Typical GP models learn from past observations to make predictions, but this reduces their applicability to systems where there is limited relevant archive data. Instead, here we use a fast approximate model from physics simulations to design the GP model. The GP is then employed to make inferences from sequential online observations in order to optimize the system. Simulation and experimental studies were carried out to demonstrate the method for online control of a storage ring. Our method is a simple prescription to construct a custom GP model, including correlations between the high-dimensional input space, while encoding the physical response of a system. The ability to inform the machine-learning model with physics, without relying on the availability and range of prior data, may have wide applications in science.
C1 [Hanuka, Adi; Huang, X.; Shtalenkova, J.; Kennedy, D.; Edelen, A.; Zhang, Z.; Ratner, D.; Duris, J.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Lalchand, V. R.] Univ Cambridge, Old Sch, Cambridge CB2 1TN, England.
RP Hanuka, A (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM adiha@slac.stanford.edu
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Aiolli F, 2012, J MACH LEARN RES PRO, V27, P81
   Brodtkorb P. A., 2015, NUMDIFFTOOLS
   Calandra R, 2016, IEEE IJCNN, P3338, DOI 10.1109/IJCNN.2016.7727626
   Camps-Valls G, 2018, APPL SOFT COMPUT, V68, P69, DOI 10.1016/j.asoc.2018.03.021
   Chang WC, 2017, AAAI CONF ARTIF INTE, P1763
   Chollet F., 2015, KERAS
   Conant RC., 1970, INT J SYST SCI, V1, P89, DOI [DOI 10.1080/00207727008920220, 10.1080/00207727008920220]
   Constantinescu EM, 2013, INT J UNCERTAIN QUAN, V3, P47, DOI 10.1615/Int.J.UncertaintyQuantification.2012003722
   Damianou A. C., 2013, PMLR, V31, P207
   de Freitas N., 2010, TR2009023 UBC
   Degrave J, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00006
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Duvenaud D., 2013, 30 INT C MACH LEARN, V28, P2203
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Ekström A, 2019, J PHYS G NUCL PARTIC, V46, DOI 10.1088/1361-6471/ab2b14
   Frazier PI, 2016, SPRINGER SER MATER S, V225, P45, DOI 10.1007/978-3-319-23871-5_3
   Gutmann MU, 2016, J MACH LEARN RES, V17
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Hettel R., 2004, 9 EUR PART ACC C EPA
   Huang X., 2019, BEAM BASED CORRECTIO
   Huang XB, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.104601
   Jalas S, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.104801
   Kirschner J, 2019, PR MACH LEARN RES, V97
   MacKay D. J., 1998, NATO ASI SERIES F CO, V168, P133
   McIntire M., 2016, UAI
   Meeds E, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P593
   Mockus Jonas, 1974, OPTIMIZATION TECHNIQ, V27, P400, DOI DOI 10.1007/3-540-07165-2_55
   Neal RM, 2012, BAYESIAN LEARNING NE
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Noack MM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48114-3
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Roussel R., ARXIV201009824
   Safranek J, 1997, NUCL INSTRUM METH A, V388, P27, DOI 10.1016/S0168-9002(97)00309-4
   Sano S, 2020, J PHARM INNOV, V15, P333, DOI 10.1007/s12247-019-09382-8
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Sun SY, 2018, PR MACH LEARN RES, V80
   Taasti VT, 2020, MED PHYS, V47, P3286, DOI 10.1002/mp.14215
   Tartakovsky A. M., 2019, 52 HAW INT C SYST SC, P1
   Terebilo A., 2001, PACS2001. Proceedings of the 2001 Particle Accelerator Conference (Cat. No.01CH37268), P3203, DOI 10.1109/PAC.2001.988056
   Tomin S., 2016, P 7 INT PART ACC C B
   Wiener N, 1930, ACTA MATH-DJURSHOLM, V55, P117, DOI 10.1007/BF02546511
   Wilson AG, 2016, ADV NEUR IN, V29
   Wu JL, 2019, COMPUT FLUIDS, V193, DOI 10.1016/j.compfluid.2019.104292
   Yang X, 2019, J COMPUT PHYS, V395, P410, DOI 10.1016/j.jcp.2019.06.041
NR 47
TC 11
Z9 11
U1 3
U2 12
PD JUL 8
PY 2021
VL 24
IS 7
AR 072802
DI 10.1103/PhysRevAccelBeams.24.072802
UT WOS:000681723000001
DA 2023-11-16
ER

PT C
AU Rattihalli, G
   Hogade, N
   Dhakal, A
   Frachtenberg, E
   Enriquez, RPH
   Bruel, P
   Mishra, A
   Milojicic, D
AF Rattihalli, Gourav
   Hogade, Ninad
   Dhakal, Aditya
   Frachtenberg, Eitan
   Enriquez, Rolando Pablo Hong
   Bruel, Pedro
   Mishra, Alok
   Milojicic, Dejan
BE Ardagna, C
   Atukorala, N
   Beckman, P
   Chang, C
   Chang, R
   Evangelinos, C
   Fan, J
   Fox, G
   Fox, J
   Hagleitner, C
   Jin, Z
   Kosar, T
   Parashar, M
TI Fine-Grained Heterogeneous Execution Framework with Energy Aware
   Scheduling
SO 2023 IEEE 16TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, CLOUD
SE IEEE International Conference on Cloud Computing
DT Proceedings Paper
CT IEEE 16th International Conference on Cloud Computing (IEEE CLOUD)
CY JUL 02-08, 2023
CL Chicago, IL
DE Energy-awareness; Heterogeneity; Serverless; Framework; Scheduler;
   Fine-granularity
AB The growing convergence of high-performance, data analytics, and machine-learning applications is increasingly pushing computing systems toward heterogeneous processors and specialized hardware accelerators. Hardware heterogeneity, in turn, leads to finer-grained workflows. State-of-the-art serverless computing resource managers do not currently provide efficient scheduling of such fine-grained tasks on systems with heterogeneous CPUs and specialized hardware accelerators (e.g., GPUs and FPGAs). Working with fine-grained tasks presents an opportunity for more efficient energy use via new scheduling models.
   Our proposed scheduler enables technologies like Nvidia's Multi-Process Service (MPS) to pack multiple fine-grained tasks on GPUs efficiently. Its advantages include better co-location of jobs and better sharing of hardware resources such as GPUs that were not previously possible on container orchestration systems. We propose a Kubernetes-native energy-aware scheduler that integrates with our heterogeneous framework. Combining finegrained resource scheduling on heterogeneous hardware and energy-aware scheduling results in up to 17.6% improvement in makespan, up to 20.16% reduction in energy consumption for CPU workloads, and up to 58.15% improvement in makespan, and up to 28.92% reduction in energy consumption for GPU workloads.
C1 [Rattihalli, Gourav; Hogade, Ninad; Dhakal, Aditya; Bruel, Pedro; Milojicic, Dejan] Hewlett Packard Labs, Milpitas, CA 95035 USA.
   [Frachtenberg, Eitan] Hewlett Packard Labs, Portland, OR USA.
   [Enriquez, Rolando Pablo Hong] Hewlett Packard Labs, Oxford, England.
   [Mishra, Alok] Hewlett Packard Labs, Rockaway, NJ USA.
RP Rattihalli, G (corresponding author), Hewlett Packard Labs, Milpitas, CA 95035 USA.
EM gourav.rattihalli@hpe.com; ninad.hogade@hpe.com; aditya.dhakal@hpe.com;
   eitan.frachtenberg@hpe.com; rhong@hpe.com; bruel@hpe.com;
   alok.mishra@hpe.com; dejan.milojicic@hpe.com
CR Andrae A, 2015, CHALLENGES, V6, P117, DOI 10.3390/challe6010117
   [Anonymous], 2011, P 2011 ACM WORKSH GA, DOI DOI 10.1145/2110486.2110490
   Arnaboldi M, 2018, PR INT CONF AUTONOM, P71, DOI 10.1109/ICAC.2018.00017
   Aslanpour MS, 2022, 2022 22ND IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2022), P190, DOI 10.1109/CCGrid54584.2022.00028
   aws.amazon, AWS LAMBD EN FUNCT C
   aws.amazon, AWS LAMBD
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Brondolin R, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING AND SELF-ORGANIZING SYSTEMS (ACSOS 2020), P11, DOI 10.1109/ACSOS49614.2020.00021
   Chard Ryan, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P65, DOI 10.1145/3369583.3392683
   Cheng HW, 2021, J SUPERCOMPUT, V77, P13385, DOI 10.1007/s11227-021-03805-5
   climateneutralgroup.com, CARB EM DAT CTR
   Copik M., 2022, RFAAS ENABLING HIGH
   Dhakal Aditya, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P492, DOI 10.1145/3419111.3421284
   docs.nvidia, MULT SERV GPU DEPL M
   Douhara Ryuki, 2020, 2020 International Conference on Computational Science and Computational Intelligence (CSCI), P1269, DOI 10.1109/CSCI51800.2020.00238
   fission, FISS SERV FUNCT KUB
   Frampton M., 2018, COMPLETE GUIDE OPEN, P97, DOI [10.1007/978-1-4842-2149-54, 10.1007/978-1-4842-2149-5]
   Ghafouri S, 2022, INT CONF UTIL CLOUD, P82, DOI 10.1109/UCC56403.2022.00019
   Gunasekaran JR, 2020, PROCEEDINGS OF THE 2020 21ST INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE '20), P280, DOI 10.1145/3423211.3425683
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ST, 2021, IEEE T COMPUT, V70, P2015, DOI 10.1109/TC.2021.3123465
   IEA, 2022, DAT CTR DAT TRANSM N
   intel, RUNN AV POW LIM EN R
   James A., 2019, ICT SUSTAINABILITY
   Jia Xuechao, 2021, 2021 IEEE 27th International Conference on Parallel and Distributed Systems (ICPADS)., P434, DOI 10.1109/ICPADS53394.2021.00060
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaur K, 2020, IEEE INTERNET THINGS, V7, P4228, DOI 10.1109/JIOT.2019.2939534
   Khullar R., 2022, 2022 10 IEEE ACS 19, P1
   Knative, US
   Kubernetes, US
   Li ZS, 2021, IEEE ACCESS, V9, P84596, DOI 10.1109/ACCESS.2021.3081559
   manpages.ubuntu, UB MANP STRESS NG TO
   Menouer T, 2021, J SUPERCOMPUT, V77, P4267, DOI 10.1007/s11227-020-03427-3
   Milojicic D, 2020, COMPUTER, V53, P14, DOI 10.1109/MC.2019.2954056
   Nassereldine Amir, 2023, IEEE ACM INT S CLUST
   Numba, 2023, MAND SET COMP US NUM
   nvidia, MULT GPU MIG NVIDIA
   openwhisk.apache, AP OPENWHISK OP SOUR
   pcp, PERF COP
   Rattihalli G, 2019, IEEE INT CONF CLOUD, P33, DOI 10.1109/CLOUD.2019.00018
   Rattihalli G, 2019, IEEE ACM INT SYMP, P188, DOI 10.1109/CCGRID.2019.00033
   Rocha I, 2019, EUROMICRO WORKSHOP P, P400, DOI 10.1109/EMPDP.2019.8671554
   Townend P, 2019, 2019 13TH IEEE INTERNATIONAL CONFERENCE ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE) / 10TH INTERNATIONAL WORKSHOP ON JOINT CLOUD COMPUTING (JCC) / IEEE INTERNATIONAL WORKSHOP ON CLOUD COMPUTING IN ROBOTIC SYSTEMS (CCRS), P156, DOI 10.1109/SOSE.2019.00030
   VAUGHAN JR, 1989, U COMPUT, V11, P193
   Zhang W, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P58, DOI 10.1145/3330345.3330351
NR 45
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 35
EP 44
DI 10.1109/CLOUD60044.2023.00014
UT WOS:001085065100004
DA 2023-11-16
ER

PT C
AU Sarma, A
   Jiang, HP
   Pattnaik, A
   Kotra, J
   Kandemir, MT
   Das, CR
AF Sarma, Anup
   Jiang, Huaipan
   Pattnaik, Ashutosh
   Kotra, Jagadish
   Kandemir, Mahmut Taylan
   Das, Chita R.
GP Assoc Comp Machinery
TI CASH: Compiler Assisted Hardware Design for Improving DRAM Energy
   Efficiency in CNN Inference
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
ID MEMORY
AB The advent of machine learning (ML) and deep learning applications has led to the development of a multitude of hardware accelerators and architectural optimization techniques for parallel architectures. This is due in part to the regularity and parallelism exhibited by the ML workloads, especially convolutional neural networks (CNNs). However, CPUs continue to be one of the dominant compute fabric in data-centers today, thereby also being widely deployed for inference tasks. As CNNs grow larger, the inherent limitations of a CPU-based system become apparent, specifically in terms of main memory data movement. In this paper, we present CASH, a compiler-assisted hardware solution that eliminates redundant data-movement to and from the main memory and, therefore, reduces main memory bandwidth and energy consumption. Our experimental evaluations on a set of four different state-of-the-art CNN workloads indicate that CASH provides, on average, similar to 40% and similar to 18% reductions in main memory bandwidth and energy consumption, respectively.
C1 [Sarma, Anup; Jiang, Huaipan; Pattnaik, Ashutosh; Kotra, Jagadish; Kandemir, Mahmut Taylan; Das, Chita R.] Penn State Univ, University Pk, PA 16802 USA.
RP Sarma, A (corresponding author), Penn State Univ, University Pk, PA 16802 USA.
EM avs6194@psu.edu; hzj5143@psu.edu; ashutosh@psu.edu; jbk5155@cse.psu.edu;
   mtk2@psu.edu; das@cse.psu.edu
CR [Anonymous], 2016, ARXIV160206709
   [Anonymous], 2017, CORR
   [Anonymous], 2016, MICROARCHITECTURE MI
   Banakar R, 2002, CODES 2002: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON HARDWARE/SOFTWARE CODESIGN, P73, DOI 10.1109/CODES.2002.1003604
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet Clement, 2011, PROC IEEE COMPUT SOC, P109
   Ferreira AP, 2010, DES AUT TEST EUROPE, P914
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Guyer SZ, 2006, ACM SIGPLAN NOTICES, V41, P364, DOI 10.1145/1133981.1134024
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Haria S, 2018, ACM SIGPLAN NOTICES, V53, P637, DOI [10.1145/3296957.3173194, 10.1145/3173162.3173194]
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hennessy J.L., 2011, COMPUTER ARCHITECTUR
   Huang G., 2017, 2017 IEEE C COMPUTER, P4700
   Huh S, 2017, INT SOC DESIGN CONF, P46, DOI 10.1109/ISOCC.2017.8368820
   Iandola FN, 2016, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR.2016.284
   Inc. CISCO, CISC GLOB CLOUD IND
   Jiang HP, 2018, INT SOC DESIGN CONF, P227
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2014, ABS14045997 CORR
   Lee BC, 2010, IEEE MICRO, V30, P131, DOI 10.1109/MM.2010.24
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Lou DD, 2018, J NANOSCI NANOTECHNO, V18, P951, DOI 10.1166/jnn.2018.13977
   Mandal A, 2018, LECT NOTES COMPUT SC, V11014, P265, DOI 10.1007/978-3-319-96983-1_19
   Muchnick S., 1997, ADV COMPILER DESIGN
   Park J., 2018, ARXIV PREPRINT ARXIV
   Pleiss G., 2017, CORR
   Rhu M, 2016, INT SYMP MICROARCH
   Sarma A., 2011, 2011 International Conference on Recent Trends in Information Systems (ReTIS), P175, DOI 10.1109/ReTIS.2011.6146863
   Sartor Jennifer B., 2014, ACM INT C PAR ARCH C
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Zlateski A, 2016, INT PARALL DISTRIB P, P801, DOI 10.1109/IPDPS.2016.119
NR 45
TC 3
Z9 3
U1 0
U2 0
PY 2019
BP 396
EP 407
DI 10.1145/3357526.3357536
UT WOS:000557305400034
DA 2023-11-16
ER

PT J
AU Zhao, JY
   Huang, SY
   Yousuf, O
   Gao, YT
   Hoskins, BD
   Adam, GC
AF Zhao, Junyun
   Huang, Siyuan
   Yousuf, Osama
   Gao, Yutong
   Hoskins, Brian D.
   Adam, Gina C.
TI Gradient Decomposition Methods for Training Neural Networks With
   Non-ideal Synaptic Devices
SO FRONTIERS IN NEUROSCIENCE
DT Article
DE non-negative matrix factorization; gradient data decomposition;
   principal component analysis; memristor; non-idealities; ReRAM
ID NONNEGATIVE MATRIX; OXIDE; ALGORITHMS; RESISTANCE; MODEL
AB While promising for high-capacity machine learning accelerators, memristor devices have non-idealities that prevent software-equivalent accuracies when used for online training. This work uses a combination of Mini-Batch Gradient Descent (MBGD) to average gradients, stochastic rounding to avoid vanishing weight updates, and decomposition methods to keep the memory overhead low during mini-batch training. Since the weight update has to be transferred to the memristor matrices efficiently, we also investigate the impact of reconstructing the gradient matrixes both internally (rank-seq) and externally (rank-sum) to the memristor array. Our results show that streaming batch principal component analysis (streaming batch PCA) and non-negative matrix factorization (NMF) decomposition algorithms can achieve near MBGD accuracy in a memristor-based multi-layer perceptron trained on the MNIST (Modified National Institute of Standards and Technology) database with only 3 to 10 ranks at significant memory savings. Moreover, NMF rank-seq outperforms streaming batch PCA rank-seq at low-ranks making it more suitable for hardware implementation in future memristor-based accelerators.
C1 [Zhao, Junyun; Huang, Siyuan; Gao, Yutong] George Washington Univ, Dept Comp Sci, Washington, DC USA.
   [Yousuf, Osama; Adam, Gina C.] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [Hoskins, Brian D.] NIST, Phys Measurement Lab, Gaithersburg, MD 20899 USA.
RP Adam, GC (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
EM ginaadam@gwu.edu
CR Adam GC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07565-4
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2008, PRINCIPAL MANIFOLDS, DOI [10.1007/978-3-540-73750-6_2, DOI 10.1007/978-3-540-73750-6_2]
   ARGALL F, 1968, SOLID STATE ELECTRON, V11, P535, DOI 10.1016/0038-1101(68)90092-0
   Baek IG, 2004, IEEE INTERNATIONAL ELECTRON DEVICES MEETING 2004, TECHNICAL DIGEST, P587, DOI 10.1109/IEDM.2004.1419228
   Barnes R., 1951, ELECTRON ENG, V23, P286
   Berdan R, 2020, NAT ELECTRON, V3, P259, DOI 10.1038/s41928-020-0405-0
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Burrello A, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P235, DOI 10.1145/3310273.3322822
   Ceze L, 2016, 2016 74TH ANNUAL DEVICE RESEARCH CONFERENCE (DRC), DOI 10.1109/DRC.2016.7548506
   Chen P.-Y., 2017, IEEE INT EL DEV M IE
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Cichocki A, 2009, NONNEGATIVE MATRIX T, DOI DOI 10.1002/9780470747278
   Cichocki A, 2009, IEICE T FUND ELECTR, VE92A, P708, DOI 10.1587/transfun.E92.A.708
   DEARNALEY G, 1970, REP PROG PHYS, V33, P1129, DOI 10.1088/0034-4885/33/3/306
   Dollar Piotr, 2017, P IEEE INT C COMPUTE, P2961
   FORSYTHE GE, 1950, B AM MATH SOC, V56, P61
   Gao YM, 2023, IEEE T PATTERN ANAL, V45, P7019, DOI 10.1109/TPAMI.2020.3025062
   Garipov Timur, 2016, ABS161103214 CORR
   Gokmen T, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00103
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Golmant N., 2018, ARXIV181112941
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   HICKMOTT TW, 1962, J APPL PHYS, V33, P2669, DOI 10.1063/1.1702530
   Hirtzlin T., 2019, 2019 IEEEACM INT S N, DOI [10.1109/NANOARCH47378.2019.181300, DOI 10.1109/NANOARCH47378]
   Hoskins B.D., 2021, P INT C NEUR SYST IC, DOI [10.1145/3477145.3477260, DOI 10.1145/3477145.3477260]
   Hoskins BD, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00793
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Huang S., 2020, 2001040771 ARXIV
   Huang SY, 2020, AAAI CONF ARTIF INTE, V34, P13813
   HULL TE, 1966, COMMUN ACM, V9, P108, DOI 10.1145/365170.365212
   Jeong DS, 2005, APPL PHYS LETT, V86, DOI 10.1063/1.1865326
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Kataeva I., 2015, 2015 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2015.7280785, DOI 10.1109/IJCNN.2015.7280785]
   Kim W, 2019, S VLSI TECH, pT66, DOI [10.23919/vlsit.2019.8776551, 10.23919/VLSIT.2019.8776551]
   Langston J, 2020, MICROSOFT ANNOUNCES
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li C, 2019, NAT MACH INTELL, V1, P49, DOI 10.1038/s42256-018-0001-4
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   Lin YH, 2019, IEEE T ELECTRON DEV, V66, P1289, DOI 10.1109/TED.2019.2894273
   Meng-Fan Chang, 2011, Proceedings of the 2011 IEEE 9th International Conference on ASIC (ASICON 2011), P299, DOI 10.1109/ASICON.2011.6157181
   Neftci EO, 2019, IEEE SIGNAL PROC MAG, V36, P51, DOI 10.1109/MSP.2019.2931595
   Neftci EO, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00324
   Nugent MA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085175
   OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Oxley D. P., 1977, Electrocomponent Science and Technology, V3, P217, DOI 10.1155/APEC.3.217
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   PAGNIA H, 1988, PHYS STATUS SOLIDI A, V108, P11, DOI 10.1002/pssa.2211080102
   Payvand M, 2020, IEEE J EM SEL TOP C, V10, P522, DOI 10.1109/JETCAS.2020.3040248
   Payvand M, 2019, FARADAY DISCUSS, V213, P487, DOI 10.1039/c8fd00114f
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Schein A, 2016, PR MACH LEARN RES, V48
   Seo S, 2004, APPL PHYS LETT, V85, P5655, DOI 10.1063/1.1831560
   Serb A, 2016, IEEE T CIRCUITS-I, V63, P827, DOI 10.1109/TCSI.2015.2476296
   She XY, 2019, IEEE IJCNN
   Stewart K, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P223, DOI [10.1109/aicas48895.2020.9073948, 10.1109/AICAS48895.2020.9073948]
   Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693
   Vogels T., 2019, ADV NEURAL INFORM PR, P14236
   Wang D, 2016, IEEE T CYBERNETICS, V46, P233, DOI 10.1109/TCYB.2015.2399533
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
NR 65
TC 2
Z9 2
U1 1
U2 9
PD NOV 22
PY 2021
VL 15
AR 749811
DI 10.3389/fnins.2021.749811
UT WOS:000727183100001
DA 2023-11-16
ER

PT J
AU Garland, J
   Gregg, D
AF Garland, James
   Gregg, David
TI Low Complexity Multiply Accumulate Unit for Weight-Sharing Convolutional
   Neural Networks
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Convolutional neural network; power efficiency; multiply accumulate;
   arithmetic hardware circuits
AB Convolutional Neural Networks (CNNs) are one of the most successful deep machine learning technologies for processing image, voice and video data. CNNs require large amounts of processing capacity and memory, which can exceed the resources of low power mobile and embedded systems. Several designs for hardware accelerators have been proposed for CNNs which typically contain large numbers of Multiply Accumulate (MAC) units. One approach to reducing data sizes and memory traffic in CNN accelerators is "weight sharing", where the full range of values in a trained CNN are put in bins and the bin index is stored instead of the original weight value. In this paper we propose a novel MAC circuit that exploits binning in weight-sharing CNNs. Rather than computing the MAC directly we instead count the frequency of each weight and place it in a bin. We then compute the accumulated value in a subsequent multiply phase. This allows hardware multipliers in the MAC circuit to be replaced with adders and selection logic. Experiments show that for the same clock speed our approach results in fewer gates, smaller logic, and reduced power.
C1 [Garland, James; Gregg, David] Trinity Coll Dublin, Dublin 2, Ireland.
RP Garland, J (corresponding author), Trinity Coll Dublin, Dublin 2, Ireland.
EM jgarland@tcd.ie; david.gregg@cs.tcd.ie
CR [Anonymous], 2015, CORR
   [Anonymous], 2015, 32 ICML
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Fürer M, 2007, ACM S THEORY COMPUT, P57, DOI 10.1145/1250790.1250800
   Gangadharan Sridhar, 2015, CONSTRAINING DESIGNS
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Szegedy C., 2015, P COMP VIS FDN JUN
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 9
TC 20
Z9 23
U1 1
U2 8
PD JUL-DEC
PY 2017
VL 16
IS 2
BP 132
EP 135
DI 10.1109/LCA.2017.2656880
UT WOS:000418870500011
DA 2023-11-16
ER

PT C
AU Lim, B
   Allard, M
   Grillotti, L
   Cully, A
AF Lim, Bryan
   Allard, Maxime
   Grillotti, Luca
   Cully, Antoine
GP ACM
TI QDax: On the Benefits of Massive Parallelization for Quality-Diversity
SO PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE
   COMPANION, GECCO 2022
DT Proceedings Paper
CT Genetic and Evolutionary Computation Conference (GECCO)
CY JUL 09-13, 2022
CL Boston, MA
DE Quality Diversity; MAP-Elites; Robotics; Hardware Acceleration
AB Quality-Diversity (QD) algorithms are a well-known approach to generate large collections of diverse and high-quality policies. However, QD algorithms are also known to be data-inefficient, requiring large amounts of computational resources and are slow when used in practice for robotics tasks. Policy evaluations are already commonly performed in parallel to speed up QD algorithms but have limited capabilities on a single machine as most physics simulators run on CPUs. With recent advances in simulators that run on accelerators, thousands of evaluations can be performed in parallel on single GPU/TPU. In this paper, we present QDax, an implementation of MAP-Elites which leverages massive parallelism on accelerators to make QD algorithms more accessible. We show that QD algorithms are ideal candidates and can scale with massive parallelism to be run at interactive timescales. The increase in parallelism does not significantly affect the performance of QD algorithms, while reducing experiment runtimes by two factors of magnitudes, turning days of computation into minutes. These results show that QD can now benefit from hardware acceleration, which contributed significantly to the bloom of deep learning.
C1 [Lim, Bryan; Allard, Maxime; Grillotti, Luca; Cully, Antoine] Imperial Coll London, Adapt & Intelligent Robot Lab, London, England.
RP Lim, B (corresponding author), Imperial Coll London, Adapt & Intelligent Robot Lab, London, England.
EM bryan.lim16@imperial.ac.uk; m.allard20@imperial.ac.uk;
   luca.grillotti16@imperial.ac.uk; a.cully@imperial.ac.uk
CR Barbu A, 2019, ADV NEUR IN, V32
   Bradbury James, 2018, JAX COMPOSABLE TRANS
   Chatzilygeroudis K, 2018, ROBOT AUTON SYST, V100, P236, DOI 10.1016/j.robot.2017.11.010
   Coumans E., 2021, PYBULLET PYTHON MODU
   Cully A, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P81, DOI 10.1145/3321707.3321804
   Cully A, 2018, IEEE T EVOLUT COMPUT, V22, P245, DOI 10.1109/TEVC.2017.2704781
   Cully A, 2015, NATURE, V521, P503, DOI 10.1038/nature14422
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diaz Manfred, 2021, ARXIV
   Ecoffet A, 2021, NATURE, V590, DOI 10.1038/s41586-020-03157-9
   Fontaine MC, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P94, DOI 10.1145/3377930.3390232
   Freeman C. D., 2021, BRAX A DIFFERENTIABL
   Kaushik R, 2020, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00151
   Lee J., 2018, J OPEN SOURCE SOFTWA, V3, P500, DOI [10.21105/joss.00500, DOI 10.21105/JOSS.00500]
   Mouret JB, 2015, Arxiv, DOI arXiv:1504.04909
   Mouret JB, 2010, IEEE C EVOL COMPUTAT
   Pugh JK, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00040
   Tjanaka Bryon, 2021, PYRIBS BARE BONES PY
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Vassiliades V, 2018, IEEE T EVOLUT COMPUT, V22, P623, DOI 10.1109/TEVC.2017.2735550
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 128
EP 131
DI 10.1145/3520304.3528927
UT WOS:001035469400052
DA 2023-11-16
ER

PT C
AU Ivanov, A
   Rothenberger, B
   Dethise, A
   Canini, M
   Hoefler, T
   Perrig, A
AF Ivanov, Andrei
   Rothenberger, Benjamin
   Dethise, Arnaud
   Canini, Marco
   Hoefler, Torsten
   Perrig, Adrian
GP USENIX Association
TI SAGE: Software-based Attestation for GPU Execution
SO PROCEEDINGS OF THE 2023 USENIX ANNUAL TECHNICAL CONFERENCE
DT Proceedings Paper
CT USENIX Annual Technical Conference (USENIX ATC)
CY JUL 10-12, 2023
CL Boston, MA
AB With the application of machine learning to security-critical and sensitive domains, there is a growing need for integrity and privacy in computation using accelerators, such as GPUs. Unfortunately, the support for trusted execution on GPUs is currently very limited - trusted execution on accelerators is particularly challenging since the attestation mechanism should not reduce performance.
   Although hardware support for trusted execution on GPUs is emerging, we study purely software-based approaches for trusted GPU execution. A software-only approach offers distinct advantages: (1) complement hardware-based approaches, enhancing security especially when vulnerabilities in the hardware implementation degrade security, (2) operate on GPUs without hardware support for trusted execution, and (3) achieve security without reliance on secrets embedded in the hardware, which can be extracted as history has shown.
   In this work, we present SAGE, a software-based attestation mechanism for GPU execution. SAGE enables secure code execution on NVIDIA GPUs of the Ampere architecture (A100), providing properties of code integrity and secrecy, computation integrity, as well as data integrity and secrecy - all in the presence of malicious code running on the GPU and CPU. Our evaluation demonstrates that SAGE is already practical today for executing code in a trustworthy way on GPUs without specific hardware support.
C1 [Ivanov, Andrei; Rothenberger, Benjamin; Hoefler, Torsten; Perrig, Adrian] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Dethise, Arnaud; Canini, Marco] KAUST, Thuwal, Saudi Arabia.
RP Ivanov, A (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Anderson R., 1998, Operating Systems Review, V32, P9, DOI 10.1145/302350.302353
   ARM, 2021, ARM TRUSTZONE TECHN
   Butterworth John, 2013, P ACM SIGSAC C COMP
   Costan Victor, 2016, IACR CRYPTOL EPRINT, V2016, P1
   Ermolov M., 2017, HACK TURNED OFF COMP
   Forlin B, 2020, PROC EUR TEST SYMP, DOI 10.1109/ets48528.2020.9131562
   Gligor Virgil D, 2019, NDSS
   Hunt T, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P817
   Intel, 2021, INT GEN CRYP LIB API
   Intel, 2021, XEON GOLD 6348 PROC
   Intel, 2021, SOFTW GUARD EXT LIN
   Jang I, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P455, DOI 10.1145/3297858.3304021
   Jia Z, 2019, Arxiv, DOI arXiv:1903.07486
   Jia Z, 2018, Arxiv, DOI arXiv:1804.06826
   JohnWalker, 2008, ENT PSEUDORANDOM NUM
   Kovah X, 2012, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2012.45
   Marsaglia G., 1996, DIEHARD BATTERY TEST
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Nunes I, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2921, DOI 10.1145/3460120.3484532
   NVIDIA, 2022, BAS LIN ALG NVIDIA G
   NVIDIA, 2021, MULT INST GPU US GUI
   NVIDIA, 2022, NVIDIA H100 TENS COR
   NVIDIA, 2020, AMP ARCH IN DEPTH
   NVIDIA, 2021, CUDA OCC CALC
   NVIDIA, 2021, CUDA BIN UT
   NVIDIA, 2020, NVIDIA EGX IS FORM C
   NVIDIA, 2021, INT 32 FP64 CAN BE U
   Olson LE, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P470, DOI 10.1145/2830772.2830819
   Ragab Hany, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P1852, DOI 10.1109/SP40001.2021.00020
   Research and Markets, 2021, DAT CTR ACC MARK GLO
   Schaller A, 2019, IEEE T DEPEND SECURE, V16, P462, DOI 10.1109/TDSC.2018.2822298
   Seshadri A, 2004, P IEEE S SECUR PRIV, P272
   Seshadri A., 2005, P 20 ACM S OP SYST P, P1
   Seshadri A, 2008, LECT NOTES COMPUT SC, V5067, P372, DOI 10.1007/978-3-540-69170-9_25
   Shaneck M, 2005, LECT NOTES COMPUT SC, V3813, P27
   Shen TX, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P723
   Smid Elaine Barker, 2010, SPECIAL PUBLICATION
   Tamarin Team, 2021, TAM PROV
   Tamarin Team, 2021, TAM MAN PROP SPEC
   TechSpot, 2022, INT SGX DEPR IMP DRM
   Teh JS, 2015, NONLINEAR DYNAM, V82, P1913, DOI 10.1007/s11071-015-2287-7
   tensorflow, 2021, END TO END OP SOURC
   TramŠr F, 2019, Arxiv, DOI arXiv:1806.03287
   Van Aubel P, 2015, LECT NOTES COMPUT SC, V9354, P228, DOI 10.1007/978-3-319-24126-5_14
   Van Bulck J, 2020, P IEEE S SECUR PRIV, P54, DOI 10.1109/SP40000.2020.00089
   Vigna S, 2017, J COMPUT APPL MATH, V315, P175, DOI 10.1016/j.cam.2016.11.006
   Volos S, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P681
   Zhao Jun, 2013, CAMBR INT WORKSH SEC, P94
   Zhu JP, 2019, Arxiv, DOI arXiv:1904.04782
NR 49
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 485
EP 499
UT WOS:001066454400032
DA 2023-11-16
ER

PT C
AU Nakanoya, M
   Chinchali, S
   Anemogiannis, A
   Datta, A
   Katti, S
   Pavone, M
AF Nakanoya, Manabu
   Chinchali, Sandeep
   Anemogiannis, Alexandros
   Datta, Akul
   Katti, Sachin
   Pavone, Marco
BE Shell, DA
   Toussaint, M
   Hsieh, MA
TI Co-Design of Communication and Machine Inference for Cloud Robotics
SO ROBOTICS: SCIENCE AND SYSTEM XVII
SE Robotics - Science and Systems
DT Proceedings Paper
CT Conference on Robotics - Science and Systems
CY JUL 12-16, 2021
CL ELECTR NETWORK
AB Today, even the most compute-and-power constrained robots can measure complex, high data-rate video and LIDAR sensory streams. Often, such robots, ranging from low-power drones to space and subterranean rovers, need to transmit high-bitrate sensory data to a remote compute server if they are uncertain or cannot scalably run complex perception or mapping tasks locally. However, today's representations for sensory data are mostly designed for human, not robotic, perception and thus often waste precious compute or wireless network resources to transmit unimportant parts of a scene that are unnecessary for a high-level robotic task. This paper presents an algorithm to learn task-relevant representations of sensory data that are co-designed with a pre-trained robotic perception model's ultimate objective. Our algorithm aggressively compresses robotic sensory data by up to 11 x more than competing methods. Further, it achieves high accuracy and robust generalization on diverse tasks including Mars terrain classification with low-power deep learning accelerators, neural motion planning, and environmental timeseries classification.
C1 [Nakanoya, Manabu] NEC Corp Ltd, Kawasaki, Kanagawa, Japan.
   [Chinchali, Sandeep; Katti, Sachin] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   [Pavone, Marco] Stanford Univ, Dept Aeronaut & Astronaut, Stanford, CA 94305 USA.
   [Chinchali, Sandeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Nakanoya, M (corresponding author), NEC Corp Ltd, Kawasaki, Kanagawa, Japan.
EM nakanoya@nec.com; csandeep@stanford.edu; skatti@stanford.edu;
   pavone@stanford.edu
CR [Anonymous], 2019, EDGE TPU
   [Anonymous], 2010, IEEE RAS INT C HUM R
   [Anonymous], 2020, MARS RECONNAISSANCE
   Cheng Yu, 2017, ARXIV171009282
   Chinchali S, 2019, ARXIV PREPRINT ARXIV
   Chinchali SP, 2018, HOTNETS-XVII: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P50, DOI 10.1145/3286062.3286070
   Crawshaw M., 2020, MULTITASK LEARNING D
   Devlin J., 2018, ARXIV, DOI 10.18653/v1/N19-1423
   Doran G., 2019, MARS ORBITAL IMAGE H
   Emmons J, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HOT TOPICS IN VIDEO ANALYTICS AND INTELLIGENT EDGES (HOTEDGEVIDEO '19), P27, DOI 10.1145/3349614.3356023
   Engstrom Logan, 2019, ROBUSTNESS PYTHON LI
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   K. I. for Space Studies, 2020, VIRTUAL WORKSHOP NEB
   Kang YP, 2017, ACM SIGPLAN NOTICES, V52, P615, DOI 10.1145/3093336.3037698
   Karaman S, 2011, IEEE INT CONF ROBOT, P1478
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Kehoe B, 2013, IEEE INT CONF ROBOT, P4263, DOI 10.1109/ICRA.2013.6631180
   Kingma Diederik P, 2013, ARXIV13126114
   LeCun Y., MNIST DATABASE HANDW
   Li PS, 2018, IEEE INT CON AUTO SC, P1420, DOI 10.1109/COASE.2018.8560447
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Manchester Z., 2013, KICKSAT CROWD FUNDED
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P423, DOI 10.1109/TASE.2015.2408456
   Nenci F, 2014, IEEE INT C INT ROBOT, P3794, DOI 10.1109/IROS.2014.6943095
   Pacelli V., 2020, ARXIV PREPRINT ARXIV
   Pacelli V, 2019, IEEE INT CONF ROBOT, P2061, DOI [10.1109/icra.2019.8794213, 10.1109/ICRA.2019.8794213]
   Qureshi AH, 2019, IEEE INT CONF ROBOT, P2118, DOI [10.1109/icra.2019.8793889, 10.1109/ICRA.2019.8793889]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanwani A. K., 2020, IEEE ROBOT AUTOM LET
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   Tu CX, 2019, IEEE INT CONF ROBOT, P3274, DOI [10.1109/icra.2019.8794264, 10.1109/ICRA.2019.8794264]
   Vander Hook J., 2020, 2020 IEEE AER C, P1
   Weber M, 2019, ARXIV PREPRINT ARXIV
NR 34
TC 4
Z9 4
U1 0
U2 0
PY 2021
UT WOS:000684604200046
DA 2023-11-16
ER

PT C
AU Geng, T
   Wu, CS
   Tan, C
   Fang, B
   Li, A
   Herbordt, M
AF Geng, Tong
   Wu, Chunshu
   Tan, Cheng
   Fang, Bo
   Li, Ang
   Herbordt, Martin
GP IEEE
TI CQNN: a CGRA-based QNN Framework
SO 2020 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 21-25, 2020
CL ELECTR NETWORK
DE QNN; CGRA; Accelerator; Machine Learning
AB Quantized Neural Networks (QNNs) have drawn tremendous attention since - when compared with Convolution Neural Networks (CNNs) - they often dramatically reduce computation, communication, and storage demands with negligible loss in accuracy. To find an optimal balance between performance and accuracy, developers use different data-widths for different layers and channels. Given this large parameter space, it is challenging to design a QNN accelerator which is generally efficient for various and flexible model configurations.
   In this paper we propose CQNN, a novel Coarse-Grained Reconfigurable Architecture-based (CGRA) QNN acceleration framework. CQNN has a large number of basic components for binary functions. By programming CQNN at runtime according to the target QNN model, these basic components are integrated to support QNN functions with any data-width and hyperparameter requirements. The result is an optimal QNN for the target model. The framework includes compiler, hardware design, simulator, and RTL generator. Experimental results show CQNNs can complete the inference of AlexNet and VGG-16 within 0.13ms and 2.63ms, respectively. We demonstrate the design on an FPGA platform; however, this is only for showcasing the method: the approach does not rely on any FPGA-specific features and can thus be implemented as ASIC as well.
C1 [Geng, Tong; Wu, Chunshu; Herbordt, Martin] Boston Univ, Boston, MA 02215 USA.
   [Tan, Cheng; Fang, Bo; Li, Ang] PNNL, Richland, WA USA.
RP Geng, T (corresponding author), Boston Univ, Boston, MA 02215 USA.
EM tgeng@bu.edu; happycwu@bu.edu; cheng.tan@pnnl.gov; bo.fang@pnnl.gov;
   ang.li@pnnl.gov; herbordt@bu.edu
CR [Anonymous], 2016, DOREFANET TRAINING L
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Courbariaux M, 2015, ADV NEUR IN, V28
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Geng T, 2021, IEEE T PARALL DISTR, V32, P199, DOI 10.1109/TPDS.2020.3013637
   Geng T, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P461, DOI 10.1145/3330345.3330386
   Geng T, 2019, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2019.00-43
   Geng T, 2018, I C FIELD PROG LOGIC, P394, DOI 10.1109/FPL.2018.00074
   Geng T, 2018, ANN IEEE SYM FIELD P, P81, DOI 10.1109/FCCM.2018.00021
   Ghasemzadeh M, 2018, ANN IEEE SYM FIELD P, P57, DOI 10.1109/FCCM.2018.00018
   Hubara I, 2018, J MACH LEARN RES, V18
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lam M., 2020, ARXIV PREPRINT ARXIV
   Li A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356169
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Micikevicius Paulius, 2017, P INT C LEARN REPR I
   Miyashita D., 2016, ARXIV PREPRINT ARXIV
   Park E, 2018, LECT NOTES COMPUT SC, V11208, P608, DOI 10.1007/978-3-030-01225-0_36
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang W, 2017, AAAI CONF ARTIF INTE, P2625
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.00881, 10.1109/CVPR.2019.01218]
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
NR 27
TC 12
Z9 12
U1 1
U2 1
PY 2020
DI 10.1109/hpec43674.2020.9286194
UT WOS:000674720500056
DA 2023-11-16
ER

PT J
AU Zabihi, M
   Resch, S
   Cilasun, H
   Chowdhury, ZI
   Zhao, ZY
   Karpuzcu, UR
   Wang, JP
   Sapatnekar, SS
AF Zabihi, Masoud
   Resch, Salonik
   Cilasun, Husrev
   Chowdhury, Zamshed, I
   Zhao, Zhengyang
   Karpuzcu, Ulya R.
   Wang, Jian-Ping
   Sapatnekar, Sachin S.
TI Exploring the Feasibility of Using 3-D XPoint as an In-Memory Computing
   Accelerator
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE Three-dimensional displays; Phase change materials; Arrays; Wires;
   Integrated circuit modeling; Heating systems; Computational modeling;
   3-D XPoint; in-memory computing; matrix-vector multiplication; neural
   network; phase-change memory (PCM)
ID DESIGN
AB This article describes how 3-D XPoint memory arrays can be used as in-memory computing accelerators. We first show that thresholded matrix-vector multiplication (TMVM), the fundamental computational kernel in many applications including machine learning (ML), can be implemented within a 3-D XPoint array without requiring data to leave the array for processing. Using the implementation of TMVM, we then discuss the implementation of a binary neural inference engine. We discuss the application of the core concept to address issues such as system scalability, where we connect multiple 3-D XPoint arrays, and power integrity, where we analyze the parasitic effects of metal lines on noise margins. To assure power integrity within the 3-D XPoint array during this implementation, we carefully analyze the parasitic effects of metal lines on the accuracy of the implementations. We quantify the impact of parasitics on limiting the size and configuration of a 3-D XPoint array, and estimate the maximum acceptable size of a 3-D XPoint subarray.
C1 [Zabihi, Masoud; Resch, Salonik; Cilasun, Husrev; Chowdhury, Zamshed, I; Zhao, Zhengyang; Karpuzcu, Ulya R.; Wang, Jian-Ping; Sapatnekar, Sachin S.] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.
RP Zabihi, M (corresponding author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.
EM zabih003@umn.edu
CR Agrawal N., 2008, P USENIX ANN TECH C, V8, P57, DOI DOI 10.1109/ISSCC.2012.6177101
   Beyer S, 2020, IEEE INT MEM WORKSH, P55, DOI 10.1109/imw48823.2020.9108150
   Burr GW, 2016, IEEE J EM SEL TOP C, V6, P146, DOI 10.1109/JETCAS.2016.2547718
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chien WC, 2018, IEEE T ELECTRON DEV, V65, P5172, DOI 10.1109/TED.2018.2871197
   Clark LT, 2017, P IEEE INT C MICRO, P1, DOI 10.1109/MSE.2017.7945071
   Clark LT, 2016, MICROELECTRON J, V53, P105, DOI 10.1016/j.mejo.2016.04.006
   Fernando BR, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206929
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Jain S, 2021, IEEE T COMPUT AID D, V40, P326, DOI 10.1109/TCAD.2020.3000185
   Jeong Y, 2018, IEEE T NANOTECHNOL, V17, P184, DOI 10.1109/TNANO.2017.2784364
   Kau D, 2009, INT EL DEVICES MEET, P571
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim Y, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900116
   Le Gallo M, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/ab7794
   LeCun Y., MNIST DATABASE HANDW
   Lee K, 2012, IEEE C ELEC DEVICES
   Liu MQ, 2017, I SYMPOS LOW POWER E
   Lou Q, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240767
   McAfee A, 2012, HARVARD BUS REV, V90, P60
   Murali GN, 2019, I CONF VLSI DESIGN, P500, DOI 10.1109/VLSID.2019.00106
   Murali GN, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), P124, DOI 10.1109/ISED.2018.8704015
   Shi LY, 2020, NANOSCALE ADV, V2, P1811, DOI 10.1039/d0na00100g
   Son K, 2020, IEEE T COMP PACK MAN, V10, P858, DOI 10.1109/TCPMT.2020.2984268
   Son K, 2019, ASIA PACIF MICROWAVE, P694, DOI [10.1109/apmc46564.2019.9038362, 10.1109/APMC46564.2019.9038362]
   Son K, 2018, 2018 IEEE SYMPOSIUM ON ELECTROMAGNETIC COMPATIBILITY, SIGNAL INTEGRITY AND POWER INTEGRITY (EMC, SI & PI), P223
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Wu J Y, 2011, IEEE International Electron Devices Meeting (IEDM), p3.2.1
   Wuttig M, 2007, NAT MATER, V6, P824, DOI 10.1038/nmat2009
   Xu N, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900082
   Yang JF, 2020, ACM TRANS MODELING P, V5, DOI 10.1145/3372783
   Zabihi M, 2020, IEEE J EXPLOR SOLID-, V6, P71, DOI 10.1109/JXCDC.2020.2985314
   Zheng QH, 2017, J PHYS D APPL PHYS, V50, DOI 10.1088/1361-6463/aa70b0
NR 34
TC 2
Z9 2
U1 0
U2 1
PD DEC
PY 2021
VL 7
IS 2
BP 88
EP 96
DI 10.1109/JXCDC.2021.3112238
UT WOS:000707441000001
DA 2023-11-16
ER

PT C
AU Papadimitriou, M
   Markou, E
   Fumero, J
   Stratikopoulos, A
   Blanaru, F
   Kotselidis, C
AF Papadimitriou, Michail
   Markou, Eleni
   Fumero, Juan
   Stratikopoulos, Athanasios
   Blanaru, Florin
   Kotselidis, Christos
BE Titzer, B
   Xu, H
   Zhang, I
TI Multiple-Tasks on Multiple-Devices (MTMD): Exploiting Concurrency in
   Heterogeneous Managed Runtimes
SO PROCEEDINGS OF THE 17TH ACM SIGPLAN/SIGOPS INTERNATIONAL CONFERENCE ON
   VIRTUAL EXECUTION ENVIRONMENTS (VEE '21)
DT Proceedings Paper
CT 17th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution
   Environments (VEE)
CY APR 16, 2021
CL ELECTR NETWORK
DE JVM; Heterogeneous Hardware; Bytecodes; Multi-threading
AB Modern commodity devices are nowadays equipped with a plethora of heterogeneous devices serving different purposes. Being able to exploit such heterogeneous hardware accelerators to their full potential is of paramount importance in the pursuit of higher performance and energy efficiency. Towards these objectives, the reduction of idle time of each device as well as the concurrent program execution across different accelerators can lead to better scalability within the computing platform.
   In this work, we propose a novel approach for enabling a Java-based heterogeneous managed runtime to automatically and efficiently deploy multiple tasks on multiple devices. We extend TornadoVM with parallel execution of bytecode interpreters to dynamically and concurrently manage and execute arbitrary tasks across multiple OpenCL-compatible devices. In addition, in order to achieve an efficient device-task allocation, we employ a machine learning approach with a multiple-classification architecture of Extra-Trees-Classifiers. Our proposed solution has been evaluated over a suite of 12 applications split into three different groups. Our experimental results showcase performance improvements up 83% compared to all tasks running on the single best device, while reaching up to 91% of the oracle performance.
C1 [Papadimitriou, Michail; Fumero, Juan; Stratikopoulos, Athanasios; Blanaru, Florin; Kotselidis, Christos] Univ Manchester, Manchester, Lancs, England.
   [Markou, Eleni] BEAT, Thessaloniki, Greece.
RP Papadimitriou, M (corresponding author), Univ Manchester, Manchester, Lancs, England.
EM michail.papadimitriou@manchester.ac.uk; e.markou@thebeat.co;
   juan.fumero@manchester.ac.uk;
   athanasios.stratikopoulos@manchester.ac.uk;
   florin.blanaru@manchester.ac.uk; christos.kotselidis@manchester.ac.uk
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Aji AM, 2016, PARALLEL COMPUT, V58, P37, DOI 10.1016/j.parco.2016.05.006
   Al Umairy Shams A. H., 2012, COMPUTER ARCHITECTUR, DOI [10.1007/978-3-642-24322-6_6, DOI 10.1007/978-3-642-24322-6_6]
   AMD, AP PROJ
   [Anonymous], 2013, P 27 INT ACM C INT C
   Baldini Ioana, 2014, 2014 IEEE 26th International Symposium on Computer Architecture and High-Performance Computing (SBAC-PAD), P254, DOI 10.1109/SBAC-PAD.2014.30
   Boyd Kendrick, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P451, DOI 10.1007/978-3-642-40994-3_29
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Braun L, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3431731
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   Clarkson James, 2018, P 15 INT C MANAGED L, DOI [10.1145/3237009.3237016, DOI 10.1145/3237009.3237016]
   Clarkson James, 2018, C COMPANION 2 INT C, DOI [10.1145/3191697.3191730, DOI 10.1145/3191697.3191730]
   CLICK C, 1995, SIGPLAN NOTICES, V30, P35, DOI 10.1145/202530.202534
   Cook S, 2012, CUDA PROGRAMMING DEV
   Duboscq Gilles, 2013, P 7 ACM WORKSHO VIRT, P1, DOI [10.1145/2542142.2542143, DOI 10.1145/2542142.2542143]
   Farris FA, 2010, AM MATH MON, V117, P851, DOI 10.4169/000298910X523344
   Fumero Juan, 2019, P 15 ACM SIGPLANSIGO, P165, DOI [10, DOI 10.1145/3313808.3313819]
   Garcia VM, 2011, COMPUT CARDIOL CONF, V38, P233
   Georges A, 2007, ACM SIGPLAN NOTICES, V42, P57, DOI 10.1145/1297105.1297033
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Ghose A, 2020, Arxiv, DOI arXiv:2009.07482
   Govindaraju Naga K, 2008, SC 08 P OF THE 2008, P1, DOI [DOI 10.1109/SC.2008.5213922, 10.1109/SC.2008.5213922]
   Grauer-Gray S., 2013, P 6 WORKSHOP GEN PUR, P127, DOI DOI 10.1145/2458523.2458536
   Grewe D, 2013, INT SYM CODE GENER, P161
   Grewe Dominik, 2011, LECT NOTES COMPUT SC
   Henry Sylvain, 2013, RR8346 INRIA
   Huseinovic A., 2015, 23 TELECOMMUNICATION, DOI [10.1109/TELFOR.2015.7377632, DOI 10.1109/TELFOR.2015.7377632]
   Huynh HP, 2012, ACM SIGPLAN NOTICES, V47, P1, DOI 10.1145/2370036.2145818
   IBM, US
   Intel, ONEAPI SPEC
   Ionescu V. M, 2017, 9 INT C ELECT COMPUT, DOI [10.1109/ECAI.2017.8166501, DOI 10.1109/ECAI.2017.8166501]
   Jordan H, 2013, INT CONFER PARA, P7, DOI 10.1109/PACT.2013.6618799
   Khalid YN, 2019, J PARALLEL DISTR COM, V132, P79, DOI 10.1016/j.jpdc.2019.05.015
   Kim Jungwon, 2012, P 26 ACM INT C SUP I, P341, DOI DOI 10.1145/2304576.2304623
   Kotselidis C, 2017, ACM SIGPLAN NOTICES, V52, P74, DOI [10.1145/3050748.3050764, 10.1145/3140607.3050764]
   Nardi L, 2015, IEEE INT CONF ROBOT, P5783, DOI 10.1109/ICRA.2015.7140009
   Nozal Raul, 2019, 2019 International Conference on High Performance Computing & Simulation (HPCS), P628, DOI 10.1109/HPCS48598.2019.9188188
   Ogilvie William F., 2015, COMPUTING JAMES LANG
   Ohshima Satoshi, 2018, LECT NOTES COMPUT SC
   Pandit Prasanna, 2014, P IEEE ACM INT S COD, DOI [10.1145/2581122.2544163, DOI 10.1145/2581122.2544163]
   Papadimitriou M, 2019, ANN IEEE SYM FIELD P, P310, DOI 10.1109/FCCM.2019.00051
   Papadimitriou Michail, 2020, ART SCI ENG PROGRAM, V5, P2, DOI [10.22152/programming-journal.org/2021/5/8, DOI 10.22152/PROGRAMMING-JOURNAL.ORG/2021/5/8]
   Parravicini A, 2021, Arxiv, DOI arXiv:2012.09646
   Playne D. P., 2009, Proceedings of the 2009 International Conference on Computer Design. CDES 2009, P150
   Rubinstein RY, 2016, SIMULATION MONTE CAR
   Singh AK, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126548
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Udupa A, 2009, INT SYM CODE GENER, P200, DOI 10.1109/CGO.2009.20
   Volkov Vasily, 2008, 2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis, DOI 10.1109/SC.2008.5214359
   Wen Y, 2014, INT C HIGH PERFORM
   You YP, 2015, ACM SIGPLAN NOTICES, V50, P161, DOI [10.1145/2858788.2688505, 10.1145/2688500.2688505]
NR 53
TC 2
Z9 2
U1 0
U2 3
PY 2021
BP 125
EP 138
DI 10.1145/3453933.3454019
UT WOS:000933131100010
DA 2023-11-16
ER

PT C
AU Taher, FN
   Balachandran, A
   Schafer, BC
AF Taher, Farah Naz
   Balachandran, Anjana
   Schafer, Benjamin Carrion
GP IEEE
TI Learning-based Diversity Estimation: Leveraging the Power of High-level
   Synthesis to mitigate Common-mode Failure
SO 2019 IEEE 37TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2019)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 37th IEEE International Conference on Computer Design (ICCD)
CY NOV 17-20, 2019
CL New York Univ Abu Dhabi, Abu Dhabi, U ARAB EMIRATES
HO New York Univ Abu Dhabi
DE Common Mode Failure; Diversity; High-Level Synthesis; Design Space
   Exploration; Predictive Modeling; Machine Learning
AB Hardware redundancy techniques are extensively used for enhancing system reliability, availability and fault tolerance. However, traditional identical module N-modular redundancy (NMR) cannot protect against Common Mode Failures (CMFs). One method that has been proposed to protect against CMFs is the use of dissimilar (diverse) module redundancy. One of the problems with previous work is that it generates these diverse modules by perturbing the gate-netlist and thus, achieve very limited diversity. In addition, previous work is very time consuming as it requires to insert fault-pairs in the gate-netlists in order to measure the effect of these on the outputs. To address these issues, this work proposes to first increase diversity by raising the level of abstraction from the gate level to the behavioral level. Secondly, we propose a fast machine learning based method that facilitates the design space exploration (DSE) of single behavioral descriptions in order to generate optimized redundant hardware accelerator system with maximum diversity to protect against CMFs. For this purpose, this work exploits one of the main advantages of C-based VLSI design: The ability to generate micro-architectures with unique characteristics from the same behavioral description by setting different synthesis directives in the form of pragmas. Experimental results show that our proposed method is a fast and efficient way to generate diverse designs to protect the system against CMFs.
C1 [Taher, Farah Naz; Schafer, Benjamin Carrion] Univ Texas Dallas, Richardson, TX 75080 USA.
   [Balachandran, Anjana] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
RP Taher, FN (corresponding author), Univ Texas Dallas, Richardson, TX 75080 USA.
EM farah.taher@utdallas.edu; anjana.balachandran@polyu.hk;
   schaferb@utdallas.edu
CR Aitken A., 1978, TECH REP
   Alcaide S, 2017, DES AUT CON, DOI 10.1145/3061639.3062231
   Avizienis A., 1977, P COMPSAC
   Cohen F. B., 1993, COMPUTERS SECURITY
   Ferrandi Fabrizio, 2008, IEEE COMP SOC ANN S
   Hall M., 2009, ACM SIGKDD EXPLORATI
   Höller A, 2015, DES AUT TEST EUROPE, P531
   McCluskey E., 1986, LOGIC DESIGN PRINCIP
   Mitra S., 2000, INT TEST C ITC
   Mitra S., 2004, IEEE T COMPUTERS
   Mitra S., 2008, DESIGN AUTOMATION TE
   Mitra S., 1999, INT TEST C ITC
   Mitra S., 2002, IEEE T COMPUTERS
   Mitra S., 2000, IEEE T RELIABILITY
   Schafer Benjamin Carrion, 2014, IEEE EMBEDDED SYSTEM
   Shivakumar P, 2002, INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS, PROCEEDINGS, P389, DOI 10.1109/DSN.2002.1028924
   Taher FN, 2019, DES AUT TEST EUROPE, P1563, DOI [10.23919/date.2019.8714816, 10.23919/DATE.2019.8714816]
   Ubar R, 2011, ADV COMPUT ELECTR EN, P1, DOI 10.4018/978-1-60960-212-3
NR 18
TC 0
Z9 0
U1 0
U2 2
PY 2019
BP 460
EP 467
DI 10.1109/ICCD46524.2019.00071
UT WOS:000542037800061
DA 2023-11-16
ER

PT J
AU Kwon, SI
   Regan, A
   Wang, YM
AF Kwon, SI
   Regan, A
   Wang, YM
TI SNS superconducting RF cavity modeling-iterative learning control
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE spallation neutron source; pulsed machine; superconducting RF cavity;
   feedback control; feedforward control; iterative
AB The Spallation Neutron Source (SNS) Superconducting RF (SRF) linear accelerator is operated A it It it pulsed beam. For the SRF control system to track the repetitive electromagnetic held reference trajectory. both feedback and feedforward controllers have been proposed, The feedback controller is utilized to guarantee the closed loop system stability and the feedforward controller is used to improve the tracking performance for the repetitive reference trajectory and to suppress repetitive disturbances. As the iteration number increases, the feedforward controller decreases the tracking error. Numerical simulations demonstrate that inclusion of the feedforward controller significantly improves the control system performance over its performance with just the feedback controller. (C) 2002 Published by Elsevier Science B.V.
C1 Los Alamos Natl Lab, SNS Div, RF Technol Grp, Los Alamos, NM 87544 USA.
RP Kwon, SI (corresponding author), Los Alamos Natl Lab, SNS Div, RF Technol Grp, SNS-2,POB 1663, Los Alamos, NM 87544 USA.
CR Amann N, 1996, INT J ADAPT CONTROL, V10, P767, DOI 10.1002/(SICI)1099-1115(199611)10:6<767::AID-ACS420>3.0.CO;2-L
   [Anonymous], 1994, LINEAR MATRIX INEQUA
   [Anonymous], ITERATIVE LEARNING C
   ARIMOTO S, 1984, J ROBOTIC SYST, V1, P123, DOI 10.1002/rob.4620010203
   CHEO BR, 1991, IEEE T ELECTRON DEV, V38, P2264, DOI 10.1109/16.88508
   FORTGANG CM, 1990, REV SCI INSTRUM, V61, P3405, DOI 10.1063/1.1141592
   HARA S, 1988, IEEE T AUTOMAT CONTR, V33, P659, DOI 10.1109/9.1274
   HOROWITZ R, 1991, IEEE T AUTOMAT CONTR, V36, P890, DOI 10.1109/9.85074
   PADAMSEE H, 1998, SUPERCONDUCTIVITY AC
   Zhou K., 1996, ROBUST OPTIMAL CONTR
NR 10
TC 6
Z9 7
U1 0
U2 1
PD APR 11
PY 2002
VL 482
IS 1-2
BP 12
EP 31
AR PII S0168-9002(01)01514-5
DI 10.1016/S0168-9002(01)01514-5
UT WOS:000175483400002
DA 2023-11-16
ER

PT J
AU Judd, P
   Albericio, J
   Hetherington, T
   Aamodt, T
   Jerger, NE
   Urtasun, R
   Moshovos, A
AF Judd, Patrick
   Albericio, Jorge
   Hetherington, Tayler
   Aamodt, Tor
   Jerger, Natalie Enright
   Urtasun, Raquel
   Moshovos, Andreas
TI Proteus: Exploiting precision variability in deep neural networks
SO PARALLEL COMPUTING
DT Article
DE Machine learning; Neural networks; Deep learning; Accelerators;
   Approximate computing; Reduced precision
AB This work investigates how using reduced precision data in Deep Neural Networks (DNNs) affects network accuracy during classification. We observe that the tolerance of DNNs to reduced precision data not only varies across networks, but also within networks. We study how error tolerance across layers varies and propose a method for finding a low precision configuration for a network while maintaining high accuracy.
   To exploit these low precision configurations, this work proposes PROTEUS, which reduces the data traffic and storage footprint needed by DNNs, resulting in reduced energy for DNN implementations. Nal-m.1s uses a different representation per layer for both the data (neuron activations) and the weights (synapses) processed by DNNs. PROTEUS is a layered extension over existing DNN implementations that maintains the native precision of the compute engine by converting to and from a fixed-point reduced precision format used in memory. PROTEUS uses a novel memory layout, enabling a simple, low-cost and low-energy conversion unit.
   We evaluate PROTEUS as an extension to a state-of-the-art accelerator [1] which uses a uniform 16-bit fixed-point representation. On five popular Convolutional Neural Networks (CNNs) and during inference PROTEUS reduces data traffic by 43% on average while maintaining accuracy within 1% compared to the full precision baseline. As a result, PROTEUS improves energy by 15% with no performance loss. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Judd, Patrick; Albericio, Jorge; Jerger, Natalie Enright; Moshovos, Andreas] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Hetherington, Tayler; Aamodt, Tor] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
   [Urtasun, Raquel] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
   [Albericio, Jorge] Univ Toronto, Toronto, ON, Canada.
RP Judd, P (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM juddpatr@ece.utoronto.ca; jalbericiola@nvidia.com; taylerh@ece.ubc.ca;
   aamodt@ece.ubc.ca; enright@ece.utoronto.ca; urtasun@cs.utoronto.edu;
   moshovos@ece.utoronto.ca
CR [Anonymous], 2014, ARXIV14090575CS
   [Anonymous], 2016, CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2015, NIPS
   [Anonymous], 2015, CAFFE MODEL ZOO
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], J DAIRY SCI, DOI DOI 10.1109/MICR0.2014.58
   [Anonymous], 2013, CORR
   [Anonymous], 2015, CORR
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   ASANOVIC K, 1993, J VLSI SIGNAL PROC, V6, P33, DOI 10.1007/BF01581957
   Buck I., 2015, NVIDIAS NEXT GEN PAS
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chippa V.K., 2013, P 50 ACM EDAC IEEE D, P1, DOI [DOI 10.1145/2463209.2488873, 10.1145/2463209.2488873]
   Girshick R., 2014, P P IEEE C COMP VIS
   Holt J. L., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P121, DOI 10.1109/IJCNN.1991.155324
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Jain A., 2016, P 2016 49 ANN IEEE A
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jonghong Kim, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7510, DOI 10.1109/ICASSP.2014.6855060
   Krizhevsky A., 2011, CUDA CONVNET HIGH PE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larkin D, 2006, LECT NOTES COMPUT SC, V4234, P1178
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Muralimanohar N., CACTI 6 0 TOOL UNDER
   Poremba M, 2015, DES AUT TEST EUROPE, P1543
   PRESLEY RK, 1994, SOUTHEASTCON '94 - CREATIVE TECHNOLOGY TRANSFER - A GLOBAL AFFAIR, P136, DOI 10.1109/SECON.1994.324283
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Seide F, 2014, INTERSPEECH, P1058
   Strey A., 1996, Euro-Par '96 Parallel Processing. Second International Euro-Par Conference. Proceedings, P470, DOI 10.1007/BFb0024738
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Xie Y., 1991, TRAINING ALGORITHMS
NR 36
TC 9
Z9 9
U1 0
U2 27
PD APR
PY 2018
VL 73
SI SI
BP 40
EP 51
DI 10.1016/j.parco.2017.05.003
UT WOS:000428486700005
DA 2023-11-16
ER

PT J
AU Pombo, N
   Araújo, P
   Viana, J
AF Pombo, Nuno
   Araujo, Pedro
   Viana, Joaquim
TI Applied computer technologies in clinical decision support systems for
   pain management: A systematic review
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
DT Review
DE Clinical decision support system; pain measurement; medical informatics;
   machine learning
ID MACHINE LEARNING TECHNIQUES; ACUTE MYOCARDIAL-INFARCTION; ACUTE
   ABDOMINAL-PAIN; CHEST-PAIN; MEDICAL DIAGNOSIS; RULE INDUCTION;
   EXPERT-SYSTEM; ACI-TIPI; TRIAGE; CLASSIFICATION
AB Millions of people around the world suffer from pain, acute or chronic and this raises the importance of its screening, assessment and treatment. Pain, is highly subjective and the use of clinical decision support systems (CDSSs) can play an important part in improving the accuracy of pain assessment, and lead to better clinical practices. This review examines CDSSs, in relation to computer technologies and was conducted with the following electronic databases: CiteSeer(x), IEEE Xplore, ISI Web of Knowledge, Mendeley, Microsoft Academic Search, PubMed, Science Accelerator, Science. gov, ScienceDirect, SpringerLink, and The Cochrane Library. The studies referenced were compiled with several criteria in mind. Firstly, that they constituted a decision support system. Secondly, that study data included pain values or results based on the detection of pain. Thirdly, that they were published in English, between 1992 and 2011, and finally that they focused on patients with acute or chronic pain. In total, thirty-nine studies highlighted the following topics: rule based algorithms, artificial neural networks, rough and fuzzy sets, statistical learning algorithms, terminologies, questionnaires and scores. The median accuracy ranged from 53% to 87.5%. The lack of integration with mobile devices, the limited use of web-based interfaces and the scarcity of systems that allow for data to be inserted by patients were all limitations that were detected.
C1 [Pombo, Nuno; Araujo, Pedro] Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
   [Pombo, Nuno; Araujo, Pedro] Univ Beira Interior, Dept Informat, Covilha, Portugal.
   [Viana, Joaquim] Univ Beira Interior, Fac Hlth Sci, Covilha, Portugal.
RP Pombo, N (corresponding author), Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
EM ngpombo@ubi.pt
CR Aase O, 1999, CARDIOLOGY, V92, P128, DOI 10.1159/000006960
   Abad-Grau MM, 2008, J BIOMED INFORM, V41, P432, DOI 10.1016/j.jbi.2008.01.007
   Abas H. I., 2011, 2011 International Conference on Semantic Technology and Information Retrieval (STAIR 2011), P106, DOI 10.1109/STAIR.2011.5995773
   AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1007/BF00153759
   [Anonymous], P P 37 ANN HAW INT C
   [Anonymous], IEE C KNOWL DISC DAT
   [Anonymous], 2007, CLIN DECIS SUPPORT S, DOI [DOI 10.1007/978-0-387-38319-4_4, 10.1007/978-0-387-38319-4_4]
   [Anonymous], AMIA ANN S P
   [Anonymous], 2006, BIOMEDICAL INFORM CO
   [Anonymous], 2005, SERVICE ORIENTED ARC
   [Anonymous], P 6 EUR KNOWL ACQ WO
   [Anonymous], PARAMETER ADJUSTMENT
   [Anonymous], 2007, CLIN DECISION SUPPOR
   [Anonymous], 1994, IASP PAIN TERMINOLOG
   [Anonymous], 1990, P READ UNC
   [Anonymous], P 11 ANN INT WORKSH
   [Anonymous], ONTOLOGY DRIVEN CARD
   [Anonymous], 35 ANN M DEC SCI I B
   [Anonymous], 1998, J TELECOMMUN INF TEC
   [Anonymous], METHODS INFORM MED
   [Anonymous], P 18 C UNC ART INT S
   [Anonymous], 2011, REL PAIN AM BLUEPR T
   [Anonymous], 1986, 5 NAT C ART INT
   [Anonymous], 2013, ITEM RESPONSE THEORY, DOI DOI 10.1007/978-94-017-1988-9_3
   [Anonymous], TI TI MANUAL NEWID V
   Apkarian AV, 2009, PROG NEUROBIOL, V87, P81, DOI 10.1016/j.pneurobio.2008.09.018
   Ashburn MA, 1999, LANCET, V353, P1865, DOI 10.1016/S0140-6736(99)04088-X
   Ball MJ, 2003, INT J MED INFORM, V69, P83, DOI 10.1016/S1386-5056(02)00098-9
   Baxt WG, 2002, ANN EMERG MED, V39, P366, DOI 10.1067/mem.2002.122705
   Binaghi E, 2008, INT J MED INFORM, V77, P256, DOI 10.1016/j.ijmedinf.2007.06.004
   Blaszczynski J, 2005, LECT NOTES ARTIF INT, V3581, P429
   Blazadonakis M, 1996, ARTIF INTELL MED, V8, P527, DOI 10.1016/S0933-3657(96)00354-5
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605
   Bramer M, 2002, KNOWL-BASED SYST, V15, P301, DOI 10.1016/S0950-7051(01)00163-0
   Breiman LF., 1983, CLASSIFICATION REGRE
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Camargo LS, 2001, NEURAL COMPUT, V13, P2673, DOI 10.1162/089976601317098484
   CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2
   Chang CH, 2007, J PAIN SYMPTOM MANAG, V33, P745, DOI 10.1016/j.jpainsymman.2006.09.018
   Cimino JJ, 2006, METHOD INFORM MED, V45, P124
   Clark P., 1989, Machine Learning, V3, P261, DOI 10.1007/BF00116835
   Clarke EJ, 1996, COMPUT BIOMED RES, V29, P271, DOI 10.1006/cbmr.1996.0020
   Cole TJ, 1991, STAT MED, V10, P1162, DOI 10.1002/sim.4780100718
   de Lima L. R. S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P132, DOI 10.1145/288627.288649
   DOMBI J, 1990, FUZZY SET SYST, V35, P1, DOI 10.1016/0165-0114(90)90014-W
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Eich HP, 1997, COMP MED SY, P2, DOI 10.1109/CBMS.1997.596400
   Ellenius J, 1997, CLIN CHEM, V43, P1919
   Ellenius J, 2000, INT J MED INFORM, V60, P1, DOI 10.1016/S1386-5056(00)00064-2
   Elomaa T, 1999, LECT NOTES COMPUT SC, V1642, P63
   Elvidge K, 2008, ST HEAL T, V136, P169
   Farion K, 2004, LECT NOTES ARTIF INT, V3066, P805
   Farion K, 2009, METHOD INFORM MED, V48, P381, DOI 10.3414/ME0574
   Farion KJ, 2008, INT J MED INFORM, V77, P208, DOI 10.1016/j.ijmedinf.2007.01.004
   FATHITORBAGHAN M, 1994, METHOD INFORM MED, V33, P522
   Forrey AW, 1996, CLIN CHEM, V42, P81
   Gamberger D, 1995, LECT NOTES ARTIF INT, V912, P151
   Giordano J, 2010, PAIN PHYSICIAN, V13, P305
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   HANSEL D, 1990, EUROPHYS LETT, V11, P687, DOI 10.1209/0295-5075/11/7/018
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed.
   Hayes B, 2008, COMMUN ACM, V51, P9, DOI [10.1145/1364782.1364786, 10.1145/1364782.1364789]
   Heckerman D., 1995, TUTORIAL LEARNING BA
   Lu HM, 2006, IEEE SYS MAN CYBERN, P1137, DOI 10.1109/ICSMC.2006.384553
   Hu XHT, 2003, LECT NOTES ARTIF INT, V2639, P114
   Hu XH, 2006, 2006 IEEE International Conference on Granular Computing, P67
   Huang HY, 2003, CIN-COMPUT INFORM NU, V21, P206, DOI 10.1097/00024665-200307000-00011
   Hunt DL, 1998, JAMA-J AM MED ASSOC, V280, P1339, DOI 10.1001/jama.280.15.1339
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Jurgelenaite R, 2006, LECT NOTES COMPUT SC, V4212, P234
   Kennedy RL, 1997, COMPUT METH PROG BIO, V52, P93, DOI 10.1016/S0169-2607(96)01782-8
   Khemphila A., 2010, 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM 2010), P193, DOI 10.1109/CISIM.2010.5643666
   Kon MA, 2000, NEURAL NETWORKS, V13, P365, DOI 10.1016/S0893-6080(00)00015-0
   Kong GL, 2012, EUR J OPER RES, V219, P564, DOI 10.1016/j.ejor.2011.10.044
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Kotsiantis SB, 2006, ARTIF INTELL REV, V26, P159, DOI [10.1007/s10462-007-9052-3, 10.1007/S10462-007-9052-3]
   Lai DTH, 2007, P ANN INT IEEE EMBS, P3144, DOI 10.1109/IEMBS.2007.4352996
   Lee YY, 2006, COMPUT BIOL MED, V36, P893, DOI 10.1016/j.compbiomed.2005.04.013
   Li HX, 2012, INT J APPROX REASON, V53, P24, DOI 10.1016/j.ijar.2011.09.002
   Lin L, 2006, DECIS SUPPORT SYST, V42, P1152, DOI 10.1016/j.dss.2005.10.007
   Loeser JD, 2008, PAIN, V137, P473, DOI 10.1016/j.pain.2008.04.025
   Lorena AC, 2011, EXPERT SYST APPL, V38, P5268, DOI 10.1016/j.eswa.2010.10.031
   LOWE HJ, 1994, JAMA-J AM MED ASSOC, V271, P1103, DOI 10.1001/jama.271.14.1103
   Lu HM, 2008, J BIOMED INFORM, V41, P340, DOI 10.1016/j.jbi.2007.08.009
   Macdonald G, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001930.pub3
   MELZACK R, 1975, PAIN, V1, P277, DOI 10.1016/0304-3959(75)90044-5
   Merboth MK, 2000, NURS CLIN N AM, V35, P375
   Meyfroidt G, 2009, BEST PRAC RES-CL ANA, V23, P127, DOI 10.1016/j.bpa.2008.09.003
   Michalowski W, 2005, INFOR, V43, P287
   Michalowski W, 2005, METHOD INFORM MED, V44, P14
   Midboe AM, 2011, TRANSL BEHAV MED, V1, P35, DOI 10.1007/s13142-011-0022-6
   Ohmann C, 1996, ARTIF INTELL MED, V8, P23, DOI 10.1016/0933-3657(95)00018-6
   Pasero CL, 1997, AM J NURS, V97, P15, DOI 10.2307/3465480
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pesonen E, 1998, ARTIF INTELL MED, V13, P139, DOI 10.1016/S0933-3657(98)00027-X
   Pombo N, 2012, LECT NOTES ENG COMP, P589
   Quinlan J., 2014, C4 5 PROGRAMS MACHIN
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Ramey D R, 1992, Arthritis Care Res, V5, P119, DOI 10.1002/art.1790050303
   Roshanov PS, 2011, IMPLEMENT SCI, V6, DOI [10.1186/1748-5908-6-88, 10.1186/1748-5908-6-92]
   Rosser BA, 2011, J TELEMED TELECARE, V17, P308, DOI 10.1258/jtt.2011.101102
   Sadeghi S, 2006, INT J MED INFORM, V75, P403, DOI 10.1016/j.ijmedinf.2005.07.028
   Selker HP, 1998, ANN INTERN MED, V129, P845, DOI 10.7326/0003-4819-129-11_Part_1-199812010-00002
   Simonic K. M., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P550, DOI 10.4108/icst.pervasivehealth.2011.246087
   Smith MY, 2007, PAIN MED, V8, pS155, DOI 10.1111/j.1526-4637.2007.00278.x
   SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926
   Stone Arthur S., 1994, Annals of Behavioral Medicine, V16, P199
   Tan KC, 2009, EXPERT SYST APPL, V36, P8616, DOI 10.1016/j.eswa.2008.10.013
   van Gerven MAJ, 2008, J BIOMED INFORM, V41, P515, DOI 10.1016/j.jbi.2008.01.006
   van Gerven MAJ, 2007, ARTIF INTELL MED, V40, P45, DOI 10.1016/j.artmed.2006.09.003
   VANDERHEIJDE DMFM, 1990, ANN RHEUM DIS, V49, P916, DOI 10.1136/ard.49.11.916
   Vapnik Vladimir, 1999, NATURE STAT LEARNING
   Wainer, 2000, COMPUTERIZED ADAPTIV
   Wan Yina, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P60, DOI 10.1109/MMIT.2010.32
   Wang AY, 2001, J AM MED INFORM ASSN, P741
   Wang MS, 2004, IEEE T INF TECHNOL B, V8, P287, DOI 10.1109/TITB.2004.834397
   Wang SJ, 2001, COMPUT BIOL MED, V31, P1, DOI 10.1016/S0010-4825(00)00022-6
   Westfall JM, 2006, ANN FAM MED, V4, P153, DOI 10.1370/afm.403
   Wilkie DJ, 2003, J PAIN SYMPTOM MANAG, V25, P213, DOI 10.1016/S0885-3924(02)00638-3
   Yaguinuma CA, 2010, IEEE INT ENTERP, P263, DOI 10.1109/EDOCW.2010.41
   Yang JL, 2011, EXPERT SYST APPL, V38, P9346, DOI 10.1016/j.eswa.2011.01.106
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   ZWICK R, 1989, INT J MAN MACH STUD, V30, P69, DOI 10.1016/S0020-7373(89)80021-5
NR 125
TC 2
Z9 2
U1 0
U2 36
PY 2014
VL 26
IS 5
BP 2411
EP 2425
DI 10.3233/IFS-130912
UT WOS:000334211500029
DA 2023-11-16
ER

PT C
AU Henry, G
   Palangpour, P
   Thomson, M
   Gardner, JS
   Arden, B
   Donahue, J
   Houck, K
   Johnson, J
   O'Brien, K
   Petersen, S
   Seroussi, B
   Walker, T
AF Henry, Glenn
   Palangpour, Parviz
   Thomson, Michael
   Gardner, J. Scott
   Arden, Bryce
   Donahue, Jim
   Houck, Kimble
   Johnson, Jonathan
   O'Brien, Kyle
   Petersen, Scott
   Seroussi, Benjamin
   Walker, Tyler
GP IEEE
TI High-Performance Deep-Learning Coprocessor Integrated into x86 SoC with
   Server-Class CPUs
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
AB Demand for high performance deep learning (DL) inference in software applications is growing rapidly. DL workloads run on myriad platforms, including general purpose processors (CPU), system-on-chip (SoC) with accelerators, graphics processing units (GPU), and neural processing unit (NPU) add-in cards. DL software engineers typically must choose between relatively slow general hardware (e.g., CPUs, SoCs) or relatively expensive, large, power-hungry hardware (e.g., GPUs, NPUs).
   This paper describes Centaur Technology's Ncore, the industry's first high-performance DL coprocessor technology integrated into an x86 SoC with server-class CPUs. Ncore's 4096 byte-wide SIMD architecture supports INT8, UINT8, INT16, and BF16 datatypes, with 20 tera-operations-per-second compute capability. Ncore shares the SoC ring bus for low-latency communication and work sharing with eight 64-bit x86 cores, offering flexible support for new and evolving models. The x86 SoC platform can further scale out performance via multiple sockets, systems, or third-party PCIe accelerators. Ncore's software stack automatically converts quantized models for Ncore consumption and leverages existing DL frameworks.
   In MLPerf's Inference v0.5 closed division benchmarks, Ncore achieves 1218 IPS throughput and 1.05ms latency on ResNet-50v1.5 and achieves lowest latency of all Mobilenet-V1 submissions (329 mu s). Ncore yields 23x speedup over other x86 vendor percore throughput, while freeing its own x86 cores for other work. Ncore is the only integrated solution among the memory intensive neural machine translation (NMT) submissions.
C1 [Henry, Glenn; Palangpour, Parviz; Thomson, Michael; Arden, Bryce; Donahue, Jim; Houck, Kimble; Johnson, Jonathan; O'Brien, Kyle; Petersen, Scott; Seroussi, Benjamin; Walker, Tyler] Centaur Technol, Austin, TX 78731 USA.
   [Gardner, J. Scott] Advantage Engn LLC, Columbia, MD USA.
RP Henry, G (corresponding author), Centaur Technol, Austin, TX 78731 USA.
CR Abadi M, 2015, PRELIMINARY WHITE PA
   [Anonymous], 2018, DEEP LEARNING INFERE
   [Anonymous], 2019, STUDY BFLOAT16 DEEP
   [Anonymous], 2019, HERALD OPTIMIZING HE
   [Anonymous], 2019, 2019 IEEE HOT CHIPS
   [Anonymous], 2017, 2017 IEEE HOT CHIPS
   [Anonymous], 2019, INT XEON PLAT 9282 P
   [Anonymous], 2016, ICLR
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Intel Corporation, 2019, INT 64 IA 32 ARCH OP
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lattner Chris, 2019, MLIR PRIMER COMPILER
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Ovtcharov K., 2015, MICROSOFT RES WHITEP, V2, P1
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Wang Y. E., 2019, BENCHMARKING TPU GPU
   Zhang C, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI), P158, DOI 10.1109/BMEI.2015.7401492
NR 26
TC 3
Z9 3
U1 0
U2 0
PY 2020
BP 15
EP 26
DI 10.1109/ISCA45697.2020.00013
UT WOS:000617734800002
DA 2023-11-16
ER

PT J
AU Xu, HJ
   Shiomi, J
   Onodera, H
AF Xu, Hongjie
   Shiomi, Jun
   Onodera, Hidetoshi
TI Evaluation Metrics for the Cost of Data Movement in Deep Neural Network
   Acceleration
SO IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND
   COMPUTER SCIENCES
DT Article
DE convolutional neural networks; machine learning; low power circuit
   design; VLSI; parallel processing
AB Hardware accelerators are designed to support a specialized processing dataflow for everchanging deep neural networks (DNNs) under various processing environments. This paper introduces two hardware properties to describe the cost of data movement in each memory hierarchy. Based on the hardware properties, this paper proposes a set of evaluation metrics that are able to evaluate the number of memory accesses and the required memory capacity according to the specialized processing dataflow. Proposed metrics are able to analytically predict energy, throughput, and area of a hardware design without detailed implementation. Once a processing dataflow and constraints of hardware resources are determined, the proposed evaluation metrics quickly quantify the expected hardware benefits, thereby reducing design time.
C1 [Xu, Hongjie] Kyoto Univ, Commun & Comp Engn, Kyoto 6068501, Japan.
   [Shiomi, Jun; Onodera, Hidetoshi] Kyoto Univ, Dept Commun & Comp Engn, Grad Sch Informat, Kyoto 6068501, Japan.
   [Onodera, Hidetoshi] Kyoto Univ, Dept Elect, Kyoto 6068501, Japan.
RP Xu, HJ (corresponding author), Kyoto Univ, Commun & Comp Engn, Kyoto 6068501, Japan.
EM xuhongjie@vlsi.kuee.kyoto-u.ac.jp; shiomi-jun@i.kyoto-u.ac.jp;
   onodera@i.kyoto-u.ac.jp
CR Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Google, 2019, EDG TPU
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ABS170404861 CORR
   Intel, 2019, INTEL NEURAL COMPUTE
   Jo J, 2018, IEEE T CIRCUITS-I, V65, P4196, DOI 10.1109/TCSI.2018.2840092
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K., 2015, ARXIV
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Vissers K, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P83, DOI 10.1145/3289602.3294007
   Wilton SJE, 1996, IEEE J SOLID-ST CIRC, V31, P677, DOI 10.1109/4.509850
   Wu YY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300666, 10.1017/S0033291719001314]
   Xu H., 2020, GLSVLSI 20
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/icassp40776.2020.9053977, 10.1109/ICASSP40776.2020.9053977]
NR 26
TC 0
Z9 0
U1 0
U2 1
PD NOV
PY 2021
VL E104A
IS 11
BP 1488
EP 1498
DI 10.1587/transfun.2020KEP0003
UT WOS:000748944700006
DA 2023-11-16
ER

PT C
AU Shi, X
AF Shi, Xuan
BE Griffith, DA
   Chun, Y
   Dean, DJ
TI Parallelizing Affinity Propagation Using Graphics Processing Units for
   Spatial Cluster Analysis over Big Geospatial Data
SO ADVANCES IN GEOCOMPUTATION
SE Advances in Geographic Information Science
DT Proceedings Paper
CT 13th International Conference on Geocomputation (Geocomputation)
CY MAY 20-23, 2015
CL Univ Texas Dallas, Dallas, TX
HO Univ Texas Dallas
DE Spatial clustering; Affinity propagation; Parallel computing; GPU
ID ALGORITHM
AB Introduced in 2007, affinity propagation (AP) is a relatively new machine learning algorithm for unsupervised classification that has seldom been applied in geospatial applications. One bottleneck is that AP could hardly handle large data, and a serial computer program would take a long time to complete an AP calculation. New multicore and manycore computer architectures, combined with application accelerators, show promise for achieving scalable geocomputation by exploiting task and data levels of parallelism. This chapter introduces our recent progress in parallelizing the AP algorithm on a graphics processing unit (GPU) for spatial cluster analysis, the potential of the proposed solution to process big geospatial data, and its broader impact for the GIScience community.
C1 [Shi, Xuan] Univ Arkansas, Dept Geosci, 216 Gearhart Hall, Fayetteville, AR 72701 USA.
RP Shi, X (corresponding author), Univ Arkansas, Dept Geosci, 216 Gearhart Hall, Fayetteville, AR 72701 USA.
EM xuanshi@uark.edu
CR [Anonymous], 1979, PHILOS GEOGRAPHY
   [Anonymous], 2006, PRIOR GEOINT RES NAT
   [Anonymous], 2009, AFFINITY PROPAGATION
   ANSELIN L, 1995, GEOGR ANAL, V27, P93, DOI 10.1111/j.1538-4632.1995.tb00338.x
   Bodenhofer U, 2015, APCLUSTER R PACKAGE
   Chehdi K, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083567
   Frey BJ, 2005, NAT GENET, V37, P991, DOI 10.1038/ng1630
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Frey BJ, 2008, SCIENCE, V319, DOI 10.1126/science.1151268
   Han J, 2001, GEOGRAPHIC DATA MINI, P201
   Jacquez GM, 2008, BLACKW COMPANION GEO, P395
   Kwan MP, 2014, GEOGR ANAL, V46, P297, DOI 10.1111/gean.12040
   Lu Y., 2000, SPATIAL CLUSTER ANAL
   Mennis J, 2009, COMPUT ENVIRON URBAN, V33, P403, DOI 10.1016/j.compenvurbsys.2009.11.001
   Napoleon D, 2012, INT J ADV RES COMPUT, V2, P326
   *NAT RES COUNC, 2006, MAPP M NAT NEEDS ENH
   Xia HY, 2009, IEEE SYS MAN CYBERN, P3116, DOI 10.1109/ICSMC.2009.5346147
   Yang C, 2010, IEEE T GEOSCI REMOTE, V48, P2647, DOI 10.1109/TGRS.2010.2040035
NR 18
TC 2
Z9 2
U1 0
U2 7
PY 2017
BP 355
EP 369
DI 10.1007/978-3-319-22786-3_32
UT WOS:000435557000032
DA 2023-11-16
ER

PT J
AU Khalifa, A
   Winter, J
   Navarro, I
   McIntosh, C
   Purdie, TG
AF Khalifa, Aly
   Winter, Jeff
   Navarro, Inmaculada
   McIntosh, Chris
   Purdie, Thomas G.
TI Domain adaptation of automated treatment planning from computed
   tomography to magnetic resonance
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE machine learning; automated treatment planning; quality assurance;
   magnetic resonance linear accelerator; domain adaptation; prostate
   cancer
ID DOSE PREDICTION; MODEL; RADIOTHERAPY; FEASIBILITY
AB Objective. Machine learning (ML) based radiation treatment planning addresses the iterative and time-consuming nature of conventional inverse planning. Given the rising importance of magnetic resonance (MR) only treatment planning workflows, we sought to determine if an ML based treatment planning model, trained on computed tomography (CT) imaging, could be applied to MR through domain adaptation. Methods. In this study, MR and CT imaging was collected from 55 prostate cancer patients treated on an MR linear accelerator. ML based plans were generated for each patient on both CT and MR imaging using a commercially available model in RayStation 8B. The dose distributions and acceptance rates of MR and CT based plans were compared using institutional dose-volume evaluation criteria. The dosimetric differences between MR and CT plans were further decomposed into setup, cohort, and imaging domain components. Results. MR plans were highly acceptable, meeting 93.1% of all evaluation criteria compared to 96.3% of CT plans, with dose equivalence for all evaluation criteria except for the bladder wall, penile bulb, small and large bowel, and one rectum wall criteria (p < 0.05). Changing the input imaging modality (domain component) only accounted for about half of the dosimetric differences observed between MR and CT plans. Anatomical differences between the ML training set and the MR linac cohort (cohort component) were also a significant contributor. Significance. We were able to create highly acceptable MR based treatment plans using a CT-trained ML model for treatment planning, although clinically significant dose deviations from the CT based plans were observed. Future work should focus on combining this framework with atlas selection metrics to create an interpretable quality assurance QA framework for ML based treatment planning.
C1 [Khalifa, Aly; McIntosh, Chris; Purdie, Thomas G.] Univ Toronto, Dept Med Biophys, Toronto, ON, Canada.
   [Khalifa, Aly; Winter, Jeff; McIntosh, Chris; Purdie, Thomas G.] Univ Hlth Network, Techna Inst, Toronto, ON, Canada.
   [Winter, Jeff; Navarro, Inmaculada; McIntosh, Chris; Purdie, Thomas G.] Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON, Canada.
   [Winter, Jeff; Navarro, Inmaculada; Purdie, Thomas G.] Univ Toronto, Dept Radiat Oncol, Toronto, ON, Canada.
   [McIntosh, Chris] Univ Hlth Network, Peter Munk Cardiac Ctr, Toronto, ON, Canada.
   [McIntosh, Chris] Univ Hlth Network, Joint Dept Med Imaging, Toronto, ON, Canada.
   [McIntosh, Chris] Vector Inst, Toronto, ON, Canada.
RP Khalifa, A (corresponding author), Univ Toronto, Dept Med Biophys, Toronto, ON, Canada.; Khalifa, A (corresponding author), Univ Hlth Network, Techna Inst, Toronto, ON, Canada.
EM aly.khalifa@mail.utoronto.ca
CR Babier A, 2021, MED PHYS, V48, P5549, DOI 10.1002/mp.14845
   Breiman L., 2001, MACH LEARN, V45, P5
   Cagni E, 2017, PHYS MEDICA, V36, P38, DOI 10.1016/j.ejmp.2017.03.002
   Campbell WG, 2017, MED PHYS, V44, P6148, DOI 10.1002/mp.12621
   Chao ML, 2021, MED DOSIM, V46, P269, DOI 10.1016/j.meddos.2021.02.005
   Conroy L, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abfff0
   Costa E, 2021, PHYS MEDICA, V86, P32, DOI 10.1016/j.ejmp.2021.05.022
   Ge YR, 2019, MED PHYS, V46, P2760, DOI 10.1002/mp.13526
   Johnstone E, 2018, INT J RADIAT ONCOL, V100, P199, DOI 10.1016/j.ijrobp.2017.08.043
   Kandalan RN, 2020, RADIOTHER ONCOL, V153, P228, DOI 10.1016/j.radonc.2020.10.027
   Kazhdan M, 2009, LECT NOTES COMPUT SC, V5762, P100, DOI 10.1007/978-3-642-04271-3_13
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Martin JM, 2007, INT J RADIAT ONCOL, V69, P1084, DOI 10.1016/j.ijrobp.2007.04.049
   Mattes MD, 2014, RADIAT ONCOL J, V32, P23, DOI 10.3857/roj.2014.32.1.23
   McIntosh C, 2021, NAT MED, V27, P999, DOI 10.1038/s41591-021-01359-w
   McIntosh C, 2017, PHYS MED BIOL, V62, P5926, DOI 10.1088/1361-6560/aa71f8
   McIntosh C, 2016, IEEE T MED IMAGING, V35, P1000, DOI 10.1109/TMI.2015.2505188
   Mclntosh C, 2017, PHYS MED BIOL, V62, P415, DOI 10.1088/1361-6560/62/2/415
   Moore KL, 2011, INT J RADIAT ONCOL, V81, P545, DOI 10.1016/j.ijrobp.2010.11.030
   Shortall J, 2020, MED PHYS, V47, P2506, DOI 10.1002/mp.14123
   Wang CH, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033819873922
   Wang WT, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac3c14
   Wu H, 2016, RADIAT ONCOL, V11, DOI 10.1186/s13014-016-0684-9
NR 23
TC 0
Z9 0
U1 0
U2 0
PD JUN 21
PY 2022
VL 67
IS 12
AR 125010
DI 10.1088/1361-6560/ac72ec
UT WOS:000808277800001
DA 2023-11-16
ER

PT J
AU Duris, J
   Kennedy, D
   Hanuka, A
   Shtalenkova, J
   Edelen, A
   Baxevanis, P
   Egger, A
   Cope, T
   McIntire, M
   Ermon, S
   Ratner, D
AF Duris, J.
   Kennedy, D.
   Hanuka, A.
   Shtalenkova, J.
   Edelen, A.
   Baxevanis, P.
   Egger, A.
   Cope, T.
   McIntire, M.
   Ermon, S.
   Ratner, D.
TI Bayesian Optimization of a Free-Electron Laser
SO PHYSICAL REVIEW LETTERS
DT Article
AB The Linac coherent light source x-ray free-electron laser is a complex scientific apparatus which changes configurations multiple times per day, necessitating fast tuning strategies to reduce setup time for successive experiments. To this end, we employ a Bayesian approach to maximizing x-ray laser pulse energy by controlling groups of quadrupole magnets. A Gaussian process model provides probabilistic predictions for the machine response with respect to control parameters, enabling a balance of exploration and exploitation in the search for the global optimum. We show that the model parameters can be learned from archived scans, and correlations between devices can be extracted from the beam transport. The result is a sample-efficient optimization routine, combining both historical data and knowledge of accelerator physics to significantly outperform existing optimizers.
C1 [Duris, J.; Kennedy, D.; Hanuka, A.; Shtalenkova, J.; Edelen, A.; Baxevanis, P.; Egger, A.; Cope, T.; Ratner, D.] SLAG Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Kennedy, D.] Univ Calif Santa Cruz, Dept Phys, Santa Cruz, CA 95064 USA.
   [McIntire, M.; Ermon, S.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Duris, J (corresponding author), SLAG Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
CR Akre R, 2008, PHYS REV SPEC TOP-AC, V11, DOI 10.1103/PhysRevSTAB.11.030703
   Borland M., 2000, ADV PHOTON SOURCE LS, DOI [10.2172/761286, DOI 10.2172/761286]
   Brochu E., ARXIV10122599
   Calandra R, 2016, IEEE IJCNN, P3338, DOI 10.1109/IJCNN.2016.7727626
   Conant RC., 1970, INT J SYST SCI, V1, P89, DOI [DOI 10.1080/00207727008920220, 10.1080/00207727008920220]
   CRESSIE N, 1990, MATH GEOL, V22, P239, DOI 10.1007/BF00889887
   Damianou A., 2013, ARTIF INTELL, P207, DOI DOI 10.1002/NME.1296
   Degrave J, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00006
   Delhomme JP, 1978, ADV WATER RESOUR, V1, P251, DOI 10.1016/0309-1708(78)90039-8
   Duvenaud D., 2013, 30 INT C MACH LEARN, V28, P2203
   Edelen A., 2019, P MACH LEARN PHYS SC
   Emma P, 2010, NAT PHOTONICS, V4, P641, DOI [10.1038/nphoton.2010.176, 10.1038/NPHOTON.2010.176]
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Huang XB, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.104601
   Huang XB, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.084001
   Jacot Arthur, 2018, NEURIPS, DOI DOI 10.48550/ARXIV.1806.07572
   Kim K, 2005, PHYS PLASMAS, V12, DOI 10.1063/1.1914536
   Kirschner J, 2019, PR MACH LEARN RES, V97
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Martinez-Cantin R, 2009, AUTON ROBOT, V27, P93, DOI 10.1007/s10514-009-9130-2
   Matthews AGD, 2017, J MACH LEARN RES, V18, P1
   McIntire M., 2016, UAI
   Mockus Jonas, 1974, OPTIMIZATION TECHNIQ, V27, P400, DOI DOI 10.1007/3-540-07165-2_55
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Noack MM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48114-3
   Rasmussen CE, 2010, J MACH LEARN RES, V11, P3011
   Reiche S, 1999, FREE ELECTRON LASERS 1998, P243
   Salvatier J, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.55
   Scheinker A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082802
   Scheinker A, 2018, IEEE T CONTR SYST T, V26, P336, DOI 10.1109/TCST.2017.2664728
   Scheinker A, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.102803
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Snoek J., 2012, ADV NEURAL INFORM PR, V25, P1
   Srinivas N, 2012, IEEE T INFORM THEORY, V58, P3250, DOI 10.1109/TIT.2011.2182033
   Sun SY, 2018, PR MACH LEARN RES, V80
   Tomin S., 2016, P 7 INT PART ACC C
   Wiedemann H., 2007, PARTICLE ACCELERATOR
   Wilson AG, 2016, ADV NEUR IN, V29
   Wu J., 2018, 38 INT FREE EL LAS C, P229
NR 40
TC 59
Z9 59
U1 5
U2 14
PD MAR 25
PY 2020
VL 124
IS 12
AR 124801
DI 10.1103/PhysRevLett.124.124801
UT WOS:000522192200003
DA 2023-11-16
ER

PT J
AU Munoz, NL
   Valero, A
   Tejero, RG
   Zoni, D
AF Munoz, Nicolas Landeros
   Valero, Alejandro
   Tejero, Ruben Gran
   Zoni, Davide
TI Gated-CNN: Combating NBTI and HCI aging effects in on-chip activation
   memories of Convolutional Neural Network accelerators
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Access patterns; Bit flip patterns; Deep learning; Duty cycle; Hardware
   design; Hot Carrier Injection; Machine learning; Negative Bias
   Temperature Instability; Threshold voltage degradation
AB Negative Bias Temperature Instability (NBTI) and Hot Carrier Injection (HCI) are two of the main reliability threats in current technology nodes. These aging phenomena degrade the transistor's threshold voltage (V-th) over the lifetime of a digital circuit, resulting in slower transistors that eventually lead to a faulty operation when the critical paths become longer than the processor cycle time. Among all the transistors on a chip, the most vulnerable transistors to such wearout effects are those used to implement SRAM storage, since memory cells are continuously degrading. In particular, NBTI ages PMOS cell transistors when a given logic value is stored for a long period (i.e., a long duty cycle), whereas HCI ages NMOS cell transistors not only when the stored value flips but also when it is accessed. This work focuses on mitigating aging in the on-chip SRAM memories of Convolutional Neural Network (CNN) accelerators storing activations. This paper makes two main contributions. At the software level, we quantify the aging induced by current CNN benchmarks with a characterization study of duty cycle, flip, and access patterns in every activation memory cell. Based on the insights from this study, this work proposes a novel microarchitectural technique, Gated-CNN, that ensures a uniform aging degradation of every memory cell. To do so, Gated-CNN exploits power-gating and address rotation techniques tailored to the memory demands and temporal/spatial localities exhibited by CNN applications, as well as the memory organization and management of CNN accelerators. Experimental results show that, compared to a conventional design, the average V-th degradation savings are at least as much as 49% on the of transistor.
C1 [Munoz, Nicolas Landeros; Zoni, Davide] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Milan, Italy.
   [Valero, Alejandro; Tejero, Ruben Gran] Univ Zaragoza, Dept Comp Sci & Syst Engn, Zaragoza, Spain.
RP Valero, A (corresponding author), Univ Zaragoza, Dept Comp Sci & Syst Engn, Zaragoza, Spain.
EM alvabre@unizar.es
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Abella J, 2007, INT SYMP MICROARCH, P85, DOI 10.1109/MICRO.2007.11
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alnuayri T, 2021, IEEE T VLSI SYST, V29, P2064, DOI 10.1109/TVLSI.2021.3115247
   [Anonymous], 2013, P 43 ANN IEEE IFIP I
   [Anonymous], 2013, P INT C HARDWARESOFT
   Bojarski Mariusz, 2016, arXiv
   Brownlee J., 2016, MASTER MACHINE LEARN
   Calimera A, 2014, IEEE T COMPUT AID D, V33, P251, DOI 10.1109/TCAD.2013.2287187
   Calimera A, 2010, IEEE INT SYMP CIRC S, P785, DOI 10.1109/ISCAS.2010.5537452
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Deng J., 2009, COMPUTER VISION PATT, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/cvprw.2009.5206848]
   Dounavi HM, 2021, J ELECTRON TEST, V37, P65, DOI 10.1007/s10836-021-05932-6
   Ganapathy S, 2014, PR IEEE COMP DESIGN, P68, DOI 10.1109/ICCD.2014.6974664
   Gebregiorgis A, 2015, ASIA S PACIF DES AUT, P231, DOI 10.1109/ASPDAC.2015.7059010
   Gong N, 2012, MICROELECTRON RELIAB, V52, P1865, DOI 10.1016/j.microrel.2012.06.045
   Gunadi E., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P103, DOI 10.1109/MICRO.2010.37
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hanif M. A., P DES AUT TEST EUR C, V2021, P729
   Howard A. G., 2017, ABS170404861 CORR
   Iandola F.N., 2014, CORR ABS14041869 ARX
   Iandola Forrest N., 2016, P IEEE C COMPUTER VI
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kather JN, 2016, SCI REP-UK, V6, DOI 10.1038/srep27988
   Kaxiras S, 2001, ACM COMP AR, P240, DOI 10.1109/ISCA.2001.937453
   Kothawade S, 2012, PR IEEE COMP DESIGN, P345, DOI 10.1109/ICCD.2012.6378662
   Kothawade S, 2011, INT SYM QUAL ELECT, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee S, 2017, IEEE T COMPUT, V66, P834, DOI 10.1109/TC.2016.2619348
   Li S., 2012, HPL2012187
   Mintarno E, 2013, INT RELIAB PHY SYM
   Moreno AA, 2020, IEEE T VLSI SYST, V28, P1993, DOI 10.1109/TVLSI.2020.3005451
   Mottaghi M.H., 2021, IEEE T COMPUT EARLY, P1
   Nigam T, 2009, 2009 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM, VOLS 1 AND 2, P634, DOI 10.1109/IRPS.2009.5173322
   Oboril F, 2012, I C DEPEND SYS NETWO
   Pilo Harold, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P378, DOI 10.1109/ISSCC.2008.4523215
   Pilo H, 2013, ISSCC DIG TECH PAP I, V56, P322, DOI 10.1109/ISSCC.2013.6487753
   Rahman Md. Tauhidur, 2014, P 51 ANN DES AUT C, P1
   Ricketts A, 2010, DES AUT TEST EUROPE, P592
   Ruospo A, 2021, MICROPROCESS MICROSY, V86, DOI 10.1016/j.micpro.2021.104318
   Samajdar A., 2018, CORR ABS181102883 AR
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shin J, 2008, CONF PROC INT SYMP C, P353, DOI 10.1109/ISCA.2008.30
   Siddiqua T, 2012, IEEE T VLSI SYST, V20, P616, DOI 10.1109/TVLSI.2011.2109973
   Siddiqua T, 2010, IEEE COMP SOC ANN, P393, DOI 10.1109/ISVLSI.2010.15
   Sim J, 2020, IEEE T VLSI SYST, V28, P87, DOI 10.1109/TVLSI.2019.2935251
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tiwari A, 2008, INT SYMP MICROARCH, P129, DOI 10.1109/MICRO.2008.4771785
   Tuzov I., 2021, P IEEEACM INT C COMP, P1
   Valero A, 2019, IEEE T COMPUT, V68, P4, DOI 10.1109/TC.2018.2849376
   Valero A, 2017, IEEE T VLSI SYST, V25, P857, DOI 10.1109/TVLSI.2016.2625809
   Vattikonda R, 2006, DES AUT CON, P1047, DOI 10.1109/DAC.2006.229436
   Yazdanbakhsh A., 2021, ARXIV210210423
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 59
TC 1
Z9 1
U1 1
U2 5
PD JUL
PY 2022
VL 128
DI 10.1016/j.sysarc.2022.102553
EA MAY 2022
UT WOS:000811098400013
DA 2023-11-16
ER

PT J
AU Papadonikolakis, M
   Bouganis, CS
AF Papadonikolakis, Markos
   Bouganis, Christos-Savvas
TI Novel Cascade FPGA Accelerator for Support Vector Machines
   Classification
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Cascade classifier; classification; field programmable gate array
   (FPGA); parallel processing; support vector machines (SVMs)
ID ARCHITECTURE; ALGORITHM
AB Support vector machines (SVMs) are a powerful machine learning tool, providing state-of-the-art accuracy to many classification problems. However, SVM classification is a computationally complex task, suffering from linear dependencies on the number of the support vectors and the problem's dimensionality. This paper presents a fully scalable field programmable gate array (FPGA) architecture for the acceleration of SVM classification, which exploits the device heterogeneity and the dynamic range diversities among the dataset attributes. An adaptive and fully-customized processing unit is proposed, which utilizes the available heterogeneous resources of a modern FPGA device in efficient way with respect to the problem's characteristics. The implementation results demonstrate the efficiency of the heterogeneous architecture, presenting a speed-up factor of 2-3 orders of magnitude, compared to the CPU implementation. The proposed architecture outperforms other proposed FPGA and graphic processor unit approaches by more than seven times. Furthermore, based on the special properties of the heterogeneous architecture, this paper introduces the first FPGA-oriented cascade SVM classifier scheme, which exploits the FPGA reconfigurability and intensifies the custom-arithmetic properties of the heterogeneous architecture. The results show that the proposed cascade scheme is able to increase the heterogeneous classifier throughput even further, without introducing any penalty on the resource utilization.
C1 [Papadonikolakis, Markos; Bouganis, Christos-Savvas] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
RP Papadonikolakis, M (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM markos.papadonikolakis07@imperial.ac.uk;
   christos-savvas.bouganis@imperial.ac.uk
CR Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2008, P 25 INT C MACHINE L, DOI [10.1145/1390156.1390170, DOI 10.1145/1390156.1390170]
   [Anonymous], 2008, NVIDIA CUDA COMP UN
   Asuncion A, 2007, UCI MACHINE LEARNING
   Burges C. J. C., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P71
   Burges CJC, 1997, ADV NEUR IN, V9, P375
   Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Carpenter A., 2009, CUSVM CUDA IMPLEMENT
   Gilbert E G., 1966, SIAM J CONTROL, V4, P61
   Hsu C.-W., 2003, 1 NAT TAIW U DEP COM
   Hsu CF, 2009, IEEE INT SOC CONF, P239, DOI 10.1109/SOCCON.2009.5398049
   Irick KM, 2008, ANN IEEE SYM FIELD P, P304, DOI 10.1109/FCCM.2008.40
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI DOI 10.1145/1150402.1150429
   Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516
   Khan FM, 2005, IEEE INT SYMP CIRC S, P5154, DOI 10.1109/ISCAS.2005.1465795
   Kukenys Ignas, 2008, 2008 23 INT C IM VIS, P1
   Langhammer M, 2008, I C FIELD PROG LOGIC, P354
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mandrake L., 2009, P 30 IEEE AER C MAR, P1
   Martin S, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2005.145
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   Papadonikolakis M., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P283, DOI 10.1109/FPT.2010.5681485
   Papadonikolakis M, 2008, I C FIELD PROG LOGIC, P384, DOI 10.1109/FPL.2008.4629968
   Papadonikolakis M, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, P337, DOI 10.1109/FPT.2008.4762412
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Romdhani S, 2004, P ROY SOC A-MATH PHY, V460, P3283, DOI 10.1098/rspa.2004.1333
   Ruiz-Llata M, 2009, LECT NOTES COMPUT SC, V5768, P467, DOI 10.1007/978-3-642-04274-4_49
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Terrillon JC, 2000, INT C PATT RECOG, P210, DOI 10.1109/ICPR.2000.902897
   Vapnik Vladimir, 1999, NATURE STAT LEARNING
NR 32
TC 58
Z9 59
U1 2
U2 18
PD JUL
PY 2012
VL 23
IS 7
BP 1040
EP 1052
DI 10.1109/TNNLS.2012.2196446
UT WOS:000305397900003
DA 2023-11-16
ER

PT C
AU Xu, PF
   Zhang, XF
   Hao, C
   Zhao, Y
   Zhang, YA
   Wang, Y
   Li, CJ
   Guan, ZT
   Chen, DM
   Lin, YY
AF Xu, Pengfei
   Zhang, Xiaofan
   Hao, Cong
   Zhao, Yang
   Zhang, Yongan
   Wang, Yue
   Li, Chaojian
   Guan, Zetong
   Chen, Deming
   Lin, Yingyan
GP ACM
TI <i>AutoDNNchip</i>: An Automated DNN Chip Predictor and Builder for Both
   FPGAs and ASICs
SO 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS
   (FPGA '20)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 23-25, 2020
CL Seaside, CA
AB Recent breakthroughs in Deep Neural Networks (DNNs) have fueled a growing demand for domain-specific hardware accelerators (i.e., DNN chips). However, designing DNN chips is non-trivial because: (1) mainstream DNNs have millions of parameters and operations; (2) the design space is large due to the numerous design choices of dataflows, processing elements, memory hierarchy, etc.; and (3) an algorithm/hardware co-design is needed to allow the same DNN functionality to have a different decomposition that would require different hardware IPs that correspond to dramatically different performance/energy/area tradeoffs. Therefore, DNN chips often take months to years to design and require a large team of cross-disciplinary experts. To enable fast and effective DNN chip design, we propose AutoDNNchip - a DNN chip generator that can automatically generate both FPGA- and ASIC-based DNN chip implementation (i.e., synthesizable RTL code with optimized algorithm-to-hardware mapping (i.e., dataflow)) given DNNs from machine learning frameworks (e.g., PyTorch) for a designated application and dataset without humans in the loop. Specifically, AutoDNNchip consists of two integrated enablers: (1) a Chip Predictor, built on top of a graph-based accelerator representation, which can accurately and efficiently predict a DNN accelerator's energy, throughput, latency, and area based on the DNN model parameters, hardware configuration, technology-based IPs, and platform constraints; and (2) a Chip Builder, which can automatically explore the design space of DNN chips (including IP selection, block configuration, resource balance, etc.), optimize chip design via the Chip Predictor, and then generate synthesizable RTL code with optimized dataflows to achieve the target design metrics. Experimental results show that our Chip Predictor's predicted performance differs from the real-measured one by <10% when validated using 15 DNN models and 4 platforms (edge-FPGA/TPU/GPU and ASIC). Furthermore, both the FPGA- and ASIC-based DNN accelerators generated by our AutoDNNchip can achieve better (up to 3.86x improvement) performance than that of expert-crafted state-of-the-art accelerators, showing the effectiveness of AutoDNNchip. Our open-source code can be found at https://github.com/RICE-EIC/AutoDNNchip.git.
C1 [Xu, Pengfei; Zhao, Yang; Zhang, Yongan; Wang, Yue; Li, Chaojian; Guan, Zetong; Lin, Yingyan] Rice Univ, Houston, TX 77251 USA.
   [Zhang, Xiaofan; Hao, Cong; Chen, Deming] Univ Illinois, Champaign, IL USA.
RP Xu, PF (corresponding author), Rice Univ, Houston, TX 77251 USA.
EM px5@rice.edu; xiaofan3@illinois.edu; congh@illinois.edu; zy34@rice.edu;
   yz87@rice.edu; yw68@rice.edu; cl114@rice.edu; zg20@rice.edu;
   dchen@illinois.edu; yingyan.lin@rice.edu
CR [Anonymous], 2019, P ADV NEUR INF PROC
   Chen D., 2005, TECHCON, V5
   Chen DM, 2010, IEEE T VLSI SYST, V18, P564, DOI 10.1109/TVLSI.2009.2013353
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Google Inc, EDG TPU
   Google Inc, PIX PHON 2 40
   Google Inc, TENS LIT
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2019, ACCURACY MEETS POWER
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon Hyoukjun, 2018, MAESTRO OPEN SOURCE
   Liang Y, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/649057
   Lin YY, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P17, DOI 10.1109/SiPS.2016.11
   Lin YC, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3284396
   Lin Y, 2017, IEEE INT CONF COMMUN, P782
   Liu SC, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P389, DOI 10.1145/3210240.3210337
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   NVIDIA Inc, NVIDIA JETS TX2
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen J., 34 AAAI C INT
   Simonyan K., 2015, ARXIV
   Su Liu, 2011, Proceedings of the 2011 Symposium on Application Accelerators in High-Performance Computing (SAAHPC 2011), P1, DOI 10.1109/SAAHPC.2011.22
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wang JS, 2018, I C FIELD PROG LOGIC, P163, DOI 10.1109/FPL.2018.00035
   Wang Y., 2018, NEURIPS WORKSH
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wang Yue, 2019, ARXIV190704523
   Wu JR, 2018, PR MACH LEARN RES, V80
   Xilinx Inc, AVN ULTRA96
   Xinlinx, VIVADO HIGH LEVEL SY
   Xiong W, 2017, INT CONF ACOUST SPEE, P5255, DOI 10.1109/ICASSP.2017.7953159
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhang XF, 2017, I C FIELD PROG LOGIC
   Zhang Xiaofan, 2019, ARXIV190909709
   Zhuge CH, 2018, PR GR LAK SYMP VLSI, P123, DOI 10.1145/3194554.3194597
NR 45
TC 42
Z9 44
U1 1
U2 7
PY 2020
BP 40
EP 50
DI 10.1145/3373087.3375306
UT WOS:000693956500010
DA 2023-11-16
ER

PT C
AU Fan, SY
   Wang, ZW
   Xu, WZ
   Hou, R
   Meng, D
   Zhang, MZ
AF Fan, Shengyu
   Wang, Zhiwei
   Xu, Weizhi
   Hou, Rui
   Meng, Dan
   Zhang, Mingzhe
GP IEEE
TI TensorFHE: Achieving Practical Computation on Encrypted Data Using GPGPU
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
ID HOMOMORPHIC ENCRYPTION; ALGORITHM
AB In the cloud computing era, privacy protection is becoming pervasive in a broad range of applications (e.g., machine learning, data mining, etc). Fully Homomorphic Encryption (FHE) is considered the perfect solution as it enables privacy-preserved computation on untrusted servers. Unfortunately, the prohibitive performance overhead blocks the wide adoption of FHE (about 10, 000x slower than the normal computation). As heterogeneous architectures have gained remarkable success in several fields, achieving high performance for FHE with specifically designed accelerators seems to be a natural choice. Until now, most FHE accelerators have focused on efficiently implementing one FHE operation at a time based on ASIC and with significantly higher performance than GPU and FPGA. However, recent state-of-the-art FHE accelerators rely on an expensive and large on-chip storage and a high-end manufacturing process (i.e., 7nm), which increase the cost of FHE adoption.
   In this paper, we propose TensorFHE, an FHE acceleration solution based on GPGPU for real applications on encrypted data. TensorFHE utilizes Tensor Core Units (TCUs) to boost the computation of Number Theoretic Transform (NTT), which is the part of FHE with highest time-cost. Moreover, TensorFHE focuses on performing as many FHE operations as possible in a certain time period rather than reducing the latency of one operation. Based on such an idea, TensorFHE introduces operation-level batching to fully utilize the data parallelism in GPGPU. We experimentally prove that it is possible to achieve comparable performance with GPGPU as with state-of-the-art ASIC accelerators. TensorFHE performs 913 KOPS and 88 KOPS for NTT and HMULT (key FHE kernels) within NVIDIA A100 GPGPU, which is 2.61x faster than state-of-the-art FHE implementation on GPGPU; Moreover, TensorFHE provides comparable performance to the ASIC FHE accelerators, which makes it even 2.9x faster than the F1+ with a specific workload. Such a pure software acceleration based on commercial hardware with high performance can open up usage of state-of-the-art FHE algorithms for a broad set of applications in real systems.
C1 [Fan, Shengyu; Wang, Zhiwei; Hou, Rui; Meng, Dan; Zhang, Mingzhe] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Wang, Zhiwei; Hou, Rui; Meng, Dan] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Fan, Shengyu; Xu, Weizhi] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
RP Fan, SY (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
EM damionfan@163.com; wangzhiwei@iie.ac.cn; xuweizhi@sdnu.edu.cn;
   hourui@iie.ac.cn; mengdan@iie.ac.cn; zhangmingzhe@iie.ac.cn
CR Al Badawi Ahmad, 2018, 2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI), P26, DOI 10.1109/SOLI.2018.8476725
   Al Badawi A., 2018, FUTURE INFORM COMMUN, P666
   Al Badawi A, 2020, IEEE ACCESS, V8, P226544, DOI 10.1109/ACCESS.2020.3045465
   Badawi A., 2018, IACR T CRYPTOGRAPHIC, P70
   Bajard Jean-Claude, 2017, Selected Areas in Cryptography - SAC 2016. 23rd International Conference. Revised Selected Papers: LNCS 10532, P423, DOI 10.1007/978-3-319-69453-5_23
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Brunelli C, 2009, IEEE WRK SIG PRO SYS, P57, DOI 10.1109/SIPS.2009.5336225
   Cao X., 2013, CRYPTOLOGY EPRINT AR
   Cao XL, 2014, LECT NOTES COMPUT SC, V8438, P169, DOI 10.1007/978-3-662-44774-1_14
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen H, 2018, LECT NOTES COMPUT SC, V10820, P315, DOI 10.1007/978-3-319-78381-9_12
   Chen X., 2022, IACR T CRYPTOGRAPH H, V2022, P94
   Cheon J. H., 2018, IACR CRYPTOLOGY EPRI, V2018, P1073
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   COCHRAN WT, 1967, PR INST ELECTR ELECT, V55, P1664, DOI 10.1109/PROC.1967.5957
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Cousins DB, 2017, IEEE T EMERG TOP COM, V5, P193, DOI 10.1109/TETC.2016.2619669
   Couso D., 2014, IEEE HIGH PERF EXTR, P1
   Dai W., 2016, LNCS, V9540, P169, DOI [10.1007/978-3-319-29172-71, DOI 10.1007/978-3-319-29172-711]
   Dong J., 2016, THESIS WORCESTER POL
   Durrani S, 2021, INT CONFER PARA, P345, DOI 10.1109/PACT52795.2021.00032
   Erabelli S., 2020, THESIS MIT
   Fan Junfeng, 2012, CRYPTOLOGY EPRINT AR
   Feng BY, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476157
   Guo C, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00020
   GUPTA A, 1990, IEEE T ACOUST SPEECH, V38, P553, DOI 10.1109/29.106875
   Han K, 2020, LECT NOTES COMPUT SC, V12006, P364, DOI 10.1007/978-3-030-40186-3_16
   Han K, 2019, AAAI CONF ARTIF INTE, P9466
   Jia Z, 2019, Arxiv, DOI arXiv:1903.07486
   Jung Hee Cheon, 2019, Selected Areas in Cryptography - SAC 2018. 25th International Conference. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11349), P347, DOI 10.1007/978-3-030-10970-7_16
   Jung W., 2021, IACR T CRYPTOGRAPH H, P114, DOI DOI 10.46586/TCHES.V2021.I4.114
   Khairy M, 2020, ANN I S COM, P473, DOI 10.1109/ISCA45697.2020.00047
   Kim J, 2022, Arxiv, DOI arXiv:2205.00922
   Kim M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/1472-6947-15-S5-S3
   Kim S, 2022, CONF PROC INT SYMP C, P711, DOI 10.1145/3470496.3527415
   Kim S, 2020, I S WORKL CHAR PROC, P264, DOI 10.1109/IISWC50251.2020.00033
   Knezevic M, 2010, IEEE T COMPUT, V59, P1715, DOI 10.1109/TC.2010.93
   Konečny J, 2015, Arxiv, DOI arXiv:1511.03575
   Lee E., 2022, INT C MACHINE LEARNI
   Lee JW, 2022, IEEE ACCESS, V10, P30039, DOI 10.1109/ACCESS.2022.3159694
   Longa P, 2016, LECT NOTES COMPUT SC, V10052, P124, DOI 10.1007/978-3-319-48965-0_8
   Madrid P. E., 1993, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V1, P164, DOI 10.1109/92.238420
   Mert AC, 2019, 2019 22ND EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P253, DOI 10.1109/DSD.2019.00045
   Mouchet C., 2020, WAHC 2020 8 WORKSHOP
   Mukherjee T., 2016, CYCLOTOMIC POLYNOMIA
   NVIDIA, 2022, NVID NSIGHT SYST
   NVIDIA, 2022, CUTLASS 2 8
   NVIDIA, 2022, CUD 11 0
   NVIDIA, 2022, NVID A100 TENS COR G
   NVIDIA, 2017, TESL NVIDIA
   Paszke A, 2019, ADV NEUR IN, V32
   Podschwadt R, 2020, PRIVATENLP WSDM, P27
   Poppelmann Thomas, 2012, Progress in Cryptology - LATINCRYPT 2012. Proceedings of the 2nd International Conference on Cryptology and Information Security in Latin America, P139, DOI 10.1007/978-3-642-33481-8_8
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Samardzic N, 2022, CONF PROC INT SYMP C, P173, DOI 10.1145/3470496.3527393
   Samardzic Nikola, 2021, MICRO54, P238, DOI 10.1145/3466752
   Shoup V, 1995, J SYMB COMPUT, V20, P363, DOI 10.1006/jsco.1995.1055
   Turan F, 2020, IEEE T COMPUT, V69, P1185, DOI 10.1109/TC.2020.2988765
   Wang W, 2014, IEEE INT SYMP CIRC S, P2800, DOI [10.1109/POWERCON.2014.6993776, 10.1109/ISCAS.2014.6865755]
   Weisstein E. W., 2004, FERMATS LITTLE THEOR
   Yi X, 2013, IEEE T KNOWL DATA EN, V25, P1125, DOI 10.1109/TKDE.2012.90
NR 61
TC 2
Z9 2
U1 1
U2 1
PY 2023
BP 922
EP 934
DI 10.1109/HPCA56546.2023.10071017
UT WOS:000982303200068
DA 2023-11-16
ER

PT C
AU Kabrick, R
   Leidel, J
   Donofrio, D
AF Kabrick, Ryan
   Leidel, John
   Donofrio, David
GP IEEE
TI Toward HDL Extensions for Rapid AI/ML Accelerator Generation
SO 2021 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 20-24, 2021
CL ELECTR NETWORK
DE StoneCutter; Chisel; HDL; AI; machine learning
AB StoneCutter, a language construct and compiler embedded in the OpenSoC System Architect family of tools, is designed to provide software architects the ability to rapidly prototype instruction set extensions and hardware accelerators. The StoneCutter compilation flow ingests high level syntax and outputs optimized and pipelined Chisel HDL for further compilation to platform-specific RTL. However, unlike other HDL approaches, StoneCutter is rooted in the notion that users define syntactic blocks that map directly to individual instruction definitions as opposed to classic finite state machines. When integrated with the adjacent System Architect design flow, StoneCutter provides a familiar, C-like language construct by which to develop the implementation for individual, programmable instructions. The LLVM-based StoneCutter compiler performs individual instruction and whole-ISA optimizations in order to generate a high performance, Chisel HDL representation of the target design. Utilizing the existing Chisel tools, users can also generate C++ cycle accurate simulation models as well as Verilog representations of the target design. As a result, the StoneCutter language and associated tooling provides a very rapid, instruction set-centric design environment for rapid development and experimentation.
   This work describes initial efforts to extend the StoneCutter infrastructure in order to encapsulate linear algebraic constructs for direct compilation into optimized AI/ML instructions. This functionality provides users and architects the ability to utilize the StoneCutter high level language constructs to develop target and domain specific AI/ML instructions using optimized linear algebraic constructs compiled directly to target-specific RTL. This enables users to create highly optimized AI/ML hardware implementations with minimal effort in traditional hardware develop flows.
C1 [Kabrick, Ryan] Tact Comp Labs, Newark, DE 19713 USA.
   [Leidel, John] Tact Comp Labs, Muenster, TX USA.
   [Donofrio, David] Tact Comp Labs, San Francisco, CA USA.
RP Kabrick, R (corresponding author), Tact Comp Labs, Newark, DE 19713 USA.
EM rkabrick@tactcomplabs.com; jleidel@tactcomplabs.com;
   ddonofrio@tactcomplabs.com
CR Bachrach J, 2012, DES AUT CON, P1212
   Ben-Kiki Oren, 2009, YAML AINT MARKUP LAN
   Conlon F., COREGEN INTERMEDIATE
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Leidel J. D., STONECUTTER LANGUAGE
   Leidel JD, 2020, 17TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2020 (CF 2020), P233, DOI 10.1145/3387902.3394029
   Leidel JD, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P308, DOI 10.1145/3310273.3323433
NR 9
TC 0
Z9 0
U1 0
U2 1
PY 2021
DI 10.1109/HPEC49654.2021.9622832
UT WOS:000766311400050
DA 2023-11-16
ER

PT J
AU Arora, A
   Ghosh, M
   Mehta, S
   Betz, V
   John, LK
AF Arora, Aman
   Ghosh, Moinak
   Mehta, Samidh
   Betz, Vaughn
   John, Lizy K.
TI Tensor Slices: FPGA Building Blocks For The Deep Learning Era
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; neural networks; deep learning; machine learning; hardware
   acceleration; computer architecture; tensor slice
AB FPGAs are well-suited for accelerating deep learning (DL) applications owing to the rapidly changing algorithms, network architectures and computation requirements in this field. However, the generic building blocks available on traditional FPGAs limit the acceleration that can be achieved. Many modifications to FPGA architecture have been proposed and deployed including adding specialized artificial intelligence (AI) processing engines, adding support for smaller precision math like 8-bit fixed point and IEEE half-precision (fp16) in DSP slices, adding shadow multipliers in logic blocks, etc. In this paper, we describe replacing a portion of the FPGA's programmable logic area with Tensor Slices. These slices have a systolic array of processing elements at their heart that support multiple tensor operations, multiple dynamically-selectable precisions and can be dynamically fractured into individual multipliers and MACs (multiply-and-accumulate). These slices have a local crossbar at the inputs that helps with easing the routing pressure caused by a large block on the FPGA. Adding these DL-specific coarse-grained hard blocks to FPGAs increases their compute density and makes them even better hardware accelerators for DL applications, while still keeping the vast majority of the real estate on the FPGA programmable at fine-grain.
C1 [Arora, Aman; John, Lizy K.] Univ Texas Austin, Dept Elect & Comp Engn, 2501 Speedway, Austin, TX 78712 USA.
   [Ghosh, Moinak] Indian Inst Technol Kharagpur, Dept Elect Engn, Kharagpur, W Bengal, India.
   [Mehta, Samidh] Bits Pilani KK Birla, Dept Elect & Elect Engn, Goa Campus, Mormugao 403726, Goa, India.
   [Betz, Vaughn] Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G8, Canada.
RP Arora, A (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, 2501 Speedway, Austin, TX 78712 USA.
EM aman.kbm@utexas.edu; moinakghosh2000@gmail.com; samidh99@gmail.com;
   vaughn@ece.utoronto.ca; ljohn@ece.utexas.edu
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Achronix, 2021, SPEEDSTER7T FPGAS
   Achronix, 2019, ACHR MACH LAERN PROC
   Arizona State University, 2012, PREDICTIVE TECHNOLOG
   Arora Aman, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P23, DOI 10.1145/3431920.3439282
   Arora A, 2021, I C FIELD PROG LOGIC, P355, DOI 10.1109/FPL53798.2021.00068
   Arora A, 2020, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP49362.2020.00018
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Brosser F, 2013, I C FIELD PROG LOGIC
   Eldafrawy M, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3393668
   Flex-Logix, 2019, FLEX LOG NNMAX INF A
   Flex-Logix, 2019, FLEX LOG EFLX EFPGA
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gaide B, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P84, DOI 10.1145/3289602.3293906
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Intel, 2019, INT AG FPGAS SOCS
   Intel, 2020, INT AG VAR PREC DSP
   Intel, 2018, BFLOAT16 HARDW NUM D
   Intel, 2020, INT STRAT 10 NX FPGA
   Langhammer Martin, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P57, DOI 10.1145/3431920.3439293
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Murray KE, 2015, ACM T RECONFIG TECHN, V8, DOI 10.1145/2629579
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Nurvitadhi Eriko, 2018, FPGA 18 P 2018 ACM S, P287, DOI [10.1145/ 3174243.3174966, DOI 10.1145/3174243.3174966]
   NVIDIA Tesla, 2017, NVIDIA TESLA V100 GP
   Jouppi NP, 2017, Arxiv, DOI arXiv:1704.04760
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Vaswani A, 2017, ADV NEUR IN, V30
   Wikipedia, 2021, ROUND
   Wikipedia, 2021, BLOCK FLOAT POINT
   Xilinx, 2018, ACC DNNS XILL ALV AC
   Xilinx, 2021, XIL ACAP ENG ARCH MA
   Xilinx, 2018, XIL ENG THEIR APPL
   Yazdanshenas S, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3301298
NR 35
TC 4
Z9 4
U1 4
U2 6
PD DEC
PY 2022
VL 15
IS 4
AR 46
DI 10.1145/3529650
UT WOS:000899304900012
DA 2023-11-16
ER

PT C
AU Rahman, MM
   Vidyaratne, L
   Carpenter, A
   Tennant, C
   Iftekharuddin, K
AF Rahman, Md Monibor
   Vidyaratne, L.
   Carpenter, A.
   Tennant, C.
   Iftekharuddin, K.
GP IEEE
TI Uncertainty Aware Deep Learning for Fault Prediction Using Multivariate
   Time Series Signals
SO 2023 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN)
CY JUN 18-23, 2023
CL Broadbeach, AUSTRALIA
DE Prediction; Deep learning; Monte Carlo dropout; Uncertainty
   Quantification
AB The superconducting radio-frequency cavities are a crucial component of the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. When a cavity faults, beam delivery to experimental end users is disrupted. Prediction of cavity faults prior to onset is essential to reduce operation and maintenance costs. In this work, a parallel long short-term memory (LSTM)-convolutional neural network (CNN)-based deep learning (DL) model is proposed to predict impending faults using pre-fault signals. Further, we introduce an uncertainty quantification approach using Monte Carlo dropout with the LSTM-CNN model to ascertain confidence in the prediction. The model was tested using multivariate time series signals from stable cavity operations and before faults. Initial results show that on the test dataset, the model can identify impending faults before their onset with an average 10-fold cross validation accuracy of 97.39% and a standard deviation of 0.12% using a 100-ms time window. It is also observed that the model performs better as the prediction time moves closer to the fault onset. For additional context, we compare the performance of the model with three machine-learning (ML)-based fault prediction models. Our proposed parallel LSTM-CNN-based DL method shows better performance than the ML-based methods.
C1 [Rahman, Md Monibor; Iftekharuddin, K.] Old Dominion Univ, Dept Elect & Comp Engn, Vis Lab, Norfolk, VA 23529 USA.
   [Vidyaratne, L.; Carpenter, A.; Tennant, C.] Jefferson Lab, Newport News, VA USA.
RP Rahman, MM (corresponding author), Old Dominion Univ, Dept Elect & Comp Engn, Vis Lab, Norfolk, VA 23529 USA.
CR Alpaydin E., 2010, INTRO MACHINE LEARNI, V2
   Carvalho TP, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106024
   Combalia M, 2020, IEEE COMPUT SOC CONF, P3211, DOI 10.1109/CVPRW50498.2020.00380
   Gal Y., DROPOUT BAYESIAN APP, DOI [10.48550/arXiv.1506.02142, DOI 10.48550/ARXIV.1506.02142]
   Gao B., PROPERTIES SOFTMAX F, DOI [10.48550/arXiv.1704.00805, DOI 10.48550/ARXIV.1704.00805]
   Guo JW, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108566
   Huang Y, 2019, IEEE ACCESS, V7, P139086, DOI 10.1109/ACCESS.2019.2940769
   Khalil K, 2020, IEEE T CIRCUITS-I, V67, P3880, DOI 10.1109/TCSI.2020.3010743
   Kumari L, 2022, REV ETNOGR FOLC, P5
   Lee WJ, 2019, PROC CIRP, V80, P506, DOI 10.1016/j.procir.2018.12.019
   Li HF, 2014, TRANSPORT RES C-EMER, V45, P17, DOI 10.1016/j.trc.2014.04.013
   Li S., REV TIME SERIES FORE, DOI [10.48550/arXiv.2209.10705, DOI 10.48550/ARXIV.2209.10705]
   Li SC, 2021, INFORMATION, V12, DOI 10.3390/info12030121
   Ling Zheng, 2019, 2019 IEEE International Conference on Energy Internet (ICEI), P537, DOI 10.1109/ICEI.2019.00101
   Lobach I., 2022, P N AM PART ACC C
   Orrù PF, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12114776
   Pham DT, 2005, P I MECH ENG B-J ENG, V219, P395, DOI 10.1243/095440505X32274
   Rahman MM, 2022, LECT NOTES COMPUT SC, V12962, P463, DOI 10.1007/978-3-031-08999-2_40
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Sak H., LONG SHORT TERM MEMO, DOI [10.48550/arXiv.1402.1128, DOI 10.48550/ARXIV.1402.1128]
   Scheinker A., ADAPTIVE LATENT SPAC, DOI [10.48550/arXiv.2105.03584, DOI 10.48550/ARXIV.2105.03584]
   Solopova A., 2019, 10 INT PART ACC C IP, DOI [10.18429/JACoW-IPAC2019- TUXXPLM2, DOI 10.18429/JAC0W-IPAC2019-TUXXPLM2]
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Vidyaratne L, 2022, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.718950
   Xu HL, 2021, DIGIT SIGNAL PROCESS, V117, DOI 10.1016/j.dsp.2021.103150
   Yang J, 2021, 2021 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE BIG DATA AND INTELLIGENT SYSTEMS (HPBD&IS), P291, DOI 10.1109/HPBDIS53214.2021.9658478
   Zhang SL, 2018, IEEE ACCESS, V6, P7675, DOI 10.1109/ACCESS.2017.2785763
NR 27
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/IJCNN54540.2023.10191827
UT WOS:001046198706024
DA 2023-11-16
ER

PT J
AU Oehlmann, P
   Osswald, P
   Blanco, JC
   Friedrich, M
   Rietzel, D
   Witt, G
AF Oehlmann, Paul
   Osswald, Paul
   Blanco, Juan Camilo
   Friedrich, Martin
   Rietzel, Dominik
   Witt, Gerd
TI Modeling Fused Filament Fabrication using Artificial Neural Networks
SO PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT
DT Article
DE Additive manufacturing; Fused Filament Fabrication; 3D printing;
   Artificial intelligence; Neural networks; Machine learning; Deep
   learning; Big data; Process control; Process monitoring; Signal
   processing; Industry 4; 0
AB With industries pushing towards digitalized production, adaption to expectations and increasing requirements for modern applications, has brought additive manufacturing (AM) to the forefront of Industry 4.0. In fact, AM is a main accelerator for digital production with its possibilities in structural design, such as topology optimization, production flexibility, customization, product development, to name a few. Fused Filament Fabrication (FFF) is a widespread and practical tool for rapid prototyping that also demonstrates the importance of AM technologies through its accessibility to the general public by creating cost effective desktop solutions. An increasing integration of systems in an intelligent production environment also enables the generation of large-scale data to be used for process monitoring and process control. Deep learning as a form of artificial intelligence (AI) and more specifically, a method of machine learning (ML) is ideal for handling big data. This study uses a trained artificial neural network (ANN) model as a digital shadow to predict the force within the nozzle of an FFF printer using filament speed and nozzle temperatures as input data. After the ANN model was tested using data from a theoretical model it was implemented to predict the behavior using real-time printer data. For this purpose, an FFF printer was equipped with sensors that collect real time printer data during the printing process. The ANN model reflected the kinematics of melting and flow predicted by models currently available for various speeds of printing. The model allows for a deeper understanding of the influencing process parameters which ultimately results in the determination of the optimum combination of process speed and print quality.
C1 [Oehlmann, Paul] Tech Univ Munich, Dept Mech Engn, Munich, Germany.
   [Osswald, Paul; Friedrich, Martin; Rietzel, Dominik] BMW Grp, Munich, Germany.
   [Blanco, Juan Camilo] Fused Form Corp, Bogota, Colombia.
   [Witt, Gerd] Univ Duisburg Essen, Duisburg, Germany.
RP Oehlmann, P (corresponding author), Tech Univ Munich, Dept Mech Engn, Munich, Germany.
EM paul.oehlmann@tum.de
CR Bayraktar Ö, 2017, POLYM ADVAN TECHNOL, V28, P1044, DOI 10.1002/pat.3960
   Bellini A, 2004, J MANUF SCI E-T ASME, V126, P237, DOI 10.1115/1.1688377
   Bishop C., 1995, NEURAL NETWORKS PATT
   Frochte J., 2019, MASCHINELLES LERNEN, DOI DOI 10.3139/9783446459977
   Go J, 2017, ADDIT MANUF, V16, P1, DOI 10.1016/j.addma.2017.03.007
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Heaton J., 2008, INTRO NEURAL NETWORK, P157
   Heller BP, 2016, ADDIT MANUF, V12, P252, DOI 10.1016/j.addma.2016.06.005
   Hull, 1986, [No title captured], Patent No. [4575330A, 4575330, No. 4.575.330A]
   I. Wohlers Associates, 2019, WOHLERS REPORT 2019
   Lee, 2018, AI SUPERPOWERS CHINA
   MAZZEI C, 2019, ADDIT MANUF
   Mohri M, 2012, FDN MACHINE LEARNING
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Obst P, 2020, ADDIT MANUF, V32, DOI 10.1016/j.addma.2019.101002
   OSSWALD T, 2018, ADDIT MANUF
   Popova E, 2017, INTEGR MATER MANUF I, V6, P54, DOI 10.1007/s40192-017-0088-1
   Qi XB, 2019, ENGINEERING-PRC, V5, P721, DOI 10.1016/j.eng.2019.04.012
   Ramanath HS, 2008, J MATER SCI-MATER M, V19, P2541, DOI 10.1007/s10856-007-3203-6
   Refaeilzadeh P., 2009, CROSS VALIDATION BT, P532, DOI [10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_565]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STAMMERS E, 1969, POLYM ENG SCI, V9, P49, DOI 10.1002/pen.760090108
   Turner BN, 2014, RAPID PROTOTYPING J, V20, P192, DOI 10.1108/RPJ-01-2013-0012
   Wu HX, 2017, INT J ADV MANUF TECH, V90, P2027, DOI 10.1007/s00170-016-9548-6
   Yardimci MA, 1997, SOL FREEFORM FABRIC, P689
NR 25
TC 12
Z9 12
U1 2
U2 21
PD JUN
PY 2021
VL 15
IS 3-4
BP 467
EP 478
DI 10.1007/s11740-021-01020-y
EA FEB 2021
UT WOS:000615779000001
DA 2023-11-16
ER

PT J
AU Whatmough, PN
   Lee, SK
   Brooks, D
   Wei, GY
AF Whatmough, Paul N.
   Lee, Sae Kyu
   Brooks, David
   Wei, Gu-Yeon
TI DNN Engine: A 28-nm Timing-Error Tolerant Sparse Deep Neural Network
   Processor for IoT Applications
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Deep neural networks (DNNs); hardware accelerators; Internet of things
   (IoT); machine learning (ML); razor; system-on-chip (SoC); timing error
   detection and correction; timing error tolerance
ID CIRCUIT
AB This paper presents a 28-nm system-on-chip (SoC) for Internet of things (IoT) applications with a programmable accelerator design that implements a powerful fully connected deep neural network (DNN) classifier. To reach the required low energy consumption, we exploit the key properties of neural network algorithms: parallelism, data reuse, small/sparse data, and noise tolerance. We map the algorithm to a very large scale integration (VLSI) architecture based around an single-instruction, multiple-data data path with hardware support to exploit data sparsity by completely eliding unnecessary computation and data movement. This approach exploits sparsity, without compromising the parallel computation. We also exploit the inherent algorithmic noise-tolerance of neural networks, by introducing circuit-level timing violation detection to allow worst case voltage guard-bands to be minimized. The resulting intermittent timing violations may result in logic errors, which conventionally need to be corrected. However, in lieu of explicit error correction, we cope with this by accentuating the noise tolerance of neural networks. The measured test chip achieves high classification accuracy (98.36% for the MNIST test set), while tolerating aggregate timing violation rates >10(-1). The accelerator achieves a minimum energy of 0.36 mu J/inference at 667 MHz; maximum throughput at 1.2 GHz and 0.57 mu J/inference; or a 10% margined operating point at 1 GHz and 0.58 mu J/inference.
C1 [Whatmough, Paul N.] Arm Res, Boston, MA 02451 USA.
   [Whatmough, Paul N.; Lee, Sae Kyu; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Lee, Sae Kyu] IBM Res, Yorktown Hts, NY 10598 USA.
RP Whatmough, PN (corresponding author), Arm Res, Boston, MA 02451 USA.
EM paul.whatmough@arm.com; saekyu.lee@ibm.com; dbrooks@eecs.harvard.edu;
   guyeon@eecs.harvard.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], 2010, SOLID STATE CIRCUITS
   [Anonymous], 2011 IEEE CUST INT C
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Bull David, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P284, DOI 10.1109/ISSCC.2010.5433919
   Chandrakasan A.P., 1996, P 9 INT C VLSI DES, P352
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Das S, 2014, IEEE T CIRCUITS-I, V61, P2290, DOI 10.1109/TCSI.2014.2333332
   Dasika G, 2008, DES AUT CON, P894
   Desoli G, 2017, ISSCC DIG TECH PAP I, P238, DOI 10.1109/ISSCC.2017.7870349
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Esser S. K., 2015, ADV NEURAL INFORM PR, P1117
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hegde R, 2004, IEEE J SOLID-ST CIRC, V39, P388, DOI 10.1109/JSSC.2003.821775
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jung Kuk Kim, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC50, DOI 10.1109/VLSIC.2015.7231323
   Kodali S, 2017, PR IEEE COMP DESIGN, P589, DOI 10.1109/ICCD.2017.102
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moons B, 2017, CONF REC ASILOMAR C, P1921, DOI 10.1109/ACSSC.2017.8335699
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Reagen B., P DES AUT C DAC
   Reagen B., 2017, SYNTHESIS LECT COMPU
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Sakr C., 2017, P INT C MACH LEAR, P3007
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Whatmough P.N., 2015, SYMP VLSI CIRCUITS, pC98
   Whatmough PN, 2017, IEEE J SOLID-ST CIRC, V52, P1643, DOI 10.1109/JSSC.2017.2669025
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Whatmough PN, 2013, IEEE T VLSI SYST, V21, P989, DOI 10.1109/TVLSI.2012.2202930
   Whatmough PN, 2013, ISSCC DIG TECH PAP I, V56, P428, DOI 10.1109/ISSCC.2013.6487800
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang YQ, 2018, IEEE J SOLID-ST CIRC, V53, P619, DOI 10.1109/JSSC.2017.2749423
NR 39
TC 63
Z9 64
U1 1
U2 18
PD SEP
PY 2018
VL 53
IS 9
SI SI
BP 2722
EP 2731
DI 10.1109/JSSC.2018.2841824
UT WOS:000444279300025
DA 2023-11-16
ER

PT C
AU Sharma, RK
   Gabrani, G
AF Sharma, Ravish Kumar
   Gabrani, Goldie
BE Misra, S
   Gervasi, O
   Murgante, B
   Stankova, E
   Korkhov, V
   Torre, C
   Rocha, AMAC
   Taniar, D
   Apduhan, BO
   Tarantino, E
TI Exploring Deep Learning Methods for Particle Track Reconstruction
SO 2019 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS
   APPLICATIONS (ICCSA 2019)
DT Proceedings Paper
CT 19th International Conference on Computational Science and Its
   Applications (ICCSA)
CY JUN 30-JUL 04, 2019
CL St Petersburg State Univ, Saint Petersburg, RUSSIA
HO St Petersburg State Univ
DE Deep Learning; Particle Track Reconstruction; LHC; Long Short Term
   Memory
AB The fundamentals of particle are studied at CERN by smashing beams of protons inside a particle accelerator. The particle coming out of the collision fly all around the space leaving charge on the detector. The trajectory of particles coming out of collision needs to be reconstructed(from data gathered from detectors) in order to identify the particle type, and to study the properties of the particle, this process is called Particle Track Reconstruction (PTR). PTR is a challenging task in high energy physics as the rate of data generated at CERN has already reached tens of petabyte per annum. Further, with the advancement of Large Hadron Collider (LHC) to High-Luminosity Large Hadron Collider (HL-LHC) by the next decade, the data generated is expected to increase around 10 times due to increase in the rate of collision. So, there is a need for a fast, accurate and scalable algorithm for PTR. Deep Learning is a popular machine learning technique that has already shown promising results in the area of computer vision, natural language processing and modelling non-linear dependencies. In this paper, the authors present four different deep learning methods for reconstructing particle track and discuss the strength and weakness of each method by evaluating them on a simulated dataset of collision between protons in the LHC.
C1 [Sharma, Ravish Kumar; Gabrani, Goldie] BML Munjal Univ, Sch Engn & Technol, Gurugram, Haryana, India.
RP Sharma, RK (corresponding author), BML Munjal Univ, Sch Engn & Technol, Gurugram, Haryana, India.
EM ravish.sharma.15cse@bml.edu.in; goldie.gabrani@bmu.edu.in
CR Baranov D., 2017, P 26 INT S NUCL EL C
   Baranov D., 2018, ARXIV181203859CSLG
   CERN, LHCB DET
   CERN, 2018, TRACKML PART TRACK C
   Chung J., 2014, ARXIV
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Evans L, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/S08001
   Farrell S., 2017, 31 ANN C NEUR INF PR
   Farrell S., 2018, ARXIV181006111HEPEX
   FRUHWIRTH R, 1987, NUCL INSTRUM METH A, V262, P444, DOI 10.1016/0168-9002(87)90887-4
   Glover C., 1992, C COMP HIGH EN PHYS
   Greff K., 2015, ARXIV150304069CSNE
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Lipton Z.C., 2015, COMPUT SCI, V1506, P19
   Ng A., 2018, MACHINE LEARNING YEA, P12
   Outrunner, 2018, 2 PLACE SOLUTION
   The ATLAS Collaboration, 2008, J INSTRUM, V3, P1
   The LHCb Collaboration, 2008, J INSTRUM, V3, P2
   Tsaris A., 2017, 18 INT WORKSH ADV CO
NR 19
TC 0
Z9 0
U1 2
U2 5
PY 2019
BP 120
EP 125
DI 10.1109/ICCSA.2019.00009
UT WOS:000587581600014
DA 2023-11-16
ER

PT C
AU Chmielewski, L
   Weissbart, L
AF Chmielewski, Lukasz
   Weissbart, Leo
BE Zhou, J
   Ahmed, CM
   Batina, L
   Chattopadhyay, S
   Gadyatskaya, O
   Jin, C
   Lin, J
   Losiouk, E
   Luo, B
   Majumdar, S
   Maniatakos, M
   Mashima, D
   Meng, W
   Picek, S
   Shimaoka, M
   Su, C
   Wang, C
TI On Reverse Engineering Neural Network Implementation on GPU
SO APPLIED CRYPTOGRAPHY AND NETWORK SECURITY WORKSHOPS, ACNS 2021
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 19th International Conference on Applied Cryptography and Network
   Security (ACNS)
CY JUN 21-24, 2021
CL ELECTR NETWORK
DE Deep neural network; Side-channel analysis; Simple power analysis;
   Reverse engineering
AB In recent years machine learning has become increasingly mainstream across industries. Additionally, Graphical Processing Unit (GPU) accelerators are widely deployed in various neural network (NN) applications, including image recognition for autonomous vehicles and natural language processing, among others. Since training a powerful network requires expensive data collection and computing power, its design and parameters are often considered a secret intellectual property of their manufacturers. However, hardware accelerators can leak crucial information about the secret neural network designs through side-channels, like Electro-Magnetic (EM) emanations, power consumption, or timing.
   We propose and evaluate non-invasive and passive reverse engineering methods to recover NN designs deployed on GPUs through EM side-channel analysis. We employ a well-known technique of simple EM analysis and timing analysis of NN layers execution. We consider commonly used NN architectures, namely Multilayer Perceptron and Convolutional Neural Networks. We show how to recover the number of layers and neurons as well as the types of activation functions. Our experimental results are obtained on a setup that is as close as possible to a real-world device in order to properly assess the applicability and extendability of our methods.
   We analyze the NN execution of a PyTorch python framework implementation running on Nvidia Jetson Nano, a module computer embedding a Tegra X1 SoC that combines an ARM Cortex-A57 CPU and a 128-core GPU within a Maxwell architecture. Our results show the importance of side-channel protections for NN accelerators in real-world applications.
C1 [Chmielewski, Lukasz; Weissbart, Leo] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Weissbart, Leo] Delft Univ Technol, Delft, Netherlands.
   [Chmielewski, Lukasz] Riscure BV, Delft, Netherlands.
RP Chmielewski, L (corresponding author), Radboud Univ Nijmegen, Nijmegen, Netherlands.; Chmielewski, L (corresponding author), Riscure BV, Delft, Netherlands.
EM lukaszc@cs.ru.nl; l.weissbart@cs.ru.nl
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2021, NVIDIA JETSON NANOMO
   [Anonymous], 2021, NVIDIA TEGRA X1 WHIT
   [Anonymous], 1997, MACH LEARN
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Chabanne H, 2021, CAAI T INTELL TECHNO, V6, P3, DOI 10.1049/cit2.12026
   Chari S, 2002, LECT NOTES COMPUT SC, V2523, P13
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Gao Y., 2018, IACR CRYPTOLOGY EPRI
   Haykin S., 2004, NEURAL NETWORKS, V2, P41, DOI DOI 10.5555/541500
   Jiang ZH, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P167, DOI 10.1145/3060403.3060462
   Jiang ZH, 2016, INT S HIGH PERF COMP, P394, DOI 10.1109/HPCA.2016.7446081
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kocher P. C., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P104
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V3, P6
   Kucera M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P391, DOI 10.1145/3133956.3134079
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Luo C, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P281, DOI 10.1109/ICCD.2015.7357115
   Maji S, 2021, IEEE INTERNET THINGS, V8, P12079, DOI 10.1109/JIOT.2021.3061314
   Naghibijouybari H., 2019, IEEE T DEPEND SECURE
   Nair V., 2010, ICML, P807
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Papernot N, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P399, DOI 10.1109/EuroSP.2018.00035
   Paszke A, 2019, ADV NEUR IN, V32
   Riscure, 2018, RISC AUT NEUR NETW C
   Takatoi G, 2020, LECT NOTES COMPUT SC, V12418, P181, DOI 10.1007/978-3-030-61638-0_11
   Tariq Z, 2019, IEEE INT CONF BIG DA, P4191, DOI 10.1109/BigData47090.2019.9005638
   Teufl P, 2010, LECT NOTES COMPUT SC, V6258, P256, DOI 10.1007/978-3-642-14706-7_20
   Wei JY, 2020, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN48063.2020.00031
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xiang Y, 2020, IEEE T CIRCUITS-II, V67, P2717, DOI 10.1109/TCSII.2020.2973007
   Xu Q, 2021, ASIA S PACIF DES AUT, P449, DOI 10.1145/3394885.3431639
   Yoshida K, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180580
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
NR 35
TC 10
Z9 10
U1 0
U2 2
PY 2021
VL 12809
BP 96
EP 113
DI 10.1007/978-3-030-81645-2_7
UT WOS:000691381600007
DA 2023-11-16
ER

PT J
AU Mittal, S
AF Mittal, Sparsh
TI A Survey on optimized implementation of deep learning models on the
   NVIDIA Jetson platform
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Review; Embedded system; NVIDIA Jetson; Neural network; Deep learning;
   Autonomous driving; Drone; Low-power computing
ID PROCESSING-IN-MEMORY; FRAMEWORK
AB Design of hardware accelerators for neural network (NN) applications involves walking a tight rope amidst the constraints of low-power, high accuracy and throughput. NVIDIA's Jetson is a promising platform for embedded machine learning which seeks to achieve a balance between the above objectives. In this paper, we provide a survey of works that evaluate and optimize neural network applications on Jetson platform. We review both hardware and algorithmic optimizations performed for running NN algorithms on Jetson and show the real-life applications where these algorithms have been applied. We also review the works that compare Jetson with similar platforms. While the survey focuses on Jetson as an exemplar embedded system, many of the ideas and optimizations will apply just as well to existing and future embedded systems. It is widely believed that the ability to run AI algorithms on low-cost, low-power platforms will be crucial for achieving the "AI for all" vision. This survey seeks to provide a glimpse of the recent progress towards that goal.
C1 [Mittal, Sparsh] IIT Hyderabad, Hyderabad, Telangana, India.
RP Mittal, S (corresponding author), IIT Hyderabad, Hyderabad, Telangana, India.
EM sparsh@iith.ac.in
CR Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   [Anonymous], 2018, NVIDIA JETSON AGX XA
   [Anonymous], 2018, J SYST ARCHIT
   [Anonymous], 2015, IEEE T PARALLEL DIST
   [Anonymous], 2015, ARXIV150503015
   [Anonymous], 2018, JETSON TK1 MOBILE EM
   [Anonymous], P IEEE C SMARTWORLD
   [Anonymous], 2017, IEEE INTERNET THINGS
   [Anonymous], ARXIV180507029
   [Anonymous], ARXIV180306077
   [Anonymous], P IEEE SMARTWORLD UB
   Ardi M., 2018, ARXIV181001732
   Ardiyanto I, 2017, IEEE ENG MED BIO, P1760, DOI 10.1109/EMBC.2017.8037184
   Attaran N., 2018, IEEE T CIRCUITS SY 2
   Azimi S. M., 2018, ARXIV181106318
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bechtel M. G., 2017, ARXIV171208644
   Biddulph A., 2018, ARXIV180903668
   Borghi G., 2017, P 28 IEEE INT VEH S
   Bura H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (ICCC), P17, DOI 10.1109/ICCC.2018.00010
   Cai L., 2018, ARXIV181112065
   Cao S., 2018, ARXIV181106641
   Carrio A., 2018, ARXIV180800259
   Cavigelli L, 2017, 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017), P1, DOI 10.1145/3131885.3131906
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen QW, 2018, IEEE T NEUR NET LEAR, V29, P1622, DOI 10.1109/TNNLS.2017.2676110
   Deepika N, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2092, DOI 10.1109/ICACCI.2017.8126154
   Duan LY, 2018, IEEE T IMAGE PROCESS, V27, P2201, DOI 10.1109/TIP.2018.2794203
   Fridman L., 2017, ARXIV171106976
   Gamal M, 2018, SHUFFLESEG REAL TIME
   Ghazi P., 2018, ARXIV180710570
   Goyal M, 2019, IEEE J BIOMED HEALTH, V23, P1730, DOI 10.1109/JBHI.2018.2868656
   Gu SS, 2018, IEEE ASME INT C ADV, P170, DOI 10.1109/AIM.2018.8452263
   Hadidi R., 2018, ARXIV180202138
   Hartwell A., 2018, ARXIV180608641
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde G., 2018, TECS, V17, P15
   Hinton Geoffrey, 2014, NEURIPS
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Intesa L, 2017, 2017 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P94, DOI 10.1109/DSD.2017.89
   Jafari A, 2018, IEEE ASME INT C ADV, P1, DOI 10.1109/AIM.2018.8452311
   Jang Y, 2017, IEEE INT CONF COMP V, P1581, DOI 10.1109/ICCVW.2017.186
   Jung S, 2018, IEEE ROBOT AUTOM LET, V3, P2539, DOI 10.1109/LRA.2018.2808368
   Kang D, 2018, INT C COMP AID DES, P105
   Kang D, 2018, DES AUT TEST EUROPE, P715, DOI 10.23919/DATE.2018.8342102
   Kaster J, 2017, PROC NAECON IEEE NAT, P149, DOI 10.1109/NAECON.2017.8268760
   Kim C. E., 2018, 181203451 ARXIV
   Lai CK, 2017, J SYST ARCHITECT, V81, P83, DOI 10.1016/j.sysarc.2017.10.010
   Lee D, 2018, 2018 3RD IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P236, DOI 10.1109/ICITE.2018.8492605
   Lee H., 2017, ARXIV171111200
   Leroux S, 2017, KNOWL INF SYST, V52, P791, DOI 10.1007/s10115-017-1029-1
   Li J, 2018, IEEE ACCESS, V6, P68730, DOI 10.1109/ACCESS.2018.2879270
   Li Q, 2017, IEEE IND ELEC, P8405, DOI 10.1109/IECON.2017.8217476
   Lian S., 2017, DES AUT C DAC, P1
   Lin S., 2018, ARXIV181103921
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   LIU Y, 2017, ADV NEURAL INFORM PR, DOI DOI 10.1155/2017/1461520
   Luo S, 2017, CHIN AUTOM CONGR, P7091, DOI 10.1109/CAC.2017.8244056
   Madaan R, 2017, IEEE INT C INT ROBOT, P3487, DOI 10.1109/IROS.2017.8206190
   Manderson T., 2018, INT C INT ROB SYST I
   Mittal Sparsh, 2014, International Journal of Computer Aided Engineering and Technology, V6, P440, DOI 10.1504/IJCAET.2014.065419
   Mittal S., 2018, NEURAL COMPUTING APP
   Mittal S., 2018, J SYST ARCHIT
   Mittal S, 2014, TECHNICAL REPORT
   Mittal S, 2015, INT J INDIAN CULT BU, V11, P1, DOI 10.1504/IJICBM.2015.070246
   Mittal S, 2019, MACH LEARN KNOW EXTR, V1, P75, DOI 10.3390/make1010005
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1537, DOI 10.1109/TPDS.2015.2442980
   Mittal S, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2856125
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Mittal S, 2014, SUSTAIN COMPUT-INFOR, V4, P33, DOI 10.1016/j.suscom.2013.11.001
   Molchanov Pavlo, 2016, ARXIV161106440
   Montanari A, 2018, SPRBRIEF MOLEC SCI, P29, DOI 10.1007/978-3-319-74132-1_3
   Otterness N, 2017, IEEE REAL TIME, P353, DOI 10.1109/RTAS.2017.3
   Page A, 2016, IEEE INT SYMP CIRC S, P1086, DOI 10.1109/ISCAS.2016.7527433
   Pedoeem J., 2018, ARXIV181105588
   Pierre JM, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P94, DOI 10.1109/ICCAR.2018.8384651
   Qi X, 2018, 2018 18TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID COMPUTING (CCGRID), P641, DOI 10.1109/CCGRID.2018.00087
   Rallapalli S, 2016, IEEE T CIRC SYST VID
   Ran L., 2016, INT C ADV MOB COMP M, P342
   Reddy B, 2017, IEEE COMPUT SOC CONF, P438, DOI 10.1109/CVPRW.2017.59
   Redmon J., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91
   Regier P., 2018, INT C HUM ROB
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rouhani BD, 2016, I SYMPOS LOW POWER E, P112, DOI 10.1145/2934583.2934599
   Sa I, 2018, IEEE ROBOT AUTOM LET, V3, P588, DOI 10.1109/LRA.2017.2774979
   Sadiq S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P436, DOI 10.1109/IRI.2018.00070
   Sanket N. J., 2018, IEEE ROB AUTOM LETT
   Sarlin Paul-Edouard, 2018, C ROB LEARN CORL
   Scrbak M, 2017, J SYST ARCHITECT, V75, P59, DOI 10.1016/j.sysarc.2016.08.001
   Shakeel A., 2017, THESIS
   Smolyanskiy N, 2017, IEEE INT C INT ROBOT, P4241, DOI 10.1109/IROS.2017.8206285
   Stanoev A., 2017, P 2017 IEEE INT C IM, P1, DOI [10.1109/IST.2017.8261524, DOI 10.1109/IST.2017.8261524]
   Sun Y, 2018, BIOSYST ENG, V176, P140, DOI 10.1016/j.biosystemseng.2018.10.012
   Susanto, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON ENGINEERING TECHNOLOGY AND APPLICATIONS (IES-ETA), P146, DOI 10.1109/ELECSYM.2017.8240393
   Tao SQ, 2018, J ROBOT, V2018, DOI 10.1155/2018/5868915
   Taylor J, 2018, TLS-TIMES LIT SUPPL, P31
   Tijtgat N, 2017, IEEE INT CONF COMP V, P2110, DOI 10.1109/ICCVW.2017.247
   Tomè D, 2016, SIGNAL PROCESS-IMAGE, V47, P482, DOI 10.1016/j.image.2016.05.007
   Duong TT, 2018, 2018 19TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P123, DOI 10.1109/SNPD.2018.8441073
   Tsai YC, 2018, INT SYMPOS VLSI DES, DOI 10.1109/ICOPS35962.2018.9575835
   Vinyals O., 2015, NEURAL INFORM PROCES, V28, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang B. H., 2018, ARXIV181011408
   Wang C, 2017, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2017.7858304
   Wang JJ, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P159, DOI 10.1109/SEC.2018.00019
   Wang Ze, 2018, ARXIV180701726
   Xie XF, 2018, ACM T EMBED COMPUT S, V17, DOI 10.1145/3122788
   Xu X., 2018, ARXIV180900110
   Yang T, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111829
   Yazdani Reza, 2017, IEEE Micro, V37, P22, DOI 10.1109/MM.2017.15
   Yosinski Jason, 2014, ADV NEURAL INFORM PR
   Zeng X, 2017, MOBISYS'17: PROCEEDINGS OF THE 15TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P56, DOI 10.1145/3081333.3081336
   Zhang X., 2018, HOTEDGE
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 116
TC 73
Z9 73
U1 11
U2 49
PD AUG
PY 2019
VL 97
BP 428
EP 442
DI 10.1016/j.sysarc.2019.01.011
UT WOS:000476961500032
DA 2023-11-16
ER

PT J
AU Mirhoseini, A
   Goldie, A
   Yazgan, M
   Jiang, JW
   Songhori, E
   Wang, S
   Lee, YJ
   Johnson, E
   Pathak, O
   Nazi, A
   Pak, J
   Tong, A
   Srinivasa, K
   Hang, WL
   Tuncer, E
   Le, QV
   Laudon, J
   Ho, RC
   Carpenter, R
   Dean, J
AF Mirhoseini, Azalia
   Goldie, Anna
   Yazgan, Mustafa
   Jiang, Joe Wenjie
   Songhori, Ebrahim
   Wang, Shen
   Lee, Young-Joon
   Johnson, Eric
   Pathak, Omkar
   Nazi, Azade
   Pak, Jiwoo
   Tong, Andy
   Srinivasa, Kavya
   Hang, William
   Tuncer, Emre
   Le, Quoc V.
   Laudon, James
   Ho, Richard
   Carpenter, Roger
   Dean, Jeff
TI A graph placement methodology for fast chip design
SO NATURE
DT Article
ID OPTIMIZATION; QUALITY
AB Machine learning tools are used to greatly accelerate chip layout design, by posing chip floorplanning as a reinforcement learning problem and using neural networks to generate high-performance chip layouts.
   Chip floorplanning is the engineering task of designing the physical layout of a computer chip. Despite five decades of research(1), chip floorplanning has defied automation, requiring months of intense effort by physical design engineers to produce manufacturable layouts. Here we present a deep reinforcement learning approach to chip floorplanning. In under six hours, our method automatically generates chip floorplans that are superior or comparable to those produced by humans in all key metrics, including power consumption, performance and chip area. To achieve this, we pose chip floorplanning as a reinforcement learning problem, and develop an edge-based graph convolutional neural network architecture capable of learning rich and transferable representations of the chip. As a result, our method utilizes past experience to become better and faster at solving new instances of the problem, allowing chip design to be performed by artificial agents with more experience than any human designer. Our method was used to design the next generation of Google's artificial intelligence (AI) accelerators, and has the potential to save thousands of hours of human effort for each new generation. Finally, we believe that more powerful AI-designed hardware will fuel advances in AI, creating a symbiotic relationship between the two fields.
C1 [Mirhoseini, Azalia; Goldie, Anna; Jiang, Joe Wenjie; Songhori, Ebrahim; Wang, Shen; Johnson, Eric; Nazi, Azade; Le, Quoc V.; Laudon, James; Dean, Jeff] Google, Brain Team, Google Res, Mountain View, CA 94043 USA.
   [Yazgan, Mustafa; Lee, Young-Joon; Pathak, Omkar; Pak, Jiwoo; Tong, Andy; Srinivasa, Kavya; Tuncer, Emre; Ho, Richard; Carpenter, Roger] Google, Google Chip Implementat & Infrastruct CI2 Team, Sunnyvale, CA USA.
   [Goldie, Anna; Hang, William] Stanford Univ, Comp Sci Dept, Stanford, CA 94305 USA.
RP Mirhoseini, A; Goldie, A (corresponding author), Google, Brain Team, Google Res, Mountain View, CA 94043 USA.; Goldie, A (corresponding author), Stanford Univ, Comp Sci Dept, Stanford, CA 94305 USA.
EM azalia@google.com; agoldie@google.com
CR Agnihotri A. R., 2005, P 2005 INT S PHYS DE, P230
   Ajayi T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3326334
   Alpert C., 2005, P ISPD, P200
   Alpert CJ, 1999, VLSI DES, V10, P99, DOI 10.1155/1999/93607
   Alpert CJ, 1996, APCCAS '96 - IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS '96, P298, DOI 10.1109/APCAS.1996.569275
   [Anonymous], 1998, HMETIS HYPERGRAPH PA
   [Anonymous], 2016, NEURAL COMBINATORIAL
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2020, REPLACE SOFTWARE OPE
   [Anonymous], 2006, P 2006 IEEE ACM INT
   Aslam B, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P423, DOI 10.1109/ISCC.2012.6249333
   Barrett T, P AAAI C ART INT 202, V34, P3243
   Bojja Venkatakrishnan S., 2019, ADV NEURAL INFORM PR, P3981
   Brenner U, 2008, IEEE T COMPUT AID D, V27, P1607, DOI 10.1109/TCAD.2008.927674
   Breuer Melvin A., 1977, PROC 14 DESIGN AUTOM, P284
   Caldwell A. E., 2000, Proceedings ASP-DAC 2000. Asia and South Pacific Design Automation Conference 2000 with EDA TechnoFair 2000. (Cat. No.00EX389), P661, DOI 10.1109/ASPDAC.2000.835182
   Caldwell AE, 1999, IEEE T COMPUT AID D, V18, P1265, DOI 10.1109/43.784119
   Chen HY, 2003, DES AUT CON, P794
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P1228, DOI 10.1109/TCAD.2008.923063
   Cheng CK, 2019, IEEE T COMPUT AID D, V38, P1717, DOI 10.1109/TCAD.2018.2859220
   CHENG CK, 1984, IEEE T COMPUT AID D, V3, P218, DOI 10.1109/TCAD.1984.1270078
   Cherniak C, 2004, P NATL ACAD SCI USA, V101, P1081, DOI 10.1073/pnas.0305212101
   DUNLOP AE, 1985, IEEE T COMPUT AID D, V4, P92, DOI 10.1109/TCAD.1985.1270101
   Fiduccia C.M., 1982, P 19 DES AUT C JUN, P175, DOI DOI 10.1109/DAC.1982.1585498
   Fogaça M, 2020, INTEGRATION, V74, P32, DOI 10.1016/j.vlsi.2020.03.007
   Fogaça M, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P569, DOI 10.1145/3287624.3287676
   Hu B, 2005, IEEE T COMPUT AID D, V24, P1188, DOI 10.1109/TCAD.2005.850802
   Huang YH, 2019, DES AUT TEST EUROPE, P180, DOI [10.23919/date.2019.8715126, 10.23919/DATE.2019.8715126]
   Ioffe S., 2015, INT C MACH LEARN ICM, P448
   Kahng A. B., 1998, P 1998 INT S PHYS DE, P190, DOI [10.1145/274535.274563, DOI 10.1145/274535.274563]
   Kahng A. B., 2003, P 2003 INT WORKSH SY, DOI [10.1145/639929.639942, DOI 10.1145/639929.639942]
   Kahng A. B., 2006, P 2006 INT WORKSH SY, DOI [10.1145/1117278.1117282, DOI 10.1145/1117278.1117282]
   Kahng AB, 2005, IEEE IC CAD, P891, DOI 10.1109/ICCAD.2005.1560188
   Kahng AB, 2004, ICCAD-2004: INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, IEEE/ACM DIGEST OF TECHNICAL PAPERS, P565, DOI 10.1109/ICCAD.2004.1382641
   Kahng AB, 2005, IEEE T COMPUT AID D, V24, P734, DOI 10.1109/TCAD.2005.846366
   Kahng AB, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'18), P68, DOI 10.1145/3177540.3177554
   Kahng AB, 2018, DES AUT CON, DOI 10.1145/3195970.3199854
   Kim MC, 2012, DES AUT CON, P747
   Kim MC, 2012, ISPD 12: PROCEEDINGS OF THE 2012 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P193
   Kim MC, 2012, IEEE T COMPUT AID D, V31, P50, DOI 10.1109/TCAD.2011.2170567
   KIPF T., 2016, P INT C LEARN REPR
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Langford J., 2008, ADV NEURAL INFORM PR, P817
   Lin T, 2013, ICCAD-IEEE ACM INT, P357, DOI 10.1109/ICCAD.2013.6691143
   Lin Y, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013302
   Lu JW, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'16), P11, DOI 10.1145/2872334.2872361
   Lu JW, 2015, IEEE T COMPUT AID D, V34, P685, DOI 10.1109/TCAD.2015.2391263
   Lu JW, 2015, ACM T DES AUTOMAT EL, V20, DOI 10.1145/2699873
   Luo T., P AS S PAC DES AUT C, P346
   Markov IL, 2015, P IEEE, V103, P1985, DOI 10.1109/JPROC.2015.2478963
   Medlock J, 2009, SCIENCE, V325, P1705, DOI 10.1126/science.1175570
   Mirhoseini A., 2018, ICLR
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Nair V., 2010, PROC 27 INT C INT C
   Naylor W. C., 2001, US Patent, Patent No. [6,301,693, 6301693]
   Nazi A., 2019, INT C LEARN REPR WOR
   Obermeier B., 2005, P ACM IEEE INT S PHY, P242, DOI DOI 10.1145/1055137.1055190
   Paliwal A., 2020, P INT C LEARN REPR
   Roy JA, 2007, INTEGR CIRCUIT SYST, P97, DOI 10.1007/978-0-387-68739-1_5
   Sarrafzadeh Majid, 2003, MODERN PLACEMENT TEC, P57
   Schulman J., 2017, PROXIMAL POLICY OPTI
   Sechen C., 1986, 23rd ACM/IEEE Design Automation Conference. Proceedings 1986 (Cat. No.86CH2288-9), P432, DOI 10.1145/318013.318083
   SHAHOOKAR K, 1991, COMPUT SURV, V23, P143, DOI 10.1145/103724.103725
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Spindler P, 2008, IEEE T COMPUT AID D, V27, P1398, DOI 10.1109/TCAD.2008.925783
   Tang ML, 2007, IEEE T SYST MAN CY B, V37, P62, DOI 10.1109/TSMCB.2006.883268
   Tsay R.-S., 1988, P 25 ACM IEEE DES AU, P318
   Usunier Nicolas, 2017, P INT C LEARN REPR I
   Viswanathan N, 2007, DES AUT CON, P453, DOI 10.1109/DAC.2007.375208
   Viswanathan N, 2007, INTEGR CIRCUIT SYST, P193, DOI 10.1007/978-0-387-68739-1_8
   [谢志鹏 Xie Zhipeng], 2018, [高分子通报, Polymer Bulletin], P1
   Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114
   Zhang M., 2018, NEURIPS, P5171
   Zhou Y., 2021, TRANSFERABLE GRAPH O
   Zhou Y., 2019, GDP GEN DEVICE PLACE
   Zoph B., 2017, P INT C LEARN REPR
NR 76
TC 139
Z9 141
U1 34
U2 136
PD JUN 10
PY 2021
VL 594
IS 7862
BP 207
EP +
DI 10.1038/s41586-021-03544-w
UT WOS:000660636100017
HC Y
HP N
DA 2023-11-16
ER

PT J
AU Zemouri, R
   Devalland, C
   Valmary-Degano, S
   Zerhouni, N
AF Zemouri, Ryad
   Devalland, Christine
   Valmary-Degano, Severine
   Zerhouni, Noureddine
TI Neural network: A future in pathology?
SO ANNALES DE PATHOLOGIE
DT Review
DE Artificial network; Artificial neural networks; Digital pathology;
   Computer-assisted diagnosis
ID DIGITAL PATHOLOGY; IMAGE-ANALYSIS; DEEP; DIAGNOSIS
AB Artificial Intelligence, in particular deep neural networks are the most used machine learning technics in the biomedical field. Artificial neural networks are inspired by the biological neurons; they are interconnected and follow mathematical models. Two phases are required: a learning and a using phase. The two main applications are classification and regression Computer tools such as GPU computational accelerators or some development tools such as MATLAB libraries are used. Their application field is vast and allows the management of big data in genomics and molecular biology as well as the automated analysis of histological slides. The Whole Slide Image scanner can acquire and store slides in the form of digital images. This scanning associated with deep learning algorithms allows automatic recognition of lesions through the automatic recognition of regions of interest previously validated by the pathologist. These computer aided diagnosis techniques are tested in particular in mammary pathology and dermatopathology. They will allow an efficient and a more comprehensive vision, and will provide diagnosis assistance in pathology by correlating several biomedical data such as clinical, radiological and molecular biology data. (C) 2019 Elsevier Masson SAS. All rights reserved.
C1 [Zemouri, Ryad] HESAM Univ, CEDRIC, Lab Conservatoire Natl Arts & Metiers CNAM, 292 Rue St Martin, F-750141 Paris 03, France.
   [Devalland, Christine] Hop Nord Franche Comte, Serv Anat & Cytol Pathol, 100 Route Moval, F-90400 Trevenans, France.
   [Valmary-Degano, Severine] CHU Grenoble Alpes, Serv Anat & Cytol Pathol, TSA10217, F-38043 Grenoble, France.
   [Zerhouni, Noureddine] Univ Bourgogne Franche Comte, CNR, ENSMM, FEMTO ST Inst, F-25000 Besancon, France.
RP Zemouri, R (corresponding author), HESAM Univ, CEDRIC, Lab Conservatoire Natl Arts & Metiers CNAM, 292 Rue St Martin, F-750141 Paris 03, France.
EM ryad.zemouri@cnam.fraa; Christine.devalland@hnfc.fr;
   svalmarydegano@chu-grenoble.fr; zerhouni@ens2m.fr
CR Angermueller C, 2016, MOL SYST BIOL, V12, DOI 10.15252/msb.20156651
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Devalland C, 2017, VIRCHOWS ARCH EUR J, V471, P1, DOI [10.1007/s00428-017-2205-0, DOI 10.1007/S00428-017-2205-0]
   Feng YQ, 2018, INT J COMPUT ASS RAD, V13, P179, DOI 10.1007/s11548-017-1663-9
   Grabe N, 2018, PATHOLOGE, V39, P539, DOI 10.1007/s00292-018-0540-9
   Granter SR, 2017, ARCH PATHOL LAB MED, V141, P624, DOI 10.5858/arpa.2017-0023-ED
   Hamilton PW, 2014, METHODS, V70, P59, DOI 10.1016/j.ymeth.2014.06.015
   Henriet J, 2016, ANN DERMATOL VENER, V143, pS240, DOI [10.1016/j.annder.2016.09.325, DOI 10.1016/J.ANNDER.2016.09.325]
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jones W, 2017, EMERG TOP LIFE SCI, V1, P257, DOI 10.1042/ETLS20160025
   Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Olsen Thomas George, 2018, J Pathol Inform, V9, P32, DOI 10.4103/jpi.jpi_31_18
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Saha M, 2016, TISSUE CELL, V48, P461, DOI 10.1016/j.tice.2016.07.006
   Sheikhzadeh F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190783
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Steiner DF, 2018, AM J SURG PATHOL, V42, P1636, DOI 10.1097/PAS.0000000000001151
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Turkki Riku, 2016, J Pathol Inform, V7, P38, DOI 10.4103/2153-3539.189703
   Vandenberghe ME, 2017, SCI REP-UK, V7, DOI 10.1038/srep45938
   Veta M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161286
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zemouri R., 2018, IFAC PAPERSONLINE, V51, P98, DOI [DOI 10.1016/j.ifacol.2018.11.660, 10.1016/j.ifacol.2018.11.660]
NR 30
TC 16
Z9 16
U1 2
U2 12
PD APR
PY 2019
VL 39
IS 2
BP 119
EP 129
DI 10.1016/j.annpat.2019.01.004
UT WOS:000467002900010
DA 2023-11-16
ER

PT J
AU Jain, S
   Ankit, A
   Chakraborty, I
   Gokmen, T
   Rasch, M
   Haensch, W
   Roy, K
   Raghunathan, A
AF Jain, S.
   Ankit, A.
   Chakraborty, I
   Gokmen, T.
   Rasch, M.
   Haensch, W.
   Roy, K.
   Raghunathan, A.
TI Neural network accelerator design with resistive crossbars:
   Opportunities and challenges
SO IBM JOURNAL OF RESEARCH AND DEVELOPMENT
DT Article
ID PHASE-CHANGE MEMORY; ARRAY; SCALE
AB Deep neural networks (DNNs) achieve best-known accuracies in many machine learning tasks involved in image, voice, and natural language processing and are being used in an ever-increasing range of applications. However, their algorithmic benefits are accompanied by extremely high computation and storage costs, sparking intense efforts in optimizing the design of computing platforms for DNNs. Today, graphics processing units (GPUs) and specialized digital CMOS accelerators represent the state-of-the-art in DNN hardware, with near-term efforts focusing on approximate computing through reduced precision. However, the ever-increasing complexities of DNNs and the data they process have fueled an active interest in alternative hardware fabrics that can deliver the next leap in efficiency. Resistive crossbars designed using emerging nonvolatile memory technologies have emerged as a promising candidate building block for future DNN hardware fabrics since they can natively execute massively parallel vector-matrix multiplications (the dominant compute kernel in DNNs) in the analog domain within the memory arrays. Leveraging in-memory computing and dense storage, resistive-crossbar-based systems cater to both the high computation and storage demands of complex DNNs and promise energy efficiency beyond current DNN accelerators by mitigating data transfer and memory bottlenecks. However, several design challenges need to be addressed to enable their adoption. For example, the overheads of peripheral circuits (analog-to-digital converters and digital-to-analog converters) and other components (scratchpad memories and on-chip interconnect) may significantly diminish the efficiency benefits at the system level. Additionally, the analog crossbar computations are intrinsically subject to noise due to a range of device- and circuit-level nonidealities, potentially leading to lower accuracy at the application level. In this article, we highlight the prospects for designing hardware accelerators for neural networks using resistive crossbars. We also underscore the key open challenges and some possible approaches to address them.
C1 [Jain, S.; Ankit, A.; Chakraborty, I; Roy, K.; Raghunathan, A.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Gokmen, T.; Rasch, M.; Haensch, W.] IBM Thomas TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Jain, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM jain130@purdue.edu; aankit@purdue.edu; ichakra@purdue.edu;
   tgokmen@us.ibm.com; malte.rasch@ibm.com; whaensch@us.ibm.com;
   kaushik@purdue.edu; raghunathan@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit A, 2017, DES AUT CON, DOI 10.1145/3061639.3062311
   Ankit A, 2017, ICCAD-IEEE ACM INT, P533, DOI 10.1109/ICCAD.2017.8203823
   [Anonymous], 2019, P ADV NEURAL INFORM
   [Anonymous], 2015, P 2015 52 ACM EDAC I
   [Anonymous], ANALOG COMPUTATION F
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], P 2015 IEEE INT EL D
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2019, ARXIV190602698
   [Anonymous], EFFICIENT CONVNETS A
   [Anonymous], P 53 ANN DES AUT C
   [Anonymous], P 54 ACM EDAC IEEE D
   [Anonymous], AI REVOLUTION WHY DE
   [Anonymous], 2015, 32 ICML
   [Anonymous], IEEE ACCESS
   [Anonymous], P IEDM
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen P, 2015, 2D MATER, V2, DOI 10.1088/2053-1583/2/3/034009
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gokmen T, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00745
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   Han S., 2015, C NEUR INF PROC SYST
   Harlap A., 2018, PIPEDREAM FAST EFFIC
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu M, 2012, DES AUT CON, P498
   Ielmini D, 2007, INT EL DEVICES MEET, P939, DOI 10.1109/IEDM.2007.4419107
   Jain S., 2018, ARXIV180900072
   Jeong Y, 2018, IEEE T NANOTECHNOL, V17, P184, DOI 10.1109/TNANO.2017.2784364
   Jerry Matthew, 2017, 2017 IEEE International Electron Devices Meeting (IEDM), P621, DOI 10.1109/IEDM.2017.8268338
   Jerry M, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aad6f8
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kataeva I., 2015, 2015 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2015.7280785, DOI 10.1109/IJCNN.2015.7280785]
   Kim S, 2017, MIDWEST SYMP CIRCUIT, P422, DOI 10.1109/MWSCAS.2017.8052950
   Kull L, 2013, ISSCC DIG TECH PAP I, V56, P468, DOI 10.1109/ISSCC.2013.6487818
   Lee D, 2013, IEEE T VLSI SYST, V21, P1583, DOI 10.1109/TVLSI.2012.2217514
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Liu BY, 2014, ICCAD-IEEE ACM INT, P63, DOI 10.1109/ICCAD.2014.7001330
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Merced-Grafals EJ, 2016, NANOTECHNOLOGY, V27, DOI 10.1088/0957-4484/27/36/365202
   Micikevicius P., 2017, ARXIV171003740
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Ranjan A, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317935
   Sengupta A, 2017, APPL PHYS REV, V4, DOI 10.1063/1.5012763
   Sengupta A, 2016, IEEE T BIOMED CIRC S, V10, P1152, DOI 10.1109/TBCAS.2016.2525823
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
   Wang PN, 2019, IEEE T VLSI SYST, V27, P988, DOI 10.1109/TVLSI.2018.2882194
   Wang YX, 2017, P INT COMP SOFTW APP, P85, DOI 10.1109/COMPSAC.2017.12
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Xia LX, 2016, DES AUT TEST EUROPE, P469
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
   Yan BN, 2017, ICCAD-IEEE ACM INT, P541, DOI 10.1109/ICCAD.2017.8203824
   Zhang JT, 2016, SYMP VLSI CIRCUITS
NR 69
TC 13
Z9 13
U1 0
U2 11
PD NOV-DEC
PY 2019
VL 63
IS 6
AR 10
DI 10.1147/JRD.2019.2947011
UT WOS:000498917500011
DA 2023-11-16
ER

PT J
AU Morijiri, K
   Mihana, T
   Kanno, K
   Naruse, M
   Uchida, A
AF Morijiri, Kensei
   Mihana, Takatomo
   Kanno, Kazutaka
   Naruse, Makoto
   Uchida, Atsushi
TI Decision making for large-scale multi-armed bandit problems using bias
   control of chaotic temporal waveforms in semiconductor lasers
SO SCIENTIFIC REPORTS
DT Article
ID SINGLE-PHOTON; OPTIMIZATION; GENERATION
AB Decision making using photonic technologies has been intensively researched for solving the multi-armed bandit problem, which is fundamental to reinforcement learning. However, these technologies are yet to be extended to large-scale multi-armed bandit problems. In this study, we conduct a numerical investigation of decision making to solve large-scale multi-armed bandit problems by controlling the biases of chaotic temporal waveforms generated in semiconductor lasers with optical feedback. We generate chaotic temporal waveforms using the semiconductor lasers, and each waveform is assigned to a slot machine (or choice) in the multi-armed bandit problem. The biases in the amplitudes of the chaotic waveforms are adjusted based on rewards using the tug-of-war method. Subsequently, the slot machine that yields the maximum-amplitude chaotic temporal waveform with bias is selected. The scaling properties of the correct decision-making process are examined by increasing the number of slot machines to 1024, and the scaling exponent of the power-law distribution is 0.97. We demonstrate that the proposed method outperforms existing software algorithms in terms of the scaling exponent. This result paves the way for photonic decision making in large-scale multi-armed bandit problems using photonic accelerators.
C1 [Morijiri, Kensei; Mihana, Takatomo; Kanno, Kazutaka; Uchida, Atsushi] Saitama Univ, Dept Informat & Comp Sci, Sakura Ku, 255 Shimo Okubo, Saitama, Saitama 3388570, Japan.
   [Naruse, Makoto] Univ Tokyo, Dept Informat Phys & Comp, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
RP Morijiri, K; Uchida, A (corresponding author), Saitama Univ, Dept Informat & Comp Sci, Sakura Ku, 255 Shimo Okubo, Saitama, Saitama 3388570, Japan.
EM kensei.1221.0926.snow@gmail.com; auchida@mail.saitama-u.ac.jp
CR Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Bueno J, 2018, OPTICA, V5, P756, DOI 10.1364/OPTICA.5.000756
   Chauvet N, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77340-3
   Chauvet N, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48647-7
   Chen XL, 2019, J LIGHTWAVE TECHNOL, V37, P4155, DOI 10.1109/JLT.2019.2923615
   Duan ZC, 2022, IEICE NONLINEAR THEO, V13, P72, DOI 10.1587/nolta.13.72
   Han YN, 2020, PHOTONICS RES, V8, P1792, DOI 10.1364/PRJ.403319
   Homma R, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45754-3
   Inagaki T, 2016, SCIENCE, V354, P603, DOI 10.1126/science.aah4243
   Ishihara T, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3178452
   Kanno K, 2012, PHYS REV E, V86, DOI 10.1103/PhysRevE.86.066202
   Kim SJ, 2016, PHILOSOPHIES, V1, P245, DOI 10.3390/philosophies1030245
   Kim SJ, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/8/083023
   Kim SJ, 2010, BIOSYSTEMS, V101, P29, DOI 10.1016/j.biosystems.2010.04.002
   Kima SJ, 2014, IEICE NONLINEAR THEO, V5, P198, DOI 10.1587/nolta.5.198
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Kuleshov V., 2016, PREPRINT
   LANG R, 1980, IEEE J QUANTUM ELECT, V16, P347, DOI 10.1109/JQE.1980.1070479
   Larger L, 2012, OPT EXPRESS, V20, P3241, DOI 10.1364/OE.20.003241
   Maeda S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84199-5
   Mihana T, 2020, OPT EXPRESS, V28, P40112, DOI 10.1364/OE.411140
   Mihana T, 2019, OPT EXPRESS, V27, P26989, DOI 10.1364/OE.27.026989
   Mihana T, 2018, COMPLEXITY, DOI 10.1155/2018/4318127
   Naruse M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29117-y
   Naruse M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08585-8
   Naruse M, 2016, ACS PHOTONICS, V3, P2505, DOI 10.1021/acsphotonics.6b00742
   Naruse M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13253
   Oda A, 2022, IEICE NONLINEAR THEO, V13, P112, DOI 10.1587/nolta.13.112
   Ohtsubo J, 2017, SPRINGER SER OPT SCI, V111, P1, DOI 10.1007/978-3-319-56138-7
   Okada N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8877660
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sutton RS., 1998
   Takano K, 2018, OPT EXPRESS, V26, P29424, DOI 10.1364/OE.26.029424
   Takeuchi S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58541-2
   Thompson WR, 1933, BIOMETRIKA, V25, P285, DOI 10.2307/2332286
   Uchida A., 2012, OPTICAL COMMUNICATIO, P165, DOI [10.1002/9783527640331, DOI 10.1002/9783527640331]
   Uchida A, 2008, NAT PHOTONICS, V2, P728, DOI 10.1038/nphoton.2008.227
NR 39
TC 3
Z9 3
U1 1
U2 7
PD MAY 16
PY 2022
VL 12
IS 1
AR 8073
DI 10.1038/s41598-022-12155-y
UT WOS:000796701700030
DA 2023-11-16
ER

PT C
AU Hall, M
   Betz, V
AF Hall, Mathew
   Betz, Vaughn
GP IEEE Comp Soc
TI From TensorFlow Graphs to LUTs and Wires: Automated Sparse and
   Physically Aware CNN Hardware Generation
SO 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2020)
DT Proceedings Paper
CT 19th International Conference on Field-Programmable Technology (ICFPT)
CY DEC 07-11, 2020
CL ELECTR NETWORK
AB We present algorithms and an architectural methodology to enable zero skipping while increasing frequency in per-layer customized data flow Convolutional Neural Network (CNN) inference accelerators for FPGAs. Data flow architectures leverage the static configurability of FPGAs to increase processing efficiency, reduce dynamic muxing, and save routing wires. While this holds out the promise of high efficiency, these architectures require a different circuit to implement every CNN, making automated exploration and implementation of the accelerator essential. Each accelerator has layer-specific subcircuits with CNN-specific parallelization parameters and CNN graph topology-based interconnection that impact fanout and routing congestion, which lower the hardware operating frequency with naive implementation strategies. To address this, we designed latency insensitive hardware templates that build a model of signal fanout and span and instantiate different structures within each compute unit to ensure a high operating frequency regardless of CNN topology and parallelism settings. We also leverage the hardware efficiency of data flow architectures to add support for zero-weight-skipping at a normalized area cost less than one half of prior work. The overall optimization tool chooses parallelism settings for each layer-specific hardware unit to balance throughput across all layers of the CNN, while respecting the FPGA device limits on available buffering space and DSP blocks. Together these optimizations enable throughput on a sparse Resnet-50 model at a batch size of 1 of 4550 images/s, which is nearly 4x the throughput of NVIDIA's fastest machine learning targeted GPU, the V100, and outperforms all prior work on FPGAs.
C1 [Hall, Mathew; Betz, Vaughn] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Betz, Vaughn] Vector Inst, Toronto, ON, Canada.
RP Hall, M (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM mathew.hall@mail.utoronto.ca; vaughn@ece.utoronto.ca
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Boutros A, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242898
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Molchanov Pavlo, 2016, ARXIV161106440
   NVIDIA Corporation, 2019, NVIDIA TESL DEEP LEA
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Tan MX, 2019, PR MACH LEARN RES, V97
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Vincent Kevin, 2017, ICLR
   Wu D, 2019, I C FIELD PROG LOGIC, P136, DOI 10.1109/FPL.2019.00030
   Zeng W., 2019, MLPRUNE MULTILAYER P
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030295
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 23
TC 9
Z9 9
U1 1
U2 2
PY 2020
BP 56
EP 65
DI 10.1109/ICFPT51103.2020.00017
UT WOS:000676387300008
DA 2023-11-16
ER

PT J
AU Roy, S
   Ali, M
   Raghunathan, A
AF Roy, Sourjya
   Ali, Mustafa
   Raghunathan, Anand
TI PIM-DRAM: Accelerating Machine Learning Workloads Using Processing in
   Commodity DRAM
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Random access memory; Computer architecture; Bandwidth; Microprocessors;
   Organizations; Decoding; Voltage; Deep Neural Network (DNN) inference;
   in-memory computing; Dynamic Random Access Memory (DRAM); neural
   networks
AB Deep Neural Networks (DNNs) have transformed the field of machine learning (ML) and are widely deployed in many applications involving image, video, speech and natural language processing. The increasing compute demands of DNNs have been widely addressed through Graphics Processing Units (GPUs) and specialized accelerators. However, as model sizes grow, these von Neumann architectures require very high off-chip memory bandwidth to keep the processing elements utilized, as a majority of the data resides in the main memory. Processing in memory is actively being explored as a promising solution to the memory wall bottleneck for ML workloads. In this work, we propose a new DRAM-based processing-in-memory (PIM) multiplication primitive coupled with intra-bank accumulation to accelerate matrix vector multiply operations in ML workloads. The proposed multiplication primitive adds <1% area overhead and does not require any change to the DRAM peripherals. Subsequently, we design a DRAM-based PIM architecture (PIM-DRAM) and a data mapping scheme for executing DNNs on the proposed architecture. System evaluations performed on the AlexNet, VGG16 and ResNet18 DNNs show that the proposed architecture, mapping, and data flow can provide up to 19.5x speedup over an NVIDIA Titan Xp GPU, highlighting the potential of processing in memory for future generations of DNN hardware.
C1 [Roy, Sourjya; Ali, Mustafa; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Roy, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM roy48@purdue.edu; ali102@purdue.edu; raghunathan@purdue.edu
CR Ali ME, 2020, IEEE T CIRCUITS-I, V67, P155, DOI 10.1109/TCSI.2019.2945617
   [Anonymous], AI REVOLUTION WHY DE
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Hajinazar N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P329, DOI 10.1145/3445814.3446749
   Hannun A., 2014, ARXIV14125567, P1
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim YB, 1999, INTEGRATION, V27, P179, DOI 10.1016/S0167-9260(99)00006-1
   Seshadri Vivek, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P185, DOI 10.1145/2540708.2540725
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Vogelsang T., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P363, DOI 10.1109/MICRO.2010.42
   Xin X, 2020, INT S HIGH PERF COMP, P303, DOI 10.1109/HPCA47549.2020.00033
NR 17
TC 3
Z9 3
U1 0
U2 5
PD DEC
PY 2021
VL 11
IS 4
BP 701
EP 710
DI 10.1109/JETCAS.2021.3127517
UT WOS:000730514000018
DA 2023-11-16
ER

PT C
AU Roy, K
   Chakraborty, I
   Ali, M
   Ankit, A
   Agrawal, A
AF Roy, Kaushik
   Chakraborty, Indranil
   Ali, Mustafa
   Ankit, Aayush
   Agrawal, Amogh
GP IEEE
TI In-Memory Computing in Emerging Memory Technologies for Machine
   Learning: An Overview
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
AB The saturating scaling trends of CMOS technology have fuelled the exploration of emerging non-volatile memory (NVM) technologies as a promising alternative for accelerating data intensive Machine Learning (ML) workloads. To that effect, researchers have explored special-purpose accelerators based on NVM crossbar primitives. NVM crossbars have high storage density and can efficiently perform massively parallel in-situ Matrix Vector Multiplication (MVM) operations, the key computation in ML workloads, helping overcome the memory bottleneck faced by von Neumann architectures. Despite the promises, analog computing nature of NVM crossbars can lead to functional errors due to device and circuit non-idealities such as parasitic resistances and device non-linearities. Moreover, NVM crossbars need high cost peripheral circuitry to be integrated in large scale systems. Hence, there is a need to study different levels of the design stack to realize the potential of this technology.
   In this paper, we present an overview of in-memory computing in NVM crossbars for ML workloads. We discuss the basic anatomy of NVM crossbars and highlight the challenges faced at the primitive level. Next, we present how the high storage density of NVM crossbars can enable spatially distributed architectures. Further, we present various modeling and evaluation tools which can effectively help us study the functionality as well as performance of NVM crossbar systems. Finally, we provide an outlook on the future research directions in this field.
C1 [Roy, Kaushik; Chakraborty, Indranil; Ali, Mustafa; Ankit, Aayush; Agrawal, Amogh] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Roy, K (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM kaushik@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Agrawal A., 2019, ARXIV190700285
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit Aayush, 2019, ARXIV191211516
   [Anonymous], 2019, ARXIV190602698
   Bavandpour M, 2018, INT EL DEVICES MEET
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chakraborty Indranil, 2020, ARXIV200306902
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Fong XY, 2016, IEEE T COMPUT AID D, V35, P1, DOI 10.1109/TCAD.2015.2481793
   Guan XM, 2012, IEEE ELECTR DEVICE L, V33, P1405, DOI 10.1109/LED.2012.2210856
   Hamann HF, 2006, NAT MATER, V5, P383, DOI 10.1038/nmat1627
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jaiswal Akhilesh, 2019, IEEE TVLSI
   Jeong Y, 2018, IEEE T NANOTECHNOL, V17, P184, DOI 10.1109/TNANO.2017.2784364
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Liu BY, 2015, DES AUT CON, DOI 10.1145/2744769.2744930
   Liu BY, 2014, ICCAD-IEEE ACM INT, P63, DOI 10.1109/ICCAD.2014.7001330
   Liu CF, 2017, DES AUT CON, DOI [10.1145/3061639.3062334, 10.1109/ICCSN.2017.8230067]
   Nag A, 2018, IEEE MICRO, V38, P41, DOI 10.1109/MM.2018.053631140
   Razavi Behzad, 2017, IEEE Solid-State Circuits Magazine, V9, P9, DOI 10.1109/MSSC.2017.2712998
   Razavi Behzad, 2015, IEEE Solid-State Circuits Magazine, V7, P38, DOI 10.1109/MSSC.2015.2442372
   Roy Sourjya, 2020, ARXIV200211151
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Slonczewski JC, 1996, J MAGN MAGN MATER, V159, pL1, DOI 10.1016/0304-8853(96)00062-5
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Wang SY, 2010, J APPL PHYS, V108, DOI 10.1063/1.3518514
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yu SM, 2010, NANOTECHNOLOGY, V21, DOI 10.1088/0957-4484/21/46/465202
NR 38
TC 24
Z9 24
U1 0
U2 3
PY 2020
AR 83.1
DI 10.1109/dac18072.2020.9218505
UT WOS:000628528400017
DA 2023-11-16
ER

PT C
AU Vavaroutsos, P
   Oroutzoglou, I
   Masouros, D
   Soudris, D
AF Vavaroutsos, Petros
   Oroutzoglou, Ioannis
   Masouros, Dimosthenis
   Soudris, Dimitrios
GP IEEE
TI Towards making the most of NLP-based device mapping optimization for
   OpenCL kernels
SO 2022 IEEE INTERNATIONAL CONFERENCE ON OMNI-LAYER INTELLIGENT SYSTEMS
   (IEEE COINS 2022)
DT Proceedings Paper
CT IEEE International Conference on Omni-Layer Intelligent Systems (IEEE
   COINS)
CY AUG 01-03, 2022
CL Barcelona, SPAIN
DE Machine Learning; Natural Language Processing; OpenCL; Heterogeneous
   Systems
AB Nowadays, we are living in an era of extreme device heterogeneity. Despite the high variety of conventional CPU architectures, accelerator devices, such as GPUs and FPGAs, also appear in the foreground exploding the pool of available solutions to execute applications. However, choosing the appropriate device per application needs is an extremely challenging task due to the abstract relationship between hardware and software. Automatic optimization algorithms that are accurate are required to cope with the complexity and variety of current hardware and software. Optimal execution has always relied on time-consuming trial and error approaches. Machine learning (ML) and Natural Language Processing (NLP) has flourished over the last decade with research focusing on deep architectures. In this context, the use of natural language processing techniques to source code in order to conduct autotuning tasks is an emerging field of study.
   In this paper, we extend the work of Cummins et al., namely Deeptune, that tackles the problem of optimal device selection (CPU or GPU) for accelerated OpenCL kernels. We identify three major limitations of Deeptune and, based on these, we propose four different DNN models that provide enhanced contextual information of source codes. Experimental results show that our proposed methodology surpasses that of Cummins et al. work, providing up to 4% improvement in prediction accuracy.
C1 [Vavaroutsos, Petros; Oroutzoglou, Ioannis; Masouros, Dimosthenis; Soudris, Dimitrios] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
RP Vavaroutsos, P (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
EM petrosvav@microlab.ntua.gr; ioroutzoglou@microlab.ntua.gr;
   demo.masouros@microlab.ntua.gr; dsoudirs@microlab.ntua.gr
CR Agakov F, 2006, INT SYM CODE GENER, P295
   Agarwal R, 2014, INFORM SYST RES, V25, P443, DOI 10.1287/isre.2014.0546
   Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695
   Ashouri AH, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3197978
   Ben-Nun T., 2018, NEURIPS
   Cavazos J, 2006, ACM SIGPLAN NOTICES, V41, P229, DOI 10.1145/1167515.1167492
   Cummins C, 2016, Arxiv, DOI arXiv:1511.02490
   Cummins C, 2017, INT CONFER PARA, P219, DOI 10.1109/PACT.2017.24
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Grewe D, 2013, INT SYM CODE GENER, P161
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Liu YX, 2009, INT PARALL DISTRIB P, P74
   Magni A, 2014, INT CONFER PARA, P455, DOI 10.1145/2628071.2628087
   Poznanski A, 2016, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2016.253
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Siami-Namini S, 2019, IEEE INT CONF BIG DA, P3285, DOI 10.1109/BigData47090.2019.9005997
   Vaswani A., 2017, ADV NEURAL INFORM PR, P6000, DOI 10.5555/3295222.3295349
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 337
EP 342
DI 10.1109/COINS54846.2022.9855002
UT WOS:000859114600056
DA 2023-11-16
ER

PT C
AU Zhang, CL
   Yu, MC
   Wang, W
   Yan, F
AF Zhang, Chengliang
   Yu, Minchen
   Wang, Wei
   Yan, Feng
GP USENIX Assoc
TI MArk: Exploiting Cloud Services for Cost-Effective, SLO-Aware Machine
   Learning Inference Serving
SO PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE
DT Proceedings Paper
CT USENIX Annual Technical Conference (ATC)
CY JUL 10-12, 2019
CL Renton, WA
AB The advances of Machine Learning (ML) have sparked a growing demand of ML-as-a-Service: developers train ML models and publish them in the cloud as online services to provide low-latency inference at scale. The key challenge of ML model serving is to meet the response-time Service-Level Objectives (SLOs) of inference workloads while minimizing the serving cost. In this paper, we tackle the dual challenge of SLO compliance and cost effectiveness with MArk (Model Ark), a general-purpose inference serving system built in Amazon Web Services (AWS). MArk employs three design choices tailor-made for inference workload. First, MArk dynamically batches requests and opportunistically serves them using expensive hardware accelerators (e.g., GPU) for improved performance-cost ratio. Second, instead of relying on feedback control scaling or over-provisioning to serve dynamic workload, which can be too slow or too expensive for inference serving, MArk employs predictive autoscaling to hide the provisioning latency at low cost. Third, given the stateless nature of inference serving, MArk exploits the flexible, yet costly serverless instances to cover the occasional load spikes that are hard to predict. We evaluated the performance of MArk using several state-of-the-art ML models trained in popular frameworks including TensorFlow, MXNet, and Keras. Compared with the premier industrial ML serving platform SageMaker, MArk reduces the serving cost up to 7:8x while achieving even better latency performance.
C1 [Zhang, Chengliang; Yu, Minchen; Wang, Wei] HKUST, Hong Kong, Peoples R China.
   [Yan, Feng] Univ Nevada, Reno, NV 89557 USA.
RP Zhang, CL (corresponding author), HKUST, Hong Kong, Peoples R China.
EM czhangbn@cse.ust.hk; myuaj@cse.ust.hk; weiwa@cse.ust.hk; fyan@unr.edu
CR Ali-Eldin A., 2012, P 3 WORKSH SCI CLOUD, P31, DOI DOI 10.1145/2287036.2287044
   Ali-Eldin A, 2012, IEEE IFIP NETW OPER, P204, DOI 10.1109/NOMS.2012.6211900
   Amazon, 2018, BUILD TRAIN DEPL MAC
   Amazon, 2018, DYN SCAL AM EC2 AUT
   Amazon, 2018, AWS AUT
   Amazon, 2018, LOAD TEST VAR AUT SC
   Amazon, 2018, CONF LAMBD FUNCT
   Amazon, 2018, TARG TRACK SCAL POL
   Aniello Leonardo, 2014, Networked Systems. Second International Conference, NETYS 2014. Revised Selected Papers. LNCS: 8593, P122, DOI 10.1007/978-3-319-09581-3_9
   [Anonymous], 2018, NEW AM EC2 SPOT PRIC
   [Anonymous], 2018, AMAZON ECS
   [Anonymous], 2018, GOOGLE KUBERNETES EN
   [Anonymous], 2017, ARXIV170707012
   [Anonymous], 2018, AMAZON EC2
   [Anonymous], 2018, REDISML
   [Anonymous], 2018, GOOGLE CLOUD FUNCTIO
   [Anonymous], NIPS BIGLEARNING WOR
   [Anonymous], 2018, AWS LAMBDA
   ARCHIVETEAM, 2017, TWITT STREAM TRAC
   AWS, 2018, BURST PERF INST
   AWS, 2018, AM EC2 RES INST
   AWS, 2018, RIGHT SIZ PROV INST
   Awslabs, 2018, MXNET MOD SERV
   Barrett E, 2013, CONCURR COMP-PRACT E, V25, P1656, DOI 10.1002/cpe.2864
   Casale G, 2010, PERFORM EVALUATION, V67, P61, DOI 10.1016/j.peva.2009.09.003
   Chollet F., 2015, KERAS DEEP LEARNING
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Cui Y., 2018, LONG DOES AWS LAMBDA
   Cui Y., 2018, IM AFRAID YOURE THIN
   Doyle R. P., 2003, P 4 C USENIX S INTER, V5
   Fang W., 2012, 2012 IEEE 9 INT C SE, P609, DOI DOI 10.1109/SCC.2012.47
   FISCHER W, 1993, PERFORM EVALUATION, V18, P149, DOI 10.1016/0166-5316(93)90035-S
   Fox A., 2009, HOTCLOUD, V9, P12
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Google, 2018, KUB HOR SCAL
   Google, 2019, CLOUD TPU PERF GUID
   Google, 2018, GOOGL CLOUD AUT
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Han R, 2014, FUTURE GENER COMP SY, V32, P82, DOI 10.1016/j.future.2012.05.018
   Harlap A, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P589, DOI 10.1145/3064176.3064182
   He Kaiming, 2016, PROC CVPR IEEE
   He X., 2015, P 24 INT S HIGH PERF, P207
   Hunt Patrick, 2010, P USENIX ATC
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Lee H, 2018, PROC 12 EUR C ANTENN
   Lee Y, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P611
   LEITNER P, 2015, P IEEE ACM UT CLOUD
   Merity Stephen, 2017, REGULARIZING OPTIMIZ
   Microsoft, 2018, MICR AZ CLOUD COMP P
   NIKRAVESH A. Y, 2015, P IEEE INT S SOFTW E
   NVIDIA, 2018, TENSORRT
   Olston C., 2017, ARXIV171206139
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Prodan R, 2009, FUTURE GENER COMP SY, V25, P785, DOI 10.1016/j.future.2008.11.002
   Qu CH, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148149
   Qu CH, 2016, J NETW COMPUT APPL, V65, P167, DOI 10.1016/j.jnca.2016.03.001
   RAJABI A, 2012, P IEEE MASCOTS
   Roy Nilabja, 2011, 2011 IEEE 4 INT C CL, P500, DOI DOI 10.1109/CLOUD.2011.42
   Sanders Jason, 2010, CUDA EXAMPLE INTRO G
   Sharma Prateek, 2015, P 10 EUR C COMP SYST, DOI 10.1109/IC4.2015.7375638
   Shi X., 2015, ADV NEURAL INFORM PR, V28, P802
   Song BB, 2018, J SUPERCOMPUT, V74, P6554, DOI 10.1007/s11227-017-2044-4
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   TensorFlow, 2018, TENSORFLOW SERV BATC
   TU Z, 2018, P NAACL DEM
   Urgaonkar B, 2008, ACM T AUTON ADAP SYS, V3, DOI 10.1145/1342171.1342172
   WANG C, 2017, P ACM EUROSYS
   Wang W., 2018, RAFIKI MACHINE LEARN
   YAN F, 2016, P IEEE ACM SC16
   YAN F, 2017, P IEEE CLOUD
   ZHANG H, 2017, P ACM SOCC
NR 72
TC 88
Z9 91
U1 0
U2 0
PY 2019
BP 1049
EP 1062
UT WOS:000489756800071
DA 2023-11-16
ER

PT C
AU Ueyoshi, K
   Ando, K
   Orimo, K
   Ikebe, M
   Asai, T
   Motomura, M
AF Ueyoshi, Kodai
   Ando, Kota
   Orimo, Kentaro
   Ikebe, Masayuki
   Asai, Tetsuya
   Motomura, Masato
GP IEEE
TI Exploring Optimized Accelerator Design for Binarized Convolutional
   Neural Networks
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB The convolutional neural network (CNN) is a state-of-the-art model that can achieve significantly high accuracy in many machine-learning tasks. Recently, for further developing the practical applications of CNNs, efficient hardware platforms for accelerating CNN have been throughly studied. A binarized neural network has been reported to minimize the multipliers, which consume a large amount of resources, with a minimal decrease in accuracy. In this study, we analyzed the optimal performance of CNN implemented on an field programmable gate array (FPGA) considering its logic resources and a memory bandwidth, using multiple types of parallelisms such as kernels, pixels, and channels both in conventional and binarized CNNs. As a result, it became clear that all the parallelisms are required for the binarized neural network to obtain the best performance of 8.38 TOPS.
C1 [Ueyoshi, Kodai; Ando, Kota; Orimo, Kentaro; Ikebe, Masayuki; Asai, Tetsuya; Motomura, Masato] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
RP Ueyoshi, K (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
EM ueyoshi@lalsie.ist.hokudai.ac.jp; ando@lalsie.ist.hokudai.ac.jp;
   orimo@lalsie.ist.hokudai.ac.jp; ikebe@ist.hokudai.ac.jp;
   asai@ist.hokudai.ac.jp; motomura@ist.hokudai.ac.jp
CR [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   [Anonymous], 2016, ARXIV160305279
   [Anonymous], MINIMIZING COMPUTATI
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Hiroki Nakahara H. I., 2017, 25 ACM SIGDA INT S F
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 14
TC 0
Z9 0
U1 0
U2 3
PY 2017
BP 2510
EP 2516
UT WOS:000426968702099
DA 2023-11-16
ER

PT C
AU Kurkure, U
   Vu, L
   Sivaraman, H
AF Kurkure, Uday
   Vu, Lan
   Sivaraman, Hari
BE Smari, WW
   Zinedine, K
TI Virtualized GPUs in High Performance Datacenters
SO PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING
   & SIMULATION (HPCS)
DT Proceedings Paper
CT International Conference on High Performance Computing and Simulation
   (HPCS)
CY JUL 16-20, 2018
CL orelans, FRANCE
DE GPU; High Performance Computing; vGPU; machine learning; deep learning;
   cloud computing; performance optimization; Virtualization; Virtual
   Machine; Graphics
AB Virtualization has become the foundation of high performance datacenters. The scale of high performance datacenters is similar to the scale of supercomputers used in High Performance Computing (HPC). Both involve millions of CPU cores, tens of thousands of accelerators like GPUs, FPGAs connected by high speed interconnects and different connection topologies. GPUs are essential in high performance computing because of their high throughput and energy efficiency. Many high performance computing workloads have avoided virtualization because of performance concerns. As the scale of high performance datacenter increases, the need for ease of management becomes critical. The virtualized GPUs offer new opportunities in efficient resource allocation in managing datacenters. In this paper, we present different GPU virtualization solutions and discuss its related aspects that helps GPU based applications running efficiently at scale. We also present a comprehensive performance study of virtualized GPU that addresses main considerations of running high performance applications in virtualized datacenters. We evaluate the performance of virtual GPUs from many different angles: the overhead of virtual GPUs compared to physical GPU, the impact of using container, the use of virtualized GPUs for many different types of HPC applications, the solution of mixing workloads to increase resource utilization and system consolidation, the scalability, as well as how to make the right choice of vGPU profile.
C1 [Kurkure, Uday; Vu, Lan; Sivaraman, Hari] VMware, Palo Alto, CA 94304 USA.
RP Kurkure, U (corresponding author), VMware, Palo Alto, CA 94304 USA.
EM ukurkure@vmware.com; lanv@vmware.com; hsivaraman@vmware.com
CR Agrawal B., 2009, VMWARE TECHNICAL J
   Arakelian C., 2016, BLAST EXTREME DISPLA
   Arakelian C., 2016, VMWARE TECHNICAL WHI
   Duato J., 2009, 4 WORKSH VIRT HIGH P
   Duato J., 2010, 1 WORKSH LANG COMP A
   Gupta V, 2011, P USENIX ATC
   Gupta Vishakha, 2009, P 3 ACM WORKSHOP SYS, P17, DOI DOI 10.1145/1519138.1519141
   Jaffe Dave, 2016, BIG DATA PERFORMANCE
   Krizhevsky Alex, 2009, NON TRADITIONAL REF
   Kurkure U., 12 WORKSH VIRT HIGH
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Markthub P, 2014, 2014 15TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2014), P105, DOI 10.1109/PDCAT.2014.26
   Merritt A, 2011, P VTDC 2011
   Pandey A., 2017, P 2017 INT C HIGH PE
   Pena A. J, 2014, PARALLEL COMPUTER, V40
   Shi L, 2009, INT PARALL DISTRIB P, P418
   Taylor Ann, 2003, PENN TREEBANK OVERVI
   Vu Lan, 2014, P 22 HIGH PERF COMP
   Walters John Paul, 2014, P 2014 IEEE 7 INT C
   Wang S.Y., 2015, P 14 INT C NETW, P37
   Zaremba W., 2014, ARXIV14092329
NR 21
TC 6
Z9 6
U1 0
U2 2
PY 2018
BP 887
EP 894
DI 10.1109/HPCS.2018.00142
UT WOS:000450677700121
DA 2023-11-16
ER

PT J
AU Martínez, J
   Vega, J
AF Martinez, Javier
   Vega, Julio
TI ROS System Facial Emotion Detection Using Machine Learning for a
   Low-Cost Robot Based on Raspberry Pi
SO ELECTRONICS
DT Article
DE ROS; low-cost; raspberry Pi; visual attention; facial emotion detection;
   human-robot interaction
ID EXPRESSION RECOGNITION
AB Facial emotion recognition (FER) is a field of research with multiple solutions in the state-of-the-art, focused on fields such as security, marketing or robotics. In the literature, several articles can be found in which algorithms are presented from different perspectives for detecting emotions. More specifically, in those emotion detection systems in the literature whose computational cores are low-cost, the results presented are usually in simulation or with quite limited real tests. This article presents a facial emotion detection system-detecting emotions such as anger, happiness, sadness or surprise-that was implemented under the Robot Operating System (ROS), Noetic version, and is based on the latest machine learning (ML) techniques proposed in the state-of-the-art. To make these techniques more efficient, and that they can be executed in real time on a low-cost board, extensive experiments were conducted in a real-world environment using a low-cost general purpose board, the Raspberry Pi 4 Model B. The final achieved FER system proposed in this article is capable of plausibly running in real time, operating at more than 13 fps, without using any external accelerator hardware, as other works (widely introduced in this article) do need in order to achieve the same purpose.
C1 [Martinez, Javier] Univ Alcala, Dept Welf Anim Res, Pza San Diego S-N, Alcala De Henares 28801, Spain.
   [Vega, Julio] Rey Juan Carlos Univ, Dept Telemat Syst & Comp, Camino Molino 5, Fuenlabrada 28942, Spain.
RP Vega, J (corresponding author), Rey Juan Carlos Univ, Dept Telemat Syst & Comp, Camino Molino 5, Fuenlabrada 28942, Spain.
EM julio.vega@urjc.es
CR Ab Wahab MN, 2021, IEEE ACCESS, V9, P134065, DOI 10.1109/ACCESS.2021.3113337
   Babu RG, 2020, LECT NOTE DATA ENG, V44, P797, DOI 10.1007/978-3-030-37051-0_89
   Bartneck C., 2020, HUMAN ROBOT INTERACT, DOI DOI 10.1017/9781108676649
   Daher AW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196526
   Devaram RR, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093366
   Ekman P., 1978, ENVIRON PSYCH NONVER
   Ekman P., 1978, FACIAL ACTION CODING
   Gao Q, 2020, NEUROCOMPUTING, V390, P198, DOI 10.1016/j.neucom.2019.02.066
   Alonso IG, 2011, INTEL SYST CONTR AUT, V53, P89, DOI 10.1007/978-94-007-1491-5_3
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Jeong M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124270
   Jiang P, 2020, IEEE SIGNAL PROC LET, V27, P1954, DOI 10.1109/LSP.2020.3031504
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kartynnik Y, 2019, Arxiv, DOI [arXiv:1907.06724, 10.48550/ARXIV.1907.06724]
   Liang A, 2017, J AM MED DIR ASSOC, V18, P871, DOI 10.1016/j.jamda.2017.05.019
   Liu LY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062250
   Lu LC, 2021, INNOV AGING, V5, DOI 10.1093/geroni/igab013
   Lucey P., 2010, 2010 IEEE COMPUTER S, P94
   Mehrabian A., 1968, COMMUN THEOR
   Miseikis J, 2020, IEEE ROBOT AUTOM LET, V5, P5339, DOI 10.1109/LRA.2020.3007462
   Mohebbi A., 2020, CURR ROBOT REP, V11, P1, DOI DOI 10.1007/S43154-020-00015-4
   Quiroz M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103749
   Rathour N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210540
   Rathour N, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111289
   Rawal N, 2022, INT J SOC ROBOT, V14, P1583, DOI 10.1007/s12369-022-00867-0
   Saeed U., 2020, P 2020 INT C ELECT I, P1, DOI 10.1109/ICEIC49074.2020.9102342
   Sajjad M, 2019, INFORM SCIENCES, V479, P416, DOI 10.1016/j.ins.2018.07.027
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   Siam AI, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8032673
   Tang Y, 2021, IEEE T IMAGE PROCESS, V30, P444, DOI 10.1109/TIP.2020.3037467
   Tekler ZD, 2022, BUILD ENVIRON, V223, DOI 10.1016/j.buildenv.2022.109472
   Tekler ZD, 2020, BUILD ENVIRON, V171, DOI 10.1016/j.buildenv.2020.106681
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI 10.1109/CVPR.2001.990517
NR 33
TC 1
Z9 1
U1 2
U2 3
PD JAN
PY 2023
VL 12
IS 1
AR 90
DI 10.3390/electronics12010090
UT WOS:000909758000001
DA 2023-11-16
ER

PT J
AU Mondal, PK
   Sanchez, LPA
   Benedetto, E
   Shen, Y
   Guo, MY
AF Mondal, Pritom Kumar
   Aguirre Sanchez, Lizeth P.
   Benedetto, Emmanuele
   Shen, Yao
   Guo, Minyi
TI A dynamic network traffic classifier using supervised ML for a
   Docker-based SDN network
SO CONNECTION SCIENCE
DT Article
DE Quality of service; software-defined network; traffic classification;
   machine learning
AB With the rapid technological growth in the last decades, the number of devices and users has drastically increased. Software-defined networking (SDN) with machine learning (ML) has become an emerging solution for network scheduling, quality of service (QoS), resource allocations, and security. This paper focuses on the implementation of a network traffic classifier using a novel Docker-based SDN network. ML offers good performance to real-time traffic solutions without depending on well-known TCP or UDP port numbers, IP addresses, or encrypted payloads. In this paper, using three ML techniques, we first classify network flows with 3, 5, and 7 parameters giving up to 97.14% accuracy. Additionally, we present a new performance accelerator algorithm (PAA), which incorporates these three ML classifiers and accelerates the overall performance significantly. We then propose a dynamic network classifier (DNC) generated from PAA over a novel Docker-based SDN network. Finally, we propose a new controller algorithm for Ryu platforms, which integrates the DNC and classifies both TCP and UDP flows in real-time. Based on the evaluations, an improvement in latency performance has been demonstrated, where analysing a packet, controller processing time takes on an average of 10 mu s. This study will certainly serve to further research on optimising SDN and QoS.
C1 [Mondal, Pritom Kumar; Aguirre Sanchez, Lizeth P.; Benedetto, Emmanuele; Shen, Yao; Guo, Minyi] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Benedetto, Emmanuele] Politecn Milan, Milan, Italy.
RP Shen, Y (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM yshen@cs.sjtu.edu.cn
CR Abar T., 2020, INT J WIRELESS MOBIL, V18, DOI https://doi.org/10.1504/IJWMC.2020.104769
   Ahmed Arif, 2020, International Journal of Cloud Computing, V9, P6
   Alsaeedi M, 2019, IEEE ACCESS, V7, P107346, DOI 10.1109/ACCESS.2019.2932422
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Amaral P., 2016, 2016 IEEE 24 INT C N, P1, DOI DOI 10.1109/ICNP.2016.7785327
   Bachiega, 2020, 2020 IEEE INT C SOFT
   Breiman L., 2001, RANDOM FORESTS, V45, P5
   Bujlow T, 2015, COMPUT NETW, V76, P75, DOI 10.1016/j.comnet.2014.11.001
   BURROWS WR, 1995, J APPL METEOROL, V34, P1848, DOI 10.1175/1520-0450(1995)034<1848:CDTSAA>2.0.CO;2
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cisco Visual Networking Index, 2018, 11 CISCO
   CUI L, 2016, IEEE NETWORK, V30
   David B., 2020, SOFTWARE DEFINED NET
   Deri L, 2014, INT WIREL COMMUN, P617, DOI 10.1109/IWCMC.2014.6906427
   Jun Zhang, 2012, International Journal of Security and Networks, V7, P252
   Karatsiolis S, 2012, IEEE INT C BIOINF BI, P139, DOI 10.1109/BIBE.2012.6399663
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Koteeswaran, 2018, INT J INTELL SYST, V17, P467, DOI [10.1504/IJISTA.2018.095114, DOI 10.1504/IJISTA.2018.095114]
   LATAH M, 2018, IET NETW, V8
   Liu CC, 2018, I C COMM SOFTW NET, P45, DOI 10.1109/ICCSN.2018.8488219
   Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783
   Liu Z, 2020, CONNECT SCI, V32, P333, DOI 10.1080/09540091.2019.1700911
   LOPEZ M, 2017, IEEE ACCESS, V5
   Mejuia D., 2013, REV POLIT CNICA, V32, P43
   Merkel Dirk, 2014, LINUX J, V2014, P2
   Mininet, MIN INST NETW YOUR L
   Moore A, 2013, TECHNICAL REPORT
   Oliveira T.P., 2016, INT J BIG DATA INTEL, V3, DOI https://doi.org/10.1504/IJBDI.2016.073903
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rezaeijo SM, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349605
   Wang C, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P78, DOI 10.1109/CIS.2015.27
   Wang P, 2016, P IEEE I C SERV COMP, P760, DOI 10.1109/SCC.2016.133
   Wengang Zhou, 2011, 2011 International Conference on Computational Problem-Solving, P641, DOI 10.1109/ICCPS.2011.6092257
   Wu, 2019, INT J HIGH PERFORM C, V14, P237, DOI [10.1504/IJHPCN.2019.10022739, DOI 10.1504/IJHPCN.2019.10022739]
   Xu J., 2018, 2018 IEEE INT C SIGN, P1
   Yuan ZW, 2016, 2016 IEEE INTERNATIONAL CONFERENCE OF ONLINE ANALYSIS AND COMPUTING SCIENCE (ICOACS), P53, DOI 10.1109/ICOACS.2016.7563047
   ZHANG C, 2018, T EMERG TELECOMMUN T, V29
NR 37
TC 4
Z9 4
U1 0
U2 18
PD JUL 3
PY 2021
VL 33
IS 3
BP 693
EP 718
DI 10.1080/09540091.2020.1870437
EA JAN 2021
UT WOS:000608321300001
DA 2023-11-16
ER

PT C
AU Neshatpour, K
   Malik, M
   Ghodrat, MA
   Sasan, A
   Homayoun, H
AF Neshatpour, Katayoun
   Malik, Maria
   Ghodrat, Mohammad Ali
   Sasan, Avesta
   Homayoun, Houman
BE Ho, H
   Ooi, BC
   Zaki, MJ
   Hu, XH
   Haas, L
   Kumar, V
   Rachuri, S
   Yu, SP
   Hsiao, MHI
   Li, J
   Luo, F
   Pyne, S
   Ogan, K
TI Energy-Efficient Acceleration of Big Data Analytics Applications Using
   FPGAs
SO PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA
DT Proceedings Paper
CT IEEE International Conference on Big Data
CY OCT 29-NOV 01, 2015
CL Santa Clara, CA
DE machine learning; hardware plus software co-design; Zynq boards;
   MapReduce; Hadoop; FPGA
AB A recent trend for big data analytics is to provide heterogeneous architectures to allow support for hardware specialization. Considering the time dedicated to create such hardware implementations, an analysis that estimates how much benefit we gain in terms of speed and energy efficiency, through offloading various functions to hardware would be necessary. This work analyzes data mining and machine learning algorithms, which are utilized extensively in big data applications in a heterogeneous CPU+FPGA platform. We select and offload the computational intensive kernels to the hardware accelerator to achieve the highest speed-up and best energy-efficiency. We use the latest Xilinx Zynq boards for implementation and result analysis. We also perform a first order comprehensive analysis of communication and computation overheads to understand how the speedup of each application contributes to its overall execution in an end-to-end Hadoop MapReduce environment. Moreover, we study how other system parameters such as the choice of CPU (big vs little) and the number of mapper slots affect the performance and power-efficiency benefits of hardware acceleration. The results show that a kernel speedup of upto x321.5 with hardware+software co-design can be achieved. This results in x2.72 speedup, 2.13x power reduction, and 15.21x energy efficiency improvement (EDP) in an end-to-end Hadoop MapReduce environment.
C1 [Neshatpour, Katayoun; Malik, Maria; Sasan, Avesta; Homayoun, Houman] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
   [Ghodrat, Mohammad Ali] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.
RP Neshatpour, K (corresponding author), George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
EM kneshatp@gmu.edu; mmalik9@gmu.edu; ghodrat@gmail.com; hhomayou@gmu.edu
CR [Anonymous], 2004, OSDI 2004
   [Anonymous], 2013, PRODUCT GUIDE VIVADO
   Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Homayoun H, 2012, P INT S HIGH PERFORM, P1
   Honjo Toshimori, 2013, 2013 IEEE International Conference on Big Data, P118, DOI 10.1109/BigData.2013.6691562
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   Kachris C., 2014, P ACM SIGDA INT S FP, P241
   Kontorinis V., 2014, 51 ANN DES AUT C 201
   Kontorinis V, 2012, CONF PROC INT SYMP C, P488, DOI 10.1109/ISCA.2012.6237042
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Malik M., 2015, 33 IEEE INT C COMP D
   Malik M., 2015, IEEE INT C BIG DAT I
   Narayanan R, 2006, I S WORKL CHAR PROC, P182
   Neshatpour K, 2015, ANN IEEE SYM FIELD P, P164, DOI 10.1109/FCCM.2015.59
   Neshatpour K, 2015, IEEE ACM INT SYMP, P1151, DOI 10.1109/CCGrid.2015.165
   Séméria L, 2001, IEEE T VLSI SYST, V9, P743, DOI 10.1109/92.974889
   Shan Y, 2010, FPGA 10, P93
   Van Craeynest K, 2012, CONF PROC INT SYMP C, P213, DOI 10.1109/ISCA.2012.6237019
   White T., 2009, HADOOP DEFINITIVE GU
   Winterstein F, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P362, DOI 10.1109/FPT.2013.6718388
NR 21
TC 30
Z9 31
U1 0
U2 7
PY 2015
BP 115
EP 123
UT WOS:000380404600017
DA 2023-11-16
ER

PT J
AU Yildirim, M
   Oguz, I
   Kaufmann, F
   Escalé, MR
   Grange, R
   Psaltis, D
   Moser, C
AF Yildirim, Mustafa
   Oguz, Ilker
   Kaufmann, Fabian
   Escale, Marc Reig
   Grange, Rachel
   Psaltis, Demetri
   Moser, Christophe
TI Nonlinear optical feature generator for machine learning
SO APL PHOTONICS
DT Article
ID SUPERCONTINUUM GENERATION; NEURAL-NETWORKS; HIGH-SPEED; PARALLEL
AB Modern machine learning models use an ever-increasing number of parameters to train (175 x 10(9) parameters for GPT-3) with large datasets to achieve better performance. Optical computing has been rediscovered as a potential solution for large-scale data processing, taking advantage of linear optical accelerators that perform operations at lower power consumption. However, to achieve efficient computing with light, it remains a challenge to create and control nonlinearity optically rather than electronically. In this study, a reservoir computing approach (RC) is investigated using a 14-mm waveguide in LiNbO3 on an insulator as an optical processor to validate the benefit of optical nonlinearity. Data are encoded on the spectrum of a femtosecond pulse, which is launched into the waveguide. The output of the waveguide is a nonlinear transform of the input, enabled by optical nonlinearities. We show experimentally that a simple digital linear classifier using the output spectrum of the waveguide increases the classification accuracy of several databases by similar to 10% compared to untransformed data. In comparison, a digital neural network (NN) with tens of thousands of parameters was required to achieve similar accuracy. With the ability to reduce the number of parameters by a factor of at least 20, an integrated optical RC approach can attain a performance on a par with a digital NN.
C1 [Yildirim, Mustafa; Oguz, Ilker; Moser, Christophe] Ecole Polytech Fed Lausanne EPFL, Lab Appl Photon Devices, Lausanne, Switzerland.
   [Kaufmann, Fabian; Grange, Rachel] Swiss Fed Inst Technol, Inst Quantum Elect, Dept Phys, Opt Nanomat Grp, Zurich, Switzerland.
   [Escale, Marc Reig] Versics AG, Auguste Piccard Hof 1,HPT Bldg, CH-8093 Zurich, Switzerland.
   [Psaltis, Demetri] Ecole Polytech Fed Lausanne EPFL, Opt Lab, Lausanne, Switzerland.
RP Yildirim, M (corresponding author), Ecole Polytech Fed Lausanne EPFL, Lab Appl Photon Devices, Lausanne, Switzerland.
EM mustafa.yidirim@epfl.ch
CR Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dudley JM, 2006, REV MOD PHYS, V78, P1135, DOI 10.1103/RevModPhys.78.1135
   Escalé MR, 2020, APL PHOTONICS, V5, DOI 10.1063/5.0028776
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Frumker E, 2007, J OPT SOC AM B, V24, P2940, DOI 10.1364/JOSAB.24.002940
   GOODMAN JW, 1978, OPT LETT, V2, P1, DOI 10.1364/OL.2.000001
   hamamatsu, US
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Koklu M, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/4793293
   Lichtinghagen R., 2020, HCV DATA, DOI [10.24432/C5D612, DOI 10.24432/C5D612]
   Marcucci G, 2020, PHYS REV LETT, V125, DOI 10.1103/PhysRevLett.125.093901
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Mounaix M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13059-8
   O' Neill J, 2020, Arxiv, DOI arXiv:2006.03669
   Paudel U, 2020, OPT EXPRESS, V28, P1225, DOI 10.1364/OE.379264
   Pohl D, 2021, IEEE PHOTONIC TECH L, V33, P85, DOI 10.1109/LPT.2020.3044648
   Rafayelyan M, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.041037
   Romera M, 2018, NATURE, V563, P230, DOI 10.1038/s41586-018-0632-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silva NA, 2021, NEW J PHYS, V23, DOI 10.1088/1367-2630/abda84
   Sludds Alexander, 2022, Science, V378, P270, DOI 10.1126/science.abq8271
   Sorokina M, 2020, J PHYS-PHOTONICS, V2, DOI 10.1088/2515-7647/abb584
   Spall J, 2020, OPT LETT, V45, P5752, DOI 10.1364/OL.401675
   Sunada S, 2020, OPT EXPRESS, V28, P30349, DOI 10.1364/OE.399495
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Tegin U, 2021, NAT COMPUT SCI, V1, P542, DOI 10.1038/s43588-021-00112-0
   Van der Sande G, 2017, NANOPHOTONICS-BERLIN, V6, P561, DOI 10.1515/nanoph-2016-0132
   Vandoorne K, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4541
   Wang C, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08969-6
   Wang C, 2018, OPT EXPRESS, V26, P1547, DOI 10.1364/OE.26.001547
   Wright LG, 2022, NATURE, V601, P549, DOI 10.1038/s41586-021-04223-6
   Yu MJ, 2019, OPT LETT, V44, P1222, DOI 10.1364/OL.44.001222
   Zhou TY, 2022, J LIGHTWAVE TECHNOL, V40, P1308, DOI 10.1109/JLT.2022.3146131
   Zhu D, 2021, ADV OPT PHOTONICS, V13, P242, DOI 10.1364/AOP.411024
NR 36
TC 0
Z9 0
U1 1
U2 1
PD OCT 1
PY 2023
VL 8
IS 10
AR 106104
DI 10.1063/5.0158611
UT WOS:001083785700001
DA 2023-11-16
ER

PT J
AU Oliveira, WC
   Canesche, M
   Reis, L
   Nacif, JAM
   Ferreira, RS
AF Oliveira, Westerley C.
   Canesche, Michael
   Reis, Lucas
   Nacif, Jose Augusto M.
   Ferreira, Ricardo S.
TI Heterogeneous reconfigurable architectures for machine learning
   dataflows
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE dataflow computing; FPGA accelerators; heterogeneous architectures; high
   performance computing
AB This work explores the placement and routing of machine learning applications' dataflow graphs on different heterogeneous coarse-grained reconfigurable architectures (CGRA). We analyze three different types of processing element (PE) heterogeneity, the first concerning the interconnection pattern, the second being on the kind of operations a single PE can execute, and the last concerning the PE buffer resources. This analysis aim to propose a fair reduction to the overall cost in comparison to the homogeneous CGRA architecture. We compare our results with the homogeneous case and one of the state-of-the-art tools for placement and routing (P&R). Our algorithm executed, on average, 52% faster than VPR 8.1 (Versatile Place and Route), which is an open-source academic tool designed for the FPGA placement and routing phases, reaching better mapping in 66% of cases and achieving the same results in 26% of cases. Furthermore, a heterogeneous architecture reduces the cost without losing performance in 76% of the cases considering multiplier heterogeneity. We propose a novel heterogeneous buffer architecture that minimizes the buffer resources by 56.3% for K-means dataflow patterns. We also show that a heterogeneous border chess architecture outperforms a homogeneous one. In addition, our mapping reaches optimal instances of single tree dataflows compared to classical Lee/Choi and H-trees.
C1 [Oliveira, Westerley C.; Canesche, Michael; Reis, Lucas; Ferreira, Ricardo S.] Univ Fed Vicosa, Dept Comp Sci, Vicosa, MG, Brazil.
   [Nacif, Jose Augusto M.] Univ Fed Vicosa, Inst Sci & Technol, UFV Florestal Campus, Florestal, MG, Brazil.
RP Ferreira, RS (corresponding author), Univ Fed Vicosa, Dept Informat, Campus Univ, BR-36570900 Vicosa, MG, Brazil.
EM ricardo@ufv.br
CR Abdelrahman TS, 2016, IEEE INT CONF ASAP, P176, DOI 10.1109/ASAP.2016.7760789
   Akbari O, 2020, IEEE T COMPUT AID D, V39, P2558, DOI 10.1109/TCAD.2019.2937738
   Browning, 1980, TREE MACHINE HIGHLY
   Carvalho W, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P233, DOI 10.1109/ICFPT51103.2020.00040
   Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Donovick C., 2019, P INT C RECONFIGURAB
   Fang Z., 2019, P INT C APPL SPEC SY
   Gobieski G., 2021, P INT S COMP ARCH IS
   Hamzeh M, 2012, DES AUT CON, P1280
   He ZH, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P233, DOI 10.1145/3373087.3375316
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Huang Y., 2013, FPGA, P171
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee SK, 1996, IEEE T PARALL DISTR, V7, P493, DOI 10.1109/71.503774
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Luo Z., 2000, P INT S CIRC SYST IS
   Mei BF, 2003, LECT NOTES COMPUT SC, V2778, P61
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Nowatzki T, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243212
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Oliveira W., 2020, P 18 S SIST COMP ALT
   Park H, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P166, DOI 10.1145/1454115.1454140
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Ravet F, 2018, PR INT PIPELINE CONF
   Silva M., 2006, P INT C REC COMP FPG
   Thompson NC, 2021, IEEE SPECTRUM, V58, P50, DOI 10.1109/MSPEC.2021.9563954
   Vasilyev A, 2016, INT SYMP MICROARCH
   Walker MJP, 2019, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2019.00019
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Weng J, 2020, ANN I S COM, P268, DOI 10.1109/ISCA45697.2020.00032
   Weng J, 2019, IEEE COMPUT ARCHIT L, V18, P161, DOI 10.1109/LCA.2019.2955456
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Zhang Y., 2021, P INT S COMP ARCH IS
NR 34
TC 0
Z9 0
U1 0
U2 2
PD AUG 1
PY 2023
VL 35
IS 17
SI SI
AR e6939
DI 10.1002/cpe.6939
EA MAR 2022
UT WOS:000769584000001
DA 2023-11-16
ER

PT C
AU Konstantinou, D
   Nicopoulos, C
   Lee, J
   Sirakoulis, GC
   Dimitrakopoulos, G
AF Konstantinou, Dimitrios
   Nicopoulos, Chrysostomos
   Lee, Junghee
   Sirakoulis, Georgios Ch
   Dimitrakopoulos, Giorgos
GP IEEE
TI SmartFork: Partitioned Multicast Allocation and Switching in
   Network-on-Chip Routers
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
AB Multicast on-chip communication is encountered in various cache-coherence protocols targeting multi-core processors, and its pervasiveness is increasing due to the proliferation of machine learning accelerators. In-network handling of multicast traffic imposes additional switching-level restrictions to guarantee deadlock freedom, while it stresses the allocation efficiency of Network-on-Chip (NoC) routers. In this work, we propose a novel NoC router microarchitecture, called SmartFork, which employs a versatile and cost-efficient multicast packet replication scheme that allows the design of high-throughput and low-cost NoCs. The design is adapted to the average branch splitting observed in real-world multicast routing algorithms. Compared to state-of-the-art NoC multicast approaches, SmartFork is demonstrated to yield higher performance in terms of latency and throughput, while still offering a cost-effective implementation.
C1 [Konstantinou, Dimitrios; Sirakoulis, Georgios Ch; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Elect & Comp Engn, Nicosia, Cyprus.
   [Lee, Junghee] Korea Univ, Sch Cyber Secur, Seoul, South Korea.
RP Konstantinou, D (corresponding author), Democritus Univ Thrace, Elect & Comp Engn, Xanthi, Greece.
CR Abadal S, 2016, COMPUT ELECTR ENG, V51, P168, DOI 10.1016/j.compeleceng.2015.12.018
   Agarwal A, 2007, DES AUT CON, P750, DOI 10.1109/DAC.2007.375264
   [Anonymous], 2015, MICROARCHITECTURE NE
   Arteris, 2018, ART IP FLEXNOC AI PA
   Bhardwaj K., 2017, INT S NETW ON CHIP N
   Boppana R. V., 1994, Proceedings. Sixth IEEE Symposium on Parallel and Distributed Processing (Cat. No.94TH0675-9), P722, DOI 10.1109/SPDP.1994.346103
   Conway P, 2007, IEEE MICRO, V27, P10, DOI 10.1109/MM.2007.43
   Dimitrakopoulos G, 2013, IEEE T COMPUT, V62, P2001, DOI 10.1109/TC.2012.116
   Dimitrakopoulos G, 2008, PR IEEE COMP DESIGN, P664, DOI 10.1109/ICCD.2008.4751932
   Ebrahimi M, 2009, DES AUT TEST EUROPE, P1064
   Jerger NE, 2008, CONF PROC INT SYMP C, P229, DOI 10.1109/ISCA.2008.12
   Krishna T, 2011, INT SYMP MICROARCH, P71
   LIN XL, 1991, ACM COMP AR, V19, P116, DOI 10.1145/115953.115965
   Lu ZH, 2006, IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI, PROCEEDINGS, P205
   Ma S., 2012, IEEE INT S HIGH PERF, P1
   Ma S, 2012, INT S HIGH PERF COMP, P467
   Malumbres MP, 1996, EIGHTH IEEE SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, PROCEEDINGS, P186, DOI 10.1109/SPDP.1996.570332
   Martin MMK, 2003, CONF PROC INT SYMP C, P182, DOI 10.1109/ISCA.2003.1206999
   Psarras A, 2016, IEEE T COMPUT, V65, P3136, DOI 10.1109/TC.2016.2519916
   Rodrigo S, 2008, INT SYMP MICROARCH, P364, DOI 10.1109/MICRO.2008.4771805
   Samman FA, 2010, IEEE T VLSI SYST, V18, P1067, DOI 10.1109/TVLSI.2009.2019758
   Seitanidis I, 2014, 2014 EIGHTH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS), P135, DOI 10.1109/NOCS.2014.7008772
   Sivaram R., 1997, PARALLEL COMPUTER RO, P39
   Stefan RA, 2014, IEEE T COMPUT, V63, P583, DOI 10.1109/TC.2012.117
   Wang L, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P64, DOI 10.1109/NOCS.2009.5071446
   Wenmin Hu, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P363, DOI 10.1109/ASPDAC.2011.5722214
NR 26
TC 0
Z9 0
U1 0
U2 1
PY 2020
UT WOS:000696570700386
DA 2023-11-16
ER

PT C
AU Chen, ZY
   Zhou, H
   Gu, J
AF Chen, Zhengyu
   Zhou, Hai
   Gu, Jie
GP ACM
TI Digital Compatible Synthesis, Placement and Implementation of
   Mixed-Signal Time-Domain Computing
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
AB Mixed-signal time-domain computing (TC) has recently drawn significant attention due to its high efficiency in applications such as machine learning accelerators. However, due to the nature of analog and mixed-signal design, there is a lack of a systematic flow of synthesis and place & route for time-domain circuits. This paper proposed a comprehensive design flow for TC. In the front-end, a variation-aware digital compatible synthesis flow is proposed. In the back-end, a placement technique using graph-based optimization engine is proposed to deal with the especially stringent matching requirement in TC. Simulation results show significant improvement over the prior analog placement methods. A 55nm test chip is used to demonstrate that the proposed design flow can meet the stringent timing matching target for TC with significant performance boost over conventional digital design.
C1 [Chen, Zhengyu; Zhou, Hai; Gu, Jie] Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.
RP Chen, ZY (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.
EM zhengyuchen2015@u.northwestern.edu; haizhou@northwestern.edu;
   jgu@northwestern.edu
CR Amravati A., 2018, ISSCC
   Buhler F. N., 2017, VLSI S
   Chen Z., 2019, IEEE JSSC
   Chou Pang-Yen, 2011, IEEE ICCAD
   Guo P.-N., 1999, IEEE ACM DAC
   Lin Chang-Tzu, 2002, IEEE ISCAS
   Lin J.-M., 2004, IEEE T CAD
   Lin P. H., 2008, IEEE ACM DAC
   LIU M, 2017, IEEE ICC, pNI306
   Ma Qiang, 2011, IEEE T COMPUTER AIDE
   Marin Jorge, 2018, IEEE ESSCIRC
   Miyashita Daisuke, 2014, IEEE JSSC
   Miyashita Daisuke, 2016, IEEE ASSCC
   Shim Yong, 2016, IEEE ACM DAC
   Xu Biying, 2017, IEEE ACM DAC
   Yunju Choi Yoontaek, 2016, IEEE S VLSI CIRC
   Zhou Hai, 2004, IEEE ICCD
NR 17
TC 19
Z9 22
U1 0
U2 0
PY 2019
DI 10.1145/3316781.3317800
UT WOS:000482058200067
DA 2023-11-16
ER

PT J
AU Elfadel, IM
AF Elfadel, Ibrahim M.
TI On the Stability of Analog ReLU Networks
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Trajectory; Asymptotic stability; Circuit stability; Neural networks;
   Symmetric matrices; Stability criteria; Design automation; Analog
   networks; Lyapunov theory; rectified linear unit (ReLU) activation;
   stability analysis
AB Rectified linear unit (ReLU) networks have become widely used in machine learning and automated inference using neural networks. Various forms of hardware accelerators based on ReLU networks have also been under development. In this brief, the stability problem in analog ReLU networks is addressed. Using the Lyapunov stability theory, it is shown that the origin of an unforced, analog ReLU dynamical system is globally asymptotically stable if the induced Euclidean norm of its connectivity matrix is less than one. An example is given to demonstrate that this upper bound is the best that can be achieved. In particular, the stability result holds for the case of a nonsymmetric connectivity matrix as may occur in some mathematical models of neurobiology.
C1 [Elfadel, Ibrahim M.] Khalifa Univ, Ctr Cyber Phys Syst, Abu Dhabi, U Arab Emirates.
   [Elfadel, Ibrahim M.] Khalifa Univ, Dept Elect Engn & Comp Sci, Abu Dhabi, U Arab Emirates.
RP Elfadel, IM (corresponding author), Khalifa Univ, Ctr Cyber Phys Syst, Abu Dhabi, U Arab Emirates.
EM ibrahim.elfadel@ku.ac.ae
CR [Anonymous], 1985, MATRIX ANAL
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   FREEMAN WJ, 1987, BIOL CYBERN, V56, P139, DOI 10.1007/BF00317988
   GRAY CM, 1989, P NATL ACAD SCI USA, V86, P1698, DOI 10.1073/pnas.86.5.1698
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   HASLER M, 1985, CIRCUITS NONLINEAIRE
   Haykin S., 2009, NEURAL NETWORKS LEAR
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   Klusowski JM, 2018, IEEE T INFORM THEORY, V64, P7649, DOI 10.1109/TIT.2018.2874447
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Nair V., 2010, ICML, P807
   Vidyasagar M., 1978, NONLINEAR SYSTEMS AN
   Ying Y, 2019, IEEE ACCESS, V7, P101633, DOI 10.1109/ACCESS.2019.2928442
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhu JH, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P265, DOI [10.1109/apccas47518.2019.8953177, 10.1109/APCCAS47518.2019.8953177]
NR 16
TC 4
Z9 4
U1 5
U2 11
PD NOV
PY 2021
VL 40
IS 11
BP 2426
EP 2430
DI 10.1109/TCAD.2020.3042155
UT WOS:000709074300023
DA 2023-11-16
ER

PT C
AU Oyamada, M
   Liu, JQ
   Narita, K
   Araki, T
AF Oyamada, Masafumi
   Liu, Jianquan
   Narita, Kazuyo
   Araki, Takuya
BE Chen, L
   Jia, Y
   Sellis, T
   Liu, G
TI MOARLE: Matrix Operation Accelerator Based on Run-Length Encoding
SO WEB TECHNOLOGIES AND APPLICATIONS, APWEB 2014
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 16th Asia-Pacific Web Conference (APWeb)
CY SEP 05-07, 2014
CL Natl Univ Def Technol, Changsha, PEOPLES R CHINA
HO Natl Univ Def Technol
DE Matrix; Compression; Run-length encoding; Similarity search; Euclidean
   distance
AB Matrix computation is a key technology in various data processing tasks including data mining, machine learning, and information retrieval. Size of matrices has been increasing with the development of computational resources and dissemination of big data. Huge matrices are memory- and computational-time-consuming. Therefore, reducing the size and computational time of huge matrices is a key challenge in the data processing area. We develop MOARLE, a novel matrix computation framework that saves memory space and computational time. In contrast to conventional matrix computational methods that target to sparse matrices, MOARLE can efficiently handle both sparse matrices and dense matrices. Our experimental results show that MOARLE can reduce the memory usage to 2% of the original usage and improve the computational performance by a factor of 124x.
C1 [Oyamada, Masafumi; Liu, Jianquan; Narita, Kazuyo; Araki, Takuya] NEC Corp Ltd, Green Platform Res Labs, Nakahara Ku, Kawasaki, Kanagawa 2118666, Japan.
RP Oyamada, M (corresponding author), NEC Corp Ltd, Green Platform Res Labs, Nakahara Ku, 1753 Shimonumabe, Kawasaki, Kanagawa 2118666, Japan.
EM m-oyamada@cq.jp.nec.com; j-liu@ct.jp.nec.com; k-narita@ct.jp.nec.com;
   t-araki@dc.jp.nec.com
CR [Anonymous], 1999, P ACM IEEE C SUP SC9
   Apple Inc, 1996, TN1023 APPL INC
   Brodie BC, 2006, CONF PROC INT SYMP C, P191, DOI 10.1145/1150019.1136500
   Cormen T. H., 2001, INTRO ALGORITHMS
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Feng X., 2012, P 2012 ACM SIGMOD IN, P325, DOI 10.1145/2213836.2213874
   Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712
   Golub Gene H, 2013, MATRIX COMPUTATIONS, P4, DOI DOI 10.56021/9781421407944
   Guennebaud G., 2010, EIGEN V3
   Guyon I., 2004, NIPS
   Lichman M., 2013, UCI MACHINE LEARNING
   Rendle S, 2013, PROC VLDB ENDOW, V6, P337, DOI 10.14778/2535573.2488340
   Willcock Jeremiah, 2006, P 20 ANN INT C SUP I, P307, DOI [DOI 10.1145/1183401.1183444, 10.1145/1183401.1183444]
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2014
VL 8709
BP 425
EP 436
UT WOS:000345287600037
DA 2023-11-16
ER

PT C
AU Sun, RD
   Liu, PL
   Accetti, C
   Naqvi, AA
   Ahmed, H
   Qian, JC
AF Sun, Rongdi
   Liu, Peilin
   Accetti, Cecil
   Naqvi, Abid A.
   Ahmed, Haroon
   Qian, Jiuchao
GP IEEE
TI A 974GOPS/W Multi-level Parallel Architecture for Binary Weight Network
   Acceleration
SO 2018 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 27-30, 2018
CL Florence, ITALY
AB Deep neural networks dominate in the machine learning field. However, deploying deep neural networks on mobile devices requires aggressive compression of models due to huge amounts of parameters. An extreme case is to restrict weights to binary values {+1/-1} without much loss of accuracy. This promising method not only reduces hardware overhead of memory and computation, but also improves the performance of network inference. In this work, a flexible architecture for binary weight network acceleration is proposed. The architecture fully exploits the inherent multi-level parallelism of neural networks, resulting in utilization of processing elements over 80% for different layers. In addition, we present efficient data placement and transmission methods in coordination with multilevel parallel processing. The accelerator is implemented using SMIC 40nm technology. It operates at 1.2V and achieves up to 974GOPS/W power efficiency.
C1 [Sun, Rongdi; Liu, Peilin; Accetti, Cecil; Naqvi, Abid A.; Ahmed, Haroon; Qian, Jiuchao] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
RP Sun, RD (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM the.sun@sjtu.edu.cn
CR Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2016, BINARYNET TRAINING D
   Glorot X., 2011, P 14 INT C ARTIFICIA, P315
   Han S., 2015, P 28 INT C NEUR INF, V1, P1135
   Kim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062189
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
NR 8
TC 2
Z9 2
U1 0
U2 2
PY 2018
DI 10.1109/ISCAS.2018.8351247
UT WOS:000451218701149
DA 2023-11-16
ER

PT S
AU Farrokhbakht, H
   Hessabi, S
   Jerger, NE
AF Farrokhbakht, Hossein
   Hessabi, Shaahin
   Jerger, N. Enright
BE Hurson, AR
   Sarbazi-Azad, H
TI Power-gating in NoCs
SO POWER-EFFICIENT NETWORK-ON-CHIPS: DESIGN AND EVALUATION, VOL. 124
SE Advances in Computers
DT Article; Book Chapter
AB Driven by trends such as machine learning, the internet of things and 5G, it is increasingly common to see computer chips with tens to hundreds of processing cores, ranging from general purpose CPUs to application specific accelerators. All processing cores must share data and coordinate their operation, leading to contention and performance penalties. Communication between cores is handled by a network-on-chip (NoC). However, NoCs for modern chips contribute considerably to the chips overall power budget. Thus, the NoC power consumption is critical for ensuring that chips can continue to keep pace with increasing demand. Although NoCs are over-provisioned to handle worst-case scenarios, the NoCs routers are quite often underutilized, making them a promising candidate for power-gating. However, applying power-gating to the on-chip routers has several challenges. In this chapter, we present different power-gating solutions to alleviate the challenges.
C1 [Farrokhbakht, Hossein] Univ Toronto, Toronto, ON, Canada.
   [Hessabi, Shaahin] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Jerger, N. Enright] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
RP Farrokhbakht, H (corresponding author), Univ Toronto, Toronto, ON, Canada.
CR [Anonymous], 2015, INT S NETW ON CHIP
   [Anonymous], 2013, ACM SIGARCH COMPUT A, DOI DOI 10.1145/2508148.2485950
   Badr M, 2014, CONF PROC INT SYMP C, P109, DOI 10.1109/ISCA.2014.6853236
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chen LZ, 2015, INT S HIGH PERF COMP, P378, DOI 10.1109/HPCA.2015.7056048
   Chen LZ, 2014, INT S HIGH PERF COMP, P296, DOI 10.1109/HPCA.2014.6835940
   Chen LZ, 2012, INT SYMP MICROARCH, P270, DOI 10.1109/MICRO.2012.33
   Daya BK, 2014, CONF PROC INT SYMP C, P25, DOI 10.1109/ISCA.2014.6853232
   DUATO J, 1993, IEEE T PARALL DISTR, V4, P1320, DOI 10.1109/71.250114
   Farrokhbakht H., 2018, INT S LOW POWER ELEC, P17
   Farrokhbakht H., 2017, INT S NETW ON CHIP N, P1
   Farrokhbakht H., 2016, 2016 10 IEEEACM INT, P1
   Farrokhbakht H, 2019, I SYMPOS LOW POWER E
   Jiang N., 2013, INT S PERFORMANCE AN, P86, DOI 10.1109/ISPASS.2013.6557149
   Keating M., 2007, LOW POWER METHODOLOG
   Kim G, 2011, DES AUT CON, P936
   Kim JS, 2003, ISLPED'03: PROCEEDINGS OF THE 2003 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P424
   Kim NS, 2003, COMPUTER, V36, P68, DOI 10.1109/MC.2003.1250885
   Matsutani Hiroki, 2010, 2010 ACM/IEEE International Symposium on Networks-on-Chip (NOCS), P61, DOI 10.1109/NOCS.2010.16
   Matsutani H, 2008, ASIA S PACIF DES AUT, P519
   Mirhosseini A, 2015, DES AUT TEST EUROPE, P1527
   Parikh R, 2014, DES AUT CON
   Samih A, 2013, INT S HIGH PERF COMP, P508, DOI 10.1109/HPCA.2013.6522345
   Sun Chen, 2012, P NOCS
   WOO SC, 1995, ACM COMP AR, P24, DOI 10.1109/ISCA.1995.524546
NR 25
TC 0
Z9 0
U1 1
U2 1
PY 2022
VL 124
BP 319
EP 356
DI 10.1016/bs.adcom.2021.11.013
UT WOS:000878180000010
DA 2023-11-16
ER

PT J
AU Brand, M
   Hannig, F
   Keszocze, O
   Teich, J
AF Brand, Marcel
   Hannig, Frank
   Keszocze, Oliver
   Teich, Juergen
TI Precision- and Accuracy-Reconfigurable Processor Architectures-An
   Overview
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Computer architecture; Arithmetic; Circuits and systems; Neural
   networks; Adders; Machine learning algorithms; Linear algebra; Accuracy;
   arithmetic; reconfigurable architectures; convolutional neural networks
ID FUSED-MULTIPLY-ADD
AB High performance and, at the same time, energy efficiency are important yet often conflicting requirements in many fields of emerging applications. Those applications range from multi-dimensional and multi-sensor digital signal processing to machine learning, such as neural network processing. Whereas conventional fixed-point and floating-point processor architectures cannot adapt to quite diverging demands related to required precision and accuracy of computations, even within a single application, e.g., in different layers of a neural network, domain-specific accelerators may be much too specific and thus rigid to cover a wide enough spectrum of applications. In this tutorial brief, we give an overview of existing processor solutions that are reconfigurable or tunable in precision or accuracy of computations. The spectrum of reviewed architectures ranges from processors with vectorizable processors over multi- and trans-precision solutions, including GPUs to any-time instruction-set processors. The latter works with a fixed precision, but the accuracy of the result of floating-point operations is encoded in the instruction word. It can thus vary from instruction to instruction. This allows realizing accuracy vs. execution time or energy tradeoffs. Subsequently, we investigate several application domains, including neural network processing, linear algebra, and approximate computing, where such emerging processor architectures can be beneficially used.
C1 [Brand, Marcel; Hannig, Frank; Keszocze, Oliver; Teich, Juergen] Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
RP Brand, M (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
EM marcel.brand@fau.de; frank.hannig@fau.de; oliver.keszoecze@fau.de;
   juergen.teich@fau.de
CR Agrawal A, 2021, ISSCC DIG TECH PAP I, V64, P144, DOI 10.1109/ISSCC42613.2021.9365791
   [Anonymous], 2021, GAP APPL PROC
   [Anonymous], 2021, XIL AI ENG TECHN
   [Anonymous], 2018, 338302001US INT
   Arunachalam V, 2018, MICROPROCESS MICROSY, V57, P23, DOI 10.1016/j.micpro.2017.12.009
   Brand M, 2020, IEEE INT CONF ASAP, P157, DOI 10.1109/ASAP49362.2020.00034
   Brand M, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P215, DOI 10.1145/3310273.3322833
   Darulova E., 2018, TOOLS ALGORITHMS CON
   Darulova E, 2018, ACM IEEE INT CONF CY, P208, DOI 10.1109/ICCPS.2018.00028
   de Dinechin F, 2011, IEEE DES TEST COMPUT, V28, P18, DOI 10.1109/MDT.2011.44
   Ebrahimi Zahra, 2020, PROC ACM GREAT LAKES, P151, DOI 10.1145/3386263.3406907
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   GRANLUND T, GNU MULTIPLE PRECISI
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Hannig F, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584660
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   IEEE standard for floating-point arithmetic, 2019, IEEE STANDARD FLOATI, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2019.8766229]
   Jaiswal MK, 2019, IEEE ACCESS, V7, P74586, DOI 10.1109/ACCESS.2019.2920936
   Johnson J., 2018, ARXIV 181101721
   Keszocze O., 2021, PROC S APPL COMPUT
   Koster U., 2017, ADV NEURAL INFORM PR, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Mach S., 2021, THESIS ETH ZURICH ZU
   Mach S., 2021, FLOATING POINT ARCHI
   Mach S, 2021, IEEE T VLSI SYST, V29, P774, DOI 10.1109/TVLSI.2020.3044752
   Mach S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351816
   Maddock J., BOOST MULTIPRECISION
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Manolopoulos K., 2010, Proceedings of the 2010 17th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2010), P5, DOI 10.1109/ICECS.2010.5724440
   Ortiz M., 2018, ARXIV180405267
   Plagwitz P, 2021, ANN IEEE SYM FIELD P, P10, DOI 10.1109/FCCM51124.2021.00010
   Prasad R, 2020, DES AUT TEST EUROPE, P1067, DOI [10.23919/DATE48585.2020.9116408, 10.23919/date48585.2020.9116408]
   Said NA, 2021, MICROELECTRON RELIAB, V120, DOI 10.1016/j.microrel.2021.114099
   Schuiki F, 2019, DES AUT TEST EUROPE, P662, DOI [10.23919/date.2019.8715007, 10.23919/DATE.2019.8715007]
   Schuster A., 2021, PROC INT WORKSHOP IO
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tagliavini G, 2019, DES AUT TEST EUROPE, P654, DOI [10.23919/date.2019.8714897, 10.23919/DATE.2019.8714897]
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Thompto BW, 2021, CONF PROC INT SYMP C, P29, DOI 10.1109/ISCA52012.2021.00012
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Wang Naigang, 2018, NEURIPS, P7675
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Yamaguchi H., PROC C AUTOM TEST EU, V2021
   Zamirai P., 2021, PREPRINTS
   Zhang H, 2019, IEEE T COMPUT, V68, P1035, DOI 10.1109/TC.2019.2895031
   Zhang T., 2019, PREPRINTS
NR 46
TC 2
Z9 2
U1 1
U2 4
PD JUN
PY 2022
VL 69
IS 6
BP 2661
EP 2666
DI 10.1109/TCSII.2022.3173753
UT WOS:000804726500022
DA 2023-11-16
ER

PT J
AU Wheeldon, A
   Serb, A
AF Wheeldon, Adrian
   Serb, Alexander
TI A study on the clusterability of latent representations in image
   pipelines
SO FRONTIERS IN NEUROINFORMATICS
DT Article
DE machine learning; symbolics; clustering; convolutional neural networks;
   autoencoders; artificial intelligence; cognitive computing
AB Latent representations are a necessary component of cognitive artificial intelligence (AI) systems. Here, we investigate the performance of various sequential clustering algorithms on latent representations generated by autoencoder and convolutional neural network (CNN) models. We also introduce a new algorithm, called Collage, which brings views and concepts into sequential clustering to bridge the gap with cognitive AI. The algorithm is designed to reduce memory requirements, numbers of operations (which translate into hardware clock cycles) and thus improve energy, speed and area performance of an accelerator for running said algorithm. Results show that plain autoencoders produce latent representations which have large inter-cluster overlaps. CNNs are shown to solve this problem, however introduce their own problems in the context of generalized cognitive pipelines.
C1 [Wheeldon, Adrian; Serb, Alexander] Univ Edinburgh, Ctr Elect Frontiers, Sch Engn, Edinburgh, Scotland.
RP Wheeldon, A (corresponding author), Univ Edinburgh, Ctr Elect Frontiers, Sch Engn, Edinburgh, Scotland.
EM adrian.wheeldon@ed.ac.uk
CR Blot M., 2020, PHD THESIS
   Cohen T. S., 2017, P INT C LEARNING REP
   Frady EP, 2020, NEURAL COMPUT, V32, P2311, DOI 10.1162/neco_a_01331
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Hartigan JA., 1975, CLUSTERING ALGORITHM
   Imani M, 2019, DES AUT TEST EUROPE, P1591, DOI [10.23919/date.2019.8715147, 10.23919/DATE.2019.8715147]
   Kanerva Pentti, 1988, SPARSE DISTRIBUTED M
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Neubert P, 2021, ROBOT SCI SYS
   Newson A, 2020, J MATH IMAGING VIS, V62, P293, DOI 10.1007/s10851-019-00924-w
   Theodoridis S., 2006, PATTERN RECOGN
NR 11
TC 0
Z9 0
U1 0
U2 0
PD FEB 16
PY 2023
VL 17
AR 1074653
DI 10.3389/fninf.2023.1074653
UT WOS:000942143800001
DA 2023-11-16
ER

PT C
AU El-Helw, I
   Hofman, R
   Bal, HE
AF El-Helw, Ismail
   Hofman, Rutger
   Bal, Henri E.
BE Malawski, M
   Rzadca, K
TI Accelerating Overlapping Community Detection: Performance Tuning a
   Stochastic Gradient Markov Chain Monte Carlo Algorithm
SO EURO-PAR 2020: PARALLEL PROCESSING
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 26th International Conference on Parallel and Distributed Computing
   (Euro-Par)
CY AUG 24-28, 2020
CL ELECTR NETWORK
DE Algorithms for accelerators and heterogeneous systems; Performance
   analysis; Combinatorial and data intensive application
AB Building efficient algorithms for data-intensive problems requires deep analysis of data access patterns. Random data access patterns exacerbate this process. In this paper, we discuss accelerating a randomized data-intensive machine learning algorithm using multi-core CPUs and several types of GPUs. A thorough analysis of the algorithm's data dependencies enabled a 75% reduction in its memory footprint. We created custom compute kernels via code generation to identify the optimal set of data placement and computational optimizations per compute device. An empirical evaluation shows up to 245x speedup compared to an optimized sequential version. Another result from this evaluation is that achieving peak performance does not always match intuition: e.g., depending on the GPU architecture, vectorization may increase or hamper performance.
C1 [El-Helw, Ismail; Hofman, Rutger; Bal, Henri E.] Vrije Univ Amsterdam, Amsterdam, Netherlands.
RP El-Helw, I (corresponding author), Vrije Univ Amsterdam, Amsterdam, Netherlands.
EM ielhelw@gmail.com; rutger@cs.vu.nl; bal@cs.vu.nl
CR [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   Bal H, 2016, COMPUTER, V49, P54, DOI 10.1109/MC.2016.127
   El-Helw I, 2016, IEEE SYM PARA DISTR, P1463, DOI 10.1109/IPDPSW.2016.165
   Gaihre A, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P121, DOI 10.1145/3307681.3326606
   Girolami M, 2011, J ROY STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x
   Gupta S, 2015, Arxiv, DOI arXiv:1502.02551
   Huang FR, 2015, Arxiv, DOI arXiv:1309.0787
   khronos, OPENCL THE OPEN STAN
   Beam AL, 2014, Arxiv, DOI [arXiv:1402.4089, 10.1080/10618600.2015.1035724, DOI 10.1080/10618600.2015.1035724]
   Leskovec J., 2014, SNAP DATASETS STANFO
   Li WZ, 2015, Arxiv, DOI arXiv:1510.04815
   Lim RV, 2017, PROC INT CONF PARAL, P523, DOI 10.1109/ICPP.2017.61
   Medlar A, 2013, BIOINFORMATICS, V29, P413, DOI 10.1093/bioinformatics/bts704
   Mei XX, 2017, IEEE T PARALL DISTR, V28, P72, DOI 10.1109/TPDS.2016.2549523
   Nugteren C., CLCUDAAPI PORTABLE H
   numpy, NUMPY HOME PAGE
   nvidia, CUBLAS HOME PAGE
   Pagh R, 2004, J ALGORITHMS, V51, P122, DOI 10.1016/j.jalgor.2003.12.002
   van Werkhoven B, 2019, FUTURE GENER COMP SY, V90, P347, DOI 10.1016/j.future.2018.08.004
   White G, 2014, COMPUT STAT DATA AN, V71, P643, DOI 10.1016/j.csda.2013.03.027
   Yan Feng, 2009, ADV NEURAL INFORM PR, V9, P2134
   Zhu HZ, 2020, FUTURE GENER COMP SY, V111, P552, DOI 10.1016/j.future.2019.09.052
NR 22
TC 1
Z9 1
U1 0
U2 0
PY 2020
VL 12247
BP 510
EP 526
DI 10.1007/978-3-030-57675-2_32
UT WOS:000851325900032
DA 2023-11-16
ER

PT C
AU Imani, M
   Gupta, S
   Rosing, T
AF Imani, Mohsen
   Gupta, Saransh
   Rosing, Tajana
GP Assoc Comp Machinery
TI Digital-based Processing In-Memory: A Highly-Parallel Accelerator for
   Data Intensive Applications
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
DE Processing in-memory; Non-volatile memory; Machine learning acceleration
AB Recently, Processing In-Memory (PIM) has been shown as a promising solution to address data movement issue in the current processors. However, today's PIM technologies are mostly analog-based, which involve both scalability and efficiency issues. In this paper, we propose a novel digital-based PIM which accelerates fundamental operations and diverse data analytic procedures using processing in-memory technology. Instead of sending a large amount of data to the processing cores for computation, our design performs a large part of computation tasks inside the memory; thus the application performance can be accelerated significantly by avoiding the memory access bottleneck. Digital-based PIM supports bit-wise operations between two selected bit-line of the memory block and then extends it to support row-parallel arithmetic operations.
C1 [Imani, Mohsen; Gupta, Saransh; Rosing, Tajana] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Imani, M (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM moimani@ucsd.edu; sgupta@ucsd.edu; tajana@ucsd.edu
CR [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, ADV FUNCTIONAL MAT
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Gupta S, 2019, PR GR LAK SYMP VLSI, P201, DOI 10.1145/3299874.3317977
   Gupta S, 2018, 2018 IEEE 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA), P1, DOI 10.1109/ICSA.2018.00009
   Haj-Ali A., 2018, IEEE ISCAS
   Imani M., 2019, IEEE ACM INT S COMP
   Imani M, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P8, DOI 10.1109/ICCKE.2017.8167879
   Imani M, 2019, PR GR LAK SYMP VLSI, P429, DOI 10.1145/3299874.3319483
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Kvatinsky S, 2015, IEEE T CIRCUITS-II, V62, P786, DOI 10.1109/TCSII.2015.2433536
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Li C, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1174, DOI 10.1109/ASE.2019.00130
   Salamat S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P166
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song L, 2017, IOP C SER EARTH ENV, V73, DOI 10.1088/1755-1315/73/1/012017
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Talati N, 2016, IEEE T NANOTECHNOL, V15, P635, DOI 10.1109/TNANO.2016.2570248
   Zhou MX, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P591, DOI 10.1145/3287624.3287711
NR 19
TC 2
Z9 2
U1 0
U2 1
PY 2019
BP 38
EP 40
DI 10.1145/3357526.3357551
UT WOS:000557305400004
DA 2023-11-16
ER

PT J
AU Khoshavi, N
   Maghsoudloo, M
   Roohi, A
   Sargolzaei, S
   Bi, Y
AF Khoshavi, Navid
   Maghsoudloo, Mohammad
   Roohi, Arman
   Sargolzaei, Saman
   Bi, Yu
TI HARDeNN: Hardware-assisted attack-resilient deep neural network
   architectures
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Black -box adversarial attacks; Binarized neural network accelerator;
   Machine learning; Soft error
AB We propose HARDeNN, a low-overhead end-to-end inference accelerator methodology to armor the underlying pre-trained neural network architecture against black-box non-input adversarial attacks. In order to find the most vulnerable neural network architectures parameters, a hardware-assisted fault injection tool and a statistical stress model have been proposed to synergy uniform fault assessment across layers and targeted in-layer fault assessment to realize a holistic, rigorous fault evaluation in NN topologies susceptible to non-input adversarial black-box attacks. The key observation from the assessment shows that the weights and activation functions are the most vulnerable neural network parameters that are susceptible to both single-bit and multiple-bit flip at-tacks. Concerning the aforementioned parameters, a multi-objective design space exploration is conducted to find a superior design under different resource constraints. The error-resiliency magnitude offered by HARDeNN can be adjusted based on the given boundaries. The experimental results show that HARDeNN methodology enhances the error-resiliency magnitude of cnvW1A1 by 17.19% and 96.15% for 100 multi-bit upsets that target weight and activation layers, respectively, during CIFAR-10 classification.(c) 2017 Elsevier Inc. All rights reserved.
C1 [Khoshavi, Navid] Adv Micro Devices AMD, Santa Clara, CA 95054 USA.
   [Maghsoudloo, Mohammad] Golestan Univ, Fac Engn, Dept Comp Engn, Gorgan, Iran.
   [Roohi, Arman] Univ Nebraska Lincoln, Dept Comp Sci & Engn, Lincoln, NE USA.
   [Sargolzaei, Saman] Univ Tennessee Martin, Dept Engn, Martin, TN USA.
   [Bi, Yu] Univ Rhode Isl, Dept Elect & Comp Engn, Kingston, RI USA.
RP Khoshavi, N (corresponding author), Adv Micro Devices AMD, Santa Clara, CA 95054 USA.
EM navid.khoshavi@amd.com
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2016, ARXIV
   Azarkhish E, 2018, IEEE T PARALL DISTR, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Azizimazreah A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Barenghi A, 2012, P IEEE, V100, P3056, DOI 10.1109/JPROC.2012.2188769
   Breier J, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P2204, DOI 10.1145/3243734.3278519
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi Y., 2018, ARXIV
   Courbariaux M., 2016, ARXIV
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Dixit A, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Goodfellow J., 2014, ARXIV
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hitaj B, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P603, DOI 10.1145/3133956.3134012
   Hubara I, 2016, ADV NEUR IN, V29
   Jung S., 2018, ARXIV
   Khoshavi N., 2020, ICMLA, P1
   Khoshavi N, 2017, INTEGRATION, V59, P10, DOI 10.1016/j.vlsi.2017.03.013
   Khoshavi N, 2014, MIDWEST SYMP CIRCUIT, P929, DOI 10.1109/MWSCAS.2014.6908568
   Kim M, 2016, ARXIV
   Kim Y, 2014, CONVOLUTIONAL NEURAL, DOI 10.3115/v1/D14-1181
   Kim Y, 2014, CONF PROC INT SYMP C, P361, DOI 10.1109/ISCA.2014.6853210
   Koster U., 2017, ADV NEURAL INFORM PR, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Lacey G, 2016, ARXIV
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Lin CY, 2018, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2018.8297290
   Liu W, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120755
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Madry Aleksander, 2017, ARXIV170606083
   Maghsoudloo M, 2015, MICROELECTRON RELIAB, V55, P2439, DOI 10.1016/j.microrel.2015.07.049
   Najibi M., 2017, IEEE I CONF COMP VIS
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761
   Paudel B. R., 2022, INT S QUALITY ELECT
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Roohi A, 2020, IEEE T COMPUT, V69, P349, DOI 10.1109/TC.2019.2949042
   Salem A., 2018, ARXIV
   Seifert N, 2012, IEEE T NUCL SCI, V59, P2666, DOI 10.1109/TNS.2012.2218128
   Sharma H., 2018, P ACMIEEE 45 ANN INT
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Simonyan M., 2014, ARXIV
   Tajik Shahin, 2022, Security and Artificial Intelligence: A Crossdisciplinary Approach. Lecture Notes in Computer Science (13049), P72, DOI 10.1007/978-3-030-98795-4_4
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang N., 2018, INT C NEURAL INFORM, P7686
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
   Yih W., 2015, CISC VIS NETW IND GL
   Zhu C., 2017, INT C LEARN REPR ICL, P1
NR 52
TC 1
Z9 1
U1 0
U2 0
PD NOV
PY 2022
VL 95
AR 104710
DI 10.1016/j.micpro.2022.104710
EA OCT 2022
UT WOS:000880097300005
DA 2023-11-16
ER

PT C
AU Colangelo, P
   Sengupta, S
   Margala, M
AF Colangelo, Philip
   Sengupta, Shayan
   Margala, Martin
GP IEEE
TI Sparse Persistent GEMM Accelerator using OpenCL for Intel FPGAs
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
DE sparsity; OpenCL; BLAS; FPGA
AB Optimizations of primitive routines such as General Matrix Multiplication (GEMM) continue to advance the state of the art performance for their applications. Various libraries such as Basic Linear Algebra Subprograms (BLAS) exist that provide API interfaces to highly tuned, hardware-specific implementations. Applications such as deep learning push the limits of what is possible from these subroutines by necessitating unique optimizations like lowering numeric precision and data type bit-width, exploiting resiliency, and removing redundancy. Hardware plays a considerable role in the performance of a subroutine because of the inherent layout of memory and arithmetic structures such as the SIMD processors found in general CPU and GPU architectures. FPGAs play a unique role in this space because the reconfigurable circuits and routing provide a pipelined architecture capable of both SIMD and MIMD-like architectures. Within a pipeline, the capability of accelerating operations on FPGA through low-bit and fine-grained designs is typically only seen in ASICs. In this paper, we provide an overview of an OpenCL based GEMM accelerator design that exploits sparsity and compression to persist data in FPGA on-chip, fine-grained SRAM. The design includes support for successive GEMMs with added activation functions, making it suitable for some machine learning applications. Results are measured running on Intel's Arria 10 GX 1150 FPGA. Compared to non-sparse and nonpersistent designs, we achieve a speedup towards the theoretical limit of 6.5x for our fine-grained implementation and 8x for our structured implementation. We measure over 1 TOP/s utilizing only 17% of Arria 10 DSP blocks for a 90% sparse design.
C1 [Colangelo, Philip] Intel Umass Lowell, San Jose, CA 95134 USA.
   [Sengupta, Shayan] Intel, San Jose, CA USA.
   [Margala, Martin] Univ Massachusetts Lowell, Lowell, MA USA.
RP Colangelo, P (corresponding author), Intel Umass Lowell, San Jose, CA 95134 USA.
EM philip.colangelo@intel.com; shayan.sengupta@intel.com;
   Martin_Margala@uml.edu
CR [Anonymous], IMPLEMENTING FPGA DE
   [Anonymous], INTEL FPGA SDK OPENC
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Chiu GR, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'18), P34, DOI 10.1145/3177540.3177561
   Colangelo P, 2019, IEEE HIGH PERF EXTR
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Gupta Suyog., 2018, PRUNE NOT PRUNE EXPL
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Han S., 2015, ADV NEURAL INFORM PR, P1135
   Intel<(R), INTEL FPGA PRODUCTS
   Lavin A., 2015, FAST ALGORITHMS CONV
   Lawson C. L., 1977, BASIC LINEAR ALGEBRA
   Ling A.C., 2017, P 5 INT WORKSH OPENC
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Mao Huizi, 2017, ABS170508922 ARXIV
   Michael Mathieu, 2013, ARXIV13125851CSCV
   Moss DJM, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P107, DOI 10.1145/3174243.3174258
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   Pete Warden, 2015, P WARDENS BLOG
   Sato, 2019, P ACM SIGDA INT S FI, P186, DOI DOI 10.1145/3289602.3293967
   Sheng K, 2009, PROC INT SYMP POWER, P255, DOI 10.1109/ISPSD.2009.5158050
   Sinha Udayan., 2017, ENABLING IMPACTFUL D
   Umuroglu Y., 2016, ABS161207119 CORR
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2020
UT WOS:000706854700463
DA 2023-11-16
ER

PT C
AU Oh, YH
   Kim, S
   Jin, Y
   Son, S
   Bae, J
   Lee, J
   Park, Y
   Kim, DU
   Ham, TJ
   Lee, JW
AF Oh, Young H.
   Kim, Seonghak
   Jin, Yunho
   Son, Sam
   Bae, Jonghyun
   Lee, Jongsung
   Park, Yeonhong
   Kim, Dong Uk
   Ham, Tae Jun
   Lee, Jae W.
GP IEEE Comp Soc
TI Layerweaver: Maximizing Resource Utilization of Neural Processing Units
   via Layer-Wise Scheduling
SO 2021 27TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2021)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 27th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 27-MAR 03, 2021
CL ELECTR NETWORK
DE Layer-wise Scheduling; Systems for Machine Learning; Inference Serving
   System; Neural Networks; Accelerator Systems; Multi-tasking
ID IOT
AB To meet surging demands for deep learning inference services, many cloud computing vendors employ high-performance specialized accelerators, called neural processing units (NPUs). One important challenge for effective use of NPUs is to achieve high resource utilization over a wide spectrum of deep neural network (DNN) models with diverse arithmetic intensities. There is often an intrinsic mismatch between the compute-to-memory bandwidth ratio of an NPU and the arithmetic intensity of the model it executes, leading to under-utilization of either compute resources or memory bandwidth. Ideally, we want to saturate both compute TOP/s and DRAM bandwidth to achieve high system throughput. Thus, we propose Layerweaver, an inference serving system with a novel multi-model time-multiplexing scheduler for NPUs. Layerweaver reduces the temporal waste of computation resources by interweaving layer execution of multiple different models with opposing characteristics: compute-intensive and memory-intensive. Layerweaver hides the memory time of a memory-intensive model by overlapping it with the relatively long computation time of a compute-intensive model, thereby minimizing the idle time of the computation units waiting for off-chip data transfers. For a two-model serving scenario of batch 1 with 16 different pairs of compute- and memory-intensive models, Layerweaver improves the temporal utilization of computation units and memory channels by 44.0% and 28.7%, respectively, to increase the system throughput by 60.1% on average, over the baseline executing one model at a time.
C1 [Oh, Young H.] Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon, South Korea.
   [Kim, Seonghak; Jin, Yunho; Son, Sam; Bae, Jonghyun; Lee, Jongsung; Park, Yeonhong; Kim, Dong Uk; Ham, Tae Jun; Lee, Jae W.] Seoul Natl Univ, Neural Proc Res Ctr NPRC, Dept Comp Sci & Engn, Seoul, South Korea.
RP Oh, YH (corresponding author), Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon, South Korea.
EM younghwan@skku.edu; ksh1102@snu.ac.kr; yhjin0509@snu.ac.kr;
   sosson97@snu.ac.kr; jonghbae@snu.ac.kr; leitia@snu.ac.kr;
   ilil96@snu.ac.kr; dongukim12@snu.ac.kr; taejunham@snu.ac.kr;
   jaewlee@snu.ac.kr
CR Alwani M, 2016, INT SYMP MICROARCH
   Amazon, AM SAGEMAKER
   [Anonymous], 2020, TENSORFLOW CORE V2 3
   [Anonymous], 2020, PYTORCH 1 6 0 DOCUME
   [Anonymous], 2013, DATACENTER COMPUTER
   Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081
   cambricon, CAMBR MLU100
   Chen Q, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P17, DOI 10.1145/3037697.3037700
   Chen Q, 2016, ACM SIGPLAN NOTICES, V51, P681, DOI 10.1145/2954679.2872368
   Chen YL, 2016, DESTECH TRANS COMP
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027
   Chollet Francois, 2017, PROC CVPR IEEE, P1251, DOI DOI 10.1109/CVPR.2017.195
   Chowdhury M., 2020, PLMR 20, P98
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Daga B., 2019, S HIGH PERF CHIPS HO
   Devlin J., 2018, ARXIV, DOI 10.18653/v1/N19-1423
   Elliott GA, 2013, REAL TIM SYST SYMP P, P33, DOI 10.1109/RTSS.2013.12
   Emer J., 2019, P 24 INT C ARCH SUPP
   Eyerman S, 2008, IEEE MICRO, V28, P42, DOI 10.1109/MM.2008.44
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Google, GOOGL NOW
   Google, GOOGL AI PLATF
   Google Cloud, EDG TPU RUN INF EDG
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Habana, HAB GOYA
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   Hauswald J, 2015, ACM SIGPLAN NOTICES, V50, P223, DOI [10.1145/2775054.2694347, 10.1145/2694344.2694347]
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He K., 2016, CORR161105431
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang YP, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P615, DOI 10.1145/3037697.3037698
   Kato S., 2011, P 2011 USENIX C USEN, P17
   Kim H., 2019, P IEEE REAL TIM SYST
   Krishna T., 2018, P 23 INT C ARCH SUPP
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Le, 2019, CORR190608237
   Lee Y, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P611
   Li H, 2018, IEEE NETWORK, V32, P96, DOI 10.1109/MNET.2018.1700202
   Lin, 2018, P 12 INT C ANT SEC I
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Matos LM, 2019, IEEE IJCNN, DOI 10.1109/ccac.2019.8921191
   Microsoft, MICR AZ MACH LEARN
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tanasic I, 2014, CONF PROC INT SYMP C, P193, DOI 10.1109/ISCA.2014.6853208
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang XF, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1088, DOI 10.1109/HPCC/SmartCity/DSS.2018.00181
   Wang Yu, 2020, P MACHINE LEARNING S, V2, P30
   Yan MY, 2019, IEEE INT CONF ROBOT, P4804, DOI [10.1109/ICRA.2019.8794024, 10.1109/icra.2019.8794024]
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao ZR, 2018, IEEE T COMPUT AID D, V37, P2348, DOI 10.1109/TCAD.2018.2858384
NR 60
TC 13
Z9 15
U1 2
U2 4
PY 2021
BP 584
EP 597
DI 10.1109/HPCA51647.2021.00056
UT WOS:000671076000044
DA 2023-11-16
ER

PT C
AU He, ZH
   Wang, ZK
   Alonso, G
AF He, Zhenhao
   Wang, Zeke
   Alonso, Gustavo
GP ACM
TI BiS-KM: Enabling Any-Precision K-Means on FPGAs
SO 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS
   (FPGA '20)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 23-25, 2020
CL Seaside, CA
DE FPGA; K-Means; Bit-Serial Arithmetic; Low-Precision Clustering; Memory
   Layout
AB K-Means is a popular clustering algorithm widely used and extensively studied in the literature. In this paper we explore the challenges and opportunities in using low precision input in conjunction with a standard K-Means algorithm as a way to improve the memory bandwidth utilization on hardware accelerators. Low precision input through quantization has become a standard technique in machine learning to reduce computational costs and memory traffic. When applied in FPGAs, several issues need to be addressed. First and foremost is the overhead of storing the data at different precision levels since, depending on the training objective, different levels of precision might be needed. Second, the FPGA design needs to accommodate varying precision without requiring reconfiguration. To address these concerns, we propose Bit-Serial K-Means (BiS-KM), a combination of a hybrid memory layout supporting data retrieval at any level of precision, a novel FPGA design based on bit-serial arithmetic, and a modified K-Means algorithm tailored to FPGAs. We have tested BiS-KM with various data sets and compared our design with a state-of-the-art FPGA accelerator. BiS-KM achieves an almost linear speedup as precision decreases, providing a more effective way to perform K-Means on FPGAs.
C1 [He, Zhenhao; Wang, Zeke; Alonso, Gustavo] Swiss Fed Inst Technol, Dept Comp Sci, Syst Grp, Zurich, Switzerland.
RP He, ZH (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Syst Grp, Zurich, Switzerland.
EM zhenhao.he@inf.ethz.ch; zeke.wang@inf.ethz.ch;
   gustavo.alonso@inf.ethz.ch
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2018, ASPLOS
   Blackard JA, 1999, COMPUT ELECTRON AGR, V24, P131, DOI 10.1016/S0168-1699(99)00046-0
   Bohm Christian, 2017, SIAM
   Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Delmas Alberto, 2017, CORR
   Estlick M., 2001, FPGA
   Feng Z., 2015, ICDE
   Feng ZQ, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P31, DOI 10.1145/2723372.2747642
   Gokhale Maya, 2003, J SUPERCOMPUT
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He ZH, 2018, I C FIELD PROG LOGIC, P368, DOI 10.1109/FPL.2018.00069
   Hubara I, 2018, J MACH LEARN RES, V18
   Hussain HM, 2012, INT J RECONFIGURABLE, V2012, DOI 10.1155/2012/135926
   HUSSAIN HM, 2011, NASA ESA C AD HARDW
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Kara Kaan, 2019, VLDB
   Kara Kaan, 2018, VLDB
   Lesser Bernd, 2011, ICCS
   Li Y., 2013, SIGMOD C, P289, DOI DOI 10.1145/2463676.2465322
   Lin Z., 2012, FPL
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Oliver N., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P80, DOI 10.1109/ReConFig.2011.4
   Owaida M, 2018, I C FIELD PROG LOGIC, P295, DOI 10.1109/FPL.2018.00057
   Owaida M, 2017, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2017.37
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Saegusa T, 2006, I C FIELD PROG LOGIC, P567
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Sinha A., 1999, IEEE INT ASIC SOC C
   Tang Qing Y., 2016, ACM Transactions on Reconfigurable Technology and Systems, V10, DOI 10.1145/2964910
   Umuroglu Y, 2018, I C FIELD PROG LOGIC, P307, DOI 10.1109/FPL.2018.00059
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vergara A, 2012, SENSOR ACTUAT B-CHEM, V166, P320, DOI 10.1016/j.snb.2012.01.074
   Wang X, 2007, ANN IEEE SYM FIELD P, P151, DOI [10.1109/FCCM.2007.38, 10.1109/FCCM.2007.40]
   Wang Z., 2018, ICDE
   Wang ZK, 2019, PROC VLDB ENDOW, V12, P807, DOI 10.14778/3317315.3317322
   Wang ZK, 2016, IEEE T PARALL DISTR, V27, P3547, DOI 10.1109/TPDS.2016.2537805
   Wang ZK, 2016, INT S HIGH PERF COMP, P114, DOI 10.1109/HPCA.2016.7446058
   Williamson T., 2013, VITREORETINAL SURG, V2nd ed., P1
   White S. A., 1989, IEEE ASSP Magazine, V6, P4, DOI 10.1109/44.41514
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang HT, 2017, PR MACH LEARN RES, V70
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
NR 49
TC 5
Z9 5
U1 0
U2 2
PY 2020
BP 233
EP 243
DI 10.1145/3373087.3375316
UT WOS:000693956500032
DA 2023-11-16
ER

PT C
AU Oppermann, J
   Sommer, L
   Weber, L
   Reuter-Oppermann, M
   Koch, A
   Sinnen, O
AF Oppermann, Julian
   Sommer, Lukas
   Weber, Lukas
   Reuter-Oppermann, Melanie
   Koch, Andreas
   Sinnen, Oliver
GP IEEE
TI SkyCastle: A Resource-Aware Multi-Loop Scheduler for High-Level
   Synthesis
SO 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2019)
DT Proceedings Paper
CT International Conference on Field-Programmable Technology (ICFPT)
CY DEC 09-13, 2019
CL Tianjin, PEOPLES R CHINA
AB A common optimisation problem in the high-level synthesis (HLS) of FPGA-based accelerators is to find a microarchitecture that maximises the performance while keeping the utilisation of the device's low-level resources below certain limits.
   We propose to tackle it directly as part of the HLS scheduler. To that end, we formalise a general, integrated scheduling and allocation problem for HLS kernels, and present SkyCastle, a novel resource-aware multi-loop scheduler using integer linear programming to solve it for a subclass of kernels composed of multiple, nested loops. In order to demonstrate the practical applicability of the approach, we model the scheduler in such a way as to be plug-in compatible with the Xilinx Vivado HLS engine, allowing the computed solutions to be fed back into its synthesis flow.
   We evaluate SkyCastle for three non-trivial kernels from the machine learning, signal processing, and physical simulation domains, on two FPGA devices. Additionally, we investigate the replication of slightly slower, but smaller accelerators as a means to further boost the overall performance. In contrast to Vivado HLS' default settings, which aim at maximum performance but may fail in later synthesis steps, the solutions computed by our scheduler always result in synthesisable designs.
C1 [Oppermann, Julian; Sommer, Lukas; Weber, Lukas; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
   [Reuter-Oppermann, Melanie] Karlsruhe Inst Technol, Discrete Optimizat & Logist Grp, Karlsruhe, Germany.
   [Sinnen, Oliver] Univ Auckland, Parallel & Reconfigurable Comp Lab, Auckland, New Zealand.
RP Oppermann, J (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM oppermann@esa.tu-darmstadt.de; sommer@esa.tu-darmstadt.de;
   weber@esa.tu-darmstadt.de; melanie.reuter@kit.edu;
   koch@esa.tu-darmstadt.de; o.sinnen@auckland.ac.nz
CR [Anonymous], 2013, LLNLTR641973
   Cong J., 2014, P 2014 ACMSIGDA INT, P213, DOI [10.1145/2554688.2554771, DOI 10.1145/2554688.2554771]
   Cong J, 2012, DES AUT TEST EUROPE, P1018
   Dua D., 2017, UCI MACHINE LEARNING
   Eichenberger A. E., 1997, P ACM SIGPLAN 97 C P
   Fan K, 2005, INT SYMP MICROARCH, P219
   Ferrandi Fabrizio, 2008, 2008 IEEE Computer Society Annual Symposium on VLSI, P417, DOI 10.1109/ISVLSI.2008.73
   Gurobi Optimization LLC., 2019, GUR DOC CONSTR
   Korinth Jens, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P214, DOI 10.1007/978-3-030-17227-5_16
   Kudlur M., 2006, P 4 INT C HARDW SOFT, P270, DOI 10.1145/1176254.1176321
   Li Peng, 2015, P 2015 ACM SIGDA INT, P200
   Molina A., 2018, MIXED SUM PRODUCT NE
   Nelson Brent E., 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P353, DOI 10.1007/978-3-030-17227-5_25
   Oppermann J, 2019, LECT NOTES COMPUT SC, V11725, P170, DOI 10.1007/978-3-030-29400-7_13
   Oppermann J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3317670
   Poon H., 2011, P UAI
   Prost-Boucle A, 2014, J SYST ARCHITECT, V60, P79, DOI 10.1016/j.sysarc.2013.10.002
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Schafer BC, 2016, IEEE T COMPUT AID D, V35, P394, DOI 10.1109/TCAD.2015.2472007
   Solis-Vasquez L., 2018, 5 INT WORKSH FPGAS S
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Wang H., 2019, J ASTRONOMICAL INSTR
   Zhao JR, 2017, ICCAD-IEEE ACM INT, P430, DOI 10.1109/ICCAD.2017.8203809
   Zheming Jin, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P199, DOI 10.1007/978-3-030-17227-5_15
   Zhong GW, 2016, DES AUT CON, DOI 10.1145/2897937.2898040
NR 25
TC 1
Z9 1
U1 0
U2 1
PY 2019
BP 36
EP 44
DI 10.1109/ICFPT47387.2019.00013
UT WOS:000574770300005
DA 2023-11-16
ER

PT C
AU Chow, M
   Ranganath, K
   Lerias, R
   Carodan, MS
   Wong, D
AF Chow, Marcus
   Ranganath, Kiran
   Lerias, Robert, Jr.
   Carodan, Mika Shanela
   Wong, Daniel
GP IEEE COMP SOC
TI Energy Efficient Task Graph Execution Using Compute Unit Masking in GPUs
SO PROCEEDINGS OF RSDHA 2021: REDEFINING SCALABILITY FOR DIVERSELY
   HETEROGENEOUS ARCHITECTURES
DT Proceedings Paper
CT Conference on Redefining Scalability for Diversely Heterogeneous
   Architectures (RSDHA)
CY NOV 19, 2021
CL St Louis, MO
DE DAGEE; Windograd-Strassen; Task Graph Execution; Compute Unit Masking;
   Resource Partitioning; Energy Efficient
AB The frontiers of Supercomputers are pushed by novel discrete accelerators. Accelerators such as GPUs are employed to enable faster execution of Machine Learning, Scientific and High-Performance Computing applications. However, it has been harder to gain increased parallelism in traditional workloads. This is why more focus has been into Task Graphs. AMD's Directed Acyclic Graph Execution Engine (DAGEE) allows the programmer to define a workload in fine-grained tasks, and the system handles the dependencies at the lower-level. We evaluate DAGEE with the Winograd-Strassen Matrix Multiplication algorithm and show that DAGEE achieves on average 15.3% speed up over the traditional matrix multiplication algorithm.
   While using DAGEE this may increase the contention among kernels due to the increased amount of parallelism. However, AMD allows the programmer to set the number of active Compute Unit (CU) by masking. This fine-grain scaling allows the system software to enable only the required number of Computation Units within a GPU. Using this mechanism we develop a Runtime that masks CU's for each task during a task graph execution and partitions each task into their separate CU's, reducing overall contention and energy consumption. We show that our CU Masking runtime on average reduces energy by 18%.
C1 [Chow, Marcus; Lerias, Robert, Jr.; Carodan, Mika Shanela] Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.
   [Ranganath, Kiran; Wong, Daniel] Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA.
RP Chow, M (corresponding author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.
EM mchow009@ucr.edu; krang006@ucr.edu; rleri001@ucr.edu; mcaro008@ucr.edu;
   danwong@ucr.edu
CR A. M. D. (AMD), 2021, DIR AC GRAPH EX ENG
   A. M. D. (AMD, 2021, RAD OP COMP SOFTW PL
   Abdolrashidi A, 2021, CONF PROC INT SYMP C, P333, DOI 10.1109/ISCA52012.2021.00034
   Abdolrashidi A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P600, DOI 10.1145/3123939.3123976
   Dennis J. B., 1975, A preliminary architecture for a basic data-flow processor
   Dutu A, 2020, ANN I S COM, P1022, DOI 10.1109/ISCA45697.2020.00087
   Hines J, 2018, COMPUT SCI ENG, V20, P78, DOI 10.1109/MCSE.2018.021651341
   Huang Jie, 2018, AAAI
   Jahanshahi A., 2021, 2021 12 INT GREEN SU
   Jahanshahi A, 2020, IEEE COMPUT ARCHIT L, V19, P139, DOI 10.1109/LCA.2020.3023723
   L. L. N. Labs, 2021, EL CAP SUP
   Lai PW, 2013, INT C HIGH PERFORM, P139, DOI 10.1109/HiPC.2013.6799109
   N. Inc, 2019, NVID DGX 1 ESS INSTR
   Nvidia, 2019, CUD GRAPHS
   O. N. Labs, 2021, FRONT EX SUP
   Otterness N., 2020, 32 EUR C REAL TIM SY
   Otterness N, 2021, 29TH INTERNATIONAL CONFERENCE ON REAL TIME NETWORKS AND SYSTEMS (RTNS 2021), P24, DOI 10.1145/3453417.3453432
   PNNL, 2021, ABSTR RUNT SYST
   Ranganath K., 2021, SC21 INT C HIGH PERF
   Ranganath K., 2021, INT WORKSH LANG COMP
   Ranganath K, 2019, IEEE COMPUT ARCHIT L, V18, P128, DOI 10.1109/LCA.2019.2933842
   Tripathy D., 2021, P 15 IEEE ACM INT C
   Tripathy D, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3451164
   Tripathy Devashree, 2020, P ACMIEEE INT S LOW, P109
NR 24
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 45
EP 51
DI 10.1109/RSDHA54838.2021.00011
UT WOS:000763827900006
DA 2023-11-16
ER

PT J
AU Gonzalez, HA
   George, R
   Muzaffar, S
   Acevedo, J
   Höppner, S
   Mayr, C
   Yoo, J
   Fitzek, FHP
   Elfadel, IM
AF Gonzalez, Hector A.
   George, Richard
   Muzaffar, Shahzad
   Acevedo, Javier
   Hoeppner, Sebastian
   Mayr, Christian
   Yoo, Jerald
   Fitzek, Frank H. P.
   Elfadel, Ibrahim M.
TI Hardware Acceleration of EEG-Based Emotion Classification Systems: A
   Comprehensive Survey
SO IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS
DT Article
DE Emotion detection and classification; EEG; hardware acceleration;
   machine learning; monitoring of neurological disorders
ID INDEPENDENT COMPONENT ANALYSIS; NEURAL-NETWORKS; IMPAIRED RECOGNITION;
   FACIAL EXPRESSIONS; FEATURE-SELECTION; BRAIN RESPONSES; SCALP EEG;
   MUSIC; IMPLEMENTATION; DESIGN
AB Recent years have witnessed a growing interest in EEG-based wearable classifiers of emotions, which could enable the real-time monitoring of patients suffering from neurological disorders such as Amyotrophic Lateral Sclerosis (ALS), Autism Spectrum Disorder (ASD), or Alzheimer's. The hope is that such wearable emotion classifiers would facilitate the patients' social integration and lead to improved healthcare outcomes for them and their loved ones. Yet in spite of their direct relevance to neuro-medicine, the hardware platforms for emotion classification have yet to fill up some important gaps in their various approaches to emotion classification in a healthcare context. In this paper, we present the first hardware-focused critical review of EEG-based wearable classifiers of emotions and survey their implementation perspectives, their algorithmic foundations, and their feature extraction methodologies. We further provide a neuroscience-based analysis of current hardware accelerators of emotion classifiers and use it to map out several research opportunities, including multi-modal hardware platforms, accelerators with tightly-coupled cores operating robustly in the near/supra-threshold region, and pre-processing libraries for universal EEG-based datasets.
C1 [Gonzalez, Hector A.; George, Richard; Hoeppner, Sebastian; Mayr, Christian] Tech Univ Dresden, Chair Highly Parallel VLSI Syst & Neuromorph Circ, D-01062 Dresden, Germany.
   [Acevedo, Javier; Fitzek, Frank H. P.] Tech Univ Dresden, Deutsch Telekom Chair Commun Networks, D-01187 Dresden, Germany.
   [Mayr, Christian; Fitzek, Frank H. P.] Tech Univ Dresden, Ctr Tactile Internet CeTi Human In The Loop, Cluster Excellence, Dresden, Germany.
   [Yoo, Jerald] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
   [Yoo, Jerald] 1 Inst Hlth, Singapore 117456, Singapore.
   [Muzaffar, Shahzad; Elfadel, Ibrahim M.] Khalifa Univ, Dept Elect Engn & Comp Sci, Abu Dhabi 127788, U Arab Emirates.
   [Muzaffar, Shahzad; Elfadel, Ibrahim M.] Khalifa Univ, Ctr Cyber Phys Syst C2PS, Abu Dhabi 127788, U Arab Emirates.
RP Gonzalez, HA (corresponding author), Tech Univ Dresden, Chair Highly Parallel VLSI Syst & Neuromorph Circ, D-01062 Dresden, Germany.
EM hector.gonzalez@tu-dresden.de; richard_miru.george@tu-dresden.de;
   shahzad.muzaffar@ku.ac.ae; javier.acevedo@tu-dresden.de;
   sebastian.hoeppner@tu-dresden.de; christian.mayr@tu-dresden.de;
   jyoo@nus.edu.sg; frank.fitzek@tu-dresden.de; ibrahim.elfadel@ku.ac.ae
CR Abtahi F, 2018, IEEE WINT CONF APPL, P10, DOI 10.1109/WACV.2018.00008
   Ackermann P, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P159
   Acunzo DJ, 2012, J NEUROSCI METH, V209, P212, DOI 10.1016/j.jneumeth.2012.06.011
   Al-Fahad R., 2019, P INT JOINT C NEUR N, P1
   Alakus TB, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101951
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Alex M, 2020, IEEE ACCESS, V8, P191080, DOI 10.1109/ACCESS.2020.3032380
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   Ali M, 2016, INT CONF UBIQ FUTUR, P946, DOI 10.1109/ICUFN.2016.7536936
   Alsolamy M, 2016, INT CONF COMP SCI, DOI 10.1109/CSIT.2016.7549457
   [Anonymous], 2010, PROC IEEE WORLD C CO
   [Anonymous], 2020, IEEE INT SYMP CIRC S, P1, DOI [10.1109/ISCAS45731.2020.9180909, DOI 10.1109/iscas45731.2020.9180909]
   [Anonymous], 2016, P STUD RES C INF INF
   [Anonymous], 2017, CC0 1 0
   Urigüen JA, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/031001
   Arikan K, 2006, CLIN EEG NEUROSCI, V37, P230, DOI 10.1177/155005940603700313
   Arnau-González P, 2019, IEEE IMAGE PROC, P2591, DOI [10.1109/ICIP.2019.8803315, 10.1109/icip.2019.8803315]
   Aslam A. R., 2019, P IEEE INT S CIRC SY, P1
   Aslam AR, 2020, IEEE CUST INTEGR CIR
   Aslam AR, 2020, IEEE T BIOMED CIRC S, V14, P838, DOI 10.1109/TBCAS.2020.3008766
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Baas BM, 1999, IEEE J SOLID-ST CIRC, V34, P380, DOI 10.1109/4.748190
   Bastos T., 2012, P 4 INT C INT HUM CO, P1, DOI [DOI 10.1109/IHCI.2012.6481860, 10.1109/IHCI.2012.6481860]
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Bigirimana AD, 2020, IEEE T NEUR SYS REH, V28, P850, DOI 10.1109/TNSRE.2020.2978951
   Blagojevic M., 2016, IEEE S VLSI CIRCUITS, P1
   Bol D, 2019, ISSCC DIG TECH PAP I, V62, P322, DOI 10.1109/ISSCC.2019.8662293
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brouwer AM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00136
   Brown L, 2011, IEEE ENG MED BIO, P2188, DOI 10.1109/IEMBS.2011.6090412
   Bucks RS, 2004, AGING MENT HEALTH, V8, P222, DOI 10.1080/13607860410001669750
   Busek P, 2005, PHYSIOL RES, V54, P327, DOI 10.33549/physiolres.930551
   Candra H, 2017, IEEE ENG MED BIO, P463, DOI 10.1109/EMBC.2017.8036862
   Carter R, 2016, INT EL DEVICES MEET
   Cecbur, 2019, CC BY SA 4 0
   Chai T.-Y., 2010, INT J INTEGR ENG, V1, P71
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Chao H, 2021, IEEE SENS J, V21, P2024, DOI 10.1109/JSEN.2020.3020828
   Chen JX, 2019, IEEE ACCESS, V7, P118530, DOI 10.1109/ACCESS.2019.2936817
   Chen JX, 2019, IEEE ACCESS, V7, P44317, DOI 10.1109/ACCESS.2019.2908285
   Chen J, 2015, APPL SOFT COMPUT, V30, P663, DOI 10.1016/j.asoc.2015.01.007
   Chen YH, 2020, IEEE T CIRCUITS-II, V67, P3437, DOI 10.1109/TCSII.2020.2999573
   Chen YH, 2020, IEEE T BIOMED CIRC S, V14, P373, DOI 10.1109/TBCAS.2020.2974049
   Cheng J, 2021, IEEE J BIOMED HEALTH, V25, P453, DOI 10.1109/JBHI.2020.2995767
   Cho K., 2014, ARXIV14061078, V1406, P1078
   Clark Jr J. W., 1998, MED INSTRUMENTATION, V3, P121
   Clerc S, 2015, P IEEE INT SOL STAT, P1
   Coan JA, 2003, PSYCHOPHYSIOLOGY, V40, P106, DOI 10.1111/1469-8986.00011
   Craik A, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0ab5
   Darwin C., 1872, P374
   Davidson RJ, 2003, PSYCHOPHYSIOLOGY, V40, P655, DOI 10.1111/1469-8986.00067
   Davis P, 2014, INT SYMP INTEGR CIRC, P248, DOI 10.1109/ISICIR.2014.7029468
   de Cheveigné A, 2018, NEUROIMAGE, V172, P903, DOI 10.1016/j.neuroimage.2018.01.035
   De Pascalis V, 2013, BIOL PSYCHOL, V94, P198, DOI 10.1016/j.biopsycho.2013.05.016
   DEJONG PJ, 1990, INT J NEUROSCI, V51, P89, DOI 10.3109/00207459009000513
   Dong HW, 2015, IEEE INT SYM MULTIM, P13, DOI 10.1109/ISM.2015.71
   Downs M., 2008, EXCELLENCE DEMENTIA
   Du XB, 2022, IEEE T AFFECT COMPUT, V13, P1528, DOI 10.1109/TAFFC.2020.3013711
   Duan RN, 2012, LECT NOTES COMPUT SC, V7666, P468, DOI 10.1007/978-3-642-34478-7_57
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   el Kaliouby R, 2006, ANN NY ACAD SCI, V1093, P228, DOI 10.1196/annals.1382.016
   EYSENCK SBG, 1985, PERS INDIV DIFFER, V6, P21, DOI 10.1016/0191-8869(85)90026-1
   Fang WC, 2019, IEEE J EM SEL TOP C, V9, P645, DOI 10.1109/JETCAS.2019.2951232
   Fdeloche, 2017, CC BY SA 4 0
   Fernandez-Duque D, 2005, NEUROPSYCHOLOGIA, V43, P1673, DOI 10.1016/j.neuropsychologia.2005.01.005
   Fletcher RR, 2010, IEEE T INF TECHNOL B, V14, P215, DOI 10.1109/TITB.2009.2038692
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Gao ZK, 2021, IEEE T COGN DEV SYST, V13, P945, DOI 10.1109/TCDS.2020.2976112
   Gao ZK, 2020, IEEE T IND INFORM, V16, P7159, DOI 10.1109/TII.2019.2955447
   Gideon J, 2017, INTERSPEECH, P1098, DOI 10.21437/Interspeech.2017-1637
   Gläscher J, 2003, J NEUROSCI, V23, P10274
   Gonzalez HA, 2020, IEEE INT SYMP CIRC S
   Gonzalez HA, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401547
   Gonzalez HA, 2020, IEEE ACCESS, V8, P140896, DOI 10.1109/ACCESS.2020.3012900
   Gonzalez HA, 2019, IEEE ENG MED BIO, P694, DOI [10.1109/EMBC.2019.8857248, 10.1109/embc.2019.8857248]
   Gooding DC, 2002, SCHIZOPHR RES, V57, P109, DOI 10.1016/S0920-9964(01)00295-X
   Govindarajan V, 2018, IEEE INT C INTELL TR, P1017, DOI 10.1109/ITSC.2018.8569585
   Grundlehner B, 2019, ENCYCLOPEDIA OF BIOMEDICAL ENGINEERING, VOL 3, P223, DOI 10.1016/B978-0-12-801238-3.10885-2
   Guo KR, 2019, IEEE ENG MED BIO, P7088, DOI [10.1109/embc.2019.8857698, 10.1109/EMBC.2019.8857698]
   Guo KR, 2017, IEEE ENG MED BIO, P489, DOI 10.1109/EMBC.2017.8036868
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Hadjidimitriou SK, 2012, IEEE T BIO-MED ENG, V59, P3498, DOI 10.1109/TBME.2012.2217495
   Hargrave R, 2002, J NEUROPSYCH CLIN N, V14, P64, DOI 10.1176/appi.neuropsych.14.1.64
   Hasan M, 2002, ELECTRON LETT, V38, P163, DOI 10.1049/el:20020117
   Hatamikia Sepideh, 2014, J Med Signals Sens, V4, P194
   He ZP, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10100687
   HJORTH B, 1970, ELECTROEN CLIN NEURO, V29, P306, DOI 10.1016/0013-4694(70)90143-4
   Höppner S, 2019, PROC EUR S-STATE DEV, P66, DOI 10.1109/essderc.2019.8901768
   Hong YY, 2012, IEEE T INSTRUM MEAS, V61, P3175, DOI 10.1109/TIM.2012.2211460
   Höppner S, 2020, IEEE T CIRCUITS-II, V67, P2159, DOI 10.1109/TCSII.2019.2959544
   HOSSEINI SA, 2011, INT J IMAGE GRAPH SI, V3, DOI DOI 10.5815/IJIGSP.2011.05.05
   Hu B, 2018, IEEE ACM T COMPUT BI, V15, P38, DOI 10.1109/TCBB.2016.2616395
   Hu HY, 2018, IEEE INT VEH SYM, P156, DOI 10.1109/IVS.2018.8500444
   Huang D., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252390
   Huang H., 2019, IEEE ACCESS, V8, P3265
   Huang JM, 2017, IEEE INT C BIOINFORM, P958, DOI 10.1109/BIBM.2017.8217786
   Huang WK, 2020, IEEE ACCESS, V8, P131636, DOI 10.1109/ACCESS.2020.3009665
   Huang YD, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8919038
   Islam MK, 2016, NEUROPHYSIOL CLIN, V46, P287, DOI 10.1016/j.neucli.2016.07.002
   Issa S, 2021, IEEE T SYST MAN CY-S, V51, P7382, DOI 10.1109/TSMC.2020.2969686
   Jalilifard A, 2016, IEEE ENG MED BIO, P845, DOI 10.1109/EMBC.2016.7590833
   Jatupaiboon N, 2015, J MED IMAG HEALTH IN, V5, P1020, DOI 10.1166/jmihi.2015.1490
   Jatupaiboon N, 2013, INT JOINT CONF COMP, P21
   Jia X, 2020, IEEE SYS MAN CYBERN, P2452, DOI [10.1109/SMC42975.2020.9283159, 10.1109/smc42975.2020.9283159]
   Jiang JF, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P105, DOI 10.1109/SNPD.2016.7515886
   Jie X, 2014, BIO-MED MATER ENG, V24, P1185, DOI 10.3233/BME-130919
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Jobst M., 2020, PROC 6 INT C EVENT B, P1, DOI [10.1109/EBCCSP51266.2020.9291357, DOI 10.1109/EBCCSP51266.2020.9291357]
   Kamae N, 2014, IEEE ASIAN SOLID STA, P53, DOI 10.1109/ASSCC.2014.7008858
   KAMINSKI MJ, 1991, BIOL CYBERN, V65, P203, DOI 10.1007/BF00198091
   Kang HJ, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.2461
   Kang HJ, 2013, ELECTRON LETT, V49, P589, DOI 10.1049/el.2013.0689
   Karn RR, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (IEEE ICCC 2019), P90, DOI 10.1109/ICCC.2019.00027
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Kelber F, 2020, NICE 20, DOI [10.1145/3381755.3381778, DOI 10.1145/3381755.3381778]
   Kemker R, 2018, AAAI CONF ARTIF INTE, P3390
   Khalili Z., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1571, DOI 10.1109/IJCNN.2009.5178854
   Khare SK, 2020, IEEE T INSTRUM MEAS, V69, P9609, DOI 10.1109/TIM.2020.3006611
   Khare SK, 2021, IEEE T NEUR NET LEAR, V32, P2901, DOI 10.1109/TNNLS.2020.3008938
   Khosrowabadi Reza, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4242, DOI 10.1109/ICPR.2010.1031
   Kim BH, 2020, IEEE T AFFECT COMPUT, V11, P230, DOI 10.1109/TAFFC.2018.2790939
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kiymik MK, 2005, COMPUT BIOL MED, V35, P603, DOI 10.1016/j.compbiomed.2004.05.001
   Knyazev GG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00158
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koelstra S, 2010, LECT NOTES ARTIF INT, V6334, P89, DOI 10.1007/978-3-642-15314-3_9
   Krisnandhika B, 2017, 2017 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS AND DEVICES (ICCED 2017), P50, DOI 10.1109/ICCED.2017.8019990
   Kroupi E, 2016, IEEE T AFFECT COMPUT, V7, P422, DOI 10.1109/TAFFC.2015.2496310
   Kumagai Y, 2017, IEEE ENG MED BIO, P2879, DOI 10.1109/EMBC.2017.8037458
   Kumar N, 2016, PROCEDIA COMPUT SCI, V84, P31, DOI 10.1016/j.procs.2016.04.062
   Lan ZR, 2016, VISUAL COMPUT, V32, P347, DOI 10.1007/s00371-015-1183-y
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Lee HY, 2007, IEEE T CIRCUITS-I, V54, P889, DOI 10.1109/TCSI.2006.888764
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P314, DOI 10.1109/ISSCC.2019.8662454
   Lee YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095415
   Li G., 2017, IEEE, V1, P1, DOI [10.1109/BIOCAS.2017.8325198, DOI 10.1109/BIOCAS.2017.8325198]
   Li M, 2009, IEEE ENG MED BIO, P1323
   Li PY, 2019, IEEE T BIO-MED ENG, V66, P2869, DOI 10.1109/TBME.2019.2897651
   Li X, 2016, IEEE INT C BIOINFORM, P352, DOI 10.1109/BIBM.2016.7822545
   Li XY, 2019, IEEE DATA MINING, P389, DOI 10.1109/ICDM.2019.00049
   Li YJ, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101060
   Liberati G, 2013, INT CONF AFFECT, P838, DOI 10.1109/ACII.2013.157
   Lin YP, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00094
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Lin YP, 2009, INT CONF ACOUST SPEE, P489, DOI 10.1109/ICASSP.2009.4959627
   Liu C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00840
   Liu NJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P896, DOI 10.1109/ICASSP.2018.8462518
   Liu SQ, 2021, IEEE ACM T COMPUT BI, V18, P1710, DOI 10.1109/TCBB.2020.3018137
   Liu S, 2017, IEEE ENG MED BIO, P2231, DOI 10.1109/EMBC.2017.8037298
   Liu S, 2016, IEEE ENG MED BIO, P841, DOI 10.1109/EMBC.2016.7590832
   Liu YH, 2013, IEEE ENG MED BIO, P4306, DOI 10.1109/EMBC.2013.6610498
   Liu YS, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P53, DOI 10.1109/CW.2012.15
   Long Short-Term Memory, 2017, CC BT SA 4 0
   Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI [10.1088/1741-2552/aab2f2, 10.1088/1741-2560/4/2/R01]
   Lulé D, 2007, J NEUROL, V254, P519, DOI 10.1007/s00415-006-0409-3
   Luo YL, 2020, IEEE ACCESS, V8, P46007, DOI 10.1109/ACCESS.2020.2978163
   Luo Y, 2018, IEEE ENG MED BIO, P2535, DOI 10.1109/EMBC.2018.8512865
   Makeig S, 2011, LECT NOTES COMPUT SC, V6975, P487, DOI 10.1007/978-3-642-24571-8_61
   Marimpis AD, 2020, IEEE ACCESS, V8, P170928, DOI 10.1109/ACCESS.2020.3025370
   Marque C, 2005, J ELECTROMYOGR KINES, V15, P310, DOI 10.1016/j.jelekin.2004.10.001
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Mayr C., 2019, ARXIV191102385
   Mehmood RM, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3011817
   Mehmood RM, 2017, IEEE ACCESS, V5, P14797, DOI 10.1109/ACCESS.2017.2724555
   Mehmood RM, 2016, COMPUT ELECTR ENG, V53, P444, DOI 10.1016/j.compeleceng.2016.04.009
   Mikhail Mina, 2013, International Journal of Autonomous and Adaptive Communications Systems, V6, P80, DOI 10.1504/IJAACS.2013.050696
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Mohammadi Z, 2017, NEURAL COMPUT APPL, V28, P1985, DOI 10.1007/s00521-015-2149-8
   Mohammadpour M, 2017, 2017 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P127, DOI 10.1109/RIOS.2017.7956455
   Moon SE, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2556, DOI 10.1109/ICASSP.2018.8461315
   Mostafa H, 2011, IEEE T VLSI SYST, V19, P1848, DOI 10.1109/TVLSI.2010.2060503
   Murugappan M, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P289, DOI 10.1109/CSPA.2013.6530058
   Murugappan M., 2009, International Journal of Medical Engineering and Informatics, V1, P342, DOI 10.1504/IJMEI.2009.022645
   Nasehi S., 2012, WSEAS T SIGNAL PROCE, V3, P87
   Nie D, 2011, I IEEE EMBS C NEUR E, P667, DOI 10.1109/NER.2011.5910636
   Nunez PL, 2006, ELECT FIELDS BRAIN N
   Onton J., 2020, IMAGINED EMOTION STU
   Pan JH, 2016, IEEE IJCNN, P2063, DOI 10.1109/IJCNN.2016.7727453
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panayiotou G, 2017, PSYCHOPHYSIOLOGY, V54, P1323, DOI 10.1111/psyp.12887
   PAPEZ JW, 1995, J NEUROPSYCH CLIN N, V7, P103
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Park C. Y, 2020, **DATA OBJECT**, DOI [10.5281/zenodo.3814370, DOI 10.5281/ZENODO.3814370]
   Parra LC, 2005, NEUROIMAGE, V28, P326, DOI 10.1016/j.neuroimage.2005.05.032
   Petrantonakis PC, 2010, IEEE T AFFECT COMPUT, V1, P81, DOI 10.1109/T-AFFC.2010.7
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Poh MZ, 2010, IEEE T BIO-MED ENG, V57, P1243, DOI 10.1109/TBME.2009.2038487
   Pons M., 2019, PROC IEEE CICC, P1
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Pu Y, 2010, IEEE J SOLID-ST CIRC, V45, P668, DOI 10.1109/JSSC.2009.2039684
   Quelen A, 2018, ISSCC DIG TECH PAP I, P304, DOI 10.1109/ISSCC.2018.8310305
   Rahman FU, 2019, ISSCC DIG TECH PAP I, V62, P312, DOI 10.1109/ISSCC.2019.8662486
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Rudovic O, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aao6760
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Saligane M., 2018, P IEEE S VLSI CIRC, P63
   Sazgar M., 2019, ABSOLUTE EPILEPSY EE, P149, DOI DOI 10.1007/978-3-030-03511-2_8
   Schneider T.R., 2010, SIMULTANEOUS EEG FMR, P121, DOI DOI 10.1093/ACPROF:OSO/9780195372731.003.0008
   Setianingrum AH, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT (CITSM), P407
   Shahabi H, 2016, COMPUT HUM BEHAV, V58, P231, DOI 10.1016/j.chb.2016.01.005
   Shen LL, 2020, IEEE ACCESS, V8, P222966, DOI 10.1109/ACCESS.2020.3039542
   Sheykhivand S, 2020, IEEE ACCESS, V8, P139332, DOI 10.1109/ACCESS.2020.3011882
   Singh K, 2021, IEEE T CIRCUITS-II, V68, P5, DOI 10.1109/TCSII.2020.3040970
   Small DM, 2003, NEURON, V39, P701, DOI 10.1016/S0896-6273(03)00467-7
   Sohaib Ahmad Tauseef, 2013, Foundations of Augmented Cognition. 7th International Conference, AC 2013. Held as Part of HCI International 2013. Proceedings, P492, DOI 10.1007/978-3-642-39454-6_53
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2015, INT CONF AFFECT, P491, DOI 10.1109/ACII.2015.7344615
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Sornmo L, 2005, BIOELECTRICAL SIGNAL, V8
   Stikic M, 2014, BRAIN-COMPUT INTERFA, V1, P99, DOI 10.1080/2326263X.2014.912883
   Stone DB, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00096
   Sweeney KT, 2012, IEEE T INF TECHNOL B, V16, P488, DOI 10.1109/TITB.2012.2188536
   Tamburro G, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00441
   Tang T, 2020, IEEE T BIOMED CIRC S, V14, P1253, DOI 10.1109/TBCAS.2020.3039353
   Tanner D, 2015, PSYCHOPHYSIOLOGY, V52, P997, DOI 10.1111/psyp.12437
   Tao L, 2020, IEEE INT SYM BROADB, DOI 10.1109/BMSB49480.2020.9379645
   Tao XM, 2019, IEEE J SEL AREA COMM, V37, P1549, DOI 10.1109/JSAC.2019.2916453
   Teo J, 2017, AIP CONF PROC, V1891, DOI 10.1063/1.5005474
   Thammasan N, 2016, IEEE IJCNN, P881, DOI 10.1109/IJCNN.2016.7727292
   Nguyen T, 2019, IEEE T MED IMAGING, V38, P2423, DOI 10.1109/TMI.2019.2900978
   Pham TD, 2012, LECT NOTES COMPUT SC, V7667, P394, DOI 10.1007/978-3-642-34500-5_47
   Tsai WL, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P183, DOI 10.1109/APCCAS.2018.8605656
   Ullah H, 2019, IEEE ACCESS, V7, P40144, DOI 10.1109/ACCESS.2019.2904400
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vanhatalo S, 2004, P NATL ACAD SCI USA, V101, P5053, DOI 10.1073/pnas.0305375101
   Vijayan AE, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P587, DOI 10.1109/CICT.2015.24
   Wallstrom GL, 2004, INT J PSYCHOPHYSIOL, V53, P105, DOI 10.1016/j.ijpsycho.2004.03.007
   Walter D, 2020, PROC IEEE COOL CHIPS, DOI 10.1109/coolchips49199.2020.9097639
   Wang KY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P142, DOI [10.1109/AICAS.2019.8771581, 10.1109/aicas.2019.8771581]
   Wang KY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P102, DOI [10.1109/AICAS.2019.8771616, 10.1109/aicas.2019.8771616]
   Wang KJ, 2019, IEEE ROMAN, DOI 10.1109/ro-man46459.2019.8956382
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734, DOI 10.1007/978-3-642-24955-6_87
   Wang XX, 2012, IEEE T VLSI SYST, V20, P1405, DOI 10.1109/TVLSI.2011.2158124
   Wang XH, 2018, IEEE INT C BIOINFORM, P1240, DOI 10.1109/BIBM.2018.8621147
   Wang Y., 2018, INT WORKSHOP FUTURE, P1, DOI [10.1145/2851141.2851145, 10.1109/IJCNN.2018.8489715, DOI 10.1109/IJCNN.2018.8489715]
   Wang YX, 2017, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2017.323
   Wang ZM, 2019, IEEE ACCESS, V7, P93711, DOI 10.1109/ACCESS.2019.2927768
   Wei CS, 2019, I IEEE EMBS C NEUR E, P328, DOI [10.1109/ner.2019.8716937, 10.1109/icsess47205.2019.9040810, 10.1109/NER.2019.8716937]
   Wei Y, 2020, IEEE T BIOMED CIRC S, V14, P145, DOI 10.1109/TBCAS.2020.2974154
   Widmann A, 2015, J NEUROSCI METH, V250, P34, DOI 10.1016/j.jneumeth.2014.08.002
   Wood KH, 2014, EMOTION, V14, P693, DOI 10.1037/a0036636
   Wu DP, 2021, IEEE J SEL AREA COMM, V39, P479, DOI 10.1109/JSAC.2020.3020677
   Wu H, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01275
   Xu HY, 2016, IEEE INT WORKSH MULT
   Xu HY, 2012, IEEE INT WORKSH MULT, P299, DOI 10.1109/MMSP.2012.6343458
   Yan Y., 2020, ARXIV200908921
   Yan YX, 2019, IEEE T BIOMED CIRC S, V13, P579, DOI 10.1109/TBCAS.2019.2906401
   Yanagimoto M, 2016, 2016 IEEE 9TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P27, DOI 10.1109/IWCIA.2016.7805744
   Yang HC, 2019, INT CONF ACOUST SPEE, P1184, DOI 10.1109/ICASSP.2019.8683290
   Yang YM, 2018, IEEE T COGN DEV SYST, V10, P408, DOI 10.1109/TCDS.2017.2685338
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Yao DZ, 2001, PHYSIOL MEAS, V22, P693, DOI 10.1088/0967-3334/22/4/305
   Yazdani A., 2009, PROC SIGMM WORKSHOP, P81
   Yeung N, 2004, PSYCHOPHYSIOLOGY, V41, P822, DOI 10.1111/j.1469-8986.2004.00239.x
   Yisi Liu, 2014, Transactions on Computational Science XXIII. Special Issue on Cyberworlds: LNCS 8490, P199, DOI 10.1007/978-3-662-43790-2_11
   Yoo J., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P292, DOI 10.1109/ISSCC.2012.6177019
   Yoon HJ, 2013, COMPUT BIOL MED, V43, P2230, DOI 10.1016/j.compbiomed.2013.10.017
   Yu C, 2015, IEEE T VLSI SYST, V23, P1793, DOI 10.1109/TVLSI.2014.2350017
   Yushu Zhao, 2019, 2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P1959, DOI 10.1109/IAEAC47372.2019.8997704
   Yuval-Greenberg S, 2008, NEURON, V58, P429, DOI 10.1016/j.neuron.2008.03.027
   Zaitchik D, 2006, NEUROPSYCHOLOGY, V20, P11, DOI 10.1037/0894-4105.20.1.11
   Zeng GX, 2019, NAT MACH INTELL, V1, P364, DOI 10.1038/s42256-019-0080-x
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhang K., 2020, SENSORS-BASEL, V6321, P1
   Zhang T, 2022, IEEE T AFFECT COMPUT, V13, P379, DOI 10.1109/TAFFC.2019.2937768
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhao GZ, 2018, IEEE T AFFECT COMPUT, V9, P362, DOI 10.1109/TAFFC.2017.2786207
   Zhao K., 2019, PROC IEEE INT S CIRC, P1
   Zhao W., 2018, 2018 MULTIDISCIP ANA, P1, DOI DOI 10.2514/6.2018-3424
   Zhao Y., 2020, P INT JOINT C NEUR N, P1
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 278
TC 10
Z9 10
U1 14
U2 42
PD JUN
PY 2021
VL 15
IS 3
BP 412
EP 442
DI 10.1109/TBCAS.2021.3089132
UT WOS:000684698900010
DA 2023-11-16
ER

PT C
AU Zhao, SR
   Shah, N
   Meert, W
   Verhelst, M
AF Zhao, Shirui
   Shah, Nimish
   Meert, Wannes
   Verhelst, Marian
BE Bolchini, C
   Verbauwhede, I
   Vatajelu, I
TI Discrete Samplers for Approximate Inference in Probabilistic Machine
   Learning
SO PROCEEDINGS OF THE 2022 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2022)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 25th Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 14-23, 2022
CL ELECTR NETWORK
DE Probabilistic models; approximate inference; discrete sampling; CDT
   algorithm; Knuth-Yao algorithm
AB Probabilistic reasoning models (PMs) and probabilistic inference bring advantages when dealing with small datasets or uncertainty on the observed data, and allow to integrate expert knowledge and create interpretable models. The main challenge of using these PMs in practice is that their inference is very compute-intensive. Therefore, custom hardware architectures for the exact and approximate inference of PMs have been proposed in the SotA. The throughput, energy and area efficiency of approximate PM inference accelerators are strongly dominated by the sampler blocks required to sample arbitrary discrete distributions.
   This paper proposes and studies novel discrete sampler architectures towards efficient and flexible hardware implementations for PM accelerators. Both cumulative distribution table (CDT) and Knuth-Yao (KY) based sampling algorithms are assessed, based on which different sampler hardware architectures were implemented. Innovation is brought in terms of a reconfigurable CDT sampling architecture with a flexible range and a reconfigurable Knuth-Yao sampling architecture that supports both flexible range and dynamic precision. All architectures are benchmarked on real-world Bayesian Networks, demonstrating up to 13x energy efficiency benefits and 11x area efficiency improvement of the optimized reconfigurable Knuth-Yao sampler over the traditional linear CDT-based samplers used in the PM SotA.
C1 [Zhao, Shirui; Shah, Nimish; Verhelst, Marian] Katholieke Univ Leuven, MICAS ESAT, Leuven, Belgium.
   [Meert, Wannes] Katholieke Univ Leuven, DTAI, Leuven, Belgium.
RP Zhao, SR (corresponding author), Katholieke Univ Leuven, MICAS ESAT, Leuven, Belgium.
EM shirui.zhao@kuleuven.be; nimish.shah@kuleuven.be;
   wannes.meert@kuleuven.be; marian.verhelst@kuleuven.be
CR [Anonymous], BAYESIAN NETWORK REP
   Banerjee U, 2019, ISSCC DIG TECH PAP I, V62, P46, DOI 10.1109/ISSCC.2019.8662528
   Guo H., 2002, JOINT WORKSH REAL TI
   Howe J, 2018, IEEE T COMPUT, V67, P322, DOI 10.1109/TC.2016.2642962
   Knuth DE, 1976, ALGORITHMS COMPLEXIT, P357
   Ko G. G., 2020, 2020 IEEE S VLSI CIR, P1
   Kong L, 2021, IEEE T COMPUT, V70, P1019, DOI 10.1109/TC.2020.3001170
   Laurel J, DESIGN AUTOMATION C, P2021
   Li DD, 2021, IEEE WCNC, DOI 10.1109/WCNC49053.2021.9417554
   Ni Y, IEEE ACCESS, V9, P2021
   Roy SS, 2014, LECT NOTES COMPUT SC, V8282, P383
   Saad FA, 2020, PR MACH LEARN RES, V108, P1036
   Song SM, 2018, IEEE CUST INTEGR CIR
   Wu Yujing, 2016, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1109/WCNC.2016.7565026
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1221
EP 1226
UT WOS:000819484300231
DA 2023-11-16
ER

PT J
AU Jamieson, M
   Brown, N
AF Jamieson, Maurice
   Brown, Nick
TI High level programming abstractions for leveraging hierarchical memories
   with micro-core architectures
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article; Proceedings Paper
CT Exascale Applications and Software Conference (EASC)
CY APR 17-19, 2018
CL Edinburgh, SCOTLAND
DE Parallel programming languages; Interpreters; Runtime environments;
   Hardware accelerators; Neural networks
AB Micro-core architectures combine many low memory, low power computing cores together in a single package. These are attractive for use as accelerators but due to limited on-chip memory and multiple levels of memory hierarchy, the way in which programmers offload kernels needs to be carefully considered. In this paper we use Python as a vehicle for exploring the semantics and abstractions of higher level programming languages to support the offloading of computational kernels to these devices. By moving to a pass by reference model, along with leveraging memory kinds, we demonstrate the ability to easily and efficiently take advantage of multiple levels in the memory hierarchy, even ones that are not directly accessible to the micro-cores. Using a machine learning benchmark, we perform experiments on both Epiphany-Ill and MicroBlaze based micro-cores, demonstrating the ability to compute with data sets of arbitrarily large size. To provide context of our results, we explore the performance and power efficiency of these technologies, demonstrating that whilst these two micro-core technologies are competitive within their own embedded class of hardware, there is still a way to go to reach HPC class GPUs. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Jamieson, Maurice; Brown, Nick] Univ Edinburgh, EPCC, Bayes Ctr, 47 Potterrow, Edinburgh, Midlothian, Scotland.
RP Jamieson, M (corresponding author), Univ Edinburgh, EPCC, Bayes Ctr, 47 Potterrow, Edinburgh, Midlothian, Scotland.
EM maurice.jamieson@ed.ac.uk
CR Agarwal N, 2016, INT S HIGH PERF COMP, P494, DOI 10.1109/HPCA.2016.7446089
   Al Kadi M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3173548
   [Anonymous], 2016, ARXIV160107133
   [Anonymous], 2013, EP ARCH REF
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2017, 1 WORKSH COMP ARCH R
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2013, OPENMP APPL PROGRAM
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2017, INTEGRATION, DOI DOI 10.1109/ACCESS.2017.2671881
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Brown N, 2016, PROCEEDINGS OF PYHPC2016: 6TH WORKSHOP ON PYTHON FOR HIGH-PERFORMANCE AND SCIENTIFIC COMPUTING, P59, DOI [10.1109/PyHPC.2016.012, 10.1109/PyHPC.2016.8]
   Cantalupo C., 2015, TECHNICAL REPORT
   Castro FM, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4786
   deDinechin B.D., 2015, 2015 IEEE HOT CHIPS, P1
   Dongarra JJ, 2003, CONCURR COMP-PRACT E, V15, P803, DOI 10.1002/cpe.728
   Lam SK, 2015, P 2 WORKSH LLVM COMP, P1, DOI DOI 10.1145/2833157.2833162
   Landaverde Raphael, 2014, IEEE Conf High Perform Extreme Comput, V2014, DOI 10.1109/HPEC.2014.7040988
   Lysecky R, 2005, DES AUT TEST EUROPE, P18, DOI 10.1109/DATE.2005.38
   Lysecky R, 2006, ACM T DES AUTOMAT EL, V11, P659, DOI 10.1145/1142980.1142986
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Sakharnykh Nikolay., 2017, MAXIMIZING UNIFIED M
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Wolf C., 2019, PICORV32 SIZE OPTIMI
NR 39
TC 0
Z9 0
U1 0
U2 6
PD APR
PY 2020
VL 138
BP 128
EP 138
DI 10.1016/j.jpdc.2019.11.011
UT WOS:000515195500010
DA 2023-11-16
ER

PT C
AU Abdelgawad, MAA
   Cheung, RCC
   Yan, H
AF Abdelgawad, M. A. A.
   Cheung, Ray C. C.
   Yan, Hong
GP IEEE
TI A High-Performance FPGA Accelerator for CUR Decomposition
SO 2022 32ND INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS, FPL
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 32nd International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2022
CL Belfast, NORTH IRELAND
DE CUR decomposition; low-rank decomposition; high level synthesis; SVD and
   QR decomposition
AB A matrix factorization is to decompose a matrix into a product of smaller matrices. It is widely used in machine learning algorithms. There are many matrix decomposition algorithms, and each has various applications. CUR matrix decomposition is a widely-used factorization tool that has been employed for dimension reduction and pattern recognition in many scientific and engineering applications, such as image processing, text mining, and wireless communications. In this paper we propose an efficient FPGA-based floating-point accelerator using high-level synthesis (HLS) for the CUR decomposition algorithm. Our experiment results demonstrate the better efficiency of our hardware design compared to the optimized CPU-based software solutions. The speedup of our FPGA-based architecture over the optimized software implementation ranges from 2.37 to 16.82 times for different dimensions of the data input matrix. We evaluated our design using large dimension matrices 1024x1024 and 2048 x 2048 and the experiment results demonstrated the efficiency of our design in terms of the utilized resources and latency. Finally, we have compared our design with other matrix decomposition algorithms such as SVD and QR decomposition, the experiment results demonstrated that CUR is more efficient than SVD and QR decomposition in terms of latency and required resources.
C1 [Abdelgawad, M. A. A.; Cheung, Ray C. C.; Yan, Hong] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
RP Abdelgawad, MAA (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM mabdelgaw2-c@my.cityu.edu.hk; r.cheung@cityu.edu.hk; h.yan@cityu.edu.hk
CR Bien J., 2010, ADV NEURAL INFORM PR, V23
   Drineas P., 2007, LINEAR ALGEBRA ITS A, V420, P553
   Drineas P, 2008, SIAM J MATRIX ANAL A, V30, P844, DOI 10.1137/07070471X
   Drineas P, 2006, SIAM J COMPUT, V36, P184, DOI 10.1137/S0097539704442702
   Gittens A., 2013, JMLR P, V28, P567
   Hamm K., 2020, STABILITY SAMPLING C
   Hoyer Patrik O, 2004, J MACHINE LEARNING R, V5, P9
   Jolliffe I. T., 2002, CHEMOMETR INTELL LAB, V2nd, DOI [10.1016/0169-7439(87)80084-9, DOI 10.1016/0169-7439(87)80084-9]
   Khichadia I., 2021, 2021 INT C COMM INF, P1
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205106, 10.1073/pnas.0803205105]
   OLoughlin D., 2014, XILINX VIVADO HIGH L
   Skalicky S, 2013, LECT NOTES COMPUT SC, V7806, P146, DOI 10.1007/978-3-642-36812-7_14
   Sorensen DC, 2016, SIAM J SCI COMPUT, V38, pA1454, DOI 10.1137/140978430
   Sun JM, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P366
   Thurau C., 2012, SDM, P684, DOI 10.1137/1.9781611972825.59
   Younes H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020205
   Zhao XW, 2018, IEEE ACCESS, V6, P3031, DOI 10.1109/ACCESS.2017.2786681
   Zhuo L, 2008, IEEE T COMPUT, V57, P1057, DOI 10.1109/TC.2008.55
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 294
EP 299
DI 10.1109/FPL57034.2022.00052
UT WOS:000975890500040
DA 2023-11-16
ER

PT C
AU Zhu, ZH
   Sun, HB
   Lin, YJ
   Dai, GH
   Xia, LX
   Han, S
   Wang, Y
   Yang, HZ
AF Zhu, Zhenhua
   Sun, Hanbo
   Lin, Yujun
   Dai, Guohao
   Xia, Lixue
   Han, Song
   Wang, Yu
   Yang, Huazhong
GP ACM
TI A Configurable Multi-Precision CNN Computing Framework Based on Single
   Bit RRAM
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
AB Convolutional Neural Networks (CNNs) play a vital role in machine learning. Emerging resistive random-access memories (RRAMs) and RRAM-based Processing-In-Memory architectures have demonstrated great potentials in boosting both the performance and energy efficiency of CNNs. However, restricted by the immature process technology, it is hard to implement and fabricate a CNN accelerator chip based on multi-bit RRAM devices. In addition, existing single bit RRAM based CNN accelerators only focus on binary or ternary CNNs which have more than 10% accuracy loss compared with full precision CNNs. This paper proposes a con. gurable multi-precision CNN computing framework based on single bit RRAM, which consists of an RRAM computing overhead aware network quantization algorithm and a con. gurable multi-precision CNN computing architecture based on single bit RRAM. The proposed method can achieve equivalent accuracy as full precision CNN but also with lower storage consumption and latency via multiple precision quantization. The designed architecture supports for accelerating the multi-precision CNNs even with various precision among different layers. Experiment results show that the proposed framework can reduce 70% computing area and 75% computing energy on average, with nearly no accuracy loss. And the equivalent energy efficiency is 1.6 similar to 8.6x compared with existing RRAM based architectures with only 1.07% area overhead.
C1 [Zhu, Zhenhua; Sun, Hanbo; Dai, Guohao; Wang, Yu; Yang, Huazhong] Tsinghua Univ, BNRist, Dept EE, Beijing, Peoples R China.
   [Lin, Yujun; Han, Song] MIT, Dept EECS, Cambridge, MA 02139 USA.
   [Xia, Lixue] Alibaba Grp, Hangzhou, Zhejiang, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, BNRist, Dept EE, Beijing, Peoples R China.
EM yu-wang@tsinghua.edu.cn
CR [Anonymous], ISCA 2016
   [Anonymous], 2014, CIFAR 10 OBJECT RECO
   [Anonymous], HPCA 2017
   [Anonymous], 2016, DOREFANET TRAINING L
   [Anonymous], ISCA 2016
   [Anonymous], DAC 2015
   [Anonymous], DAC 2016
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], CVPR 2016
   Chang MF, 2014, ISSCC DIG TECH PAP I, V57, P332, DOI 10.1109/ISSCC.2014.6757457
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Choo KD, 2016, ISSCC DIG TECH PAP I, V59, P460, DOI 10.1109/ISSCC.2016.7418106
   Kull L, 2017, ISSCC DIG TECH PAP I, P474, DOI 10.1109/ISSCC.2017.7870467
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin JL, 2018, DES AUT TEST EUROPE, P407, DOI 10.23919/DATE.2018.8342044
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Saberi M, 2011, IEEE T CIRCUITS-I, V58, P1736, DOI 10.1109/TCSI.2011.2107214
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Xia L., 2016, P 53 ACMEDACIEEE ANN, P1
   Zhu Z., 2018, ICCAD, P1
NR 24
TC 52
Z9 53
U1 2
U2 7
PY 2019
DI 10.1145/3316781.3317739
UT WOS:000482058200056
DA 2023-11-16
ER

PT C
AU Xu, SY
   Schafer, BC
AF Xu, Siyuan
   Schafer, Benjamin Carrion
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI On the Design of High Performance HW Accelerator through High-level
   Synthesis Scheduling Approximations
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
DE Approximate Computing; High-level Synthesis; Machine Learning;
   Behavioral Hardware Accelerators
AB High-level synthesis (HLS) takes as input a behavioral description (e.g. C/C++) and generates efficient hardware through three main steps: allocation, scheduling, and binding. The scheduling step, times the operations in the behavioral description by scheduling different portions of the code at unique clock steps (control steps). The code portions assigned to each clock step mainly depend on the target synthesis frequency and target technology. This work makes use of this to generate smaller and faster circuits by approximating the program portions scheduled in each clock step and by exploiting the slack between different scheduling step to further increase the performance/reduce the latency of the resultant circuit. In particular, each individual scheduling step is approximated given a maximum error boundary and a library of different approximation techniques. In order to further optimize the resultant circuit, different scheduling steps are merged based on the timing slack of different control step without violating the given timing constraint (target frequency). Experimental results from different domain-specific applications show that our method works well and is able to increase the throughput on average by 82% while at the same time reducing the area by 21% for a given maximum allowable error.
C1 [Xu, Siyuan; Schafer, Benjamin Carrion] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
RP Xu, SY (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
EM siyuan.xu@utdallas.edu; schaferb@utdallas.edu
CR [Anonymous], 2019, NEC CYBERWORKBENCH
   [Anonymous], APPL CONVERSION RES
   [Anonymous], 2014, PROC DESIGN AUTOM TE
   Baek W, 2010, ACM SIGPLAN NOTICES, V45, P198, DOI 10.1145/1809028.1806620
   Cadence, 2019, STRAT
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Dosselmann R., 2005, CAN C EL COMP ENG SA, P1906
   Grigorian B, 2014, PR IEEE COMP DESIGN, P317, DOI 10.1109/ICCD.2014.6974700
   Gupta P, 2011, NANOELECTRONIC CIRCUIT DESIGN, P409, DOI 10.1007/978-1-4419-7609-3_12
   Khudia DS, 2016, IEEE DES TEST, V33, P43, DOI 10.1109/MDAT.2015.2501306
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Li CF, 2015, DES AUT CON, DOI 10.1145/2744769.2744863
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Liu C., 2014, 2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1, DOI 10.1109/NSSMIC.2014.7431111
   Meng JY, 2009, INT PARALL DISTRIB P, P107
   Mentor Graphics, 2019, CATAP
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mohammadhassani A., 2018, 2018 8 INT C COMP KN
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Schafer BC, 2014, IEEE EMBED SYST LETT, V6, P53, DOI 10.1109/LES.2014.2320556
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Wu Y, 2017, ASIA S PACIF DES AUT, P163, DOI 10.1109/ASPDAC.2017.7858314
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
   Xu S., 2019, 38 IEEE ACM INT C CO
   Xu SY, 2017, IEEE T VLSI SYST, V25, P3077, DOI 10.1109/TVLSI.2017.2735299
   Yazdanbakhsh A., 2016, IEEE DESIGN TEST
NR 26
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 1378
EP 1383
UT WOS:000610549200254
DA 2023-11-16
ER

PT C
AU Kamath, AK
   Abi-Karam, S
   Bhat, A
   Hao, C
AF Kamath, Akshay Karkal
   Abi-Karam, Stefan
   Bhat, Ashwin
   Hao, Cong
BE IEEE
TI M5: Multi-modal Multi-task Model Mapping on Multi-FPGA with Accelerator
   Configuration Search
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE Multi-FPGA; DNN Model Mapping Framework
AB Recent machine learning (ML) models have advanced from single-modality single-task to multi-modality multi-task (MMMT). MMMT models typically have multiple backbones of different sizes along with complicated connections, exposing great challenges for hardware deployment. For scalable and energy-efficient implementations, multi-FPGA systems are emerging as the ideal design choices. However, finding the optimal solutions for mapping MMMT models onto multiple FPGAs is non-trivial. Existing mapping algorithms focus on either streamlined linear deep neural network architectures or only the critical path of simple heterogeneous models. Direct extensions of these algorithms for MMMT models lead to sub-optimal solutions. To address these shortcomings, we propose M5, a novel MMMT Model Mapping framework for Multi-FPGA platforms. In addition to handling multiple modalities present in the models, M5 can flexibly explore accelerator configurations and possible resource sharing opportunities to significantly improve the system performance. For various computation-heavy MMMT models, experiment results demonstrate that M5 can remarkably outperform existing mapping methods and lead to an average reduction of 35%, 62%, and 70% in the number of low-end, mid-end, and high-end FPGAs required to achieve the same throughput, respectively. Code is publicly available(1).
C1 [Kamath, Akshay Karkal; Abi-Karam, Stefan; Bhat, Ashwin; Hao, Cong] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Abi-Karam, Stefan] Georgia Tech Res Inst, Atlanta, GA USA.
RP Kamath, AK (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM akshay.k2@gatech.edu; stefanabikaram@gatech.edu; ashwinbhat@gatech.edu;
   callie.hao@gatech.edu
CR Biookaghazadeh S, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3432816
   Brightwell G., 1991, P 23 ANN ACM S THEOR, P175, DOI DOI 10.1145/103418.103441
   GRAHAM RL, 1969, SIAM J APPL MATH, V17, P416, DOI 10.1137/0117039
   Hao C, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458577
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu RH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1419, DOI 10.1109/ICCV48922.2021.00147
   Iqbal M, 2018, Arxiv, DOI arXiv:1806.11226
   Jiang WW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358192
   KAHN AB, 1962, COMMUN ACM, V5, P558, DOI 10.1145/368996.369025
   Mehler A, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P150, DOI 10.1145/3209542.3209572
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Ramezani R, 2021, J SUPERCOMPUT, V77, P597, DOI 10.1007/s11227-020-03281-3
   Ruder S, 2017, Arxiv, DOI arXiv:1706.05098
   Shan J., 2021, IEEE TCAD
   Shan J., 2020, IEEE TCAD
   Shen T, 2019, IEEE COMPUT SOC CONF, P1611, DOI 10.1109/CVPRW.2019.00203
   Sun YX, 2020, IEICE T INF SYST, VE103D, P2457, DOI 10.1587/transinf.2020PAP0003
   Thuseethan Selvarajah, 2020, 2020 WI IAT
   Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788
   Valada A, 2018, IEEE INT CONF ROBOT, P6939, DOI 10.1109/ICRA.2018.8462979
   VALIANT LG, 1979, SIAM J COMPUT, V8, P410, DOI 10.1137/0208032
   Yamauchi Yugo, 2020, 2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW), P277, DOI 10.1109/CANDARW51189.2020.00060
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhang WT, 2019, DES AUT TEST EUROPE, P1241, DOI [10.23919/DATE.2019.8715174, 10.23919/date.2019.8715174]
   Zhang X., 2022, DAC
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2023
UT WOS:001027444200056
DA 2023-11-16
ER

PT J
AU Ioannou, L
   Fahmy, SA
AF Ioannou, Lenos
   Fahmy, Suhaib A.
TI Streaming Overlay Architecture for Lightweight LSTM Computation on FPGA
   SoCs
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE LSTM; neural networks; overlay; machine learning
AB Long-Short Term Memory (LSTM) networks, and Recurrent Neural Networks (RNNs) in general, have demonstrated their suitability in many time series data applications, especially in Natural Language Processing (NLP). Computationally, LSTMs introduce dependencies on previous outputs in each layer that complicate their computation and the design of custom computing architectures, compared to traditional feed-forward networks. Most neural network acceleration work has focused on optimising the core matrix-vector operations on highly capable FPGAs in server environments. Research that considers the embedded domain has often been unsuitable for streaming inference, relying heavily on batch processing to achieve high throughput. Moreover, many existing accelerator architectures have not focused on fully exploiting the underlying FPGA architecture, resulting in designs that achieve lower operating frequencies than the theoretical maximum. This paper presents a flexible overlay architecture for LSTMs on FPGA SoCs that is built around a streaming dataflow arrangement, uses DSP block capabilities directly, and is tailored to keep parameters within the architecture while moving input data serially to mitigate external memory access overheads. The architecture is designed as an overlay that can be configured to implement alternative models or update model parameters at runtime. It achieves higher operating frequency and demonstrates higher performance than other lightweight LSTM accelerators, as demonstrated in an FPGA SoC implementation.
C1 [Ioannou, Lenos] Univ Warwick, Coventry, W Midlands, England.
   [Fahmy, Suhaib A.] King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn, Thuwal 23955, Saudi Arabia.
   [Ioannou, Lenos] Sch Engn, Lib Rd, Coventry CV4 7AL, W Midlands, England.
RP Ioannou, L (corresponding author), Univ Warwick, Coventry, W Midlands, England.; Ioannou, L (corresponding author), Sch Engn, Lib Rd, Coventry CV4 7AL, W Midlands, England.
EM l.ioannou@warwick.ac.uk; suhaib.fahmy@kaust.edu.sa
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   [Anonymous], 2020, ZYNQ 7000 SOC Z 7007
   [Anonymous], 2018, 7 SERIES DSP48E1 SLI
   [Anonymous], 2021, VIRTEX 7 T XT FPGAS
   [Anonymous], 2018, ZYNQ 7000 SOC Z 7030
   [Anonymous], HEY SIRI ON DEVICE D
   [Anonymous], 2021, ZYNQ ULTRASCALE MPSO
   Azari E, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3366634
   Azari E, 2019, IEEE INT CONF BIG DA, P4450, DOI 10.1109/BigData47090.2019.9006030
   Chanana Ashish, 2017, 2017 42nd International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2017.8067214
   Chang A. X. M., 2015, RECURRENT NEURAL NET, DOI DOI 10.48550/ARXIV.1511.05552
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Chollet F, 2018, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Ghasemzadeh SA, 2021, Arxiv, DOI arXiv:2101.02667
   Han S., 2015, ADV NEURAL INFORM PR, P1135
   Hubara I, 2016, ADV NEUR IN, V29
   Ioannou L, 2020, IEEE T VLSI SYST, V28, P1392, DOI 10.1109/TVLSI.2020.2987202
   Ioannou L, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P355, DOI 10.1109/ICFPT47387.2019.00066
   Ioannou L, 2019, I C FIELD PROG LOGIC, P232, DOI 10.1109/FPL.2019.00043
   Jain AK, 2016, DES AUT TEST EUROPE, P1628
   Jihyun Kim, 2016, 2016 International Conference on Platform Technology and Service (PlatCon). Proceedings, P1, DOI 10.1109/PlatCon.2016.7456805
   Langhammer M, 2018, I C FIELD PROG LOGIC, P43, DOI 10.1109/FPL.2018.00015
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   Maor G, 2019, PR IEEE COMP DESIGN, P38, DOI 10.1109/ICCD46524.2019.00014
   Milenkoski M, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1126, DOI 10.23919/MIPRO.2018.8400205
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Qing XY, 2018, ENERGY, V148, P461, DOI 10.1016/j.energy.2018.01.177
   Que ZQ, 2020, J SIGNAL PROCESS SYS, V92, P965, DOI 10.1007/s11265-020-01549-8
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Ronak B, 2016, IEEE T COMPUT AID D, V35, P573, DOI 10.1109/TCAD.2015.2474363
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Rybalkin V, 2017, DES AUT TEST EUROPE, P1390, DOI 10.23919/DATE.2017.7927210
   Samajdar A, 2019, I C FIELD PROG LOGIC, P342, DOI 10.1109/FPL.2019.00061
   Skillman Allan, 2020, 2020 IEEE Hot Chips 32 Symposium (HCS), DOI 10.1109/HCS49909.2020.9220415
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wu E., 2017, I C FIELD PROG LOGIC, P1
   Xie ZZ, 2011, ADV INTEL SOFT COMPU, V111, P125
   Xilinx, 2020, UG579 ULTRASCALE ARC
   Zhang XY, 2020, PR IEEE COMP DESIGN, P469, DOI 10.1109/ICCD50377.2020.00086
   Zhu C., 2017, INT C LEARN REPR ICL, P1
NR 43
TC 2
Z9 2
U1 3
U2 7
PD MAR
PY 2023
VL 16
IS 1
AR 8
DI 10.1145/3543069
UT WOS:000939239900008
DA 2023-11-16
ER

PT C
AU Chen, CY
   Chakrabarty, K
AF Chen, Ching-Yuan
   Chakrabarty, Krishnendu
GP IEEE
TI Pruning of Deep Neural Networks for Fault-Tolerant Memristor-based
   Accelerators
SO 2021 58TH ACM/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 58th ACM/IEEE Design Automation Conference (DAC)
CY DEC 05-09, 2021
CL San Francisco, CA
AB Hardware-level reliability is a major concern when deep neural network (DNN) models are mapped to neuromorphic accelerators such as memristor-based crossbars. Manufacturing defects and variations lead to hardware faults in the crossbar. Although memristor-based DNNs are inherently tolerant to these faults and many faults are benign for a given inferencing application, there is still a non-negligible number of critical faults (CFs) in the memristor crossbars that can lead to misclassification. It is therefore important to efficiently identify these CFs so that fault-tolerance solutions can focus on them. In this paper, we present an efficient technique based on machine learning to identify these CFs; CFs can be identified with over 98% accuracy and at a rate that is 20 times faster than a baseline using random fault injection. We next present a fault-tolerance technique that iteratively prunes a DNN by targeting weights that are mapped to CFs in the memristor crossbars. Our results for the CIFAR-10 data set and several benchmark DNNs show that the proposed pruning technique eliminates up to 95% of the CFs with less than 1% DNN inferencing accuracy loss. This reduction in the total number of CFs leads to a 99% savings in the hardware redundancy required for fault tolerance.
C1 [Chen, Ching-Yuan; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
RP Chen, CY (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
CR Abramowitz M., 2013, HDB MATH FUNCTIONS F
   Chaudhuri A., 2018, ITC
   Chen CY, 2015, IEEE T COMPUT, V64, P180, DOI 10.1109/TC.2014.12
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Fackenthal R, 2014, ISSCC DIG TECH PAP I, V57, P338, DOI 10.1109/ISSCC.2014.6757460
   Fieback M., 2019, ITC
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hamdioui S., 2019, ITC
   Hastie T., 2009, ELEMENTS STAT LEARNI
   He ZH, 2020, PSYCHOL MED, V50, P2768, DOI 10.1017/S0033291719002915
   Kim SG, 2017, INT EL DEVICES MEET
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, CIFAR 10 CIFAR 100 D
   Li W., 2020, ASPDAC
   Lin JL, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P639, DOI 10.1145/3287624.3287715
   Liu CC, 2017, DES AUT CON, DOI 10.1145/3061639.3062310
   Madry Aleksander, 2018, DEEP LEARNING MODELS
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Mao MQ, 2018, IEEE T VLSI SYST, V26, P1290, DOI 10.1109/TVLSI.2018.2814544
   Rolewicz S., 1987, FUNCTIONAL ANAL CONT
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K., 2014, VERY DEEP CONVOLUTIO
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Xia LX, 2018, IEEE J EM SEL TOP C, V8, P102, DOI 10.1109/JETCAS.2017.2776980
   Xia LX, 2017, DES AUT CON, DOI 10.1145/3061639.3062248
   Xu Z, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000149
   Zhang S., 2020, IEEE INT C AI CIRC S
NR 28
TC 4
Z9 4
U1 0
U2 6
PY 2021
BP 889
EP 894
DI 10.1109/DAC18074.2021.9586269
UT WOS:000766079700149
DA 2023-11-16
ER

PT C
AU Tann, H
   Hashemi, S
   Bahar, RI
   Reda, S
AF Tann, Hokchhay
   Hashemi, Soheil
   Bahar, R. Iris
   Reda, Sherief
GP IEEE
TI Hardware-Software Codesign of Accurate, Multiplier-free Deep Neural
   Networks
SO PROCEEDINGS OF THE 2017 54TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 54th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 18-22, 2017
CL Austin, TX
AB While Deep Neural Networks (DNNs) push the state-of-the-art in many machine learning applications, they often require millions of expensive floating-point operations for each input classification. This computation overhead limits the applicability of DNNs to low-power, embedded platforms and incurs high cost in data centers. This motivates recent interests in designing low-power, low-latency DNNs based on fixed-point, ternary, or even binary data precision. While recent works in this area offer promising results, they often lead to large accuracy drops when compared to the floating-point networks. We propose a novel approach to map floating-point based DNNs to 8-bit dynamic fixed-point networks with integer power-of-two weights with no change in network architecture. Our dynamic fixed-point DNNs allow different radix points between layers. During inference, power-of-two weights allow multiplications to be replaced with arithmetic shifts, while the 8-bit fixed-point representation simplifies both the buffer and adder design. In addition, we propose a hardware accelerator design to achieve low-power, low-latency inference with insignificant degradation in accuracy. Using our custom accelerator design with the CIFAR-10 and ImageNet datasets, we show that our method achieves significant power and energy savings while increasing the classification accuracy.
C1 [Tann, Hokchhay; Hashemi, Soheil; Bahar, R. Iris; Reda, Sherief] Brown Univ, Sch Engn, Providence, RI 02912 USA.
RP Tann, H (corresponding author), Brown Univ, Sch Engn, Providence, RI 02912 USA.
EM hokchhay_tann@brown.edu; soheil_hashemi@brown.edu; iris_bahar@brown.edu;
   sherief_reda@brown.edu
CR [Anonymous], 2014, CORR
   Ba L. J., 2014, ADV NEURAL INFORM PR, V2, P2654
   Bengio, 2016, ABS160202830 CORR
   Bucilua C., 2006, P ACM SIGKDD
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Courbariaux Matthieu, 2014, ARXIV14127024
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Hinton Geoffrey, 2015, ARXIV150302531
   Hwang K., 2014 IEEE SIPS
   Jia Y., 2014, PROC 22 ACM INT C MU, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M., 2009, P IEEE ASAP IEEE COM
   Sarwar S. S., 2016, CORR
   Soudry D., 2014, NEURIPS, V27, P963, DOI DOI 10.5555/2968826.2968934
   TANG CZ, 1993, IEEE T SIGNAL PROCES, V41, P2724, DOI 10.1109/78.229903
   Tann H., 2016, CORR
   Zhang C., 2015, P ACM SIGDA FPGA
NR 21
TC 40
Z9 42
U1 1
U2 1
PY 2017
DI 10.1145/3061639.3062259
UT WOS:000424895400117
DA 2023-11-16
ER

PT J
AU Moraitis, T
   Toichkin, D
   Journé, A
   Chua, Y
   Guo, QH
AF Moraitis, Timoleon
   Toichkin, Dmitry
   Journe, Adrien
   Chua, Yansong
   Guo, Qinghai
TI SoftHebb: Bayesian inference in unsupervised Hebbian soft
   winner-take-all networks
SO NEUROMORPHIC COMPUTING AND ENGINEERING
DT Article
DE adversarial robustness; local plasticity; alternative to
   backpropagation; neuromorphic efficiency; Bayesian generative model;
   online unsupervised Hebbian learning; cortical learning theory
ID INFORMATION
AB Hebbian plasticity in winner-take-all (WTA) networks is highly attractive for neuromorphic on-chip learning, owing to its efficient, local, unsupervised, and on-line nature. Moreover, its biological plausibility may help overcome important limitations of artificial algorithms, such as their susceptibility to adversarial attacks, and their high demands for training-example quantity and repetition. However, Hebbian WTA learning has found little use in machine learning, likely because it has been missing an optimization theory compatible with deep learning (DL). Here we show rigorously that WTA networks constructed by standard DL elements, combined with a Hebbian-like plasticity that we derive, maintain a Bayesian generative model of the data. Importantly, without any supervision, our algorithm, SoftHebb, minimizes cross-entropy, i.e. a common loss function in supervised DL. We show this theoretically and in practice. The key is a 'soft' WTA where there is no absolute 'hard' winner neuron. Strikingly, in shallow-network comparisons with backpropagation, SoftHebb shows advantages beyond its Hebbian efficiency. Namely, it converges in fewer iterations, and is significantly more robust to noise and adversarial attacks. Notably, attacks that maximally confuse SoftHebb are also confusing to the human eye, potentially linking human perceptual robustness, with Hebbian WTA circuits of cortex. Finally, SoftHebb can generate synthetic objects as interpolations of real object classes. All in all, Hebbian efficiency, theoretical underpinning, cross-entropy-minimization, and surprising empirical advantages, suggest that SoftHebb may inspire highly neuromorphic and radically different, but practical and advantageous learning algorithms and hardware accelerators.
C1 [Moraitis, Timoleon; Journe, Adrien] Zurich Res Ctr, Huawei Technol, Zurich, Switzerland.
   [Chua, Yansong; Guo, Qinghai] Adv Comp & Storage Lab, Huawei Technol, Shenzhen, Peoples R China.
RP Moraitis, T (corresponding author), Zurich Res Ctr, Huawei Technol, Zurich, Switzerland.; Guo, QH (corresponding author), Adv Comp & Storage Lab, Huawei Technol, Shenzhen, Peoples R China.
EM timoleon.moraitis@huawei.com; guoqinghai@huawei.com
CR Amato G, 2019, LECT NOTES COMPUT SC, V11751, P324, DOI 10.1007/978-3-030-30642-7_29
   [Anonymous], 2009, ADV NEURAL INFORM PR
   Bardes A, 2022, Arxiv, DOI arXiv:2105.04906
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bengio Y, 2016, Arxiv, DOI arXiv:1502.04156
   Berthelot D, 2018, Arxiv, DOI arXiv:1807.07543
   Binas J, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00068
   Binzegger T, 2004, J NEUROSCI, V24, P8441, DOI 10.1523/JNEUROSCI.1400-04.2004
   Bittar A, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.865897
   Bojanowski P, 2019, Arxiv, DOI arXiv:1707.05776
   Cannon J, 2014, EUR J NEUROSCI, V39, P705, DOI 10.1111/ejn.12453
   Chen T, 2020, PR MACH LEARN RES, V119
   Cowen-Rivers AI, 2022, J ARTIF INTELL RES, V74, P1269
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   CRICK F, 1989, NATURE, V337, P129, DOI 10.1038/337129a0
   Czarnecki WM, 2017, PR MACH LEARN RES, V70
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Diehl PU, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00099
   Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152
   Ernoult M, 2020, Arxiv, DOI arXiv:2005.04168
   Foldiak P., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P401, DOI 10.1109/IJCNN.1989.118615
   FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346
   Frenkel C, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.629892
   Garcia Rodriguez H., 2022, INT C MACHINE LEARNI, P18704
   Goodfellow Ian J., 2014, GENERATIVE ADVERSARI, DOI 10.48550/arXiv.1406.2661
   Grinberg L, 2019, Arxiv, DOI arXiv:1908.08993
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1111/j.1551-6708.1987.tb00862.x
   Guerguiev J, 2017, ELIFE, V6, DOI 10.7554/eLife.22901
   Hahnloser R, 1999, NAT NEUROSCI, V2, P746, DOI 10.1038/11219
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hu T, 2014, CONF REC ASILOMAR C, P613, DOI 10.1109/ACSSC.2014.7094519
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Illing B, 2019, NEURAL NETWORKS, V118, P90, DOI 10.1016/j.neunet.2019.06.001
   Isomura T, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20082-0
   Jeffares A., 2022, INT C LEARNING REPRE
   Journe A, 2022, Arxiv, DOI arXiv:2209.11883
   Kingma DP., 2017, ARXIV
   Krotov D, 2019, P NATL ACAD SCI USA, V116, P7723, DOI 10.1073/pnas.1820458116
   Lagani G, 2021, NEURAL NETWORKS, V143, P719, DOI 10.1016/j.neunet.2021.08.003
   Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719
   Lillicrap TP, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13276
   LINSKER R, 1992, NEURAL COMPUT, V4, P691, DOI 10.1162/neco.1992.4.5.691
   Maass W, 2000, NEURAL COMPUT, V12, P2519, DOI 10.1162/089976600300014827
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   MALSBURG CV, 1973, KYBERNETIK, V14, P85, DOI 10.1007/BF00288907
   Millidge B, 2020, Arxiv, DOI [arXiv:2006.04182, DOI 10.48550/ARXIV.2006.04182]
   Moraitis T, 2021, Arxiv, DOI arXiv:2009.06808
   Nessler B, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003037
   Nokland A, 2016, ADV NEUR IN, V29
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Payeur A, 2021, NAT NEUROSCI, V24, P1010, DOI 10.1038/s41593-021-00857-x
   Pehlevan C, 2015, ADV NEUR IN, V28
   Pehlevan C, 2017, CONF REC ASILOMAR C, P593, DOI 10.1109/ACSSC.2017.8335410
   Pehlevan C, 2014, CONF REC ASILOMAR C, P769, DOI 10.1109/ACSSC.2014.7094553
   Pfeiffer M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00774
   Pogodin R, 2022, Arxiv, DOI arXiv:2106.13031
   Pogodin R, 2020, Arxiv, DOI arXiv:2006.07123
   Poirazi P, 2020, NAT REV NEUROSCI, V21, P303, DOI 10.1038/s41583-020-0301-7
   Qin Y, 2020, Arxiv, DOI arXiv:2002.07405
   Radford A, 2016, Arxiv, DOI arXiv:1511.06434
   Rauber J, 2018, Arxiv, DOI [arXiv:1707.04131, DOI 10.48550/ARXIV.1707.04131]
   Rutishauser U, 2011, NEURAL COMPUT, V23, P735, DOI 10.1162/NECO_a_00091
   SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0
   Sarwat SG, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29870-9
   Scellier B, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00024
   Scherr F, 2023, Arxiv, DOI arXiv:2210.09224
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Diehl PU, 2016, Arxiv, DOI arXiv:1608.08267
   Xiao H, 2017, Arxiv, DOI arXiv:1708.07747
   Zador A, 2022, Arxiv, DOI [arXiv:2210.08340, DOI 10.48550/ARXIV.2210.08340]
NR 72
TC 3
Z9 3
U1 0
U2 0
PD DEC 1
PY 2022
VL 2
IS 4
AR 044017
DI 10.1088/2634-4386/aca710
UT WOS:001064071500001
DA 2023-11-16
ER

PT C
AU Chien, SWD
   Markidis, S
   Olshevsky, V
   Bulatov, Y
   Laure, E
   Vetter, JS
AF Chien, Steven W. D.
   Markidis, Stefano
   Olshevsky, Vyacheslav
   Bulatov, Yaroslav
   Laure, Erwin
   Vetter, Jeffrey S.
GP IEEE
TI TensorFlow Doing HPC An Evaluation of TensorFlow Performance in HPC
   Applications
SO 2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
DE TensorFlow; Emerging Programming Environments; Parallel Computing;
   Heterogeneous Supercomputers; HPC Applications
AB TensorFlow is a popular emerging open-source programming framework supporting the execution of distributed applications on heterogeneous hardware. While TensorFlow has been initially designed for developing Machine Learning (ML) applications, in fact TensorFlow aims at supporting the development of a much broader range of application kinds that are outside the ML domain and can possibly include HPC applications. However, very few experiments have been conducted to evaluate TensorFlow performance when running HPC workloads on supercomputers. This work addresses this lack by designing four traditional HPC benchmark applications: STREAM, matrix-matrix multiply, Conjugate Gradient (CG) solver and Fast Fourier Transform (FFT). We analyze their performance on two supercomputers with accelerators and evaluate the potential of TensorFlow for developing HPC applications. Our tests show that TensorFlow can fully take advantage of high performance networks and accelerators on supercomputers. Running our Tensor-Flow STREAM benchmark, we obtain over 50% of theoretical communication bandwidth on our testing platform. We find an approximately 2x, 1.7x and 1.8x performance improvement when increasing the number of GPUs from two to four in the matrix-matrix multiply, CG and FFT applications respectively. All our performance results demonstrate that TensorFlow has high potential of emerging also as HPC programming framework for heterogeneous supercomputers.
C1 [Chien, Steven W. D.; Markidis, Stefano; Olshevsky, Vyacheslav; Laure, Erwin] KTH Royal Inst Technol, Stockholm, Sweden.
   [Bulatov, Yaroslav] South Pk Commons, San Francisco, CA USA.
   [Vetter, Jeffrey S.] Oak Ridge Natl Lab, Oak Ridge, TN USA.
RP Chien, SWD (corresponding author), KTH Royal Inst Technol, Stockholm, Sweden.
CR Abadi M, 2017, MAPL'17: PROCEEDINGS OF THE 1ST ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P1, DOI 10.1145/3088525.3088527
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agullo E, 2017, LECT NOTES COMPUT SC, V10104, P69, DOI 10.1007/978-3-319-58943-5_6
   [Anonymous], 2018, ARXIV180508430
   [Anonymous], 2017, P AUT WORKSH 31 C NE
   [Anonymous], 2018, ARXIV180401138
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631
   Awan AA, 2017, ACM SIGPLAN NOTICES, V52, P193, DOI [10.1145/3155284.3018769, 10.1145/3018743.3018769]
   Bosilca G, 2013, COMPUT SCI ENG, V15, P36, DOI 10.1109/MCSE.2013.98
   Chien S. W. D., 2018, 2018 IEEE ACM 3 INT
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   Geron A., 2017, HANDS ON MACHINE LEA
   Jia C., 2017, INT J PARALLEL PROGR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kleppmann M., 2017, DESIGNING DATA INTEN
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Markidis S, 2015, INT J HIGH PERFORM C, V29, P311, DOI 10.1177/1094342015576846
   Mathuriya A., 2018, ARXIV180804728
   McCalpin J. D., 1995, IEEE COMPUTER SOC TE, V1995, P19
   Nowak F, 2013, LECT NOTES COMPUT SC, V7767, P171, DOI 10.1007/978-3-642-36424-2_15
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Vishnu A., 2016, ARXIV160302339
   Yi B., 2017, P SIGCOMM POST DEM, P28, DOI DOI 10.1145/3123878.3131975
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
NR 25
TC 1
Z9 1
U1 1
U2 7
PY 2019
BP 509
EP 518
DI 10.1109/IPDPSW.2019.00092
UT WOS:000543704600074
DA 2023-11-16
ER

PT C
AU Salamat, S
   Imani, M
   Khaleghi, B
   Rosing, T
AF Salamat, Sahand
   Imani, Mohsen
   Khaleghi, Behnam
   Rosing, Tajana
GP ACM
TI F5-HD: Fast Flexible FPGA-based Framework for Refreshing
   Hyperdimensional Computing
SO PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 24-26, 2019
CL Seaside, CA
DE Brain-inspired Hyperdimensional Computing; Machine Learning; FPGA-based
   Acceleration; Automated Template-based Hardware Generation
AB Hyperdimensional (HD) computing is a novel computational paradigm that emulates the brain functionality in performing cognitive tasks. The underlying computation of HD involves a substantial number of element-wise operations (e.g., addition and multiplications) on ultra-wise hypervectors, in the granularities of as small as a single bit, which can be effectively parallelized and pipelined. In addition, though different HD applications might vary in terms of number of input features and output classes (labels), they generally follow the same computation flow. Such characteristics of HD computing inimitably matches with the intrinsic capabilities of FPGAs, making these devices a unique solution for accelerating these applications.
   In this paper, we propose F5-HD, a fast and flexible FPGA-based framework for refreshing the performance of HD computing. F5-HD eliminates the arduous task of handcrafted designing of hardware accelerators by automatically generating an FPGA implementation of HD accelerator leveraging a template of optimized processing elements, according to the applications specification and user's constraint. Our evaluations using different classification benchmarks revealed that F5-HD provides 86.9x and 7.8x (11.9x and 1.7x) higher energy efficiency improvement and faster training (inference) as compared to an optimized implementation of HD on AMD R9 390 GPU, respectively.
C1 [Salamat, Sahand; Imani, Mohsen; Khaleghi, Behnam; Rosing, Tajana] Univ Calif San Diego, Comp Sci & Engn Dept, La Jolla, CA 92093 USA.
RP Salamat, S (corresponding author), Univ Calif San Diego, Comp Sci & Engn Dept, La Jolla, CA 92093 USA.
EM sasalama@ucsd.edu; moimani@ucsd.edu; bkhaleghi@ucsd.edu; tajana@ucsd.edu
CR [Anonymous], 2012, CISC VIS NETW IND GL
   [Anonymous], 2017, XILINX POWER ESTIMAT
   [Anonymous], 2019, ASP DAC
   [Anonymous], 2018, 2018 IEEE INT C REB
   [Anonymous], DAC
   [Anonymous], 2018, ICCAD
   [Anonymous], 2015, IEEE T NEUR NET LEAR
   [Anonymous], 2018, ARXIV180708583
   [Anonymous], 2018, IOT
   DeHon A, 2000, COMPUTER, V33, P41, DOI 10.1109/2.839320
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Falsafi B, 2017, IEEE MICRO, V37, P60, DOI 10.1109/MM.2017.19
   Griffin G., 2007, 120 CAL I TECHN
   Imani Mohsen, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P271, DOI 10.1109/BHI.2018.8333421
   Imani M., 2019, DATE IEEE ACM
   Imani M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P97
   Imani M, 2017, IEEE DES TEST, V34, P94, DOI 10.1109/MDAT.2017.2740839
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Joshi A., QUANTUM INTERACTION
   Kanerva P, 2014, ANN ALLERTON CONF, P304, DOI 10.1109/ALLERTON.2014.7028470
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Li HT, 2016, INT EL DEVICES MEET
   Montagna  F., 2018, P ACM 55 ANN DES AUT, P111
   Najafabadi F. R., 2016, DESIGN AUTOMATION TE, P1
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Räsänen OJ, 2016, IEEE T NEUR NET LEAR, V27, P1878, DOI 10.1109/TNNLS.2015.2462721
   Reiss A., 2012, P P 5 INT C PERVASIV, DOI [10.1145/2413097.2413148, DOI 10.1145/2413097.2413148]
   Salvatore A, 2018, WILEY BLACK HIST REL, P1
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wu TF, 2018, ISSCC DIG TECH PAP I, P492, DOI 10.1109/ISSCC.2018.8310399
NR 30
TC 51
Z9 51
U1 0
U2 3
PY 2019
BP 53
EP 62
DI 10.1145/3289602.3293913
UT WOS:000522383700007
DA 2023-11-16
ER

PT J
AU Awais, M
   Zahir, A
   Shah, SAA
   Reviriego, P
   Ullah, A
   Ullah, N
   Khan, A
   Ali, H
AF Awais, Muhammad
   Zahir, Ali
   Shah, Syed Ayaz Ali
   Reviriego, Pedro
   Ullah, Anees
   Ullah, Nasim
   Khan, Adam
   Ali, Hazrat
TI Toward Optimal Softcore Carry-aware Approximate Multipliers on Xilinx
   FPGAs
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Neural Network
ID RADIX-8 BOOTH MULTIPLIERS; LOW-POWER; DESIGN
AB Domain-specific accelerators for signal processing, image processing, and machine learning are increasingly being implemented on SRAM-based field-programmable gate arrays (FPGAs). Owing to the inherent error tolerance of such applications, approximate arithmetic operations, in particular, the design of approximate multipliers, have become an important research problem. Truncation of lower bits is a widely used approximation approach; however, analyzing and limiting the effects of carry-propagation due to this approximation has not been explored in detail yet. In this article, an optimized carry-aware approximate radix-4 Booth multiplier design is presented that leverages the built-in slice look-up tables (LUTs) and carry-chain resources in a novel configuration. The proposed multiplier simplifies the computation of the upper and lower bits and provides significant benefits in terms of FPGA resource usage (LUTs saving 38.5%-42.9%), Power Delay Product (PDP saving 49.4%-53%), performance metric (LUTs x critical path delay (CPD) x PDP saving 68.9%-73.1%) and errors (70% improvement in mean relative error distance) compared to the latest state-of-the-art designs. Therefore, the proposed designs are an attractive choice to implement multiplication on FPGA-based accelerators.
C1 [Awais, Muhammad; Zahir, Ali; Shah, Syed Ayaz Ali] COM SATS Univ Islamabad, Dept Elect & Comp Engn, Islamabad, Pakistan.
   [Reviriego, Pedro] Univ Politecn Madrid, Dept Telemat Syst Engn, Madrid, Spain.
   [Ullah, Anees; Khan, Adam] Univ Engn & Technol, Dept Elect Engn, Peshawar, Pakistan.
   [Ullah, Nasim] Taif Univ KSA, Dept Elect Engn, Coll Engn, Taif, Saudi Arabia.
   [Ali, Hazrat] Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar.
RP Awais, M (corresponding author), COM SATS Univ Islamabad, Dept Elect & Comp Engn, Islamabad, Pakistan.
EM awais9362@gmail.com; alizahir@cuiatd.edu.pk; ayaz@cuiatd.edu.pk;
   pedro.reviriego@upm.es; aneesullah@uetpeshawar.edu.pk;
   nasimullah@tu.edu.sa; adamkhan@uetpeshawar.edu.pk; haali2@hbku.edu.qa
CR Ahmadinejad M, 2019, AEU-INT J ELECTRON C, V110, DOI 10.1016/j.aeue.2019.152859
   Ansari MS, 2021, IEEE T COMPUT, V70, P614, DOI 10.1109/TC.2020.2992113
   Chen K, 2019, IEEE T COMPUT, V68, P784, DOI 10.1109/TC.2018.2885044
   Dadda L, 1965, ALTA FREQ, V34, P349
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P189, DOI 10.1109/TCSI.2018.2856245
   Jiang HL, 2016, IEEE T COMPUT, V65, P2638, DOI 10.1109/TC.2015.2493547
   Koren I., 2002, COMPUTER ARITHMETIC
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Lin CH, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P33, DOI 10.1109/ICCD.2013.6657022
   Liu C, 2014, DES AUT TEST EUROPE
   Liu WQ, 2020, P IEEE, V108, P394, DOI 10.1109/JPROC.2020.2975695
   Liu WQ, 2017, IEEE T COMPUT, V66, P1435, DOI 10.1109/TC.2017.2672976
   Lotric U, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101175
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Parhami B., 2010, COMPUTER ARITHMETIC
   Pilipovic R, 2021, IEEE T CIRCUITS-I, V68, P2535, DOI 10.1109/TCSI.2021.3069168
   Qiqieh I, 2017, DES AUT TEST EUROPE, P7, DOI 10.23919/DATE.2017.7926950
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Sabetzadeh F, 2019, IEEE T CIRCUITS-I, V66, P4200, DOI 10.1109/TCSI.2019.2918241
   Strollo AGM, 2020, IEEE T CIRCUITS-I, V67, P3021, DOI 10.1109/TCSI.2020.2988353
   Ullah S, 2022, IEEE T COMPUT AID D, V41, P211, DOI 10.1109/TCAD.2021.3056337
   Ullah S, 2021, IEEE T COMPUT, V70, P384, DOI 10.1109/TC.2020.2988404
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3195996
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Venkatachalam S, 2019, IEEE T COMPUT, V68, P1697, DOI 10.1109/TC.2019.2926275
   Walters EG, 2016, COMPUTERS, V5, DOI 10.3390/computers5040020
   Waris H, 2021, IEEE T CIRCUITS-II, V68, P1566, DOI 10.1109/TCSII.2021.3065333
   Waris H, 2020, IEEE T CIRCUITS-II, V67, P3367, DOI 10.1109/TCSII.2020.2975094
   Xilinx, 2018, 7 SER FPGAS CONF US
   Xilinx, 2019, VIVADO DESIGN SUITE
   Yang TX, 2017, PR IEEE COMP DESIGN, P89, DOI 10.1109/ICCD.2017.22
NR 32
TC 1
Z9 1
U1 0
U2 0
PD JUL
PY 2023
VL 22
IS 4
AR 76
DI 10.1145/3564243
UT WOS:001053965300017
DA 2023-11-16
ER

PT J
AU Sebastian, A
   Le Gallo, M
   Khaddam-Aljameh, R
   Eleftheriou, E
AF Sebastian, Abu
   Le Gallo, Manuel
   Khaddam-Aljameh, Riduan
   Eleftheriou, Evangelos
TI Memory devices and applications for in-memory computing
SO NATURE NANOTECHNOLOGY
DT Review
ID PHASE-CHANGE MATERIALS; DEEP NEURAL-NETWORKS; LOGIC; DESIGN; SPIN;
   ACCELERATOR; GENERATION; SWITCHES; SYNAPSE; SIGNAL
AB Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing.
   This Review provides an overview of memory devices and the key computational primitives for in-memory computing, and examines the possibilities of applying this computing approach to a wide range of applications.
C1 [Sebastian, Abu; Le Gallo, Manuel; Khaddam-Aljameh, Riduan; Eleftheriou, Evangelos] IBM Res Zurich, Ruschlikon, Switzerland.
RP Sebastian, A (corresponding author), IBM Res Zurich, Ruschlikon, Switzerland.
EM ase@zurich.ibm.com
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agarwal S, 2017, S VLSI TECH, pT174, DOI 10.23919/VLSIT.2017.7998164
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2014, IEEE HOT CHIP SYMP
   Aziz A, 2018, DES AUT TEST EUROPE, P1289, DOI 10.23919/DATE.2018.8342213
   Balatti S, 2016, IEEE T ELECTRON DEV, V63, P2029, DOI 10.1109/TED.2016.2537792
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Beck A, 2000, APPL PHYS LETT, V77, P139, DOI 10.1063/1.126902
   Bekas C., 2009, P 2 WORKSH HIGH PERF, P1
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Bichler O, 2012, IEEE T ELECTRON DEV, V59, P2206, DOI 10.1109/TED.2012.2197951
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Brivio S, 2017, NANOTECHNOLOGY, V28, DOI 10.1088/1361-6528/aa8013
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Burr GW, 2016, IEEE J EM SEL TOP C, V6, P146, DOI 10.1109/JETCAS.2016.2547718
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai F., 2019, HARNESSING INTRINSIC
   Carboni R, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900198
   Carboni R, 2018, IEEE ELECTR DEVICE L, V39, P951, DOI 10.1109/LED.2018.2833543
   Chanthbouala A, 2012, NAT MATER, V11, P860, DOI [10.1038/NMAT3415, 10.1038/nmat3415]
   Chen WH, 2019, NAT ELECTRON, V2, P420, DOI 10.1038/s41928-019-0288-0
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng L, 2019, ADV FUNCT MAT
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi S, 2018, NAT MATER, V17, P335, DOI 10.1038/s41563-017-0001-5
   Choi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10492
   Chua L, 2011, APPL PHYS A-MATER, V102, P765, DOI 10.1007/s00339-011-6264-9
   Covi E, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00482
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Dazzi M, 2019, P NEURIPS MLSYS WORK
   Di Ventra M, 2013, NAT PHYS, V9, P200, DOI 10.1038/nphys2566
   Diehl P.U., 2015, 2015 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2015.7280696
   Diorio C, 1996, IEEE T ELECTRON DEV, V43, P1972, DOI 10.1109/16.543035
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Eleftheriou E, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947008
   Eryilmaz SB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00205
   Esser S. K., 2015, ADV NEURAL INFORM PR, P1117
   Farooq M., 2011, P INT EL DEV M, P7
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Fuller EJ, 2019, SCIENCE, V364, P570, DOI 10.1126/science.aaw5581
   Gaba S, 2013, NANOSCALE, V5, P5872, DOI 10.1039/c3nr01176c
   Gao LG, 2016, IEEE T ELECTRON DEV, V63, P3109, DOI 10.1109/TED.2016.2578720
   Giannopoulos I., 2018, 2018 IEEE INT EL DEV, P27
   Godse A. P., 2008, COMPUTER ORG ARCHITE
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Gupta S, 2018, ADV ASIAN HUM-ENV RE, P173, DOI 10.1007/978-3-319-72257-3_8
   Haj-Ali A, 2018, IEEE T CIRCUITS-I, V65, P4258, DOI 10.1109/TCSI.2018.2846699
   Hamdioui S, 2019, DES AUT TEST EUROPE, P486, DOI [10.23919/date.2019.8715020, 10.23919/DATE.2019.8715020]
   He K., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1007/978-3-319-46493-0_38
   HICKMOTT TW, 1962, J APPL PHYS, V33, P2669, DOI 10.1063/1.1702530
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu SG, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8522
   Hubara I, 2018, J MACH LEARN RES, V18
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jeong DS, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600090
   Jia Z, 2019, DISSECTING NVIDIA TU
   Jiang H, 2018, NAT ELECTRON, V1, P548, DOI 10.1038/s41928-018-0146-5
   Jiang WG, 2017, NAT COMMUN, V8, P1, DOI 10.1038/ncomms15066
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Jo SH, 2009, NANO LETT, V9, P496, DOI 10.1021/nl803669s
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karam R, 2015, P IEEE, V103, P1311, DOI 10.1109/JPROC.2015.2434888
   Kavehei O, 2013, NANOSCALE, V5, P5119, DOI 10.1039/c3nr00535f
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kent AD, 2015, NAT NANOTECHNOL, V10, P187, DOI 10.1038/nnano.2015.24
   Kheradpisheh SR, 2018, NEURAL NETWORKS, V99, P56, DOI 10.1016/j.neunet.2017.12.005
   Khvalkovskiy AV, 2013, J PHYS D APPL PHYS, V46, DOI 10.1088/0022-3727/46/7/074001
   Kim KM, 2019, PHYS STATUS SOLIDI-R, V13, DOI 10.1002/pssr.201800629
   Kim T, 2015, 2015 28TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P170, DOI 10.1109/SOCC.2015.7406934
   Kimura H, 2004, IEEE J SOLID-ST CIRC, V39, P919, DOI 10.1109/JSSC.2004.827802
   Koelmans WW, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9181
   Kumar S, 2017, NATURE, V548, P318, DOI 10.1038/nature23307
   Kuzum D, 2012, NANO LETT, V12, P2179, DOI 10.1021/nl201040y
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Le Gallo M, 2017, INT EL DEVICES MEET
   Le Gallo M, 2018, IEEE T ELECTRON DEV, V65, P4304, DOI 10.1109/TED.2018.2865352
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Le Gallo M, 2016, PROC EUR S-STATE DEV, P373, DOI 10.1109/ESSDERC.2016.7599664
   Le Gallo M, 2016, J APPL PHYS, V119, DOI 10.1063/1.4938532
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Lee JM, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00191
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li KS, 2014, S VLSI TECH
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Linn E, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/30/305205
   Liu BY, 2015, DES AUT CON, DOI 10.1145/2744769.2744930
   Liu SJ, 2018, IEEE CIRC SYST MAG, V18, P29, DOI 10.1109/MCAS.2017.2785421
   Maan AK, 2017, IEEE T NEUR NET LEAR, V28, P1734, DOI 10.1109/TNNLS.2016.2547842
   Mahmoudi H, 2013, SOLID STATE ELECTRON, V84, P191, DOI 10.1016/j.sse.2013.02.017
   Mancini C, 2016, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ANIMAL-COMPUTER INTERACTION, ACI 2016, DOI 10.1145/2995257.2995395
   Merrikh-Bayat F, 2018, IEEE T NEUR NET LEAR, V29, P4782, DOI 10.1109/TNNLS.2017.2778940
   Mizrahi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03963-w
   Moraitis T, 2018, IEEE NANOTECHNOL MAG, V12, P45, DOI 10.1109/MNANO.2018.2845479
   Mostafa H, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9941
   MURRAY AF, 1994, IEEE T NEURAL NETWOR, V5, P792, DOI 10.1109/72.317730
   Mutlu O, 2019, MICROPROCESS MICROSY, V67, P28, DOI 10.1016/j.micpro.2019.01.009
   Nandakumar SR, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351656
   Hao N, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P224, DOI 10.1109/CISP.2015.7407880
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Nicholas JH., 2002, ACCURACY STABILITY N
   Nili H, 2018, NAT ELECTRON, V1, P197, DOI 10.1038/s41928-018-0039-7
   OVSHINSKY SR, 1968, PHYS REV LETT, V21, P1450, DOI 10.1103/PhysRevLett.21.1450
   Pantazi A, 2016, NANOTECHNOLOGY, V27, DOI 10.1088/0957-4484/27/35/355205
   Parihar A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00825-1
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Pawlowski J. T., 2011, P IEEE HOT CHIPS 23, DOI DOI 10.1109/HOTCHIPS.2011.7477494
   Pfeiffer M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00774
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Qiao N, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00141
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Ríos C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau5759
   Ríos C, 2015, NAT PHOTONICS, V9, P725, DOI [10.1038/NPHOTON.2015.182, 10.1038/nphoton.2015.182]
   Salinga M, 2018, NAT MATER, V17, P681, DOI 10.1038/s41563-018-0110-9
   Sebastian A., 2019, 2019 Symposium on VLSI Technology, pT168, DOI 10.23919/VLSIT.2019.8776518
   Sebastian A, 2018, J APPL PHYS, V124, DOI 10.1063/1.5042413
   Sebastian A, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01481-9
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Serb A, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12611
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharmin S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11732-w
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/nnano.2017.83, 10.1038/NNANO.2017.83]
   Sheridan PM, 2016, IEEE T NEUR NET LEAR, V27, P2327, DOI 10.1109/TNNLS.2015.2482220
   Shulaker MM, 2017, NATURE, V547, P74, DOI 10.1038/nature22994
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   STURGES RH, 1988, IEEE T ROBOTIC AUTOM, V4, P157, DOI 10.1109/56.2079
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Suri M, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talati N, 2016, IEEE T NANOTECHNOL, V15, P635, DOI 10.1109/TNANO.2016.2570248
   Tang J., 2018, 2018 IEEE INT EL DEV, DOI [10.1109/IEDM.2018.8614551, DOI 10.1109/IEDM.2018.8614551]
   Torrejon J, 2017, NATURE, V547, P428, DOI 10.1038/nature23011
   Tuma T, 2016, IEEE ELECTR DEVICE L, V37, P1238, DOI 10.1109/LED.2016.2591181
   Tuma T, 2016, NAT NANOTECHNOL, V11, P693, DOI [10.1038/NNANO.2016.70, 10.1038/nnano.2016.70]
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/NMAT4856, 10.1038/nmat4856]
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Vourkas I, 2016, IEEE CIRC SYST MAG, V16, P15, DOI 10.1109/MCAS.2016.2583673
   Wang PN, 2019, IEEE T VLSI SYST, V27, P988, DOI 10.1109/TVLSI.2018.2882194
   Wang ZR, 2020, NAT REV MATER, V5, P173, DOI 10.1038/s41578-019-0159-3
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Woniak S., 2018, DEEP NETWORKS INCORP
   Wright CD, 2013, ADV FUNCT MATER, V23, P2248, DOI 10.1002/adfm.201202383
   Wu TF, 2018, IEEE J SOLID-ST CIRC, V53, P3183, DOI 10.1109/JSSC.2018.2870560
   Wuttig M, 2017, NAT PHOTONICS, V11, P465, DOI [10.1038/nphoton.2017.126, 10.1038/NPHOTON.2017.126]
   Xiong F, 2011, SCIENCE, V332, P568, DOI 10.1126/science.1201938
   Xu N, 2019, PHYS STATUS SOLIDI-R, V13, DOI 10.1002/pssr.201900033
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang KY, 2014, ISSCC DIG TECH PAP I, V57, P280, DOI 10.1109/ISSCC.2014.6757434
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yoon KJ, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600326
   Yoon SM, 2014, INT C CONTR AUTOMAT, P127, DOI 10.1109/ICCAS.2014.6987971
   Yu J, 2017, ASIAPAC SIGN INFO PR, P171
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhirnov V. V., 2015, EMERGING NANOELECTRO
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 180
TC 749
Z9 759
U1 103
U2 669
PD JUL
PY 2020
VL 15
IS 7
BP 529
EP 544
DI 10.1038/s41565-020-0655-z
EA MAR 2020
UT WOS:000522382800001
HC Y
HP N
DA 2023-11-16
ER

PT J
AU Ahammed, A
   Ezekiel, AM
   Obermaisser, R
AF Ahammed, Abu Shad
   Ezekiel, Aniebiet Micheal
   Obermaisser, Roman
TI Time-Efficient Identification Procedure for Neurological Complications
   of Rescue Patients in an Emergency Scenario Using Hardware-Accelerated
   Artificial Intelligence Models
SO ALGORITHMS
DT Article
DE neurology; machine learning; TVM; VTA; artificial intelligence; support
   vector machine; random forest; logistic regression; naive bayes;
   artificial neural network; K-nearest neighbour; prediction; rescue
   patient
ID DISEASES; BRAIN
AB During an emergency rescue operation, rescuers have to deal with many different health complications like cardiovascular, respiratory, neurological, psychiatric, etc. The identification process of the common health complications in rescue events is not very difficult or time-consuming because the health vital symptoms or primary observations are enough to identify, but it is quite difficult with some complications related to neurology e.g., schizophrenia, epilepsy with non-motor seizures, or retrograde amnesia because they cannot be identified with the trend of health vital data. The symptoms have a wide spectrum and are often non-distinguishable from other types of complications. Further, waiting for results from medical tests like MRI and ECG is time-consuming and not suitable for emergency cases where a quick treatment path is an obvious necessity after the diagnosis. In this paper, we present a novel solution for overcoming these challenges by employing artificial intelligence (AI) models in the diagnostic procedure of neurological complications in rescue situations. The novelty lies in the procedure of generating input features from raw rescue data used in AI models, as the data are not like traditional clinical data collected from hospital repositories. Rather, the data were gathered directly from more than 200,000 rescue cases and required natural language processing techniques to extract meaningful information. A step-by-step analysis of developing multiple AI models that can facilitate the fast identification of neurological complications, in general, is presented in this paper. Advanced data analytics are used to analyze the complete record of 273,183 rescue events in a duration of almost 10 years, including rescuers' analysis of the complications and their diagnostic methods. To develop the detection model, seven different machine learning algorithms-Support Vector Machine (SVM), Random Forest (RF), K-nearest neighbor (KNN), Extreme Gradient Boosting (XGB), Logistic Regression (LR), Naive Bayes (NB) and Artificial Neural Network (ANN) were used. Observing the model's performance, we conclude that the neural network and extreme gradient boosting show the best performance in terms of selected evaluation criteria. To utilize this result in practical scenarios, the paper also depicts the possibility of embedding such machine learning models in hardware like FPGA. The goal is to achieve fast detection results, which is a primary requirement in any rescue mission. An inference time analysis of the selected ML models and VTA AI accelerator of Apache-TVM machine learning compiler used for the FPGA is also presented in this research.
C1 [Ahammed, Abu Shad; Ezekiel, Aniebiet Micheal; Obermaisser, Roman] Univ Siegen, Chair Embedded Syst, Dept Elect Engn & Comp Sci, D-57076 Siegen, Germany.
RP Ahammed, A; Obermaisser, R (corresponding author), Univ Siegen, Chair Embedded Syst, Dept Elect Engn & Comp Sci, D-57076 Siegen, Germany.
EM abu.ahammed@uni-siegen.de; micheal.ezekiel@uni-siegen.de;
   roman.obermaisser@uni-siegen.de
CR Ahammed A.S., 2022, P IECON 2022 48 ANN
   Anderson M.R., 2013, P CIDR
   Berrar D., 2019, ENCY BIOINFORMATICS, V1, P542, DOI DOI 10.1016/B978-0-12-809633-8.20349-X
   Chen TQ, 2018, Arxiv, DOI arXiv:1802.04799
   Chin JH, 2014, NEUROLOGY, V83, P349, DOI 10.1212/WNL.0000000000000610
   Chowdhary K. R., 2020, FUNDAMENTALS ARTIFIC, P603, DOI DOI 10.1007/978-81-322-3972-7_19
   Farkiya A., 2015, INT J COMPUT SCI INF, V6, P5465
   Fiala G, 2022, 2022 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS 2022), DOI 10.1109/SAS54819.2022.9881378
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gautam R, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1519-7
   Goeders J, 2018, ANN IEEE SYM FIELD P, P149, DOI 10.1109/FCCM.2018.00032
   Goldsmith J, 2020, IEEE ACCESS, V8, P129012, DOI 10.1109/ACCESS.2020.3008954
   Grattarola D, 2021, IEEE COMPUT INTELL M, V16, P99, DOI 10.1109/MCI.2020.3039072
   Guo S, 2004, GENES BRAIN BEHAV, V3, P63, DOI 10.1046/j.1601-183X.2003.00053.x
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Jain A., 2020, P 26 ACM SIGKDD INT
   James SL, 2019, LANCET NEUROL, V18, P56, DOI [10.1016/S1474-4422(19)30034-1, 10.1016/S1474-4422(18)30415-0, 10.1016/S1474-4422(18)30499-X]
   Jeyaraj M.N., 2022, ARXIV
   Jung M.G., 2015, P 2015 8 INT C DAT T
   Katarya Rahul, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P302, DOI 10.1109/ICESC48915.2020.9155586
   Kennedy DP, 2012, TRENDS COGN SCI, V16, P559, DOI 10.1016/j.tics.2012.09.006
   Kumar A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290607.3312928, 10.1109/imarc45935.2019.9118731]
   Li MZ, 2021, IEEE T PARALL DISTR, V32, P708, DOI 10.1109/TPDS.2020.3030548
   Lutz C, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1633, DOI 10.1145/3318464.3389705
   Ma BS, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103761
   Manaswi NK, 2018, DEEP LEARNING APPL U, DOI [10.1007/978-1-4842-3516-4_2, DOI 10.1007/978-1-4842-3516-4_2]
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Nahiduzzaman M., 2020, P BRAIN INF 13 INT C
   Pradhan A., 2012, INT J EMERGING TECHN, V2, P82, DOI 10.1007/978-3-662-47926-1_26
   Ray Susmita, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P35, DOI 10.1109/COMITCon.2019.8862451
   Realdigital, 2023, HARDW PYNQ Z2
   Saric R, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102106
   Sharma M, 2017, IRBM, V38, P305, DOI 10.1016/j.irbm.2017.09.002
   Shoeibi A, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115780
   Silva J, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062184
   Singh P., 2021, MACHINE LEARNING INT, P89, DOI DOI 10.1016/B978-0-12-821229-5.00003-3
   Siuly S, 2016, DATA SCI ENG, V1, P54, DOI 10.1007/s41019-016-0011-3
   Subramanian M., 1999, IEEE DATA ENG B, V22, P27
   Tanasa D, 2004, IEEE INTELL SYST, V19, P59, DOI 10.1109/MIS.2004.1274912
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Valliani AA, 2019, NEUROL THER, V8, P351, DOI 10.1007/s40120-019-00153-8
   Venkatesh R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1398-y
NR 42
TC 0
Z9 0
U1 4
U2 4
PD MAY 18
PY 2023
VL 16
IS 5
AR 258
DI 10.3390/a16050258
UT WOS:000994786000001
DA 2023-11-16
ER

PT J
AU Zhang, KH
AF Zhang, Kaiheng
TI An Efficiency-Based Improvement of a Reconstruction Algorithm
   Reconstructs Signal from Its Scattering Transform
SO INTERNATIONAL JOURNAL OF WIRELESS INFORMATION NETWORKS
DT Article
DE Efficiency; Scattering transform; Gradient descent; Signal
   reconstruction
AB Scattering transform has many advantages and has been widely used in various fields since proposed. An algorithm using machine learning was proposed by some developers of Kymatio to reconstruct the signal based on the Scattering transform of the signal on the internet (Reconstruct a synthetic signal from its scattering transform (DB/OL) and Andreux et al. , 2019). In this paper, I improve this reconstruction algorithm to an efficiency-based algorithm. However, the coefficient in the original formula for the input signal is defined and followed by original gradient descent algorithm with the learning rate multiplied by an accelerator or braker for every iteration. Once the error is spotted out then the system is discarded. By introducing an efficiency parameter, the calculation time and the eliminated error are linked, so that coefficient can be determined to improve the efficiency and eliminated most errors in a short time. Also, the experimenter can adjust the importance parameter in the efficiency parameter to determine the importance of speed and accuracy, which provides the experimenter with more choices.
C1 [Zhang, Kaiheng] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
RP Zhang, KH (corresponding author), Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
EM 2018212828@bupt.edu.cn
CR Andén J, 2019, IEEE T SIGNAL PROCES, V67, P3704, DOI 10.1109/TSP.2019.2918992
   Andén J, 2014, IEEE T SIGNAL PROCES, V62, P4114, DOI 10.1109/TSP.2014.2326991
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Eickenberg M., 2019, KYMATIO SCATTERING T
   Gupta R, 2020, CMES-COMP MODEL ENG, V123, P1175, DOI 10.32604/cmes.2020.010092
   Lostanlen V, SCATTERING M MATLAB
   Mallat S, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0203
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Manogaran Gunasekaran, 2018, International Journal of Advanced Intelligence Paradigms, V10, P118
   Tateishi, 2020, MATH MACHINE LEARNIN, P15
   The Kymatio Developers, US GUID
   The Kymatio Developers, REC SYNTH SIGN ITS S
   The Mathwork Inc, WAV SCATT
   Waldspurger I, 2017, 2017 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P143, DOI 10.1109/SAMPTA.2017.8024473
NR 14
TC 0
Z9 0
U1 0
U2 3
PD MAR
PY 2023
VL 30
IS 1
BP 111
EP 118
DI 10.1007/s10776-021-00526-7
EA AUG 2021
UT WOS:000683672100001
DA 2023-11-16
ER

PT J
AU Lee, SH
   Zhu, XJ
   Lu, WD
AF Lee, Seung Hwan
   Zhu, Xiaojian
   Lu, Wei D.
TI Nanoscale resistive switching devices for memory and computing
   applications
SO NANO RESEARCH
DT Review
DE resistive switching; oxygen vacancy; metal cation; memory application;
   in-memory computing; bio-inspired application
ID MEMRISTIVE DEVICES; FILAMENT GROWTH; NEURAL-NETWORK; LOGIC OPERATIONS;
   CROSSBAR ARRAYS; DYNAMICS; CLASSIFICATION; EFFICIENT; STORAGE; SYSTEM
AB With the slowing down of the Moore's law and fundamental limitations due to the von-Neumann bottleneck, continued improvements in computing hardware performance become increasingly more challenging. Resistive switching (RS) devices are being extensively studied as promising candidates for next generation memory and computing applications due to their fast switching speed, excellent endurance and retention, and scaling and three-dimensional (3D) stacking capability. In particular, RS devices offer the potential to natively emulate the functions and structures of synapses and neurons, allowing them to efficiently implement neural networks (NNs) and other in-memory computing systems for data intensive applications such as machine learning tasks. In this review, we will examine the mechanisms of RS effects and discuss recent progresses in the application of RS devices for memory, deep learning accelerator, and more faithful brain-inspired computing tasks. Challenges and possible solutions at the device, algorithm, and system levels will also be discussed.
C1 [Lee, Seung Hwan; Zhu, Xiaojian; Lu, Wei D.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
RP Lu, WD (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
EM wluee@umich.edu
CR Adam GC, 2016, NANO RES, V9, P3914, DOI 10.1007/s12274-016-1260-1
   Agarwal S, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00484
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2017, P IEEE INT EL DEV M
   Appeltant L, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1476
   Baek IG, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Bai Y, 2014, SCI REP-UK, V4, DOI 10.1038/srep05780
   Balatti S, 2013, ADV MATER, V25, P1474, DOI 10.1002/adma.201204097
   Balatti S, 2015, IEEE T ELECTRON DEV, V62, P1831, DOI 10.1109/TED.2015.2422999
   Belmonte A, 2018, NANO RES, V11, P4017, DOI 10.1007/s12274-018-1983-2
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Burr GW, 2008, IBM J RES DEV, V52, P449, DOI 10.1147/rd.524.0449
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Chen B, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choi BJ, 2016, ADV FUNCT MATER, V26, P5290, DOI 10.1002/adfm.201600680
   Choi BJ, 2016, ADV MATER, V28, P356, DOI 10.1002/adma.201503604
   Choi S, 2018, NAT MATER, V17, P335, DOI 10.1038/s41563-017-0001-5
   CHUA LO, 1976, P IEEE, V64, P209, DOI 10.1109/PROC.1976.10092
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Di Ventra M, 2013, NAT PHYS, V9, P200, DOI 10.1038/nphys2566
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Fackenthal R, 2014, ISSCC DIG TECH PAP I, V57, P338, DOI 10.1109/ISSCC.2014.6757460
   Fang HH, 2010, APPL PHYS LETT, V97, DOI 10.1063/1.3486683
   Feng S, 2019, MATER DESIGN, V162, P300, DOI 10.1016/j.matdes.2018.11.060
   Frank DJ, 2001, P IEEE, V89, P259, DOI 10.1109/5.915374
   Gaba S, 2014, IEEE ELECTR DEVICE L, V35, P1239, DOI 10.1109/LED.2014.2363618
   Gao LG, 2015, IEEE ELECTR DEVICE L, V36, P1157, DOI 10.1109/LED.2015.2481819
   Gao LG, 2013, IEEE T NANOTECHNOL, V12, P115, DOI 10.1109/TNANO.2013.2241075
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gomez R, 2012, ACMIEEE INT CONF HUM, P439
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Govoreanu B, 2014, IEEE ELECTR DEVICE L, V35, P63, DOI 10.1109/LED.2013.2291911
   Handy J, 2015, P 2015 STOR DEV C SA
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hsieh MC, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Hsu CW, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Huang JJ, 2011, IEEE ELECTR DEVICE L, V32, P1427, DOI 10.1109/LED.2011.2161601
   Huang P, 2016, ADV MATER, V28, P9758, DOI 10.1002/adma.201602418
   Hubara I, 2018, J MACH LEARN RES, V18
   Hyung Dong Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P151, DOI 10.1109/VLSIT.2012.6242506
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Ielmini D, 2011, IEEE T ELECTRON DEV, V58, P3246, DOI 10.1109/TED.2011.2161088
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277
   Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016
   James AP, 2014, IEEE T VLSI SYST, V22, P190, DOI 10.1109/TVLSI.2012.2232946
   Jeong DS, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600090
   Jo S.H., 2015, P IEEE INT EL DEV M
   Jo SH, 2015, IEEE T ELECTRON DEV, V62, P3477, DOI 10.1109/TED.2015.2426717
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jo SH, 2009, NANO LETT, V9, P870, DOI 10.1021/nl8037689
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kau D., 2009, IEEE INT ELECT DEVIC, P1
   Kawahara A, 2013, IEEE J SOLID-ST CIRC, V48, P178, DOI 10.1109/JSSC.2012.2215121
   Khan HN, 2018, NAT ELECTRON, V1, P14, DOI 10.1038/s41928-017-0005-9
   Kim GH, 2013, ADV FUNCT MATER, V23, P1440, DOI 10.1002/adfm.201202170
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kim S, 2015, NANO LETT, V15, P2203, DOI 10.1021/acs.nanolett.5b00697
   Kim S, 2014, ACS NANO, V8, P2369, DOI 10.1021/nn405827t
   Kim S, 2013, SCI REP-UK, V3, DOI 10.1038/srep01680
   Kim WG, 2014, S VLSI TECH
   KRESSE G, 1993, PHYS REV B, V47, P558, DOI 10.1103/PhysRevB.47.558
   Lam Chung H, 2010, 10 IEEE INT C SOLID, P1080
   Larentis S, 2012, IEEE T ELECTRON DEV, V59, P2468, DOI 10.1109/TED.2012.2202320
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Lee J, 2019, ACS APPL MATER INTER, V11, P11579, DOI 10.1021/acsami.8b18386
   Lee J, 2018, ADV MATER, V30, DOI 10.1002/adma.201702770
   Lee J, 2016, ACS NANO, V10, P3571, DOI 10.1021/acsnano.5b07943
   Lee MJ, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3629
   Lee MJ, 2011, NAT MATER, V10, P625, DOI [10.1038/NMAT3070, 10.1038/nmat3070]
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Linn E, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/30/305205
   Liu Q, 2010, ACS NANO, V4, P6162, DOI 10.1021/nn1017582
   Liu TY, 2013, ISSCC DIG TECH PAP I, V56, P210, DOI 10.1109/ISSCC.2013.6487703
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213
   Markram H, 2012, SCI AM, V306, P50, DOI 10.1038/scientificamerican0612-50
   Menzel S, 2015, NANOSCALE, V7, P12673, DOI 10.1039/c5nr02258d
   Menzel S, 2012, J APPL PHYS, V111, DOI 10.1063/1.3673239
   Moon J, 2019, NAT ELECTRON, V2, P480, DOI 10.1038/s41928-019-0313-3
   Moore G. E., 1975, IEDM, P11, DOI DOI 10.1109/N-SSC.2006.4804410
   MOORE GE, 1965, ELECTRONICS, V38, DOI DOI 10.1109/N-SSC.2006.4785860
   Nardi F, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Ohno T, 2011, NAT MATER, V10, P591, DOI [10.1038/NMAT3054, 10.1038/nmat3054]
   OVSHINSKY SR, 1968, PHYS REV LETT, V21, P1450, DOI 10.1103/PhysRevLett.21.1450
   Park GS, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3382
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Pickett MD, 2013, NAT MATER, V12, P114, DOI [10.1038/nmat3510, 10.1038/NMAT3510]
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Qin SJ, 2015, PHYS CHEM CHEM PHYS, V17, P8627, DOI 10.1039/c4cp04903a
   Russo U, 2009, IEEE T ELECTRON DEV, V56, P1040, DOI 10.1109/TED.2009.2016019
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/nnano.2017.83, 10.1038/NNANO.2017.83]
   Shin J, 2011, J APPL PHYS, V109, DOI 10.1063/1.3544205
   Sills S, 2014, S VLSI TECH
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Snider GS, 2007, NANOTECHNOLOGY, V18, DOI 10.1088/0957-4484/18/3/035204
   Son M, 2011, IEEE ELECTR DEVICE L, V32, P1579, DOI 10.1109/LED.2011.2163697
   Stoliar P, 2017, ADV FUNCT MATER, V27, DOI 10.1002/adfm.201604740
   Strukov DB, 2005, NANOTECHNOLOGY, V16, P888, DOI 10.1088/0957-4484/16/6/045
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Sutter H, 2005, DR DOBBS J, V30, P16
   Taur Y, 1997, P IEEE, V85, P486, DOI 10.1109/5.573737
   Tian XZ, 2014, NANO RES, V7, P1065, DOI 10.1007/s12274-014-0469-0
   Torrejon J, 2017, NATURE, V547, P428, DOI 10.1038/nature23011
   Valov I, 2016, NANOSCALE, V8, P13828, DOI 10.1039/c6nr01383j
   Valov I, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/25/254003
   Verstraeten D, 2006, IEEE IJCNN, P1050
   Wang W, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat4752
   Wang ZQ, 2012, ADV FUNCT MATER, V22, P2759, DOI 10.1002/adfm.201103148
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Waser R, 2009, ADV MATER, V21, P2632, DOI 10.1002/adma.200900375
   Woo J. O., 2014, SCI WORLD J, V2014, P7
   Wootae Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P37, DOI 10.1109/VLSIT.2012.6242449
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xia QF, 2009, NANO LETT, V9, P3640, DOI 10.1021/nl901874j
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Yang JJ, 2008, NAT NANOTECHNOL, V3, P429, DOI 10.1038/nnano.2008.160
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang YC, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5232
   Yang YC, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1737
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Zahurak J, 2014, INT EL DEVICES MEET
   Zhu XJ, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900184
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, IEEE T MULTI-SCALE C, V4, P698, DOI 10.1109/TMSCS.2017.2721160
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
   Zidan MA, 2017, IEEE T NANOTECHNOL, V16, P721, DOI 10.1109/TNANO.2017.2710158
NR 138
TC 76
Z9 78
U1 6
U2 44
PD MAY
PY 2020
VL 13
IS 5
BP 1228
EP 1243
DI 10.1007/s12274-020-2616-0
EA JAN 2020
UT WOS:000507801500006
DA 2023-11-16
ER

PT J
AU Zhang, P
   Fang, JB
   Yang, CQ
   Huang, C
   Tang, T
   Wang, Z
AF Zhang, Peng
   Fang, Jianbin
   Yang, Canqun
   Huang, Chun
   Tang, Tao
   Wang, Zheng
TI Optimizing Streaming Parallelism on Heterogeneous Many-Core
   Architectures
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Task analysis; Graphics processing units; Hardware; Parallel processing;
   Runtime; Machine learning; Predictive models; Heterogeneous computing;
   parallelism; performance tuning; machine learning
ID INTEL XEON PHI; PERFORMANCE; OPENCL; OPTIMIZATION; COMPILER; PROCESSORS;
   GENERATION; PROGRAMS
AB As many-core accelerators keep integrating more processing units, it becomes increasingly more difficult for a parallel application to make effective use of all available resources. An effective way of improving hardware utilization is to exploit spatial and temporal sharing of the heterogeneous processing units by multiplexing computation and communication tasks - a strategy known as heterogeneous streaming. Achieving effective heterogeneous streaming requires carefully partitioning hardware among tasks, and matching the granularity of task parallelism to the resource partition. However, finding the right resource partitioning and task granularity is extremely challenging, because there is a large number of possible solutions and the optimal solution varies across programs and datasets. This article presents an automatic approach to quickly derive a good solution for hardware resource partition and task granularity for task-based parallel applications on heterogeneous many-core architectures. Our approach employs a performance model to estimate the resulting performance of the target application under a given resource partition and task granularity configuration. The model is used as a utility to quickly search for a good configuration at runtime. Instead of hand-crafting an analytical model that requires expert insights into low-level hardware details, we employ machine learning techniques to automatically learn it. We achieve this by first learning a predictive model offline using training programs. The learned model can then be used to predict the performance of any unseen program at runtime. We apply our approach to 39 representative parallel applications and evaluate it on two representative heterogeneous many-core platforms: a CPU-XeonPhi platform and a CPU-GPU platform. Compared to the single-stream version, our approach achieves, on average, a 1.6x and 1.1x speedup on the XeonPhi and the GPU platform, respectively. These results translate to over 93 percent of the performance delivered by a theoretically perfect predictor.
C1 [Zhang, Peng; Fang, Jianbin; Yang, Canqun; Huang, Chun; Tang, Tao] Natl Univ Def Technol, Comp Sci, Changsha 410073, Hunan, Peoples R China.
   [Wang, Zheng] Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
RP Fang, JB (corresponding author), Natl Univ Def Technol, Comp Sci, Changsha 410073, Hunan, Peoples R China.
EM zhangpeng13a@nudt.edu.cn; j.fang@nudt.edu.cn; canqun@nudt.edu.cn;
   chunhuang@nudt.edu.cn; taotang84@nudt.edu.cn; z.wang5@leeds.ac.uk
CR [Anonymous], 2017, INT J PARALLEL PROG, DOI DOI 10.1007/S10766-016-0425-6
   [Anonymous], 2013, ACM SIGPLAN NOTICES
   [Anonymous], 2015, POPULATION PYRAMIDS
   [Anonymous], 2017, P S COMP ARITHM, DOI DOI 10.1109/ARITH.2017.19
   [Anonymous], 2008, CH CRC COMP SCI DATA
   [Anonymous], 2018, INT C SUP ICS 2018, DOI DOI 10.1145/3205289.3205321
   [Anonymous], 2014, P 2014 IEEE INT PAR, DOI DOI 10.1109/IPDPSW.2014.115
   [Anonymous], 2018, J PARALLEL DISTR COM, DOI DOI 10.1016/J.JPDC.2017.09.005
   [Anonymous], 2016, IEEE SYM PARA DISTR, DOI DOI 10.1109/IPDPSW.2016.217
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-47099-3_10
   [Anonymous], 2017, SC17 P INT C HIGH, DOI DOI 10.1145/3126908.3126931
   [Anonymous], 2018, CON P 14 INT C EM, DOI DOI 10.1145/3281411.3281422
   [Anonymous], 2017, ACM SIGPLAN NOTICES, DOI DOI 10.1145/3078633.3081040
   [Anonymous], 2014, LECT NOTES COMPUT SC
   [Anonymous], 2016, PARALLEL PROCESS LET, DOI DOI 10.1142/S0129626416400028
   [Anonymous], 2013, INT SYM CODE GENER
   [Anonymous], 2015, CUDA C BEST PRACT GU
   [Anonymous], 2011, ENV LOWC STRAT
   [Anonymous], 2016, IEEE T PARALL DISTR, DOI DOI 10.1109/TPDS.2015.2442983
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Boslaugh S., 2012, STAT NUTSHELL, V2nd
   Chen C, 2017, COMPUTING, V99, P791, DOI 10.1007/s00607-016-0537-2
   Cummins C, 2017, INT CONFER PARA, P219, DOI 10.1109/PACT.2017.24
   Dastgeer U., 2011, P 4 INT WORKSH MULT, P25
   Ertel W., 1994, P INT C PAR ARCH LAN, P289
   Ferrao P., 2018, P EUR C PAR PROC, P796
   Fursin G., 2008, GCC SUMMIT
   Gómez-Luna J, 2012, J PARALLEL DISTR COM, V72, P1117, DOI 10.1016/j.jpdc.2011.07.011
   Gorsuch R. L., 2014, FACTOR ANAL, V2nd
   Grewe D, 2013, INT SYM CODE GENER, P161
   Grosser T., 2016, P INT C SUP, P1
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Jha S, 2015, PROC VLDB ENDOW, V8, P642, DOI 10.14778/2735703.2735704
   Katagiri T, 2017, IEEE SYM PARA DISTR, P1399, DOI 10.1109/IPDPSW.2017.27
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kreyszig E., 2009, ADV ENG MATH, V10th
   Lastovetsky A, 2017, IEEE T PARALL DISTR, V28, P787, DOI 10.1109/TPDS.2016.2599527
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lee S., 2010, P ACM IEEE INT C HIG, P1
   Lee S, 2009, ACM SIGPLAN NOTICES, V44, P101, DOI 10.1145/1594835.1504194
   Li ZK, 2016, IEEE SYM PARA DISTR, P1341, DOI 10.1109/IPDPSW.2016.99
   Liao L., 2018, P 47 INT C PAR PROC
   Liu BZ, 2016, INT J HIGH PERFORM C, V30, P169, DOI 10.1177/1094342015585845
   Lu M, 2015, IEEE T PARALL DISTR, V26, P3066, DOI 10.1109/TPDS.2014.2365784
   Luk C. K., 2009, MICRO, P45
   Manly B. F., 2004, MULTIVARIATE STAT ME
   Marco VS, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P95, DOI 10.1145/3135974.3135984
   Memeti S, 2018, IEEE INT C COMPUT, P138, DOI 10.1109/CSE.2018.00026
   Meswani MR, 2013, INT J HIGH PERFORM C, V27, P89, DOI 10.1177/1094342012468180
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Nukada A., 2009, P C HIGH PERF COMP N, P1
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Rawat PS, 2018, P IEEE, V106, P1902, DOI 10.1109/JPROC.2018.2862896
   Ren J, 2017, IEEE INFOCOM SER
   Shen J, 2016, IEEE T PARALL DISTR, V27, P2766, DOI 10.1109/TPDS.2015.2509972
   Tang WT, 2015, INT SYM CODE GENER, P136, DOI 10.1109/CGO.2015.7054194
   Dao TT, 2018, IEEE T PARALL DISTR, V29, P283, DOI 10.1109/TPDS.2017.2755657
   The Khronos OpenCL Working Group, 2016, OPENCL OP STAND PAR
   Tillet P., 2017, P C HIGH PERF COMP N, P1
   Tournavitis G, 2009, ACM SIGPLAN NOTICES, V44, P177, DOI 10.1145/1543135.1542496
   van Werkhoven B, 2014, IEEE ACM INT SYMP, P11, DOI 10.1109/CCGrid.2014.16
   Wang Z, 2018, P IEEE, V106, P1879, DOI 10.1109/JPROC.2018.2817118
   Wang Z, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P307
   Wang Z, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2677036
   Wang Z, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2579561
   Wang Z, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2512436
   Wen Y, 2014, INT C HIGH PERFORM
   Yuan L., 2019, IEEE ACCESS, V7
   Zhang P, 2018, INT PARALL DISTRIB P, P515, DOI 10.1109/IPDPS.2018.00061
NR 69
TC 8
Z9 11
U1 2
U2 16
PD AUG 1
PY 2020
VL 31
IS 8
BP 1878
EP 1896
DI 10.1109/TPDS.2020.2978045
UT WOS:000562115100001
DA 2023-11-16
ER

PT C
AU Zhang, X
   Hao, C
   Zhou, PP
   Jones, A
   Hu, JT
AF Zhang, Xinyi
   Hao, Cong
   Zhou, Peipei
   Jones, Alex
   Hu, Jingtong
GP ACM
TI H2H: Heterogeneous Model to Heterogeneous System Mapping with
   Computation and Communication Awareness
SO PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022
DT Proceedings Paper
CT 59th ACM/IEEE Design Automation Conference (DAC) - From Chips to Systems
   - Learn Today, Create Tomorrow
CY JUL 10-14, 2022
CL San Francisco, CA
AB The complex nature of real-world problems calls for heterogeneity in both machine learning (ML) models and hardware systems. The heterogeneity in ML models comes from multi-sensor perceiving and multi-task learning, i.e., multi-modality multi-task (MMMT), resulting in diverse deep neural network (DNN) layers and computation patterns. The heterogeneity in systems comes from diverse processing components, as it becomes the prevailing method to integrate multiple dedicated accelerators into one system. Therefore, a new problem emerges: heterogeneous model to heterogeneous system mapping (H2H). While previous mapping algorithms mostly focus on efficient computations, in this work, we argue that it is indispensable to consider computation and communication simultaneously for better system efficiency. We propose a novel H2H mapping algorithm with both computation and communication awareness; by slightly trading computation for communication, the system overall latency and energy consumption can be largely reduced. The superior performance of our work is evaluated based on MAESTRO modeling, demonstrating 15%-74% latency reduction and 23%-64% energy reduction compared with existing computation-prioritized mapping algorithms. Code is publicly available at https://github.com/xyzxinyizhang/H2H.
C1 [Zhang, Xinyi; Zhou, Peipei; Jones, Alex; Hu, Jingtong] Univ Pittsburgh, Pittsburgh, PA USA.
   [Hao, Cong] Georgia Inst Technol, Atlanta, GA USA.
RP Zhang, X (corresponding author), Univ Pittsburgh, Pittsburgh, PA USA.
EM xiz173@pitt.edu; callie.hao@ece.gatech.edu; peipei.zhou@pitt.edu;
   akjones@pitt.edu; jthu@pitt.edu
CR [Anonymous], AWS NETW
   Chen DR, 2018, J PARALLEL DISTR COM, V118, P379, DOI 10.1016/j.jpdc.2017.08.006
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Ditty M., 2018, HOT CHIPS S HIGH PER
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gaide B, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P84, DOI 10.1145/3289602.3293906
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hao C, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458577
   Iqbal M, 2018, Arxiv, DOI arXiv:1806.11226
   Jiang WW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358192
   Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Li B., 2020, P ISLPED, P175
   Li XY, 2017, Arxiv, DOI arXiv:1702.01638
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mehler A, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P150, DOI 10.1145/3209542.3209572
   nvidia, US
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Riley Chris, 2019, BASIC TUTORIAL MAXIM
   Shen T, 2019, IEEE COMPUT SOC CONF, P1611, DOI 10.1109/CVPRW.2019.00203
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Taura K., 2000, Proceedings 9th Heterogeneous Computing Workshop (HCW 2000) (Cat. No.PR00556), P102, DOI 10.1109/HCW.2000.843736
   Thuseethan Selvarajah, 2020, 2020 WI IAT
   Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788
   Valada A, 2018, IEEE INT CONF ROBOT, P6939, DOI 10.1109/ICRA.2018.8462979
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Chang AXM, 2017, Arxiv, DOI arXiv:1708.00117
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhang XY, 2020, PR IEEE COMP DESIGN, P469, DOI 10.1109/ICCD50377.2020.00086
NR 36
TC 3
Z9 3
U1 0
U2 0
PY 2022
BP 601
EP 606
DI 10.1145/3489517.3530509
UT WOS:001041471300101
DA 2023-11-16
ER

PT J
AU Robson, R
   Kelsey, E
   Goel, A
   Nasir, SM
   Robson, E
   Garn, M
   Lisle, M
   Kitchens, J
   Rugaber, S
   Ray, F
AF Robson, Robby
   Kelsey, Elaine
   Goel, Ashok
   Nasir, Sazzad M.
   Robson, Elliot
   Garn, Myk
   Lisle, Matt
   Kitchens, Jeanne
   Rugaber, Spencer
   Ray, Fritz
TI Intelligent links: AI-supported connections between employers and
   colleges
SO AI MAGAZINE
DT Article
AB When modernization and other changes demand workforce reskilling, employers often turn to local colleges for training programs. Doing so can be a frustrating experience. HR and talent professionals have difficulty identifying and communicating requirements, especially for new jobs and roles, while college continuing education (CE) and professional development offices have difficulty understanding and responding to company needs. This article describes an NSF Convergence Accelerator project called SkillSync((TM)) in which multiple forms of AI are used to address this specific problem and provide national efforts (e.g., the US Chamber of Commerce Talent Pipeline Management initiative) with skills data and skills alignment services. Skillsync uses variations on the Siamese Multi-depth Transformer-based Hierarchical Encoder (SMITH) and other natural language understanding methods to map job descriptions and course information to skills taxonomies, uses machine-learned models to align skills needs with learning outcomes and training, and incorporates an intelligent coach based on Georgia Tech's Jill Watson "virtual teaching assistant" to answer questions about Skillsync's vocabulary, functionality, and process. This article describes these AI methods, how these methods are used in Skillsync, and the challenges involved.
C1 [Robson, Robby; Kelsey, Elaine; Nasir, Sazzad M.; Robson, Elliot; Ray, Fritz] Eduworks Corp, 400 SW 4th St Suite 110, Corvallis, OR 97333 USA.
   [Goel, Ashok; Garn, Myk; Rugaber, Spencer] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Lisle, Matt] Univ Syst Georgia, Atlanta, GA USA.
   [Kitchens, Jeanne] Credential Engine, Washington, DC USA.
RP Robson, R (corresponding author), Eduworks Corp, 400 SW 4th St Suite 110, Corvallis, OR 97333 USA.
EM robby.robson@eduworks.com
CR An S, 2020, LECT NOTES ARTIF INT, V12164, P20, DOI 10.1007/978-3-030-52240-7_4
   [Anonymous], 1999, DESCENT MIND PSYCHOL
   Baxter G, 2011, INTERACT COMPUT, V23, P4, DOI 10.1016/j.intcom.2010.07.003
   Bell B., 2020, P 8 ANN GEN INT FRAM, P101
   Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7
   Broscheit S., 2019, P 23 C COMPUTATIONAL, P677
   Devlin Jacob, 2018, N AM CHAPTER ASS COM
   Du J., 2019, ARXIV PREPRINT ARXIV
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Fry R., 2021, PEW RES CTR REPORT
   Goel A., 2020, ABS200601908 CORR
   Goel A., 2018, ED SCALE ENG ONLINE
   Goel A. K., 2016, VIRTUAL TEACHING ASS
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Joshi M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5803
   Lu K., 2020, LNCS, V12300, P189, DOI DOI 10.1007/978-3-030-62077-6
   Rajapakse, 2020, SIMPLE TRANSFORMERS
   Ruder S., 2019, P 2019 C N AM CHAPTE, P15, DOI [10.18653/v1/n19-5004, DOI 10.18653/V1/N19-5004]
   Stewart F, 2020, ECON DEV Q, V34, P356, DOI 10.1177/0891242420948604
   Wolf T., P 2020 C EMPIRICAL M, P38
   Yang L, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1725, DOI 10.1145/3340531.3411908
NR 21
TC 0
Z9 0
U1 3
U2 9
PD MAR
PY 2022
VL 43
IS 1
BP 75
EP 82
DI 10.1002/aaai.12040
UT WOS:000780336400010
DA 2023-11-16
ER

PT C
AU Srivastava, A
   Lazaris, A
   Brooks, B
   Kannan, R
   Prasanna, VK
AF Srivastava, Ajitesh
   Lazaris, Angelos
   Brooks, Benjamin
   Kannan, Rajgopal
   Prasanna, Viktor K.
GP Assoc Comp Machinery
TI Predicting Memory Accesses: The Road to Compact ML-driven Prefetcher
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
DE memory access prediction; prefetching; deep learning; compression
AB With the advent of fast processors, TPUs, accelerators, and heterogeneous architectures, computation is no longer the only bottleneck. In fact for many applications, speed of execution is limited by memory performance. To address memory performance, more accurate prefetching is necessary. While sophisticated machine learning algorithms have shown to predict memory accesses with high accuracy, they suffer with several issues that prevent them from being practical solutions as hardware prefetchers. These issues are centered around size of the model that results in high memory requirement, high latency and difficulty in online retraining. As the first step towards building ML-based prefetchers, we propose a compressed-LSTM approach for accurate memory access prediction. With a novel compression technique based on output encoding, we show that for the problem of predicting one of n memory locations, our technique results in O(n/log n) compression factor over the traditional LSTM approach. We further demonstrate through experiments on several benchmarks that the prediction accuracy drop due to compression is small and the training is fast. The actual compression obtained is of the order of 100x.
C1 [Srivastava, Ajitesh; Lazaris, Angelos; Brooks, Benjamin; Prasanna, Viktor K.] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Kannan, Rajgopal] Army Res Lab West, Adelphi, MD USA.
RP Srivastava, A (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM ajiteshs@usc.edu; alazaris@usc.edu; bjbrooks@usc.edu;
   rajgopal.kannan.civ@mail.mil; prasanna@usc.edu
CR [Anonymous], 2016, 49 ANN IEEE ACM INT, DOI DOI 10.1109/MICR0.2016.7783763
   [Anonymous], 1999, LEARNING FORGET CONT
   [Anonymous], 2009, PROC ACM C HIGH PERF
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2016, ARXIV160405529
   [Anonymous], 2018, CORR
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Fedchenko V., 2018, CORR
   Hashemi M., 2018, LEARNING MEMORY ACCE
   Hashemi Milad, 2018, CORR
   Kondguli S, 2018, CONF PROC INT SYMP C, P83, DOI 10.1109/ISCA.2018.00018
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Michaud P, 2016, INT S HIGH PERF COMP, P469, DOI 10.1109/HPCA.2016.7446087
   Moreira FB, 2017, ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2017, P45, DOI 10.1145/3075564.3075578
   Narayanan Arvind, 2018, P 2018 WORKSH NETW M, P48
   Peled L, 2018, NEURAL NETWORK MEMOR
   Rahman S, 2015, IEEE I C EMBED SOFTW, P383, DOI 10.1109/HPCC-CSS-ICESS.2015.175
   Sakr M.F., 1997, ICML, V97, P305
   Sakr MF, 1996, IEEE IJCNN, P1564, DOI 10.1109/ICNN.1996.549133
   Shevgoor M, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P141, DOI 10.1145/2830772.2830793
   Vinyals Oriol, 2015, ADV NEURAL INFORM PR, V28
   Xu ZX, 2017, DES AUT TEST EUROPE, P169, DOI 10.23919/DATE.2017.7926977
   Zeng Y, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P305, DOI 10.1145/3132402.3132405
NR 24
TC 14
Z9 14
U1 0
U2 1
PY 2019
BP 461
EP 470
DI 10.1145/3357526.3357549
UT WOS:000557305400040
DA 2023-11-16
ER

PT C
AU Wei, MT
   Lin, YS
   Lee, CR
AF Wei, Ming-ting
   Lin, Yu-Shiang
   Lee, Che-Rung
BE Chen, J
   Yang, LT
TI Performance Optimization for InfiniB and Virtualization on QEMU/KVM
SO 11TH IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGY AND
   SCIENCE (CLOUDCOM 2019)
SE International Conference on Cloud Computing Technology and Science
DT Proceedings Paper
CT 11th IEEE Int Conf on Cloud Comp Technol and Sci (CloudCom) / 19th IEEE
   Int Conf Comp and Informat Technol (CIT) / 2019 Int Workshop on Resource
   Brokering with Blockchain (RBchain) / Asia-Pacific Serv Comp Conf
   (APSCC)
CY DEC 11-13, 2019
CL Sydney, AUSTRALIA
DE Memory virtualization; QEMU/KVM; Infini-Band
AB The emergence of machine learning applications has brought the new demands for high performance computing in cloud environment. Besides accelerators, such as GPU or TPU, fast interconnection among and within computers becomes more and more important to achieve efficient training and learning. One of the high-bandwidth, low-latency interconnection architectures is InfiniBand. However, software based virtualization of InfiniBand in QEMU/KVM suffers large performance degradation owing to virtualization overhead and memory allocation problem. In this paper, two techniques, doorbell mapping and memlink, are proposed to optimize the performance the InfiniBand virtualization on QEMU/KVM. Doorbell mapping allows the applications in guest user-space to access the doorbell memory page directly so that the virtualization overhead is minimized. Memlink ensures memory contiguity after virtualization, which is a critical requirement for zero-copy between guest and host. Experiments show that the virtualized InfiniBand with mmap and memlink can achieve near native performance for large data transmissions. Comparing to the previous InfiniBand virtualization on QEMU/KVM, our implementation obtains over 3.5 times performance improvement in various benchmarks.
C1 [Wei, Ming-ting] Rayark Inc, Taipei, Taiwan.
   [Lin, Yu-Shiang] Ind Technol Res Inst, Informat & Commun Res Lab, Hsinchu, Taiwan.
   [Lee, Che-Rung] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
RP Wei, MT (corresponding author), Rayark Inc, Taipei, Taiwan.
EM mwei@rayark.com; YuShiangLin@itri.org.tw; cherung@cs.nthu.edu.tw
CR [Anonymous], ICPP 2018
   [Anonymous], 2014, RDMA AW NETW PROGR U
   [Anonymous], 2010, CISC VIS NETW IND GL
   [Anonymous], 2017, ACCURATE LARGE MINIB
   [Anonymous], 2009, CISC VIS NETW IND GL
   Bellard F, 2005, USENIX Association Proceedings of the FREENIX/Open Source Track, P41
   Bhoedjang RAF, 1998, COMPUTER, V31, P53, DOI 10.1109/2.730737
   Duato J., 2010, RCUDA REDUCING NUMBE, P224
   Gillespie M., 2009, BEST PRACTICES PARAV, V26, P2013
   Hsu HC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P545, DOI 10.1109/CIT.2016.30
   Kutch P., 2011, APPL NOTE
   Liu J., HIGH PERFORMANCE VMM
   Liu JX, 2004, IEEE MICRO, V24, P42, DOI 10.1109/MM.2004.1268994
   Luszczek P. R., 2006, SC 06
   Pfister G. F., 2001, HIGH PERFORMANCE MAS, V42, P617
   Russell R., 2018, ACM SIGOPS OPERATING, V42, P95
   Sayantan Sur, 2006, Proceedings of the 2006 ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming PPoPP'06, P32
   Shi L, 2012, IEEE T COMPUT, V61, P804, DOI 10.1109/TC.2011.112
   Tian Kun, 2014, P 2014 USENIX C USEN, P121
   Yi-Man Ma, 2012, 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom). Proceedings, P777, DOI 10.1109/CloudCom.2012.6427589
   Ying C., 2018, CORR
NR 21
TC 2
Z9 2
U1 2
U2 4
PY 2019
BP 19
EP 26
DI 10.1109/CloudCom.2019.00016
UT WOS:000552335500003
DA 2023-11-16
ER

PT C
AU Kinzer, S
   Kim, JK
   Ghodrati, S
   Yatham, B
   Althoff, A
   Mahajan, D
   Lerner, S
   Esmaeilzadeh, H
AF Kinzer, Sean
   Kim, Joon Kyung
   Ghodrati, Soroush
   Yatham, Brahmendra
   Althoff, Alric
   Mahajan, Divya
   Lerner, Sorin
   Esmaeilzadeh, Hadi
GP IEEE Comp Soc
TI A Computational Stack for Cross-Domain Acceleration
SO 2021 27TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2021)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 27th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 27-MAR 03, 2021
CL ELECTR NETWORK
DE Accelerator design; Machine learning systems; Algorithms/System
   Co-design; Domain Specific Language
ID LANGUAGE; DESIGN
AB Domain-specific accelerators obtain performance benefits by restricting their algorithmic domain. These accelerators utilize specialized languages constrained to particular hardware, thus trading off expressiveness for high performance. The pendulum has swung from one hardware for all domains (general-purpose processors) to one hardware per individual domain. The middle-ground on this spectrum-which provides a unified computational stack across multiple, but not all, domains-is an emerging and open research challenge. This paper sets out to explore this region and its associated tradeoff between expressiveness and performance by defining a cross-domain stack, dubbed PolyMath. This stack defines a high-level cross-domain language (CDL), called PMLang, that in a modular and reusable manner encapsulates mathematical properties to be expressive across multiple domains-Robotics, Graph Analytics, Digital Signal Processing, Deep Learning, and Data Analytics. PMLang is backed by a recursively-defined intermediate representation allowing simultaneous access to all levels of operation granularity, called srDFG. Accelerator-specific or domain-specific IRs commonly capture operations in the granularity that best fits a set of Domain-Specific Architectures (DSAs). In contrast, the recursive nature of the srDFG enables simultaneous access to all the granularities of computation for every operation, thus forming an ideal bridge for converting to various DSA-specific IRs across multiple domains. Our stack unlocks multi-acceleration for end-to-end applications that cross the boundary of multiple domains each comprising different data and compute patterns.
   Evaluations show that by using PolyMath it is possible to harness accelerators across the five domains to realize an average speedup of 3.3 x over a Xeon CPU along with 18.1 x reduction in energy. In comparison to Jetson Xavier and Titan XP, cross-domain acceleration offers 1.7 x and 7.2 x improvement in performance-per-watt, respectively. We measure the cross-domain expressiveness and performance tradeoff by comparing each benchmark against its hand-optimized implementation to achieve 83.9% and 76.8% of the optimal performance for single-domain algorithms and end-to-end applications. For the two case studies of end-to-end applications (comprising algorithms from multiple domains), results show that accelerating all kernels offers an additional 2.0 x speedup over CPU, 6.1 x improvement in performance-per-watt over Titan Xp, and 2.8 x speedup over Jetson Xavier compared to only the one most effective single-domain kernel being accelerated. Finally, we examine the utility and expressiveness of PolyMath through a user study, which shows, on average, PolyMath requires 1.9 x less time to implement algorithms from two different domains with 2.5 x fewer lines of code relative to Python.
C1 [Kinzer, Sean; Kim, Joon Kyung; Ghodrati, Soroush; Yatham, Brahmendra; Lerner, Sorin; Esmaeilzadeh, Hadi] Univ Calif San Diego, Alternat Comp Technol ACT Lab, San Diego, CA 92103 USA.
   [Althoff, Alric] Tortuga Log, San Jose, CA USA.
   [Mahajan, Divya] Microsoft, Redmond, WA USA.
RP Kinzer, S (corresponding author), Univ Calif San Diego, Alternat Comp Technol ACT Lab, San Diego, CA 92103 USA.
EM skinzer@eng.ucsd.edu; jkkim@eng.ucsd.edu; soghodra@eng.ucsd.edu;
   byatham@eng.ucsd.edu; alric@tortugalogic.com;
   divya.mahajan@microsoft.com; lerner@eng.ucsd.edu; hadi@eng.ucsd.edu
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   ACTLab, 2017, TABLA SOURC COD
   Ahn Byung Hoon, 2020, ICLR
   Ahn Byung Hoon, 2020, MLSYS
   [Anonymous], 2007, TEXAS INSTRUMENTS C6
   [Anonymous], 2011, ICML
   [Anonymous], 2017, MATLAB VERS 9 3 0 71
   Auerbach J, 2010, ACM SIGPLAN NOTICES, V45, P89, DOI 10.1145/1932682.1869469
   Bezanson J, 2012, ABS12095145 CORR
   Bordignon M, 2011, IEEE INT C INT ROBOT, P3659, DOI 10.1109/IROS.2011.6048419
   Chandramoorthy N, 2015, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2015.7056017
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen Y, 2016, DESTECH TRANS COMP
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Curtin RR, 2013, J MACH LEARN RES, V14, P801
   Davis JD, 2008, DES AUT CON, P780
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Del Sozzo E., 2018, 2018 IEEE 29 INT C A, P1
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Felipe Kuhne, 2005, LAT AM ROB S
   Fix Jordan, 2018, ABS180500907 CORR
   Frigerio Marco, 2015, INT WORKSH DOM SPEC
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Ghodrati Soroush, 2020, 2020 53 ANN IEEE ACM
   Ghodrati Soroush, 2020, PACT
   Grouplens, MOVIELENS DATASET
   Ham TJ, 2016, INT SYMP MICROARCH
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houska B, 2011, OPTIM CONTR APPL MET, V32, P298, DOI 10.1002/oca.939
   Howard A. G., 2017, ABS170404861 CORR
   Jain AK, 2016, ANN IEEE SYM FIELD P, P1, DOI 10.1109/FCCM.2016.10
   Kamel M, 2015, IEEE INTL CONF CONTR, P1160, DOI 10.1109/CCA.2015.7320769
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Kotsifakou M, 2018, ACM SIGPLAN NOTICES, V53, P68, DOI 10.1145/3200691.3178493
   Kwak H., 2010, P 19 INT C WORLD WID, P591, DOI DOI 10.1145/1772690.1772751
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lattner Chris, 2019, MLIR PRIMER COMPILER
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lichman M., 2013, UCI MACHINE LEARNING
   Lindholm T., 2014, JAVA VIRTUAL MACHINE, V8th
   Liu H, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807594
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Moreau T., 2019, IEEE MICRO
   Moreau Thierry, 2018, ABS180704188 CORR
   Morris GW, 2007, I C FIELD PROG LOGIC, P5, DOI 10.1109/FPL.2007.4380617
   Murray S., 2016, P 49 ANN IEEE ACM IN, P1, DOI DOI 10.1109/MICRO.2016.7783748
   Nicolas Vasilache, 2018, ABS180204730 CORR
   Nvidia, 2008, NVID CUD SDK IM VID
   Nvidia, DENS LIN ALG GPUS
   Nvidia, NV TOOLK
   Nvidia, NVID NVBLAS LIB
   Nvidia, NV CUD FAST FOUR TRA
   Paszke Adam, 2017, AUTOMATIC DIFFERENTI
   Patterson David, 2017, ABS170404760 CORR
   R Core Team, 2023, R LANG ENV STAT COMP
   Ragan-Kelley J, 2018, COMMUN ACM, V61, P106, DOI 10.1145/3150211
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Roesch J, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P58, DOI 10.1145/3211346.3211348
   Sacks J, 2018, CONF PROC INT SYMP C, P479, DOI 10.1109/ISCA.2018.00047
   Samragh M, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3391901
   Sanderson Conrad, 2016, J OPEN SOURCE SOFTW
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sharma H, 2016, INT SYMP MICROARCH
   Steele Guy L., 2006, P 11 ACM SIGPLAN S P, P1, DOI [10.1145/1122971.1122972, DOI 10.1145/1122971.1122972]
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Turakhia Y, 2018, ACM SIGPLAN NOTICES, V53, P199, DOI [10.1145/3173162.3173193, 10.1145/3296957.3173193]
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Venkatesh G, 2010, ASPLOS XV: FIFTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P205
   Zhang XY, 2012, INT C PAR DISTRIB SY, P684, DOI 10.1109/ICPADS.2012.97
NR 72
TC 5
Z9 5
U1 0
U2 2
PY 2021
BP 54
EP 70
DI 10.1109/HPCA51647.2021.00015
UT WOS:000671076000005
DA 2023-11-16
ER

PT J
AU Shea, C
   Mohsenin, T
AF Shea, Colin
   Mohsenin, Tinoosh
TI Heterogeneous Scheduling of Deep Neural Networks for Low-power Real-time
   Designs
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article; Proceedings Paper
CT 3rd Workshop on Hardware Algorithms for Learning On-a-Chip (HALO)
CY NOV 16, 2017
CL Irvine, CA
DE Machine learning; real-time; scheduling; co-design; hardware; software;
   FPGA
AB Deep neural networks have become the readiest answer to a range of application challenges including image recognition, stock analysis, natural language processing, and biomedical applications such as seizure detection. All while outperforming prior leading solutions that relied heavily on hand-engineered techniques. However, deployment of these neural networks often requires high-computational and memory-intensive solutions. These requirements make it challenging to deploy Deep Neural Networks (DNNs) in embedded, real-time low-power applications where classic architectures, GPUs and CPUs, still impose significant power burden. Systems-on-Chip (SoC) with Field-programmable Gate Arrays (FPGAs) can be used to improve performance and allow more fine-grain control of resources than CPUs or GPUs, but it is difficult to find the optimal balance between hardware and software to improve DNN efficiency. In the current research literature there have been few proposed solutions to address optimizing hardware and software deployments of DNNs in embedded low-power systems. To address the computation resource restriction and low-power needs for deploying these networks, we describe and implement a domain-specific metric model for optimizing task deployment on differing platforms, hardware and software. Next, we propose a DNN hardware accelerator called Scalable Low-power Accelerator for real-time deep neural Networks (SCALENet) that includes multithreaded software workers. Finally, we propose a heterogeneous aware scheduler that uses the DNN-specific metric models and the SCALENet accelerator to allocate a task to a resource based on solving a numerical cost for a series of domain objectives. To demonstrate the applicability of our contribution, we deploy nine modern deep network architectures, each containing a different number of parameters within the context of two different neural network applications: image processing and biomedical seizure detection. Utilizing the metric modeling techniques integrated into the heterogeneous aware scheduler and the SCALENet accelerator, we demonstrate the ability to meet computational requirements, adapt to multiple architectures, and lower power by providing an optimized task to resource allocation. Our heterogeneous aware scheduler improves power saving by decreasing power consumption by 10% of the total system power, does not affect the accuracy of the networks, and still meets the real-time deadlines. We demonstrate the ability to achieve parity with or exceed the energy efficiency of NVIDIA GPUs when evaluated against Jetson TK1 with embedded GPU SoC and with a 4x power savings in a power envelope of 2.0W. When compared to existing FPGA-based accelerators, SCALENet's accelerator and heterogeneous aware scheduler achieves a 4.8x improvement in energy efficiency.
C1 [Shea, Colin; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, 1000 Hilltop Circle, Catonsville, MD 21250 USA.
RP Shea, C (corresponding author), Univ Maryland Baltimore Cty, 1000 Hilltop Circle, Catonsville, MD 21250 USA.
EM cshea3@umbc.edu; tinoosh@umbc.edu
CR Abtahi T., 2017, IEEE INT S CIRC SYST, P1, DOI DOI 10.1109/ISCAS.2017.8050588
   Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   [Anonymous], POW METH GUID
   [Anonymous], 2018, P INT C RECONFIGURAB
   [Anonymous], ACM SIGARCH COMPUTER
   [Anonymous], 2015, 2015 IEEE 12 INT C W, DOI DOI 10.1109/BSN.2015.7299406
   Braun TD, 2001, J PARALLEL DISTR COM, V61, P810, DOI 10.1006/jpdc.2000.1714
   Cannell P, 2016, J INTERACT MEDIA EDU, DOI 10.5334/jime.412
   Chafi H, 2011, ACM SIGPLAN NOTICES, V46, P35, DOI 10.1145/2038037.1941561
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Figueira SM, 1996, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, P392, DOI 10.1109/HPDC.1996.546210
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   He K., 2015, INDIAN J CHEM B
   Hosseini M, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317873
   Hosseini M, 2019, INT SYM QUAL ELECT, P259, DOI 10.1109/ISQED.2019.8697574
   Iandola FN, 2016, PROC INT C LEARN
   Inggs G, 2013, PROC INT CONF PARAL, P688, DOI 10.1109/ICPP.2013.82
   Javaheripi Mojan, 2019, P AUTOML WORKSH 36 I
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang QM, 2011, J SYST SOFTWARE, V84, P985, DOI 10.1016/j.jss.2011.01.051
   Khaturia M., 2018, P 2018 IEEE 19 WORKS, P1
   Khatwani M., 2019, P IEEE EMBS C NEUR E
   Liu X., ABS180206367 CORR
   Ma JZ, 2015, SOLID STATE SCI, V49, P1, DOI 10.1016/j.solidstatesciences.2015.09.007
   Makrani HM, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P727, DOI 10.1145/3287624.3288756
   Neshatpour K, 2019, INT SYM QUAL ELECT, P265, DOI 10.1109/ISQED.2019.8697497
   Neshatpour K, 2018, DES AUT TEST EUROPE, P551, DOI 10.23919/DATE.2018.8342068
   Ortega-Zamorano F, 2014, IEEE T IND INFORM, V10, P1154, DOI 10.1109/TII.2013.2294137
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Park SH, 2015, PLANT BIOTECHNOL REP, V9, P6
   Samragh M., 2019, ABS190105582 CORR
   Samragh M., 2019, P ML FOR SYST WORKSH
   Sayadi H, 2017, PR IEEE COMP DESIGN, P129, DOI 10.1109/ICCD.2017.28
   Shea C., 2018, ACM P GREAT LAK S VE
   Sim Jaehyeong, 2016, P INT SOL STAT CIRC
   Simonyan K., 2015, ARXIV
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van Deursen A, 2000, ACM SIGPLAN NOTICES, V35, P26, DOI 10.1145/352029.352035
   Vasilache N, 2014, ABS14127580 CORR
   Zhang Chen, 2015, P INT S FIELD PROGR
   Zhong G., 2018, ABS180400706 CORR
NR 49
TC 9
Z9 10
U1 0
U2 6
PD DEC
PY 2019
VL 15
IS 4
SI SI
AR 36
DI 10.1145/3358699
UT WOS:000535716700006
DA 2023-11-16
ER

PT C
AU Ganesan, V
   Selvam, S
   Sen, S
   Kumar, P
   Raghunathan, A
AF Ganesan, Vinod
   Selvam, Surya
   Sen, Sanchari
   Kumar, Pratyush
   Raghunathan, Anand
GP IEEE
TI A Case for Generalizable DNN Cost Models for Mobile Devices
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON WORKLOAD CHARACTERIZATION (IISWC
   2020)
SE International Symposium on Workload Characterization Proceedings
DT Proceedings Paper
CT 16th IEEE International Symposium on Workload Characterization (IISWC)
CY OCT 27-29, 2020
CL ELECTR NETWORK
DE runtime; deep learning; mobile devices; machine learning
AB Accurate workload characterization of Deep Neural Networks (DNNs) is challenged by both network and hardware diversity. Networks are being designed with newer motifs such as depthwise separable convolutions, bottleneck layers, etc., which have widely varying performance characteristics. Further, the adoption of Neural Architecture Search (NAS) is creating a Cambrian explosion of networks, greatly expanding the space of networks that must be modeled. On the hardware front, myriad accelerators are being built for DNNs, while compiler improvements are enabling more efficient execution of DNNs on a wide range of CPUs and GPUs. Clearly, characterizing each DNN on each hardware system is infeasible. We thus need cost models to estimate performance that generalize across both devices and networks. In this work, we address this challenge by building a cost model of DNNs on mobile devices. The modeling and evaluation are based on latency measurements of 118 networks on 105 mobile System-on-Chips (SoCs). As a key contribution, we propose that a hardware platform can be represented by its measured latencies on a judiciously chosen, small set of networks, which we call the signature set. We also design a machine learning model that takes as inputs (i) the target hardware representation (measured latencies of the signature set on the hardware) and (ii) a representation of the structure of the DNN to be evaluated, and predicts the latency of the DNN on the target hardware. We propose and evaluate different algorithms to select the signature set. Our results show that by carefully choosing the signature set, the network representation, and the machine learning algorithm, we can train accurate cost models that generalize well. We demonstrate the value of such a cost model in a collaborative workload characterization setup, wherein every mobile device contributes a small set of latency measurements to a centralized repository. With even a small number of measurements per new device, we show that the proposed cost model matches the accuracy of device-specific models trained on an order-of-magnitude larger number of measurements. The entire codebase is released at https://github.com/iitm-sysdl/Generalizable-DNNcost-models.
C1 [Ganesan, Vinod; Selvam, Surya; Kumar, Pratyush] IIT Madras, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Sen, Sanchari; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Selvam, Surya] Purdue Univ, W Lafayette, IN 47907 USA.
   [Sen, Sanchari] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
RP Ganesan, V (corresponding author), IIT Madras, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM vinodg@cse.iitm.ac.in; cs16b029@cse.iitm.ac.in; sen9@purdue.edu;
   pratyush@cse.iitm.ac.in; raghunathan@purdue.edu
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Cai H., 2019, ONCE FOR ALL TRAIN N, P1
   Chen T., 2016, KDD16 P 22 ACM, P785, DOI [DOI 10.1145/2939672.2939785, 10.1145/2939672.2939785]
   Chen Tianqi, 2018, ARXIV180508166, V31, P3389
   Dai XL, 2019, PROC CVPR IEEE, P11390, DOI 10.1109/CVPR.2019.01166
   Han S., 2018, ARXIV PREPRINT ARXIV
   Howard A. G., 2017, ABS170404861 CORR
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Iandola F.N., 2016, CORR ABS160207360
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kaufman Samuel, 2019, P WORKSH ML SYST NEU, P1
   Krause A, 2008, J MACH LEARN RES, V9, P235
   Leskovec J., 2017, NIPS
   Paszke A, 2019, ADV NEUR IN, V32
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Wang D., SINGLE PATH NAS DESI
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
NR 20
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 169
EP 180
DI 10.1109/IISWC50251.2020.00025
UT WOS:000651388300016
DA 2023-11-16
ER

PT J
AU Kulkarni, A
   Page, A
   Attaran, N
   Jafari, A
   Malik, M
   Homayoun, H
   Mohsenin, T
AF Kulkarni, Adwaya
   Page, Adam
   Attaran, Nasrin
   Jafari, Ali
   Malik, Maria
   Homayoun, Houman
   Mohsenin, Tinoosh
TI An Energy-Efficient Programmable Manycore Accelerator for Personalized
   Biomedical Applications
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Low-power manycore accelerator; personalized biomedical applications;
   seizure detection; stress detection; tongue drive system (TDS)
ID PROCESSOR; PARALLEL; PLATFORM
AB Wearable personalized health monitoring systems can offer a cost-effective solution for human health care. These systems must constantly monitor patients' physiological signals and provide highly accurate, and quick processing and delivery of the vast amount of data within a limited power and area footprint. These personalized biomedical applications require sampling and processing multiple streams of physiological signals with a varying number of channels and sampling rates. The processing typically consists of feature extraction, data fusion, and classification stages that require a large number of digital signal processing (DSP) and machine learning (ML) kernels. In response to these requirements, in this paper, a tiny, energy-efficient, and domain-specific manycore accelerator referred to as power-efficient nanoclusters (PENC) is proposed to map and execute the kernels of these applications. Simulation results show that the PENC is able to reduce energy consumption by up to 80% and 25% for DSP and ML kernels, respectively, when optimally parallelized. In addition, we fully implemented three compute-intensive personalized biomedical applications, namely, multichannel seizure detection, multiphysiological stress detection, and standalone tongue drive system (sTDS), to evaluate the proposed manycore performance relative to commodity embedded CPU, graphical processing unit (GPU), and field-programmable gate array (FPGA)-based implementations. For these three case studies, the energy consumption and the performance of the proposed PENC manycore, when acting as an accelerator along with an Intel Atom processor as a host, are compared with the existing commercial off-the-shelf general-purpose, customizable, and programmable embedded platforms, including Intel Atom, Xilinx Artix-7 FPGA, and NVIDIA TK1 advanced RISC machine -A15 and KI GPU system on a chip. For these applications, the PENC manycore is able to significantly improve throughput and energy efficiency by up to 1872x and 276x, respectively. For the most computational intensive application of seizure detection, the PENC manycore is able to achieve a throughput of 15.22 giga-operations-per-second (GOPs), which is a 14x improvement in throughput over custom FPGA solution. For stress detection, the PENC achieves a throughput of 21.36 GOPs and an energy efficiency of 4.23 GOP/J, which is 14.87x and 2.28x better over FPGA implementation, respectively. For the sTDS application, the PENC improves a throughput by 5.45x and an energy efficiency by 2.37x over FPGA implementation.
C1 [Kulkarni, Adwaya; Page, Adam; Attaran, Nasrin; Jafari, Ali; Mohsenin, Tinoosh] Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
   [Malik, Maria; Homayoun, Houman] George Mason Univ, Elect & Comp Engn Dept, Fairfax, VA 22030 USA.
RP Kulkarni, A (corresponding author), Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
EM adwayak1@umbc.edu
CR Al Khatib I, 2006, DES AUT CON, P125, DOI 10.1109/DAC.2006.229190
   Alemzadeh H., 2011, 2011 IEEE/NIH 5th Life Science Systems and Applications Workshop (LiSSA), P112, DOI 10.1109/LISSA.2011.5754169
   [Anonymous], P IEEE BIOM CIRC SYS
   [Anonymous], 2016, IEEE SENSORS DIG TEC
   [Anonymous], 2014, DAC 14
   [Anonymous], THESIS
   [Anonymous], IEEE T BIOM IN PRESS
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2016, 2016 INT C HARDWARES
   [Anonymous], 2006, IMPERIAL COLL REPORT
   [Anonymous], CADENCE DESIGN SYSTE
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2012, PROC IEEE S VLSI CIR, DOI DOI 10.1109/VLSIC.2012.6243837
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], 2013, THESIS
   [Anonymous], 2010, P INT C MOB COMP APP
   [Anonymous], ACM T EMBED IN PRESS
   [Anonymous], 2013, P WORKSH POW AW COMP
   [Anonymous], P 21 ED GREAT LAK S
   Asano S, 2009, I C FIELD PROG LOGIC, P126, DOI 10.1109/FPL.2009.5272532
   Bisasky J, 2013, INT SYM QUAL ELECT, P368, DOI 10.1109/ISQED.2013.6523637
   Bisasky J, 2012, IEEE INT SYMP CIRC S, P564, DOI 10.1109/ISCAS.2012.6272092
   Bohnenstiehl B, 2017, IEEE J SOLID-ST CIRC, V52, P891, DOI 10.1109/JSSC.2016.2638459
   Choi J, 2012, IEEE T INF TECHNOL B, V16, P279, DOI 10.1109/TITB.2011.2169804
   Conti F, 2016, J SIGNAL PROCESS SYS, V84, P339, DOI 10.1007/s11265-015-1070-9
   Deng Y, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P584, DOI 10.1109/IRI.2012.6303062
   Dogan AY, 2011, LECT NOTES COMPUT SC, V6951, P102, DOI 10.1007/978-3-642-24154-3_11
   Dreslinski Ronald G., 2007, 2007 16th International Conference on Parallel Architectures and Compilation Techniques, P175
   Ghasemzadeh H, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2501626.2501636
   Hanson S, 2009, IEEE J SOLID-ST CIRC, V44, P1145, DOI 10.1109/JSSC.2009.2014205
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Homayoun H, 2012, P INT S HIGH PERFORM, P1
   Jafari Ali, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348376
   Kim C, 2012, 2012 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT'12), P329, DOI 10.1109/FPT.2012.6412157
   Krimer E, 2010, IEEE COMPUT ARCHIT L, V9, P21, DOI 10.1109/L-CA.2010.5
   Kulkarni A, 2016, ACM J EMERG TECH COM, V13, DOI 10.1145/2827699
   Kulkarni A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P57, DOI 10.1145/2902961.2902984
   Kulkarni A, 2016, IEEE INT SYMP CIRC S, P1138, DOI 10.1109/ISCAS.2016.7527446
   Kulkarni A, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P120, DOI 10.1109/HST.2016.7495568
   Kulkarni A, 2016, INT SYM QUAL ELECT, P362, DOI 10.1109/ISQED.2016.7479228
   Kulkarni A, 2014, PR GR LAK SYMP VLSI, P299, DOI 10.1145/2591513.2591598
   Kulkarni A, 2015, IEEE INT SYMP CIRC S, P970, DOI 10.1109/ISCAS.2015.7168797
   Kumar R, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P81
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Lukefahr A, 2012, INT SYMP MICROARCH, P317, DOI 10.1109/MICRO.2012.37
   Malik M, 2016, IEEE COMP SOC ANN, P559, DOI 10.1109/ISVLSI.2016.112
   Malik M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P85, DOI 10.1109/BigData.2015.7363745
   Malik M, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P379, DOI 10.1109/ICCD.2015.7357128
   Neshatpour K, 2016, IEEE INT SYMP CIRC S, P1134, DOI 10.1109/ISCAS.2016.7527445
   Neshatpour K, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P115, DOI 10.1109/BigData.2015.7363748
   Neshatpour K, 2015, ANN IEEE SYM FIELD P, P164, DOI 10.1109/FCCM.2015.59
   Neshatpour K, 2015, IEEE ACM INT SYMP, P1151, DOI 10.1109/CCGrid.2015.165
   Page A., 2016, PROC IEEE 24 ANN INT, P1
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Page A, 2015, IEEE ENG MED BIO, P7111, DOI 10.1109/EMBC.2015.7320031
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Pu Y, 2010, IEEE J SOLID-ST CIRC, V45, P668, DOI 10.1109/JSSC.2009.2039684
   Rosén J, 2007, RTSS 2007: 28TH IEEE INTERNATIONAL REAL-TIME SYSTEMS SYMPOSIUM, PROCEEDINGS, P49, DOI 10.1109/RTSS.2007.24
   Tavana MK, 2015, DES AUT CON, DOI 10.1145/2744769.2744833
   Tavana MK, 2014, I SYMPOS LOW POWER E, P275, DOI 10.1145/2627369.2627654
   Truong DN, 2009, IEEE J SOLID-ST CIRC, V44, P1130, DOI 10.1109/JSSC.2009.2013772
   Tsoi KH, 2010, FPGA 10, P115
   Viseh S, 2015, IEEE T CIRCUITS-II, V62, P174, DOI 10.1109/TCSII.2014.2387683
   Yoo J, 2013, IEEE J SOLID-ST CIRC, V48, P214, DOI 10.1109/JSSC.2012.2221220
NR 66
TC 9
Z9 10
U1 0
U2 10
PD JAN
PY 2018
VL 26
IS 1
BP 96
EP 109
DI 10.1109/TVLSI.2017.2754272
UT WOS:000419089200009
DA 2023-11-16
ER

PT J
AU Vidyaratne, L
   Carpenter, A
   Powers, T
   Tennant, C
   Iftekharuddin, KM
   Rahman, MM
   Shabalina, AS
AF Vidyaratne, Lasitha
   Carpenter, Adam
   Powers, Tom
   Tennant, Chris
   Iftekharuddin, Khan M. M.
   Rahman, Md Monibor
   Shabalina, Anna S. S.
TI Deep Learning Based Superconducting Radio-Frequency Cavity Fault
   Classification at Jefferson Laboratory
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
DT Article
DE time-series classification; fault identification; superconducting
   radio-frequency cavities; particle accelerator; LINAC; deep recurrent
   learning; convolutional neural networks
ID TIME-SERIES; SYSTEM
AB This work investigates the efficacy of deep learning (DL) for classifying C100 superconducting radio-frequency (SRF) cavity faults in the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. CEBAF is a large, high-power continuous wave recirculating linac that utilizes 418 SRF cavities to accelerate electrons up to 12 GeV. Recent upgrades to CEBAF include installation of 11 new cryomodules (88 cavities) equipped with a low-level RF system that records RF time-series data from each cavity at the onset of an RF failure. Typically, subject matter experts (SME) analyze this data to determine the fault type and identify the cavity of origin. This information is subsequently utilized to identify failure trends and to implement corrective measures on the offending cavity. Manual inspection of large-scale, time-series data, generated by frequent system failures is tedious and time consuming, and thereby motivates the use of machine learning (ML) to automate the task. This study extends work on a previously developed system based on traditional ML methods (Tennant and Carpenter and Powers and Shabalina Solopova and Vidyaratne and Iftekharuddin, Phys. Rev. Accel. Beams, 2020, 23, 114601), and investigates the effectiveness of deep learning approaches. The transition to a DL model is driven by the goal of developing a system with sufficiently fast inference that it could be used to predict a fault event and take actionable information before the onset (on the order of a few hundred milliseconds). Because features are learned, rather than explicitly computed, DL offers a potential advantage over traditional ML. Specifically, two seminal DL architecture types are explored: deep recurrent neural networks (RNN) and deep convolutional neural networks (CNN). We provide a detailed analysis on the performance of individual models using an RF waveform dataset built from past operational runs of CEBAF. In particular, the performance of RNN models incorporating long short-term memory (LSTM) are analyzed along with the CNN performance. Furthermore, comparing these DL models with a state-of-the-art fault ML model shows that DL architectures obtain similar performance for cavity identification, do not perform quite as well for fault classification, but provide an advantage in inference speed.
C1 [Vidyaratne, Lasitha; Carpenter, Adam; Powers, Tom; Tennant, Chris] Jefferson Lab, Newport News, VA 23606 USA.
   [Iftekharuddin, Khan M. M.; Rahman, Md Monibor] Old Dominion Univ, Dept Elect & Comp Engn, ODU Vis Lab, Norfolk, VA USA.
   [Shabalina, Anna S. S.] Jefferson Lab, Warrington, England.
RP Vidyaratne, L (corresponding author), Jefferson Lab, Newport News, VA 23606 USA.
EM lasithav@jlab.org
CR [Anonymous], 2015, P ESANN
   BEVERIDGE S, 1981, J MONETARY ECON, V7, P151, DOI 10.1016/0304-3932(81)90040-4
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Caiado J, 2006, COMPUT STAT DATA AN, V50, P2668, DOI 10.1016/j.csda.2005.04.012
   Cho J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123491
   Chua KC, 2010, MED ENG PHYS, V32, P679, DOI 10.1016/j.medengphy.2010.04.009
   De Veaux R. D., 2005, STATS DATA MODELS
   Eren L, 2019, J SIGNAL PROCESS SYS, V91, P179, DOI 10.1007/s11265-018-1378-3
   Geron A, 2019, HANDS ON MACHINE LEA
   Kingma DP., 2017, ARXIV
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Meidinger EE., 1980, APPL TIME SERIES ANA
   Paszke A, 2019, ADV NEUR IN, V32
   Reece CE, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.124801
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shoeb A. H., 2010, P 27 INT C MACHINE L, P975, DOI DOI 10.5555/3104322.3104446
   Shumway R.H., 2000, TIME SERIES ANAL ITS, DOI [DOI 10.1007/978-1-4757-3261-0, 10.1007/978-1-4757-3261-0]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Vidyaratne&DAG; L., 2021, 18 INT C ACCELERATOR
   Wei XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0693-8
   Zhao XQ, 2019, IEEE T NEUR SYS REH, V27, P2164, DOI 10.1109/TNSRE.2019.2938295
NR 24
TC 1
Z9 1
U1 1
U2 5
PD JAN 3
PY 2022
VL 4
AR 718950
DI 10.3389/frai.2021.718950
UT WOS:000913852900001
DA 2023-11-16
ER

PT C
AU He, MX
   Thottethodi, M
   Vijaykumar, TN
AF He, Mingxuan
   Thottethodi, Mithuna
   Vijaykumar, T. N.
GP IEEE
TI Booster: An Accelerator for Gradient Boosting Decision Trees Training
   and Inference
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS 2022)
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE Gradient boosting; accelerator
AB Recent breakthroughs in machine learning (ML) have sparked hardware innovation for efficient execution of the emerging ML workloads. For instance, due to recent refinements and high-performance implementations, well-established gradient boosting decision tree (GBT) models (e.g., XGBoost) have demonstrated their dominance in commercially-important contexts, such as table-based datasets (e.g., relational databases and spreadsheets). Unfortunately, GBT training and inference are time-consuming (e.g., several hours of training for large datasets). Despite their importance, GBTs have not been targeted for hardware acceleration as much as neural networks.
   We propose Booster, a novel accelerator for GBTs based on their unique characteristics. We observe that the dominant steps of GBT training and inference (accounting for 90-98% of time) involve simple, fine-grained, independent operations on smallf-ootprint data structures (e.g., histograms and shallow trees) - i.e., GBT is on-chip memory bandwidth-bound. Unfortunately, existing multicores and GPUs do not support massively-parallel data structure accesses that are irregular and data-dependent. By employing a scalable sea-of-small-SRAMs approach and an SRAM bandwidth-preserving mapping of data record fields to the SRAMs called group-by-field mapping, Booster achieves significantly more parallelism (e.g., 3200-way parallelism) than multicores and GPUs. In addition, Booster employs a redundant data representation that significantly lowers the memory bandwidth demand. Our simulations reveal that Booster achieves 11.4x and 6.4x speedups for training, and 45x and 22x (21x and 11x) speedups for offline (online) inference, over an ideal 32-core multicore and an ideal GPU, respectively. Based on ASIC synthesis of FPGA-validated RTL using 45 nm technology, we estimate a Booster chip to occupy 60 mm(2) of area and dissipate 23 W when operating at 1-GHz clock speed.
C1 [He, Mingxuan; Thottethodi, Mithuna; Vijaykumar, T. N.] Purdue Univ, Elmore Family Sch ECE, W Lafayette, IN 47907 USA.
RP He, MX (corresponding author), Purdue Univ, Elmore Family Sch ECE, W Lafayette, IN 47907 USA.
EM he238@purdue.edu; mithuna@purdue.edu; vijay@ecn.purdue.edu
CR Alcolea A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030314
   Ampere, AMP ALTR
   [Anonymous], LIGHTGBM EXPT
   [Anonymous], 2013, ALLSTATE CLAIM DATA
   [Anonymous], 2012, BOOSTING ADAPTIVE CO
   [Anonymous], AWESOME XGBOOST
   [Anonymous], TERABYTE CLICK LOG
   [Anonymous], HG INSIGHTS
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Data Expo, 2009, AIRLINE ON TIME PERF
   Dorogush A. V, 2017, WORKSHOP ML SYSTEMS
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gantz J., 2011, EXTRACTING VALUE CHA, V1142, P1
   He X., 2014, P 8 INT WORKSHOP DAT, P1, DOI [DOI 10.1145/2648584.2648589, 10.1145/2648584.2648589]
   Ke GL, 2017, ADV NEUR IN, V30
   Keck T., 2016, ARXIV
   Ling XL, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P689, DOI 10.1145/3041021.3054192
   Meidan Y, 2018, IEEE PERVAS COMPUT, V17, P12, DOI 10.1109/MPRV.2018.03367731
   NCSU, FREEPDK45
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Pafka S, 2016, FLIGHT DELAY DATA
   Qin T, 2013, Arxiv, DOI arXiv:1306.2597
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Sadasue T, 2020, ANN IEEE SYM FIELD P, P234, DOI 10.1109/FCCM48280.2020.00067
   Schmidt P, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P400, DOI 10.1145/3242969.3242985
   Tanaka Takuya, 2018, Arxiv, DOI arXiv:1812.08295
   Wen ZY, 2019, IEEE T PARALL DISTR, V30, P2706, DOI 10.1109/TPDS.2019.2920131
   wikipedia, US
NR 33
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 1051
EP 1062
DI 10.1109/IPDPS53621.2022.00106
UT WOS:000854096200098
DA 2023-11-16
ER

PT C
AU Wang, Y
   Li, P
AF Wang, Yu
   Li, Peng
GP IEEE Comp Soc
TI Algorithm and Hardware Co-Design for FPGA Acceleration of Hamiltonian
   Monte Carlo Based No-U-Turn Sampler
SO 2021 IEEE 32ND INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2021)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 32nd IEEE International Conference on Application-specific Systems,
   Architectures and Processors (ASAP)
CY JUL 07-08, 2021
CL ELECTR NETWORK
DE Hamiltonian Monte Carlo; No-U-Turn Sampler; FPGA; Hardware Acceleration
AB Monte Carlo (MC) methods are widely used in many research areas such as physical simulation, statistical analysis, and machine learning. Application of MC methods requires drawing fast mixing samples from a given probability distribution. Among existing sampling methods, the Hamiltonian Monte Carlo (HMC) utilizes gradient information during Hamiltonian simulation and can produce fast mixing samples at the highest efficiency. However, without carefully chosen simulation parameters for a specific problem, HMC generally suffers from simulation locality and computation waste. As a result, the No-U-Turn Sampler (NUTS) has been proposed to automatically tune these parameters during simulation and is the current state-of-the-art sampling algorithm. However, application of NUTS requires frequent gradient calculation of a given distribution and high-volume vector processing, especially for large-scale problems, leading to drawing an expensively large number of samples and a desire of hardware acceleration. While some hardware acceleration works have been proposed for traditional Markov Chain Monte Carlo (MCMC) and HMC methods, there is no existing work targeting hardware acceleration of the NUTS algorithm. In this paper, we present the first NUTS accelerator on FPGA while addressing the high complexity of this state-of-the-art algorithm. Our hardware and algorithm co-optimizations include an incremental resampling technique which leads to a more memory efficient architecture and pipeline optimization for multi-chain sampling to maximize the throughput. We also explore three levels of parallelism in the NUTS accelerator to further boost performance. Compared with optimized C++ NUTS package: RSTAN, our NUTS accelerator can reach a maximum speedup of 50.6X and an energy improvement of 189.7X.
C1 [Wang, Yu; Li, Peng] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
RP Wang, Y (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM yu95@ucsb.edu; lip@ucsb.edu
CR Bingham E, 2018, J MACH LEARN RES
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Chen TQ, 2014, PR MACH LEARN RES, V32, P1683
   Gonzalez J., 2011, P 14 INT C ARTIFICIA, P324
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Koushanfar F., 2018, CAUSALEARN AUTOMATED, P1
   Liu SL, 2017, IEEE T COMPUT, V66, P745, DOI 10.1109/TC.2016.2630682
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mingas Grigorios, 2012, Reconfigurable Computing: Architectures, Tools and Applications. Proceedings of the 8th International Symposium, ARC 2012, P227, DOI 10.1007/978-3-642-28365-9_19
   Neal R. M., 1996, BAYESIAN LEARNING NE, P29, DOI DOI 10.1007/978-1-4612-0745-0_2
   Neal RM, 2011, CH CRC HANDB MOD STA, P113
   Nesterov Y, 2009, MATH PROGRAM, V120, P221, DOI 10.1007/s10107-007-0149-x
NR 12
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 9
EP 16
DI 10.1109/ASAP52443.2021.00009
UT WOS:000698747200002
DA 2023-11-16
ER

PT J
AU Raha, A
   Raghunathan, V
AF Raha, Arnab
   Raghunathan, Vijay
TI QLUT: Input-Aware Quantized Table Lookup for Energy-Efficient
   Approximate Accelerators
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Approximate computing; Low-power design; Accelerators; Lookup table
AB Approximate computing has emerged as a popular design paradigm for optimizing the performance and energy consumption of error-resilient applications in domains such as machine learning, graphics, data analytics, etc. Numerous techniques for approximate computing have been proposed at different layers of the system stack, from circuits to architecture to software. In this work, we propose a new technique, called quantized table lookup, for approximating the meta-functions used in the core computational kernels of error-resilient applications. In contrast to prior work that directly approximates the functionality of the meta-functions, the proposed technique instead approximates the input data to the meta-functions by reducing/quantizing them to a much smaller set of values that we call quantized inputs. The small number of quantized inputs enables us to completely replace the energy-intensive arithmetic units in the meta-function with small and energy-efficient lookup tables (called quantized lookup tables or QLUT) that contain precomputed output values corresponding to the quantized inputs. The proposed approximation technique is not only highly generic, but also inherently quality-configurable and input-aware. Quality-configurability and input-awareness are achieved bymodulating the size of the qLUT as well as selecting the values of the quantized inputs judiciously based on the statistics of the original input data. To evaluate the proposed technique, we have implemented the dominant meta-functions of nine error-resilient application benchmarks as quantized table lookup based hardware accelerators using 45nm technology. Experimental results demonstrate average energy savings of 46% at the application-level for minimal (< 1%) loss in output quality.
C1 [Raha, Arnab; Raghunathan, Vijay] Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.
RP Raha, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.
EM araha@purdue.edu; vr@purdue.edu
CR Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Amirtharajah R, 2004, IEEE J SOLID-ST CIRC, V39, P337, DOI 10.1109/JSSC.2003.821774
   [Anonymous], 2011, P DATE
   [Anonymous], ICCAD IEEE ACM INT
   [Anonymous], P 50 ANN DES AUT C D
   [Anonymous], P INT C SUP ICS 17
   Ayinala M, 2013, CONF REC ASILOMAR C, P2167, DOI 10.1109/ACSSC.2013.6810693
   Baek W, 2010, PLDI '10: PROCEEDINGS OF THE 2010 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P198, DOI 10.1145/1806596.1806620
   Chippa V.K., 2013, P 50 ACM EDAC IEEE D, P1, DOI [DOI 10.1145/2463209.2488873, 10.1145/2463209.2488873]
   Chippa V, 2011, DES AUT CON, P603
   de Dinechin F, 2005, IEEE T COMPUT, V54, P319, DOI 10.1109/TC.2005.54
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Krause PK, 2011, DES AUT TEST EUROPE, P944
   Laurenzano MA, 2016, ACM SIGPLAN NOTICES, V51, P161, DOI [10.1145/2908080.2908087, 10.1145/2980983.2908087]
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nguyen HT, 2000, IEEE T VLSI SYST, V8, P419, DOI 10.1109/92.863621
   Potkonjak M, 1996, IEEE T COMPUT AID D, V15, P151, DOI 10.1109/43.486662
   Raha A, 2014, I CONF VLSI DESIGN, P324, DOI 10.1109/VLSID.2014.62
   Raha A, 2017, DES AUT CON, DOI 10.1145/3061639.3062333
   Raha A, 2017, IEEE EMBED SYST LETT, V9, P21, DOI 10.1109/LES.2017.2658566
   Raha A, 2017, IEEE T VLSI SYST, V25, P462, DOI 10.1109/TVLSI.2016.2586379
   Raha A, 2016, IEEE T VLSI SYST, V24, P846, DOI 10.1109/TVLSI.2015.2424212
   Raha A, 2015, DES AUT TEST EUROPE, P665
   Ranjan A., 2014, P DATE, P1, DOI DOI 10.7873/DATE.2014.377
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Shafique M, 2016, 2016 53 ACM EDAC IEE, P1, DOI DOI 10.1145/2897937.2905008
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Sidiroglou-Douskos S., 2011, 19 ACM SIGSOFT, P124, DOI DOI 10.1145/2025113.2025133
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Voronenko Y, 2007, ACM T ALGORITHMS, V3, DOI 10.1145/1240233.1240234
NR 32
TC 12
Z9 12
U1 0
U2 5
PD OCT
PY 2017
VL 16
SU 5
SI SI
AR 130
DI 10.1145/3126531
UT WOS:000414353800013
DA 2023-11-16
ER

PT J
AU Hassan, O
   Paul, T
   Shuvo, MH
   Parvin, D
   Thakker, R
   Chen, MR
   Mosa, AM
   Islam, SK
AF Hassan, Omiya
   Paul, Tanmoy
   Shuvo, Maruf Hossain
   Parvin, Dilruba
   Thakker, Rushil
   Chen, Mengrui
   Mosa, Abu Saleh Mohammad
   Islam, Syed Kamrul
TI Energy Efficient Deep Learning Inference Embedded on FPGA for Sleep
   Apnea Detection
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Deep learning; Feedforward neural network; FPGA; Sleep apnea; ECG;
   Oxygen saturation; System-on-a-chip
ID AUTOMATIC DETECTION
AB Sleep apnea is a type of disorder caused by the absence of breathing for a specific period of time coupled with a significant decrease in the blood oxygen saturation level. The monitoring process of sleep apnea is challenging due to the requirement of overnight expensive sleep study, hand-crafted feature extraction from breathing signals, and manual annotations by the sleep experts. Therefore, a low-cost, energy-efficient, portable, and automated biomedical system is necessary to improve early detection, frequent monitoring, and clinical decision-making. In this paper, a digital hardware design of a trained deep feedforward neural network (FNN) is implemented on a Field Programmable Gate-Array (FPGA) for the detection of sleep apnea. The model was trained and evaluated with hyperparameters obtained from a three-step optimization process which ensures compact design solution in low-power miniaturized CMOS circuits. A three-layer FNN trained with ADAM optimizer and mean square error (MSE) loss minimization shows an accuracy of around 88%. An application-specific deep learning inference module realized in FPGA hardware platform confirms a power consumption below 34 W which is 5 x lower than that of commercially available machine learning accelerators. The outcome of this research can be integrated into a system-on-a-chip (SoC) platform for developing a smart automated sleep apnea detection device.
C1 [Hassan, Omiya; Paul, Tanmoy; Shuvo, Maruf Hossain; Parvin, Dilruba; Thakker, Rushil; Chen, Mengrui; Islam, Syed Kamrul] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.
   [Mosa, Abu Saleh Mohammad] Univ Missouri, Dept Hlth Management & Informat, Columbia, MO 65211 USA.
RP Hassan, O (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.
EM omiya.hassan@mail.missouri.edu
CR Agarap Abien Fred, 2018, ARXIV PREPRINT ARXIV, P7
   Alvarez D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62223-4
   Azimi H, 2020, IEEE ACCESS, V8, P173428, DOI 10.1109/ACCESS.2020.3025808
   Bhattacharjee R, 2021, J CLIN SLEEP MED, V17, P1379, DOI 10.5664/jcsm.9202
   Dey D, 2018, BIOMED ENG LETT, V8, P95, DOI 10.1007/s13534-017-0055-y
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gottlieb DJ, 2020, JAMA-J AM MED ASSOC, V323, P1389, DOI 10.1001/jama.2020.3514
   Hassan O., 2020, MACHINE LEARNING MOD, P607
   Hassan O, 2020, IEEE INT SYM MED MEA, DOI 10.1109/memea49120.2020.9137291
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   King DB, 2015, ACS SYM SER, V1214, P1
   Kristiansen Stein, 2021, ACM Transactions on Computing and Healthcare, V2, DOI 10.1145/3433987
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li KY, 2018, NEUROCOMPUTING, V294, P94, DOI 10.1016/j.neucom.2018.03.011
   Mahbub Ifana, 2015, 2015 IEEE Topical Conference on Biomedical Wireless Technologies, Networks and Sensing Systems (BioWireleSS). Proceedings, P1, DOI 10.1109/BIOWIRELESS.2015.7152130
   Mahbub I, 2017, IEEE SENS J, V17, P1858, DOI 10.1109/JSEN.2017.2651073
   Mendonça F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030888
   Mendonça F, 2018, SLEEP MED REV, V41, P149, DOI 10.1016/j.smrv.2018.02.004
   Nikonov D. E., 2019, ARXIV PREPRINT ARXIV
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   Penzel Thomas, 2018, F1000Res, V7, P413, DOI 10.12688/f1000research.13010.1
   Pullano Salvatore Andrea, 2017, IEEE Rev Biomed Eng, V10, P199, DOI 10.1109/RBME.2017.2757899
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Shamsir S., 2020, 2020 IEEE INT INSTR, P1, DOI [10.1109/I2MTC43012.2020.9129295, DOI 10.1109/I2MTC43012.2020.9129295]
   Shamsir S, 2018, IEEE IMTC P, P529
   Song CY, 2016, IEEE T BIO-MED ENG, V63, P1532, DOI 10.1109/TBME.2015.2498199
   Tisan A., 2009, ACTA TECHNICA NAPOCE, V50, P15, DOI DOI 10.1109/CADSM.2019.8779253
   Tsmots I, 2019, EXP DES APPL CAD SYS, DOI 10.1109/cadsm.2019.8779253
   Vanegas E, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185446
   Varon C, 2015, IEEE T BIO-MED ENG, V62, P2269, DOI 10.1109/TBME.2015.2422378
   Wang T, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9768072
   Ye GH, 2021, IEEE J BIOMED HEALTH, V25, P2848, DOI 10.1109/JBHI.2021.3050113
   Yüzer AH, 2020, IRBM, V41, P39, DOI 10.1016/j.irbm.2019.10.007
NR 33
TC 3
Z9 3
U1 1
U2 14
PD JUN
PY 2022
VL 94
IS 6
BP 609
EP 619
DI 10.1007/s11265-021-01722-7
EA JAN 2022
UT WOS:000740610700001
DA 2023-11-16
ER

PT C
AU Amarnath, C
   Chatterjee, A
AF Amarnath, Chandramouli
   Chatterjee, Abhijit
BE Savino, A
   Maniatakos, M
   DiCarlo, S
   Gizopoulos, D
TI A Novel Approach to Error Resilience in Online Reinforcement Learning
SO 2023 IEEE 29TH INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN, IOLTS
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 29th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 03-05, 2023
CL Platanias, GREECE
DE Neural Networks; Fault Tolerance; Resilience; Soft Errors; Reinforcement
   Learning
ID DNN ACCELERATORS; NETWORK
AB Online reinforcement learning (RL) based systems are being increasingly deployed in a variety of safety-critical applications ranging from drone control to medical robotics. These systems typically use RL onboard rather than relying on remote operation from high-performance datacenters. Due to the dynamic nature of the environments they work in, onboard RL hardware is vulnerable to soft errors from radiation, thermal effects and electrical noise that corrupt the results of computations. Existing approaches to on-line error resilience in machine learning systems have relied on availability of the large training datasets to configure resilience parameters, which is not necessarily feasible for online RL systems. Similarly, other approaches involving specialized hardware or modifications to training algorithms are difficult to implement for onboard RL applications. In contrast, we present a novel error resilience approach for online RL that makes use of running statistics collected across the (real-time) RL training process to configure error detection thresholds without the need to access a reference training dataset. In this methodology, statistical concentration bounds leveraging running statistics are used to diagnose neuron outputs as erroneous. These erroneous neurons are then set to zero (suppressed). Our approach is compared against the state of the art and validated on several RL algorithms involving the use of multiple concentration bounds on CPU as well as GPU hardware.
C1 [Amarnath, Chandramouli; Chatterjee, Abhijit] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Amarnath, C (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM chandamarnath@gatech.edu; abhijit.chatterjee@ece.gatech.edu
CR Amarnath C, 2022, IEEE INT ON LINE, DOI 10.1109/IOLTS56730.2022.9897815
   Banerjee S, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3338123
   Chen Z, 2021, INT J PROD RES, DOI [10.1109/DSN48987.2021.00018, 10.1080/00207543.2021.2006818]
   F. Foundation, 2022, GYMNASIUM-GER
   Ghosh BK, 2002, AM STAT, V56, P186, DOI 10.1198/000313002119
   Hanif MA, 2020, IEEE INT ON LINE, DOI 10.1109/iolts50870.2020.9159734
   Hari SKS, 2022, IEEE T DEPEND SECURE, V19, P2546, DOI 10.1109/TDSC.2021.3063083
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Huang S., 2022, J MACH LEARN RES, V23, P1
   Ibrahim Y, 2020, MICROELECTRON RELIAB, V115, DOI 10.1016/j.microrel.2020.113969
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/date.2019.8715178, 10.23919/DATE.2019.8715178]
   Mahmoud A., 2020, HARDNN FEATURE MAP V
   Mahmoud A, 2020, 50TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOPS (DSN-W 2020), P25, DOI 10.1109/DSN-W50199.2020.00014
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ozen E, 2022, IEEE T COMPUT AID D, V41, P3934, DOI 10.1109/TCAD.2022.3197540
   Ozen E, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3477007
   Ozen E, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415680
   Ozen E, 2020, IEEE T COMPUT AID D, V39, P3250, DOI 10.1109/TCAD.2020.3012209
   Paszke A, 2019, ADV NEUR IN, V32
   Rech P, 2013, IEEE T NUCL SCI, V60, P2797, DOI 10.1109/TNS.2013.2252625
   Schorn C, 2018, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE.2018.8342151
   Skolik A, 2023, EPJ QUANTUM TECHNOL, V10, DOI 10.1140/epjqt/s40507-023-00166-1
   Tan KL, 2020, P AMER CONTR CONF, P3959, DOI [10.23919/acc45564.2020.9147846, 10.23919/ACC45564.2020.9147846]
   Terpstra D, 2010, TOOLS FOR HIGH PERFORMANCE COMPUTING 2009, P157, DOI 10.1007/978-3-642-11261-4_11
   Vershynin R., 2019, HIGH DIMENSIONAL PRO
   Wang X., 2022, IEEE T NEUR NET LEAR
   WELFORD BP, 1962, TECHNOMETRICS, V4, P419, DOI 10.2307/1266577
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Yang C. H., 2021, CAUSAL INFERENCE Q N
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang S, 2016, IEEE T SIGNAL PROCES, V64, P3338, DOI 10.1109/TSP.2016.2546224
NR 31
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/IOLTS59296.2023.10224892
UT WOS:001062141900028
DA 2023-11-16
ER

PT C
AU Aceto, G
   Ciuonzo, D
   Montieri, A
   Persico, V
   Pescape, A
AF Aceto, Giuseppe
   Ciuonzo, Domenico
   Montieri, Antonio
   Persico, Valerio
   Pescape, Antonio
BE Secci, S
   Chrisment, I
   Fiore, M
   Tabourier, L
   Lim, KW
TI Know your Big Data Trade-offs when Classifying Encrypted Mobile Traffic
   with Deep Learning
SO PROCEEDINGS OF THE 3RD NETWORK TRAFFIC MEASUREMENT AND ANALYSIS
   CONFERENCE (TMA 2019)
DT Proceedings Paper
CT 3rd IFIP/IEEE Network Traffic Measurement and Analysis Conference (TMA)
CY JUN 19-21, 2019
CL Paris, FRANCE
DE traffic classification; mobile apps; big data; deep learning; Android
   apps; iOS apps; encrypted traffic
ID IDENTIFICATION
AB The spread of handheld devices has led to the unprecedented growth of traffic volumes traversing both local networks and the Internet, appointing mobile traffic classification as a key tool for gathering highly-valuable profiling information, other than traffic engineering and service management. However, the nature of mobile traffic severely challenges state-of-art Machine-Learning (ML) approaches, since the quickly evolving and expanding set of apps generating traffic hinders ML-based approaches, that require domain-expert design. Deep Learning (DL) represents a promising solution to this issue, but results in higher completion times, in turn suggesting the application of the Big-Data (BD) paradigm. In this paper, we investigate for the first time BD-enabled classification of encrypted mobile traffic using DL from a general standpoint, (a) defining general design guidelines, (b) leveraging a public-cloud platform, and (c) resorting to a realistic experimental setup. We found that, while BD represents a transparent accelerator for some tasks, this is not the case for the training phase of DL architectures for traffic classification, requiring a specific BD-informed design. The experimental setup is built upon a three-dimensional investigation path in the BD adoption, namely: (i) completion time, (ii) deployment costs, and (iii) classification performance, highlighting relevant non-trivial trade-offs.
C1 [Aceto, Giuseppe; Ciuonzo, Domenico; Montieri, Antonio; Persico, Valerio; Pescape, Antonio] Univ Napoli Federico II, Naples, Italy.
   [Aceto, Giuseppe; Persico, Valerio; Pescape, Antonio] NM2 Srl, Naples, Italy.
RP Aceto, G (corresponding author), Univ Napoli Federico II, Naples, Italy.; Aceto, G (corresponding author), NM2 Srl, Naples, Italy.
EM giuseppe.aceto@unina.it; domenico.ciuonzo@unina.it;
   antonio.montieri@unina.it; valerio.persico@unina.it; pescape@unina.it
CR Abu Alsheikh M, 2016, IEEE NETWORK, V30, P22, DOI 10.1109/MNET.2016.7474340
   Aceto G, 2019, IEEE T NETW SERV MAN, V16, P445, DOI 10.1109/TNSM.2019.2899085
   Aceto G, 2018, J NETW COMPUT APPL, V103, P131, DOI 10.1016/j.jnca.2017.11.007
   Dainotti A, 2012, IEEE NETWORK, V26, P35, DOI 10.1109/MNET.2012.6135854
   Diro AA, 2018, IEEE COMMUN MAG, V56, P169, DOI 10.1109/MCOM.2018.1700332
   Quoc DL, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P1008, DOI 10.1109/CLOUD.2015.138
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hajjar A, 2015, J NETW COMPUT APPL, V58, P130, DOI 10.1016/j.jnca.2015.10.003
   Jejdling F, 2019, ERICSSON MOBILITY RE
   Joeri C. I.-D., 2016, DISTRIBUTED KERAS DI
   Le L.-V, 2018, T NETWORKS COMMUNICA, V6
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Lotfollahi M, 2018, Arxiv, DOI arXiv:1709.02656
   Majchrzak TA, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P6162
   Mulinka P, ACM BIG DAMA 18
   Persico V, 2018, FUTURE GENER COMP SY, V89, P98, DOI 10.1016/j.future.2018.05.068
   Rajashekar D, 2016, INT CONF DAT MIN WOR, P319, DOI [10.1109/ICDMW.2016.89, 10.1109/ICDMW.2016.0052]
   Razaghpanah A, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P350, DOI 10.1145/3143361.3143400
   Taylor VF, 2018, IEEE T INF FOREN SEC, V13, P63, DOI 10.1109/TIFS.2017.2737970
   Viegas E, 2019, BIGFLOW REAL TIME RE
   Wang W, IEEE ISI 17
   Wang Zhanyi, 2015, BLACKHAT US
   Yao HY, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P439, DOI 10.1145/2789168.2790097
   Zhou BJ, 2018, INT WIREL COMMUN, P1507, DOI 10.1109/IWCMC.2018.8450335
NR 24
TC 10
Z9 11
U1 0
U2 0
PY 2019
BP 121
EP 128
UT WOS:000851465000016
DA 2023-11-16
ER

PT C
AU Homayoun, H
AF Homayoun, Houman
GP ACM
TI Heterogeneous Chip Multiprocessor Architectures for Big Data
   Applications
SO PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS
   (CF'16)
DT Proceedings Paper
CT ACM International Conference on Computing Frontiers (CF)
CY MAY 16-18, 2016
CL Como, ITALY
DE Heterogeneous Architectures; Performance; Power; Application
   Characterization; Big Data; Accelerator
AB Emerging big data analytics applications require a significant amount of server computational power. The costs of building and running a computing server to process big data and the capacity to which we can scale it are driven in large part by those computational resources. However, big data applications share many characteristics that are fundamentally different from traditional desktop, parallel, and scale-out applications. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and are running a complex and deep software stack with various components (e.g. Hadoop, Spark, MPI, Hbase, Impala, MySQL, Hive, Shark, Apache, and MangoDB) that are bound together with a runtime software system and interact significantly with I/O and OS, exhibiting high computational intensity, memory intensity, I/O intensity and control intensity. Current server designs, based on commodity homogeneous processors, will not be the most efficient in terms of performance/watt for this emerging class of applications. In other domains, heterogeneous architectures have emerged as a promising solution to enhance energy-efficiency by allowing each application to run on a core that matches resource needs more closely than a one-size-fits-all core. A heterogeneous architecture integrates cores with various micro-architectures and accelerators to provide more opportunity for efficient workload mapping. In this work, through methodical investigation of power and performance measurements, and comprehensive system level characterization, we demonstrate that a heterogeneous architecture combining high performance big and low power little cores is required for efficient big data analytics applications processing, and in particular in the presence of accelerators and near real-time performance constraints.
C1 [Homayoun, Houman] George Mason Univ, Fairfax, VA 22030 USA.
RP Homayoun, H (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
EM hhomayou@gmu.edu
CR Andersen DG, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P1
   [Anonymous], 2007, P 2007 SPEC BENCHM W
   Armstrong, 2013, P ACM SIGMOD
   ARNOLD M., 2001, P 9 CODES
   Arora M, 2012, IEEE MICRO, V32, P4, DOI 10.1109/MM.2012.57
   Arora N, 2010, VLSI DES
   Baru C, LECT NOTES COMPUTER
   Chung E. S., 2013, ACM SIGARCH COMPUTER, V41
   Clark NT, 2005, IEEE T COMPUT, V54, P1258, DOI 10.1109/TC.2005.156
   Ferdman M, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P37
   Gao W., ASBD 2013 CONJUNCTIO
   Ghazal Ahmad, 2013, P 2013 ACM SIGMOD IN, P1197, DOI 10.1145/2463676.2463712
   Gutierrez A., 2014, INTEGRATED 3DSTACKED
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Homayoun H, 2006, LECT NOTES COMPUT SC, V4017, P299, DOI 10.1007/11796435_31
   Homayoun Houman, 2008, ICCD IEEE INT C COMP
   Homayoun Houman, HIGH PERFORMANCE COM
   Huang SS, 2010, I C DATA ENGIN WORKS, P41, DOI 10.1109/ICDEW.2010.5452747
   Kontorinis V, 2014, DES AUT CON
   Kukunas James T, 2014, CISC VIS NETW IND GL
   Kumar R, 2005, COMPUTER, V38, P32, DOI 10.1109/MC.2005.379
   Li A., ACM 10
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Luo Xi, BIGDATA 2013
   Neshatpour Katayoun, 2015, CLUST CLOUD GRID COM
   Neshatpour Katayoun, 2015, FIELD PROGR CUST COM
   Neshatpour Katayoun, 2015, BIG DAT BIG DAT 2015
   Nilakantan S., 2013, PLATFORM INDEPENDENT
   Prakash TK, 2008, ISAST T COMPUT SOFTW, V2, P36, DOI DOI 10.1109/TPDS.2010.199
   Reddi VJ, 2010, CONF PROC INT SYMP C, P314, DOI 10.1145/1816038.1816002
   Shan Y, 2010, P ACM SIGDA INT S FI
   Wu Ren, 2009, GPU ACCELERATED LARG
   YU P., P CASES 04
   Yu P, 2007, I C FIELD PROG LOGIC, P273, DOI 10.1109/FPL.2007.4380659
NR 34
TC 1
Z9 1
U1 0
U2 4
PY 2016
BP 400
EP 405
DI 10.1145/2903150.2908078
UT WOS:000693994700055
DA 2023-11-16
ER

PT C
AU Garrett, T
   George, AD
AF Garrett, Tyler
   George, Alan D.
GP IEEE COMP SOC
TI Improving Dependability of Onboard Deep Learning with Resilient
   TensorFlow
SO 2021 IEEE SPACE COMPUTING CONFERENCE (SCC)
DT Proceedings Paper
CT IEEE Space Computing Conference (SCC)
CY AUG 23-26, 2021
CL ELECTR NETWORK
DE TensorFlow; GPU-Based Computing; Deep Learning; Onboard Processing;
   Fault-Tolerant Design; High-Performance Computing
AB As the dawn of a new age in spaceflight approaches, the drive to equip future spacecraft with high-performance computing capabilities is increasing. Many within the industry are looking to leverage solutions enabled by machine learning (ML) and artificial intelligence to enhance mission efficiency. Tasks such as image processing and object tracking are desired for long-duration spaceflight and extravehicular activities. In order to realize these applications in practice, enhancements to onboard processing are needed. ML applications require state-of-the-art processors and hardware accelerators, such as GPUs. However, GPUs are heavily susceptible to radiation-induced single-event effects (SEEs). Additionally, missions require a level of safety-criticality, which is unable to be met by existing commercial-off-the-shelf (COTS) GPUs. In an effort to create an end-to-end solution, this work aims to bridge ML-application development with device-architectural awareness to deliver a fault-aware implementation of the TensorFlow framework called Resilient TensorFlow (RTF). By building customized operations into the TensorFlow framework and employing them within the graph of various models, RTF demonstrates an ability to mask faults that occur during processing while minimizing overhead. Reducing faults during the processing of deep-learning applications brings the space computing industry closer to realizing onboard high-performance computing.
C1 [Garrett, Tyler; George, Alan D.] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
RP Garrett, T (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
EM tmg61@pitt.edu; alan.george@pitt.edu
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Bruhn FC, 2020, CEAS SPACE J, V12, P551, DOI 10.1007/s12567-020-00321-9
   Chen ZT, 2020, PROC INT SYMP SOFTW, P426, DOI 10.1109/ISSRE5003.2020.00047
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li GP, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P240, DOI 10.1109/SC.2016.20
   Mahmoud A., 2020, ARXIV PREPRINT ARXIV
   Oliveira DAG, 2014, IEEE T NUCL SCI, V61, P3115, DOI 10.1109/TNS.2014.2362014
   Oliveira DAG, 2014, INT SYM DEFEC FAU TO, P209, DOI 10.1109/DFT.2014.6962085
   Ozen E, 2019, ASIAN TEST SYMPOSIUM, P7, DOI 10.1109/ATS47505.2019.000-8
   Roffe S, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172799
   Rudolph D., 2014, PROC 28 ANN AIAAUSU
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan JWJ, 2012, INT CONFER PARA, P191
   Villa O, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P372, DOI 10.1145/3352460.3358307
   Wyrwas E. J., 2017, 2017 NEPP EL TECHN W, P26
NR 17
TC 3
Z9 3
U1 0
U2 3
PY 2021
BP 134
EP 142
DI 10.1109/SCC49971.2021.00021
UT WOS:000722592900014
DA 2023-11-16
ER

PT J
AU Basaklar, T
   Goksoy, AA
   Krishnakumar, A
   Gumussoy, S
   Ogras, UY
AF Basaklar, Toygun
   Goksoy, A. Alper
   Krishnakumar, Anish
   Gumussoy, Suat
   Ogras, Umit Y.
TI DTRL: Decision Tree-based Multi-Objective Reinforcement Learning for
   Runtime Task Scheduling in Domain-Specific System-on-Chips
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Domain-specific system-on-chip; task scheduling; reinforcement learning;
   decision trees; resource management; multi-objective optimization
ID GRAPHS; ALGORITHMS
AB Domain-specific systems-on-chip (DSSoCs) combine general-purpose processors and specialized hardware accelerators to improve performance and energy efficiency for a specific domain. The optimal allocation of tasks to processing elements (PEs) withminimal runtime overheads is crucial to achieving this potential. However, this problem remains challenging as prior approaches suffer from non-optimal scheduling decisions or significant runtime overheads. Moreover, existing techniques focus on a single optimization objective, such as maximizing performance. This work proposes DTRL, a decision-tree-based multi-objective reinforcement learning technique for runtime task scheduling in DSSoCs. DTRL trains a single global differentiable decision tree (DDT) policy that covers the entire objective space quantified by a preference vector. Our extensive experimental evaluations using our novel reinforcement learning environment demonstrate that DTRL captures the trade-off between execution time and power consumption, thereby generating a Pareto set of solutions using a single policy. Furthermore, comparison with state-of-the-art heuristic-, optimization-, and machine learning-based schedulers shows that DTRL achieves up to 9x higher performance and up to 3.08x reduction in energy consumption. The trained DDT policy achieves 120 ns inference latency on Xilinx Zynq ZCU102 FPGA at 1.2 GHz, resulting in negligible runtime overheads. Evaluation on the same hardware shows that DTRL achieves up to 16% higher performance than a state-of-the-art heuristic scheduler.
C1 [Basaklar, Toygun; Goksoy, A. Alper; Krishnakumar, Anish; Ogras, Umit Y.] Univ Wisconsin, 1415 Engn Dr, Madison, WI 53706 USA.
   [Gumussoy, Suat] Siemens Corp Technol, 755 Coll Rd E, Princeton, NJ 08540 USA.
RP Basaklar, T (corresponding author), Univ Wisconsin, 1415 Engn Dr, Madison, WI 53706 USA.
EM basaklar@wisc.edu; agoksoy@wisc.edu; anish.n.krishnakumar@wisc.edu;
   suat.gumussoy@siemens.com; uogras@wisc.edu
CR Abazari F, 2019, SIMUL MODEL PRACT TH, V93, P119, DOI 10.1016/j.simpat.2018.10.004
   Abdolmaleki Abbas, 2020, P 37 INT C MACHINE L, P11
   Amarnath A, 2021, IEEE COMPUT ARCHIT L, V20, P82, DOI 10.1109/LCA.2021.3085505
   Andrychowicz Marcin, 2021, INT C LEARN REPR, P1
   Arda SE, 2020, IEEE T COMPUT, V69, P1248, DOI 10.1109/TC.2020.2986963
   Basaklar T, 2022, Arxiv, DOI arXiv:2208.07914
   Behnamian J, 2014, APPL SOFT COMPUT, V21, P139, DOI 10.1016/j.asoc.2014.03.031
   Benini L, 2008, LECT NOTES COMPUT SC, V5366, P470, DOI 10.1007/978-3-540-89982-2_41
   Bittencourt LF, 2010, EUROMICRO WORKSHOP P, P27, DOI 10.1109/PDP.2010.56
   Bose Pradip, 2021, P INT WORKSH DOM SPE, P1
   Brockman G, 2016, Arxiv, DOI [arXiv:1606.01540, DOI 10.48550/ARXIV.1606.01540]
   Chen X, 2019, IEEE INT C INT ROBOT, P977, DOI [10.1109/iros40897.2019.8968092, 10.1109/IROS40897.2019.8968092]
   Chronaki K, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P329, DOI 10.1145/2751205.2751235
   Cplex I. I, 2009, INT BUSINESS MACHINE, V46, P157
   Ding ZH, 2021, Arxiv, DOI arXiv:2011.07553
   Frosst N, 2017, Arxiv, DOI arXiv:1711.09784
   futurenetworks.ieee, RF CONV SIGN COMP DR
   github, CEDR COMP INT EXT DS
   github, DS3 SIM
   Goksoy AA, 2022, IEEE EMBED SYST LETT, V14, P51, DOI 10.1109/LES.2021.3110426
   Green D., 2018, HETEROGENEOUS INTEGR
   HAMIDZADEH B, 1995, CONCURRENCY-PRACT EX, V7, P633, DOI 10.1002/cpe.4330070705
   Hayes CF, 2022, AUTON AGENT MULTI-AG, V36, DOI 10.1007/s10458-022-09552-y
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hu ZM, 2019, INT CON DISTR COMP S, P2037, DOI 10.1109/ICDCS.2019.00201
   Huang SY, 2022, Arxiv, DOI [arXiv:2006.14171, 10.32473/flairs.v35i.130584]
   HWANG JJ, 1989, SIAM J COMPUT, V18, P244, DOI 10.1137/0218016
   Jiang ED, 2021, TSINGHUA SCI TECHNOL, V26, P646, DOI 10.26599/TST.2021.9010007
   Krishnakumar A, 2020, IEEE T COMPUT AID D, V39, P4064, DOI 10.1109/TCAD.2020.3012861
   Kwok YK, 1996, IEEE T PARALL DISTR, V7, P506, DOI 10.1109/71.503776
   Kwok YK, 1999, ACM COMPUT SURV, V31, P406, DOI 10.1145/344588.344618
   Lipton ZC., 2018, QUEUE, V16, P31, DOI DOI 10.1145/3236386.3241340
   Liu CM, 2015, IEEE T SYST MAN CY-S, V45, P385, DOI 10.1109/TSMC.2014.2358639
   Mack J, 2023, ACM T EMBED COMPUT S, V22, DOI 10.1145/3529257
   Mao HZ, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P270, DOI 10.1145/3341302.3342080
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '16), P50, DOI 10.1145/3005745.3005750
   Moazzemi K, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358203
   Mossalam H, 2016, Arxiv, DOI arXiv:1610.02707
   Navon A., 2020, LEARNING PARETO FRON
   Pan XL, 2017, Arxiv, DOI arXiv:1704.03952
   Roijers DM, 2013, J ARTIF INTELL RES, V48, P67, DOI 10.1613/jair.3987
   Sakellariou R., 2004, Proceedings. 18th International Parallel and Distributed Processing Symposium
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Silva A, 2020, Arxiv, DOI arXiv:1903.09338
   Silva Andrew, 2020, INT C ARTIFICIAL INT, P1855
   Suárez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409
   Sung TT, 2022, IEEE ACCESS, V10, P98048, DOI 10.1109/ACCESS.2022.3203401
   Tong Z, 2020, NEURAL COMPUT APPL, V32, P5553, DOI 10.1007/s00521-019-04118-8
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Topcuoglu H, 1999, PROC HETER COMP WORK, P3, DOI 10.1109/HCW.1999.765092
   Torrado Ruben Rodriguez, 2018, IEEE C COMP INT GAM, P1
   ULLMAN JD, 1975, J COMPUT SYST SCI, V10, P384, DOI 10.1016/S0022-0000(75)80008-0
   Vega Augusto, 2021, DOSSA 3 WORKSH HPCA
   VELTMAN B, 1990, PARALLEL COMPUT, V16, P173, DOI 10.1016/0167-8191(90)90056-F
   Wang XJ, 2022, IEEE T MOBILE COMPUT, V21, P598, DOI 10.1109/TMC.2020.3012509
   xilinx, ZCU102 EV BOARD
   Xu Jie, 2020, INT C MACHINE LEARNI, P10607
   Yang H, 2008, ISOCC: 2008 INTERNATIONAL SOC DESIGN CONFERENCE, VOLS 1-3, P134, DOI 10.1109/SOCDC.2008.4815591
   Yang Runzhe, 2019, ADV NEURAL INFORM PR, V32, P14636
   Yu C, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3477600
   Zhou JY, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103282
   2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 62
TC 0
Z9 0
U1 0
U2 0
PD OCT
PY 2023
VL 22
IS 5
SU S
DI 10.1145/3609108
UT WOS:001074334300016
DA 2023-11-16
ER

PT J
AU Alioto, M
   De, V
   Marongiu, A
AF Alioto, Massimo
   De, Vivek
   Marongiu, Andrea
TI Energy-Quality Scalable Integrated Circuits and Systems: Continuing
   Energy Scaling in the Twilight of Moore's Law
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Energy-efficient integrated circuits; VLSI; machine learning; signal
   processing; architectures; software
ID VERIFYING QUANTITATIVE RELIABILITY; VLSI CIRCUITS; SPECIAL-ISSUE;
   APPROXIMATE; EFFICIENT; PROCESSOR; SRAM; AWARE; ARCHITECTURE; MANAGEMENT
AB This paper aims to take stock of recent advances in the field of energy-quality (EQ) scalable circuits and systems, as promising direction to continue the historical exponential energy downscaling under diminished returns from technology and voltage scaling. EQ-scalable systems explicitly trade off energy and quality at different levels of abstraction and sub-systems, dealing with "quality" as an explicit design requirement, and reducing energy whenever the application, the task, or the dataset allow quality degradation (e.g., vision and machine learning). A general framework for EQ-scalable systems based on the concept of quality slack is presented along with scalable architectures. A taxonomy of techniques to trade off energy and quality, a VLSI perspective, and possible quality control strategies are then discussed. The state of the art is surveyed to put the advances in its different sub-fields into a unitary perspective, emphasizing the on-going and prospective trends. At the component level, the generality of the EQ-scaling concept is shown through several examples, ranging from logic to analog circuits, to memories, data converters, and accelerators. Interesting implications of the joint adoption of EQ scaling and machine learning are also discussed, suggesting that their synergy gives ample room for further energy and performance improvements. From a level of abstraction viewpoint, EQ scaling is discussed from the circuit level to architectures, the hardware-software interface, the programming language, the compiler level, and run-time adaptation. Several case studies are discussed to put EQ scaling in the context of real-world applications.
C1 [Alioto, Massimo] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
   [De, Vivek] Intel Labs, Circuit Technol Res Grp, Hillsboro, OR 97124 USA.
   [Marongiu, Andrea] Univ Bologna, Dept Comp Sci & Engn, I-40126 Bologna, Italy.
RP Alioto, M (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
EM massimo.alioto@nus.edu.sg; vivek.de@intel.com; a.marongiu@unibo.it
CR Aamodt TM, 2008, ACM T EMBED COMPUT S, V7, DOI 10.1145/1347375.1347379
   Addabbo T, 2006, IEEE T CIRCUITS-I, V53, P326, DOI 10.1109/TCSI.2005.856670
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Alioto M., 2017, ENABLING INTERNET TH
   Alioto M, 2018, IEEE J EM SEL TOP C, V8, P361, DOI 10.1109/JETCAS.2018.2865783
   Alioto M, 2017, IEEE T CIRCUITS-I, V64, P2221, DOI 10.1109/TCSI.2017.2730678
   Alioto M, 2017, DES AUT TEST EUROPE, P127, DOI 10.23919/DATE.2017.7926970
   Alioto M, 2012, IEEE T CIRCUITS-II, V59, P849, DOI 10.1109/TCSII.2012.2231011
   Alioto M, 2012, IEEE T CIRCUITS-I, V59, P3, DOI 10.1109/TCSI.2011.2177004
   Almurib HAF, 2016, DES AUT TEST EUROPE, P660
   Alvarez A. B., IEEE J SOLID STATE C
   Alvarez AB, 2017, IEEE ASIAN SOLID STA, P241, DOI 10.1109/ASSCC.2017.8240261
   Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Aman M. N., IEEE INTERNET THINGS
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], 2015, P 25 GREAT LAK S VLS
   [Anonymous], 2010, P 7 INT C AUTONOMIC
   [Anonymous], 2017, ADV VIDEO CODING GEN
   [Anonymous], 2018, HIGH EFFICIENCY VIDE
   [Anonymous], 2011, DESIGN AUTOMATION TE
   [Anonymous], 2013, 2013 INT C HARDWARES
   Ansel J, 2011, INT SYM CODE GENER, P85, DOI 10.1109/CGO.2011.5764677
   Ansel J, 2009, ACM SIGPLAN NOTICES, V44, P38, DOI 10.1145/1543135.1542481
   Ariyarathna V, 2018, IEEE J EM SEL TOP C, V8, P466, DOI 10.1109/JETCAS.2018.2832177
   Babic Z, 2011, MICROPROCESS MICROSY, V35, P23, DOI 10.1016/j.micpro.2010.07.001
   Baek W, 2010, PLDI '10: PROCEEDINGS OF THE 2010 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P198, DOI 10.1145/1806596.1806620
   Barroso LA, 2007, COMPUTER, V40, P33, DOI 10.1109/MC.2007.443
   Behroozi S, 2018, IEEE J EM SEL TOP C, V8, P379, DOI 10.1109/JETCAS.2018.2856085
   Bengio, 2016, ABS160202830 CORR
   Bergman K., 2008, AIR FORCE RES LAB, V15
   Bolchini C, 2012, DES AUT TEST EUROPE, P1429
   Borkar S., 2011, P 48 DES AUT C DAC S
   Boston B, 2015, ACM SIGPLAN NOTICES, V50, P470, DOI [10.1145/2814270.2814301, 10.1145/2858965.2814301]
   Bowman KA, 2009, IEEE J SOLID-ST CIRC, V44, P49, DOI 10.1109/JSSC.2008.2007148
   Boyapati R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P666, DOI [10.1145/3140659.3080241, 10.1145/3079856.3080241]
   Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, 10.1017/cbo9780511804441]
   Campanoni S, 2015, INT SYM CODE GENER, P235, DOI 10.1109/CGO.2015.7054203
   Carbin M, 2016, COMMUN ACM, V59, P83, DOI 10.1145/2958738
   Carbin M, 2013, ACM SIGPLAN NOTICES, V48, P33, DOI [10.1145/2544173.2509546, 10.1145/2509136.2509546]
   Carbin M, 2012, ACM SIGPLAN NOTICES, V47, P169, DOI 10.1145/2345156.2254086
   Carroll TL, 2005, CHAOS, V15, DOI 10.1063/1.1827451
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Ceze L., ISAT DARPA WORKSH AC
   Chang G, 2018, IEEE J EM SEL TOP C, V8, P369, DOI 10.1109/JETCAS.2018.2864655
   Chang IJ, 2011, IEEE T CIRC SYST VID, V21, P101, DOI 10.1109/TCSVT.2011.2105550
   Chaudhuri S, 2011, P 19 ACM SIGSOFT S 1, P102
   Cheemalavagu S., 2005, IFIP VLSI-SoC 2005. IFIP WG 10.5 International Conference on Very Large Scale Integration System-on-Chip, P452
   Chen J., 2012, THESIS
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chippa V, 2011, DES AUT CON, P603
   Chippa VK, 2010, DES AUT CON, P555
   Cho M, 2011, IEEE T VLSI SYST, V19, P161, DOI 10.1109/TVLSI.2009.2031468
   Choudhury MR, 2008, DES AUT TEST EUROPE, P782
   Das S, 2009, IEEE J SOLID-ST CIRC, V44, P32, DOI 10.1109/JSSC.2008.2007145
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   de Kruijf M, 2010, CONF PROC INT SYMP C, P497, DOI 10.1145/1816038.1816026
   Desoli G, 2017, ISSCC DIG TECH PAP I, P238, DOI 10.1109/ISSCC.2017.7870349
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dreslinski RG, 2010, P IEEE, V98, P253, DOI 10.1109/JPROC.2009.2034764
   Du K, 2012, DES AUT TEST EUROPE, P1257
   Egilmez B, 2015, DES AUT TEST EUROPE, P1217
   Eldar Y, 2012, COMPRESSED SENSING T
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Fangzhe Chang, 2001, Cluster Computing, V4, P49, DOI 10.1023/A:1011464226688
   Farkhani H, 2018, IEEE J EM SEL TOP C, V8, P627, DOI 10.1109/JETCAS.2018.2813389
   Fick L, 2014, IEEE J SOLID-ST CIRC, V49, P2462, DOI 10.1109/JSSC.2014.2358589
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   Frustaci F, 2016, IEEE T VLSI SYST, V24, P2128, DOI 10.1109/TVLSI.2015.2503733
   Frustaci F, 2015, IEEE J SOLID-ST CIRC, V50, P1310, DOI 10.1109/JSSC.2015.2408332
   Gaines B.R., 1969, ADV INFORM SYSTEMS S, V2, P37, DOI 10.1109/12.954505
   George J, 2006, CASES 06 P 2006 INT, P158, DOI 10.1145/1176760.1176781
   Giterman R, 2018, IEEE J SOLID-ST CIRC, V53, P2136, DOI 10.1109/JSSC.2018.2820145
   Graillat S., 2016, P 17 INT S SCI COMP, P98
   Guo YX, 2013, IEEE T PARALL DISTR, V24, P1149, DOI 10.1109/TPDS.2012.201
   Halpern M, 2016, INT S HIGH PERF COMP, P64, DOI 10.1109/HPCA.2016.7446054
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2016, ICLR
   Harpe P., 2015, HIGH PERFORMANCE AD
   Hegde R, 2004, IEEE J SOLID-ST CIRC, V39, P388, DOI 10.1109/JSSC.2003.821775
   Hegde R, 2001, IEEE T VLSI SYST, V9, P813, DOI 10.1109/92.974895
   Hegde R., 1999, Proceedings. 1999 International Symposium on Low Power Electronics and Design (Cat. No.99TH8477), P30, DOI 10.1109/LPE.1999.799405
   HERLIHY M, 1993, CONF PROC INT SYMP C, P289, DOI 10.1145/173682.165164
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Iandola Forrest N., 2016, P IEEE C COMPUTER VI
   Jolliffe I. T., 2002, CHEMOMETR INTELL LAB, V2nd, DOI [10.1016/0169-7439(87)80084-9, DOI 10.1016/0169-7439(87)80084-9]
   Kahng AB, 2012, DES AUT CON, P820
   Karam LJ, 2009, IEEE SIGNAL PROC MAG, V26, P38, DOI 10.1109/MSP.2009.934113
   Kaul H., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P182, DOI 10.1109/ISSCC.2012.6176987
   Kerman M. C., 2009, EVENT DETECTION CHAL
   Khayatzadeh M, 2016, ISSCC DIG TECH PAP I, V59, P310, DOI 10.1109/ISSCC.2016.7418031
   Khudia DS, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P554, DOI 10.1145/2749469.2750371
   Kim SH, 2011, IEEE T COMPUT AID D, V30, P1163, DOI 10.1109/TCAD.2011.2126573
   Kim Y, 2015, IEEE T VLSI SYST, V23, P2733, DOI 10.1109/TVLSI.2014.2365458
   Koomey JG, 2011, IEEE ANN HIST COMPUT, V33, P46, DOI 10.1109/MAHC.2010.28
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kurdahi FJ, 2010, IEEE T VLSI SYST, V18, P852, DOI 10.1109/TVLSI.2009.2016665
   Kwon J, 2012, IEEE T CIRCUITS-I, V59, P2275, DOI 10.1109/TCSI.2012.2185335
   Kyaw K Y, 2010, IEEE INT C ELECT DEV, DOI DOI 10.1109/EDSSC.2010.5713751
   Lam Michael O, 2013, P 27 INT ACM C SUPER, P369
   Le Callet P, 2003, IEEE IMAGE PROC, P437
   Liu C., 2014, P DES AUT TEST EUR C, P1, DOI DOI 10.7873/DATE.2014.108
   Lu SL, 2004, COMPUTER, V37, P67, DOI 10.1109/MC.2004.1274006
   Ludwig JT, 1996, IEEE J SOLID-ST CIRC, V31, P395, DOI 10.1109/4.494201
   Mach S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351816
   Madisetti V., 2009, DIGIT SIGNAL PROCESS
   Maes R., 2013, PHYS UNCLONABLE FUNC
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Maier D, 2018, INT SYM CODE GENER, P290, DOI 10.1145/3168814
   Makhzan MA, 2009, IEEE T VLSI SYST, V17, P827, DOI 10.1109/TVLSI.2009.2016714
   Malladi KT, 2012, CONF PROC INT SYMP C, P37, DOI 10.1109/ISCA.2012.6237004
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Mangharam R., 2011, Proceedings of the 2011 IEEE 32nd Real-Time Systems Symposium (RTSS 2011), P47, DOI 10.1109/RTSS.2011.41
   Medhat R, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126519
   Menezes A, 1996, HDB APPL CRYPTOGRAPH
   Meng JY, 2009, INT PARALL DISTRIB P, P107
   Miao J., 2013, P DATE, P1
   Miao J, 2012, ICCAD-IEEE ACM INT, P728
   Misailovic S., 2010, P 32 ACMIEEE INT C S, V1, P25, DOI DOI 10.1145/1806799.1806808
   Misailovic S, 2014, ACM SIGPLAN NOTICES, V49, P309, DOI [10.1145/2714064.2660231, 10.1145/10.1145/2660193.2660231]
   Misailovic S, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465790
   Misailovic S, 2011, LECT NOTES COMPUT SC, V6887, P316, DOI 10.1007/978-3-642-23702-7_24
   Mohammed A, 2018, IEEE J EM SEL TOP C, V8, P603, DOI 10.1109/JETCAS.2018.2830971
   Mohapatra D, 2009, I SYMPOS LOW POWER E, P195
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Moskvitch K., 2018, QUANTAMAGAZINE
   Murmann B, ADC PERFORMANCE SURV
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Na Gong, 2012, IEEE Transactions on Circuits and Systems II: Express Briefs, V59, P883, DOI 10.1109/TCSII.2012.2231018
   Narayanamoorthy S, 2015, IEEE T VLSI SYST, V23, P1180, DOI 10.1109/TVLSI.2014.2333366
   Nasrabadi N.M., 2007, PATTERN RECOGN, V16, DOI 10.1117/1.2819119
   Nelson M., 1996, DATA COMPRESSION BOO
   Ho NM, 2017, ASIA S PACIF DES AUT, P63, DOI 10.1109/ASPDAC.2017.7858297
   Nii K, 2008, SYMP VLSI CIRCUITS, P212, DOI 10.1109/VLSIC.2008.4586011
   Ning Zhu, 2011, 2011 International SoC Design Conference (ISOCC 2011), P393, DOI 10.1109/ISOCC.2011.6138614
   Nogues E., IEEE T EMERG TOPICS
   Okada K, 2011, DIGITALLY-ASSISTED ANALOG AND RF CMOS CIRCUIT DESIGN FOR SOFTWARE-DEFINED RADIO, P1, DOI 10.1007/978-1-4419-8514-9
   Papagiannopoulou D, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126556
   Park J, 2010, IEEE T VLSI SYST, V18, P787, DOI 10.1109/TVLSI.2009.2016839
   Parlitz U., 1999, 1999 European Control Conference (ECC). Proceedings, P4637
   Pennebaker W. B., 1993, JPEG STILL IMAGE DAT
   Poppelbaum W., 1967, P NOV 14 16 1967 FAL
   Powers D. M., 2011, EVALUATION PRECISION, DOI 10.48550/arXiv.2010.16061
   Preskill J., 2018, QUANTUM COMPUTING IN
   Rabaey J. M., 2011, 2011 Symposium on VLSI Circuits. Digest of Technical Papers, P6
   Rahimi A, 2015, DES AUT CON, DOI 10.1145/2744769.2744915
   Rahimi A, 2013, DES AUT TEST EUROPE, P541
   Rahimi A, 2014, IEEE J EM SEL TOP C, V4, P216, DOI 10.1109/JETCAS.2014.2315883
   Rajwar R, 2001, INT SYMP MICROARCH, P294, DOI 10.1109/MICRO.2001.991127
   Ranjan A., 2012, P DAC
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Renganarayana L., 2012, P 2012 ACM WORKSH RE, P41, DOI DOI 10.1145/2414729.2414737
   Rinard M., 2006, P 20 ANN INT C SUPER, P324
   Ringenburg M, 2015, ACM SIGPLAN NOTICES, V50, P399, DOI [10.1145/2694344.2694365, 10.1145/2775054.2694365]
   Rovere G, 2018, IEEE J EM SEL TOP C, V8, P543, DOI 10.1109/JETCAS.2018.2828505
   Rubio-González C, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503296
   Rusci M, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P314, DOI 10.1145/3203217.3204463
   Samadi M, 2014, ACM SIGPLAN NOTICES, V49, P35, DOI 10.1145/2541940.2541948
   Sampson A., 2016, P WORKSH APPR COMP S, P1
   Sampson A., 2015, TECH REP
   Sampson A, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P164
   Schulte MJ, 2000, IEEE T COMPUT, V49, P387, DOI 10.1109/12.859535
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Sinha A., 1999, Twelfth Annual IEEE International ASIC/SOC Conference (Cat. No.99TH8454), P327, DOI 10.1109/ASIC.1999.806528
   Sorber J, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P161
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Tagliavini G, 2018, IEEE T COMPUT AID D, V37, P982, DOI 10.1109/TCAD.2016.2633474
   Tagliavini G, 2015, IEEE COMP SOC ANN, P280, DOI 10.1109/ISVLSI.2015.64
   Tahan Oussama, 2012, Architecture of Computing Systems - ARCS 2012. Proceedings 25th International Conference, P25, DOI 10.1007/978-3-642-28293-5_3
   Tarkoma S, 2014, SMARTPHONE ENERGY CONSUMPTION: MODELING AND OPTIMIZATION, P1, DOI 10.1017/CBO9781107326279
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   Van De Plassche R., 2003, CMOS INTEGRATED ANAL
   Vassiliadis V., 2015, P 12 ACM INT C COMP
   Venkataramani S, 2013, DES AUT TEST EUROPE, P1367
   Venkataramani S, 2012, DES AUT CON, P796
   Verma AK, 2008, DES AUT TEST EUROPE, P1092
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weis C., 2018, P IEEE INT S CIRC SY, P1
   Wells JW, 2018, IEEE J EM SEL TOP C, V8, P578, DOI 10.1109/JETCAS.2018.2859218
   Wentzloff D. D., LOW POWER RADIO SURV
   Weste N. H. E., 2011, CMOS VLSI DESIGN CIR
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xu JW, 2018, IEEE J EM SEL TOP C, V8, P616, DOI 10.1109/JETCAS.2018.2834140
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
   Yalcin G, 2013, DES AUT TEST EUROPE, P220
   Yip M., 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P190, DOI 10.1109/ISSCC.2011.5746277
   Zhang YQ, 2016, ISSCC DIG TECH PAP I, V59, P160, DOI 10.1109/ISSCC.2016.7417956
   Zhu N, 2009, PROCEEDINGS OF THE 2009 12TH INTERNATIONAL SYMPOSIUM ON INTEGRATED CIRCUITS (ISIC 2009), P400
   Zhu N, 2010, IEEE T VLSI SYST, V18, P1225, DOI 10.1109/TVLSI.2009.2020591
   Zhu ZA, 2012, POPL 12: PROCEEDINGS OF THE 39TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P441
   Zimmer B, 2016, IEEE J SOLID-ST CIRC, V51, P930, DOI 10.1109/JSSC.2016.2519386
NR 196
TC 25
Z9 25
U1 1
U2 11
PD DEC
PY 2018
VL 8
IS 4
BP 653
EP 678
DI 10.1109/JETCAS.2018.2881461
UT WOS:000454224200001
DA 2023-11-16
ER

PT J
AU Wang, WJ
   Caselle, M
   Boltz, T
   Blomley, E
   Brosi, M
   Dritschler, T
   Ebersoldt, A
   Kopmann, A
   Garcia, AS
   Schreiber, P
   Bründermann, E
   Weber, M
   Müller, AS
   Fang, YW
AF Wang, Weija
   Caselle, Michele
   Boltz, Tobias
   Blomley, Edmund
   Brosi, Miriam
   Dritschler, Timo
   Ebersoldt, Andreas
   Kopmann, Andreas
   Garcia, Andrea Santamaria
   Schreiber, Patrick
   Bruendermann, Erik
   Weber, Marc
   Mueller, Anke-Susanne
   Fang, Yangwang
TI Accelerated Deep Reinforcement Learning for Fast Feedback of Beam
   Dynamics at KARA
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article; Proceedings Paper
CT 22nd IEEE-NPSS Real Time Conference (RT) on Computing Applications in
   Nuclear and Plasma Sciences
CY OCT, 2020
CL ELECTR NETWORK
DE Hardware; Radio frequency; Real-time systems; Detectors; Control
   systems; Reinforcement learning; Perturbation methods; Artificial
   intelligence; beam diagnostics; control systems; machine learning;
   particle accelerators; real-time control; reinforcement learning (RL)
AB Coherent synchrotron radiation (CSR) is generated when the electron bunch length is in the order of the magnitude of the wavelength of the emitted radiation. The self-interaction of short electron bunches with their own electromagnetic fields changes the longitudinal beam dynamics significantly. Above a certain current threshold, the micro-bunching instability develops, characterized by the appearance of distinguishable substructures in the longitudinal phase space of the bunch. To stabilize the CSR emission, a real-time feedback control loop based on reinforcement learning (RL) is proposed. Informed by the available THz diagnostics, the feedback is designed to act on the radio frequency (RF) system of the storage ring to mitigate the micro-bunching dynamics. To satisfy low-latency requirements given by the longitudinal beam dynamics, the RL controller has been implemented on hardware (FPGA). In this article, a real-time feedback loop architecture and its performance is presented and compared with a software implementation using Keras-RL on CPU/GPU. The results obtained with the CSR simulation Inovesa demonstrate that the functionality of both platforms is equivalent. The training performance of the hardware implementation is similar to software solution, while it outperforms the Keras-RL implementation by an order of magnitude. The presented RL hardware controller is considered as an essential platform for the development of intelligent CSR control systems.
C1 [Wang, Weija; Caselle, Michele; Dritschler, Timo; Ebersoldt, Andreas; Kopmann, Andreas] Karlsruhe Inst Technol KIT, Inst Data Proc & Elect, D-76344 Eggenstein Leopoldshafen, Germany.
   [Boltz, Tobias; Blomley, Edmund; Brosi, Miriam; Bruendermann, Erik; Mueller, Anke-Susanne] Karlsruhe Inst Technol KIT, Inst Beam Phys & Technol, D-76344 Eggenstein Leopoldshafen, Germany.
   [Garcia, Andrea Santamaria; Schreiber, Patrick] Karlsruhe Inst Technol KIT, Lab Applicat Synchrotron Radiat, D-76131 Karlsruhe, Germany.
   [Weber, Marc] Karlsruhe Inst Technol KIT, Div Phys & Math 5, D-76344 Eggenstein Leopoldshafen, Germany.
   [Fang, Yangwang] Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710072, Peoples R China.
RP Caselle, M (corresponding author), Karlsruhe Inst Technol KIT, Inst Data Proc & Elect, D-76344 Eggenstein Leopoldshafen, Germany.
EM michele.caselle@kit.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2016, ZYNQ ULTR MPSOC PROD
   [Anonymous], 2012, TERAHERTZ TECHNIQUES
   Boltz T, 2019, P 10 INT PART ACC C, P104
   Brosi M, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.110701
   Caselle M, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/03/C03015
   Chollet F., 2015, KERAS
   Fu Y., 2017, WP486 XIL
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lillicrap T.P., 2016, CONTINUOUS CONTROL D
   Müller AS, 2010, REV ACCEL SCI TECH, V3, P165, DOI 10.1142/S1793626810000427
   Muller A.-S, 2017, J INSTRUM, V12
   Schönfeldt P, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.030704
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Schulman John, 2017, ARXIV170706347, DOI DOI 10.48550/ARXIV.1707.06347
   Shoji Y, 2008, P C P, V806233
   Steinmann J. L, 2019, DIAGNOSTICS SHORT EL
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Teytelman D, 2019, IGP12 720F
NR 20
TC 3
Z9 3
U1 2
U2 10
PD AUG
PY 2021
VL 68
IS 8
BP 1794
EP 1800
DI 10.1109/TNS.2021.3084515
PN 1-3
UT WOS:000687247300037
DA 2023-11-16
ER

PT J
AU Senoo, T
   Jinguji, A
   Kuramochi, R
   Nakahara, H
AF Senoo, Takeshi
   Jinguji, Akira
   Kuramochi, Ryosuke
   Nakahara, Hiroki
TI Multilayer Perceptron Training Accelerator Using Systolic Array
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
DT Article
DE neural network; training accelerator; multilayer perceptron; machine
   learning; intrusion detection system
AB Multilayer perceptron (MLP) is a basic neural network model that is used in practical industrial applications, such as network in-trusion detection (NID) systems. It is also used as a building block in newer models, such as gMLP. Currently, there is a demand for fast training in NID and other areas. However, in training with numerous GPUs, the problems of power consumption and long training times arise. Many of the latest deep neural network (DNN) models and MLPs are trained using a back -propagation algorithm which transmits an error gradient from the output layer to the input layer such that in the sequential computation, the next input cannot be processed until the weights of all layers are updated from the last layer. This is known as backward locking. In this study, a weight parameter update mechanism is proposed with time delays that can accom-modate the weight update delay to allow simultaneous forward and back-ward computation. To this end, a one-dimensional systolic array structure was designed on a Xilinx U50 Alveo FPGA card in which each layer of the MLP is assigned to a processing element (PE). The time-delay backpropa-gation algorithm executes all layers in parallel, and transfers data between layers in a pipeline. Compared to the Intel Core i9 CPU and NVIDIA RTX 3090 GPU, it is 3 times faster than the CPU and 2.5 times faster than the GPU. The processing speed per power consumption is 11.5 times better than that of the CPU and 21.4 times better than that of the GPU. From these results, it is concluded that a training accelerator on an FPGA can achieve high speed and energy efficiency.
C1 [Senoo, Takeshi; Jinguji, Akira; Kuramochi, Ryosuke; Nakahara, Hiroki] Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
RP Senoo, T (corresponding author), Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
EM senoo@reconf.ict.e.titech.ac.jp; jinguji@reconf.ict.e.titech.ac.jp;
   kuramochi@reconf.ict.e.titech.ac.jp; nakahara@ict.e.titech.ac.jp
CR Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Carreira-Perpiñán MA, 2014, JMLR WORKSH CONF PRO, V33, P10
   Czarnecki W.M., 2017, ARXIV
   Geng T, 2018, ANN IEEE SYM FIELD P, P81, DOI 10.1109/FCCM.2018.00021
   Gironés RG, 2005, J VLSI SIG PROC SYST, V40, P189, DOI 10.1007/s11265-005-4961-3
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   HUO ZY, 2018, PR MACH LEARN RES, V80
   Isakov M, 2018, I C FIELD PROG LOGIC, P55, DOI 10.1109/FPL.2018.00017
   Jaderberg Max, 2016, ARXIV
   Liu H, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.250502
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Nakahara H, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P168, DOI 10.1109/FPT.2017.8280135
   Omondi A. R., 2006, FPGA IMPLEMENTATIONS, V365
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Senoo T., 2021, APCCAS, P173
   Taylor G, 2016, PR MACH LEARN RES, V48
   Umuroglu Y, 2020, I C FIELD PROG LOGIC, P291, DOI 10.1109/FPL50879.2020.00055
   Yadan O., 2015, ARXIV
   Zhao W., 2016, IEEE 27 INT C APPL S
NR 20
TC 1
Z9 1
U1 0
U2 2
PD DEC
PY 2022
VL E105D
IS 12
BP 2048
EP 2056
DI 10.1587/transinf.2022PAP0003
UT WOS:000892257200007
DA 2023-11-16
ER

PT J
AU Feng, JH
   Qin, DT
   Liu, YG
   Wang, X
   Lv, H
AF Feng, Jihao
   Qin, Datong
   Liu, Yonggang
   Wang, Xin
   Lv, Hao
TI Pseudo-spectral optimization and model predictive control of vehicle
   shift process with dual clutch transmission
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF
   MECHANICAL ENGINEERING SCIENCE
DT Article
DE Dual-clutch transmission; shifting control; pseudo-spectral
   optimization; trajectory planning; model predictive control
ID MICRO-SLIP CONTROL; CONTROL STRATEGY; GEAR SHIFT; ENGAGEMENT
AB To improve the shift quality of dual clutch transmission (DCT) vehicles and reduce the jerk and sliding friction in the shift process, a real-time planning of clutch optimal engagement trajectory and control method in the shift process is proposed. This method combines pseudo-spectral optimization, machine learning, and model predictive control. First, considering the jerk, sliding friction work, and shift time as the optimization indices, the adaptive pseudo-spectral method is employed to optimize the engagement trajectory of the clutch during the shift process. Based on the optimal trajectory data set, a gradient boosting decision tree-based real-time planning method for the clutch target engagement trajectory is proposed. Second, a model predictive control strategy for the shift process is proposed based on the DCT system model to track the optimal target trajectory in real-time. Simulations and experiments reveal that the proposed target engagement trajectory planning method can plan the clutch target engagement trajectory for various accelerator pedal openings and initial clutch speed states in real-time, and the proposed model predictive control method can accurately track the target trajectory. Compared with the original vehicle strategy, under 35% and 65% accelerator pedal opening, the maximum absolute value of jerk produced by the proposed strategy was reduced by 31.06% and 31.46%, respectively, and the sliding friction work was reduced by 22.87% and 23.24%, respectively. The shift times of the proposed strategy under 35% and 65% accelerator pedal openings were 19.12% and 20.69% lower than that of the original vehicle strategy, respectively.
C1 [Feng, Jihao; Qin, Datong; Liu, Yonggang] Chongqing Univ, State Key Lab Mech Transmiss, Chongqing, Peoples R China.
   [Feng, Jihao; Qin, Datong; Liu, Yonggang] Chongqing Univ, Coll Mech & Vehicle Engn, Chongqing, Peoples R China.
   [Wang, Xin; Lv, Hao] Chongqing Changan Automobile Co Ltd, Chongqing, Peoples R China.
   [Qin, Datong] Chongqing Univ, State Key Lab Mech Transmiss, A Campus, Chongqing 400044, Peoples R China.
RP Qin, DT (corresponding author), Chongqing Univ, State Key Lab Mech Transmiss, A Campus, Chongqing 400044, Peoples R China.
EM dtqin@cqu.edu.cn
CR Coric M, 2017, J DYN SYST-T ASME, V139, DOI 10.1115/1.4035403
   Darby CL, 2011, J SPACECRAFT ROCKETS, V48, P433, DOI 10.2514/1.52136
   Ding Z, 2021, MECHATRONICS, V73, DOI 10.1016/j.mechatronics.2020.102466
   Feng JH, 2021, MEASUREMENT, V181, DOI 10.1016/j.measurement.2021.109609
   Gao AY, 2020, IEEE ACCESS, V8, P60428, DOI 10.1109/ACCESS.2020.2983613
   Garg D, 2010, AUTOMATICA, V46, P1843, DOI 10.1016/j.automatica.2010.06.048
   Kim S, 2020, IEEE-ASME T MECH, V25, P1578, DOI 10.1109/TMECH.2020.2980120
   Kim S, 2018, MECH MACH THEORY, V121, P633, DOI 10.1016/j.mechmachtheory.2017.11.008
   Kim S, 2017, MECH MACH THEORY, V113, P109, DOI 10.1016/j.mechmachtheory.2017.02.013
   Li AT, 2022, MECH MACH THEORY, V173, DOI 10.1016/j.mechmachtheory.2022.104804
   Li GQ, 2018, MECH SYST SIGNAL PR, V103, P23, DOI 10.1016/j.ymssp.2017.09.040
   Liu JK, 2018, P I MECH ENG D-J AUT, V232, P651, DOI 10.1177/0954407017704783
   Liu QF, 2020, IEEE T VEH TECHNOL, V69, P1055, DOI 10.1109/TVT.2019.2949469
   Mishra KD, 2017, CONTROL ENG PRACT, V65, P100, DOI 10.1016/j.conengprac.2017.05.007
   Oh JJ, 2017, IEEE T CONTR SYST T, V25, P1856, DOI 10.1109/TCST.2016.2620421
   Ouyang TC, 2020, APPL MATH MODEL, V85, P157, DOI 10.1016/j.apm.2020.03.019
   Song XY, 2011, J DYN SYST-T ASME, V133, DOI 10.1115/1.4003797
   Tan SQ, 2021, SAE INT J COMMER VEH, V14, P173, DOI 10.4271/02-14-02-0013
   Tongli Lu, 2019, Proceedings of the Institution of Mechanical Engineers, Part K (Journal of Multi-Body Dynamics), V233, P43, DOI 10.1177/1464419318785422
   van Berkel K, 2014, CONTROL ENG PRACT, V22, P57, DOI 10.1016/j.conengprac.2013.09.010
   Wang SH, 2019, MECH SYST SIGNAL PR, V130, P164, DOI 10.1016/j.ymssp.2019.05.008
   Wang WC, 2020, VEHICLE SYST DYN, V58, P604, DOI 10.1080/00423114.2019.1594316
   Wei WP, 2022, IEEE T CONTR SYST T, V30, P368, DOI 10.1109/TCST.2021.3058330
   Wu GQ, 2023, SAE INT J VEH DYN ST, V7, P3, DOI 10.4271/10-07-01-0001
   Wu JL, 2017, APPL MATH MODEL, V51, P1, DOI 10.1016/j.apm.2017.06.030
   Yahagi S, 2020, P I MECH ENG D-J AUT, V234, P2279, DOI 10.1177/0954407020907257
   Zhang CS, 2017, EXPERT SYST APPL, V82, P128, DOI 10.1016/j.eswa.2017.04.003
   ZHAO ZG, 2014, MATH PROBL ENG, V2014
   Zhao ZG, 2016, MECH SYST SIGNAL PR, V75, P413, DOI 10.1016/j.ymssp.2015.12.027
   Zhou B, 2017, P I MECH ENG K-J MUL, V231, P750, DOI 10.1177/1464419317699308
NR 30
TC 0
Z9 0
U1 11
U2 17
PD AUG
PY 2023
VL 237
IS 16
BP 3789
EP 3806
DI 10.1177/09544062221148040
EA JAN 2023
UT WOS:000920352000001
DA 2023-11-16
ER

PT C
AU Nicholas, GS
   Gui, YT
   Saqib, F
AF Nicholas, Geraldine Shirley
   Gui, Yutian
   Saqib, Fareena
GP IEEE
TI A Survey and Analysis on SoC Platform Security in ARM, Intel and RISC-V
   Architecture
SO 2020 IEEE 63RD INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT 63rd IEEE International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY APR 09-12, 2020
CL ELECTR NETWORK
DE RISC-V; ARM TrustZone; Intel SGX; Trusted Execution Environment (TEE)
ID BOOT
AB Modern heterogeneous computing including IoT devices and Networks deliver optimized and enhanced performance along with high speed but rely on an increased number of components to achieve the desired results. The design productivity for hardware accelerators with machine learning platforms for various application has significant progress on system-on-chip architectures. Most of these technologies provide the desired performance, however, there is always a tradeoff between security and performance. The major role in developing frameworks for hardware security attacks depends on the IP and system architecture. RISC-V provides a platform for custom implementation of security extensions when compared to other traditional architectures. This paper provides a brief survey of different hardware/ software security attacks and summarizes a comparison of security features in RISC-V and other traditional architectures along with security extensions that can be achieved by RISC-V.
C1 [Nicholas, Geraldine Shirley; Gui, Yutian; Saqib, Fareena] Univ N Carolina, Dept Elect & Comp Engn, Charlotte, NC 28223 USA.
RP Nicholas, GS (corresponding author), Univ N Carolina, Dept Elect & Comp Engn, Charlotte, NC 28223 USA.
EM gnichola@uncc.edu; ygui@uncc.edu; fasqib@uncc.edu
CR [Anonymous], 2017, TRUSTZONE TECHN ARMV
   Benhani E, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P108, DOI 10.1109/SOCC.2017.8226018
   Costan V, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P857
   Costan Victor, 2016, IACR CRYPTOL EPRINT, V2016, P1
   Hwang D, 2019, DES AUT TEST EUROPE, P740, DOI [10.23919/DATE.2019.8715277, 10.23919/date.2019.8715277]
   Intel Corporation, 2014, SOFTW GUARD EXT PROG
   Lebedev I, 2018, P IEEE COMPUT SECUR, P46, DOI 10.1109/CSF.2018.00011
   Lee Dayeol, 2019, ABS190710119 ARXIV
   Mukhtar MA, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P299, DOI [10.1109/C-CODE.2019.8680982, 10.1109/c-code.2019.8680982]
   Sabet M, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P57, DOI 10.1109/Trustcom.2015.357
   Schwarz Michael, 2017, Detection of Intrusions and Malware, and Vulnerability Assessment. 14th International Conference, DIMVA 2017. Proceedings: LNCS 10327, P3, DOI 10.1007/978-3-319-60876-1_1
   Siddiqui AS, 2019, INT WORKSHOP MICROPR, P56, DOI 10.1109/MTV48867.2019.00019
   Siddiqui AS, 2019, 2019 IEEE 4TH INTERNATIONAL VERIFICATION AND SECURITY WORKSHOP (IVSW 2019), P37, DOI [10.1109/ivsw.2019.8854418, 10.1109/IVSW.2019.8854418]
   Hoang TT, 2020, IEEE ACCESS, V8, P74015, DOI 10.1109/ACCESS.2020.2987617
   Waterman Andrew, 2014, UCBEECS201454
   Yasin M, 2017, IEEE INT CONF VLSI, P237
   Zhang N., 2016, IACR CRYPTOLOGY EPRI, V2016, P980
NR 17
TC 4
Z9 4
U1 3
U2 9
PY 2020
BP 718
EP 721
DI 10.1109/mwscas48704.2020.9184573
UT WOS:000776673800176
DA 2023-11-16
ER

PT J
AU Titov, M
AF Titov, M.
TI Next frontiers in particle physics detectors: INSTR2020 summary and a
   look into the future
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Accelerator Applications; Instrumentation for particle accelerators and
   storage rings high energy (linear accelerators, synchrotrons)
ID TIMING PERFORMANCE; CHAMBER; DAMAGE; TPC
AB The physics goals of high luminosity particle accelerators, from LHC to HL-LHC and to the next generation of lepton colliders, have set quite stringent constraints on the future needs at the Instrumentation Frontier. Many technologies are reaching their sensitivity limit and new approaches need to be developed to overcome the currently irreducible technological challenges. The detrimental effect of the material budget and power consumption represents a very serious concern for a high-precision silicon vertex and tracking detectors. One of the most promising areas is CMOS sensors offering low mass and potentially radiation-hard technology for the future proton-proton and electron-positron colliders, intensity frontier and heavy-ion experiments. MPGDs have become a well-established technique in the fertile field of gaseous detectors; these will remain the primary choice whenever the large-area coverage with low material budget is required. Vacuum tube technology is inherently fast and new developments include advances in microchannel plates for photomultipliers with a potential for a picosecond-time resolution in large systems. Several novel concepts of picosecond-timing detectors will have numerous powerful applications in particle identification, pile-up rejection and event reconstruction, and serve numerous scientific goals. The story of modern calorimetry is a textbook example of physics research driving the development of an experimental method. Silicon photomultipliers have seen a rapid progress in the last decade, becoming the standard solution for scintillator-based devices. The integration of advanced electronics and data transmission functionalities plays an increasingly important role and needs to be addressed. Bringing the modern algorithmic advances from the field of machine learning from offline applications to online operations and trigger systems is another major challenge. The timescales spanned by future projects in particle physics, ranging from few years to many decades, constitute a challenge in itself, in addition to the complexity and diversity of the required accelerator and detector R&D. This paper summarizes advances and recent trends in the instrumentation techniques for particle physics experiments, largely based on the presentations given at the International Conference "Instrumentation for Colliding Beam Physics" (INSTR-20), held at BINP Novosibirsk, Russia, from 24 to 28 February, 2020.
C1 [Titov, M.] Commissariat Energie Atom & Energies Alternative, DRF, IRFU, DPHP, F-91191 Gif Sur Yvette, France.
RP Titov, M (corresponding author), Commissariat Energie Atom & Energies Alternative, DRF, IRFU, DPHP, F-91191 Gif Sur Yvette, France.
EM maxim.titov@cea.fr
CR Abbon P, 2007, NUCL INSTRUM METH A, V577, P455, DOI 10.1016/j.nima.2007.03.026
   Abi B, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/t08008
   Achasov MN, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07005
   Adams B., ARXIV160301843
   Adams BW, 2015, NUCL INSTRUM METH A, V795, P1, DOI 10.1016/j.nima.2015.05.027
   Ahmed Z., 2019, CPAD INSTR FRONT WOR
   Aimard B, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/11/P11003
   Akchurin N, 2017, NUCL INSTRUM METH A, V859, P31, DOI 10.1016/j.nima.2017.03.065
   Akimov D., 2020, COMMUNICATION   0224
   Albertsson K, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/2/022008
   Aleksa M., 2018, CERNOPEN2018006
   Alexopoulos T, 2011, NUCL INSTRUM METH A, V640, P110, DOI 10.1016/j.nima.2011.03.025
   ALICE collaboration, ALICEPUBLIC2018003
   Allport P, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/05/C05005
   Angelico E, 2020, REV SCI INSTRUM, V91, DOI 10.1063/5.0008606
   Angelico E, 2017, NUCL INSTRUM METH A, V846, P75, DOI 10.1016/j.nima.2016.12.008
   Arazi L., 2020, COMMUNICATION   0224
   Arogancia DC, 2009, NUCL INSTRUM METH A, V602, P403, DOI 10.1016/j.nima.2009.01.014
   Attié D, 2017, NUCL INSTRUM METH A, V856, P109, DOI 10.1016/j.nima.2016.11.002
   Bambade P., ARXIV190301629
   Baracchini E, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07036
   Belias A., 2020, COMMUNICATION   0224
   Bencivenni G, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09034
   Blondel A., ARXIV190912245
   Boldyrev A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09030
   Brau JE, 2010, ANNU REV NUCL PART S, V60, P615, DOI 10.1146/annurev.nucl.012809.104449
   Brunbauer F., 2020, COMMUNICATION   0224
   Budnev N., 2020, P INT C INSTR COLL B
   CALICE collaboration, ARXIV12125127 CALICE
   CALICE collaboration, 2014, JINST, V9
   CALICE collaboration, 2010, JINST, V5
   Calzaferri S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09040
   Cartiglia N, 2019, NUCL INSTRUM METH A, V924, P350, DOI 10.1016/j.nima.2018.09.157
   Casse G, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/05/C05057
   Cavallari F, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/03/C03041
   Ceresa D, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/01/C01054
   Chadeeva M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07014
   Chefdeville M, 2016, NUCL INSTRUM METH A, V824, P510, DOI 10.1016/j.nima.2015.11.073
   CMS Collaboration, 2017, PHASE 2 UPGRADE CMS, DOI [DOI 10.17181/CERN.IV8M.1JY2, 10.17181/CERN.IV8M.1JY2]
   Credo T, 2004, IEEE NUCL SCI CONF R, P586
   Croci G, 2010, J INSTRUM, V5, DOI 10.1088/1748-0221/5/03/P03001
   Dasgupta S., 2020, COMMUNICATION   0224
   de Oliveira R., 2020, COMMUNICATION   0224
   Deptuch G., 2003, ARXIV13074301
   Di Mauro A, 2020, NUCL INSTRUM METH A, V952, DOI 10.1016/j.nima.2019.04.078
   Dittmeier S, 2016, NUCL INSTRUM METH A, V830, P417, DOI 10.1016/j.nima.2016.06.016
   Dolinski MJ, 2019, ANNU REV NUCL PART S, V69, P219, DOI [10.1146/annurev-nucl-101918023407, 10.1146/annurev-nucl-101918-023407]
   Domenici D., 2020, COMMUNICATION   0224
   Donghia R., 2020, COMMUNICATION   0224
   Dörenkamp S, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/9427231
   Ellis R.K., ARXIV191011775
   Elsen E., 2020, COMMUNICATION   0224
   Fabjan CW, 2003, REV MOD PHYS, V75, P1243, DOI 10.1103/RevModPhys.75.1243
   Fedotov S., 2020, COMMUNICATION   0224
   Fernando W, 2012, PHYSCS PROC, V37, P1805, DOI 10.1016/j.phpro.2012.02.507
   Frisch H.J., 2019, POS MPGD2017
   Garcia L., 2020, COMMUNICATION   0224
   Garcia-Sciveres M, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aab064
   Garutti E, 2019, NUCL INSTRUM METH A, V926, P69, DOI 10.1016/j.nima.2018.10.191
   Gianotti P, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06047
   Gnanvo K., 2020, COMMUNICATION   0224
   Gnesi I, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09019
   Gololo MGD, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08020
   Gostkin M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06046
   Grancagnolo F., 2020, COMMUNICATION   0224
   Guz Yu., 2020, COMMUNICATION   0224
   Hartmann F, 2019, NUCL INSTRUM METH A, V924, P250, DOI 10.1016/j.nima.2018.08.101
   Hartmann F, 2011, ANNU REV NUCL PART S, V61, P197, DOI 10.1146/annurev-nucl-102010-130052
   Heuer RD, 2013, PHYS SCRIPTA, VT158, DOI 10.1088/0031-8949/2013/T158/014018
   Hoffman A.C. Abusleme, ARXIV190502520
   Hong D, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09032
   Iddon JP, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08009
   ILD collaboration, ARXIV 1912 0 46 01
   Iodice M., 2020, COMMUNICATION   0224
   Isaacson J.P., 2017, FRAM TDR LHCB UPGR 2
   Jeitler M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09009
   Jesus-Valls C., 2020, P INT C INSTR COLL B
   Joram C, 2015, J INSTRUM, V10, DOI 10.1088/1748-0221/10/08/C08005
   Joram C., 2019, COMMUNICATION   0218
   Kimura M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08012
   Kodys P., 2020, COMMUNICATION   0224
   Korzhik M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08001
   Krammer N, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07038
   Krizan P., 2020, COMMUNICATION   0224
   Krizan P, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/10/C10010
   Krizan P, 2013, NUCL INSTRUM METH A, V706, P48, DOI 10.1016/j.nima.2012.05.013
   Kröger J, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08005
   Kudenko Yu., 2020, P INT C INSTR COLL B
   Kugathasan T., 2018, P 27 INT WORKSH VERT
   Kulish E., 2020, COMMUNICATION   0224
   Kumpan A., 2020, COMMUNICATION   0224
   Lai A., COMMUNICATION   0224
   Lai Y.T., 2020, P INT C INSTR COLL B
   Lee S, 2018, REV MOD PHYS, V90, DOI 10.1103/RevModPhys.90.025002
   Lippmann C, 2012, NUCL INSTRUM METH A, V666, P148, DOI 10.1016/j.nima.2011.03.009
   Liu Z, 2019, NUCL INSTRUM METH A, V927, P396, DOI 10.1016/j.nima.2019.02.068
   Logachev P., 2020, COMMUNICATION   0224
   Longo S., 2020, COMMUNICATION   0224
   Lupberger M, 2017, IEEE T NUCL SCI, V64, P1159, DOI 10.1109/TNS.2017.2689244
   Mahon DJ, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06045
   Mandurrino M., 2019, ARXIV191006045
   Massafferri A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08006
   Maximov D., 2020, COMMUNICATION   0224
   Meschi E, 2015, J PHYS CONF SER, V664, DOI 10.1088/1742-6596/664/8/082032
   Moll M, 2018, IEEE T NUCL SCI, V65, P1561, DOI 10.1109/TNS.2018.2819506
   Monzani S, 2019, NUOVO CIM C-COLLOQ C, V42, DOI 10.1393/ncc/i2019-19184-8
   Movchan S., 2020, COMMUNICATION   0224
   Muchnoi N, 2009, NUCL INSTRUM METH A, V607, P340, DOI 10.1016/j.nima.2009.05.145
   Musienko Y, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09036
   Mussgiller A., 2020, COMMUNICATION   0224
   Nakagiri K., 2020, COMMUNICATION   0224
   Nappi E, 2005, RIV NUOVO CIMENTO, V28, P1, DOI 10.1393/ncr/i2006-10004-6
   Nappi E, 2011, NUCL INSTRUM METH A, V628, P1, DOI 10.1016/j.nima.2010.06.277
   Neri N, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/11/C11040
   Ovtin I., 2020, COMMUNICATION   0224
   Paladino A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07023
   Papanestis A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09022
   Pernegger H, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/06/P06008
   Poitras ME, 2016, RECH SOINS INFIRM, P24, DOI 10.3917/rsi.126.0024
   Poluektov A., 2020, COMMUNICATION   0224
   Preston M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08011
   Pudzha D., 2020, COMMUNICATION   0224
   Qi H., 2020, COMMUNICATION   0224
   Ratcliff B, 2020, NUCL INSTRUM METH A, V970, DOI 10.1016/j.nima.2020.163442
   Rodriguez AR, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08015
   Ruchti RC, 1996, ANNU REV NUCL PART S, V46, P281, DOI 10.1146/annurev.nucl.46.1.281
   Sagawa H, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09012
   Sahin O., 2020, COMMUNICATION   0224
   Sauli F., 2014, GASEOUS RAD DETECTOR
   Schwarz C., 2020, COMMUNICATION   0224
   Schwiening J., 2020, COMMUNICATION   0224
   Sefkow F, 2016, REV MOD PHYS, V88, DOI 10.1103/RevModPhys.88.015003
   Shebalin V., 2020, COMMUNICATION   0224
   Shebalin V., 2020, RUSSIA
   Shekhtman L, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06005
   Shiltsev V., ARXIV200309084
   Simon F, 2019, NUCL INSTRUM METH A, V926, P85, DOI 10.1016/j.nima.2018.11.042
   Sinev N., 2015, P 24 INT WORKSH VERT
   Snoeys W, 2019, NUCL INSTRUM METH A, V924, P51, DOI 10.1016/j.nima.2018.06.034
   Sprygin A. V., 2012, Sel'skokhozyaistvennaya Biologiya, P24
   Suvorov Y., 2020, COMMUNICATION   0224
   Tassielli G.F., 2020, COMMUNICATION   0224
   Tessarotto F, 2017, NUCL INSTRUM METH A, V876, P225, DOI 10.1016/j.nima.2017.03.011
   Thomson MA, 2009, NUCL INSTRUM METH A, V611, P25, DOI 10.1016/j.nima.2009.09.009
   Titov M., 2004, ICFA INSTRUM B, V26, P002
   Titov M., LC DETECTORS R D LIA
   Titov M, 2013, MOD PHYS LETT A, V28, DOI 10.1142/S0217732313400221
   Torre S. Dalla, 2018, ARXIV180609955
   Tsuboyama T, 2019, NUCL INSTRUM METH A, V924, P422, DOI 10.1016/j.nima.2018.08.089
   Turchetta R, 2011, J INSTRUM, V6, DOI 10.1088/1748-0221/6/01/C01099
   Tyrtyshnaia A, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21249703
   Tytgat M, 2011, IEEE NUCL SCI CONF R, P1019, DOI 10.1109/NSSMIC.2011.6154312
   Tzanis P, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07002
   Uno S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07016
   Va'vra J., 2020, Journal of Physics: Conference Series, V1498, DOI 10.1088/1742-6596/1498/1/012013
   Va'vra J., 2020, COMMUNICATION   0224
   Vaidyanathan A., 2020, COMMUNICATION   0224
   Valderanis C., 2020, COMMUNICATION   0224
   Valerio P., 2015, P 23 INT WORKSH VERT
   Vereschagin S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09044
   Verzi V, 2017, PROG THEOR EXP PHYS, V2017, DOI 10.1093/ptep/ptx082
   Vinogradov S, 2020, NUCL INSTRUM METH A, V952, DOI 10.1016/j.nima.2018.12.067
   Wang F, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/07/C07006
   Wang J, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09008
   Winter M., 2019, P 28 INT WORKSH VERT
   Yarema R, 2013, J INSTRUM, V8, DOI 10.1088/1748-0221/8/01/C01052
   Yashin II, 2015, J PHYS CONF SER, V632, DOI 10.1088/1742-6596/632/1/012030
   Zakareishvili T, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09003
   Zhang Y, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/08/P08021
   Zhao R., 2019, THESIS
   Zhu RY, 2019, J PHYS CONF SER, V1162, DOI 10.1088/1742-6596/1162/1/012022
NR 171
TC 1
Z9 1
U1 3
U2 11
PD OCT
PY 2020
VL 15
IS 10
AR C10023
DI 10.1088/1748-0221/15/10/C10023
UT WOS:000608484000005
DA 2023-11-16
ER

PT C
AU Zhang, XY
   Xia, HJ
   Zhuang, DL
   Sun, H
   Fu, X
   Taylor, MB
   Song, SWL
AF Zhang, Xingyao
   Xia, Haojun
   Zhuang, Donglin
   Sun, Hao
   Fu, Xin
   Taylor, Michael B.
   Song, Shuaiwen Leon
GP IEEE Comp Soc
TI η-LSTM: Co-Designing Highly-Efficient Large LSTM Training via Exploiting
   Memory-Saving and Architectural Design Opportunities
SO 2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2021)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT ACM/IEEE 48th Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 14-19, 2021
CL ELECTR NETWORK
DE Machine Learning; Neural nets; Recurrent Neural Network; Accelerator
AB Recently, the recurrent neural network, or its most popular type-the Long Short Term Memory (LSTM) network-has achieved great success in a broad spectrum of real-world application domains, such as autonomous driving, natural language processing, sentiment analysis, and epidemiology. Due to the complex features of the real-world tasks, current LSTM models become increasingly bigger and more complicated for enhancing the learning ability and prediction accuracy. However, through our in-depth characterization on the state-of-the-art general-purpose deep-learning accelerators, we observe that the LSTM training execution grows inefficient in terms of storage, performance, and energy consumption, under an increasing model size. With further algorithmic and architectural analysis, we identify the root cause for large LSTM training inefficiency: massive intermediate variables. To enable a highly-efficient LSTM training solution for the ever-growing model size, we exploit some unique memory-saving and performance improvement opportunities from the LSTM training procedure, and leverage them to propose the first cross-stack training solution, eta-LSTM, for large ISTM models. eta-LSTM comprises both software-level and hardware-level innovations that effectively lower the memory footprint upper-bound and excessive data movements during large ISTM training, while also drastically improving training performance and energy efficiency. Experimental results on six real-world large LSTM training benchmarks demonstrate that eta-LSTM reduces the required memory footprint by an average of 57.5% (up to 75.8%) and brings down the data movements for weight matrices, activation data, and intermediate variables by 40.9%, 32.9%, and 80.0%, respectively. Furthermore, it outperforms the state-of-the-art GPU implementation for LSTM training by an average of 3.99x (up to 5.73x) on performance and 2.75x (up to 4.25x) on energy. We hope this work can shed some light on how to design high logic utilization for future NPUs.
C1 [Zhang, Xingyao; Fu, Xin] Univ Houston, ECOMS Lab, Houston, TX 77004 USA.
   [Zhang, Xingyao; Taylor, Michael B.] Univ Washington, Bespoke Silicon Grp BSG, Seattle, WA 98195 USA.
   [Xia, Haojun; Zhuang, Donglin; Sun, Hao; Song, Shuaiwen Leon] Univ Sydney, Future Syst Architecture Lab, Sydney, NSW, Australia.
RP Zhang, XY (corresponding author), Univ Houston, ECOMS Lab, Houston, TX 77004 USA.; Zhang, XY (corresponding author), Univ Washington, Bespoke Silicon Grp BSG, Seattle, WA 98195 USA.
EM xingyaoz@cs.washington.edu; xhjustc@gmail.com; dzhu9887@sydney.edu.au;
   hsun2147@uni.sydney.edu.au; xfu8@central.uh.edu; prof.taylor@gmail.com;
   leonange1991@gmail.com
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   [Anonymous], ACCUMULATOR V12 0 LO
   [Anonymous], AXI HIGH BANDWIDTH M
   [Anonymous], 2020, MLSYS
   [Anonymous], NVIDIA TURING GPU AR
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Feist T., 2012, WP416V11 XIL INC, V5, P30
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Geng T, 2019, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2019.00-43
   Ghosh S., 2016, ARXIV160206291
   Girma A, 2019, PROC INT C TOOLS ART, P894, DOI 10.1109/ICTAI.2019.00127
   Gu ZC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062046
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hochreiter S., 2001, GRADIENT FLOW RECURR, DOI 10.1109/9780470544037.ch14
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jia R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P12
   Jin S., 2021, PPOPP 21 26 ACM SIGP, P2021
   Johnson M., 2017, T ASSOC COMPUT LING, V5, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Li A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356169
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Luong M.-T., 2016, ACHIEVING OPEN VOCAB
   Maas A., 2011, P 49 ANN M ASS COMPU
   Mahmoud M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P781, DOI 10.1109/MICRO50266.2020.00069
   Marcus M., 1994, HUMAN LANGUAGE TECHN
   Palmer D. A., 2014, US Patent, Patent No. [8,655,815, 8655815]
   Park SH, 2018, IEEE INT VEH SYM, P1672, DOI 10.1109/IVS.2018.8500658
   Paszke A, 2019, ADV NEUR IN, V32
   Polyzos S, 2021, TOUR RECREAT RES, V46, P175, DOI 10.1080/02508281.2020.1777053
   Profiler N. V., 2014, US GUID
   Rhu M, 2016, INT SYMP MICROARCH
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Silfa F, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243184
   Tax N, 2017, LECT NOTES COMPUT SC, V10253, P477, DOI 10.1007/978-3-319-59536-8_30
   Ullrich Karen, 2017, ICLR
   Voorhees E. M., 2000, SIGIR Forum, V34, P200
   Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491
   Wang S., P 2018 ACM SIGDA INT, P11
   Wang SR, 2019, IEEE ACCESS, V7, P62930, DOI 10.1109/ACCESS.2019.2917312
   Weston J., 2015, ARXIV150205698
   Wissolik M., 2017, XILINX WHITEPAPER
   Yang DQ, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P711, DOI 10.1109/MICRO50266.2020.00064
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Zhang C., 2021, 35 ACM INT C SUP
   Zhang XY, 2021, IEEE T COMPUT, V70, P495, DOI 10.1109/TC.2021.3056929
   Zhang XY, 2020, INT S HIGH PERF COMP, P542, DOI 10.1109/HPCA47549.2020.00051
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhao Y, 2020, ANN I S COM, P954, DOI 10.1109/ISCA45697.2020.00082
   Zheng BJ, 2020, ANN I S COM, P1089, DOI 10.1109/ISCA45697.2020.00092
NR 51
TC 2
Z9 2
U1 2
U2 10
PY 2021
BP 567
EP 580
DI 10.1109/ISCA52012.2021.00051
UT WOS:000702275600042
DA 2023-11-16
ER

PT C
AU Tanomoto, M
   Takamaeda-Yamazaki, S
   Yao, J
   Nakashima, Y
AF Tanomoto, Masakazu
   Takamaeda-Yamazaki, Shinya
   Yao, Jun
   Nakashima, Yasuhiko
GP IEEE
TI A CGRA-based Approach for Accelerating Convolutional Neural Networks
SO 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE
   SYSTEMS-ON-CHIP (MCSOC)
DT Proceedings Paper
CT 9th IEEE International Symposium on Embedded Multicore/Manycore
   Systems-on-Chip (MCSoC)
CY SEP 23-25, 2015
CL Polytechn Turin, Turin, ITALY
HO Polytechn Turin
AB Convolutional neural network (CNN) is an emerging approach for achieving high recognition accuracy in various machine learning applications. To accelerate CNN computations, various GPU-based or application-specific hardware approaches have been recently proposed. However, since they require large computing hardware and absolute energy amount, they are not suitable for embedded applications. In this paper, we propose a novel approach to accelerate CNN computations using a CGRA (Coarse Grained Reconfigurable Architecture) for low-power embedded systems. We first present a new CGRA with distributed scratchpad memory blocks for efficient temporal blocking to reduce memory bandwidth pressure. We then show the architecture of our CNN accelerator using the CGRA with some dedicated software implementation. We evaluated our approach by comparing some existing platforms, such as high-end and mobile GPUs, and general multicore CPUs. The evaluation result shows that our proposal achieves 1.93x higher performance per memory bandwidth and 2.92x higher area performance, respectively.
C1 [Tanomoto, Masakazu; Takamaeda-Yamazaki, Shinya; Yao, Jun; Nakashima, Yasuhiko] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
RP Tanomoto, M (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
EM tanomoto.masakazu.tb8@is.naist.jp; shinya@is.naist.jp;
   yaojun@is.naist.jp; nakashim@is.naist.jp
CR [Anonymous], 2015, MISCELLANEOUS
   [Anonymous], BIGLEARN NIPS WORKSH
   [Anonymous], 2015, DEEP RESIDUAL LEARNI
   [Anonymous], 2014, CORR
   [Anonymous], 2011, NIPS 2011 BIGLEARNIN
   [Anonymous], 2014, ACMMM
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Y., 2014, ACM IEEE INT S MICR
   Collobert Ronan, 2008, P 25 INT C MACHINE L, P160
   Farabet C., 2011, WORSH IN CVPR
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Inagaki Y, 2014, 2014 SECOND INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR), P388, DOI 10.1109/CANDAR.2014.100
   Jafri SMAH, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P506, DOI 10.1109/HPCSim.2014.6903727
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Simard P, 2006, 10 INT WORKSH FRONT
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 23
TC 34
Z9 42
U1 0
U2 6
PY 2015
BP 73
EP 80
DI 10.1109/MCSoC.2015.41
UT WOS:000380390400010
DA 2023-11-16
ER

PT C
AU Denton, M
   Schmit, H
AF Denton, Matthew
   Schmit, Herman
GP IEEE Comp Soc
TI Direct Spatial Implementation of Sparse Matrix Multipliers for Reservoir
   Computing
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
AB Reservoir computing is a nascent sub-field of machine learning which relies on the recurrent multiplication of a very large, sparse, fixed matrix. We argue that direct spatial implementation of these fixed matrices minimizes the work performed in the computation, and allows for significant reduction in latency and power through constant propagation and logic minimization. Bit-serial arithmetic enables massive static matrices to be implemented. We present the structure of our bit-serial matrix multiplier, and evaluate using canonical signed digit representation to further reduce logic utilization. We have implemented these matrices on a large FPGA and provide a cost model that is simple and extensible. These FPGA implementations, on average, reduce latency by 50x up to 86x versus GPU libraries. Comparing against a recent sparse DNN accelerator, we measure a 4.1x to 47x reduction in latency depending on matrix dimension and sparsity.
C1 [Denton, Matthew; Schmit, Herman] Google Res, Mountain View, CA 94043 USA.
RP Denton, M (corresponding author), Google Res, Mountain View, CA 94043 USA.
EM myuzaki@google.com; schmit@google.com
CR Albericio J., 2016, ARXIV
   [Anonymous], 2017, NVIDIA TESLA V100 GP
   Antonik P., 2015, 24 BELG DUTCH C MACH
   Avizienis A, 1961, IRE T ELECT COMPUTER, VEC-10, P389
   Barham P, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P177, DOI 10.1145/3317550.3321441
   Bianchi FM, 2021, IEEE T NEUR NET LEAR, V32, P2169, DOI 10.1109/TNNLS.2020.3001377
   Chetlur S, 2014, Arxiv, DOI arXiv:1410.0759
   Dong JAT, 2020, Arxiv, DOI arXiv:2006.07310
   Dua D., 2017, UCI MACHINE LEARNING
   Frankle Jonathan, 2019, Arxiv, DOI [arXiv:1803.03635, 10.48550/arXiv.1803.03635]
   Gale T, 2020, Arxiv, DOI arXiv:2006.10901
   Gallicchio C, 2020, Arxiv, DOI arXiv:2006.02957
   Han S, 2016, Arxiv, DOI arXiv:1602.01528
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Dau HA, 2019, IEEE-CAA J AUTOMATIC, V6, P1293, DOI 10.1109/JAS.2019.1911747
   Hooker S, 2021, COMMUN ACM, V64, P58
   Hooker Sara, 2020, HARDWARE LOTTERY
   Reddi VJ, 2020, Arxiv, DOI arXiv:1911.02549
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2017, IEEE COMPUT ARCHIT L, V16, P80, DOI 10.1109/LCA.2016.2597140
   Karpathy A., CVPR 21 WORKSH AUT D
   Kawai Y, 2019, NEURAL NETWORKS, V112, P15, DOI 10.1016/j.neunet.2019.01.002
   Kleyko D, 2020, Arxiv, DOI arXiv:1706.00280
   Murray A. F., 1988, NEURAL INFORM PROCES, P573
   NVIDIA, 2020, NVIDIA CUSPARSE API
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Sabour S, 2017, Arxiv, DOI [arXiv:1710.09829, DOI 10.48550/ARXIV.1710.09829]
   Schrauwen B, 2007, LECT NOTES COMPUT SC, V4668, P471
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Sharma H, 2018, Arxiv, DOI arXiv:1712.01507
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Vaswani A., 2017, P ADV NEURAL INFORM, V30, P6000, DOI 10.5555/3295222.3295349
   Verstraeten D., 2005, P 16 ANN PRORISC WOR, P454
   Xilinx, 2020, VIRT ULTRASCALE
NR 35
TC 1
Z9 1
U1 1
U2 2
PY 2022
BP 1
EP 11
DI 10.1109/HPCA53966.2022.00009
UT WOS:000838704300001
DA 2023-11-16
ER

PT J
AU Konstantinou, D
   Nicopoulos, C
   Lee, J
   Dimitrakopoulos, G
AF Konstantinou, Dimitris
   Nicopoulos, Chrysostomos
   Lee, Junghee
   Dimitrakopoulos, Giorgos
TI Multicast-enabled network-on-chip routers leveraging partitioned
   allocation and switching
SO INTEGRATION-THE VLSI JOURNAL
DT Article
DE Network-on-Chip; Multicast; Router; Micro-architecture
AB Multicast on-chip communication is encountered in various cache-coherence protocols targeting multi-core processors, and its pervasiveness is increasing due to the proliferation of machine learning accelerators. Innetwork handling of multicast traffic imposes additional switching-level restrictions to guarantee deadlock freedom, while it stresses the allocation efficiency of Network-on-Chip (NoC) routers. In this work, we propose a novel partitioned NoC router microarchitecture, called SmartFork, which employs a versatile and cost-efficient multicast packet replication scheme that allows the design of high-throughput and low-cost NoCs. The design is adapted to the average branch splitting observed in real-world multicast routing algorithms. Compared to state-of-the-art NoC multicast approaches, SmartFork is demonstrated to yield high performance in terms of latency and throughput, while still offering a cost-effective implementation.
C1 [Konstantinou, Dimitris; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Dept Elect & Comp Engn, Nicosia, Cyprus.
   [Lee, Junghee] Korea Univ, Sch Cyber Secur, Seoul, South Korea.
RP Dimitrakopoulos, G (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
EM dimitrak@ee.duth.gr
CR Abadal S, 2016, COMPUT ELECTR ENG, V51, P168, DOI 10.1016/j.compeleceng.2015.12.018
   Agarwal A, 2007, DES AUT CON, P750, DOI 10.1109/DAC.2007.375264
   Agarwal N, 2009, INT SYM PERFORM ANAL, P33, DOI 10.1109/ISPASS.2009.4919636
   [Anonymous], 2003, INT S COMP ARCH ISCA
   [Anonymous], 2012, PROC INT S HIGH PERF
   [Anonymous], 2015, MICROARCHITECTURE NE
   Arteris, 2018, ART IP FLEXNOC AI PA
   Bhardwaj K., 2017, INT S NETW ON CHIP N
   Bhardwaj K, 2019, IEEE T VLSI SYST, V27, P350, DOI 10.1109/TVLSI.2018.2876856
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Boppana R. V., 1994, Proceedings. Sixth IEEE Symposium on Parallel and Distributed Processing (Cat. No.94TH0675-9), P722, DOI 10.1109/SPDP.1994.346103
   Boyd S., 2004, CONVEX OPTIMIZATION
   Conway P, 2007, IEEE MICRO, V27, P10, DOI 10.1109/MM.2007.43
   Daya BK, 2014, CONF PROC INT SYMP C, P25, DOI 10.1109/ISCA.2014.6853232
   Dimitrakopoulos G, 2013, IEEE T COMPUT, V62, P2001, DOI 10.1109/TC.2012.116
   Dimitrakopoulos G, 2008, PR IEEE COMP DESIGN, P664, DOI 10.1109/ICCD.2008.4751932
   Ebrahimi M, 2009, DES AUT TEST EUROPE, P1064
   Gurobi L, 2020, OPTIMIZATION GUROBI
   Jerger NE, 2008, CONF PROC INT SYMP C, P229, DOI 10.1109/ISCA.2008.12
   Krishna T, 2011, INT SYMP MICROARCH, P71
   Krishna T, 2010, PR IEEE COMP DESIGN, P439, DOI 10.1109/ICCD.2010.5647666
   LIN XL, 1991, ACM COMP AR, V19, P116, DOI 10.1145/115953.115965
   Lu Z., 2006, ISVLSI
   Ma S., 2012, IEEE INT S HIGH PERF, P1
   Magnusson PS, 2002, COMPUTER, V35, P50, DOI 10.1109/2.982916
   Malumbres M.P., 1996, IEEE S PAR DIST PROC
   Martin MM., 2005, COMPUTER ARCHITECTUR, V33, P92
   Psarras A, 2016, IEEE T COMPUT, V65, P3136, DOI 10.1109/TC.2016.2519916
   Rodrigo S, 2008, INT SYMP MICROARCH, P364, DOI 10.1109/MICRO.2008.4771805
   Samman FA, 2010, IEEE T VLSI SYST, V18, P1067, DOI 10.1109/TVLSI.2009.2019758
   Seitanidis I, 2014, 2014 EIGHTH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS), P135, DOI 10.1109/NOCS.2014.7008772
   Sivaram R., 1997, PARALLEL COMPUTER RO, P39
   Stefan RA, 2014, IEEE T COMPUT, V63, P583, DOI 10.1109/TC.2012.117
   Wang L, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P64, DOI 10.1109/NOCS.2009.5071446
   Wenmin Hu, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P363, DOI 10.1109/ASPDAC.2011.5722214
   Ye Lu, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P358, DOI 10.1109/SOCC.2012.6398332
NR 36
TC 4
Z9 4
U1 0
U2 5
PD MAR
PY 2021
VL 77
BP 104
EP 112
DI 10.1016/j.vlsi.2020.10.008
UT WOS:000611946100010
DA 2023-11-16
ER

PT C
AU Jo, CW
   Lee, KY
AF Jo, Cheol-Won
   Lee, Kwang-Yeob
GP IEEE
TI Design of multicycle path accelerator for neural network
SO 2019 INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC)
SE International SoC Design Conference
DT Proceedings Paper
CT 16th International System-on-Chip Design Conference (ISOCC)
CY OCT 06-09, 2019
CL SOUTH KOREA
DE Multi Cycle; Neural Network; MAC; machine learning
AB In this paper, MAC computation, which is the most used operation in neural network computing, is accelerated by multicycle_path. When using a pipeline, we can not divide the operation into fixed delays. Thus, exiting pipelines determine the operating frequency with the lowest frequency. We proposed the method confirmed that confirmed that the operation frequency of the whole process is improved by using multicycle_path to divide the operation into a certain delay and to perform the operation. In this paper, the experiment was divided into SingleCycle, Conventional Multicycle, MultiCycle_Ex and MultiCycle_Slice. Conventional Multicycle achieved 2.23 times higher operating frequency than SingleCycle, but resource usage tripled. MultiCycle_Ex achieved a 2.67 times higher operating frequency while maintaining the resource usage of SingleCycle, and MultiCycle_Slice achieved operating frequency about 8.2 times higher than SingleCycle.
C1 [Jo, Cheol-Won; Lee, Kwang-Yeob] Seokyoung Univ, Dept Comp Engn, Seoul, South Korea.
RP Lee, KY (corresponding author), Seokyoung Univ, Dept Comp Engn, Seoul, South Korea.
EM cheolgu94@skuniv.ac.kr; kylee@skuniv.ac.kr
CR Caulfield AM, 2016, INT SYMP MICROARCH
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Higuchi H, 2002, DES AUT CON, P164, DOI 10.1109/DAC.2002.1012613
   Jeong Hyung-Ki, 2008, J IKEEE, V12, P246
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Singh M, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P1008, DOI 10.1109/DATE.2004.1269025
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zheng HB, 2014, IEEE T COMPUT AID D, V33, P1832, DOI 10.1109/TCAD.2014.2361661
NR 9
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 221
EP 224
UT WOS:000694734600031
DA 2023-11-16
ER

PT C
AU Chen, YZ
   Lu, L
   Kim, B
   Kim, TTH
AF Chen, Yuzong
   Lu, Lu
   Kim, Bongjin
   Kim, Tony Tae-Hyoung
GP IEEE
TI Reconfigurable 2T2R ReRAM with Split Word-lines for TCAM Operation and
   In-Memory Computing
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
DE Non-volatile memory; ReRAM; TCAM; in-memory computing
AB The increased latency and power consumption due to data movement between memory and ALU have become the major obstacle in modern big-data and machine learning applications. Beyond von-Neumann architectures, particularly in-memory computing, is under intensive research to overcome this memory access bottleneck. In this work, we propose a 2T2R ReRAM structure that supports ternary content addressable memory (TCAM), logic in-memory operations, and in-memory dot product for Deep Neural Networks (DNNs) besides the normal non-volatile memory (NVM) functionality. This is achieved by employing reconfigurable sense amplifiers and novel word-line drivers. The proposed architecture can serve as a high-density storage system as well as an accelerator for data-intensive applications. Simulation results verify that the proposed 2T2R structure functions correctly for TCAM search, logic in-memory operations and in-memory dot product.
C1 [Chen, Yuzong; Lu, Lu; Kim, Bongjin; Kim, Tony Tae-Hyoung] Nanyang Technol Univ, VIRTUS, Sch Elect & Elect Engn, Singapore, Singapore.
RP Chen, YZ (corresponding author), Nanyang Technol Univ, VIRTUS, Sch Elect & Elect Engn, Singapore, Singapore.
EM E150056@e.ntu.edu.sg
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Bocquet M., 2018, 2018 IEEE INT ELECT, DOI 10.1109/IEDM.2018.8614639
   Chang MF, 2016, IEEE INT SYMP CIRC S, P1142, DOI 10.1109/ISCAS.2016.7527447
   Chen W. H., 2017, IEDM, DOI [10.1109/IEDM.2017.8268468, DOI 10.1109/IEDM.2017.8268468]
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107, DOI DOI 10.5555/3157382.3157557
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jung Myoungsoo, 2013, P INT ACM C INT C SU, P103
   Ly DRB, 2018, INT EL DEVICES MEET
   Messaris I, 2018, IEEE T COMPUT AID D, V37, P3151, DOI 10.1109/TCAD.2018.2791468
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yang Z., 2019, IEEE INT SYMP CIRC S, P1, DOI DOI 10.1109/iscas.2019.8702555
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zheng L, 2014, IEEE INT SYMP CIRC S, P2253, DOI 10.1109/ISCAS.2014.6865619
NR 14
TC 0
Z9 0
U1 0
U2 1
PY 2020
UT WOS:000696570700278
DA 2023-11-16
ER

PT J
AU Sadredini, E
   Rahimi, R
   Verma, V
   Stan, M
   Skadron, K
AF Sadredini, Elaheh
   Rahimi, Reza
   Verma, Vaibhav
   Stan, Mircea
   Skadron, Kevin
TI A Scalable and Efficient In-Memory Interconnect Architecture for
   Automata Processing
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Interconnect; processing in memory; automata processing
AB Accelerating finite automata processing benefits regular-expression workloads and a wide range of other applications that do not map obviously to regular expressions, including pattern mining, bioinfomatics, and machine learning. Existing in-memory automata processing accelerators suffer from inefficient routing architectures. They are either incapable of efficiently place-and-route a highly connected automaton or require an excessive amount of hardware resources. In this paper, we propose a compact, low-overhead, and yet flexible in-memory interconnect architecture that efficiently implements routing for next-state activation, and can be applied to the existing in-memory automata processing architectures. We use SRAM 8T subarrays to evaluate our interconnect. Compared to the Cache Automaton routing design, our interconnect reduces the number of switches 7x, therefore, reduces area overhead for the interconnect. It also has faster row cycle time because of shorter wires and consumes less power.
C1 [Sadredini, Elaheh; Skadron, Kevin] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
   [Rahimi, Reza; Verma, Vaibhav; Stan, Mircea] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22903 USA.
RP Sadredini, E (corresponding author), Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
EM elaheh@virginia.edu; rahimi@virginia.edu; vv8dn@virginia.edu;
   mircea@virginia.edu; skadron@virginia.edu
CR [Anonymous], 2016, P INT C HIGH PERF CO
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Gogte, 2016, MICR MICRO 2016 49 A, P1, DOI DOI 10.1109/MICRO.2016.7783747
   ReemKaraki, 2017, P INT C REC COMP FPG, P1
   Sadredini E., 2017, P INT C SUPERCOMPUTI, DOI [10.1145/3079079.3079084, DOI 10.1145/3079079.3079084]
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Wadden J, 2018, I S WORKL CHAR PROC, P13, DOI 10.1109/IISWC.2018.8573482
   Wadden J, 2017, ANN IEEE SYM FIELD P, P180, DOI 10.1109/FCCM.2017.38
   Wadden P, 2016, CAMBR MEDIEV CELT ST, P1
   Zhuo YW, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P29, DOI 10.1109/MICRO.2018.00012
NR 13
TC 2
Z9 2
U1 1
U2 8
PD JUL-DEC
PY 2019
VL 18
IS 2
BP 87
EP 90
DI 10.1109/LCA.2019.2909870
UT WOS:000473595600001
DA 2023-11-16
ER

PT C
AU Jeng, YL
   Huang, SB
   Lai, CF
AF Jeng, Yu -Lin
   Huang, Sheng-Bo
   Lai, Chin-Feng
GP IEEE
TI Inspect Road Quality by Using Anomaly Detection Approach
SO 2018 INTERNATIONAL CONFERENCE ON SYSTEM SCIENCE AND ENGINEERING (ICSSE)
SE International Conference on System Science and Engineering
DT Proceedings Paper
CT International Conference on System Science and Engineering (ICSSE)
CY JUN 28-30, 2018
CL Taipei, TAIWAN
DE Road quality monitoring; Crowdsensing; Mobile Sensors; Smartphones
AB Road quality can be representative of a country's development status, affect transportation speeds and traveler safety. However, there is no standard or set of rules to protect people from the dangers of damaged roads. This study proposes a method for evaluating road quality, which has been made possible by the recent rapid development of information technology and machine learning algorithms, and the popularity and widespread use of smartphones. The proposed inspection method is a road quality inspection APP which collects raw data from smartphone sensors, including GPS and accelerator sensors. Once the data is collected, the server side of the proposed system runs an anomaly detection algorithm to interpret the recorded oscillating amplitude of a specific section of road. The calculated results are then added to the Google Maps app, and abnormal road sections are marked in different colors.
C1 [Jeng, Yu -Lin] Southern Taiwan Univ Sci & Technol, Dept Informat Management, Tainan, Taiwan.
   [Huang, Sheng-Bo; Lai, Chin-Feng] Natl Cheng Kung Univ, Dept Engn Sci, Tainan, Taiwan.
RP Jeng, YL (corresponding author), Southern Taiwan Univ Sci & Technol, Dept Informat Management, Tainan, Taiwan.
EM jackjeng@stust.edu.tw; n98074037@ncku.edu.tw; cinfon@ieee.org
CR Ding MM, 2016, TSINGHUA SCI TECHNOL, V21, P500
   Ganti RK, 2011, IEEE COMMUN MAG, V49, P32, DOI 10.1109/MCOM.2011.6069707
   Hoang Dang Hai, 2018, ADV COMM TECHN ICACT, P281
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Prarthana TS, 2017, IEEE CONF CLOUD COMP, P3, DOI 10.1109/CCEM.2017.19
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Qing Yu, 2017, 2017 International Conference on Computing Intelligence and Information System (CIIS). Proceedings, P62, DOI 10.1109/CIIS.2017.18
   Sun T, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P405, DOI 10.1109/CompComm.2017.8322580
   Yousefi H, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P205, DOI 10.1109/AISP.2017.8324082
NR 9
TC 0
Z9 0
U1 0
U2 1
PY 2018
UT WOS:000517102000055
DA 2023-11-16
ER

PT C
AU Crovetti, P
   Rubino, R
   Abdullah, A
   Musolino, F
AF Crovetti, Paolo
   Rubino, Roberto
   Abdullah, Ahmed
   Musolino, Francesco
GP IEEE
TI Emerging Relaxation and DDPM D/A Converters: Overview and Perspectives
SO 2022 IEEE 65TH INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS 2022)
DT Proceedings Paper
CT IEEE 65th International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY AUG 07-10, 2022
CL Fukuoka, JAPAN
DE Relaxation Digital to Analog Converter (ReDAC); Dyadic Digital Pulse
   Modulation (DDPM); Digital to Analog Converter (DAC); Digital-based
   Analog Processing
ID ANALOG
AB In this paper, two emerging, digital-intensive, matching-indifferent, bitstream digital-to-analog (D/A) conversion techniques proposed in the last years, namely: the Relaxation D/A Conversion (ReDAC) and the Dyadic Digital Pulse Modulation (DDPM)-based D/A conversion, are reviewed and compared. After the basic concepts are introduced, the main challenges and research achievements over the last years are summarized and the performance of different integrated circuit (IC), field-programmable gate array (FPGA) and microcontroller-based ReDACs and DDPM-DACs are discussed and compared, highlighting advantages and open research questions. Present applications of the two techniques in voltage and current mode A/D conversion, RF modulation, digitally controlled switching-mode power converters, and machine learning accelerators will be discussed, and future application perspectives will be outlined.
C1 [Crovetti, Paolo; Rubino, Roberto; Abdullah, Ahmed; Musolino, Francesco] Politecn Torino, Dipartimento Elettron & Telecomunicaz DET, Turin, Italy.
RP Crovetti, P (corresponding author), Politecn Torino, Dipartimento Elettron & Telecomunicaz DET, Turin, Italy.
EM paolo.crovetti@polito.it
CR Abdullah A, 2022, IEEE ACCESS, V10, P17515, DOI 10.1109/ACCESS.2022.3150865
   Aiello O, 2020, IEEE ACCESS, V8, P70890, DOI 10.1109/ACCESS.2020.2986949
   Aiello O, 2019, IEEE I C ELECT CIRC, P715, DOI [10.1109/ICECS46596.2019.8964789, 10.1109/icecs46596.2019.8964789]
   Aiello O, 2019, IEEE ACCESS, V7, P126479, DOI 10.1109/ACCESS.2019.2938737
   Aiello O, 2019, IEEE T CIRCUITS-I, V66, P2865, DOI 10.1109/TCSI.2019.2903464
   Alioto M., 2017, ENABLING INTERNET TH
   Carrara S, 2021, IEEE SENS J, V21, P12398, DOI 10.1109/JSEN.2020.3029432
   Crovari Pietro, 2020, IEEE INT SYMP CIRC S, P1, DOI [10.1145/3405755.3406163, DOI 10.1109/iscas45731.2020.9180696]
   Crovetti PS, 2021, ELECTRON LETT, V57, P212, DOI 10.1049/ell2.12050
   Crovetti PS, 2019, ELECTRON LETT, V55, P685, DOI 10.1049/el.2019.0784
   Crovetti PS, 2019, ELECTRON LETT, V55, P672, DOI 10.1049/el.2019.1622
   Crovetti PS, 2012, ELECTRON LETT, V48, P1114, DOI 10.1049/el.2012.1683
   Crovetti PS, 2020, IEEE T POWER ELECTR, V35, P11155, DOI 10.1109/TPEL.2020.2978696
   Crovetti PS, 2017, IEEE T CIRCUITS-I, V64, P573, DOI 10.1109/TCSI.2016.2614231
   Crovetti PS, 2015, IEEE T CIRCUITS-I, V62, P1315, DOI 10.1109/TCSI.2015.2402991
   Crovetti PS, 2013, IEEE T CIRCUITS-I, V60, P3107, DOI 10.1109/TCSI.2013.2255671
   Gupta A., 2022, 2022 IEEE CUSTOM INT
   Hyun D, 2002, IEEE T CIRCUITS-I, V49, P646, DOI 10.1109/TCSI.2002.1001954
   Lu YS, 2020, IEEE T CIRCUITS-I, V67, P2859, DOI 10.1109/TCSI.2020.2979336
   Moffo BL, 2015, IEEE T CIRCUITS-II, V62, P543, DOI 10.1109/TCSII.2015.2407233
   Mohan R, 2017, IEEE J SOLID-ST CIRC, V52, P298, DOI 10.1109/JSSC.2016.2615320
   Rubino R., 2022, 2022 IEEE INT S CIRC, DOI DOI 10.1109/ISCAS48785.2022.9937502
   Rubino R, 2021, IEEE T CIRCUITS-I, V68, P2494, DOI 10.1109/TCSI.2021.3064419
   Rubino R, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P13, DOI 10.1109/APCCAS47518.2019.8953168
   Song Y, 2022, IEEE T INTELL TRANSP, V23, P22084, DOI 10.1109/TITS.2022.3164596
   Toledo P, 2021, IEEE T CIRCUITS-II, V68, P816, DOI 10.1109/TCSII.2021.3049680
   Toledo P, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060983
   Usmonov M, 2019, IEEE ENER CONV, P2224, DOI [10.1109/ECCE.2019.8913214, 10.1109/ecce.2019.8913214]
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/MWSCAS54063.2022.9859310
UT WOS:000861351300023
DA 2023-11-16
ER

PT J
AU Filippas, D
   Nicopoulos, C
   Dimitrakopoulos, G
AF Filippas, Dionysios
   Nicopoulos, Chrysostomos
   Dimitrakopoulos, Giorgos
TI Templatized Fused Vector Floating-Point Dot Product for High-Level
   Synthesis
SO JOURNAL OF LOW POWER ELECTRONICS AND APPLICATIONS
DT Article
DE floating point arithmetic; vector dot product; high level synthesis
AB Machine-learning accelerators rely on floating-point matrix and vector multiplication kernels. To reduce their cost, customized many-term fused architectures are preferred, which improve the latency, power, and area of the designs. In this work, we design a parameterized fused many-term floating-point dot product architecture that is ready for high-level synthesis. In this way, we can exploit the efficiency offered by a well-structured fused dot-product architecture and the freedom offered by high-level synthesis in tuning the design's pipeline to the selected floating-point format and architectural constraints. When compared with optimized dot-product units implemented directly in RTL, the proposed design offers lower-latency implementations under the same clock frequency with marginal area savings. This result holds for a variety of floating-point formats, including standard and reduced-precision representations.
C1 [Filippas, Dionysios; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Elect & Comp Engn, Xanthi 67100, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Elect & Comp Engn, CY-1678 Nicosia, Cyprus.
RP Nicopoulos, C (corresponding author), Univ Cyprus, Elect & Comp Engn, CY-1678 Nicosia, Cyprus.
EM nicopoulos@ucy.ac.cy
CR Agrawal A, 2019, P S COMP ARITHM, P92, DOI 10.1109/ARITH.2019.00023
   Andersch M., NVIDIA HOPPER ARCHIT
   Burgess N, 2019, P S COMP ARITHM, P88, DOI 10.1109/ARITH.2019.00022
   cadence, GEN SYNTH SOL
   Cadence, INN IMPL SYST
   de Dinechin F, 2011, IEEE DES TEST COMPUT, V28, P18, DOI 10.1109/MDT.2011.44
   Dimitrakopoulos G, 2008, IEEE T VLSI SYST, V16, P837, DOI 10.1109/TVLSI.2008.2000458
   Fingeroff M., 2010, HIGH LEVEL SYNTHESIS
   Galal S, 2011, P S COMP ARITHM, P129, DOI 10.1109/ARITH.2011.26
   Gholami A., 2021, ARXIV
   github, SIEMENS EDA ALGORITH
   github, IC LAB DUTH REPOSITO
   Hickmann B, 2020, P S COMP ARITHM, P133, DOI 10.1109/ARITH48897.2020.00029
   Hickmann B, 2019, P S COMP ARITHM, P116, DOI 10.1109/ARITH.2019.00031
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Kasgen P., 2018, USING TEMPLATE METAP
   Kaul H, 2019, P S COMP ARITHM, P84, DOI 10.1109/ARITH.2019.00021
   Kim D, 2009, IEEE T COMPUT, V58, P890, DOI 10.1109/TC.2008.210
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Micikevicius P, 2017, ARXIV
   Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433
   Saleh HH, 2008, PR IEEE COMP DESIGN, P427, DOI 10.1109/ICCD.2008.4751896
   Seidel PM, 2001, P S COMP ARITHM, P184, DOI 10.1109/ARITH.2001.930118
   Siemens, EDA QUEST ADV SIM
   Sohn J, 2013, P S COMP ARITHM, P41, DOI 10.1109/ARITH.2013.26
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tambe T, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218516
   Thomas DB, 2019, ANN IEEE SYM FIELD P, P227, DOI 10.1109/FCCM.2019.00038
   Uguen Y, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3377403
   Wang Shibo, 2019, GOOGLE CLOUD BLOG
   Xilinx Vitis, HLS HARDW DES METH A
NR 31
TC 0
Z9 0
U1 1
U2 1
PD DEC
PY 2022
VL 12
IS 4
AR 56
DI 10.3390/jlpea12040056
UT WOS:000901042200001
DA 2023-11-16
ER

PT C
AU Temple, S
   Neto, WL
   Snelgrove, A
   Tang, XF
   Gaillardon, PE
AF Temple, Scott
   Neto, Walter Lau
   Snelgrove, Ashton
   Tang, Xifan
   Gaillardon, Pierre-Emmanuel
GP IEEE
TI Invited: Getting the Most out of your Circuits with Heterogeneous Logic
   Synthesis
SO 2021 58TH ACM/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 58th ACM/IEEE Design Automation Conference (DAC)
CY DEC 05-09, 2021
CL San Francisco, CA
AB High Level Synthesis (HLS) speeds hardware development and opens the door to non-expert designers, focusing on functionality rather than implementation. The expense and rigidity of commercial electronic design automation (EDA) tool chains can be an obstacle for these users. LSOracle is an opensource logic synthesis tool which leverages multiple underlying data structures, including and -inverter graphs (AIGs), majority-inverter graphs (MIGs), and xor-and graphs (XAGs) to automatically optimize circuits using the best representation for each region of a design, without manual intervention. The use of MIGs and XAGs gives particularly strong performance in arithmetic logic, cryptography cores, and machine-learning accelerators; applications which may be of particular interest for HLS users. Here we present an overview of the approach and demonstrate an open-source HLS-to-GDS II workflow using LSOracle, Bambu, and OpenROAD. We test the integration on a small benchmark suite and show a reduction in delay of up to 31%.
C1 [Temple, Scott; Neto, Walter Lau; Snelgrove, Ashton; Tang, Xifan; Gaillardon, Pierre-Emmanuel] Univ Utah, Elect & Comp Engn, Salt Lake City, UT 84112 USA.
RP Gaillardon, PE (corresponding author), Univ Utah, Elect & Comp Engn, Salt Lake City, UT 84112 USA.
EM pierre-emmanuel.gaillardon@utah.edu
CR Ajayi T., 2019, DAC
   Amarú L, 2014, DES AUT CON, DOI 10.1145/2593069.2593158
   [Anonymous], ABC SYSTEM SEQUENTIA
   Neto W. L., 2020, DATE
   Pilato C, 2013, I C FIELD PROG LOGIC
   Schlag S., 2016, ALENEX
   Soeken M., 2018, ARXIV180505121
   Sui X., 2010, LCPC
   Temple S., 2021, GOMACTECH
   Testa E., 2020, DATE
   Testa E., 2019, DAC
   Wolf Clifford, 2013, P 21 AUSTRIAN WORKSH
NR 12
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 1331
EP 1334
DI 10.1109/DAC18074.2021.9586215
UT WOS:000766079700226
DA 2023-11-16
ER

PT C
AU Kim, D
   Zhao, J
   Bachrach, J
   Asanovi, K
AF Kim, Donggyu
   Zhao, Jerry
   Bachrach, Jonathan
   Asanovi, Krste
GP Assoc Comp Machinery
TI Simmani: Runtime Power Modeling for Arbitrary RTL with Automatic Signal
   Selection
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
ID REGULARIZATION; PERFORMANCE
AB This paper presents a novel runtime power modeling methodology which automatically identifies key signals for power dissipation of any RTL design. The toggle-pattern matrix is constructed with the VCD dumps from a training set, where each signal is represented as a high-dimensional point. By clustering signals showing similar switching activities, a small number of signals are automatically selected, and then the design-specific but workload-independent activity-based power model is constructed using regression against cycle-accurate power traces obtained from industry-standard CAD tools. We can also automatically instrument an FPGA-accelerated RTL simulation with runtime activity counters to obtain power traces of realistic workloads at speed. Our methodology is demonstrated with a heterogeneous processor composed of an in-order core and a custom vector accelerator, running not only microbenchmarks but also real-world machine-learning applications.
C1 [Kim, Donggyu; Zhao, Jerry; Bachrach, Jonathan; Asanovi, Krste] Univ Calif Berkeley, Berkeley, CA 94720 USA.
RP Kim, D (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM dgkim@berkeley.edu; jerryz123@berkeley.edu; jrb@berkeley.edu;
   krste@berkeley.edu
CR [Anonymous], ICCAD
   [Anonymous], 2016, ISCA
   [Anonymous], DAC
   [Anonymous], 2016, TECHNICAL REPORT
   [Anonymous], 9 ACM SIGOPS EUR WOR
   [Anonymous], PROC ICML
   [Anonymous], PACT
   [Anonymous], HPCA
   [Anonymous], 2009, HP LAB
   [Anonymous], ICCAD
   [Anonymous], DAC
   [Anonymous], HPCA
   [Anonymous], MICRO
   [Anonymous], ISCA
   [Anonymous], ISPASS
   [Anonymous], 2017, 1 WORKSH COMP ARCH R
   [Anonymous], DAC
   [Anonymous], 2009, MICRO
   [Anonymous], 2009, ISPASS
   [Anonymous], ISCA
   [Anonymous], 2015, RICE RES
   [Anonymous], INT S COMP ARCH HIGH
   [Anonymous], 2010, FPL
   [Anonymous], HOMILIA HEXAEMERON
   [Anonymous], ISLPED
   [Anonymous], MICR MOB LPDDR2 SDRA
   [Anonymous], UCBEECS201617
   [Anonymous], 2015 IEEE ACM INT S
   [Anonymous], DATE
   [Anonymous], 2002, ASPLOS
   [Anonymous], 2015, HPCA
   [Anonymous], ISCA
   [Anonymous], ISCA
   [Anonymous], MOB LPDDR2 SYST POW
   [Anonymous], 2012, MICRO
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bertran R, 2013, IEEE T COMPUT, V62, P1289, DOI 10.1109/TC.2012.97
   Blum A, 2016, FOUND DATA SCI
   BOGLIOLO A, 2000, ACM T DESIGN AUTOMAT, V5
   Cochran R, 2011, INT SYMP MICROARCH, P175
   Dubach C., 2007, MICRO
   Eyerman S, 2010, IEEE T COMPUT, V59, P1576, DOI 10.1109/TC.2010.65
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gupta S, 2000, IEEE T VLSI SYST, V8, P18, DOI 10.1109/92.820758
   IPEK E, 2006, ASPLOS
   ISCI C, 2003, MICRO
   Isci C, 2006, INT SYMP MICROARCH, P347
   Isci C, 2006, INT S HIGH PERF COMP, P122, DOI 10.1109/HPCA.2006.1598119
   Jacobson H., 2011, HPCA
   JOSEPH PJ, 2006, MICRO
   JOSEPH PJ, 2006, HPCA
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kim D., 2017, 1 WORKSH COMP ARCH R
   Kim D, 2019, THESIS
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Laeufer K, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240842
   Lee B., 2008, MICRO
   LEE B, 2007, HPCA
   LEE B, 2006, ASPLOS
   Leng Jingwen, 2013, ISCA
   LI T, 2003, SIGMETRICS
   Najm F. N., 1994, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V2, P446, DOI 10.1109/92.335013
   Palacharla S., 1997, ISCA
   Patel A., 2011, DAC
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shafi H, 2003, IBM J RES DEV, V47, P641, DOI 10.1147/rd.475.0641
   Shao Yakun Sophia, 2014, ISCA
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wenisch TF, 2006, IEEE MICRO, V26, P18, DOI 10.1109/MM.2006.79
   Zheng B, 2016, IEEE COMP SOC ANN, P53, DOI 10.1109/ISVLSI.2016.126
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127
NR 72
TC 16
Z9 16
U1 0
U2 0
PY 2019
BP 1050
EP 1062
DI 10.1145/3352460.3358322
UT WOS:000519057400078
DA 2023-11-16
ER

PT C
AU Bolsens, I
AF Bolsens, Ivo
GP IEEE
TI Future workloads drive the need for high performant and adaptive
   computing hardware
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM,
   IPDPS
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
AB As big data pushes the need for high-performance and adaptive computing beyond the exascale threshold, the pressure is on to find computing architectures that meet the right mix of price, performance, and power efficiency to support cost-effective data center scalability, acceleration of applications that drive higher end-user productivity and faster time to insights and lower power consumption for sustainability. This will require heterogeneous architectures that combine traditional CPUs and GPUs with innovative accelerators to meet the ever-growing demand of big-data-driven workloads. Endpoints connected to the cloud are being infused with intelligence through sensors, cameras and other devices and are creating massive amounts of mostly unstructured data. Processing this data is driving demand for new workloads such as machine learning. Adaptive computing allows for compute and connectivity hardware that can adapt to the workload and efficiently process data in use, in motion and at rest.
C1 [Bolsens, Ivo] AMD, Adapt & Embedded Comp Grp, Santa Clara, CA 95054 USA.
RP Bolsens, I (corresponding author), AMD, Adapt & Embedded Comp Grp, Santa Clara, CA 95054 USA.
NR 0
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 690
EP 690
DI 10.1109/IPDPS54959.2023.00074
UT WOS:001035517300065
DA 2023-11-16
ER

PT J
AU Kulichenko, M
   Barros, K
   Lubbers, N
   Fedik, N
   Zhou, GQ
   Tretiak, S
   Nebgen, B
   Niklasson, AMN
AF Kulichenko, Maksim
   Barros, Kipton
   Lubbers, Nicholas
   Fedik, Nikita
   Zhou, Guoqing
   Tretiak, Sergei
   Nebgen, Benjamin
   Niklasson, Anders M. N.
TI Semi-Empirical Shadow Molecular Dynamics: A PyTorch Implementation
SO JOURNAL OF CHEMICAL THEORY AND COMPUTATION
DT Article
ID GRAMICIDIN-S; BROYDEN METHOD; CONVERGENCE; PARAMETERS; SPECTRA; MODEL
AB Extended Lagrangian Born-Oppenheimer molecular dynamics (XL-BOMD) in its most recent shadow potential energy version has been implemented in the semiempirical PyTorch-based software PySeQM. The implementation includes finite electronic temperatures, canonical density matrix perturbation theory, and an adaptive Krylov subspace approximation for the integration of the electronic equations of motion within the XL-BOMB approach (KSA-XL-BOMD). The PyTorch implementation leverages the use of GPU and machine learning hardware accelerators for the simulations. The new XL-BOMD formulation allows studying more challenging chemical systems with charge instabilities and low electronic energy gaps. The current public release of PySeQM continues our development of modular architecture for large-scale simulations employing semi-empirical quantum-mechanical treatment. Applied to molecular dynamics, simulation of 840 carbon atoms, one integration time step executes in 4 s on a single Nvidia RTX A6000 GPU.
C1 [Kulichenko, Maksim; Barros, Kipton; Fedik, Nikita; Nebgen, Benjamin; Niklasson, Anders M. N.] Los Alamos Natl Lab, Theoret Div, Los Alamos, NM 87545 USA.
   [Barros, Kipton; Fedik, Nikita] Los Alamos Natl Lab, Ctr Nonlinear Studies, Los Alamos, NM 87545 USA.
   [Lubbers, Nicholas] Los Alamos Natl Lab, Comp Computat & Stat Sci Div, Los Alamos, NM 87545 USA.
   [Zhou, Guoqing] NVIDIA Corp, Santa Clara, CA 95051 USA.
   [Tretiak, Sergei] Los Alamos Natl Lab, Theoret Div, Ctr Nonlinear Studies, Los Alamos, NM 87545 USA.
   [Tretiak, Sergei] Los Alamos Natl Lab, Ctr Integrated Nanotechnol, Los Alamos, NM 87545 USA.
RP Kulichenko, M; Niklasson, AMN (corresponding author), Los Alamos Natl Lab, Theoret Div, Los Alamos, NM 87545 USA.
EM maxim@lanl.gov; amn@lanl.gov
CR Albaugh A, 2018, J CHEM THEORY COMPUT, V14, P499, DOI 10.1021/acs.jctc.7b01041
   Albaugh A, 2017, J PHYS CHEM LETT, V8, P1714, DOI 10.1021/acs.jpclett.7b00450
   Allen M., 1989, COMPUTER SIMULATION, DOI DOI 10.1007/BF00646086
   ANDERSON DG, 1965, J ACM, V12, P547, DOI 10.1145/321296.321305
   Arita M, 2014, J CHEM THEORY COMPUT, V10, P5419, DOI 10.1021/ct500847y
   Atkins P., 2009, ELEMENTS PHYS CHEM, P459
   Bannwarth C, 2021, WIRES COMPUT MOL SCI, V11, DOI 10.1002/wcms.1493
   Bikadi Z, 2009, J CHEMINFORMATICS, V1, DOI 10.1186/1758-2946-1-15
   Bjorgaard JA, 2018, J CHEM THEORY COMPUT, V14, P799, DOI 10.1021/acs.jctc.7b00857
   Bonella S, 2020, PHYS CHEM CHEM PHYS, V22, P10775, DOI 10.1039/d0cp00163e
   BROYDEN CG, 1965, MATH COMPUT, V19, P557
   CAR R, 1985, PHYS REV LETT, V55, P2471, DOI 10.1103/PhysRevLett.55.2471
   Christensen AS, 2016, CHEM REV, V116, P5301, DOI 10.1021/acs.chemrev.5b00584
   Coretti A, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5055704
   Davidchack RL, 2009, J CHEM PHYS, V130, DOI 10.1063/1.3149788
   DEWAR MJS, 1977, J AM CHEM SOC, V99, P4899, DOI 10.1021/ja00457a004
   DEWAR MJS, 1985, J AM CHEM SOC, V107, P3902, DOI 10.1021/ja00299a024
   Dral PO, 2015, J CHEM THEORY COMPUT, V11, P2120, DOI 10.1021/acs.jctc.5b00141
   Erteeb MA, 2021, AM J CHEM, P1, DOI [./10.5923/j.chemistry.20211101.01, DOI 10.5923/J.CHEMISTRY.20211101.01]
   Gause GF, 1944, NATURE, V154, P703, DOI 10.1038/154703a0
   GLASSER L, 1987, J CHEM EDUC, V64, pA260, DOI 10.1021/ed064pA260
   Hourahine B, 2020, J CHEM PHYS, V152, DOI 10.1063/1.5143190
   JOHNSON DD, 1988, PHYS REV B, V38, P12807, DOI 10.1103/PhysRevB.38.12807
   Joshi K, 2012, J PHYS CHEM B, V116, P483, DOI 10.1021/jp207102v
   KERKER GP, 1981, PHYS REV B, V23, P3082, DOI 10.1103/PhysRevB.23.3082
   KOHN W, 1965, PHYS REV, V140, P1133, DOI 10.1103/PhysRev.140.A1133
   Kupser P, 2010, J AM CHEM SOC, V132, P2085, DOI 10.1021/ja909842j
   Leven I, 2019, PHYS CHEM CHEM PHYS, V21, P18652, DOI 10.1039/c9cp02979f
   Martínez E, 2015, J CHEM PHYS, V142, DOI 10.1063/1.4917546
   Marx D., 2000, NIC SERIES, V3, P329
   MCWEENY R, 1960, REV MOD PHYS, V32, P335, DOI 10.1103/RevModPhys.32.335
   MERMIN ND, 1963, ANN PHYS-NEW YORK, V21, P99, DOI 10.1016/0003-4916(63)90226-4
   Nagornova NS, 2010, J AM CHEM SOC, V132, P4040, DOI 10.1021/ja910118j
   Niklasson AMN, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.123001
   Niklasson AMN, 2021, EUR PHYS J B, V94, DOI 10.1140/epjb/s10051-021-00151-6
   Niklasson AMN, 2020, J CHEM THEORY COMPUT, V16, P3628, DOI 10.1021/acs.jctc.0c00264
   Niklasson AMN, 2020, J CHEM PHYS, V152, DOI 10.1063/1.5143270
   Niklasson AMN, 2017, J CHEM PHYS, V147, DOI 10.1063/1.4985893
   Niklasson AMN, 2009, J CHEM PHYS, V130, DOI 10.1063/1.3148075
   Niklasson AMN, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.123004
   Niklasson AMN, 2007, J CHEM PHYS, V126, DOI 10.1063/1.2715556
   Paszke A., 2017, NIPS
   Peak D., 2005, ENCY SOILS ENV, V4, P80, DOI DOI 10.1016/B0-12-348530-4/00174-0
   PULAY P, 1980, CHEM PHYS LETT, V73, P393, DOI 10.1016/0009-2614(80)80396-4
   Pulay P, 2004, CHEM PHYS LETT, V386, P272, DOI 10.1016/j.cplett.2004.01.069
   PULAY P, 1969, MOL PHYS, V17, P197, DOI 10.1080/00268976900100941
   PURVIS GD, 1982, J CHEM PHYS, V76, P1910, DOI 10.1063/1.443164
   Radhi A.H., 2020, NEUROQUANTOLOGY, V18, P37, DOI https://doi.org/10.14704/nq.2020.18.1.NQ20105
   Remler DK, 1990, MOL PHYS, V70, P921, DOI 10.1080/00268979000101451
   ROOTHAAN CCJ, 1951, REV MOD PHYS, V23, P69, DOI 10.1103/RevModPhys.23.69
   Sabirov DS, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8060968
   Schwerdtfeger P, 2015, WIRES COMPUT MOL SCI, V5, P96, DOI 10.1002/wcms.1207
   SRIVASTAVA GP, 1984, J PHYS A-MATH GEN, V17, pL317, DOI 10.1088/0305-4470/17/6/002
   Steneteg P, 2010, PHYS REV B, V82, DOI 10.1103/PhysRevB.82.075110
   STEWART JJP, 1989, J COMPUT CHEM, V10, P209, DOI 10.1002/jcc.540100208
   Thiel W, 2014, WIRES COMPUT MOL SCI, V4, P145, DOI 10.1002/wcms.1161
   TOXVAERD S, 1994, PHYS REV E, V50, P2271, DOI 10.1103/PhysRevE.50.2271
   VandeVondele J, 2005, COMPUT PHYS COMMUN, V167, P103, DOI 10.1016/j.cpc.2004.12.014
   Vitale V, 2015, J CHEM THEORY COMPUT, V11, P3321, DOI 10.1021/acs.jctc.5b00391
   Wilson Jr E.B., 1980, MOL VIBRATIONS
   Zhang Q, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79153-w
   Zheng GS, 2011, J CHEM PHYS, V135, DOI 10.1063/1.3605303
   Zheng PK, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27340-2
   Zhou GQ, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2120333119
   Zhou GQ, 2020, J CHEM THEORY COMPUT, V16, P4951, DOI 10.1021/acs.jctc.0c00243
NR 65
TC 0
Z9 0
U1 6
U2 6
PD MAY 10
PY 2023
VL 19
IS 11
BP 3209
EP 3222
DI 10.1021/acs.jctc.3c00234
EA MAY 2023
UT WOS:000989055100001
DA 2023-11-16
ER

PT C
AU Vieira, J
   Roma, N
   Falcao, G
   Tomás, P
AF Vieira, Joao
   Roma, Nuno
   Falcao, Gabriel
   Tomas, Pedro
GP IEEE
TI PROCESSING CONVOLUTIONAL NEURAL NETWORKS ON CACHE
SO 2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
DT Proceedings Paper
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 04-08, 2020
CL Barcelona, SPAIN
DE CNNs; SIMD; Near-cache processing
ID CNN
AB With the advent of Big Data application domains, several Machine Learning (ML) signal-processing algorithms, such as Convolutional Neural Networks (CNNs), are required to process progressively larger datasets at a great cost in terms of both compute power and memory bandwidth. Although dedicated accelerators have been developed targeting this issue, they usually require moving massive amounts of data across the memory hierarchy to the processing cores and low-level knowledge of how data is stored in the memory devices to enable in-/near-memory processing solutions. In this paper, we propose and assess a novel mechanism that operates at cache level, leveraging both data-proximity and parallel processing capabilities, enabled by dedicated fully-digital vector Functional Units (FUs). We also demonstrate the integration of this mechanism in a conventional Central Processing Unit (CPU). The obtained results show that our engine provides performance improvements on CNNs ranging from 3.92x to 16.6x.
C1 [Vieira, Joao; Roma, Nuno; Tomas, Pedro] Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
   [Falcao, Gabriel] Univ Coimbra, Inst Telecomunicacoes, Coimbra, Portugal.
RP Vieira, J (corresponding author), Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agrawal T, 2019, INT CONF ACOUST SPEE, P1363, DOI 10.1109/ICASSP.2019.8682397
   Barmpoutis P, 2019, INT CONF ACOUST SPEE, P8301, DOI [10.1109/icassp.2019.8682647, 10.1109/ICASSP.2019.8682647]
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Eckert C, 2019, IEEE MICRO, V39, P11, DOI 10.1109/MM.2019.2908101
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   Girshick R. B., 2014, CORR, P580, DOI DOI 10.1109/CVPR.2014.81
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Liu X., 2019, ISLPED, P1
   Pons J, 2019, INT CONF ACOUST SPEE, P336, DOI 10.1109/ICASSP.2019.8682912
   Pouyan P, 2016, INT WORKS POW TIM, P141, DOI 10.1109/PATMOS.2016.7833679
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Seshadri V, 2015, IEEE COMPUT ARCHIT L, V14, P127, DOI 10.1109/LCA.2015.2434872
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shaikh S, 2019, BJR CASE REP, V5, DOI 10.1259/bjrcr.20180001
   Sun J, 2019, INT CONF ACOUST SPEE, P7285, DOI 10.1109/ICASSP.2019.8682201
   Vieira J., 2019, VLSI SOC
   Vieira J, 2018, INT SYM COMP ARCHIT, P197, DOI [10.1109/CAHPC.2018.8645905, 10.1109/SBAC-PAD.2018.00041]
   Wang XW, 2019, INT S HIGH PERF COMP, P81, DOI 10.1109/HPCA.2019.00029
   Wang Y, 2018, IEEE T PARALL DISTR, V29, P1428, DOI 10.1109/TPDS.2018.2791440
   Wu X, 2017, NONLINEAR ANAL-HYBRI, V26, P1, DOI 10.1016/j.nahs.2017.04.001
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Yitbarek SF, 2016, DES AUT TEST EUROPE, P1449
NR 27
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 1658
EP 1662
DI 10.1109/icassp40776.2020.9054326
UT WOS:000615970401179
DA 2023-11-16
ER

PT C
AU Cancilla, M
   Canalini, L
   Bolelli, F
   Allegretti, S
   Carrión, S
   Paredes, R
   Gómez, JA
   Leo, S
   Piras, ME
   Pireddu, L
   Badouh, A
   Marco-Sola, S
   Alvarez, L
   Moreto, M
   Grana, C
AF Cancilla, Michele
   Canalini, Laura
   Bolelli, Federico
   Allegretti, Stefano
   Carrion, Salvador
   Paredes, Roberto
   Gomez, Jon A.
   Leo, Simone
   Piras, Marco Enrico
   Pireddu, Luca
   Badouh, Asaf
   Marco-Sola, Santiago
   Alvarez, Lluc
   Moreto, Miquel
   Grana, Costantino
GP IEEE COMP SOC
TI The DeepHealth Toolkit: A Unified Framework to Boost Biomedical
   Applications
SO 2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
DT Proceedings Paper
CT 25th International Conference on Pattern Recognition (ICPR)
CY JAN 10-15, 2021
CL ELECTR NETWORK
AB Given the overwhelming impact of machine learning on the last decade, several libraries and frameworks have been developed in recent years to simplify the design and training of neural networks, providing array-based programming, automatic differentiation and user-friendly access to hardware accelerators. None of those tools, however, was designed with native and transparent support for Cloud Computing or heterogeneous High-Performance Computing (HPC). The DeepHealth Toolkit is an open source Deep Learning toolkit aimed at boosting productivity of data scientists operating in the medical field by providing a unified framework for the distributed training of neural networks, which is able to leverage hybrid HPC and cloud environments in a transparent way for the user. The toolkit is composed of a Computer Vision library, a Deep Learning library, and a front-end for non-expert users; all of the components are focused on the medical domain, but they are general purpose and can be applied to any other field. In this paper, the principles driving the design of the DeepHealth libraries are described, along with details about the implementation and the interaction between the different elements composing the toolkit. Finally, experiments on common benchmarks prove the efficiency of each separate component and of the DeepHealth Toolkit overall.
C1 [Cancilla, Michele; Canalini, Laura; Bolelli, Federico; Allegretti, Stefano; Grana, Costantino] Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Modena, Italy.
   [Carrion, Salvador; Paredes, Roberto; Gomez, Jon A.] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
   [Leo, Simone; Piras, Marco Enrico; Pireddu, Luca] CRS4, Data Intens Comp Grp, Pula, Italy.
   [Badouh, Asaf; Marco-Sola, Santiago] Barcelona Supercomp Ctr, Barcelona, Spain.
   [Marco-Sola, Santiago; Alvarez, Lluc; Moreto, Miquel] Univ Autonoma Barcelona, Barcelona, Spain.
   [Alvarez, Lluc; Moreto, Miquel] Univ Politecn Cataluna, Barcelona, Spain.
RP Cancilla, M (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Modena, Italy.
EM michele.cancilla@unimore.it; laura.canalini@unimore.it;
   federico.bolelli@unimore.it; stefano.allegretti@unimore.it;
   salcarpo@prhlt.upv.es; rparedes@prhlt.upv.es; jon@prhlt.upv.es;
   simone.leo@crs4.it; marco.enrico.piras@crs4.it; luca.pireddu@crs4.it;
   asaf.badouh@bsc.es; santiago.marco-sola@bsc.es; lluc.alvarez@bsc.es;
   miguel.moreto@bsc.es; costantino.grana@unimore.it
CR Allegretti S., 2020, 4 INT C IM VIS PATT
   Allegretti S, 2020, IEEE T PARALL DISTR, V31, P423, DOI 10.1109/TPDS.2019.2934683
   [Anonymous], 2020, SIIM ACR PNEUMOTHORA
   [Anonymous], 2020, KUBEFLOW MACHINE LEA
   [Anonymous], 2020, RABBITMQ MESSAGING J
   [Anonymous], 2020, CELERY DISTRIBUTED T
   [Anonymous], 2020, WXWIDGETS CROSSPLATF
   [Anonymous], 2020, DJANGO WEB FRAMEWORK
   [Anonymous], 2020, OPENAPI SPECIFICATIO
   [Anonymous], 2020, LANGUAGE NEUTRAL PLA
   [Anonymous], 2020, YAML YAML AINT MARKU
   [Anonymous], 2020, OPEN NEURAL NETWORK
   Badia Rosa M., 2015, SoftwareX, V3-4, P32, DOI 10.1016/j.softx.2015.10.004
   Bolelli F, 2019, LECT NOTES COMPUT SC, V11752, P148, DOI 10.1007/978-3-030-30645-8_14
   Bolelli F, 2020, J REAL-TIME IMAGE PR, V17, P229, DOI 10.1007/s11554-018-0756-1
   Bolelli F, 2020, IEEE T IMAGE PROCESS, V29, P1999, DOI 10.1109/TIP.2019.2946979
   Chollet F., 2015, KERAS
   Combalia M., 2019, BCN20000 DERMOSCOPIC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Jakob W., 2020, PYBIND11 SEAMLESS OP
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lyskov S, 2020, BINDER
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
NR 25
TC 7
Z9 7
U1 0
U2 3
PY 2021
BP 9881
EP 9888
DI 10.1109/ICPR48806.2021.9411954
UT WOS:000681331402052
DA 2023-11-16
ER

PT C
AU Schimmelpfennig, RDR
   Vef, MRAR
   Salkhordeh, RZ
   Miranda, AEO
   Nou, RAM
   Brinkmann, AR
AF Schimmelpfennig, Frederic
   Vef, Marc-Andre
   Salkhordeh, Reza
   Miranda, Alberto
   Nou, Ramon
   Brinkmann, Andre
GP IEEE Comp Soc
TI Streamlining distributed Deep Learning I/O with ad hoc file systems
SO 2021 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER 2021)
SE IEEE International Conference on Cluster Computing
DT Proceedings Paper
CT IEEE International Conference on Cluster Computing (Cluster)
CY SEP 07-10, 2021
CL ELECTR NETWORK
DE Deep Learning; HPC; file system; data parallel
AB With evolving techniques to parallelize Deep Learning (DL) and the growing amount of training data and model complexity, High-Performance Computing (HPC) has become increasingly important for machine learning engineers. Although many compute clusters already use learning accelerators or GPUs, HPC storage systems are not suitable for the I/O requirements of DL workflows. Therefore, users typically copy the whole training data to the worker nodes or distribute partitions. Because DL depends on randomized input data, prior work stated that partitioning impacts DL accuracy. Their solutions focused mainly on training I/O performance on a high-speed network but did not cover the data stage-in process, for example.
   We show in this paper that, in practice, (unbiased) partitioning is not harmful for distributed DL accuracy. Nevertheless, manual partitioning can be error prone and inefficient. Typically, data must be unpacked and shuffled before it is distributed to nodes. We propose a solution that features both: efficient stage-in and fast access to a global namespace to prevent biases. Our architecture is based around an ad hoc storage system relying on a high-speed interconnect allowing an efficient stage-in of DL data sets into a single global namespace. Our proposed solution does not limit access to parts of the data set or relies on data duplication, also relieving the HPC storage system. We obtain high I/O performance during training and ensure minimal interference with communication of the learning workers. The optimizations are transparent to DL applications and their accuracy is not affected by our architecture.
C1 [Schimmelpfennig, Frederic; Vef, Marc-Andre; Salkhordeh, Reza; Brinkmann, Andre] Johannes Gutenberg Univ Mainz, Mainz, Germany.
   [Miranda, Alberto; Nou, Ramon] Barcelona Supercomp Ctr BSC, Barcelona, Spain.
RP Schimmelpfennig, RDR (corresponding author), Johannes Gutenberg Univ Mainz, Mainz, Germany.
EM frschimm@uni-mainz.de; vef@uni-mainz.de; rsalkhor@uni-mainz.de;
   alberto.miranda@bsc.es; ramon.nou@bsc.es; brinkman@uni-mainz.de
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2015, 13 USENIX C FILE STO
   Bahri Y., 2021, ABS210206701 CORR
   Ben-Nun T, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3320060
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Braam P., 2005, ABS190301955
   Brinkmann A, 2020, J COMPUT SCI TECH-CH, V35, P4, DOI 10.1007/s11390-020-9801-1
   Chien SWD, 2020, IEEE INT C CL COMP, P359, DOI 10.1109/CLUSTER49012.2020.00046
   Chien SWD, 2018, PROCEEDINGS OF 2018 IEEE/ACM 3RD JOINT INTERNATIONAL WORKSHOP ON PARALLEL DATA STORAGE & DATA INTENSIVE SCALABLE COMPUTING SYSTEMS (PDSW-DISCS), P54, DOI 10.1109/PDSW-DISCS.2018.00011
   Chowdhury F, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337902
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar Piotr, 2017, P IEEE INT C COMPUTE, P2961
   Dueben PD, 2018, GEOSCI MODEL DEV, V11, P3999, DOI 10.5194/gmd-11-3999-2018
   He Kaiming, 2016, PROC CVPR IEEE
   Herold Frank, 2014, INTRO BEEGFS
   Jacob S, 2019, PROCEEDINGS OF THE 2019 RESEARCH ON EQUITY AND SUSTAINED PARTICIPATION IN ENGINEERING, COMPUTING, AND TECHNOLOGY (RESPECT), DOI [10.1109/respect46404.2019.8985944, 10.1109/cluster.2019.8891012]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V3, P6
   Kurth T, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Meng Q, 2019, NEUROCOMPUTING, V337, P46, DOI 10.1016/j.neucom.2019.01.037
   Mikami H., 2018, ARXIV PREPRINT ARXIV
   Oral S., 2013, P CRAY US GROUP C CU
   Oyama Y, 2021, IEEE T PARALL DISTR, V32, P1641, DOI 10.1109/TPDS.2020.3047974
   Paszke A., 2019, ADV NEURAL INFORM PR
   Patel T, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356183
   Pumma S, 2019, ACM TRANS PARALLEL C, V6, DOI 10.1145/3331526
   Rasp S, 2018, P NATL ACAD SCI USA, V115, P9684, DOI 10.1073/pnas.1810286115
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Schmuck F, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FAST'02 CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P231
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Soumagne J., 2013, IEEE INT C CL COMP, P1
   Sun Peng, 2019, ARXIV190206855
   Vef M.-A., 2018, P 2018 IEEE INT C CL
   Vef MA, 2020, J COMPUT SCI TECH-CH, V35, P72, DOI 10.1007/s11390-020-9797-6
   Vef MA, 2018, ACM T STORAGE, V14, DOI 10.1145/3149376
   Wang LP, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404472
   Wang T, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P807, DOI 10.1109/SC.2016.68
   Yang CC, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P235, DOI 10.1109/HiPC.2019.00037
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Zagoruyko Sergey, 2016, BRIT MACHINE VISION, P5
   Zhang Z, 2020, INT PARALL DISTRIB P, P409, DOI 10.1109/IPDPS47924.2020.00050
   Zhu Y, 2019, IEEE INT C CL COMP, P34, DOI 10.1109/cluster.2019.8891023
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
NR 44
TC 0
Z9 0
U1 0
U2 2
PY 2021
BP 169
EP 180
DI 10.1109/Cluster48925.2021.00062
UT WOS:000728391000016
DA 2023-11-16
ER

PT J
AU Valdes, G
   Morin, O
   Valenciaga, Y
   Kirby, N
   Pouliot, J
   Chuang, C
AF Valdes, Gilmer
   Morin, Olivier
   Valenciaga, Yanisley
   Kirby, Niel
   Pouliot, Jean
   Chuang, Cynthia
TI Use of TrueBeam developer mode for imaging QA
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE automated QA; TrueBeam developer mode; XML scripts; image-guidance
   radiation therapy; support vector machine
ID CONE-BEAM CT; QUALITY-ASSURANCE; SYSTEM
AB The purpose of this study was to automate regular Imaging QA procedures to become more efficient and accurate. Daily and monthly imaging QA for SRS and SBRT protocols were fully automated on a Varian linac. A three-step paradigm where the data are automatically acquired, processed, and analyzed was defined. XML scripts were written and used in developer mode in a TrueBeam linac to automatically acquire data. MATLAB R013B was used to develop an interface that could allow the data to be processed and analyzed. Hardware was developed that allowed the localization of several phantoms simultaneously on the couch. 14 KV CBCTs from the Emma phantom were obtained using a TrueBeam onboard imager as example of data acquisition and analysis. The images were acquired during two months. Artifacts were artificially introduced in the images during the reconstruction process using iTool reconstructor. Support vector machine algorithms to automatically identify each artifact were written using the Machine Learning MATLAB R2011 Toolbox. A daily imaging QA test could be performed by an experienced medical physicist in 14.3 +/- 2.4 min. The same test, if automated using our paradigm, could be performed in 4.2 +/- 0.7 min. In the same manner, a monthly imaging QA could be performed by a physicist in 70.7 +/- 8.0 min and, if fully automated, in 21.8 +/- 0.6 min. Additionally, quantitative data analysis could be automatically performed by Machine Learning Algorithms that could remove the subjectivity of data interpretation in the QA process. For instance, support vector machine algorithms could correctly identify beam hardening, rings and scatter artifacts. Traditional metrics, as well as metrics that describe texture, are needed for the classification. Modern linear accelerators are equipped with advanced 2D and 3D imaging capabilities that are used for patient alignment, substantially improving IGRT treatment accuracy. However, this extra complexity exponentially increases the number of QA tests needed. Using the new paradigm described above, not only the bare minimum - but also best practice - QA programs could be implemented with the same manpower.
C1 [Valdes, Gilmer; Morin, Olivier; Kirby, Niel] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA USA.
   [Valdes, Gilmer; Pouliot, Jean; Chuang, Cynthia] Univ Penn, Dept Radiat Oncol, Perelman Ctr Adv Med, Philadelphia, PA 19104 USA.
   [Valenciaga, Yanisley] Univ Calif Los Angeles, David Geffen Sch Med, Biomed Phys Interdept Program, Los Angeles, CA 90095 USA.
RP Valdes, G (corresponding author), Perelman Ctr Adv Med, Dept Radiat Oncol, 3400 Civ Blvd, Philadelphia, PA 19104 USA.
EM gilmer.valdes@uphs.upenn.edu
CR Bissonnette JP, 2012, MED PHYS, V39, P1946, DOI 10.1118/1.3690466
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Das Indra J, 2011, J Appl Clin Med Phys, V12, P3350
   DROEGE RT, 1982, MED PHYS, V9, P758, DOI 10.1118/1.595124
   FONTENOT JD, 2014, J APPL CLIN MED PHY, V15, P4528
   Gao S, 2012, MED PHYS, V39, P3604, DOI 10.1118/1.4734633
   Gayou O, 2007, MED PHYS, V34, P3183, DOI 10.1118/1.2752374
   Gopal A, 2009, MED PHYS, V36, P2006, DOI 10.1118/1.3099559
   Kim C, 2012, MED PHYS, V39, P3656, DOI 10.1118/1.4734854
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   LUTZ W, 1988, INT J RADIAT ONCOL, V14, P373, DOI 10.1016/0360-3016(88)90446-4
   Soh L., 1999, IEEE T GEOSCI REMOTE, V37
   Sumida I, 2014, J RADIAT RES, V55, P191, DOI 10.1093/jrr/rrt100
   Tourassi GD, 1999, RADIOLOGY, V213, P317, DOI 10.1148/radiology.213.2.r99nv49317
NR 14
TC 26
Z9 27
U1 0
U2 11
PY 2015
VL 16
IS 4
BP 322
EP 333
DI 10.1120/jacmp.v16i4.5363
UT WOS:000368340600027
DA 2023-11-16
ER

PT J
AU Looe, HK
   Blum, I
   Schönfeld, AB
   Tekin, T
   Delfs, B
   Poppe, B
AF Looe, Hui Khee
   Blum, Isabel
   Schoenfeld, Ann-Britt
   Tekin, Tuba
   Delfs, Bjoern
   Poppe, Bjoern
TI Model-based machine learning for the recovery of lateral dose profiles
   of small photon fields in magnetic field
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE magnetic resonance guided radiation therapy; Lorentz force; small field
   dosimetry; lateral response function; artificial neural network;
   deconvolution; machine learning
ID BODY RADIATION-THERAPY; MONTE-CARLO; IONIZATION CHAMBERS; DOSIMETER
   RESPONSE; DETECTOR DENSITY; DIODE; DECONVOLUTION; ACCELERATOR; SYSTEM;
   IMPACT
AB Objective. To investigate the feasibility to train artificial neural networks (NN) to recover lateral dose profiles from detector measurements in a magnetic field. Approach. A novel framework based on a mathematical convolution model has been proposed to generate measurement-less training dataset. 2D dose deposition kernels and detector lateral fluence response functions of two air-filled ionization chambers and two diode-type detectors have been simulated without magnetic field and for magnetic field B = 0.35 and 1.5 T. Using these convolution kernels, training dataset consisting pairs of dose profiles D (x, y) and signal profiles M (x, y) were computed for a total of 108 2D photon fluence profiles psi(x, y) (80% training/20% validation). The NN were tested using three independent datasets, where the second test dataset has been obtained from simulations using realistic phase space files of clinical linear accelerator and the third test dataset was measured at a conventional linac equipped with electromagnets. Main results. The convolution kernels show magnetic field dependence due to the influence of the Lorentz force on the electron transport in the water phantom and detectors. The NN show good performance during training and validation with mean square error reaching a value of 1e-6 or smaller. The corresponding correlation coefficients R reached the value of 1 for all models indicating an excellent agreement between expected D (x, y) and predicted D-pred(x, y). The comparisons between D (x, y) and D-pred (x, y) using the three test datasets resulted in gamma indices (1 mm/1% global) <1 for all evaluated data points. Significance. Two verification approaches have been proposed to warrant the mathematical consistencies of the NN outputs. Besides offering a correction strategy not existed so far for relative dosimetry in a magnetic field, this work could help to raise awareness and to improve understanding on the distortion of detector's signal profiles by a magnetic field.
C1 [Looe, Hui Khee; Blum, Isabel; Tekin, Tuba; Delfs, Bjoern; Poppe, Bjoern] Carl von Ossietzky Univ Oldenburg, Pius Hosp, Univ Clin Med Radiat Phys, Med Campus, Oldenburg, Germany.
   [Schoenfeld, Ann-Britt] PTB, Braunschweig, Germany.
RP Looe, HK (corresponding author), Carl von Ossietzky Univ Oldenburg, Pius Hosp, Univ Clin Med Radiat Phys, Med Campus, Oldenburg, Germany.
EM hui.k.looe@uni-oldenburg.de
CR Bednarz G, 2002, PHYS MED BIOL, V47, P3643, DOI 10.1088/0031-9155/47/20/306
   Blum I, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac0f2e
   Chofor N, 2014, Z MED PHYS, V24, P27, DOI 10.1016/j.zemedi.2013.04.001
   Chofor N, 2012, Z MED PHYS, V22, P181, DOI 10.1016/j.zemedi.2012.05.001
   Corradini S, 2019, RADIAT ONCOL, V14, DOI 10.1186/s13014-019-1308-y
   Cranmer-Sargison G, 2011, MED PHYS, V38, P6592, DOI 10.1118/1.3658572
   de Pooter J, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ab9efe
   Delfs B, 2021, MED PHYS, DOI 10.1002/mp.14994
   Delfs B, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aadd3d
   Delfs B, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aa9bd5
   FEIST H, 1968, NUCL INSTRUM METHODS, V58, P236, DOI 10.1016/0029-554X(68)90470-9
   Fenwick JD, 2013, PHYS MED BIOL, V58, P2901, DOI 10.1088/0031-9155/58/9/2901
   Folkert MR, 2017, ADV DRUG DELIVER REV, V109, P3, DOI 10.1016/j.addr.2016.11.005
   Francescon P, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab6154
   Francescon P, 2017, PHYS MED BIOL, V62, P1076, DOI 10.1088/1361-6560/aa5610
   Harder D., 2014, COMPREHENSIVE BIOMED, P249
   Herrup D, 2005, MED PHYS, V32, P3636, DOI 10.1118/1.2128086
   Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0
   Kontaxis C, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abd66d
   Laub WU, 2003, MED PHYS, V30, P341, DOI 10.1118/1.1544678
   Liu H, 2018, MED PHYS, V45, P5586, DOI 10.1002/mp.13230
   Looe HK, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aab50c
   Looe HK, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aa9b46
   Looe HK, 2017, PHYS MED BIOL, V62, P5131, DOI 10.1088/1361-6560/aa6ca0
   Looe HK, 2015, PHYS MED BIOL, V60, P6585, DOI 10.1088/0031-9155/60/16/6585
   Looe HK, 2013, Z MED PHYS, V23, P129, DOI 10.1016/j.zemedi.2012.12.010
   Malkov VN, 2016, MED PHYS, V43, P4447, DOI 10.1118/1.4954318
   Meijsing I, 2009, PHYS MED BIOL, V54, P2993, DOI 10.1088/0031-9155/54/10/002
   Morales JE, 2014, MED PHYS, V41, DOI 10.1118/1.4895827
   Mund K, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12865
   Mutic S, 2014, SEMIN RADIAT ONCOL, V24, P196, DOI 10.1016/j.semradonc.2014.02.008
   O'Brien DJ, 2018, MED PHYS, V45, P884, DOI 10.1002/mp.12699
   Palacios MA, 2018, INT J RADIAT ONCOL, V102, P426, DOI 10.1016/j.ijrobp.2018.06.002
   Pappas E, 2006, MED PHYS, V33, P3700, DOI 10.1118/1.2349691
   Pojtinger S, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aac4f2
   Poppinga D, 2018, Z MED PHYS, V28, P224, DOI 10.1016/j.zemedi.2017.07.006
   Raaymakers BW, 2009, PHYS MED BIOL, V54, pN229, DOI 10.1088/0031-9155/54/12/N01
   Reynolds M, 2014, MED PHYS, V41, DOI 10.1118/1.4893276
   Reynolds M, 2013, MED PHYS, V40, DOI 10.1118/1.4794496
   Rister B, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00715-8
   Schönfeld AB, 2021, J APPL CLIN MED PHYS, V22, P64, DOI 10.1002/acm2.13447
   Schönfeld AB, 2019, MED PHYS, V46, P4257, DOI 10.1002/mp.13710
   Scott AJD, 2012, PHYS MED BIOL, V57, P4461, DOI 10.1088/0031-9155/57/14/4461
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simiele E, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aab56c
   SKARSGARD L, 1961, RADIAT RES, V14, P261, DOI 10.2307/3570921
   Spindeldreier CK, 2017, PHYS MED BIOL, V62, P6708, DOI 10.1088/1361-6560/aa7ae4
   Tekin T, 2020, MED PHYS, V47, P6509, DOI 10.1002/mp.14535
   Thariat J, 2013, NAT REV CLIN ONCOL, V10, P52, DOI 10.1038/nrclinonc.2012.203
   Timmerman RD, 2014, J CLIN ONCOL, V32, P2847, DOI 10.1200/JCO.2014.55.4675
   Underwood TSA, 2013, MED PHYS, V40, DOI 10.1118/1.4812687
   Weber C, 2020, MED PHYS, V47, P3165, DOI 10.1002/mp.14149
NR 52
TC 0
Z9 0
U1 0
U2 1
PD APR 21
PY 2022
VL 67
IS 8
AR 085006
DI 10.1088/1361-6560/ac5bfa
UT WOS:000778387000001
DA 2023-11-16
ER

PT C
AU Rankin, D
   Krupa, J
   Harris, P
   Flechas, MA
   Holzman, B
   Klijnsma, T
   Pedro, K
   Tran, N
   Hauck, S
   Hsu, SC
   Trahms, M
   Lin, K
   Lou, Y
   Ho, TW
   Duarte, J
   Liu, M
AF Rankin, Dylan
   Krupa, Jeffrey
   Harris, Philip
   Flechas, Maria Acosta
   Holzman, Burt
   Klijnsma, Thomas
   Pedro, Kevin
   Tran, Nhan
   Hauck, Scott
   Hsu, Shih-Chieh
   Trahms, Matthew
   Lin, Kelvin
   Lou, Yu
   Ho, Ta-Wei
   Duarte, Javier
   Liu, Mia
GP IEEE
TI FPGAs-as-a-Service Toolkit (FaaST)
SO PROCEEDINGS OF H2RC 2020: 2020 SIXTH IEEE/ACM INTERNATIONAL WORKSHOP ON
   HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC)
DT Proceedings Paper
CT 6th IEEE/ACM International Workshop on Heterogeneous High-performance
   Reconfigurable Computing (H2RC)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE FPGAs; machine learning; as a service; high energy physics
AB Computing needs for high energy physics are already intensive and are expected to increase drastically in the coming years. In this context, heterogeneous computing, specifically as-a-service computing, has the potential for significant gains over traditional computing models. Although previous studies and packages in the field of heterogeneous computing have focused on GPUs as accelerators, FPGAs are an extremely promising option as well. A series of workflows are developed to establish the performance capabilities of FPGAs as a service. Multiple different devices and a range of algorithms for use in high energy physics are studied. For a small, dense network, the throughput can be improved by an order of magnitude with respect to GPUs as a service. For large convolutional networks, the throughput is found to be comparable to GPUs as a service. This work represents the first open-source FPGAs-as-a-service toolkit.
C1 [Rankin, Dylan; Krupa, Jeffrey; Harris, Philip] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Flechas, Maria Acosta; Holzman, Burt; Klijnsma, Thomas; Pedro, Kevin; Tran, Nhan] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Hauck, Scott; Hsu, Shih-Chieh; Trahms, Matthew; Lin, Kelvin; Lou, Yu] Univ Washington, Seattle, WA 98195 USA.
   [Ho, Ta-Wei] Natl Tsing Hua Univ, Hsinchu 300044, Taiwan.
   [Duarte, Javier] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Liu, Mia] Purdue Univ, W Lafayette, IN 47907 USA.
RP Rankin, D (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Agarap Abien Fred, 2018, ARXIV PREPRINT ARXIV, P7
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   ATLAS Collaboration, 2020, COMPUTING SOFTWARE P
   Aymerich FM, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P120
   Banerjee P, 2011, COMPUTER, V44, P36, DOI 10.1109/MC.2011.67
   Bennett K, 2000, SEVENTH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P214, DOI 10.1109/APSEC.2000.896702
   Bouguettaya A, 2017, COMMUN ACM, V60, P64, DOI 10.1145/2983528
   CMS Collaboration, 2020, CMS OFFLINE COMPUTIN
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Duarte Javier, 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0027-2
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fabjan CW, 2003, REV MOD PHYS, V75, P1243, DOI 10.1103/RevModPhys.75.1243
   Ghanathe NP, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/01/C01083
   Google LLC, 2018, GRPC
   Holzman B, 2017, COMPUT SOFTW BIG SCI, V1, P1, DOI DOI 10.1007/S41781-017-0001-9
   Intel, 2018, THREAD BUILDING BLOC
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kasieczka G., 2019, **DATA OBJECT**, DOI [10.5281/zenodo.2603256, DOI 10.5281/ZENODO.2603256]
   Kasieczka G, 2019, SCIPOST PHYS, V7, DOI 10.21468/SciPostPhys.7.1.014
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Krupa J., 2020, ARXIV200710359
   Loncar V, 2020, HLS FPGA MACHINE LEA, V6, DOI [DOI 10.5281/ZENODO.3969548V0.3.0, 10.5281/zenodo.3969548V0.3.0]
   Lou Y, 2020, ML SUITE GRPC INTERF
   Massironi A, 2020, J PHYS CONF SER, V1525, DOI 10.1088/1742-6596/1525/1/012040
   Microsoft Corporation, 2020, AZURE STACK EDGE DAT
   Microsoft Corporation, 2017, MICROSOFT PLATFORM W
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Nvidia, 2019, TRITON INFERENCE SER
   Rankin D., FAAST FACILE, DOI DOI 10.5281/ZENODO.3992377
   Reese W., 2008, LINUX J, V173, P2
   Rovere M, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.591315
   Tarafdar N, 2020, ANN IEEE SYM FIELD P, P239, DOI 10.1109/FCCM48280.2020.00072
   Tarreau W., 2020, HAPROXY
   Xilinx Inc., 2020, XILINX ML SUITE
NR 38
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 38
EP 47
DI 10.1109/H2RC51942.2020.00010
UT WOS:000649743100005
DA 2023-11-16
ER

PT C
AU Tsung, PK
   Tsai, SF
   Pai, A
   Lai, SJ
   Lu, C
AF Tsung, Pei-Kuei
   Tsai, Sung-Fang
   Pai, Alex
   Lai, Shu-Jen
   Lu, Chienping
GP IEEE
TI High Performance Deep Neural Network on Low Cost Mobile GPU
SO 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE)
SE International Conference on Consumer Electronics
DT Proceedings Paper
CT IEEE International Conference on Consumer Electronics (ICCE)
CY JAN 07-11, 2016
CL Las Vegas, NV
AB In recent years, machine learning based on deep neural networks (DNN) is playing an increasingly important role. Artificial intelligence applications using DNN are achieving higher and higher accuracy levels. However, the multi-layer characteristic of a DNN makes for huge computational complexity consumption requirements. In order to feasibly run DNN applications on mobile devices, an efficient DNN flow optimized for a mobile GPU is desired. In this paper, a mobile-GPU-accelerated DNN flow is proposed. By the proposed input buffer address remapping scheme, shader assembly code optimization and kernel merging between computing nodes, 10.6 FPS is achieved in a 35.2 GFLOPS mobile GPU with 94.9mJ per frame, which is a 58x speed up and a 104x more energy efficient compared to a pure mobile CPU solution. Compared with state-of-the-art GPU accelerator devices and libraries, the proposed scheme provides a 226%similar to 1000% higher computing efficiency.
C1 [Tsung, Pei-Kuei; Tsai, Sung-Fang; Pai, Alex; Lai, Shu-Jen; Lu, Chienping] MediaTek, Hsinchu, Taiwan.
RP Tsung, PK (corresponding author), MediaTek, Hsinchu, Taiwan.
EM pei-kuei.tsung@mediatek.com; sung-fang.tsai@mediatek.com;
   alex.pai@mediatek.com; sz.lai@mediatek.com; chienping.lu@mediatek.com
CR [Anonymous], 2014, IEEE CVPR
   [Anonymous], 2013, ICASSP
   [Anonymous], 2014, DEEP VISUAL SEMANTIC
   Brown L., 2015, GTC
   Deng J., 2009, CVPR
   Krizhevsky A, 2012, NIPS 2012, V1, P1097, DOI 10.1061/(ASCE)GT.1943-5606.0001284
   Simonyan K., 2015, VERY DEEP CONVOLUTIO, V1, P3
   Szegedy C., 2014, P IEEE C COMP VIS PA, P1
NR 8
TC 0
Z9 0
U1 0
U2 2
PY 2016
UT WOS:000386327000027
DA 2023-11-16
ER

PT C
AU Chirila, M
   D'Alberto, P
   Ting, HY
   Veidenbaum, A
   Nicolau, A
AF Chirila, Mihnea
   D'Alberto, Paolo
   Ting, Hsin-Yu
   Veidenbaum, Alexander
   Nicolau, Alexandru
GP IEEE
TI A Heterogeneous Solution to the All-pairs Shortest Path Problem using
   FPGAs
SO PROCEEDINGS OF THE TWENTY THIRD INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2022)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 23rd International Symposium on Quality Electronic Design (ISQED)
CY APR 06-07, 2022
CL Santa Jose, CA
DE FPGA; heterogeneous computing; graph algorithms
AB Heterogeneous systems present exciting new opportunities for graph and Machine Learning applications. This paper presents a novel approach for the All-pairs Shortest Path (APSP) computation using a heterogeneous CPU-FPGA Accelerator system. It is based on a recursive variant of Kleene's APSP algorithm. Carefully re-engineering the algorithm to exploit parallelism in both the Floyd-Warshall algorithm and the general Kleene algorithm to perform Floyd-Warshall and Matrix-Multiply on the FPGA while the CPU efficiently balances the communication and computation between the kernels, improves state-of-the-art performance on FPGAs for APSP, while achieving near-GPU levels of performance, with less power and hardware resources, and outperforms the CPU-only solution by over 137x for a 8192x8192 problem size. When adjusted for power draw differences in process nodes, it also surpasses the GPU implementation in terms of performance per Watt by over 13%.
C1 [Chirila, Mihnea; D'Alberto, Paolo; Ting, Hsin-Yu; Veidenbaum, Alexander; Nicolau, Alexandru] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
RP Chirila, M (corresponding author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
EM mchirila@uci.edu; paolod@Xilinx.com; hting1@uci.edu; alexv@ics.uci.edu;
   nicolau@ics.uci.edu
CR Besta M., 2019, GRAPH PROCESSING FPG
   Betkaoui B., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P99, DOI 10.1109/FPL.2012.6339247
   Betkaoui B, 2012, IEEE INT CONF ASAP, P8, DOI 10.1109/ASAP.2012.30
   Bondhugula U., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Bondhugula U, 2006, ANN IEEE SYM FIELD P, P152
   Buluc A, 2010, PARALLEL COMPUT, V36, P241, DOI 10.1016/j.parco.2009.12.002
   Cormen T. H., 2009, INTRO ALGORITHMS
   D'Alberto P, 2007, ALGORITHMICA, V47, P203, DOI 10.1007/s00453-006-1224-z
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Huiling Shang, 2012, 2012 IEEE Symposium on VLSI Technology, P129, DOI 10.1109/VLSIT.2012.6242495
   Litvinov G. L, 2012, IDEMPOTENT TROPICAL
   Rezaei S., 2016, 2016 INT C RECONFIGU, P1
   Sao P, 2020, PROCEEDINGS OF THE 25TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '20), P250, DOI 10.1145/3332466.3374533
   Tommiska M., 2001, Field Programmable Logic and Applications. 11th International Conference, FPL 2001. Proceedings (Lecture Notes in Computer Science Vol.2147), P653
   TSMC, 16 12NM TECHN
   ULLMAN JD, 1990, SIGMOD REC, V19, P44, DOI 10.1145/93605.93620
   WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107
   Wu SY, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Xilinx.Inc, XIL GEMX LIB
   Zhou SJ, 2017, INT SYM COMP ARCHIT, P137, DOI 10.1109/SBAC-PAD.2017.25
   Zhou SJ, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P129, DOI 10.1109/IPDPSW.2015.130
   Zhou SJ, 2016, ANN IEEE SYM FIELD P, P103, DOI 10.1109/FCCM.2016.35
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 108
EP 113
DI 10.1109/ISQED54688.2022.9806279
UT WOS:000890309300018
DA 2023-11-16
ER

PT C
AU Dann, J
   Ritter, D
   Fröning, H
AF Dann, Jonas
   Ritter, Daniel
   Froening, Holger
GP IEEE
TI GraphScale: Scalable Bandwidth-Efficient Graph Processing on FPGAs
SO 2022 32ND INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS, FPL
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 32nd International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2022
CL Belfast, NORTH IRELAND
AB Recent advances in graph processing on FPGAs promise to alleviate performance bottlenecks with irregular memory access patterns. Such bottlenecks challenge performance for a growing number of important application areas like machine learning and data analytics. While FPGAs denote a promising solution through flexible memory hierarchies and massive parallelism, we argue that current graph processing accelerators either use the off-chip memory bandwidth inefficiently or do not scale well across memory channels.
   In this work, we propose GraphScale, a scalable graph processing framework for FPGAs. For the first time, GraphScale combines multi-channel memory with asynchronous graph processing (i.e., for fast convergence on results) and a compressed graph representation (i.e., for efficient usage of memory bandwidth and reduced memory footprint). GraphScale solves common graph problems like breadth-first search, PageRank, and weakly-connected components through modular user-defined functions, a novel two-dimensional partitioning scheme, and a high-performance two-level crossbar design.
C1 [Dann, Jonas; Ritter, Daniel] SAP SE, Walldorf, Germany.
   [Dann, Jonas; Froening, Holger] Heidelberg Univ, Heidelberg, Germany.
RP Dann, J (corresponding author), SAP SE, Walldorf, Germany.; Dann, J (corresponding author), Heidelberg Univ, Heidelberg, Germany.
EM jonas.dann@sap.com; daniel.ritter@sap.com;
   holger.froening@ziti.uni-heidelberg.de
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Attia OG, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P228, DOI 10.1109/IPDPSW.2014.30
   Balaji V, 2018, I S WORKL CHAR PROC, P203, DOI 10.1109/IISWC.2018.8573478
   Besta Maciej, 2019, DEMYSTIFYING GRAPH D
   Betkaoui B, 2012, IEEE INT CONF ASAP, P8, DOI 10.1109/ASAP.2012.30
   Chen X., 2022, TRETS
   Chenhao Liu, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, DOI 10.1145/3431920.3439463
   Dai GH, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P217, DOI 10.1145/3020078.3021739
   Dann J., 2020, NONRELATIONAL DATABA
   Dann J., 2021, BTW, P101
   Dann J., 2021, GRADES NDA
   Lei G., 2015, IRACST ESTIJ, V5
   Leskovec J., 2014, SNAP DATASETS STANFO
   Lumsdaine A, 2007, PARALLEL PROCESS LET, V17, P5, DOI 10.1142/S0129626407002843
   Rossi R. A., AAAI
   Shao Z., 2019, FPGA
   Shijie Zhou, 2015, 2015 International Conference on Reconfigurable Computing and FPGAs (ReConFig), P1, DOI 10.1109/ReConFig.2015.7393332
   Xinyu Chen, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P69, DOI 10.1145/3431920.3439290
   Yao PC, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243201
   Zhang JL, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P229, DOI 10.1145/3174243.3174245
   Zhou SJ, 2019, IEEE T PARALL DISTR, V30, P2249, DOI 10.1109/TPDS.2019.2910068
   Zhu Xiaowei, 2015, USENIX ANN TECHN C, P375
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 24
EP 32
DI 10.1109/FPL57034.2022.00016
UT WOS:000975890500004
DA 2023-11-16
ER

PT C
AU Prasad, R
   Das, S
   Martin, KJM
   Tagliavini, G
   Coussy, P
   Benini, L
   Rossi, D
AF Prasad, Rohit
   Das, Satyajit
   Martin, Kevin J. M.
   Tagliavini, Giuseppe
   Coussy, Philippe
   Benini, Luca
   Rossi, Davide
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI TRANSPIRE: An energy-efficient TRANSprecision floating-point
   Programmable archItectuRE
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB In recent years, Coarse Grain Reconfigurable Architecture (CGRA) accelerators have been increasingly deployed in Internet-of-Things (IoT) end nodes. A modern CGRA has to support and efficiently accelerate both integer and floating-point (FP) operations. In this paper, we propose an ultra-low-power tunable-precision CGRA architectural template, called TRANSprecision floating-point Programmable archItectuRE (TRANSPIRE), and its associated compilation flow supporting both integer and FP operations. TRANSPIRE employs transprecision computing and multiple Single Instruction Multiple Data (SIMD) to accelerate FP operations while boosting energy efficiency as well. Experimental results show that TRANSPIRE achieves a maximum of 10.06x performance gain and consumes 12.91x less energy w.r.t. a RISC-V based CPU with an enhanced ISA supporting SIMD-style vectorization and FP data-types, while executing applications for near-sensor computing and embedded machine learning, with an area overhead of 1.25x only.
C1 [Prasad, Rohit; Martin, Kevin J. M.; Coussy, Philippe] Univ Bretagne Sud, UMR 6285, Lab STICC, F-56100 Lorient, France.
   [Prasad, Rohit; Tagliavini, Giuseppe; Benini, Luca; Rossi, Davide] Univ Bologna, Elect Elect & Informat Engn, Bologna, Italy.
   [Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab, Zurich, Switzerland.
   [Das, Satyajit] IIT Palakkad, Dept Comp Sci & Engn, Pudussery East, Kerala, India.
RP Prasad, R (corresponding author), Univ Bretagne Sud, UMR 6285, Lab STICC, F-56100 Lorient, France.
EM Rohit.Prasad@univ-ubs.fr; satyajitdas@iitkpd.ac.in;
   Giuseppe.Tagliavini@unibo.it; Luca.Benini@iis.ee.ethz.ch
CR Akbari O., 2018, DATE 2018
   [Anonymous], 2019, STM32H7 SER
   [Anonymous], 2018, STM32 ULTRALOW POWER
   Brunelli C., 2010, J SYST ARCHIT, V56
   Carroll A., 2007, DESIGNING COARSE GRA
   Das S., 2019, TCAD, V38
   Das S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351749
   Das S, 2016, IEEE COMP SOC ANN, P655, DOI 10.1109/ISVLSI.2016.54
   De Sutter B., 2010, HDB SIGNAL PROCESSIN
   Duch L, 2017, IEEE T CIRCUITS-I, V64, P2448, DOI 10.1109/TCSI.2017.2701499
   FAN X, 2018, IEEE T VLSI SYST, V29, DOI DOI 10.1007/S41365-018-0389-X
   Frantz G., 2004, SPRY061 TEX INSTR
   Gautschi M., 2017, IEEE T VLSI SYST, V25
   He WJ, 2017, DES AUT CON, DOI 10.1145/3061639.3062291
   Jo M., 2013, INTEGRATION VLSI J, V47
   Levi G., 1973, CALCOLO, V9, P341, DOI DOI 10.1007/BF02575586
   Mach S., 2019, VLSI SOC
   Mach S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351816
   Montagna Fabio, 2017, Journal of Low Power Electronics and Applications, V7, DOI 10.3390/jlpea7020016
   Nicol C., 2017, WAVE COMPUTING
   Nicol C., 2016, WAVE COMPUTING
   Rossi D, 2014, IEEE CONV EL ELECT I
   Sukjin Kim, 2015, 2015 IEEE Hot Chips 27 Symposium (HCS), DOI 10.1109/HOTCHIPS.2015.7477475
   Tagliavini G., 2018, DATE 2018
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
NR 25
TC 13
Z9 13
U1 0
U2 2
PY 2020
BP 1067
EP 1072
DI 10.23919/date48585.2020.9116408
UT WOS:000610549200197
DA 2023-11-16
ER

PT C
AU Gessinger-Befurt, P
   Salzburger, A
   Niermann, J
AF Gessinger-Befurt, Paul
   Salzburger, Andreas
   Niermann, Joana
GP IOP
TI The Open Data Detector Tracking System
SO 20TH INTERNATIONAL WORKSHOP ON ADVANCED COMPUTING AND ANALYSIS
   TECHNIQUES IN PHYSICS RESEARCH
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 20th International Workshop on Advanced Computing and Analysis
   Techniques in Physics Research (ACAT)
CY NOV 29-DEC 03, 2021
CL ELECTR NETWORK
AB Charged particle reconstruction in High Energy Physics experiments is a significant part of overall event reconstruction. Depending on the physics environment, for instance in collider experiments with high multiplicities or luminosities, the tracking problem increases in complexity and often poses not only an algorithmic, but also a computational challenge. With the high-luminosity phase of the LHC at CERN approaching, research for new approaches and algorithms for track reconstruction has seen an increased interest. Both new technological approaches like hardware accelerators, as well as machine learning are being developed. However, testing and developing these new approaches against the existing experiments' software stacks can prove to be challenging, as they typically focus on stable data taking, discouraging disruptive changes. This document presents a virtual tracking detector that is designed to be a simplified, but realistic model of a real-world detector, that can serve as a robust testbed for new developments.
C1 [Gessinger-Befurt, Paul; Salzburger, Andreas; Niermann, Joana] CERN, CH-1211 Geneva, Switzerland.
   [Niermann, Joana] Georg August Univ Gottingen, Phys Inst 2, D-37073 Gottingen, Germany.
RP Gessinger-Befurt, P (corresponding author), CERN, CH-1211 Geneva, Switzerland.
EM paul.gessinger@cern.ch; andreas.salzburger@cern.ch;
   joana.niermann@phys.uni-goettingen.de
CR Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   Ai X., 2021, PREPRINT
   Allaire Corentin, 2022, Zenodo, DOI 10.5281/ZENODO.6445359
   Amrouche S, 2021, PREPRINT
   Amrouche S, 2020, SPRING SER CHALLENGE, P231, DOI 10.1007/978-3-030-29135-8_9
   [Anonymous], 2017, HIGH LUMINOSITY LARG
   [Anonymous], 2017, CERNLHCC2017005
   ATLAS Collaboration, 2008, JINST, V3, DOI DOI 10.1088/1748-0221/3/08/S08003
   Kiehn M, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921406037
   Petri c M, 2017, J PHYS C SERIES, V898
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2023
VL 2438
AR 012110
DI 10.1088/1742-6596/2438/1/012110
UT WOS:001026601300110
DA 2023-11-16
ER

PT C
AU Siauciulis, M
   Northcote, D
   Goldsmith, J
   Crockett, LH
   Kalade, S
AF Siauciulis, Marius
   Northcote, David
   Goldsmith, Josh
   Crockett, Louise H.
   Kalade, Sarunas
GP IEEE
TI 100GBit/s RF sample offload for RFSoC using GNU Radio and PYNQ
SO 2023 21ST IEEE INTERREGIONAL NEWCAS CONFERENCE, NEWCAS
SE IEEE International New Circuits and Systems Conference
DT Proceedings Paper
CT 21st IEEE Interregional NEWCAS Conference (NEWCAS)
CY JUN 26-28, 2023
CL Edinburgh, SCOTLAND
DE high speed offload; GNU Radio; PYNQ; Software Defined Radio; Zynq
   UltraScale plus RFSoC; hardware software co-design
AB Modern software defined radio systems are capable of multi-gigabit-per-second sampling rates producing unprecedented amounts of digitized RF data. In applications such as wideband spectrum sensing and machine learning algorithms for cognitive radio, prototyping, and instrumentation, it is often impractical to process the acquired data locally in real-time. This motivates the need for a high speed connection to offload data to an accelerator application running on a secondary processing resource. In this paper, we present a novel hardware and software co-design using the AMD RFSoC 4x2 platform, PYNQ and GNU Radio projects. The demonstrated system is capable of continuous 80GBit/s offload in a 100GBit/s channel, utilising a GPU acceleration to rapidly process the Fast Fourier Transforms of a full 2GHz bandwidth RF signal at 60 frames per second.
C1 [Siauciulis, Marius; Northcote, David; Goldsmith, Josh; Crockett, Louise H.] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Scotland.
   [Kalade, Sarunas] Adv Micro Devices Inc, Santa Clara, CA USA.
RP Siauciulis, M (corresponding author), Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Scotland.
EM marius.siauciulis@strath.ac.uk
CR AMD Inc, ULTRASCALE DEVICES I
   AMD Inc, VIT MOD COMP
   AMD Inc, VIV ML OV
   AMD Inc, XUP VITIS NETWORK EX
   AMD Inc, 2019, UND KEY PAR RF SAMPL
   AMD Inc, 2019, AD DIR RF SAMPL SOL
   [Anonymous], RFSOC 4X2 OV
   [Anonymous], PYNQ PYTHON PRODUCTI
   casper- toolflow.readthedocs, TUTORIAL 4 100GBE CA
   Chao Liu, 2021, Monthly Notices of the Royal Astronomical Society, V501, P5096, DOI 10.1093/mnras/staa3895
   MathWorks Inc, SIMULINK SIMULATION
   osmocom, GR FOSPHOR GNU RADIO
   Roland R., NLOAD REAL TIME NETW
   Smith Jenny, 100GBE PYNQ
   Stefanazzi L, 2022, REV SCI INSTRUM, V93, DOI 10.1063/5.0076249
   StrathSDR, U STRATHCLYDE SOFTWA
   xmlrpc, WHAT IS XML RPC
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/NEWCAS57931.2023.10198070
UT WOS:001050763800041
DA 2023-11-16
ER

PT J
AU Abdelfattah, A
   Costa, T
   Dongarra, J
   Gates, M
   Haidar, A
   Hammarling, S
   Higham, NJ
   Kurzak, J
   Luszczek, P
   Tomov, S
   Zounon, M
AF Abdelfattah, Ahmad
   Costa, Timothy
   Dongarra, Jack
   Gates, Mark
   Haidar, Azzam
   Hammarling, Sven
   Higham, Nicholas J.
   Kurzak, Jakub
   Luszczek, Piotr
   Tomov, Stanimire
   Zounon, Mawussi
TI A Set of Batched Basic Linear Algebra Subprograms and LAPACK Routines
SO ACM TRANSACTIONS ON MATHEMATICAL SOFTWARE
DT Article
DE BLAS; batched BLAS
ID EXTENDED SET; PERFORMANCE; FERMI; MODEL
AB This article describes a standard API for a set of Batched Basic Linear Algebra Subprograms (Batched BLAS or BBLAS). The focus is on many independent BLAS operations on small matrices that are grouped together and processed by a single routine. called a Batched BLAS routine. The matrices are grouped together in uniformly sized groups, with just one group if all the matrices are of equal size. The aim is to provide more efficient, but portable, implementations of algorithms on high-performance many-core platforms. These include multicore and many-core CPU processors, GPUs and coprocessors, and other hardware accelerators with floating-point compute facility. As well as the standard types of single and double precision, we also include half and quadruple precision in the standard. In particular, half precision is used in many very large scale applications, such as those associated with machine learning.
C1 [Abdelfattah, Ahmad; Dongarra, Jack; Gates, Mark; Luszczek, Piotr; Tomov, Stanimire] Univ Tennessee, 1122 Volunteer Blvd,Suite 203, Knoxville, TN 37996 USA.
   [Costa, Timothy; Haidar, Azzam] NVIDIA, Santa Clara, CA USA.
   [Dongarra, Jack] Oak Ridge Natl Lab, Oak Ridge, TN USA.
   [Dongarra, Jack; Hammarling, Sven; Higham, Nicholas J.] Univ Manchester, Manchester, Lancs, England.
   [Kurzak, Jakub] AMD, Knoxville, TN USA.
   [Zounon, Mawussi] NAG Ltd, Manchester, Lancs, England.
RP Abdelfattah, A (corresponding author), Univ Tennessee, 1122 Volunteer Blvd,Suite 203, Knoxville, TN 37996 USA.
EM ahmad@icl.utk.edu; dongarra@icl.utk.edu; mgates3@icl.utk.edu;
   azzamhaidar@nvidia.com; sven.hammarling@btinternet.com;
   nick.higham@manchester.ac.uk; luszczek@icl.utk.edu; tomov@icl.utk.edu;
   mawussi.zounon@nag.co.uk
CR Abdelfattah A, 2016, LECT NOTES COMPUT SC, V9697, P21, DOI 10.1007/978-3-319-41321-1_2
   Agullo E., 2010, GPU COMPUTING GEMS, V2
   Agullo E, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012037
   Anderson E., 1999, LAPACK USERS GUIDE, V3rd ed., DOI 10.1137/1.9780898719604
   Anderson MJ, 2012, INT PARALL DISTRIB P, P2, DOI 10.1109/IPDPS.2012.11
   [Anonymous], 2016, 201625 MIMS U MANCH
   [Anonymous], 2015, FULL WALK SGEMM IMPL
   [Anonymous], 2012, P STATE OF THE ART S
   [Anonymous], 2015, P 8 WORKSH GEN PURP, DOI DOI 10.1145/2716282.2716288
   Auer AA, 2006, MOL PHYS, V104, P211, DOI 10.1080/00268970500275780
   Baboulin Marc, 2015, P SMOK MOUNT COMP SC
   Baboulin Marc, 2016, UTEECS16738
   Brock B, 2015, J COMPUT PHYS, V302, P591, DOI 10.1016/j.jcp.2015.09.013
   Demmel J., 2017, PROPOSAL NEXT GENERA
   Dong TX, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P157, DOI 10.1109/HPCC.2014.30
   Dong TX, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.103
   DONGARA JJ, 1979, LINPACK USERS GUIDE
   Dongarra J, 2019, ACM T MATH SOFTWARE, V45, DOI 10.1145/3264491
   Dongarra J, 2017, PROCEDIA COMPUT SCI, V108, P495, DOI 10.1016/j.procs.2017.05.138
   DONGARRA JJ, 1988, ACM T MATH SOFTWARE, V14, P1, DOI 10.1145/42288.42291
   DONGARRA JJ, 1988, ACM T MATH SOFTWARE, V14, P18, DOI 10.1145/42288.42292
   DONGARRA JJ, 1990, ACM T MATH SOFTWARE, V16, P1, DOI 10.1145/77626.79170
   Gates Mark, 2019, P INT C HIGH PERF CO, P13
   Guney Murat, 2015, BATCHED MATRIX MATRI
   Hackbusch W, 1999, COMPUTING, V62, P89, DOI 10.1007/s006070050015
   Haidar A, 2015, ACM SIGPLAN NOTICES, V50, P261, DOI [10.1145/2858788.2688534, 10.1145/2688500.2688534]
   Haidar A, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.58
   Hammarling Sven, 2017, 2 WORKSH BATCH REPR
   Hammarling Sven, 2016, WORKSH BATCH REPR RE
   Higham Nicholas J, 2018, 201833 MIMS U MANCH
   HSL, 2013, COLL FORTR COD LARG
   Im EJ, 2004, INT J HIGH PERFORM C, V18, P135, DOI 10.1177/1094342004041296
   Jack Dongarra, 2016, CEUR WORKSHOP P, V1686
   Kabir K, 2015, LECT NOTES COMPUT SC, V9137, P58, DOI 10.1007/978-3-319-20119-1_5
   Keyes David, 2011, NSF ACCI TASK FORCE
   Khodayari A, 2014, METAB ENG, V25, P50, DOI 10.1016/j.ymben.2014.05.014
   Lai JJ, 2013, INT SYM CODE GENER, P89
   Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, P308, DOI 10.1145/355841.355848
   Masliah Ian, 2016, UTEECS16740
   Molero J. M., 2013, PUMPS-POMPES-PUMPEN, DOI [10.1145/2716282.2716288, DOI 10.1145/2716282.2716288]
   Nath R, 2010, INT J HIGH PERFORM C, V24, P511, DOI 10.1177/1094342010385729
   NVIDIA, 2016, CUBLAS 7 5
   Tan Guangming, 2011, P 2011 INT C HIGH PE, DOI [10.1145/2063384.2063431, DOI 10.1145/2063384.2063431]
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
   Villa O., 2013, 2013 IEEE INT C CLUS, P1, DOI DOI 10.1109/CLUSTER.2013.6702656
   Villa O, 2013, LECT NOTES COMPUT SC, V8097, P813, DOI 10.1007/978-3-642-40047-6_81
   Yeralan SN, 2017, ACM T MATH SOFTWARE, V44, DOI 10.1145/3065870
NR 47
TC 11
Z9 13
U1 1
U2 7
PD JUN
PY 2021
VL 47
IS 3
AR 21
DI 10.1145/3431921
UT WOS:000668366600002
DA 2023-11-16
ER

PT J
AU Deng, L
   Li, GQ
   Han, S
   Shi, LP
   Xie, Y
AF Deng, Lei
   Li, Guoqi
   Han, Song
   Shi, Luping
   Xie, Yuan
TI Model Compression and Hardware Acceleration for Neural Networks: A
   Comprehensive Survey
SO PROCEEDINGS OF THE IEEE
DT Article
DE Neural networks; Tensor decomposition; Data quantization; Acceleration;
   Program processors; Machine learning; Task analysis; Compact neural
   network; data quantization; neural network acceleration; neural network
   compression; sparse neural network; tensor decomposition
ID SINGULAR-VALUE DECOMPOSITION; TENSOR DECOMPOSITIONS; MEMORY; TRAIN;
   COMPUTATION; ENERGY; ARCHITECTURES; PREDICTION; ACCURACY; CNN
AB Domain-specific hardware is becoming a promising topic in the backdrop of improvement slow down for general-purpose processors due to the foreseeable end of Moore's Law. Machine learning, especially deep neural networks (DNNs), has become the most dazzling domain witnessing successful applications in a wide spectrum of artificial intelligence (AI) tasks. The incomparable accuracy of DNNs is achieved by paying the cost of hungry memory consumption and high computational complexity, which greatly impedes their deployment in embedded systems. Therefore, the DNN compression concept was naturally proposed and widely used for memory saving and compute acceleration. In the past few years, a tremendous number of compression techniques have sprung up to pursue a satisfactory tradeoff between processing efficiency and application accuracy. Recently, this wave has spread to the design of neural network accelerators for gaining extremely high performance. However, the amount of related works is incredibly huge and the reported approaches are quite divergent. This research chaos motivates us to provide a comprehensive survey on the recent advances toward the goal of efficient compression and execution of DNNs without significantly compromising accuracy, involving both the high-level algorithms and their applications in hardware design. In this article, we review the mainstream compression approaches such as compact model, tensor decomposition, data quantization, and network sparsification. We explain their compression principles, evaluation metrics, sensitivity analysis, and joint-way use. Then, we answer the question of how to leverage these methods in the design of neural network accelerators and present the state-of-the-art hardware architectures. In the end, we discuss several existing issues such as fair comparison, testing workloads, automatic compression, influence on security, and framework/hardware-level support, and give promising topics in this field and the possible challenges as well. This article attempts to enable readers to quickly build up a big picture of neural network compression and acceleration, clearly evaluate various methods, and confidently get started in the right way.
C1 [Deng, Lei; Li, Guoqi; Shi, Luping] Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
   [Deng, Lei; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Li, Guoqi; Shi, Luping] Tsinghua Univ, Beijing Innovat Ctr Future Chip, Beijing 100084, Peoples R China.
   [Han, Song] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
RP Li, GQ (corresponding author), Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
EM leideng@ucsb.edu; liguoqi@mail.tsinghua.edu.cn; songhan@mit.edu;
   lpshi@mail.tsinghua.edu.cn; yuanxie@ucsb.edu
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Aizenberg I, 2012, SOFT COMPUT, V16, P563, DOI 10.1007/s00500-011-0755-7
   Al Bahou A, 2018, PROC IEEE COOL CHIPS
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2018, ADV NEURAL INFORM PR
   [Anonymous], ARXIV190305662
   [Anonymous], 2018, ARXIV181007378
   [Anonymous], 2017, P IEEE C COMPUTER VI
   [Anonymous], ARXIV161101427
   [Anonymous], ARXIV180902220
   [Anonymous], 2011, COMPUT METH APPL MAT, DOI DOI 10.2478/CMAM-2011-0016
   [Anonymous], 2018, P ICLR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2017, P ICLR
   [Anonymous], 2018, ARXIV181000859
   [Anonymous], 2018, ADV NEURAL INFORM PR
   [Anonymous], 2018, ARXIV180900095
   [Anonymous], 2018, P INT C LEARNING REP
   [Anonymous], ARXIV180510352
   [Anonymous], P AAAI FEB
   [Anonymous], 2020, P ICLR
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, P ICLR
   [Anonymous], 2017, ARXIV170805552
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], IEEE T COMPUT AIDED
   [Anonymous], 2018, ARXIV180511797
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2015, DEEP LEARNING, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2018, ARXIV181100482
   [Anonymous], 2016, P ICLR
   [Anonymous], 2017, FPL
   [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], 2018, P ICLR
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2017, CORR
   [Anonymous], 2016, DOREFANET TRAINING L
   [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, P ICLR
   [Anonymous], 2018, ARXIV180600512
   [Anonymous], 2018, P INT C LEARN REPR
   [Anonymous], MATRIX
   [Anonymous], P SIAM INT C DAT MIN
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 2017, ARXIV170405119
   [Anonymous], 2018, UNQ UNIFORM NOISE IN
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], 2016, COMPUTER SCI
   [Anonymous], 2018, ARXIV180506523
   [Anonymous], ARXIV180602639
   [Anonymous], P ACM IEEE 45 ANN IN
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], 2016, ARXIV
   [Anonymous], 2019, ARXIV190907514
   [Anonymous], IEEE J SOLID STATE C
   [Anonymous], ARXIV170805344
   [Anonymous], 2017, TENSOR REGRESSION NE
   [Anonymous], 2018, 6 INT C LEARNING REP
   [Anonymous], P IEEE CVF C COMP VI
   [Anonymous], ARXIV150701526
   [Anonymous], P ICLR
   [Anonymous], 2018, P INT C COMPUTER AID
   [Anonymous], ARXIV180101928
   [Anonymous], P ACM IEEE 45 ANN IN
   [Anonymous], ARXIV170206763
   [Anonymous], 2018, ARXIV180200150
   [Anonymous], 2018, 2018 17 INT S INFOTE, DOI DOI 10.1109/INFOTEH.2018.8345545
   [Anonymous], 2015, P ICLR
   [Anonymous], ARXIV190301061
   [Anonymous], 2018, INT C LEARN REPR
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], ARXIV171100436
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], P EMNLP OCT
   [Anonymous], 2016, P ICLR
   [Anonymous], ARXIV190111117
   [Anonymous], 2018, PROC IEEE UNDERGRADU
   [Anonymous], 2015, ADV NEUR IN
   [Anonymous], 2016, P ICLR
   [Anonymous], 2017, ARXIV170310722
   [Anonymous], 2018, ARXIV180609228
   [Anonymous], 2016, ARXIV160301025
   [Anonymous], 2018, ARXIV180806866
   [Anonymous], P ADV NEUR INF PROC
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Arjovsky M, 2016, PR MACH LEARN RES, V48
   Astrid M, 2017, INT CONF BIG DATA, P115, DOI 10.1109/BIGCOMP.2017.7881725
   Ba L. J., 2013, P ADV NEURAL INFORM, V2, P3084
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Banner R., 2018, P ADV NEURAL INFORM, P5145
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Cai H., 2018, ARXIV181200332
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Cai Y, 2018, DES AUT CON, DOI 10.1145/3195970.3196071
   Cai ZW, 2017, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR.2017.574
   Canziani A., 2016, P IEEE INT S CIRC SY
   Chen Y.-H., 2018, ARXIV180707928
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen YP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P635
   Cheng J, 2018, IEEE T NEUR NET LEAR, V29, P4730, DOI 10.1109/TNNLS.2017.2774288
   Cheng M, 2019, IEEE T COMPUT AID D, V38, P834, DOI 10.1109/TCAD.2018.2824304
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chien JT, 2018, IEEE T NEUR NET LEAR, V29, P1998, DOI 10.1109/TNNLS.2017.2690379
   Chin T.-W., 2018, ARXIV181000518
   Cho K., 2014, LEARNING PHRASE REPR, DOI [10, DOI 10.3115/V1/D14-1179]
   Choi Y., 2018, ARXIV180508303
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cichocki A, 2018, STUD COMPUT INTELL, V738, P3, DOI 10.1007/978-3-319-67946-4_1
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Cohen N, 2016, PR MACH LEARN RES, V48
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai XL, 2019, IEEE T COMPUT, V68, P1487, DOI 10.1109/TC.2019.2914438
   Tran DT, 2018, NEURAL NETWORKS, V105, P328, DOI 10.1016/j.neunet.2018.05.017
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Deb T, 2018, MATER TODAY-PROC, V5, P2222
   Deng CH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P264, DOI 10.1145/3307650.3322258
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Deng L, 2018, NEURAL NETWORKS, V100, P49, DOI 10.1016/j.neunet.2018.01.010
   Denil M., 2013, NIPS
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Elsken Thomas, 2018, ARXIV180409081
   Espig M, 2012, COMPUT VIS SCI, V15, P331, DOI 10.1007/s00791-014-0218-7
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI 10.1109/CVPRW.2011.5981829
   Garipov Timur, 2016, ABS161103214 CORR
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gittens A, 2016, J MACH LEARN RES, V17
   Grasedyck L, 2010, SIAM J MATRIX ANAL A, V31, P2029, DOI 10.1137/090764189
   Guo X., 2017, IEDM, P6, DOI [10.1109/iedm.2017.8268341, DOI 10.1109/IEDM.2017.8268341, 10.1109/CISP-BMEI.2017.8301926]
   Guo Y., 2016, ADV NEURAL INFORM PR, P1379
   Guo Y., 2018, SURVEY METHODS THEOR
   Hammerstrom D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P537, DOI 10.1109/IJCNN.1990.137621
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hassibi Babak, 1992, ADV NEURAL INFORM PR, V5, P2, DOI DOI 10.5555/645753.668069
   He Qinyao, 2016, EFFECTIVE QUANTIZATI
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   He ZZ, 2017, ARCH BIOCHEM BIOPHYS, V623, P1, DOI 10.1016/j.abb.2017.01.013
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hieu TH, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P1300, DOI 10.1109/ICCIT.2009.170
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoffer E, 2018, ADV NEURAL INFORM PR, P2160
   Holschneider M., 1990, WAVELETS, P286, DOI [DOI 10.1007/978-3-642-75988-8_28, 10.1007/978-3-642-75988-8_28]
   Hou M, 2015, IEEE IMAGE PROC, P1344, DOI 10.1109/ICIP.2015.7351019
   Howard A. G., 2017, ABS170404861 CORR
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HT, 2018, IEEE T NANOTECHNOL, V17, P645, DOI 10.1109/TNANO.2017.2732698
   Hubara I, 2018, J MACH LEARN RES, V18
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Jafari A, 2018, PR GR LAK SYMP VLSI, P443, DOI 10.1145/3194554.3194634
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jain S., 2018, ARXIV180900072
   Janzamin M., 2015, ARXIV150608473
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Jia Xianyan, 2018, ARXIV180711205
   Jian Xue, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6359, DOI 10.1109/ICASSP.2014.6854828
   Jiang P, 2018, ADV CIV ENG, V2018, DOI 10.1155/2018/4748526
   Jiang Su, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P29, DOI 10.1007/978-3-319-78890-6_3
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Judd P, 2016, INT SYMP MICROARCH
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim C, 2018, IEEE J EM SEL TOP C, V8, P770, DOI 10.1109/JETCAS.2018.2865006
   Kim E, 2018, PROC CVPR IEEE, P8669, DOI 10.1109/CVPR.2018.00904
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Koster U., 2017, NIPS, P1742
   Krishnamoorthi Raghuraman, 2018, ARXIV180608342
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumamoto T, 2017, J PHYS SOC JPN, V86, DOI 10.7566/JPSJ.86.024005
   Kumar NK, 2017, LINEAR MULTILINEAR A, V65, P2212, DOI 10.1080/03081087.2016.1267104
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Kurakin A., 2016, INT C LEARN REPR
   Lasenby, 2018, ARXIV180404849
   LeCun Y., 1989, ADV IN NEURAL INFORM, P598
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2017, IEEE ASIAN SOLID STA, P237, DOI 10.1109/ASSCC.2017.8240260
   Lee N, 2018, MULTIDIM SYST SIGN P, V29, P921, DOI 10.1007/s11045-017-0481-0
   Lee N, 2016, SIAM J MATRIX ANAL A, V37, P598, DOI 10.1137/15M1028479
   Li CH, 2007, 2007 CIT: 7TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P47, DOI 10.1109/CIT.2007.52
   Li GQ, 2018, NEUROCOMPUTING, V272, P154, DOI 10.1016/j.neucom.2017.06.058
   Li H, 2017, ADV NEUR IN, V30
   Li J., 2018, CORR
   Li L, 2013, INT CONF ACOUST SPEE, P3707, DOI 10.1109/ICASSP.2013.6638350
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li SC, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P696, DOI [10.1109/MICRO.2018.00062, 10.1109/MICR0.2018.00062]
   Liang L, 2018, IEEE ACCESS, V6, P58324, DOI 10.1109/ACCESS.2018.2874823
   Lin C, 2018, P ADV NEUR INF PROC, P10169
   Lin JL, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P639, DOI 10.1145/3287624.3287715
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3756
   Lin Zhouhan, 2015, NEURAL NETWORKS FEW
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu H., 2018, INT C LEARNING REPRE
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Liu YG, 2016, IEEE T NEUR NET LEAR, V27, P273, DOI 10.1109/TNNLS.2015.2496964
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Liu Zhuang, 2018, ARXIV181005270
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Luo WJ, 2016, ADV NEUR IN, V29
   Makhzani A., 2015, NIPS, P2791
   Marzi Z, 2018, IEEE INT SYMP INFO, P31, DOI 10.1109/ISIT.2018.8437638
   Masana Marc, 2017, P IEEE INT C COMPUTE
   McKinstry J. L., 2018, ARXIV180904191
   Micikevicius P., 2017, ARXIV171003740
   Molchanov Pavlo, 2016, ARXIV161106440
   Morcos A. S., 2018, P INT C LEARN REPR
   Neil D., 2016, P 30 INT C NEUR INF, P3889, DOI DOI 10.48550/ARXIV.1610.09513
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Oseledets IV, 2010, SIAM J MATRIX ANAL A, V31, P2130, DOI 10.1137/090757861
   Ott Joachim, 2016, CORR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Perros I, 2015, IEEE DATA MINING, P943, DOI 10.1109/ICDM.2015.29
   Pham H., 2018, 35 INT C MACH LEARN
   Ramachandran P., 2017, ARXIV
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rauhut H, 2015, APPL NUMER HARMON AN, P419, DOI 10.1007/978-3-319-16042-9_14
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Ren A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P925, DOI 10.1145/3297858.3304076
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Rovid A., 2011, Proceedings of the 2011 15th IEEE International Conference on Intelligent Engineering Systems (INES), P69, DOI 10.1109/INES.2011.5954721
   Sainath TN, 2013, INT CONF ACOUST SPEE, P6655, DOI 10.1109/ICASSP.2013.6638949
   Sak H, 2014, INTERSPEECH, P338
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schütt KT, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13890
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shim K, 2017, ADV NEUR IN, V30
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Song MC, 2018, CONF PROC INT SYMP C, P752, DOI 10.1109/ISCA.2018.00068
   Spring R, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P445, DOI 10.1145/3097983.3098035
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava Rupesh Kumar, 2015, HIGHWAY NETWORKS, P2
   Sun X, 2017, PR MACH LEARN RES, V70
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Tang W, 2017, AAAI CONF ARTIF INTE, P2625
   Tjandra A, 2018, IEEE IJCNN
   Tjandra A, 2017, IEEE IJCNN, P4451, DOI 10.1109/IJCNN.2017.7966420
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.00881, 10.1109/CVPR.2019.01218]
   Wang Naigang, 2018, ARXIV181208011, P7686
   Wang PQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196116
   Wen W., 2017, ARXIV170905027
   Wen W, 2016, ADV NEUR IN, V29
   Wen W, 2017, ADV NEUR IN, V30
   Wen W, 2017, IEEE I CONF COMP VIS, P658, DOI 10.1109/ICCV.2017.78
   WEST J, 1995, DISCRETE MATH, V146, P247, DOI 10.1016/0012-365X(94)00067-1
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Wu S, 2019, IEEE T NEUR NET LEAR, V30, P2043, DOI 10.1109/TNNLS.2018.2876179
   Wu ZZ, 2016, INT CONF ACOUST SPEE, P5140, DOI 10.1109/ICASSP.2016.7472657
   Xiao LC, 2018, PR MACH LEARN RES, V80
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue SF, 2015, INT CONF ACOUST SPEE, P4555, DOI 10.1109/ICASSP.2015.7178833
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Yang YC, 2017, PR MACH LEARN RES, V70
   Ye JM, 2018, PROC CVPR IEEE, P9378, DOI 10.1109/CVPR.2018.00977
   Yin PH, 2018, SIAM J IMAGING SCI, V11, P2205, DOI 10.1137/18M1166134
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Yu R., 2017, LONG TERM FORECASTIN
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Zagoruyko Sergey, 2016, BRIT MACHINE VISION, P5
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang SZ, 2016, ADV NEUR IN, V29
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang T., 2018, ADAM ADMM UNIFIED SY
   Zhang TY, 2018, LECT NOTES COMPUT SC, V11212, P191, DOI 10.1007/978-3-030-01237-3_12
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhao HJ, 2017, IEEE T INTELL TRANSP, V18, P192, DOI 10.1109/TITS.2016.2571726
   Zhao Q., 2016, ARXIV
   Zhao QB, 2019, INT CONF ACOUST SPEE, P8608, DOI 10.1109/ICASSP.2019.8682231
   Zhao Y, 2017, ADVANCES IN ENERGY AND ENVIRONMENT RESEARCH, P345
   Zhou GB, 2016, INT J AUTOM COMPUT, V13, P226, DOI 10.1007/s11633-016-1006-2
   Zhou MY, 2019, SIGNAL PROCESS-IMAGE, V73, P12, DOI 10.1016/j.image.2018.03.017
   Zhou SC, 2017, J COMPUT SCI TECH-CH, V32, P667, DOI 10.1007/s11390-017-1750-y
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhu C., 2016, ARXIV161201064
   Zhu M. H., 2018, ARXIV171001878
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 307
TC 317
Z9 333
U1 50
U2 203
PD APR
PY 2020
VL 108
IS 4
BP 485
EP 532
DI 10.1109/JPROC.2020.2976475
UT WOS:000528671200003
HC Y
HP N
DA 2023-11-16
ER

PT C
AU Kotselidis, C
   Diamantopoulos, S
   Akrivopoulos, O
   Rosenfeld, V
   Doka, K
   Mohammed, H
   Mylonas, G
   Spitadakis, V
   Morgan, W
AF Kotselidis, Christos
   Diamantopoulos, Sothis
   Akrivopoulos, Orestis
   Rosenfeld, Viktor
   Doka, Katerina
   Mohammed, Hazeef
   Mylonas, Georgios
   Spitadakis, Vassilis
   Morgan, Will
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI Efficient Compilation and Execution of JVM-Based Data Processing
   Frameworks on Heterogeneous Co-Processors
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB This paper addresses the fundamental question of how modern Big Data frameworks can dynamically and transparently exploit heterogeneous hardware accelerators. After presenting the major challenges that have to be addressed towards this goal, we describe our proposed architecture for automatic and transparent hardware acceleration of Big Data frameworks and applications, Our vision is to retain the uniform programming model of Big Data frameworks and enable automatic, dynamic Just-In-Time compilation of the candidate code segments that benefit from hardware acceleration to the corresponding format. In conjunction with machine learning-based device selection, that respect user-defined constraints (e.g., cost, time, etc.), we enable dynamic code execution on GPUs and FPGAs transparently to the user. In addition, we dynamically re-steer execution at runtime based on the availability of resources. Our preliminary results demonstrate that our approach can accelerate an existing Apache Flink application by up to 16.5x.
C1 [Kotselidis, Christos] Univ Manchester, Manchester, Lancs, England.
   [Diamantopoulos, Sothis] Exus Ltd, London, England.
   [Akrivopoulos, Orestis] SparkWorks ITC Ltd, Swadlincote, England.
   [Rosenfeld, Viktor] German Res Ctr Artificial Intelligence, Kaiserslautern, Germany.
   [Doka, Katerina] Natl Tech Univ Athens, Athens, Greece.
   [Mohammed, Hazeef] Kaleao Ltd, Cambridge, England.
   [Mylonas, Georgios] Comp Technol Inst & Press Diophantus, Patras, Greece.
   [Spitadakis, Vassilis] Neurocom Luxembourg, Luxembourg, Luxembourg.
   [Morgan, Will] IProov Ltd, London, England.
RP Kotselidis, C (corresponding author), Univ Manchester, Manchester, Lancs, England.
EM christos.kotselidis@manchester.ac.uk; s.diamantopoulos@exus.co.uk;
   akribopo@sparkworks.net; viktor.rosenfeld@dfki.de;
   katerina@cslab.ece.ntua.gr; hazeef.mohammed@kaleao.com; mylonasg@cti.gr;
   v.spitadakis@neurocom.lu; will.morgan@iproov.com
CR [Anonymous], 2010, P 1 ACM S CLOUD COMP, DOI [10.1145/1807128.1807148, DOI 10.1145/1807128.1807148]
   Bress S., 2018, VLDB J
   Carbone P., 2015, ABS150608603 CORR
   Carbone P., 2015, IEEE DATA ENG B, V38, P28, DOI DOI 10.1109/IC2EW.2016.56
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Clark JE, 2018, PSYCHOL MED, V48, P2277, DOI 10.1017/S0033291718000430
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   El-Helw I., 2014, P 23 INT S HIGH PERF
   Fowers J, 2012, FPGA 12: PROCEEDINGS OF THE 2012 ACM-SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P47
   Fumero J., 2019, P 15 ACM SIGPLAN SIG
   Grossman M., 2013, 27 INT PAR DISTR PRO
   Ishizaki K, 2015, INT CONFER PARA, P419, DOI 10.1109/PACT.2015.46
   Koliousis A, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P555, DOI 10.1145/2882903.2882906
   Kotselidis C, 2017, ACM SIGPLAN NOTICES, V52, P74, DOI [10.1145/3050748.3050764, 10.1145/3140607.3050764]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li P., 2015, 2015 IEEE INT C NETW
   Lindholm T., 2014, JAVA VIRTUAL MACHINE, V8th
   Miao HY, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P617
   Rosenfeld V., 2015, ADMS VLDG
   Sabne Amit, 2015, P 24 INT S HIGH PERF
   Tan W., 2018, 1 CLASS GPUS SUPP AP
   Vavilapalli VK, 2013, P ACM SOCC, DOI 10.1145/2523616.2523633
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
NR 24
TC 2
Z9 3
U1 0
U2 5
PY 2020
BP 175
EP 179
UT WOS:000610549200031
DA 2023-11-16
ER

PT C
AU Plaza, M
   Deniziak, S
   Plaza, M
   Belka, R
   Pieta, P
AF Plaza, Malgorzata
   Deniziak, Stanislaw
   Plaza, Miroslaw
   Belka, Radoslaw
   Pieta, Pawel
BE Romaniuk, RS
   Linczuk, M
TI Analysis of parallel computational models for clustering
SO PHOTONICS APPLICATIONS IN ASTRONOMY, COMMUNICATIONS, INDUSTRY, AND
   HIGH-ENERGY PHYSICS EXPERIMENTS 2018
SE Proceedings of SPIE
DT Proceedings Paper
CT SPIE-IEEE-PSP WILGA on Photonics Applications in Astronomy,
   Communications, Industry, and High-Energy Physics Experiments
CY JUN 03-10, 2018
CL Wilga, POLAND
DE big data; clustering; cluster analysis; data mining; machine learning;
   parallel algorithms
ID ALGORITHM
AB Clustering is one of the main task of data mining, where groups of similar objects are discovered and grouping of similar data as well as outliers detection are performed. Processing of huge datasets requires scalable models of computations and distributed computing environments, therefore efficient parallel clustering methods are required for this purpose. Usually for parallel data analytics the MapReduce processing model is used. But growing computer power of heterogeneous platforms based on graphic processors and FPGA accelerators causes that CUDA and OpenCL models may be interesting alternative to MapReduce. This paper presents comparative analysis of effectiveness of applying MapReduce and CUDA/OpenCL processing models for clustering. We compare different methods of clustering in terms of their possibilities of parallelization using both models of computation. The conclusions indicate directions for further work in this area.
C1 [Plaza, Malgorzata; Deniziak, Stanislaw; Plaza, Miroslaw; Belka, Radoslaw; Pieta, Pawel] Kielce Univ Technol, Fac Elect Engn Automat Control & Comp Sci, Al Tysiaclecia PP 7, PL-25314 Kielce, Poland.
RP Plaza, M (corresponding author), Kielce Univ Technol, Fac Elect Engn Automat Control & Comp Sci, Al Tysiaclecia PP 7, PL-25314 Kielce, Poland.
EM malgorzata.plaza@tu.kielce.pl
CR Aggarwal CC, 2000, SIGMOD REC, V29, P70, DOI 10.1145/335191.335383
   AMD, 2009, AMD US GUID
   Anchalia P., 2014, 16 INT CON COMP MOD
   Anderberg M.R., 1973, CLUSTER ANAL APPL
   Andrade G, 2013, PROCEDIA COMPUT SCI, V18, P369, DOI 10.1016/j.procs.2013.05.200
   Andreopoulos B, 2009, BRIEF BIOINFORM, V10, P297, DOI 10.1093/bib/bbn058
   Ankerst M., 1999, SIGMOD Record, V28, P49, DOI 10.1145/304181.304187
   [Anonymous], EVALUATING MAPREDUCE
   [Anonymous], 1994, P INT C VERY LARGE D
   [Anonymous], 2009, OPENCL SPEC VERS 1 0
   [Anonymous], 2013, 2013 INT C INFORM SC
   Berkhin P., 2006, GROUPING MULTIDIMENS, P25, DOI DOI 10.1007/3-540-28349-8_2
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bi-Ru Dai, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P59, DOI 10.1109/CLOUD.2012.42
   Buyya R., 2016, BIG DATA PRINCIPLES
   Chang D., 2009, 22 INT C PAR DISTR C
   Cheeseman P, 1996, ADV KNOWLEDGE DISCOV, P153, DOI DOI 10.5555/257938.257954
   Cheng C.-H., 1999, PROC ACM SIGMOD INT, P84, DOI [10.1145/312129.312199, DOI 10.1145/312129.312199]
   Dean J., 2004, P 6 S OP SYST DES IM, P139
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dobre C, 2014, INT J PARALLEL PROG, V42, P710, DOI 10.1007/s10766-013-0272-7
   Ene A., 2011, SIGKDD, P681, DOI DOI 10.1145/2020408.2020515
   Ester M., 1996, P 2 INT C KNOWL DISC, P226
   Fahad A., 2014, IEEE T EMERGING TOPI, V2
   Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265
   Gao H., 2010, INT J DIGITAL CONTEN, V4, P95, DOI DOI 10.4156/JDCTA
   GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5
   Grossman M., 2013, 27 INT IEEE PAR DIST
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Han J., 2006, DATA MINING CONCEPTS
   He B., 2008, PARALLEL ARCHITECTUR
   He BS, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P260, DOI 10.1145/1454115.1454152
   Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58
   Hinneburg A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506
   Hong CT, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P217, DOI 10.1145/1854273.1854303
   Hong-tao B., 2009, IEEE, V7
   Huang Z., 1997, RES ISSUES DATA MINI, V3, P34
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Hussain H. M., 2011, RECONFIGURABLE COMPU
   Hussain H. M., 2011, ADAPTIVE HARDWARE SY
   Jain A.K., 1988, ALGORITHMS CLUSTERIN
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jiadong Wu, 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, P1740, DOI 10.1109/IPDPS.2011.331
   Jin C., 2013, P 4 INT SC WORKSH DA
   Junker B., 2008, ANAL BIOL NETWORKS
   Kailing K, 2004, SIAM PROC S, P246
   Kambatla K, 2014, J PARALLEL DISTR COM, V74, P2561, DOI 10.1016/j.jpdc.2014.01.003
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
   Kaufman L., 1990, FINDING GROUPS DATA
   Kaufman L, 2009, FINDING GROUPS DATA
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Krechowicz A, 2016, LECT NOTES COMPUT SC, V9573, P302, DOI 10.1007/978-3-319-32149-3_29
   Lee KH, 2011, SIGMOD REC, V40, P11, DOI 10.1145/2094114.2094118
   Li L, 2011, MODELLING SIMULATION, P325
   Lin C, 2011, ADV INTEL SOFT COMPU, V123, P93
   MacQueen J, 1967, 5 BERK S MATH STAT P, DOI DOI 10.1007/S11665-016-2173-6
   Mahmood AN, 2008, IEEE T KNOWL DATA EN, V20, P752, DOI 10.1109/TKDE.2007.190725
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   NVIDIA, 2008, TESL C1060 COMP PROC
   NVIDIA, 2012, CUDA PROGR GUID
   Okur S., 2012, HADOOP APARAPI MAKIN
   Papadimitriou S, 2008, IEEE DATA MINING, P512, DOI 10.1109/ICDM.2008.142
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Sadalage P. J., 2012, NOSQL DISTILLED BRIE
   Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P428
   Srirama SN, 2012, FUTURE GENER COMP SY, V28, P184, DOI 10.1016/j.future.2011.05.025
   Sun TY, 2009, 2009 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2009), P494, DOI 10.1109/PDCAT.2009.46
   Tan H., 2011, IEEE 17 INT C PAR DI
   Wang W, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P186
   Wang ZK, 2016, IEEE T PARALL DISTR, V27, P3547, DOI 10.1109/TPDS.2016.2537805
   Xu XW, 1998, PROC INT CONF DATA, P324, DOI 10.1109/ICDE.1998.655795
   Zaharia Matei, 2008, 8 USENIX C OP SYST D, P29
   Zechner M, 2009, INTENSIVE: 2009 FIRST INTERNATIONAL CONFERENCE ON INTENSIVE APPLICATIONS AND SERVICES, P7, DOI 10.1109/INTENSIVE.2009.19
   Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328
   Zhang T, 1996, ACM SIGMOD RECORD, V25, P103, DOI [DOI 10.1145/235968.233324, 10.1145/235968.233324, 10.1145/233269.233324]
   Zhang YQ, 2016, P IEEE, V104, P2114, DOI 10.1109/JPROC.2016.2591592
   Zhao WZ, 2013, INT CON ADV INFO NET, P862, DOI 10.1109/AINA.2013.47
NR 79
TC 2
Z9 2
U1 0
U2 1
PY 2018
VL 10808
AR 108081O
DI 10.1117/12.2500795
UT WOS:000450820000060
DA 2023-11-16
ER

PT J
AU Wuraola, A
   Patel, N
   Nguang, SK
AF Wuraola, Adedamola
   Patel, Nitish
   Nguang, Sing Kiong
TI Efficient activation functions for embedded inference engines
SO NEUROCOMPUTING
DT Article
DE Activation function; Square non-linearity; Embedded neural networks;
   Hardware accelerator
ID MULTILAYER FEEDFORWARD NETWORKS; DEEP NEURAL-NETWORKS; LINEAR UNITS;
   APPROXIMATION
AB The importance of the choice of the activation function for training and inferencing in machine learning cannot be overemphasized. Activation functions can influence network training convergence, performance accuracy, and can make training and inference stages computationally expensive. We introduce a family of square-based activation functions for embedded devices that consume only one instruction cycle with the potential of being resource efficient when constructed in silicon. We show that the proposed family are computationally efficient when compared with exponential-based non-linearities. The family includes functions for deep neural network architectures, support vector machines, recurrent neural networks, and others. We demonstrate the universal ability of the square-based family of activation functions on a variety of neural network architectures. We analyze the hidden representations of our trained multilayer perceptron network in an attempt to explain the performance gains, and speed-up observed when using square non-linearities. Speed-up was recorded with the quadratic-based kernel transformation on support vector machines. We record higher performance accuracy for recurrent neural network architectures and logistic regression using this family. Speed up was also recorded for implementation on Intel CPU and ARM processors. This family will find particular importance in low-end hardware devices with limited hardware capabilities.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wuraola, Adedamola; Patel, Nitish; Nguang, Sing Kiong] Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
RP Wuraola, A (corresponding author), Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
EM awur978@aucklanduni.ac.nz; nd.patel@auckland.ac.nz;
   sk.nguang@auckland.ac.nz
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Abai Z., 2019, ARXIV PREPRINT ARXIV
   Adedamola W, 2020, SQNL FAMILY
   Aimonen P, 2009, LIBFIXMATH
   Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746
   Apicella A, 2019, NEUROCOMPUTING, V370, P1, DOI 10.1016/j.neucom.2019.08.065
   Aymeric, 2017, TENSORFLOW EXAMPLES
   Brownlee J, 2019, SEQUENCE CLASSIFICAT
   Carlile B., 2017, ARXIV171009967
   Ciuparu A, 2020, NEUROCOMPUTING, V384, P376, DOI 10.1016/j.neucom.2019.12.014
   Clevert D.A., 2016, P 6 INT C LEARN REPR
   Dimitrios R, 2020, SVHN CLASSIFICATION
   Drewnik M, 2017, LECT NOTES COMPUT SC, V10244, P87, DOI 10.1007/978-3-319-59105-6_8
   Dua D., 2017, UCI MACHINE LEARNING
   Giri S., 2019, RESNET MODEL TINY IM
   Gulcehre C, 2016, PR MACH LEARN RES, V48
   Hao L., 2017, P 31 C NEUR INF PROC
   Harrison, 2016, RNN W LSTM CELL EXAM
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D., 2016, PREPRINT
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Intel, 2018, VECT MATH VM PERF AC
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang XH, 2018, NEUROCOMPUTING, V275, P1132, DOI 10.1016/j.neucom.2017.09.056
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keras, 2019, KER EX
   Kim D, 2020, NEUROCOMPUTING, V406, P253, DOI 10.1016/j.neucom.2020.03.051
   Krizhevsky A., CIFAR 10
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Li Y., TRAINING NEURAL NETW
   Li Y, 2018, NEUROCOMPUTING, V301, P11, DOI 10.1016/j.neucom.2018.01.084
   Lin M., 2013, NETWORK IN NETWORK, P1
   Martens J., 2010, P 27 INT C MACH LEA, P735
   Moreno PJ, 2004, ADV NEUR IN, V16, P1385
   Nvidia, 2014, NVIDIA CUDNN
   Qian S, 2018, NEUROCOMPUTING, V272, P204, DOI 10.1016/j.neucom.2017.06.070
   Ramachandran P., 2017, P INT C LEARN REPR W
   Roopal, 2017, LSTM TENSORFLOW
   Schraudolph NN, 1999, NEURAL COMPUT, V11, P853, DOI 10.1162/089976699300016467
   Sen S, 2018, IEEE T COMPUT AID D, V37, P2266, DOI 10.1109/TCAD.2018.2858362
   Simonyan K., 2015, VERY DEEP CONVOLUTIO, V1, P3
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang X, 2019, NEUROCOMPUTING, V363, P88, DOI 10.1016/j.neucom.2019.07.017
   Wei, 2018, CONVOLUTIONAL NEURAL
   Wuraola A, 2018, IEEE IJCNN
   Wuraola A, 2018, LECT NOTES COMPUT SC, V11302, P103, DOI 10.1007/978-3-030-04179-3_9
   Xi S, 2017, RESTRICTED BOLTZMANN
   Ying Y, 2019, IEEE ACCESS, V7, P101633, DOI 10.1109/ACCESS.2019.2928442
   Zagoruyko Sergey, 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
NR 54
TC 5
Z9 5
U1 1
U2 5
PD JUN 28
PY 2021
VL 442
BP 73
EP 88
DI 10.1016/j.neucom.2021.02.030
EA MAR 2021
UT WOS:000646233500007
DA 2023-11-16
ER

PT C
AU Gong, HH
   Xing, K
   Du, WW
AF Gong, Haihua
   Xing, Kai
   Du, Wenwen
GP IEEE
TI Distinguishing between a Driver and Passenger via a Silent Smartphone
SO 2017 1ST IEEE SYMPOSIUM ON PRIVACY-AWARE COMPUTING (PAC)
DT Proceedings Paper
CT 1st IEEE Symposium on Privacy-Aware Computing (PAC)
CY AUG 01-04, 2017
CL George Washington Univ, Washington, DC
HO George Washington Univ
AB This poster investigates the discrimination problem between car driver and car passengers using smartphones, which is critical to active safety enhancement and usage based insurance. The proposed system leverages a smartphone without the assistance of extra devices or resources, e.g., car speakers, bluetooth network, Internet or cloud. Specifically, our system builds a unsupervised machine learning platform on Android based smartphones, in which the data of the Inertial Measurement Unit (IMU), i.e., gyro, accelerator, magnetometer, is taken as the input. With the attitude and trajectory data generated from the IMU measurement, the neural network extract the fundamental features of the spacial characteristics of driver and passengers during accelerating, deceleration, turning, starting, stopping, driving, based on which we may further distinguish driver and passengers. The experiments show that the proposed system is able to provide a classification accuracy over 95%, at a low false positive rate.
C1 [Gong, Haihua; Xing, Kai; Du, Wenwen] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Anhui, Peoples R China.
RP Gong, HH (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Anhui, Peoples R China.
EM ghh8513@mail.ustc.edu.cn; kxing@ustc.edu.cn; dwwo@mail.ustc.edu.cn
CR [Anonymous], 2013, P 11 ANN INT C MOBIL
   Bo C., 2013, P 19 ANN INT C MOB C, P199, DOI DOI 10.1145/2500423.2504575
   Yang J., 2011, PROC INT C MOBILE CO, P97
NR 3
TC 0
Z9 0
U1 0
U2 1
PY 2017
BP 190
EP 191
DI 10.1109/PAC.2017.37
UT WOS:000428577000023
DA 2023-11-16
ER

PT C
AU Song, YS
   Li, FY
   Liu, JY
   Zhang, JA
AF Song, Yunsheng
   Li, Fangyi
   Liu, Jianyu
   Zhang, Juao
BE TallonBallesteros, AJ
TI The Mechanism Analysis of the Accelerator for Support Vector Regression
   Based on Data Partition
SO FUZZY SYSTEMS AND DATA MINING VI
SE Frontiers in Artificial Intelligence and Applications
DT Proceedings Paper
CT 6th International Conference on Fuzzy Systems and Data Mining (FSDM)
CY NOV 13-16, 2020
CL ELECTR NETWORK
DE Machine learning; Large-scale data; Data partition; Support vector
   regression; Generation ability
AB Support vector regression is an important algorithm in machine learning, and it is widely used in real life for its good performance, such as house price forecast, disease prediction, weather forecast, and so on. However, it cannot efficiently process large-scale data, because it has a high time complexity in the training process. Data partition as an important solution to solve the large-scale learning problem mainly focuses on the classification task, it trains the classifiers over the divided subsets produced by data partition and obtain the final classifier by combining those classifiers. Meanwhile, the most existing method rarely study the influence of data partition on the regressor performance, so that it is difficult to keep its generation ability. To solve this problem, we obtain the estimation of the difference in objective function before and after the data partition. Mini-Batch K-Means clustering is adopted to largely reduce this difference, and an improved algorithm is proposed. This proposed algorithm includes training stage and prediction stage. In training stag, it uses Mini-Batch K-Means clustering to divide the input space into some disjoint sub-regions of equal sample size, then it trains the regressor on each divided sub-region using support vector regression algorithm. In the prediction stage, the regressor merely offers the predicted label for the unlabeled instances that are in the same sub-region. Experiment results on real datasets illustrate that the proposed algorithm obtains the similar generation ability as the original algorithm, but it has less execution time than other acceleration algorithms.
C1 [Song, Yunsheng; Li, Fangyi; Liu, Jianyu; Zhang, Juao] Shandong Agr Univ, Sch Informat Sci & Engn, Tai An 271018, Shandong, Peoples R China.
RP Song, YS (corresponding author), Shandong Agr Univ, Tai An 271018, Shandong, Peoples R China.
EM sys_sd@126.com
CR Adnan RM, 2020, J HYDROL, V586, DOI 10.1016/j.jhydrol.2019.124371
   CACHIN C, 1994, NEURAL NETWORKS, V7, P175, DOI 10.1016/0893-6080(94)90066-3
   Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, DOI DOI 10.1145/1961189.1961199
   Foody GM, 1999, INT J REMOTE SENS, V20, P3549, DOI 10.1080/014311699211192
   Guo G, 2007, PATTERN RECOGN LETT, V28, P2173, DOI 10.1016/j.patrec.2007.04.017
   Han J, 2012, MOR KAUF D, P1
   Han XX, 2014, QUAL RELIAB ENG INT, V30, P891, DOI 10.1002/qre.1654
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Jimenez S., 2019, ADV INTELL SYST COMP, V1099, P182, DOI [10.1007/978-3-030-35740-5_13, DOI 10.1007/978-3-030-35740-5_13]
   Kleiner A, 2014, J R STAT SOC B, V76, P795, DOI 10.1111/rssb.12050
   Pan XL, 2018, NEUROCOMPUTING, V287, P163, DOI 10.1016/j.neucom.2018.01.083
   Pan XL, 2018, IEEE T NEUR NET LEAR, V29, P1876, DOI 10.1109/TNNLS.2017.2688182
   Song YS, 2019, INT J MACH LEARN CYB, V10, P2389, DOI 10.1007/s13042-018-0877-7
   Wang KN, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/7102946
   Yang LM, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105483
   Zhang C, 2020, INFORM SCIENCES, V507, P665, DOI 10.1016/j.ins.2019.01.033
NR 16
TC 1
Z9 1
U1 1
U2 4
PY 2020
VL 331
BP 528
EP 535
DI 10.3233/FAIA200730
UT WOS:000661247100051
DA 2023-11-16
ER

PT J
AU Akarvardar, K
   Wong, HSP
AF Akarvardar, Kerem
   Wong, H-S Philip
TI Technology Prospects for Data-Intensive Computing
SO PROCEEDINGS OF THE IEEE
DT Article
DE Artificial intelligence (AI); AI accelerators; big data applications;
   CMOS technology; deep learning; DRAM chips; energy efficiency; high
   performance computing; machine learning; Moore's Law; multichip modules
   (MCMs); nonvolatile memory; roadmaps (technology planning); SRAM chips;
   system integration; system-in-package (SiP); system-on-chip;
   three-dimensional integrated circuits; wafer bonding
ID MOORES LAW; POWER; GPU; OPTIMIZATION; INTERCONNECT; EFFICIENCY;
   ROOFLINE; TUTORIAL; DESIGN; SYSTEM
AB For many decades, progress in computing hardware has been closely associated with CMOS logic density, performance, and cost. As such, slowdown in 2-D scaling, frequency saturation in CPUs, and increased cost of design and chip fabrication for advanced technology nodes since the early 2000s have led to concerns about how semiconductor technology may evolve in the future. However, the last two decades have also witnessed a parallel development in the application landscape: the advent of big data and consequent rise of data-intensive computing, using techniques such as machine learning. In this article, we advance the idea that data-intensive computing would further cement semiconductor technology as a foundational technology with multidimensional pathways for growth. Continued progress of semiconductor technology in this new context would require the adoption of a system-centric perspective to holistically harness logic, memory, and packaging resources. After examining the performance metrics for data-intensive computing, we present the historical trends for general-purpose graphics processing unit (GPGPU) as a representative data-intensive computing hardware. Thereon, we estimate the values of the key data-intensive computing parameters for the next decade, and our projections may serve as a precursor for a dedicated technology roadmap. By analyzing the compiled data, we identify and discuss specific opportunities and challenges for data-intensive computing hardware technology.
C1 [Akarvardar, Kerem; Wong, H-S Philip] Corp Res, Taiwan Semicond Mfg Co TSMC, San Jose, CA 95134 USA.
   [Wong, H-S Philip] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
RP Akarvardar, K (corresponding author), Corp Res, Taiwan Semicond Mfg Co TSMC, San Jose, CA 95134 USA.
EM kerema@tsmc.com; hspwong@stanford.edu
CR Aamodt Tor M., 2018, GEN PURPOSE GRAPHICS, DOI DOI 10.1007/978-3-031-01759-9
   Alfano M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2624284
   Altman A., 2019, PROC IEEE HOT CHIPS, P1
   Aly MMS, 2019, P IEEE, V107, P19, DOI 10.1109/JPROC.2018.2882603
   AMD, ADDR CHALL EN EFF CO
   [Anonymous], TSMCS CHIP SCALING E
   [Anonymous], NEW STANDARD COULD L
   [Anonymous], IMAGE OPENCLIPART VE
   [Anonymous], AMD AIMS INCREASE CH
   [Anonymous], JEDEC PUBLISHES HBM3
   [Anonymous], TSMC LAUNCHES NEW N1
   [Anonymous], 2009, NVIDIAS FERMI 1 COMP
   [Anonymous], CHIP MARKET WILL HIT
   [Anonymous], SAMBANOVAS NEW SILIC
   [Anonymous], NVIDIA TESLA V100 GP
   [Anonymous], NVIDIA A100 TENSOR C
   [Anonymous], NVIDIA ARM INTEL PUB
   [Anonymous], MUCH DATA IS CREATED
   [Anonymous], 2003, 2003 IEEE INT ELECT
   [Anonymous], AMD ADDRESSING CHALL
   [Anonymous], JEDEC UPDATES HBM2 M
   [Anonymous], NVIDIA H100 TENSOR C
   [Anonymous], 2012, P 2012 ACMIEEE INT S
   [Anonymous], TSMC BEGINS PILOT PR
   [Anonymous], GEFORCE GPU POWER PR
   [Anonymous], NVIDIA HOPPER GPU AR
   [Anonymous], CUDA C BEST PRACT GU
   [Anonymous], HETEROGENEOUS INTEGR, V2021
   [Anonymous], TSMC UNVEILS N4X NOD
   [Anonymous], AMD CDNA 2 ARCHITECT
   [Anonymous], GPU SPECS DATABASE
   [Anonymous], GRAPHICS CARDS TDP T
   Arunkumar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P320, DOI 10.1145/3079856.3080231
   Auth C., 2017, 2017 IEEE International Electron Devices Meeting (IEDM), p29.1.1, DOI 10.1109/IEDM.2017.8268472
   Auth C., 2012, 2012 IEEE Symposium on VLSI Technology, P131, DOI 10.1109/VLSIT.2012.6242496
   Batra G., 2019, ARTIF INTELL
   Beyne E., 2021, INT EL DEVICES MEET, P3
   Bohr Mark, 2009, 2009 IEEE International Solid-State Circuits Conference (ISSCC 2009), P23, DOI 10.1109/ISSCC.2009.4977293
   Bohr M., 2007, IEEE SOLID STATE CIR, V12, P11, DOI DOI 10.1109/N-SSC.2007.4785534
   Bourjot E, 2021, ELEC COMP C, P470, DOI 10.1109/ECTC32696.2021.00085
   Brochard L, 2019, ENERGY EFFICIENT COM
   Burkacky O., 2021, VALUE CREATION CAN S
   Cao K, 2019, J SYST ARCHITECT, V97, P397, DOI 10.1016/j.sysarc.2019.01.003
   Chang K, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3273956
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Chehab B., 2020, PROC SPIE, V11328
   Chen A, 2016, SOLID STATE ELECTRON, V125, P25, DOI 10.1016/j.sse.2016.07.006
   Chen FC, 2019, ELEC COMP C, P594, DOI 10.1109/ECTC.2019.00095
   Chen JY, 2009, INT EL DEVICES MEET, P1, DOI 10.1109/CLEOE-EQEC.2009.5196326
   Chen MF, 2020, IEEE T ELECTRON DEV, V67, P5343, DOI 10.1109/TED.2020.3021358
   Chen R., 2020, INT EL DEVICES MEET, P15
   Chen YH, 2020, ELEC COMP C, P576, DOI 10.1109/ECTC32862.2020.00096
   Cheng Y. -K., 2020, INT EL DEVICES MEET, P41
   Choi JW, 2013, INT PARALL DISTRIB P, P661, DOI 10.1109/IPDPS.2013.77
   Close GF, 2013, IEEE T CIRCUITS-I, V60, P1521, DOI 10.1109/TCSI.2012.2220459
   Dally W. J., 2017, DEEP LEARNING HPC
   Dally W. J., 2016, EFFICIENCY PROGRAMMA
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   DeBenedictis EP, 2017, COMPUTER, V50, P69, DOI 10.1109/MC.2017.3001236
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Dolbeau R, 2018, J SUPERCOMPUT, V74, P1341, DOI 10.1007/s11227-017-2177-5
   Douglas C, 2021, 2021 IEEE IEDM IEEE, P3
   Elsherbini A, 2021, ELEC COMP C, P1014, DOI 10.1109/ECTC32696.2021.00166
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Farmahini-Farahani A, 2018, PROCEEDINGS OF WORKSHOP ON MEMORY CENTRIC HIGH PERFORMANCE COMPUTING (MCHPC'18), P4, DOI 10.1145/3286475.3286484
   Fazio A, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371976
   Fu Y., 2022, BMC PLANT BIOL, V19, P1
   Games W, 2020, ISSCC DIG TECH PAP I, P144
   Garland M, 2010, COMMUN ACM, V53, P58, DOI 10.1145/1839676.1839694
   Ghane M, 2018, Arxiv, DOI arXiv:1809.09206
   Gokhale M, 2008, COMPUTER, V41, P60, DOI 10.1109/MC.2008.125
   Gomes Wilfred, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P42, DOI 10.1109/ISSCC42614.2022.9731673
   Guerreiro J, 2018, INT S HIGH PERF COMP, P789, DOI 10.1109/HPCA.2018.00072
   Gupta MK, 2021, IEEE T ELECTRON DEV, V68, P6106, DOI 10.1109/TED.2021.3121349
   Gupta MK, 2021, IEEE T ELECTRON DEV, V68, P3819, DOI 10.1109/TED.2021.3088392
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Hanhirova J, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P204, DOI 10.1145/3204949.3204975
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hou SY, 2017, IEEE T ELECTRON DEV, V64, P4071, DOI 10.1109/TED.2017.2737644
   Hsia H, 2021, ELEC COMP C, P263, DOI 10.1109/ECTC32696.2021.00052
   Huang H. Howie, 2014, 2014 IEEE International Conference on Big Data (Big Data), P16, DOI 10.1109/BigData.2014.7004471
   Huang PK, 2021, ELEC COMP C, P101, DOI 10.1109/ECTC32696.2021.00028
   Hung JN, 2021, ELEC COMP C, P105, DOI 10.1109/ECTC32696.2021.00029
   Hwang T, 2018, Arxiv, DOI [arXiv:1803.08971, DOI 10.2139/SSRN.3147971, 10.48550/arXiv.1803.08971]
   Hwu WM, 2018, IEEE MICRO, V38, P56, DOI 10.1109/MM.2018.2877839
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Esser SK, 2020, Arxiv, DOI arXiv:1902.08153
   Kaisler S, 2013, P ANN HICSS, P995, DOI 10.1109/HICSS.2013.645
   Kammler Th, 2018, ECS Transactions, V85, P39, DOI 10.1149/08508.0039ecst
   Kandiah Vijay, 2021, MICRO54 54 ANN IEEE, P738
   Keckler S., ENERGY EFFICIENT ARC
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Knowles S., 2021, IEEE HOT CHIPS 33 S, P1
   Le BQ, 2019, IEEE T ELECTRON DEV, V66, P641, DOI 10.1109/TED.2018.2879788
   Lee D, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2832911
   Leiserson CE, 2020, SCIENCE, V368, P1079, DOI 10.1126/science.aam9744
   Lie S, 2022, IEEE HOT CHIPS 34 S
   Lin X. -W., 2021, INT CONF SOFTW ENG, P3
   Liu M, 2021, ISSCC DIG TECH PAP I, V64, P9, DOI 10.1109/ISSCC42613.2021.9366060
   Liu YZ, 2019, NAT ELECTRON, V2, P555, DOI 10.1038/s41928-019-0340-0
   Loubet N, 2017, S VLSI TECH, pT230, DOI 10.23919/VLSIT.2017.7998183
   Madan N, 2007, INT SYMP MICROARCH, P223, DOI 10.1109/MICRO.2007.31
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Mathur R., 2021, PROC IEEE CUSTOM INT, P1
   Mathur R, 2020, ELEC COMP C, P541, DOI 10.1109/ECTC32862.2020.00091
   Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433
   Milojevic D, 2021, PROC SPIE, V11614, DOI 10.1117/12.2584532
   Min M, 2020, 2020 INTERNATIONAL WAFER LEVEL PACKAGING CONFERENCE (IWLPC), DOI 10.23919/IWLPC52010.2020.9375855
   Mistry K, 2007, INT EL DEVICES MEET, P247, DOI 10.1109/iedm.2007.4418914
   Mittal S, 2017, IEEE T PARALL DISTR, V28, P16, DOI 10.1109/TPDS.2016.2546249
   Moore SK, 2020, IEEE SPECTRUM, V57, P25, DOI [10.1109/mspec.2020.9150552, 10.1109/MSPEC.2020.9150552]
   Mutlu Onur, 2014, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V1, P19
   Naffziger S, 2021, ISSCC
   Naffziger S, 2021, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA52012.2021.00014
   Nakamura H., 2006, S VLSI TECHNOL DIG T, P158, DOI [10.1109/VLSIT.2006.1705265, DOI 10.1109/VLSIT.2006.1705265]
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Niu D., 2022, 2022 IEEE INT SOLIDS, P1
   Nogami T., 2022, IEEE S VLSI TECHN CI, P423
   Nurvitadhi E, 2018, I C FIELD PROG LOGIC, P106, DOI 10.1109/FPL.2018.00027
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   OConnor M., HIGH BANDWIDTH ENERG
   Oh CS, 2020, ISSCC DIG TECH PAP I, P330, DOI 10.1109/isscc19947.2020.9063110
   Oh Y, 2022, IEEE EMBED SYST LETT, V14, P187, DOI 10.1109/LES.2022.3163749
   Oldiges P, 2020, IEEE ACCESS, V8, P154329, DOI 10.1109/ACCESS.2020.3017756
   Paik Y., 2017, FLASH MEM SUMM
   Papermaster M., 2019, PROC IEEE 26 INT C H, P1
   Papermaster M., 2021, PROC S VLSI CIRCUITS, P1
   Park MJ, 2022, IEEE J SOLID-ST CIRC, DOI [10.1109/ISSCC42614.2022.9731562, 10.1109/JSSC.2022.3193354]
   Patterson D. A., 2012, COMPUTER ARCHITECTUR
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Perumkunnil M., 2020, IEDM, P15
   Pomianowski A., 2021, IEEE HOT CHIPS 33 S, P1
   Puttaswamy K, 2009, IEEE T COMPUT, V58, P1369, DOI 10.1109/TC.2009.92
   Qadeer W, 2015, COMMUN ACM, V58, P85, DOI 10.1145/2735841
   Qureshi Z, 2023, Arxiv, DOI arXiv:2203.04910
   Rydning D.R.-J.G, 2018, DIGITIZATION WORLD E
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samavedam SB, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372023
   Scherer M, 2022, IEEE T COMPUT AID D, V41, P1020, DOI 10.1109/TCAD.2021.3075420
   Shahidi GG, 2019, IEEE ACCESS, V7, P851, DOI 10.1109/ACCESS.2018.2885895
   Sharma D.D., UNIVERSAL CHIPLET IN
   Sheikh Farhana, 2021, IEEE Solid-State Circuits Magazine, V13, P77, DOI 10.1109/MSSC.2021.3111386
   Shen YW, 2019, J LIGHTWAVE TECHNOL, V37, P245, DOI 10.1109/JLT.2019.2897365
   Shiba K, 2021, IEEE T CIRCUITS-I, V68, P692, DOI 10.1109/TCSI.2020.3037892
   Sinha S, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372120
   Sinha S, 2020, Arxiv, DOI arXiv:2005.10866
   Smith S., 2022, ARXIV
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Stosic D, TRAINING NEURAL NETW
   Stow D, 2019, IEEE COMPUT ARCHIT L, V18, P132, DOI 10.1109/LCA.2019.2941715
   Su L. T., 2017, INT EL DEVICES MEET, P1
   Swaminathan R., 2021, HOT CHIPS 33 TUTORIA
   Sze Vivienne, 2020, IEEE Solid-State Circuits Magazine, V12, P28, DOI 10.1109/MSSC.2020.3002140
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tang ZH, 2019, E-ENERGY'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON FUTURE ENERGY SYSTEMS, P315, DOI 10.1145/3307772.3328315
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Timoneda X, 2020, IEEE T COMMUN, V68, P3247, DOI 10.1109/TCOMM.2020.2973988
   Tsai YF, 2008, IEEE T VLSI SYST, V16, P444, DOI 10.1109/TVLSI.2007.915429
   TSMC, 2023, INT TSMC HINTS 3400M
   WANG NG, 2018, ADV NEUR IN, V31
   Wang PH, 2011, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2019608.2019612
   Wang X, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P711, DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00134
   Watson HJ, 2014, COMMUN ASSOC INF SYS, V34, P1247
   Wei TW, 2021, IEEE T COMP PACK MAN, V11, P415, DOI 10.1109/TCPMT.2020.3045113
   Wen W, 2017, MICROPROCESS MICROSY, V49, P44, DOI 10.1016/j.micpro.2017.01.005
   Williams S, PERFORMANCE TUNING R
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wong HSP, 2020, P IEEE, V108, P478, DOI 10.1109/JPROC.2020.2981715
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Wu C.H., 2021, 2021 S VLSI CIRCUITS, P1
   Wu H., 2018, IEDM
   Wu SY, 2019, INT EL DEVICES MEET
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Wuu John, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P428, DOI 10.1109/ISSCC42614.2022.9731565
   Yeap G, 2019, INT EL DEVICES MEET, DOI 10.1109/IEDM19573.2019.8993577
   Yu D., 2014, P IEEE CUST INT CIRC, P1
   Yu D., 2021, HOTCHIPS 33 TUTORIAL
   Zhang Y, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2020.2975656
   Zhao J., 2013, ACM T ARCHIT CODE OP, V10, P1
   Zhu LJ, 2021, IEEE T VLSI SYST, V29, P1152, DOI 10.1109/TVLSI.2021.3073070
   Zhu MH, 2018, IEEE T VLSI SYST, V26, P831, DOI 10.1109/TVLSI.2018.2791442
NR 183
TC 3
Z9 3
U1 5
U2 8
PD JAN
PY 2023
VL 111
IS 1
BP 92
EP 112
DI 10.1109/JPROC.2022.3218057
UT WOS:000927958400010
DA 2023-11-16
ER

PT J
AU Huang, HJ
   Li, YT
   Sun, J
   Zhu, XY
   Zhang, J
   Luo, L
   Li, JL
   Wang, ZK
AF Huang, Hongjing
   Li, Yingtao
   Sun, Jie
   Zhu, Xueying
   Zhang, Jie
   Luo, Liang
   Li, Jialin
   Wang, Zeke
TI P4SGD: Programmable Switch Enhanced Model-Parallel Training on
   Generalized Linear Models on Distributed FPGAs
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Distributed training system; FPGA; GLMs; P4
ID MACHINE
AB Generalized linear models (GLMs) are a widely utilized family of machine learning models in real-world applications. As data size increases, it is essential to perform efficient distributed training for these models. However, existing systems for distributed training have a high cost for communication and often use large batch sizes to balance computation and communication, which negatively affects convergence. Therefore, we argue for an efficient distributed GLM training system that strives to achieve linear scalability, while keeping batch size reasonably low. As a start, we propose P4SGD, a distributed heterogeneous training system that efficiently trains GLMs through model parallelism between distributed FPGAs and through forward-communication-backward pipeline parallelism within an FPGA. Moreover, we propose a light-weight, latency-centric in-switch aggregation protocol to minimize the latency of the AllReduce operation between distributed FPGAs, powered by a programmable switch. As such, to our knowledge, P4SGD is the first solution that achieves almost linear scalability between distributed accelerators through model parallelism. We implement P4SGD on eight Xilinx U280 FPGAs and a Tofino P4 switch. Our experiments show P4SGD converges up to 6.5X faster than the state-of-the-art GPU counterpart.
C1 [Huang, Hongjing; Li, Yingtao; Zhu, Xueying; Zhang, Jie; Wang, Zeke] Zhejiang Univ, Collaborat Innovat Ctr Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
   [Sun, Jie] Zhejiang Univ, Collaborat Innovat Ctr Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
   [Sun, Jie] Alibaba Grp, Hangzhou 311121, Peoples R China.
   [Luo, Liang] Univ Washington, Seattle, WA 98195 USA.
   [Li, Jialin] Natl Univ Singapore, Singapore 119077, Singapore.
RP Wang, ZK (corresponding author), Zhejiang Univ, Collaborat Innovat Ctr Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
EM huang_hj@zju.edu.cn; Li_Yingtao@zju.edu.cn; sunjie.sun@alibaba-inc.com;
   zhuxueying@zju.edu.cn; carlzhang4@zju.edu.cn;
   liangluo@cs.washington.edu; lijl@comp.nus.edu.sg; wangzeke@zju.edu.cn
CR [Anonymous], 2015, P SPE RES SIM S
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Bressana Pietro, 2020, NAI '20: Proceedings of the Workshop on Network Application Integration/CoDesign, P35, DOI 10.1145/3405672.3405807
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Caulfield AM, 2016, INT SYMP MICROARCH
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chiu GR, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'18), P34, DOI 10.1145/3177540.3177561
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cui HG, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901323
   Dass J, 2020, IEEE T COMPUT, V69, P1015, DOI 10.1109/TC.2020.2993552
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Edge-core, 2020, WEDG 100BF 32X R07
   Elgohary A, 2016, PROC VLDB ENDOW, V9, P960
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Free Software Foundation Inc., 2019, LM SENS
   Graham RL, 2016, PROCEEDINGS OF FIRST WORKSHOP ON OPTIMIZATION OF COMMUNICATION IN HPC RUNTIME SYSTEMS (COM-HPC 2016), P1, DOI [10.1109/COM-HPC.2016.6, 10.1109/COMHPC.2016.006]
   Gray Alan, 2019, GETTING STARTED CUDA
   Ho Qirong, 2013, Adv Neural Inf Process Syst, V2013, P1223
   Huang YP, 2019, ADV NEUR IN, V32
   Intel, 2021, INT TOF PROGR ETH SW
   Intel, 2021, INT TOF 2 P4 PROGR E
   Jia ZH, 2018, Arxiv, DOI arXiv:1807.05358
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Krizhevsky A, 2014, Arxiv, DOI [arXiv:1404.5997, DOI 10.48550/ARXIV.1404.5997]
   Lao C, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P741
   Lee JH, 2020, IEEE INT SYMP PHYS, DOI 10.1109/ipfa49335.2020.9260706
   Li M., 2014, P S OP SYST DES IMPL, P583
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   Li Zhuohan, 2021, TERAPIPE TOKEN LEVEL
   Luo L, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P41, DOI 10.1145/3267809.3267840
   Mahajan D, 2018, Arxiv, DOI arXiv:1801.06027
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Microsoft, 2020, ZERO DEEPSP NEW SYST
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   NVIDIA, 2023, CUBLAS REL 12 1
   NVIDIA, 2012, NVIDIA SYST MAN INT
   NVIDIA, 2021, ACC GPU STOR COMM NV
   NVIDIA, 2020, NVIDIA COLL COMM LIB
   Oden L, 2014, IEEE ACM INT SYMP, P483, DOI 10.1109/CCGrid.2014.21
   Park JH, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P307
   Pop P, 2016, IET CYBER PHYS SYST, V1, P86, DOI 10.1049/iet-cps.2016.0021
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Sapio A, 2020, Arxiv, DOI arXiv:1903.06701
   Sharma H, 2016, INT SYMP MICROARCH
   Shoeybi M, 2020, Arxiv, DOI [arXiv:1909.08053, 10.48550/ARXIV.1909.08053, DOI 10.1073/PNAS.2205690119]
   Thangakrishnan I, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/sc41405.2020.00048
   Umuroglu Y, 2018, I C FIELD PROG LOGIC, P307, DOI 10.1109/FPL.2018.00059
   Wang Q, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P277
   Wang ZK, 2019, PROC VLDB ENDOW, V12, P807, DOI 10.14778/3317315.3317322
   Xilinx, 2020, ALV U280 DAT CTR ACC
   Xillinx, 2023, ALV CARD MAN SOL SUB
   Xu YZ, 2021, Arxiv, DOI [arXiv:2105.04663, 10.48550/ARXIV.2105.04663]
   Zhang ZP, 2020, PROC INT CONF DATA, P1513, DOI 10.1109/ICDE48307.2020.00134
   Zheng LM, 2022, Arxiv, DOI arXiv:2201.12023
   Zheng TY, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9834-8
NR 56
TC 0
Z9 0
U1 4
U2 4
PD AUG
PY 2023
VL 34
IS 8
BP 2311
EP 2324
DI 10.1109/TPDS.2023.3279255
UT WOS:001022028500001
DA 2023-11-16
ER

PT J
AU Taheri, F
   Bayat-Sarmadi, S
   Hadayeghparast, S
AF Taheri, Farhad
   Bayat-Sarmadi, Siavash
   Hadayeghparast, Shahriar
TI RISC-HD: Lightweight RISC-V Processor for Efficient Hyperdimensional
   Computing Inference
SO IEEE INTERNET OF THINGS JOURNAL
DT Article
DE FPGA design; hyperdimensional (HD) computing; instruction set
   architecture (ISA) extension; pruning; RISC-V
ID INTERNET
AB Hyperdimensional (HD) computing is a lightweight machine learning method widely used in Internet of Things applications for classification tasks. Although many hardware accelerators are proposed to improve the performance of HD, they suffer from low flexibility that makes them not practical in most real-life scenarios. To improve the flexibility, an opensource instruction set architecture (ISA) called RISC-V has been employed and extended for a specific application such as machine learning. This article aims to improve the efficiency and flexibility of HD computing for resource-constrained applications. To this end, we extend a RISC-V core (RI5CY) for HD computing called RISC-HD. First, to reduce the computational overhead at the HD inference phase, we introduce a pruning method to remove the ineffectual dimensions. The proposed pruning method can reduce the dimension from 10k to 1k with negligible accuracy loss. Second, an ISA extension for RI5CY is proposed to compute the HD inference efficiently. Experimental results indicate that RISC-HD adds 1.42x area overhead to the RI5CY core; however, it consumes only 2932 slices on the Artix-7 FPGA, which is suitable for resource-constrained devices. Additionally, RISC-HD improves the total clock cycle by 7.48x compared to the RI5CY core and 6.17x compared to ARM Cortex-M4 in the ISOLET data set. Moreover, RISC-HD achieves 7.22x energy efficiency compared to the RI5CY core.
C1 [Taheri, Farhad; Bayat-Sarmadi, Siavash; Hadayeghparast, Shahriar] Sharif Univ Technol, Dept Comp Engn, Tehran 1458889694, Iran.
RP Bayat-Sarmadi, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran 1458889694, Iran.
EM farhadtaheri@ce.sharif.edu; sbayat@sharif.edu;
   hadayeghparast@ce.sharif.edu
CR Anguita D., 2013, ESANN
   [Anonymous], IBEX
   [Anonymous], ROCKET
   [Anonymous], OVP SIMULATOR
   [Anonymous], RI5CY
   [Anonymous], PULPINO
   [Anonymous], VIVADO DESIGN SUITE
   [Anonymous], FREEDOM
   Bartolini A, 2019, IEEE I C ELECT CIRC, P771, DOI [10.1109/ICECS46596.2019.8964699, 10.1109/icecs46596.2019.8964699]
   Benatti S, 2019, IEEE T BIOMED CIRC S, V13, P516, DOI 10.1109/TBCAS.2019.2914476
   Burrello Alessio, 2019, 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE). Proceedings, P752, DOI 10.23919/DATE.2019.8715186
   Burrello A, 2021, IEEE J BIOMED HEALTH, V25, P935, DOI 10.1109/JBHI.2020.3022211
   Das Kajaree, 2017, INT J INNOVATIVE RES, V5, P1301, DOI DOI 10.15680/IJIRCCE.2017.0502001
   Farzam SMH, 2022, IEEE T CIRCUITS-I, V69, P1221, DOI 10.1109/TCSI.2021.3129589
   Frank A., 2010, UCI MACHINE LEARNING
   Fritzmann Tim, 2020, IACR T CRYPTOGRAPH H, V4, P239
   Garofalo A, 2020, DES AUT TEST EUROPE, P186, DOI 10.23919/DATE48585.2020.9116529
   Garofalo A, 2019, IEEE I C ELECT CIRC, P33, DOI [10.1109/icecs46596.2019.8965067, 10.1109/ICECS46596.2019.8965067]
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hadayeghparast S, 2022, IEEE INTERNET THINGS, V9, P15839, DOI 10.1109/JIOT.2022.3152850
   Imani M, 2020, IEEE T COMPUT AID D, V39, P2268, DOI 10.1109/TCAD.2019.2954472
   Imani M, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317785
   Imani M, 2019, ANN IEEE SYM FIELD P, P190, DOI 10.1109/FCCM.2019.00034
   Imani M, 2019, DES AUT TEST EUROPE, P126, DOI [10.23919/date.2019.8714821, 10.23919/DATE.2019.8714821]
   Imani M, 2018, DES AUT CON, DOI 10.1145/3195970.3196060
   Kazemi A, 2021, I SYMPOS LOW POWER E, DOI 10.1109/ISLPED52811.2021.9502498
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kundu S, 2020, IEEE T COMPUT, V69, P1045, DOI 10.1109/TC.2020.2972520
   Lin J, 2017, IEEE INTERNET THINGS, V4, P1125, DOI 10.1109/JIOT.2017.2683200
   Montagna F, 2018, DES AUT CON, DOI 10.1145/3195970.3196096
   Morris J, 2022, IEEE T COMPUT AID D, V41, P897, DOI 10.1109/TCAD.2021.3069139
   Morris Justin, 2019, I SYMPOS LOW POWER E, P1, DOI [DOI 10.1109/islped.2019.8824908, DOI 10.1109/ISLPED.2019.8824908]
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paulin G, 2021, IEEE T VLSI SYST, V29, P1624, DOI 10.1109/TVLSI.2021.3093242
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Reiss A., 2012, P P 5 INT C PERVASIV, DOI [10.1145/2413097.2413148, DOI 10.1145/2413097.2413148]
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Taheri F., 2022, IEEE T CIRCUITS SY 1, V69, P1045
   Wang XY, 2020, IEEE INTERNET THINGS, V7, P4403, DOI 10.1109/JIOT.2020.2976702
   Waterman, 2011, UCBEECS201162
NR 42
TC 2
Z9 2
U1 2
U2 6
PD DEC 1
PY 2022
VL 9
IS 23
BP 24030
EP 24037
DI 10.1109/JIOT.2022.3191717
UT WOS:000904931000051
DA 2023-11-16
ER

PT C
AU Li, JY
   Wang, FG
   Araki, T
   Qiu, JD
AF Li, Jiayu
   Wang, Fugang
   Araki, Takuya
   Qiu, Judy
GP IEEE
TI Generalized Sparse Matrix-Matrix Multiplication for Vector Engines and
   Graph Applications
SO PROCEEDINGS OF MCHPC'19: 2019 IEEE/ACM WORKSHOP ON MEMORY CENTRIC HIGH
   PERFORMANCE COMPUTING (MCHPC)
DT Proceedings Paper
CT IEEE/ACM Workshop on Memory Centric High Performance Computing (MCHPC)
CY NOV 18, 2019
CL Denver, CO
DE Sparse Linear Algebra Kernel; NEC Vector Engine; Graph
AB Generalized sparse matrix-matrix multiplication (SpGEMM) is a key primitive kernel for many high-performance graph algorithms as well as for machine learning and data analysis algorithms. Although many SpGEMM algorithms have been proposed, such as ESC and SPA, there is currently no SpGEMM kernel optimized for vector engines (VEs). NEC SX-Aurora is the new vector computing system that can achieve high performance by leveraging high bandwidth memory of 1.2TB/s and long vector of VEs, where the execution of scientific applications is limited by memory bandwidth. In this paper, we demonstrate significant initial work of SpGEMM kernel for a vector engine and implement it to vectorize several essential graph analysis algorithms: Butterfly counting and Triangle counting. We propose a SpGEMM algorithm with a novel hybrid method based on sparse vectors and loop raking to maximize the length of vectorizable code for vector machine architectures. The experimental results show that the vector engine has advantages on more massive data sets. This work contributes to the high performance and portability of the SpGEMM kernel to a new family of heterogeneous computing systems, which is Vector Host (VH) equipped with different accelerators or VEs.
C1 [Li, Jiayu; Wang, Fugang; Qiu, Judy] Indiana Univ, Intelligent Syst Engn, Bloomington, IN 47405 USA.
   [Araki, Takuya] NEC Corp Ltd, Data Sci Res Labs, Yokohama, Kanagawa, Japan.
RP Li, JY (corresponding author), Indiana Univ, Intelligent Syst Engn, Bloomington, IN 47405 USA.
EM jl145@iu.edu; fuwang@indiana.edu; t-araki@dc.jp.nec.com;
   xqiu@indiana.edu
CR Afanasyev Ilya V., 2019, Parallel Computing Technologies. 15th International Conference, PaCT 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11657), P125, DOI 10.1007/978-3-030-25636-4_10
   Alon N, 2008, BIOINFORMATICS, V24, pI241, DOI 10.1093/bioinformatics/btn163
   [Anonymous], ARXIV10062183
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Battiston F, 2017, CHAOS, V27, DOI 10.1063/1.4979282
   Bell N, 2012, SIAM J SCI COMPUT, V34, pC123, DOI 10.1137/110838844
   Chen L., 2019, ARXIV190304395
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049670
   Demouth Julien, 2012, GPU TECHN C
   GILBERT JR, 1992, SIAM J MATRIX ANAL A, V13, P333, DOI 10.1137/0613024
   Kepner J, 2011, SOFTW ENVIRON TOOLS, V22, P1, DOI 10.1137/1.9780898719918
   Komatsu Kazuhiko, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P685, DOI 10.1109/SC.2018.00057
   Liu WF, 2015, J PARALLEL DISTR COM, V85, P47, DOI 10.1016/j.jpdc.2015.06.010
   Nagasaka Y., 2017, P 46 INT C PAR PROC
   Sanei-Mehri SV, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2150, DOI 10.1145/3219819.3220097
   Stanley Richard P, 2013, SPRINGER, V20, P22
   Zagha M., 1991, Proceedings Supercomputing '91 (Cat. No.91CH3058-5), P712, DOI 10.1145/125826.126164
NR 18
TC 2
Z9 2
U1 0
U2 1
PY 2019
BP 33
EP 42
DI 10.1109/MCHPC49590.2019.00012
UT WOS:000529056800005
DA 2023-11-16
ER

PT C
AU Kwasniewska, A
   Raghava, S
   Davila, C
   Sevenier, M
   Gamba, D
   Ruminski, J
AF Kwasniewska, Alicja
   Raghava, Sharath
   Davila, Carlos
   Sevenier, Mikael
   Gamba, David
   Ruminski, Jacek
GP IEEE
TI Preferred Benchmarking Criteria for Systematic Taxonomy of Embedded
   Platforms (STEP) in Human System Interaction Systems
SO 2022 15TH INTERNATIONAL CONFERENCE ON HUMAN SYSTEM INTERACTION (HSI)
SE Conference on Human System Interaction
DT Proceedings Paper
CT 15th IEEE International Conference on Human System Interaction (HSI)
CY JUL 28-31, 2022
CL Trobe Univ, Melbourne, AUSTRALIA
HO Trobe Univ
DE embedded systems; benchmarking; system design; neural networks; machine
   learning
AB The rate of progress in the field of Artificial Intelligence (AI) and Machine Learning (ML) has significantly increased over the past ten years and continues to accelerate. Since then, AI has made the leap from research case studies to real production ready applications. The significance of this growth cannot be undermined as it catalyzed the very nature of computing. Conventional platforms struggle to achieve greater performance and efficiency, what causes a surging demand for innovative AI accelerators, specialized platforms and purpose-built computes. At the same time, it is required to provide solutions for assessment of ML platform performance in a reproducible and unbiased manner to be able to provide a fair comparison of different products. This is especially valid for Human System Interaction (HSI) systems that require specific data handling for low latency responses in emergency situations or to improve user experience, as well as for preserving data privacy and security by processing it locally. Taking it into account, this work presents a comprehensive guideline on preferred benchmarking criteria for evaluation of ML platforms that include both lower level analysis of ML models and system-level evaluation of the entire pipeline. In addition, we propose a Systematic Taxonomy of Embedded Platforms (STEP) that can be used by the community and customers for better selection of specific ML hardware consistent with their needs for better design of ML-based HSI solutions.
C1 [Kwasniewska, Alicja; Raghava, Sharath; Davila, Carlos; Sevenier, Mikael; Gamba, David] SiMa Technol, San Jose, CA 95110 USA.
   [Ruminski, Jacek] Gdansk Univ Technol, Gdansk, Poland.
RP Kwasniewska, A (corresponding author), SiMa Technol, San Jose, CA 95110 USA.
EM alicja@sima.ai; sharath.raghava@sima.ai; carlos@sima.ai;
   sevenier@sima.ai; david.gamba@sima.ai; jacek.ruminski@pg.edu.pl
CR Ajani TS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134412
   Banbury C. R., 2020, ARXIV
   Baruffaldi S., 2020, IDENTIFYING MEASURIN
   Basicmi, 2022, AI CHIP ICS IPS
   Batarseh FA, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00315-8
   Batra G., 2019, ARTIF INTELL, V2
   Beyer D, 2019, INT J SOFTW TOOLS TE, V21, P1, DOI 10.1007/s10009-017-0469-y
   Burr GW, 2022, IEEE DES TEST, V39, P18, DOI 10.1109/MDAT.2021.3063366
   Casalino L, 2021, INT J HIGH PERFORM C, V35, P432, DOI 10.1177/10943420211006452
   Deng CY, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101656
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Famili A., 1997, Intelligent Data Analysis, V1
   H. AI, 2019, HIGH LEV EXP GROUP A
   Hamdan S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226441
   Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13
   Jacob B, 2017, Arxiv, DOI arXiv:1712.05877
   Kaczmarek M, 2012, J MED IMAG HEALTH IN, V2, P56, DOI 10.1166/jmihi.2012.1061
   Krishnamoorthi R, 2018, Arxiv, DOI arXiv:1806.08342
   Kwasniewska A, 2019, IEEE IND ELEC, P96, DOI 10.1109/IECON.2019.8927153
   Kwasniewska A, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103263
   Kwasniewska A, 2017, C HUM SYST INTERACT, P41, DOI 10.1109/HSI.2017.8004993
   Lewandowska M., 2011, 2011 Federated Conference on Computer Science and Information Systems (FedCSIS), P405
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mao YZ, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/6635638
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Perpetuini D, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063286
   Rai R, 2021, INT J PROD RES, V59, P4773, DOI 10.1080/00207543.2021.1956675
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Sakuma Y, 2021, Arxiv, DOI arXiv:2103.11704
   Shafique M, 2021, Arxiv, DOI arXiv:2109.09829
   Shahriari Kyarash, 2017, 2017 IEEE Canada International Humanitarian Technology Conference (IHTC), P197, DOI 10.1109/IHTC.2017.8058187
   Shalf J, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0061
   Suo Kun, 2021, SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing, P1182, DOI 10.1145/3412841.3441993
   Szankin M, 2019, C HUM SYST INTERACT, P28, DOI 10.1109/hsi47298.2019.8942636
   Theissler A, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107864
   Wei YC, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875910
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wolf S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163088
   Wu N, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3418498
   Zhou Y, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER ENGINEERING (ICAICE 2020), P494, DOI 10.1109/ICAICE51518.2020.00102
   Zitouni H, 2022, J KING SAUD UNIV-COM, V34, P1124, DOI 10.1016/j.jksuci.2020.04.012
NR 42
TC 1
Z9 1
U1 0
U2 0
PY 2022
UT WOS:000861739100032
DA 2023-11-16
ER

PT J
AU Mitchell, R
   Frank, E
   Holmes, G
AF Mitchell, Rory
   Frank, Eibe
   Holmes, Geoffrey
TI GPUTreeShap: massively parallel exact calculation of SHAP scores for
   tree ensembles
SO PEERJ COMPUTER SCIENCE
DT Article
DE Shapley values; GPU computing; Interpretability
ID ALGORITHMS
AB SHapley Additive exPlanation (SHAP) values (Lundberg & Lee, 2017) provide a game theoretic interpretation of the predictions of machine learning models based on Shapley values (Shapley, 1953). While exact calculation of SHAP values is computationally intractable in general, a recursive polynomial-time algorithm called TreeShap (Lundberg et al., 2020) is available for decision tree models. However, despite its polynomial time complexity, TreeShap can become a significant bottleneck in practical machine learning pipelines when applied to large decision tree ensembles. Unfortunately, the complicated TreeShap algorithm is difficult to map to hardware accelerators such as GPUs. In this work, we present GPUTreeShap, a reformulated TreeShap algorithm suitable for massively parallel computation on graphics processing units. Our approach first preprocesses each decision tree to isolate variable sized sub-problems from the original recursive algorithm, then solves a bin packing problem, and finally maps sub-problems to single-instruction, multiple-thread (SIMT) tasks for parallel execution with specialised hardware instructions. With a single NVIDIA Tesla V100-32 GPU, we achieve speedups of up to 19x for SHAP values, and speedups of up to 340x for SHAP interaction values, over a state-of-the-art multi-core CPU implementation executed on two 20-core Xeon E5-2698 v4 2.2 GHz CPUs. We also experiment with multi-GPU computing using eight V100 GPUs, demonstrating throughput of 1.2 M rows per second-equivalent CPU-based performance is estimated to require 6850 CPU cores.
C1 [Mitchell, Rory] Nvidia, Santa Clara, CA 95051 USA.
   [Frank, Eibe; Holmes, Geoffrey] Univ Waikato, Hamilton, New Zealand.
RP Mitchell, R (corresponding author), Nvidia, Santa Clara, CA 95051 USA.
EM ramitchellnz@gmail.com
CR Anderson R, 1984, 1003 STANF U COMP SC
   ANDERSON RJ, 1989, INFORM COMPUT, V82, P262, DOI 10.1016/0890-5401(89)90003-5
   Andrew, 2013, P 30 INT C MACH LEAR, P1337
   [Anonymous], 2010, P 2010 ACM SIGMOD IN, DOI DOI 10.1145/1807167.1807207
   Blackard JA, 1998, THESIS COLARADO STAT
   Boyer V, 2012, COMPUT OPER RES, V39, P42, DOI 10.1016/j.cor.2011.03.014
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chetlur S, 2014, ARXIV14100759, DOI [10. 48550/arXiv.1410.0759, DOI 10.48550/ARXIV.1410.0759]
   CONNOLLY D, 1991, J OPER RES SOC, V42, P513
   Dorogush A.V., 2018, CATBOOST GRADIENT BO, DOI DOI 10.48550/ARXIV.1810.11363
   Fang B, 2005, IEEE INT SYMP CIRC S, P1126
   Fatahalian Kayvon, 2004, P ACM SIGGRAPH EUROG, P133
   Fujimoto K, 2006, GAME ECON BEHAV, V55, P72, DOI 10.1016/j.geb.2005.03.002
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   Green Oded, 2012, P 26 ACM INT C SUPER, P331, DOI [10. 1145 / 2304576.2304621, DOI 10.1145/2304576.2304621]
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Hall Jesse D., 2003, CACHE BANDWIDTH AWAR
   Harris M, 2005, GPU GEMS, V2, P547
   Jiang CH, 2005, PACT 2005: 14TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P185
   JOHNSON DS, 1974, J COMPUT SYST SCI, V8, P272, DOI 10.1016/S0022-0000(74)80026-7
   Ke GL, 2017, ADV NEUR IN, V30
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Liu Y, 2006, LECT NOTES COMPUT SC, V3994, P188
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Man E. C., 1996, APPROXIMATION ALGORI, P46
   Mitchell R, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.127
   Moreland K, 2003, P ACM SIGGRAPH EUROG, V112, P112, DOI DOI 10.2312/EGGH.EGGH03.112-119
   NVIDIA Corporation, 2020, CUDA C PROGRAMMING G
   Pace RK, 1997, STAT PROBABIL LETT, V33, P291, DOI 10.1016/s0167-7152(96)00140-x
   Perry M, 2014, J PHYS CONF SER, V513, DOI 10.1088/1742-6596/513/2/022027
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shapley LS., 1953, CONTRIBUTIONS THEORY, V2, P307, DOI [10.1515/9781400881970-018, DOI 10.1515/9781400881970-018]
   Sharp T., 2012, US Patent, Patent No. [8,290,882, 8290882]
   Sharp T, 2008, LECT NOTES COMPUT SC, V5305, P595, DOI 10.1007/978-3-540-88693-8_44
   Si S., 2017, GPU ACCELERATION LAR, DOI [10.48550/arXiv.1706.08359, DOI 10.48550/ARXIV.1706.08359]
   Steflen P, 2010, LECT NOTES COMPUT SC, V6068, P290
   Xiao H, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1708.07747
NR 40
TC 10
Z9 10
U1 4
U2 11
PD APR 5
PY 2022
VL 8
AR e880
DI 10.7717/peerj-cs.880
UT WOS:000784807600003
DA 2023-11-16
ER

PT C
AU Golnari, PA
   Malik, S
AF Golnari, Pareesa Ameneh
   Malik, Sharad
GP IEEE
TI Evaluating Matrix Representations for Error-Tolerant Computing
SO PROCEEDINGS OF THE 2017 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 20th Conference and Exhibition on Design, Automation and Test in Europe
   (DATE)
CY MAR 27-31, 2017
CL EPFL Campus, Lausanne, SWITZERLAND
HO EPFL Campus
AB 'We propose a methodology to determine the suitability of different data representations in terms of their errortolerance for a given application with accelerator-based computing. This methodology helps match the characteristics of a representation to the data access patterns in an application. For this, we first identify a benchmark of key kernels from linear algebra that can be used to construct applications of interest using any of several widely used data representations. This is then used in an experimental framework for studying the error tolerance of a specific data format for an application.
   As case studies, we evaluate the error-tolerance of seven dataformats on sparse matrix to vector multiplication, diagonal add, and two machine learning applications i) principal component analysis (PCA), which is a statistical technique widely used in data analysis and ii) movie recommendation system with Restricted Boltzmann Machine (RBM) as the core. We observe that the Dense format behaves well for complicated data accesses such as diagonal accessing but is poor in utilizing local memory. Sparse formats with simpler addressing methods and a careful selection of stored information, e.g., CRS and ELLPACK, demonstrate a better error-tolerance for most of our target applications.
C1 [Golnari, Pareesa Ameneh; Malik, Sharad] Princeton Univ, Princeton, NJ 08544 USA.
RP Golnari, PA (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.
EM amene@princeton.edu; sharad@princeton.edu
CR [Anonymous], 1994, TECHNICAL REPORT
   [Anonymous], 2003, CITESEERX
   Borkar S, 2005, IEEE MICRO, V25, P10, DOI 10.1109/MM.2005.110
   Cota E. G., 2015, DAC
   Golnari A., 2015, ICCAD
   Hugues M. R., 2010, HPCC
   Lee K.-H., 2013, SIPS
   Salakhutdinov R., 2007, ICML
   Thomas S., 2014, IISWC
   Yetim Y., 2013, DATE
NR 10
TC 1
Z9 1
U1 0
U2 1
PY 2017
BP 1659
EP 1662
UT WOS:000404171500312
DA 2023-11-16
ER

PT J
AU Gandhi, J
   Shekhawat, D
   Santosh, M
   Pandey, JG
AF Gandhi, Jugal
   Shekhawat, Diksha
   Santosh, M.
   Pandey, Jai Gopal
TI Logic locking for IP security: A comprehensive analysis on challenges,
   techniques, and trends
SO COMPUTERS & SECURITY
DT Article
DE IP piracy and IP security; Logic locking; Logic obfuscation;
   Boolean-SATisfiability (SAT) attack; Machine learning-based attacks;
   Graph neural network (GNN)
ID HARDWARE ACCELERATORS; INTEGRATED-CIRCUITS; SUPPLY-CHAIN; LOW-COST;
   OBFUSCATION; ATTACK; SCAN; FUNCTIONALITY; METHODOLOGY; PARADIGM
AB A substantial part of the Integrated Circuit (IC) supply chain that involves semiconductor fabrication, packaging, and testing has shifted globally to minimize IC costs and satisfy market needs. This globalized supply chain and the presence of non-trusted entities have raised concerns about security issues. The fabless business model has resulted in numerous vulnerabilities. Logic Locking (LL) has emerged as a potential/versatile technique utilized by industries/academia. LL protects IPs integrated with System-onChip (SoC) designs from hardware threats throughout the IC supply chain. The applicability, feasibility, and effectiveness of LL have been investigated for more than a decade. The research interests involve metrics that evaluate the consequences of locking at multiple levels of abstraction, tampering, threat model description, machine learning implementation, and resiliency against physical attacks. However, complex logical and physical vulnerabilities that increase in effectiveness simultaneously as LL prevention/mitigation solutions have challenged the trustworthiness and resilience of modern LL solutions. We have classified known defenses and vulnerabilities by explaining measurements and fundamentals of LL, assumptions, limitations, and emerging technologies that highlight needs and guide future research. This survey paper aims to enable IP owners, SoC engineers, and researchers to explore and determine stateof-the-art logic locking techniques for further evaluation and research.(c) 2023 Elsevier Ltd. All rights reserved.
C1 [Gandhi, Jugal; Shekhawat, Diksha; Santosh, M.; Pandey, Jai Gopal] Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
   [Gandhi, Jugal; Shekhawat, Diksha; Santosh, M.; Pandey, Jai Gopal] CSIR, Cent Elect Engn Res Inst CEERI, Pilani 333031, Rajasthan, India.
RP Gandhi, J (corresponding author), Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.; Gandhi, J (corresponding author), CSIR, Cent Elect Engn Res Inst CEERI, Pilani 333031, Rajasthan, India.
EM jugalacsir@ceeri.res.in; jai@ceeri.res.in
CR Alam M, 2019, PR GR LAK SYMP VLSI, P105, DOI 10.1145/3299874.3318001
   Alaql A, 2022, IEEE T COMPUT AID D, V41, P854, DOI 10.1109/TCAD.2021.3075939
   Alaql A, 2021, IEEE T VLSI SYST, V29, P1529, DOI 10.1109/TVLSI.2021.3089555
   Alaql A, 2021, IEEE T INF FOREN SEC, V16, P3724, DOI 10.1109/TIFS.2021.3092135
   Alaql A, 2019, PROCEEDINGS OF THE 2019 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM (ASIANHOST)
   Alkabani YM, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 16TH USENIX SECURITY SYMPOSIUM, P291
   Alrahis L., 2019, ARXIV
   Alrahis L., 2021, ARXIV
   Alrahis L, 2021, Arxiv, DOI arXiv:2111.07062
   Alrahis L, 2022, IEEE T EMERG TOP COM, V10, P1575, DOI 10.1109/TETC.2021.3108487
   Alrahis L, 2022, IEEE T CIRCUITS-II, V69, P1602, DOI 10.1109/TCSII.2021.3113035
   Alrahis L, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P780, DOI 10.23919/DATE51398.2021.9474039
   Alrahis L, 2021, IEEE T INF FOREN SEC, V16, P2508, DOI 10.1109/TIFS.2021.3057576
   Amirov SF, 2020, 2020 INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING, APPLICATIONS AND MANUFACTURING (ICIEAM), DOI 10.1109/icieam48468.2020.9112045
   [Anonymous], 2013, P 8 ANN CYBER SECURI, DOI DOI 10.1145/2459976.2459985
   [Anonymous], 2015, AUTOMOTIVE NEWS
   [Anonymous], 2019, MAXIM INTEGRATED
   [Anonymous], 2012, INFORM TECHNOLOGY SE
   [Anonymous], 2014, NXP SMARTMXTM HIGH S
   [Anonymous], 1971, 12 ANN S SWITCH AUT, DOI DOI 10.1109/SWAT.1971.10
   Apple Secure Enclave (SEP), US
   Azar K., 2018, P IACR T CRYPT HARDW, V1, P97
   Baumgarten A, 2010, IEEE DES TEST COMPUT, V27, P66, DOI 10.1109/MDT.2010.24
   Bhandari J, 2021, Arxiv, DOI arXiv:2111.04222
   Bhandari J, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643548
   Bhunia S., 2018, HARDWARE SECURITY HA
   Bossuet L., 2017, FDN HARDWARE IP PROT
   Caldwell AE, 2004, IEEE T COMPUT AID D, V23, P208, DOI 10.1109/TCAD.2003.822126
   Chakraborty A, 2020, IEEE T COMPUT AID D, V39, P1952, DOI 10.1109/TCAD.2019.2944586
   Chakraborty A, 2018, DES AUT CON, DOI 10.1145/3195970.3196058
   Chakraborty P, 2018, PROCEEDINGS OF THE 2018 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM (ASIANHOST), P56, DOI 10.1109/AsianHOST.2018.8607163
   Chakraborty RS, 2009, IEEE T COMPUT AID D, V28, P1493, DOI 10.1109/TCAD.2009.2028166
   Chakravarty P, 2019, IDEA OF THE UNIVERSITY: HISTORIES AND CONTEXTS, P181, DOI 10.1109/HST.2019.8741028
   Chaudhuri P.P., 1997, ADDITIVE CELLULAR AU, V43
   Chen HL, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942134
   Chiang HY, 2020, IEEE T COMPUT AID D, V39, P2178, DOI 10.1109/TCAD.2019.2960351
   Colombier Brice, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P98, DOI 10.1109/ISVLSI.2017.26
   Colombier B, 2014, IET COMPUT DIGIT TEC, V8, P274, DOI 10.1049/iet-cdt.2014.0028
   Corno F, 2000, IEEE DES TEST COMPUT, V17, P44, DOI 10.1109/54.867894
   Critical Program Information (CPI), ID PROT RES DEV TEST
   Daniel B., 2020, COUNTERFEIT ELECT PA
   Darjani Armin, 2022, GLSVLSI '22: Proceedings of the Great Lakes Symposium on VLSI 2022, P147, DOI 10.1145/3526241.3530371
   Dey S., 2022, SECURE PHYS DESIGN
   Diaz-Rizo A.R., 2022, IEEE T CIRCUITS-I
   Dofe J, 2018, IEEE T COMPUT AID D, V37, P273, DOI 10.1109/TCAD.2017.2697960
   Dupuis S, 2019, J ELECTRON TEST, V35, P273, DOI 10.1007/s10836-019-05800-4
   Dupuis S, 2014, IEEE INT ON LINE, P49, DOI 10.1109/IOLTS.2014.6873671
   Duvalsaint D, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000130
   Duvalsaint D, 2019, 2019 IEEE INTERNATIONAL TEST CONFERENCE IN ASIA (ITC-ASIA 2019), P97, DOI 10.1109/ITC-Asia.2019.00030
   Editorial, 2016, TOP 10 FABLESS IC DE
   EETimes, 2012, IHS COUNTERFEIT PART
   El Massad M, 2017, Arxiv, DOI arXiv:1703.10187
   El Massad M, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23218
   El Massad M, 2017, ICCAD-IEEE ACM INT, P33, DOI 10.1109/ICCAD.2017.8203757
   Elshamy M, 2021, IEEE T VLSI SYST, V29, P2130, DOI 10.1109/TVLSI.2021.3117584
   Elsharief S., 2022, 20221752 CRYPT EPRIN
   False, 2019, DS3660 DEEPCOVER SEC
   Felton D., 2021, WHAT IS ARM TRUSTZON
   Fyrbiak Marc, 2018, IACR T CRYPTOGR HARD, V2018, P293
   Gdi T., 2020, DARPA SELECTS TEAMS
   Gilmer J, 2017, Arxiv, DOI [arXiv:1704.01212, DOI 10.48550/ARXIV.1704.01212]
   Guin U, 2018, IEEE T VLSI SYST, V26, P818, DOI 10.1109/TVLSI.2018.2797019
   Guin U, 2014, J ELECTRON TEST, V30, P9, DOI 10.1007/s10836-013-5430-8
   Han ZK, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1055
   hensoldt- cyber, MIG V HENSOLDT CYBER
   Hu B, 2019, PR GR LAK SYMP VLSI, P171, DOI 10.1145/3299874.3317992
   Hu YH, 2021, Arxiv, DOI arXiv:2108.04892
   intel, INTEL TRUSTED EXECUT
   intel, ANTITAMPER CAPABILIT
   iwls, IWLS 20 05 BENCHMARK
   Jain A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL CONFERENCE ON PHYSICAL ASSURANCE AND INSPECTION ON ELECTRONICS (PAINE), DOI 10.1109/PAINE49178.2020.9337734
   Jayasankaran NG, 2022, IEEE T EMERG TOP COM, V10, P386, DOI 10.1109/TETC.2020.3025561
   Kahng AB, 1998, 1998 DESIGN AUTOMATION CONFERENCE, PROCEEDINGS, P776, DOI 10.1109/DAC.1998.724576
   Kahng AB, 1998, 1998 DESIGN AUTOMATION CONFERENCE, PROCEEDINGS, P782, DOI 10.1109/DAC.1998.724577
   Kamali H. M., 2020, P 2020 GREAT LAK S V, DOI DOI 10.1145/3386263.3407655
   Kamali H. M., 2022, ADV LOGIC LOCKING PR
   Kamali HM, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415667
   Kamali HM, 2018, IEEE COMP SOC ANN, P405, DOI 10.1109/ISVLSI.2018.00080
   Karfa C, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P32, DOI 10.23919/DATE51398.2021.9473927
   Karmakar R, 2018, Arxiv, DOI [arXiv:1801.04961, 10.48550/arXiv.1801.04961]
   Karmakar R, 2021, IEEE T EMERG TOP COM, V9, P2109, DOI 10.1109/TETC.2019.2963094
   Karmakar R, 2020, DES AUT TEST EUROPE, P448, DOI 10.23919/DATE48585.2020.9116259
   Karmakar R, 2017, I CONF VLSI DESIGN, P429, DOI 10.1109/VLSID.2017.29
   Karousos N, 2017, IEEE INT ON LINE, P221, DOI 10.1109/IOLTS.2017.8046226
   Karri R, 2010, COMPUTER, V43, P39, DOI 10.1109/MC.2010.299
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Keshavarz S., 2018, J HARDWARE SYSTEMS S, V2, P214
   Kirk J., 2013, 3 INDICTED ALLEGED S
   Kirovski D, 2003, IEEE T COMPUT AID D, V22, P1277, DOI 10.1109/TCAD.2003.816208
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Koushanfar F, 2001, DES AUT CON, P490, DOI 10.1109/DAC.2001.935558
   Koushanfar F., 2017, HARDWARE PROTECTION, P161, DOI DOI 10.1007/978-3-319-49019-9_7
   Koushanfar F, 2012, IEEE T INF FOREN SEC, V7, P51, DOI 10.1109/TIFS.2011.2163307
   Hamilton WL, 2018, Arxiv, DOI [arXiv:1706.02216, DOI 10.48550/ARXIV.1706.02216]
   Lee J, 2005, INT SYM DEFEC FAU TO, P51
   Lee J, 2007, IEEE T DEPEND SECURE, V4, P325, DOI 10.1109/TDSC.2007.70215
   Lee J, 2006, IEEE VLSI TEST SYMP, P94, DOI 10.1109/VTS.2006.7
   Leonhard J, 2021, IEEE T COMPUT AID D
   Leonhard J, 2019, DES AUT TEST EUROPE, P84, DOI [10.23919/date.2019.8715043, 10.23919/DATE.2019.8715043]
   Li L, 2022, DES AUT TEST EUROPE, P1323, DOI 10.23919/DATE54114.2022.9774729
   Li L, 2021, 2021 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P292, DOI 10.1109/HOST49136.2021.9702288
   Li L, 2019, DES AUT TEST EUROPE, P540, DOI [10.23919/date.2019.8714955, 10.23919/DATE.2019.8714955]
   Li M, 2019, IEEE T COMPUT AID D, V38, P1399, DOI 10.1109/TCAD.2017.2750088
   Limaye N, 2021, DES AUT CON, P91, DOI 10.1109/DAC18074.2021.9586314
   Limaye N, 2022, IEEE T INF FOREN SEC, V17, P744, DOI 10.1109/TIFS.2022.3149147
   Limaye N, 2021, IEEE T COMPUT AID D, V40, P1740, DOI 10.1109/TCAD.2020.3029133
   Limaye N, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942047
   Limaye N, 2020, DES AUT TEST EUROPE, P270, DOI 10.23919/DATE48585.2020.9116197
   Lipp M, 2018, Arxiv, DOI arXiv:1801.01207
   Liu B, 2016, INTEGRATION, V55, P438, DOI 10.1016/j.vlsi.2016.03.002
   Liu YT, 2020, INT SYM QUAL ELECT, P199, DOI [10.1109/ISQED48828.2020.9136983, 10.1109/isqed48828.2020.9136983]
   Mankali L, 2023, IEEE T INF FOREN SEC, V18, P304, DOI 10.1109/TIFS.2022.3218429
   maximintegrated, DEEPCOVER SECURITY M
   McMillan KL, 2003, LECT NOTES COMPUT SC, V2725, P1
   Meade T, 2017, IEEE INT SYMP CIRC S
   Mellor J, 2021, 2021 IEEE VIRTUAL IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGIES FOR HOMELAND SECURITY, DOI 10.1109/HST53381.2021.9619800
   Miller B. L., 1995, Complex Systems, V9, P193
   Mishra P., 2017, HARDWARE IP SECURITY, DOI 10.1007/978-3-319-49025-0
   Mohan P, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1186, DOI 10.23919/DATE51398.2021.9473910
   Mutschler A. S., 2008, SEMI SEMIEQUIPMENT I
   Muttaki MR, 2021, DES AUT CON, P79, DOI 10.1109/DAC18074.2021.9586159
   Nguyen QL, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11233906
   Ojo B., 2013, XILINX SUES FLEXTRON
   Patnaik S, 2022, IEEE T INF FOREN SEC, V17, P3290, DOI 10.1109/TIFS.2022.3207361
   Patnaik S, 2020, IEEE T COMPUT AID D, V39, P4466, DOI 10.1109/TCAD.2020.2981034
   Perez TD, 2020, IEEE ACCESS, V8, P184013, DOI 10.1109/ACCESS.2020.3029339
   Pilato C, 2021, Arxiv, DOI arXiv:2010.05344
   Pilato C, 2018, DES AUT CON, DOI 10.1145/3195970.3196126
   Pilato C, 2018, IEEE EMBED SYST LETT, V10, P77, DOI 10.1109/LES.2017.2774800
   Plaza SM, 2015, IEEE T COMPUT AID D, V34, P961, DOI 10.1109/TCAD.2015.2404876
   pld, INDEX MAKSIMBENCHMAR
   Potluri S., 2020, CORRARXIV, V2005, P13032
   Press R., 2021, HARDWARE ROOT TRUST
   qualcomm, QUALCOMM SECURITY MO
   Rahman MS, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P775, DOI 10.1145/3489517.3530542
   Rahman MS, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3444960
   Rajendran J., 2013, P 2013 ACM SIGSAC C, P709, DOI DOI 10.1145/2508859.2516656
   Rajendran J, 2015, IEEE T COMPUT, V64, P410, DOI 10.1109/TC.2013.193
   Rajendran J, 2014, P IEEE, V102, P1266, DOI 10.1109/JPROC.2014.2332154
   Rajendran J, 2012, DES AUT CON, P83
   Rajendran R, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS (ITST), P1, DOI 10.1109/ITST.2013.6685512
   Rambus, 2020, CRYPTOMANAGER PROVIS
   Rezaei A, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P358, DOI 10.1145/3287624.3287691
   Rezaei A, 2018, DES AUT TEST EUROPE, P85, DOI 10.23919/DATE.2018.8341984
   Rizo A.R.D., 2022, IEEE T CIRCUITS-II
   Roshanisefat S., 2021, RANE OPEN SOURCE FOR, P221
   Roshanisefat S., 2020, IEEE VLSI TEST SYMP, p2002.07857
   Roshanisefat Shervin, 2018, Arxiv, DOI arXiv:1804.09162
   Roshanisefat S, 2020, IEEE T VLSI SYST, V28, P954, DOI 10.1109/TVLSI.2020.2968552
   Rostami M, 2014, P IEEE, V102, P1283, DOI 10.1109/JPROC.2014.2335155
   Roy JA, 2008, DES AUT TEST EUROPE, P948
   Saha A, 2021, IEEE T COMPUT AID D, V40, P2445, DOI 10.1109/TCAD.2021.3050035
   Salmani H, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P471, DOI 10.1109/ICCD.2013.6657085
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Selsam D, 2019, Arxiv, DOI arXiv:1802.03685
   Sengupta A., 2021, IACR T CRYPTOGRAPHIC, P418, DOI DOI 10.46586/TCHES.V2021.I3.418-440
   Sengupta A, 2020, IEEE T COMPUT AID D, V39, P4439, DOI 10.1109/TCAD.2020.2968898
   Sengupta A, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243467
   Sengupta A, 2018, IEEE VLSI TEST SYMP
   Shakya B., 2017, J HARDWARE SYSTEMS S, DOI DOI 10.1007/S41635-017-0001-6
   Shakya B., 2017, HARDWARE PROTECTION, P3
   Shakya Bicky, 2019, IACR T CRYPTOGRAPHIC, V1, P175
   Shamsi K, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942049
   Shamsi K, 2018, PR GR LAK SYMP VLSI, P147, DOI 10.1145/3194554.3194580
   Shamsi K, 2019, DES AUT TEST EUROPE, P534, DOI [10.23919/DATE.2019.8715053, 10.23919/date.2019.8715053]
   Shamsi K, 2019, IEEE T INF FOREN SEC, V14, P347, DOI 10.1109/TIFS.2018.2850319
   Shamsi K, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P173, DOI 10.1145/3060403.3060458
   Shamsi K, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P95, DOI 10.1109/HST.2017.7951805
   Shen YQ, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P657, DOI 10.1145/3287624.3287670
   Shen YQ, 2018, DES AUT TEST EUROPE, P629, DOI 10.23919/DATE.2018.8342086
   Shen YQ, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P179, DOI 10.1145/3060403.3060469
   Sherstinsky A, 2021, Arxiv, DOI [arXiv:1808.03314, 10.1016/j.physd.2019.132306]
   Shihab MM, 2019, DES AUT TEST EUROPE, P528, DOI [10.23919/date.2019.8714856, 10.23919/DATE.2019.8714856]
   Sisejkovic D., 2021, ARXIV
   Sisejkovic D., 2022, DESIGNING TRUSTWORTH
   Sisejkovic D, 2022, Arxiv, DOI arXiv:2203.05399
   Sisejkovic D, 2021, Arxiv, DOI arXiv:2107.08695
   Sisejkovic D, 2020, Arxiv, DOI arXiv:2011.10389
   Sisejkovic D, 2021, IEEE INT CONF VLSI, P180, DOI 10.1109/VLSI-SoC53125.2021.9606998
   Sisejkovic D, 2018, 2018 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION (SAMOS XVIII), P179, DOI 10.1145/3229631.3229636
   Skudlarek JP, 2016, COMPUTER, V49, P28, DOI 10.1109/MC.2016.243
   Sorensson N., 2005, INT C THEOR APPL SAT
   Staff R., 2016, EPIC SYSTEMS WINS 94
   STM32Trust, US
   Subramanyan P, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P137, DOI 10.1109/HST.2015.7140252
   Sweeney J., 2020, P 2020 IEEE INT S HA, V2005, P10649
   synopsys, SECURITY IP CRYPTOGR
   Technologies Ag I., OPTIGA TRUST X SLS 3
   Tehranipoor F, 2019, PR GR LAK SYMP VLSI, P335, DOI 10.1145/3299874.3318031
   Tehranipoor M, 2012, INTRODUCTION TO HARDWARE SECURITY AND TRUST, P1, DOI 10.1007/978-1-4419-8080-9
   Torrance R, 2011, DES AUT CON, P333
   Tuyls P, 2006, LECT NOTES COMPUT SC, V4249, P369
   Vaidyanathan K, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE-ORIENTED SECURITY AND TRUST (HOST), P1, DOI 10.1109/HST.2014.6855559
   Veli ckovi c P., 2018, GRAPH ATTENTION NETW, V1710, P10903
   Wang XX, 2018, IEEE T COMPUT AID D, V37, P1867, DOI 10.1109/TCAD.2017.2772817
   Weste N.H., 2015, CMOS VLSI DESIGN CIR
   Xie Y, 2019, IEEE T COMPUT AID D, V38, P199, DOI 10.1109/TCAD.2018.2801220
   Xie Y, 2017, DES AUT CON, DOI 10.1145/3061639.3062226
   Xu XL, 2017, LECT NOTES COMPUT SC, V10529, P189, DOI 10.1007/978-3-319-66787-4_10
   Yang FF, 2019, IEEE T INF FOREN SEC, V14, P2778, DOI 10.1109/TIFS.2019.2904838
   Yang S., 1991, LOGIC SYNTHESIS OPTI
   Yang XM, 2022, IEEE T COMPUT AID D, V41, P29, DOI 10.1109/TCAD.2021.3053912
   Yasin M., 2019, TRUSTWORTHY HARDWARE
   Yasin M, 2015, INT SYM DEFEC FAU TO, P97, DOI 10.1109/DFT.2015.7315143
   Yasin M, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942150
   Yasin M, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967012
   Yasin M, 2020, IEEE T EMERG TOP COM, V8, P517, DOI 10.1109/TETC.2017.2740364
   Yasin M, 2017, IEEE INT CONF VLSI, P237
   Yasin M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1601, DOI 10.1145/3133956.3133985
   Yasin M, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P166, DOI 10.1109/HST.2017.7951830
   Yasin M, 2017, ASIA S PACIF DES AUT, P342, DOI 10.1109/ASPDAC.2017.7858346
   Yasin M, 2016, IEEE T COMPUT AID D, V35, P1411, DOI 10.1109/TCAD.2015.2511144
   Yasin M, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P236, DOI 10.1109/HST.2016.7495588
   Yiqiong Shi, 2012, 2012 International Symposium on Communications and Information Technologies (ISCIT), P538, DOI 10.1109/ISCIT.2012.6380958
   Zaman M, 2018, DES AUT TEST EUROPE, P1592, DOI 10.23919/DATE.2018.8342269
   Zamiri Azar Kimia, 2020, Arxiv, DOI arXiv:2009.02208
   Azar KZ, 2021, IEEE T VLSI SYST, V29, P643, DOI 10.1109/TVLSI.2021.3060345
   Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114
   Zeng HQ, 2020, Arxiv, DOI arXiv:1907.04931
   Zhang DR, 2017, IEEE VLSI TEST SYMP
   Zhang GL, 2018, DES AUT TEST EUROPE, P91, DOI 10.23919/DATE.2018.8341985
   Zhang JN, 2018, Arxiv, DOI arXiv:1803.07294
   Zhang MH, 2018, Arxiv, DOI arXiv:1802.09691
   Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438
   Zhang YQ, 2019, PROCEEDINGS OF THE 3RD ACM WORKSHOP ON ATTACKS AND SOLUTIONS IN HARDWARE SECURITY WORKSHOP (ASHES '19), P75, DOI 10.1145/3338508.3359576
   Zhou H, 2017, ICCAD-IEEE ACM INT, P49, DOI 10.1109/ICCAD.2017.8203759
   Zhou JB, 2021, Arxiv, DOI arXiv:1910.12142
NR 227
TC 0
Z9 0
U1 3
U2 3
PD JUN
PY 2023
VL 129
AR 103196
DI 10.1016/j.cose.2023.103196
EA APR 2023
UT WOS:000979658200001
DA 2023-11-16
ER

PT C
AU Dhakal, A
   Kulkarni, SG
   Ramakrishnan, KK
AF Dhakal, Aditya
   Kulkarni, Sameer G.
   Ramakrishnan, K. K.
GP IEEE Comp Soc
TI Machine Learning at the Edge: Efficient Utilization of Limited CPU/GPU
   Resources by Multiplexing
SO 2020 IEEE 28TH INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS (IEEE ICNP
   2020)
SE IEEE International Conference on Network Protocols Proceedings
DT Proceedings Paper
CT 28th IEEE International Conference on Network Protocols (IEEE ICNP)
CY OCT 13-16, 2020
CL ELECTR NETWORK
DE GPU; Machine Learning; Deep Neural Networks; Inference
AB Edge clouds can provide very responsive services for end-user devices that require more significant compute capabilities than they have. But edge cloud resources such as CPUs and accelerators such as GPUs are limited and must be shared across multiple concurrently running clients. However, multiplexing GPUs across applications is challenging. Further, edge servers are likely to require considerable amounts of streaming data to be processed. Getting that data from the network stream to the GPU can be a bottleneck, limiting the amount of work GPUs do. Finally, the lack of prompt notification of job completion from GPU also results in ineffective GPU utilization. We propose a framework that addresses these challenges in the following manner. We utilize spatial sharing of GPUs to multiplex the GPU more efficiently. While spatial sharing of GPU can increase GPU utilization, the uncontrolled spatial sharing currently available with state-of-the-art systems such as CUDA-MPS can cause interference between applications, resulting in unpredictable latency. Our framework utilizes controlled spatial sharing of GPU, which limits the interference across applications. Our framework uses the GPU DMA engine to offload data transfer to GPU, therefore preventing CPU from being bottleneck while transferring data from the network to GPU. Our framework uses the CUDA event library to have timely, low overhead GPU notifications. Preliminary experiments show that we can achieve low DNN inference latency and improve DNN inference throughput by a factor of similar to 1.4.
C1 [Dhakal, Aditya; Ramakrishnan, K. K.] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Kulkarni, Sameer G.] Indian Inst Technol, Gandhinagar, Gujarat, India.
RP Dhakal, A (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM adhak001@ucr.edu; sameergk@iitgn.ac.in; kk@cs.ucr.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2020, NVIDIA HYPER Q
   [Anonymous], 2020, TORCHSERVE
   [Anonymous], 2017, 2017 IEEE INT S LOCA
   [Anonymous], 2018, USENIX WORKSH HOT TO
   [Anonymous], 2011, NVIDIA UNIVERSAL VIR
   [Anonymous], BIGLEARN NIPS WORKSH
   Chang H, 2014, IEEE CONF COMPUT, P346, DOI 10.1109/INFCOMW.2014.6849256
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Dhakal A, 2019, PROCEEDINGS OF THE 2019 IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2019), P396, DOI [10.1109/NETSOFT.2019.8806698, 10.1109/netsoft.2019.8806698]
   Liu LD, 2019, IEEE INT SYM BROADB, DOI [10.1109/bmsb47279.2019.8971843, 10.1145/3326285.3329055]
   NVIDIA Corporation, 2019, TENS DEV GUID
   NVIDIA Tesla., 2019, NVIDIA, P108
   Ran XK, 2018, IEEE INFOCOM SER, P1421, DOI 10.1109/INFOCOM.2018.8485905
   Redmon J., 2013, DARKNET OPEN SOURCE
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Suo J, 2016, 2016 21ST OPTOELECTRONICS AND COMMUNICATIONS CONFERENCE (OECC) HELD JOINTLY WITH 2016 INTERNATIONAL CONFERENCE ON PHOTONICS IN SWITCHING (PS)
   Wang SQ, 2020, IEEE T COMPUT AID D, V39, P2254, DOI 10.1109/TCAD.2019.2944584
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
NR 20
TC 4
Z9 4
U1 0
U2 0
PY 2020
DI 10.1109/icnp49622.2020.9259361
UT WOS:000646028000013
DA 2023-11-16
ER

PT J
AU Xing, Y
   Liang, S
   Sui, LZ
   Jia, XJ
   Qiu, JT
   Liu, X
   Wang, YS
   Shan, Y
   Wang, Y
AF Xing, Yu
   Liang, Shuang
   Sui, Lingzhi
   Jia, Xijie
   Qiu, Jiantao
   Liu, Xin
   Wang, Yushun
   Shan, Yi
   Wang, Yu
TI DNNVM: End-to-End Compiler Leveraging Heterogeneous Optimizations on
   FPGA-Based CNN Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Hardware; Optimization; Layout; Field programmable gate arrays;
   Throughput; Computer architecture; Deep learning; Compiler;
   convolutional neural network (CNN); field-programmable gate array
   (FPGA); fusion; optimizations
ID SUBGRAPH ISOMORPHISM; ALGORITHM
AB The convolutional neural network (CNN) has become a state-of-the-art method for several artificial intelligence domains in recent years. The increasingly complex CNN models are both computation-bound and I/O-bound. Field-programmable gate array-based accelerators driven by custom instruction set architecture (ISA) achieve a balance between generality and efficiency, but there is much on them left to be optimized. We propose the full-stack compiler deep neural network virtual machine (DNNVM), which is an integration of optimizers for graphs, loops and data layouts, an assembler, a runtime supporter, and a validation environment. The DNNVM works in the context of deep learning frameworks and transforms CNN models into the directed acyclic graph: XGraph. Based on XGraph, we transform the optimization challenges for both data layout and pipeline into graph-level problems. DNNVM enumerates all potentially profitable fusion opportunities by a heuristic subgraph isomorphism algorithm to leverage pipeline and data layout optimizations, and searches for the best choice of execution strategies of the whole computing graph. On the Xilinx ZU2@330 MHz and ZU9@330 MHz, we achieve equivalently state-of-the-art performance on our benchmarks by naive implementations without optimizations, and the throughput is further improved up to 1.26x by leveraging heterogeneous optimizations in DNNVM. Finally, with ZU9@330 MHz, we achieve state-of-the-art performance for VGG and ResNet50. We achieve a throughput of 2.82 TOPs/s and an energy efficiency of 123.7 GOPs/s/W for VGG. Additionally, we achieve 1.38 TOPs/s for ResNet50 and 1.41 TOPs/s for GoogleNet.
C1 [Xing, Yu; Sui, Lingzhi; Jia, Xijie; Liu, Xin; Wang, Yushun; Shan, Yi] Xilinx Inc, Dept Architecture, Beijing 100083, Peoples R China.
   [Xing, Yu; Liang, Shuang; Qiu, Jiantao; Wang, Yu] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Xing, Yu; Liang, Shuang; Qiu, Jiantao; Wang, Yu] Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM yuxing@xilinx.com; yu-wang@tsinghua.edu.cn
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2018, CORR
   [Anonymous], 2017, INCREMENTAL NETWORK
   [Anonymous], 2018, ABS180204730 CORR
   [Anonymous], CORR
   Chang A. X., 2017, CORR
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75
   De Chen, 2019, International Journal of Pavement Engineering, V20, P557, DOI 10.1080/10298436.2017.1316644
   Fu V. Y., 2017, WP490 XIL
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ABS170404861 CORR
   Jangda A, 2018, ACM SIGPLAN NOTICES, V53, P261, DOI 10.1145/3200691.3178507
   Jia Y., 2019, CAFFE
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lee J, 2012, PROC VLDB ENDOW, V6, P133, DOI 10.14778/2535568.2448946
   Liu YZ, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1025
   Moreau T., 2018, CORR
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI [10.1145/2694344.2694364, 10.1145/2775054.2694364]
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J., ARXIV
   Redmon J., 2019, DARKNET
   Ren XG, 2015, PROC VLDB ENDOW, V8, P617, DOI 10.14778/2735479.2735493
   Sharma H, 2016, INT SYMP MICROARCH
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tidwell R. P., 2005, XAPP706 XIL
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wei R., 2018, INT C LEARN REPR
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhao RZ, 2018, I C FIELD PROG LOGIC, P147, DOI 10.1109/FPL.2018.00033
NR 41
TC 41
Z9 42
U1 1
U2 29
PD OCT
PY 2020
VL 39
IS 10
BP 2668
EP 2681
DI 10.1109/TCAD.2019.2930577
UT WOS:000572636400055
DA 2023-11-16
ER

PT J
AU Gao, MX
   Chen, H
   Liu, DK
AF Gao, Muxuan
   Chen, He
   Liu, Dake
TI An ASIP for Neural Network Inference on Embedded Devices with 99% PE
   Utilization and 100% Memory Hidden under Low Silicon Cost
SO SENSORS
DT Article
DE deep neural networks; machine learning; deep learning processor;
   scheduling framework; instruction set architecture (ISA)
ID ACCELERATOR; PROCESSOR
AB The computation efficiency and flexibility of the accelerator hinder deep neural network (DNN) implementation in embedded applications. Although there are many publications on deep neural network (DNN) processors, there is still much room for deep optimization to further improve results. Multiple dimensions must be simultaneously considered when designing a DNN processor to reach the performance limit of the architecture, including architecture decision, flexibility, energy efficiency, and silicon cost minimization. Flexibility is defined as the ability to support as many multiple networks as possible and to easily adjust the scale. For energy efficiency, there are huge opportunities for power efficiency optimization, which involves access minimization and memory latency minimization based on on-chip memory minimization. Therefore, this work focused on low-power and low-latency data access with minimized silicon cost. This research was implemented based on an ASIP (application specific instruction set processor) in which an ISA was based on the caffe2 inference operator and the hardware design was based on a single instruction multiple data (SIMD) architecture. The scalability and system performance of our SoC extension scheme were demonstrated. The VLIW was used to execute multiple instructions in parallel. All costs for data access time were thus eliminated for the convolution layer. Finally, the processor was synthesized based on TSMC 65 nm technology with a 200 MHz clock, and the Soc extension scheme was analyzed in an experimental model. Our design was tested on several typical neural networks, achieving 196 GOPS at 200 MHz and 241 GOPS/W on the VGG16Net and AlexNet.
C1 [Gao, Muxuan; Chen, He; Liu, Dake] Beijing Inst Technol, Sch Informat & Elect, Beijing 100811, Peoples R China.
RP Chen, H (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100811, Peoples R China.
EM gao.muxuan@foxmail.com; chenhe@bit.edu.cn; dake@bit.edu.cn
CR Amdahl G. M., 1967, AFIPS CONF P, P483, DOI 10.1145/1465482.1465560
   Azimirad V, 2022, NEUROCOMPUTING, V490, P319, DOI 10.1016/j.neucom.2021.11.097
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chenarlogh VA, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066079
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Gao M., 2018, SCALABLE NEAR DATA P
   Ghani A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071148
   Gukeh MJ, 2021, ACS APPL MATER INTER, V13, P46171, DOI 10.1021/acsami.1c13262
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel P., 2016, ARXIV
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Horowitz M., ENERGY TABLE 45 NM P
   Huang BM, 2021, IEEE T CIRCUITS-I, V68, P4672, DOI 10.1109/TCSI.2021.3108762
   Ju Y., 2022, P 2022 IEEE INT SOLI, V65, P1
   Kadetotad D, 2020, IEEE J SOLID-ST CIRC, V55, P1877, DOI 10.1109/JSSC.2020.2992900
   Liu D, 2008, MORG KAUF SER SYST, P1
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Markham A., 2017, NVIDIA DEV BLOG
   Ouyang P, 2017, DES AUT CON, DOI 10.1145/3061639.3062187
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Roshani M, 2020, FLOW MEAS INSTRUM, V75, DOI 10.1016/j.flowmeasinst.2020.101804
   Shukla S, 2018, IEEE SOLID-ST CIRC L, V1, P217, DOI 10.1109/LSSC.2019.2902738
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tu FB, 2021, IEEE J SOLID-ST CIRC, V56, P658, DOI 10.1109/JSSC.2020.3021661
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
NR 26
TC 0
Z9 0
U1 4
U2 6
PD MAY
PY 2022
VL 22
IS 10
AR 3841
DI 10.3390/s22103841
UT WOS:000803544600001
DA 2023-11-16
ER

PT J
AU Hu, X
   Zhao, Y
   Deng, L
   Liang, L
   Zuo, PF
   Ye, J
   Lin, YY
   Xie, Y
AF Hu, Xing
   Zhao, Yang
   Deng, Lei
   Liang, Ling
   Zuo, Pengfei
   Ye, Jing
   Lin, Yingyan
   Xie, Yuan
TI Practical Attacks on Deep Neural Networks by Memory Trojaning
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Trojan horses; Hardware; Integrated circuit modeling; Computational
   modeling; Security; Payloads; Convolutional neural networks (CNNs); deep
   learning accelerator; deep learning attack; hardware Trojan
ID THREAT
AB Deep neural network (DNN) accelerators are widely deployed in computer vision, speech recognition, and machine translation applications, in which attacks on DNNs have become a growing concern. This article focuses on exploring the implications of hardware Trojan attacks on DNNs. Trojans are one of the most challenging threat models in hardware security where adversaries insert malicious modifications to the original integrated circuits (ICs), leading to malfunction once being triggered. Such attacks can be conducted by adversaries because modern ICs commonly include third-party intellectual property (IP) blocks. Previous studies design hardware Trojans to attack DNNs with the assumption that adversaries have full knowledge or manipulation of the DNN systems' victim model and toolchain in addition to the hardware platforms, yet such a threat model is strict, limiting their practical adoption. In this article, we propose a memory Trojan methodology that implants the malicious logics merely into the memory controllers of DNN systems without the necessity of toolchain manipulation or accessing to the victim model and thus is feasible for practical uses. Specifically, we locate the input image data among the massive volume of memory traffics based on memory access patterns and propose a Trojan trigger mechanism based on detecting the geometric feature in input images. Extensive experiments show that the proposed trigger mechanism is effective even in the presence of environmental noises and preprocessing operations. Furthermore, we design and implement the payload and verify that the proposed Trojan technique can effectively conduct both untargeted and targeted attacks on DNNs.
C1 [Hu, Xing; Ye, Jing] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Zhao, Yang; Lin, Yingyan] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
   [Deng, Lei; Liang, Ling; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Zuo, Pengfei] Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
RP Deng, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM huxing@ict.ac.cn; zhao.yang@rice.edu; leideng@ucsb.edu;
   lingliang@ucsb.edu; pfzuo@hust.edu.cn; yejing@ict.ac.cn;
   yingyan.lin@rice.edu; yuanxie@ucsb.edu
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Alfeld S, 2016, AAAI CONF ARTIF INTE, P1452
   Alwani M, 2016, INT SYMP MICROARCH
   Amodei D., 2016, ARXIV
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2016.2577031, DOI 10.1109/TPAMI.2016.2577031]
   [Anonymous], 2015, CHINA UNVEILS WORLDS
   [Anonymous], 2010, IMAGENET 1 CROP ERRO
   [Anonymous], ARXIV180605768
   [Anonymous], 2016, ARXIV161103814
   [Anonymous], 2018, GARTNER IDENTIFIES T
   [Anonymous], FRACTAL GEOMETRY MAT
   Ateniese G., 2013, ARXIV13064447
   Backes M., 2016, ADVERSARIAL PERTURBA
   Bhunia S, 2014, P IEEE, V102, P1229, DOI 10.1109/JPROC.2014.2334493
   Biggio B., 2013, JOINT EUROPEAN C MAC, P387, DOI DOI 10.1007/978-3-642-40994-3_25
   Brown Tom B, 2017, ARXIV171209665
   Carlini N., 2017, PROVABLY MINIMALLY D
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cisse Moustapha M., 2017, ARXIV170705373, P6977
   Deng L, 2020, IEEE T COMPUT AID D, V39, P117, DOI 10.1109/TCAD.2018.2883959
   Dong Y., 2017, CVPR
   Fredrikson M, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P17
   Goodfellow I., 2015, CORR ABS14126572
   Guo K, 2016, 2016 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2016.7936208
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, V1704, P4861
   Ji Y., 2019, PROGRAMMABLE NEURAL
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   King S. T., 2008, LEET 08, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V3, P6
   Kurakin Alexey, 2016, CORR
   LeCun Y., 1998, MNIST DATABASE HANDW
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Li WS, 2018, IEEE COMP SOC ANN, P482, DOI 10.1109/ISVLSI.2018.00093
   Liu T, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P227, DOI 10.1109/HST.2018.8383920
   Liu Xin, 2018, ARXIV180602299
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Liu YQ, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23291
   Mopuri Konda Reddy, 2017, PROC BRIT MACH VIS C
   Narodytska N., 2016, ARXIV PREPRINT ARXIV
   Nvidia Deep Learning Accelerator (NVDLA), 2017, NVIDIA
   Oh SJ, 2017, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2017.165
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Papernot Nicolas, 2016, CORR
   Putic M, 2018, DES AUT CON, DOI 10.1145/3195970.3196033
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S., 2015, ARXIV151105122
   Samajdar A., 2018, COMPUTING RES REPOSI
   Sarkar Sayantan, 2017, ARXIV170701159
   Shafahi Ali, 2018, NEURIPS
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srndic N, 2014, P IEEE S SECUR PRIV, P197, DOI 10.1109/SP.2014.20
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tehranipoor M, 2010, IEEE DES TEST COMPUT, V27, P10, DOI 10.1109/MDT.2010.7
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Wang BH, 2018, P IEEE S SECUR PRIV, P36, DOI 10.1109/SP.2018.00038
   Werner DH, 1999, IEEE ANTENNAS PROPAG, V41, P37, DOI 10.1109/74.801513
   Xi GH, 2019, TSINGHUA SCI TECHNOL, V24, P226, DOI 10.26599/TST.2018.9010114
   Xu WL, 2016, 23RD ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2016), DOI 10.14722/ndss.2016.23115
   Xue MF, 2019, IEEE ACCESS, V7, P5124, DOI 10.1109/ACCESS.2018.2887268
   Ye J, 2018, ASIAN TEST SYMPOSIUM, P68, DOI 10.1109/ATS.2018.00024
   Yu SC, 2019, IEEE COMP SOC ANN, P303, DOI 10.1109/ISVLSI.2019.00062
   Zhang WC, 2019, TSINGHUA SCI TECHNOL, V24, P360, DOI 10.26599/TST.2018.9010111
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 74
TC 11
Z9 11
U1 4
U2 11
PD JUN
PY 2021
VL 40
IS 6
BP 1230
EP 1243
DI 10.1109/TCAD.2020.2995347
UT WOS:000652792400018
DA 2023-11-16
ER

PT C
AU Herrmann, V
   Knapheide, J
   Steinert, F
   Stabernack, B
AF Herrmann, Viktor
   Knapheide, Justin
   Steinert, Fritjof
   Stabernack, Benno
BE Fabelo, H
   Ortega, S
   Skavhaug, A
TI A YOLO v3-tiny FPGA Architecture using a Reconfigurable Hardware
   Accelerator for Real-time Region of Interest Detection
SO 2022 25TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD)
SE EUROMICRO Conference Proceedings
DT Proceedings Paper
CT 25th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2022
CL Maspalomas, SPAIN
DE FPGA; Object Detection; Hardware; YOLO
AB With the recent advances in the fields of machine learning, neural networks and deep-learning algorithms have become a prevalent subject of computer vision. Especially for tasks like object classification and detection Convolutional Neuronal Networks (CNNs) have surpassed the previous traditional approaches. In addition to these applications, CNNs can recently also be found in other applications. For example the parametrization of video encoding algorithms as used in our example is quite a new application domain. Especially CNN's high recognition rate makes them particularly suitable for finding Regions of Interest (ROIs) in video sequences, which can be used for adapting the data rate of the compressed video stream accordingly.
   On the downside, these CNN require an immense amount of processing power and memory bandwidth. Object detection networks such as You Only Look Once (YOLO) try to balance processing speed and accuracy but still rely on power-hungry GPUs to meet real-time requirements. Specialized hardware like Field Programmable Gate Array (FPGA) implementations proved to strongly reduce this problem while still providing sufficient computational power. In this paper we propose a flexible architecture for object detection hardware acceleration based on the YOLO v3-tiny model. The reconfigurable accelerator comprises a high throughput convolution engine, custom blocks for all additional CNN operations and a programmable control unit to manage on-chip execution. The model can be deployed without significant changes based on 32-bit floating point values and without further methods that would reduce the model accuracy. Experimental results show a high capability of the design to accelerate the object detection task with a processing time of 27.5 ms per frame. It is thus real-time-capable for 30 FPS applications at frequency of 200 MHz.
C1 [Herrmann, Viktor; Knapheide, Justin; Steinert, Fritjof; Stabernack, Benno] Fraunhofer Inst Telecommun, Heinrich Hertz Inst, Berlin, Germany.
   [Knapheide, Justin; Steinert, Fritjof; Stabernack, Benno] Univ Potsdam, Embedded Syst Architectures Signal Proc, Potsdam, Germany.
RP Herrmann, V (corresponding author), Fraunhofer Inst Telecommun, Heinrich Hertz Inst, Berlin, Germany.
EM viktor.herrmann@hhi.fraunhofer.de; justin.knapheide@hhi.fraunhofer.de;
   fritjof.steinert@hhi-extern.fraunhofer.de;
   benno.stabernack@hhi.fraunhofer.de
CR Adiono T, 2021, IEEE ACCESS, V9, P141890, DOI 10.1109/ACCESS.2021.3120629
   [Anonymous], 2022, XIL VIT
   [Anonymous], 2018, YOLO REAL TIME OBJEC
   Bochkovskiy A., 2020, PREPRINT
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu B, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P241, DOI 10.1109/FPT.2018.00043
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Pestana D, 2021, IEEE ACCESS, V9, P75864, DOI 10.1109/ACCESS.2021.3081818
   Redmon J, 2016, Arxiv, DOI [arXiv:1612.08242, DOI 10.48550/ARXIV.1612.08242]
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shiguang Zhang, 2020, 2020 IEEE 3rd International Conference on Electronics Technology (ICET), P74, DOI 10.1109/ICET49382.2020.9119500
   Steinert F, 2022, J SIGNAL PROCESS SYS, V94, P693, DOI 10.1007/s11265-021-01727-2
   Steinert F, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P149, DOI 10.1109/DSD51259.2020.00033
   Wang ZX, 2020, IEEE ACCESS, V8, P116569, DOI 10.1109/ACCESS.2020.3004198
   Zhewen Yu, 2020, Applied Reconfigurable Computing Architectures, Tools, and Applications. 16th International Symposium, ARC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 120830), P330, DOI 10.1007/978-3-030-44534-8_25
NR 19
TC 0
Z9 0
U1 6
U2 8
PY 2022
BP 84
EP 92
DI 10.1109/DSD57027.2022.00021
UT WOS:000946536500104
DA 2023-11-16
ER

PT J
AU Basalama, S
   Sohrabizadeh, A
   Wang, J
   Guo, LC
   Cong, J
AF Basalama, Suhail
   Sohrabizadeh, Atefeh
   Wang, Jie
   Guo, Licheng
   Cong, Jason
TI FlexCNN: An End-to-end Framework for Composing CNN Accelerators on FPGA
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; CNN; ONNX; systolic array; transposed convolution; dilated
   convolution; OpenPose; U-Net; E-Net
AB With reduced data reuse and parallelism, recent convolutional neural networks (CNNs) create new challenges for FPGA acceleration. Systolic arrays (SAs) are efficient, scalable architectures for convolutional layers, but without proper optimizations, their efficiency drops dramatically for reasons: (1) the different dimensions within same-type layers, (2) the different convolution layers especially transposed and dilated convolutions, and (3) CNN's complex dataflow graph. Furthermore, significant overheads arise when integrating FPGAs into machine learning frameworks. Therefore, we present a flexible, composable architecture called FlexCNN, which delivers high computation efficiency by employing dynamic tiling, layer fusion, and data layout optimizations. Additionally, we implement a novel versatile SA to process normal, transposed, and dilated convolutions efficiently. FlexCNN also uses a fully pipelined software-hardware integration that alleviates the software overheads. Moreover, with an automated compilation flow, FlexCNN takes a CNN in the ONNX1 representation, performs a design space exploration, and generates an FPGA accelerator. The framework is tested using three complex CNNs: OpenPose, U-Net, and E-Net. The architecture optimizations achieve 2.3x performance improvement. Compared to a standard SA, the versatile SA achieves close-to-ideal speedups, with up to 15.98x and 13.42x for transposed and dilated convolutions, with a 6% average area overhead. The pipelined integration leads to a 5x speedup for OpenPose.
C1 [Basalama, Suhail; Sohrabizadeh, Atefeh; Wang, Jie; Guo, Licheng; Cong, Jason] Univ Calif Los Angeles, 404 Westwood Blvd Engn,6 Room 468, Los Angeles, CA 90095 USA.
RP Basalama, S (corresponding author), Univ Calif Los Angeles, 404 Westwood Blvd Engn,6 Room 468, Los Angeles, CA 90095 USA.
EM basalama@ucla.edu; atefehsz@cs.ucla.edu; jiewang@cs.ucla.edu;
   lcguo@cs.ucla.edu; cong@cs.ucla.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2018, P 5 INT WORKSHOP FPG
   Bai L, 2018, IEEE T CIRCUITS-II, V65, P1415, DOI 10.1109/TCSII.2018.2865896
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chang Tian-Sheuan, 2020, IEEE INT S CIRCUITS, P1
   Chen QY, 2020, IEEE T VLSI SYST, V28, P1540, DOI 10.1109/TVLSI.2020.2976454
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chen YT, 2016, ANN IEEE SYM FIELD P, P29, DOI 10.1109/FCCM.2016.18
   Chetlur S, 2014, Arxiv, DOI arXiv:1410.0759
   Chi YZ, 2021, ANN IEEE SYM FIELD P, P204, DOI [10.1109/FCCM51124.2021.00032, 10.1109/fccm51124.2021.00032]
   Chi YZ, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240850
   Cong Jason, 2018, 10 USENIX WORKSHOP H
   Cong Jason, 2018, IEEE ACM INT C COMPU, P1
   Deng HP, 2021, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM51124.2021.00029
   Di XK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020286
   docs.xilinx.com, U280 PERFORMANCE 14E
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   DPUCAHX8H Resource Utilization, US
   DPUCAHX8L Resource Utilization, US
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Ignatov A, 2019, LECT NOTES COMPUT SC, V11133, P288, DOI 10.1007/978-3-030-11021-5_19
   Im D, 2019, IEEE INT SYMP CIRC S
   Jinguji A, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P313, DOI 10.1109/FPT.2018.00061
   Kim Ildoo, 2018, TF POSE ESTIMATION
   Kim T, 2017, PR MACH LEARN RES, V70
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Licheng Guo, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P81, DOI 10.1145/3431920.3439289
   Liu SL, 2019, I C FIELD PROG LOGIC, P187, DOI 10.1109/FPL.2019.00037
   Liu SL, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242900
   Liu WJ, 2019, IEEE INT SYMP CIRC S
   Matthews AGD, 2017, J MACH LEARN RES, V18, P1
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Radford A, 2016, Arxiv, DOI arXiv:1511.06434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma H, 2016, INT SYMP MICROARCH
   Shen JZ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P97, DOI 10.1145/3174243.3174257
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Sifre Laurent, 2014, THESIS ECOLE NORMALE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabizadeh A, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P133, DOI 10.1145/3373087.3375321
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Tan WR, 2017, IEEE IMAGE PROC, P3760, DOI 10.1109/ICIP.2017.8296985
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Vitis AI, US
   Wei XC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240856
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Xilinx, 2019, VIVADO DESIGN SUITE
   Xing Y, 2020, IEEE T COMPUT AID D, V39, P2668, DOI 10.1109/TCAD.2019.2930577
   Yang X, 2020, Arxiv, DOI arXiv:1809.04070
   Yazdanbakhsh A, 2018, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2018.00019
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, 10.48550/arXiv.1511.07122]
   Yu YX, 2020, IEEE T VLSI SYST, V28, P1545, DOI 10.1109/TVLSI.2020.2995741
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang N, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030282
   Zhang XF, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415609
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 63
TC 1
Z9 1
U1 3
U2 3
PD JUN
PY 2023
VL 16
IS 2
AR 23
DI 10.1145/3570928
UT WOS:001020376000007
DA 2023-11-16
ER

PT C
AU Malik, M
   Rafatirah, S
   Sasan, A
   Homayoun, H
AF Malik, Maria
   Rafatirah, Setareh
   Sasan, Avesta
   Homayoun, Houman
BE Ho, H
   Ooi, BC
   Zaki, MJ
   Hu, XH
   Haas, L
   Kumar, V
   Rachuri, S
   Yu, SP
   Hsiao, MHI
   Li, J
   Luo, F
   Pyne, S
   Ogan, K
TI System and Architecture Level Characterization of Big Data Applications
   on Big and Little Core Server Architectures
SO PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA
DT Proceedings Paper
CT IEEE International Conference on Big Data
CY OCT 29-NOV 01, 2015
CL Santa Clara, CA
DE Performance; Power; Characterization; Big Data; High-Performance server;
   Low-Power server; Accelerator
AB Emerging Big Data applications require a significant amount of server computational power. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and exhibit high computational intensity, memory intensity, I/O intensity and control intensity. Big data applications require computing resources that can efficiently scale to manage massive amounts of diverse data. However, the rapid growth in the data yields challenges to process data efficiently using current server architectures such as big Xeon cores. Furthermore, physical design constraints, such as power and density, have become the dominant limiting factor for scaling out servers. Therefore recent work advocates the use of low-power embedded cores in servers such as little Atom to address these challenges. In this work, through methodical investigation of power and performance measurements, and comprehensive system level and micro-architectural analysis, we characterize emerging big data applications on big Xeon and little Atom-based server architecture. The characterization results across a wide range of real-world big data applications and various software stacks demonstrate how the choice of big vs little core-based server for energy-efficiency is significantly influenced by the size of data, performance constraints, and presence of accelerator. Furthermore, the microarchitecture-level analysis highlights where improvement is needed in big and little cores microarchitecture.
C1 [Malik, Maria; Sasan, Avesta; Homayoun, Houman] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
   [Rafatirah, Setareh] George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA 22030 USA.
RP Malik, M (corresponding author), George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
EM mmalik9@gmu.edu; srafatir@gmu.edu; hhomayou@gmu.edu
CR Absalyamov I., 2013, ADMS VLDB
   ANDERSEN DG, 2009, P ACM SIGOPS 22 SOSP, P1
   [Anonymous], ACM SIGARCH COMPUTER
   Armstrong, 2013, P ACM SIGMOD
   ARNOLD M., 2001, P 9 CODES
   Arora M, 2012, IEEE MICRO, V32, P4, DOI 10.1109/MM.2012.57
   Arora N, 2010, VLSI DESIGN
   Baru C, LECT NOTES COMPUTER
   Blem E., HPCA2013 IEEE 19 INT, P1
   Gao W., ASBD 2013 CONJUNCTIO
   Ghazal A., 2013, ACM SIGMOD C
   Gutierrez A., 2014, P 19 ASPLOS
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Homayoun H., HPCA 2012
   Honjo Toshimori, 2013, 2013 IEEE International Conference on Big Data, P118, DOI 10.1109/BigData.2013.6691562
   Huang S, 2010, P 26 ICDEW
   Kontorinis V., 2014, 51 ANN DAC 2014
   Kontorinis V., 39TH ISCA 2012
   Kukunas J.T., 2014, HIGH PERFORMANCE ZLI
   Li A., ACM 10
   Li T., 2009, P CASES
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Luo Xi, 2013, BIGDATA 2013
   Neshatpour K, 2015, 15 IEEE ACM CCGRID 2
   Neshatpour K, 2015, BIGDATA 2015
   Neshatpour K., IEEE FCCM 2015
   Nilakantan S., 2013, IISWC IEEE
   PRAKASH TK, 2008, ISAST 2008
   Reddi VJ, 2010, CONF PROC INT SYMP C, P314, DOI 10.1145/1816038.1816002
   Shan Y., 2010, P ANN ACM SIGDA INT
   Tavana Khavari, ISLPED 14
   Willke T.L., 2012, BIG LEARNING WS NIPS
   YU P., P FPL 07, P273
   YU P., P CASES 04
NR 34
TC 12
Z9 12
U1 0
U2 6
PY 2015
BP 85
EP 94
UT WOS:000380404600014
DA 2023-11-16
ER

PT C
AU Crumley, D
   Hossain, M
   Martin, K
   Ivey, F
   Yarnell, R
   DeMara, RF
   Bai, Y
AF Crumley, D.
   Hossain, M.
   Martin, K.
   Ivey, F.
   Yarnell, Richard
   DeMara, R. F.
   Bai, Y.
GP IEEE
TI Rehosting YOLOv2 Framework for Reconfigurable Fabric-based Acceleration
SO SOUTHEASTCON 2022
SE IEEE SoutheastCon-Proceedings
DT Proceedings Paper
CT SoutheastCon Conference
CY MAR 26-APR 03, 2022
CL Mobile, AL
DE Field Programmable Gate Array (FPGA); Machine Learning Accelerator;
   Convolutional Neural Network (CNN); You Only Look Once (YOLO) framework
AB While Convolutional Neural Networks are attaining widespread utility for computer vision tasks such as object detection and classification, the frameworks used to implement these systems are largely designed for use with CPUs and GPUs, with the latter being the hardware-optimized approach. This application-optimized hardware approach can be advanced further by researching Convolutional Neural Networks implemented on low-power and embedded devices using FPGAs. FPGAs consume substantially less energy than GPUs, offering additional potential benefits for embedded hardware acceleration of Convolutional Neural Nets. Because GPUs are still the favored target device for CNNs, there is an abundance of libraries and tools that can be used to create custom architectures in languages such as Python and C++. This, however, is not the case for FPGA development. Herein, a workflow is outlined for the conversion of Convolutional Neural Networks from a high-level language implementation to a bitstream which can be configured on an FPGA device and utilized as a hardware accelerator for image and video processing. Within this workflow, the data is quantized to reduce memory usage, C++ code is synthesized to Verilog using Vivado HLS tools, the resulting hardware module is integrated with the ZYNQ SOC processor, and the final implementation is tested for accuracy.
C1 [Crumley, D.; Hossain, M.; Martin, K.; Ivey, F.; Yarnell, Richard; DeMara, R. F.] Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA.
   [Bai, Y.] Calif State Univ Fullerton, Comp Engn Program, Fullerton, CA 92831 USA.
RP Crumley, D (corresponding author), Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA.
EM david_crumley@knights.ucf.edu; mousam.hossain@knights.ucf.edu;
   kaitlyn.martin@knights.ucf.edu; boivey3@knights.ucf.edu;
   richardyarnell@knights.ucf.edu; ronald.demara@ucf.edu;
   ybai@fullerton.edu
CR Alhussain A., 2022, PROCOF IEEE C INFORM, P1
   Cai YX, 2021, AAAI CONF ARTIF INTE, V35, P955
   Chen C, 2019, THESIS JIANGNAN U
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Xilinx PYNQ documentation, PYTH PROD ZYNQ PYNQ
   Zhang KN, 2005, LECT NOTES COMPUT SC, V3637, P12, DOI 10.1007/11549703_2
NR 6
TC 1
Z9 1
U1 2
U2 5
PY 2022
BP 445
EP 446
DI 10.1109/SoutheastCon48659.2022.9763979
UT WOS:000821548200074
DA 2023-11-16
ER

PT J
AU Zha, Y
   Nowak, E
   Li, J
AF Zha, Yue
   Nowak, Etienne
   Li, Jing
TI Liquid Silicon: A Nonvolatile Fully Programmable Processing-in-Memory
   Processor With Monolithically Integrated ReRAM
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE In-memory processing; neural network (NN); nonvolatile; reconfigurable
   architecture; resistive-RAM (RRAM); ternary content-addressable memory
AB The slowdown of the CMOS technology scaling, and the trade-off between efficiency and flexibility have fueled the exploration into novel architectures with emerging post-CMOS technology [e.g., resistive-RAM (RRAM)]. In this article, a nonvolatile fully programmable processing-in-memory (PIM) processor named Liquid Silicon is demonstrated, which combines the superior programmability of general-purpose computing devices [e.g., field-programmable gate array (FPGA)] and the high efficiency of domain-specific accelerators. Besides the general computing applications, Liquid Silicon is particularly well suited for artificial intelligence (AI)/machine learning and big data applications, which not only poses high computational/memory demand but also evolves rapidly. To fabricate the Liquid Silicon chip, the HfO2 RRAM is monolithically integrated on top of the commercial 130 nm CMOS. Our measurement confirms that Liquid Silicon chip can operate reliably at a low voltage of 650 mV. It achieves 60.9 TOPS/W in performing neural network (NN) inferences, and 480 GOPS/W in performing content-based similarity search (a key big data application) at a nominal voltage supply of 1.2 V, showing $3\times $ and $100\times $ improvement over the state-of-the-art domain-specific CMOS-/RRAM-based accelerators. In addition, it outperforms the latest nonvolatile FPGA in energy efficiency by $3\times $ in general computing applications.
C1 [Zha, Yue; Li, Jing] Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA.
   [Nowak, Etienne] CEA Leti, Minatec Campus, F-38054 Grenoble, France.
RP Li, J (corresponding author), Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA.
EM zhayue@seas.upenn.edu; janeli@seas.upenn.edu
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Ambrogio S., 2015, P IEEE INT REL PHYS
   Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   [Anonymous], 2015, 2015 S VLSI CIRC DIG
   [Anonymous], 2009, INTR INT QUICKPATH I
   [Anonymous], 1991, TECH REP
   [Anonymous], 2016, PROC 35TH INT CONF C
   Chhajed G, 2010, INT CONF COMP SCI, P375, DOI 10.1109/ICCSIT.2010.5564782
   Farmahini-Farahani A, 2015, IEEE COMPUT ARCHIT L, V14, P26, DOI 10.1109/LCA.2014.2333735
   Grossi A, 2016, INT EL DEVICES MEET
   Grossi A, 2019, IEEE T ELECTRON DEV, V66, P1281, DOI 10.1109/TED.2019.2894387
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Li J, 2014, IEEE J SOLID-ST CIRC, V49, P896, DOI 10.1109/JSSC.2013.2292055
   Liu YP, 2016, ISSCC DIG TECH PAP I, V59, P84, DOI 10.1109/ISSCC.2016.7417918
   Moons B, 2018, IEEE CUST INTEGR CIR
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Su F, 2017, SYMP VLSI CIRCUITS, pC260
   Tsurumi K, 2018, IEEE ASIAN SOLID STA, P129
   Yin SY, 2018, SYMP VLSI CIRCUITS, P37, DOI 10.1109/VLSIC.2018.8502388
   Yin SY, 2018, SYMP VLSI CIRCUITS, P139, DOI 10.1109/VLSIC.2018.8502309
   Young Yang Liauw, 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P406, DOI 10.1109/ISSCC.2012.6177067
   Zha Y, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P51, DOI 10.1145/31742433174244
   Zha Y, 2018, ACM SIGPLAN NOTICES, V53, P214, DOI [10.1145/3296957.3173167, 10.1145/3173162.3173167]
NR 23
TC 14
Z9 16
U1 2
U2 22
PD APR
PY 2020
VL 55
IS 4
BP 908
EP 919
DI 10.1109/JSSC.2019.2963005
UT WOS:000522446300008
DA 2023-11-16
ER

PT J
AU Choong, BCM
   Luo, T
   Liu, C
   He, BS
   Zhang, W
   Zhou, JT
AF Choong, Benjamin Chen Ming
   Luo, Tao
   Liu, Cheng
   He, Bingsheng
   Zhang, Wei
   Zhou, Joey Tianyi
TI Hardware-software co-exploration with racetrack memory based in-memory
   computing for CNN inference in embedded systems
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Artificial intelligence; Hardware-software co-design; Deep learning;
   Embedded systems; Emerging memory
ID NEURAL-NETWORKS; ENERGY; ARCHITECTURE; ACCELERATOR; MACHINE; ADDER
AB Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.
C1 [Choong, Benjamin Chen Ming] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore.
   [Luo, Tao] Agcy Sci Technol & Res, Inst High Performance Comp, 1 Fusionopolis Way,16-16 Connexis, Singapore 138632, Singapore.
   [Liu, Cheng] Chinese Acad Sci, Inst Comp Technol, 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
   [He, Bingsheng] Natl Univ Singapore, Sch Comp, COM1,13 Comp Dr, Singapore 117417, Singapore.
   [Zhang, Wei] Hong Kong Univ Sci & Technol, Kowloon, Clear Water Bay, Hong Kong, Peoples R China.
   [Zhou, Joey Tianyi] ASTAR, Ctr Frontier AI Res, 1 Fusionopolis Way,16-16 Connexis, Singapore 138632, Singapore.
RP Luo, T (corresponding author), Agcy Sci Technol & Res, Inst High Performance Comp, 1 Fusionopolis Way,16-16 Connexis, Singapore 138632, Singapore.
EM leto.luo@gmail.com
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], 2014, 51 ACMEDACIEEE DESIG
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   Chauwin M, 2019, PHYS REV APPL, V12, DOI 10.1103/PhysRevApplied.12.064053
   Chen C, 2018, IEEE T COMPUT, V67, P1765, DOI 10.1109/TC.2018.2839719
   Chen C, 2018, IEEE T PARALL DISTR, V29, P1275, DOI 10.1109/TPDS.2018.2794343
   Chen C, 2017, IEEE T SYST MAN CY-S, V47, P2740, DOI 10.1109/TSMC.2017.2690673
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen ZG, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358199
   Ding RZ, 2018, ASIA S PACIF DES AUT, P1, DOI 10.1109/ASPDAC.2018.8297274
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Han S, 2016, ARXIV 151000149
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Trinh HP, 2013, IEEE T CIRCUITS-I, V60, P1469, DOI 10.1109/TCSI.2012.2220507
   Howard A.G., 2017, MOBILENETS EFFICIENT, V1704, P4861
   Hsu LC, 2020, J SYST ARCHITECT, V111, DOI 10.1016/j.sysarc.2020.101831
   Hu QD, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P397, DOI 10.1145/2902961.2902967
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kang HJ, 2020, IEEE T CIRC SYST VID, V30, P2093, DOI 10.1109/TCSVT.2019.2911674
   Kang W, 2018, IEEE NON-VOLATILE ME, P7, DOI 10.1109/NVMSA.2018.00009
   Kang W, 2017, IEEE T ELECTRON DEV, V64, P1060, DOI 10.1109/TED.2017.2656140
   Kim N, 2021, IEEE T NEUR NET LEAR, V32, P2925, DOI 10.1109/TNNLS.2020.3008996
   Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lin CJ, 2009, INT EL DEVICES MEET, P256
   Liu BC, 2017, IEEE INT SYMP PARAL, P383, DOI 10.1109/ISPA/IUCC.2017.00061
   Luo SJ, 2021, APL MATER, V9, DOI 10.1063/5.0042917
   Luo T, 2020, INT CON DISTR COMP S, P1409, DOI 10.1109/ICDCS47774.2020.00186
   Luo T, 2020, IEEE T COMPUT AID D, V39, P438, DOI 10.1109/TCAD.2018.2889670
   Luo T, 2017, ICCAD-IEEE ACM INT, P276, DOI 10.1109/ICCAD.2017.8203789
   Luo T, 2016, ASIA S PACIF DES AUT, P286, DOI 10.1109/ASPDAC.2016.7428025
   Malladi KT, 2012, CONF PROC INT SYMP C, P37, DOI 10.1109/ISCA.2012.6237004
   Mao MJ, 2017, IEEE T COMPUT, V66, P1478, DOI 10.1109/TC.2017.2690855
   Matsunaga S, 2008, APPL PHYS EXPRESS, V1, DOI 10.1143/APEX.1.091301
   Mei LY, 2021, IEEE T COMPUT, V70, P1160, DOI 10.1109/TC.2021.3059962
   Meng H, 2005, IEEE ELECTR DEVICE L, V26, P360, DOI 10.1109/LED.2005.848129
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Parkin SSP, 2008, SCIENCE, V320, P190, DOI 10.1126/science.1145799
   Paszke A, 2019, ADV NEUR IN, V32
   Riente F., 2021, IEEE T EMERG TOP COM, DOI DOI 10.1109/TETC.2021.3078061
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Silicon Integration Initiative Inc., 2016, 45NM FREEPDK LIB
   Simonyan K., 2015, 3 INT C LEARNING REP, P1
   Song LL, 2017, IEEE T VLSI SYST, V25, P1285, DOI 10.1109/TVLSI.2016.2644279
   Sun ZY, 2013, DES AUT CON
   Venkatesan R, 2013, DES AUT TEST EUROPE, P1825
   Venkatesan R, 2014, CONF PROC INT SYMP C, P253, DOI 10.1109/ISCA.2014.6853233
   Wang GD, 2019, IEEE T CIRCUITS-I, V66, P215, DOI 10.1109/TCSI.2018.2866932
   Wang J., 2020, IEEE T COMPUT, DOI DOI 10.1109/TC.2020.3045433
   Wang YH, 2014, DES AUT TEST EUROPE
   Wang YH, 2016, IEEE T INF FOREN SEC, V11, P2426, DOI 10.1109/TIFS.2016.2576903
   Xu HF, 2015, ASIA S PACIF DES AUT, P417, DOI 10.1109/ASPDAC.2015.7059042
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
   Zand R, 2017, IEEE T NANOTECHNOL, V16, P32, DOI 10.1109/TNANO.2016.2625749
   Zhang C, 2015, ASIA S PACIF DES AUT, P100, DOI 10.1109/ASPDAC.2015.7058988
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang XC, 2015, SCI REP-UK, V5, DOI 10.1038/srep09400
   Zhang Y, 2012, J APPL PHYS, V111, DOI 10.1063/1.4716460
   Zhao W., 2013, 2013 IEEE FAIBLE TEN, P1, DOI DOI 10.1109/FTFC.2013.6577771
   Zhou Aojun, 2017, INT C LEARN REPR ICL
   Zhu CY, 2020, IEEE T VLSI SYST, V28, P1953, DOI 10.1109/TVLSI.2020.3002779
NR 68
TC 1
Z9 1
U1 1
U2 13
PD JUL
PY 2022
VL 128
AR 102507
DI 10.1016/j.sysarc.2022.102507
EA MAY 2022
UT WOS:000802886800003
DA 2023-11-16
ER

PT C
AU Albericio, J
   Delmás, A
   Judd, P
   Sharify, S
   O'Leary, G
   Genov, R
   Moshovos, A
AF Albericio, Jorge
   Delmas, Alberto
   Judd, Patrick
   Sharify, Sayeh
   O'Leary, Gerard
   Genov, Roman
   Moshovos, Andreas
GP ACM
TI Bit-Pragmatic Deep Neural Network Computing
SO 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
DT Proceedings Paper
CT 50th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 14-18, 2017
CL Cambridge, MA
DE Hardware Accelerators; Machine Learning; Neural Networks
AB Deep Neural Networks expose a high degree of parallelism, making them amenable to highly data parallel architectures. However, data-parallel architectures often accept inefficiency in individual computations for the sake of overall efficiency. We show that on average, activation values of convolutional layers during inference in modern Deep Convolutional Neural Networks (CNNs) contain 92% zero bits. Processing these zero bits entails ineffectual computations that could be skipped. We propose Pragmatic (PRA), a massively data-parallel architecture that eliminates most of the ineffectual computations on-the-fly, improving performance and energy efficiency compared to state-of-the-art high-performance accelerators [5]. The idea behind PRA is deceptively simple: use serial-parallel shift-and-add multiplication while skipping the zero bits of the serial input. However, a straightforward implementation based on shift-and-add multiplication yields unacceptable area, power and memory access overheads compared to a conventional bit-parallel design. PRA incorporates a set of design decisions to yield a practical, area and energy efficient design.
   Measurements demonstrate that for convolutional layers, PRA is 4.31x faster than DaDianNao [5] (DaDN) using a 16-bit fixed-point representation. While PRA requires 1.68x more area than DaDN, the performance gains yield a 1.70x increase in energy efficiency in a 65nm technology. With 8-bit quantized activations, PRA is 2.25x faster and 1.31x more energy efficient than an 8-bit version of DaDN.
C1 [Albericio, Jorge] NVIDIA, Santa Clara, CA 95051 USA.
   [Albericio, Jorge; Delmas, Alberto; Judd, Patrick; Sharify, Sayeh; O'Leary, Gerard; Genov, Roman; Moshovos, Andreas] Univ Toronto, Toronto, ON, Canada.
RP Albericio, J (corresponding author), NVIDIA, Santa Clara, CA 95051 USA.
EM jalbericiola@nvidia.com; delmasl1@ece.utoronto.ca;
   juddpatr@ece.utoronto.ca; sayeh@ece.utoronto.ca;
   gerard.oleary@eecg.utoronto.ca; roman@eecg.utoronto.ca;
   moshovos@ece.utoronto.ca
CR Albericio Jorge, 2016, 2016 IEEE ACM INT C
   Alemdar H., 2016, CORR
   [Anonymous], 2014, CORR
   [Anonymous], DES COMP
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   CHEN YH, 2016, DIGEST TECHNICAL PAP, V59, P262
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Courbariaux Matthieu, 2015, ARXIV E PRINTS
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Girshick Ross, 2013, RICH FEATURE HIERARC
   Gonzalez R, 1996, IEEE J SOLID-ST CIRC, V31, P1277, DOI 10.1109/4.535411
   Graybill R, 2002, S COMP SCI, P293
   Han  S., 2015, ARXIV151000149CS
   Han S., 2016, ARXIV160201528CS
   Iandola F.N., 2016, CORR ABS160207360
   Jonghong Kim, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7510, DOI 10.1109/ICASSP.2014.6855060
   Judd P., 2015, ARXIV151105236V4CSLG
   Judd P., 2016, MICRO 49
   Judd P., 2016, COMPUTER ARCHITECTUR
   Judd P., 2016, WORKSH APPR COMP WAP
   Muralimanohar N., CACTI 6 0 TOOL UNDER
   Nair V., 2010, PROC 27 INT C INT C
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Poremba M, 2015, DES AUT TEST EUROPE, P1543
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Warden Peter, 2016, LOW PRECISION MATRIX
   YAO HH, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P359, DOI 10.1109/ACSSC.1993.342534
NR 28
TC 127
Z9 131
U1 2
U2 8
PY 2017
BP 382
EP 394
DI 10.1145/3123939.3123982
UT WOS:000455679300029
DA 2023-11-16
ER

PT J
AU Lin, JP
   Haberstroh, F
   Karsch, S
   Döpp, A
AF Lin, Jinpu
   Haberstroh, Florian
   Karsch, Stefan
   Doepp, Andreas
TI Applications of object detection networks in high-power laser systems
   and experiments
SO HIGH POWER LASER SCIENCE AND ENGINEERING
DT Article
DE high repetition rate; laser-plasma accelerators; machine learning;
   object detection; optical diagnostics
ID PETAWATT; DRIVEN; DYNAMICS; PW
AB The recent advent of deep artificial neural networks has resulted in a dramatic increase in performance for object classification and detection. While pre-trained with everyday objects, we find that a state-of-the-art object detection architecture can very efficiently be fine-tuned to work on a variety of object detection tasks in a high-power laser laboratory. In this paper, three exemplary applications are presented. We show that the plasma waves in a laser-plasma accelerator can be detected and located on the optical shadowgrams. The plasma wavelength and plasma density are estimated accordingly. Furthermore, we present the detection of all the peaks in an electron energy spectrum of the accelerated electron beam, and the beam charge of each peak is estimated accordingly. Lastly, we demonstrate the detection of optical damage in a high-power laser system. The reliability of the object detector is demonstrated over 1000 laser shots in each application. Our study shows that deep object detection networks are suitable to assist online and offline experimental analysis, even with small training sets. We believe that the presented methodology is adaptable yet robust, and we encourage further applications in Hz-level or kHz-level high-power laser facilities regarding the control and diagnostic tools, especially for those involving image data.
C1 [Lin, Jinpu; Haberstroh, Florian; Karsch, Stefan; Doepp, Andreas] Ludwig Maximilians Univ Munchen, Garching, Germany.
RP Lin, JP (corresponding author), Ludwig Maximilians Univ Munchen, Coulombwall 1, D-85748 Garching, Germany.
EM Lin.Jinpu@physik.uni-muenchen.de
CR Amorin C, 2019, STAT ANAL DATA MIN, V12, P505, DOI 10.1002/sam.11437
   Borneis S, 2021, HIGH POWER LASER SCI, V9, DOI 10.1017/hpl.2021.16
   cala-laser.de/, US
   Danson CN, 2004, NUCL FUSION, V44, pS239, DOI 10.1088/0029-5515/44/12/S15
   Danson CN, 2019, HIGH POWER LASER SCI, V7, DOI 10.1017/hpl.2019.36
   Ding H, 2020, PHYS REV E, V101, DOI 10.1103/PhysRevE.101.023209
   Downer MC, 2018, REV MOD PHYS, V90, DOI 10.1103/RevModPhys.90.035002
   Englesbe A, 2021, APPL OPTICS, V60, pG113, DOI 10.1364/AO.426240
   Gales S, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aacfe8
   Gaul EW, 2010, APPL OPTICS, V49, P1676, DOI 10.1364/AO.49.001676
   Gilljohann MF, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.011046
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   github, HTTPS GITHUB COM ULT
   Gonoskov A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43465-3
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   Hidding B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132626
   Hsu A, 2020, PHYS PLASMAS, V27, DOI 10.1063/1.5130585
   Humbird KD, 2020, IEEE T PLASMA SCI, V48, P61, DOI 10.1109/TPS.2019.2955098
   Humbird KD, 2019, IEEE T NEUR NET LEAR, V30, P1286, DOI 10.1109/TNNLS.2018.2869694
   Kurz T, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5041755
   Li WQ, 2018, OPT LETT, V43, P5681, DOI 10.1364/OL.43.005681
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Li Z, 2020, OPT EXPRESS, V28, P10165, DOI 10.1364/OE.387987
   Lin J, 2019, OPT EXPRESS, V27, P10912, DOI 10.1364/OE.27.010912
   Lin JP, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0047940
   Nees J., 2020, 2020 C LASERS ELECTR, P1
   Noaman-ul-Haq M, 2018, NUCL INSTRUM METH A, V883, P191, DOI 10.1016/j.nima.2017.11.075
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sävert A, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.055002
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Smith JR, 2020, NEW J PHYS, V22, DOI 10.1088/1367-2630/abbfce
   Streeter MJV, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5027297
   STRICKLAND D, 1985, OPT COMMUN, V55, P447, DOI 10.1016/0030-4018(85)90151-8
   Sung JH, 2017, OPT LETT, V42, P2058, DOI 10.1364/OL.42.002058
   Tudor P., 2022, LPA ONL WORKSH CONTR
   Wenz J, 2019, NAT PHOTONICS, V13, P263, DOI 10.1038/s41566-019-0356-z
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zhang ZX, 2020, HIGH POWER LASER SCI, V8, DOI 10.1017/hpl.2020.3
NR 39
TC 3
Z9 3
U1 9
U2 9
PD JAN 13
PY 2023
VL 11
AR e7
DI 10.1017/hpl.2023.1
UT WOS:000939714200001
DA 2023-11-16
ER

PT J
AU Tahir, A
   Morison, G
   Skelton, DA
   Gibson, RM
AF Tahir, Ahsen
   Morison, Gordon
   Skelton, Dawn A.
   Gibson, Ryan M.
TI Hardware/Software Co-Design of Fractal Features Based Fall Detection
   System
SO SENSORS
DT Article
DE fall detection; wearable sensors; classification; machine learning;
   fractal features; hardware software co-design; FPGA; reconfigurable
   design; embedded system on chip
ID TIME-SERIES; UNIT-ROOT; LONG; DYNAMICS; TESTS
AB Falls are a leading cause of death in older adults and result in high levels of mortality, morbidity and immobility. Fall Detection Systems (FDS) are imperative for timely medical aid and have been known to reduce death rate by 80%. We propose a novel wearable sensor FDS which exploits fractal dynamics of fall accelerometer signals. Fractal dynamics can be used as an irregularity measure of signals and our work shows that it is a key discriminant for classification of falls from other activities of life. We design, implement and evaluate a hardware feature accelerator for computation of fractal features through multi-level wavelet transform on a reconfigurable embedded System on Chip, Zynq device for evaluating wearable accelerometer sensors. The proposed FDS utilises a hardware/software co-design approach with hardware accelerator for fractal features and software implementation of Linear Discriminant Analysis on an embedded ARM core for high accuracy and energy efficiency. The proposed system achieves 99.38% fall detection accuracy, 7.3x speed-up and 6.53x improvements in power consumption, compared to the software only execution with an overall performance per Watt advantage of 47.6x, while consuming low reconfigurable resources at 28.67%.
C1 [Tahir, Ahsen; Morison, Gordon; Gibson, Ryan M.] Glasgow Caledonian Univ, Sch Comp Engn & Built Environm, Glasgow G4 0BA, Lanark, Scotland.
   [Tahir, Ahsen] Univ Engn & Technol, Dept Elect Engn, Lahore 54890, Punjab, Pakistan.
   [Skelton, Dawn A.] Glasgow Caledonian Univ, Sch Hlth & Life Sci, Glasgow G4 0BA, Lanark, Scotland.
RP Tahir, A (corresponding author), Glasgow Caledonian Univ, Sch Comp Engn & Built Environm, Glasgow G4 0BA, Lanark, Scotland.; Tahir, A (corresponding author), Univ Engn & Technol, Dept Elect Engn, Lahore 54890, Punjab, Pakistan.
EM ahsen.tahir@gcu.ac.uk; Gordon.Morison@gcu.ac.uk; Dawn.Skelton@gcu.ac.uk;
   Ryan.Gibson@gcu.ac.uk
CR Abdelwahab S., 2017, P 2 INT C COMPUTING, P1, DOI DOI 10.1145/3167486
   Akouaydi H, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P153, DOI 10.1109/ASAR.2017.8067778
   Ali AAS, 2014, I C COMP SYST APPLIC, P685, DOI 10.1109/AICCSA.2014.7073266
   Ali SF, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061918
   [Anonymous], DIG ACC ADXL345 EP
   [Anonymous], P SAI INT SYST C LON
   [Anonymous], P 2017 IEEE E W DES
   [Anonymous], INT J COMPUT ELECT A
   [Anonymous], 1973, P SECT INT S INF THE, DOI 10.1007/978-1-4612-1694-0
   Bizovska L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197091
   Box G.E.P., 1976, TIME SERIES ANAL FOR, P575
   Chelli A, 2019, IEEE ACCESS, V7, P38670, DOI 10.1109/ACCESS.2019.2906693
   Coviello G, 2020, IEEE SENS J, V20, P8771, DOI 10.1109/JSEN.2020.2982744
   de Fontenay BP, 2020, IEEE SENS J, V20, P7783, DOI 10.1109/JSEN.2020.2982568
   DICKEY DA, 1979, J AM STAT ASSOC, V74, P427, DOI 10.2307/2286348
   Diebolt C, 2005, QUAL QUANT, V39, P827, DOI 10.1007/s11135-004-0436-z
   Doulamis A, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P558, DOI 10.1145/3197768.3201543
   FLANDRIN P, 1992, IEEE T INFORM THEORY, V38, P910, DOI 10.1109/18.119751
   Gibson RM, 2017, BIOMED SIGNAL PROCES, V33, P96, DOI 10.1016/j.bspc.2016.10.016
   Gibson RM, 2016, APPL SOFT COMPUT, V39, P94, DOI 10.1016/j.asoc.2015.10.062
   Gomez Rivera D., 2016, International Journal of Information and Electronics Engineering, V6, P313, DOI 10.18178/ijiee.2016.6.5.645
   Hausdorff JM, 2007, HUM MOVEMENT SCI, V26, P555, DOI 10.1016/j.humov.2007.05.003
   Hsieh CY, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P818, DOI 10.1109/ICASI.2018.8394388
   Hsieh YZ, 2018, IEEE ACCESS, V6, P6048, DOI 10.1109/ACCESS.2017.2771389
   Hussain F, 2019, IEEE SENS J, V19, P4528, DOI 10.1109/JSEN.2019.2898891
   Iqbal S, 2015, INT CONF ELECTRO INF, P25, DOI 10.1109/EIT.2015.7293419
   Josinski H, 2015, LECT NOTES ARTIF INT, V9012, P317, DOI 10.1007/978-3-319-15705-4_31
   Kim S, 2018, PROC VLDB ENDOW, V12, P1, DOI 10.14778/3275536.3275537
   Koutsiana E, 2017, FRONT BIOENG BIOTECH, V5, DOI 10.3389/fbioe.2017.00049
   KWIATKOWSKI D, 1992, J ECONOMETRICS, V54, P159, DOI 10.1016/0304-4076(92)90104-Y
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Liu KC, 2018, IEEE SENS J, V18, P9882, DOI 10.1109/JSEN.2018.2872835
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   MANDELBROT B, 1967, SCIENCE, V156, P636, DOI 10.1126/science.156.3775.636
   Margiotta N., 2016, P 2016 5 INT C EL DE, P1
   Mau Dung Nguyen, 2020, 2020 IEEE International Conference on Consumer Electronics (ICCE), DOI 10.1109/ICCE46568.2020.9042999
   Morbidoni C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080894
   NG S, 1995, J AM STAT ASSOC, V90, P268, DOI 10.2307/2291151
   Noury N, 2008, IRBM, V29, P340, DOI 10.1016/j.irbm.2008.08.002
   Ong PS, 2014, IEEE REGION 10 SYMP, P397, DOI 10.1109/TENCONSpring.2014.6863065
   Pang I, 2019, J GERIATR PHYS THER, V42, P48, DOI 10.1519/JPT.0000000000000181
   Park SH, 2020, PAEDIATR INT CHILD H, V40, P166, DOI 10.1080/20469047.2020.1747002
   Perc M, 2005, EUR J PHYS, V26, P525, DOI 10.1088/0143-0807/26/3/017
   Reynard F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100550
   Rossignol S, 2006, PHYSIOL REV, V86, P89, DOI 10.1152/physrev.00028.2005
   Saadeh W, 2019, IEEE T NEUR SYS REH, V27, P995, DOI 10.1109/TNSRE.2019.2911602
   Saadeh W, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P441, DOI 10.1109/BHI.2017.7897300
   Sahoo S, 2020, IEEE SENS J, V20, P8128, DOI 10.1109/JSEN.2020.2980863
   Schneider B, 2020, HEALTHC TECHNOL LETT, V7, P25, DOI 10.1049/htl.2019.0015
   Schwert GW, 2002, J BUS ECON STAT, V20, P5, DOI 10.1198/073500102753410354
   Sekine M, 2002, IEEE T NEUR SYS REH, V10, P188, DOI 10.1109/TNSRE.2002.802879
   Senouci B, 2016, J REAL-TIME IMAGE PR, V12, P649, DOI 10.1007/s11554-014-0456-4
   SOWELL F, 1992, J MONETARY ECON, V29, P277, DOI 10.1016/0304-3932(92)90016-U
   Stadnitski T, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00127
   Sucerquia A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010198
   Sukor ASA, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P233, DOI 10.1109/CSPA.2018.8368718
   Tahir A, 2021, PROBAB ENG INFORM SC, V35, P37, DOI 10.1017/S0269964819000317
   Terrier P, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-12
   Tian Y., 2013, EXPLORING SYSTEM WID
   Gia TN, 2018, MICROPROCESS MICROSY, V56, P34, DOI 10.1016/j.micpro.2017.10.014
   Nguyen TL, 2018, INT CONF KNOWL SYS, P129, DOI 10.1109/KSE.2018.8573328
   Vavoulas G, 2013, IEEE INT C BIOINF BI
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   WORNELL GW, 1992, IEEE T SIGNAL PROCES, V40, P611, DOI 10.1109/78.120804
   Xu T, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318400052
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhong ZC, 2018, IEEE ASME INT C ADV, P1039, DOI 10.1109/AIM.2018.8452687
NR 67
TC 2
Z9 2
U1 0
U2 5
PD APR
PY 2020
VL 20
IS 8
AR 2322
DI 10.3390/s20082322
UT WOS:000533346400164
DA 2023-11-16
ER

PT C
AU Adavally, S
   Weaver, A
   Vasireddy, P
   Kavi, K
   Mehta, G
   Gulur, N
AF Adavally, Shashank
   Weaver, Alex
   Vasireddy, Pranathi
   Kavi, Krishna
   Mehta, Gayatri
   Gulur, Nagendra
GP IEEE Comp Soc
TI HETEROGENEOUS ARCHITECTURE FOR SPARSE DATA PROCESSING
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE Sparse matrices; DNN; Hardware Accelerators; RISCV
AB Sparse matrices are very common types of information used in scientific and machine learning applications including deep neural networks. Sparse data representations lead to storage efficiencies by avoiding storing zero values. However, sparse representations incur metadata computational overheads - software first needs to find row/column locations of non-zero values before performing necessary computations. Such metadata accesses involve indirect memory accesses (of the form a[b[i] ] where a[.] and b[.] are large arrays) and they are cache and prefetch-unfriendly, resulting in frequent load stalls.
   In this paper, we will explore a dedicated hardware for a memory-side accelerator called Hardware Helper Thread (HHT) that performs all the necessary index computations to fetch only the nonzero elements from sparse matrix and sparse vector and supply those values to the primary core, creating heterogeneity within a single CPU core. We show both performance gains and energy savings of HHT for sparse matrix-dense vector multiplication (SpMV) and sparse matrixsparse vector multiplication (SpMSpV). The ASIC HHT shows average performance gains ranging between 1.7 and 3.5 depending on the sparsity levels, vector-widths used by RISCV vector instructions and if the Vector (in Matrix-Vector multiplication) is sparse or dense. We also show energy savings of 19% on average when ASIC HHT is used compared to baseline (for SpMV), and the HHT requires 38.9% of a RISCV core area.
C1 [Adavally, Shashank; Weaver, Alex; Vasireddy, Pranathi; Kavi, Krishna; Mehta, Gayatri; Gulur, Nagendra] Univ North Texas, Denton, TX 76203 USA.
RP Adavally, S (corresponding author), Univ North Texas, Denton, TX 76203 USA.
CR Adavally S, 2020, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, MEMSYS 2020, P46, DOI 10.1145/3422575.3422777
   Agrawal SR, 2016, ACM SIGPLAN NOTICES, V51, P25, DOI 10.1145/2851141.2851144
   Azad A, 2018, NUCLEIC ACIDS RES, V46, DOI 10.1093/nar/gkx1313
   Azad A, 2017, INT PARALL DISTRIB P, P688, DOI 10.1109/IPDPS.2017.76
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Barredo A, 2019, INT CONFER PARA, P482, DOI 10.1109/PACT.2019.00056
   Bell N, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Buluc A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P721, DOI 10.1109/IPDPS.2011.73
   Buluç A, 2011, INT J HIGH PERFORM C, V25, P496, DOI 10.1177/1094342011403516
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Buluc Aydin., SIAM J SCI COMPUTING, V34
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Farzaneh A, 2009, COMMUN FAC SCI UNIV, V58, P1, DOI 10.1501/Commua1_0000000648
   Fox L.M, 2003, WORKSHOP COMPILERS T
   Gonzalez Abraham, 2019, RISC V ISA SIM
   Greathouse JL, 2014, INT CONF HIGH PERFOR, P769, DOI 10.1109/SC.2014.68
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He Guoming, 2010, KDD, P543
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard Andrew G., 2017, arXiv
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Intel, 2019, OV INTR INT
   Kanellopoulos K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P600, DOI 10.1145/3352460.3358286
   Li W., 2006, IEEE COMPUT ARCHIT L, V5
   lowRISC, 2017, IBEX EMB 32 BIT RISC
   Moreau T., 2019, IEEE MICRO
   NXP, 2019, NXP MICR OV
   NXP, 2019, MICR MICR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Rawal A, 2019, IEEE SYM PARA DISTR, P47, DOI 10.1109/IPDPSW.2019.00016
   Rezaei M, 2006, J SYST ARCHITECT, V52, P41, DOI 10.1016/j.sysarc.2005.02.004
   RISCV Foundation, 2020, RISCV VECT EXT SPEC
   RISCV Foundation, 2020, RISC V FREE OP RISC
   Sadi F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P347, DOI 10.1145/3352460.3358330
   Sandler M., 2018, CVPR
   SCHAUMBURG K, 1980, COMPUT CHEM, V4, P1, DOI 10.1016/0097-8485(80)85003-0
   Simonyan K., 2015, VERY DEEP CONVOLUTIO, V1, P3
   Stephens N, 2017, IEEE MICRO, V37, P26, DOI 10.1109/MM.2017.35
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   TI, 2019, MSP432P401R MSP432P4
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yavits Leonid, 2017, CORR
   Yu XY, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P178, DOI 10.1145/2830772.2830807
   Zhang Y., 2017, CORR
NR 48
TC 1
Z9 1
U1 1
U2 2
PY 2022
BP 6
EP 15
DI 10.1109/IPDPSW55747.2022.00012
UT WOS:000855041000001
DA 2023-11-16
ER

PT C
AU Meyers, V
   Gnad, D
   Tahoori, M
AF Meyers, Vincent
   Gnad, Dennis
   Tahoori, Mehdi
GP IEEE
TI Reverse Engineering Neural Network Folding with Remote FPGA Power
   Analysis
SO 2022 IEEE 30TH INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM
   COMPUTING MACHINES (FCCM 2022)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT IEEE 30th International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 15-18, 2022
CL New York, NY
ID GOLDEN-AGE
AB Specialized hardware accelerators in the form of FPGAs are widely being used for neural network implementations. By that, they also become the target of power analysis attacks that try to reverse engineer the embedded secret information, in the form of model parameters. However, most of these attacks assume rather simple implementations, not realistic frameworks. Layer folding is used in such accelerators to optimize the network under given area constraints with various degrees of parallel and sequential operations. In this paper, we show that folding does mislead existing power side-channel attacks on frameworks such as FINN. We show how we can extract the folding parameters successfully and use that information to subsequently also recover the number of neurons - something not reliably possible without knowing the folding information. Following the methodologies of both profiling side-channel attacks and machine learning, our approach can extract the amount of neurons with 98% accuracy on a test device, compared to 44-79% accuracy based on related work under the same test conditions and datasets. Furthermore, we show how a classifier that is based on regression can detect previously unknown parameters, which has not been shown before. To verify our results under different environmental conditions, we test the target device in a climate chamber under various temperature ranges and still reach accuracies of at least 93%.
C1 [Meyers, Vincent; Gnad, Dennis; Tahoori, Mehdi] Karlsruhe Inst Technol KIT, Chair Dependable Nano Comp CDNC, Karlsruhe, Germany.
RP Meyers, V (corresponding author), Karlsruhe Inst Technol KIT, Chair Dependable Nano Comp CDNC, Karlsruhe, Germany.
EM vincent.meyers@student.kit.edu; dennis.gnad@kit.edu;
   mehdi.tahoori@kit.edu
CR Amazon Web Services, EC2 EL COMP CLOUD
   [Anonymous], 2021, ALIBABA CLOUD CLOUD
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Breier J, 2022, IEEE T RELIAB, V71, P1527, DOI 10.1109/TR.2021.3105697
   Chari S, 2002, LECT NOTES COMPUT SC, V2523, P13
   Christ M, 2018, NEUROCOMPUTING, V307, P72, DOI 10.1016/j.neucom.2018.03.067
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Dubey A, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415649
   Dubey A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P197, DOI [10.1109/host45689.2020.9300276, 10.1109/HOST45689.2020.9300276]
   Fahn PN, 1999, LECT NOTES COMPUT SC, V1717, P173
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Glamocanin O, 2020, DES AUT TEST EUROPE, P1007, DOI 10.23919/DATE48585.2020.9116481
   Guo P, 2018, I C FIELD PROG LOGIC, P51, DOI 10.1109/FPL.2018.00016
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Heuser A, 2012, LECT NOTES COMPUT SC, V7178, P365, DOI 10.1007/978-3-642-27954-6_23
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Krautter J., 2018, IACR TCHES, P44, DOI 10.13154/tches.v2018.i3.44-68
   Krautter J, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942094
   Krautter J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3328222
   Li YX, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3154839
   Liu WY, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218577
   Masle A. L., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P14, DOI 10.1109/FPL.2012.6339235
   Moini S, 2021, IEEE J EM SEL TOP C, V11, P357, DOI 10.1109/JETCAS.2021.3074608
   Moreau T, 2019, Arxiv, DOI arXiv:1807.04188
   Murshed MGS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3469029
   Paszke A, 2019, ADV NEUR IN, V32
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Rakin AS, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1919
   Real MM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156790
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Tian SQ, 2021, ANN IEEE SYM FIELD P, P242, DOI 10.1109/FCCM51124.2021.00037
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Wolf S, 2021, IEEE COMP SOC ANN, P242, DOI 10.1109/ISVLSI51109.2021.00052
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
   Zhang YC, 2021, IEEE T INF FOREN SEC, V16, P4377, DOI 10.1109/TIFS.2021.3106169
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zick K. M., 2013, P ACMSIGDA INT S FIE, P101
NR 46
TC 1
Z9 1
U1 0
U2 3
PY 2022
BP 122
EP 131
DI 10.1109/FCCM53951.2022.9786107
UT WOS:000856347400015
DA 2023-11-16
ER

PT C
AU Chikin, A
   Amaral, JN
   Ali, K
   Tiotto, E
AF Chikin, Artem
   Amaral, Jose Nelson
   Ali, Karim
   Tiotto, Ettore
GP IEEE
TI Toward an Analytical Performance Model to Select between GPU and CPU
   Execution
SO 2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
DE Heterogeneous Computing; OpenMP; GPGPU; MIC; Static Analysis; Hybrid
   Analysis; Performance Model
ID PREDICTION
AB Automating the device selection in heterogeneous computing platforms requires the modelling of performance both on CPUs and on accelerators. This work argues for the use of a hybrid analytical performance modelling approach is a practical way to build fast and efficient methods to select an appropriate target for a given computation kernel. The target selection problem has been addressed in the literature, however there has been a strong emphasis on building empirical models with machine learning techniques. We argue that the applicability of such solutions is often limited in production systems. This paper focus on the issue of building a selector to decide if an OpenMP loop nest should be executed in a CPU or in a GPU. To this end, it offers a comprehensive comparison evaluation of the difference in GPU kernel performance on devices of multiple generations of architectures. The idea is to underscore the need for accurate analytical performance models and to provide insights in the evolution of GPU accelerators. This work also highlights a drawback of existing approaches to modelling GPU performance - accurate modelling of memory coalescing characteristics. To that end, we examine a novel application of an inter-thread difference analysis that can further improve analytical models. Finally, this work presents an initial study of an Open Multi-Processing (OpenMP) runtime framework for target-offloading target selection.
C1 [Chikin, Artem] Intel Corp, Toronto, ON, Canada.
   [Amaral, Jose Nelson; Ali, Karim] Univ Alberta, Edmonton, AB, Canada.
   [Tiotto, Ettore] IBM Canada, Markham, ON, Canada.
RP Chikin, A (corresponding author), Intel Corp, Toronto, ON, Canada.
EM artem.chikin@intel.com; jamaral@ualberta.ca; karim2@ualberta.ca;
   etiotto@ca.ibm.com
CR Aversa R, 2005, PARALLEL COMPUT, V31, P1013, DOI 10.1016/j.parco.2005.03.009
   BOLLINGER SW, 1991, IEEE T COMPUT, V40, P325, DOI 10.1109/12.76410
   Bull J., 1999, EUR WORKSH OPENMP
   Bull J. M., 2012, IWOMP 12
   Chennupati G, 2018, LECT NOTES COMPUT SC, V10724, P114, DOI 10.1007/978-3-319-72971-8_6
   Chikin A., 2018, pattent Application, Patent No. 15918334
   Dagum L., 1998, IEEE COMPUTATIONAL S
   Daoud MI, 2008, J PARALLEL DISTR COM, V68, P399, DOI 10.1016/j.jpdc.2007.05.015
   Eichenberger A. E., 2013, OPENMP ERA LOW POWER
   ELREWINI H, 1990, J PARALLEL DISTR COM, V9, P138, DOI 10.1016/0743-7315(90)90042-N
   Fauzia N, 2015, INT SYM CODE GENER, P12, DOI 10.1109/CGO.2015.7054183
   Gera P, 2018, INT SYM PERFORM ANAL, P139, DOI 10.1109/ISPASS.2018.00027
   Ghane M., 2015, OPENMP HETEROGENOUS
   Grobelny E, 2007, SIMUL-T SOC MOD SIM, V83, P721, DOI 10.1177/0037549707084939
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Ipek E, 2005, LECT NOTES COMPUT SC, V3648, P196
   Jia Z., 2018, DISSECTING NVIDIA VO
   Kaleem R, 2014, INT CONFER PARA, P151, DOI 10.1145/2628071.2628088
   Laukemann J., 2018, AUTOMATED INSTRUCTIO
   Lee BC, 2007, PROCEEDINGS OF THE 2007 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING PPOPP'07, P249, DOI 10.1145/1229428.1229479
   Liao CH, 2007, CONCURR COMP-PRACT E, V19, P2317, DOI 10.1002/cpe.1174
   Liao S, 2007, I S BIOMED IMAGING, P5, DOI 10.1109/ISBI.2007.356774
   Lloyd T., 2018, WAMCA 2018
   Pallipuram VK, 2015, J SUPERCOMPUT, V71, P162, DOI 10.1007/s11227-014-1292-9
   Rolls Daniel, 2010, Proceedings of the 18th IEEE International Conference on Program Comprehension (ICPC 2010), P50, DOI 10.1109/ICPC.2010.36
   Singh K, 2007, CONCURR COMP-PRACT E, V19, P2219, DOI 10.1002/cpe.1171
   Snavely A, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P149, DOI 10.1109/WWC.2001.990754
   Valero-Lara P., 2014, COMPUTER PHYS COMMUN, V185
   Valero-Lara P., 2017, CONCURRENCY COMPUTAT, V29
   Wang Z., 2009, PRINCIPLES PRACTICE
   Wolf ME, 1996, PROCEEDINGS OF THE 29TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE - MICRO-29, P274, DOI 10.1109/MICRO.1996.566468
   Xingfu Wu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P181, DOI 10.1109/CSE.2011.42
NR 32
TC 5
Z9 5
U1 0
U2 0
PY 2019
BP 353
EP 362
DI 10.1109/IPDPSW.2019.00068
UT WOS:000543704600052
DA 2023-11-16
ER

PT J
AU Ardakani, A
   Condo, C
   Ahmadi, M
   Gross, WJ
AF Ardakani, Arash
   Condo, Carlo
   Ahmadi, Mehdi
   Gross, Warren J.
TI An Architecture to Accelerate Convolution in Deep Neural Networks
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Convolutional neural networks; deep neural network; machine learning;
   hardware implementation; pattern recognition; very large scale
   integration (VLSI)
AB In the past few years, the demand for real-time hardware implementations of deep neural networks (DNNs), especially convolutional neural networks (CNNs), has dramatically increased, thanks to their excellent performance on a wide range of recognition and classification tasks. When considering real-time action recognition and video/image classification systems, latency is of paramount importance. Therefore, applications strive to maximize the accuracy while keeping the latency under a given application-specific maximum: in most cases, this threshold cannot exceed a few hundred milliseconds. Until now, the research on DNNs has mainly focused on achieving a better classification or recognition accuracy, whereas very few works in literature take in account the computational complexity of the model. In this paper, we propose an efficient computational method, which is inspired by a computational core of fully connected neural networks, to process convolutional layers of state-of-the-art deep CNNs within strict latency requirements. To this end, we implemented our method customized for VGG and VGG-based networks which have shown state-of-the-art performance on different classification/recognition data sets. The implementation results in 65-nm CMOS technology show that the proposed accelerator can process convolutional layers of VGGNet up to 9.5 times faster than state-of-the-art accelerators reported to-date while occupying 3.5 mm(2).
C1 [Ardakani, Arash; Condo, Carlo; Gross, Warren J.] McGill Univ, Dept Elect & Comp Engn, Montreal, PQ H3A 0E9, Canada.
   [Ahmadi, Mehdi] Polytech Montreal, Dept Comp Engn, Montreal, PQ H3T 1J4, Canada.
RP Ardakani, A (corresponding author), McGill Univ, Dept Elect & Comp Engn, Montreal, PQ H3A 0E9, Canada.
EM arash.ardakani@mail.mcgill.ca; carlo.condo@mail.mcgill.ca;
   mehdi.ahmadi@polymtl.ca; warren.gross@mcgill.ca
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Ardakani A., 2016, ARXIV PREPRINT ARXIV, V3, P1
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Ardakani A, 2016, INT SYM TURBO CODES, P216, DOI 10.1109/ISTC.2016.7593108
   Cavigelli L., 2015, P 25 EDITION GREAT L, P199, DOI [10.1145/2742060.2743766, DOI 10.1145/2742060.2743766]
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen TYH, 2015, SenSys'15: Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems, P155, DOI 10.1145/2809695.2809711
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chollet F., 2015, KERAS
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2016, ICLR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Knag Phil, 2016, 2016 IEEE Symposium on VLSI Circuits (VLSI-Circuits), DOI 10.1109/VLSIC.2016.7573526
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Labs H. P., TECH REP, P1
   Lane ND, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P117, DOI 10.1145/2699343.2699349
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1998, MNIST DATABASE HANDW
   Mettler Toledo Inc, DDR4 SDRAM AUT
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Moreno Felix, 2008, IECON 2008 - 34th Annual Conference of IEEE Industrial Electronics Society, P2445, DOI 10.1109/IECON.2008.4758340
   Netzer Y., 2011, READING DIGITS NATUR, V2, P5
   Pullini A, 2018, IEEE T CIRCUITS-II, V65, P1094, DOI 10.1109/TCSII.2017.2652982
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smithson S. C., 2016, P 35 INT C COMP AID, P1, DOI DOI 10.1145/2966986.2967058
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang S., 2017, CHAIN NN ENERGY EFFI
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
NR 41
TC 75
Z9 76
U1 1
U2 30
PD APR
PY 2018
VL 65
IS 4
BP 1349
EP 1362
DI 10.1109/TCSI.2017.2757036
UT WOS:000427578800017
DA 2023-11-16
ER

PT J
AU Paim, G
   Amrouch, H
   da Costa, EAC
   Bampi, S
   Henkel, J
AF Paim, Guilherme
   Amrouch, Hussam
   da Costa, Eduardo Antonio Cesar
   Bampi, Sergio
   Henkel, Joerg
TI Bridging the Gap Between Voltage Over-Scaling and Joint Hardware
   Accelerator-Algorithm Closed-Loop
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
DT Article
DE Timing; Hardware; Logic gates; Encoding; Heuristic algorithms;
   Standards; Runtime; Voltage over-scaling; timing errors; closed-loops
ID DESIGN METHODOLOGY; ARCHITECTURE; IMAGE
AB Voltage over-scaling (VOS) optimizes energy while causing timing errors due to an unsustainable clock frequency. Many algorithms, such as in multimedia and machine learning applications, are capable of tolerating such errors. VOS has never been investigated in hardware accelerators running closed-loop algorithms. As the errors impact most decisions and actions in the subsequent steps, closed-loops dynamically change the execution flow. Timing errors should be evaluated by an accurate gate-level simulation, but a large gap still remains: how these timing errors propagate from the underlying hardware all the way up to the entire algorithm run, where they just may degrade the performance and quality of service of the application at stake? This paper tackles this issue showing a framework for VOS investigation, embracing any kind of application. Our framework simulates the VOS-induced timing errors at gate-level, dynamically linking the hardware result with the algorithm and vice versa during the evolution of the runtime of the application. The state-of-the-art VOS literature for video encoding application fails to assess the ultimate impacts of VOS-induced timing errors, as current works open the encoding loops. Unlike those, our work investigates the ultimate impact of a hardware accelerator dynamically carrying through to the video encoder all VOS-induced timing errors and preserving the full compliance to the standard. We employ a parallel sum of absolute differences (SAD) hardware accelerator as a case study. We assess the performance of the overall encoder under varying timing guardbands. Next, it is demonstrated that, under VOS, the ultimate impact in compression efficiency is related to the video's motion intensity. Additionally, the advantages of timing guardband controlled reduction are clearly quantified in our results by virtue of the framework. Reducing at maximum 9.5% the clock frequency, energy savings (up to 16.5% in energy/operation) are achieved in SAD for video compression.
C1 [Paim, Guilherme; Bampi, Sergio] Univ Fed Rio Grande Sul UFRGS, Grad Program Microelect PGMICRO, BR-91501970 Porto Alegre, RS, Brazil.
   [Amrouch, Hussam] Univ Stuttgart, Chair Semicond Test & Reliabil STAR, D-70174 Stuttgart, Germany.
   [da Costa, Eduardo Antonio Cesar] Univ Catolica Pelotas UCPel, Grad Program Elect & Comp, BR-96015560 Pelotas, RS, Brazil.
   [Henkel, Joerg] Karlsruhe Inst Technol KIT, Chair Embedded Syst CES, D-76131 Karlsruhe, Germany.
RP Paim, G (corresponding author), Univ Fed Rio Grande Sul UFRGS, Grad Program Microelect PGMICRO, BR-91501970 Porto Alegre, RS, Brazil.
EM gppaim@inf.ufrgs.br; amrouch@iti.uni-stuttgart.de;
   eduardo.costa@ucpel.edu.br; bampi@inf.ufrgs.br; henkel@kit.edu
CR Afzali-Kusha H, 2020, INT SYM QUAL ELECT, P67, DOI [10.1109/isqed48828.2020.9137039, 10.1109/ISQED48828.2020.9137039]
   Afzali-Kusha H, 2020, IEEE T VLSI SYST, V28, P1207, DOI 10.1109/TVLSI.2020.2978874
   Amrouch H, 2019, IEEE T COMPUT, V68, P1647, DOI 10.1109/TC.2019.2916869
   Amrouch H, 2017, DES AUT CON, DOI 10.1145/3061639.3062331
   [Anonymous], 2019, VLSI ARCHITECTURES F
   [Anonymous], 2019, DEGRADATION AWARE CE
   Bossen Frank, 2013, JCTVCL1100, V7
   Brkic S, 2017, 2017 25TH TELECOMMUNICATION FORUM (TELFOR), P246
   Brkic S, 2017, IEEE T INFORM THEORY, V63, P6295, DOI 10.1109/TIT.2017.2741466
   Cai H, 2016, IEEE INT SYMP NANO, P203, DOI 10.1145/2950067.2950101
   Chen JA, 2013, IEEE T VLSI SYST, V21, P1322, DOI 10.1109/TVLSI.2012.2205953
   Chen MY, 2014, BIOMED CIRC SYST C, P628, DOI 10.1109/BioCAS.2014.6981804
   Enomoto T, 2013, ASIA S PACIF DES AUT, P75, DOI 10.1109/ASPDAC.2013.6509563
   Han J, 2016, IEEE T CIRCUITS-II, V63, P984, DOI 10.1109/TCSII.2016.2538158
   He K, 2013, IEEE T CIRC SYST VID, V23, P961, DOI 10.1109/TCSVT.2013.2243658
   Jeon D, 2012, IEEE T CIRCUITS-II, V59, P952, DOI 10.1109/TCSII.2012.2231036
   Kammoun A, 2020, IEEE T CIRC SYST VID, V30, P4340, DOI 10.1109/TCSVT.2019.2954749
   Liu RF, 2011, IEEE J EM SEL TOP C, V1, P343, DOI 10.1109/JETCAS.2011.2165749
   Liu Y, 2010, IEEE T VLSI SYST, V18, P517, DOI 10.1109/TVLSI.2009.2012863
   Masera M, 2017, IEEE T CIRC SYST VID, V27, P2714, DOI 10.1109/TCSVT.2016.2595320
   Mohanty BK, 2020, IEEE T CIRC SYST VID, V30, P4944, DOI 10.1109/TCSVT.2020.2966376
   Myers J, 2016, IEEE J SOLID-ST CIRC, V51, P31, DOI 10.1109/JSSC.2015.2477046
   Oliveira PAM, 2017, IEEE T CIRC SYST VID, V27, P1066, DOI 10.1109/TCSVT.2016.2515378
   Paim G, 2020, IEEE T CIRC SYST VID, V30, P3814, DOI 10.1109/TCSVT.2019.2945763
   Paim G, 2019, IEEE T CIRCUITS-I, V66, P680, DOI 10.1109/TCSI.2018.2868513
   Salamin S, 2019, I SYMPOS LOW POWER E
   Sedighi B, 2014, I SYMPOS LOW POWER E, P201, DOI 10.1145/2627369.2627638
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tu FB, 2019, IEEE T CIRC SYST VID, V29, P892, DOI 10.1109/TCSVT.2018.2812781
   Vangal S, 2020, J LOW POWER ELECT AP, V10, DOI 10.3390/jlpea10020016
   Varatkar GV, 2006, ISLPED '06: PROCEEDINGS OF THE 2006 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P113, DOI 10.1109/LPE.2006.4271817
   Varatkar GV, 2008, IEEE T VLSI SYST, V16, P1399, DOI 10.1109/TVLSI.2008.2000675
   Wang SH, 2017, IEEE T CIRC SYST VID, V27, P380, DOI 10.1109/TCSVT.2015.2511858
   Weibrich M., 2017, P 27 INT S POW TIM M, P1
   Weissbrich M., 2019, Integration, The VLSI Journal, V69, P120, DOI 10.1016/j.vlsi.2019.01.002
   Zervakis G, 2019, IEEE T CIRCUITS-II, V66, P607, DOI 10.1109/TCSII.2018.2869025
   Zervakis G, 2018, IEEE T VLSI SYST, V26, P1204, DOI 10.1109/TVLSI.2018.2803202
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
NR 42
TC 3
Z9 3
U1 2
U2 6
PD JAN
PY 2022
VL 32
IS 1
BP 398
EP 410
DI 10.1109/TCSVT.2021.3059229
UT WOS:000742183600035
DA 2023-11-16
ER

PT C
AU Diamantopoulos, D
   Hagleitner, C
AF Diamantopoulos, Dionysios
   Hagleitner, Christoph
GP IEEE
TI HelmGemm: Managing GPUs and FPGAs for transprecision GEMM workloads in
   containerized environments
SO 2019 IEEE 30TH INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2019)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 30th IEEE International Conference on Application-Specific Systems,
   Architectures and Processors (ASAP)
CY JUL 15-17, 2019
CL Cornell Tech, New York, NY
HO Cornell Tech
DE cloud computing; coherent accelerators; container; energy saving; FPGA;
   transprecision computing
AB Major global vendors, including Google, IBM, Facebook and Amazon, have recently provided containerized system configurations as a competitive alternative to traditional hypervisor-based virtualization thanks to their rapid deployment, efficiency, compatibility, and maintainability. Similar to traditional cloud environments, energy consumption still constitutes the lion's share of overall infrastructure operating expenses. Most public and private cloud providers have coupled their datacenters with accelerators such as GPUs and FPGAs to improve the energy efficiency of their systems. However, it remains a challenging task to manage such heterogeneous systems and share resources in multi-tenant environments while improving energy efficiency. To address this need, we propose HelmGemm, a system-level component to support energy-efficient computing on CPU GPU FPGA heterogeneous architectures for container services. HelmGemm is application-specific to workloads featuring the BLAS3 GEMM routine and allows precision selection across the computational progress, i.e. a technique that recently gave rise to the term "transprecision computing". By evaluating HelmGemm on a POWER9 system with 4 x V100 GPUs and 2x9V3 FPGAs, we succeeded in improving the average energy efficiency by up to 2.3x in containerized configurations across three representative GEMM-based cloud applications in the field of machine learning, i.e. for speech recognition, language modeling, and deep neural networks.
C1 [Diamantopoulos, Dionysios; Hagleitner, Christoph] IBM Res, Zurich, Switzerland.
RP Diamantopoulos, D (corresponding author), IBM Res, Zurich, Switzerland.
EM did@zurich.ibm.com; hle@zurich.ibm.com
CR [Anonymous], 2015, ACM COMPUT SURV, DOI DOI 10.1145/
   Kang Dong-Ki, 2016, J MOBILE NETWORKS AP
   Kayiran O., 2014, 47 ANN IEEE ACM MICR
   Kim Daehyeok, 2019, NSDI
   Licht Johannes de Fine, 2018, TRANSFORMATIONS HIGH
   Malossi A. C. I., 2018, DATE
   Redmon J., 2018, P IEEE C COMP VIS PA, P1
NR 7
TC 5
Z9 6
U1 0
U2 0
PY 2019
BP 71
EP 74
DI 10.1109/ASAP.2019.00-27
UT WOS:000574772800018
DA 2023-11-16
ER

PT J
AU Hrinivich, WT
   Lee, J
AF Hrinivich, William Thomas
   Lee, Junghoon
TI Artificial intelligence-based radiotherapy machine parameter
   optimization using reinforcement learning
SO MEDICAL PHYSICS
DT Article
DE artificial intelligence; deep&#8208; Q learning; optimization;
   reinforcement learning; treatment planning; volumetric modulated arc
   therapy
ID VOLUMETRIC MODULATED ARC; TREATMENT PLAN OPTIMIZATION; THERAPY; IMRT
AB Purpose To develop and evaluate a volumetric modulated arc therapy (VMAT) machine parameter optimization (MPO) approach based on deep-Q reinforcement learning (RL) capable of finding an optimal machine control policy using previous prostate cancer patient CT scans and contours, and applying the policy to new cases to rapidly produce deliverable VMAT plans in a simplified beam model.
   Methods A convolutional deep-Q network was employed to control the dose rate and multileaf collimator of a C-arm linear accelerator model using the current dose distribution and machine parameter state as input. A Q-value was defined as the discounted cumulative cost based on dose objectives, and experience-replay RL was performed to determine a policy to minimize the Q-value. A two-dimensional network design was employed which optimized each opposing leaf pair independently while monitoring the corresponding dose plane blocked by those leaves. This RL approach was applied to CT and contours from 40 retrospective prostate cancer patients. The dataset was split into training (15 patients) and validation (5 patients) groups to optimize the network, and its performance was tested in an independent cohort of 20 patients by comparing RL-based dose distributions to conformal arcs and clinical intensity modulated radiotherapy (IMRT) delivering a prescription dose of 78 Gy in 40 fractions.
   Results Mean +/- SD execution time of the RL VMAT optimization was 1.5 +/- 0.2 s per slice. In the test cohort, mean +/- SD (P-value) planning target volume (PTV), bladder, and rectum dose were 80.5 +/- 2.0 Gy (P < 0.001), 44.2 +/- 14.6 Gy (P < 0.001), and 43.7 +/- 11.1 Gy (P < 0.001) for RL VMAT compared to 81.6 +/- 1.1 Gy, 51.6 +/- 12.9 Gy, and 36.0 +/- 12.3 Gy for clinical IMRT.
   Conclusions RL was applied to VMAT MPO using clinical patient contours without independently optimized treatment plans for training and achieved comparable target and normal tissue dose to clinical plans despite the application of a relatively simple network design originally developed for video-game control. These results suggest that extending a RL approach to a full three-dimensional beam model could enable rapid artificial intelligence-based optimization of deliverable treatment plans, reducing the time required for radiotherapy planning without requiring previous plans for training.
C1 [Hrinivich, William Thomas; Lee, Junghoon] Johns Hopkins Univ, Dept Radiat Oncol & Mol Radiat Sci, Baltimore, MD 21287 USA.
RP Lee, J (corresponding author), Johns Hopkins Univ, Dept Radiat Oncol & Mol Radiat Sci, Baltimore, MD 21287 USA.
EM jun-ghoon@jhu.edu
CR Babier A, 2020, MED PHYS, V47, P297, DOI 10.1002/mp.13896
   Barkousaraie AS, 2020, MED PHYS, V47, P880, DOI 10.1002/mp.13986
   Bedford JL, 2013, J APPL CLIN MED PHYS, V14, P172, DOI 10.1120/jacmp.v14i2.4136
   Bertsekas D, 2019, REINFORCEMENT LEARNI
   Bohoudi O, 2017, RADIOTHER ONCOL, V125, P439, DOI 10.1016/j.radonc.2017.07.028
   Breedveld S, 2019, EUR J OPER RES, V277, P1, DOI 10.1016/j.ejor.2018.08.019
   Cui SN, 2020, MED PHYS, V47, pE127, DOI 10.1002/mp.14140
   Das IJ, 2008, TG106 THER PHYS COMM
   El Naqa I, 2020, MED PHYS, V47, pE125, DOI 10.1002/mp.14088
   Fan JW, 2019, MED PHYS, V46, P370, DOI 10.1002/mp.13271
   Good D, 2013, INT J RADIAT ONCOL, V87, P176, DOI 10.1016/j.ijrobp.2013.03.015
   Kingma DP., 2017, ARXIV
   Lamb J, 2017, CUREUS J MED SCIENCE, V9, DOI 10.7759/cureus.1618
   Lee HH, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-019-39131-3, 10.1038/s41598-019-46417-z]
   Li XY, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba5eb
   McIntosh C, 2017, PHYS MED BIOL, V62, P5926, DOI 10.1088/1361-6560/aa71f8
   Men CH, 2010, MED PHYS, V37, P5787, DOI 10.1118/1.3491675
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Monz M, 2008, PHYS MED BIOL, V53, P985, DOI 10.1088/0031-9155/53/4/011
   Nguyen D, 2020, MED PHYS, V47, P837, DOI 10.1002/mp.13955
   Otto K, 2008, MED PHYS, V35, P310, DOI 10.1118/1.2818738
   Palma D, 2008, INT J RADIAT ONCOL, V72, P996, DOI 10.1016/j.ijrobp.2008.02.047
   Peng F, 2012, PHYS MED BIOL, V57, P4569, DOI 10.1088/0031-9155/57/14/4569
   Shen CY, 2020, MED PHYS, V47, P2329, DOI 10.1002/mp.14114
   SHEN CY, 2019, PHYS MED BIOL, V64
   Shiraishi S, 2016, MED PHYS, V43, P378, DOI 10.1118/1.4938583
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Tian Z, 2015, MED PHYS, V42, P2841, DOI 10.1118/1.4919742
   Unkelbach J, 2015, MED PHYS, V42, P1367, DOI 10.1118/1.4908224
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wieser HP, 2017, MED PHYS, V44, P2556, DOI 10.1002/mp.12251
NR 34
TC 14
Z9 14
U1 5
U2 30
PD DEC
PY 2020
VL 47
IS 12
BP 6140
EP 6150
DI 10.1002/mp.14544
EA NOV 2020
UT WOS:000585935500001
DA 2023-11-16
ER

PT C
AU Zhou, Z
   Li, C
   Wei, XC
   Wang, XY
   Sun, GY
AF Zhou, Zhe
   Li, Cong
   Wei, Xuechao
   Wang, Xiaoyang
   Sun, Guangyu
GP ACM
TI GNNear: Accelerating Full-Batch Training of Graph Neural Networks with
   Near-Memory Processing
SO PROCEEDINGS OF THE 2022 31ST INTERNATIONAL CONFERENCE ON PARALLEL
   ARCHITECTURES AND COMPILATION TECHNIQUES, PACT 2022
DT Proceedings Paper
CT 31st International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY OCT 08-12, 2022
CL Discovery Partners Inst, Chicago, IL
HO Discovery Partners Inst
DE near-memory processing; graph neural networks; domain-specific
   accelerator; machine learning
AB Recently, Graph Neural Networks (GNNs) have become state-of-the-art algorithms for analyzing non-euclidean graph data. However, to realize efficient GNN training is challenging, especially on large graphs. The reasons are many-folded: 1) GNN training incurs a substantial memory footprint. Full-batch training on large graphs even requires hundreds to thousands of gigabytes of memory. 2) GNN training involves both memory-intensive and computation-intensive operations, challenging current CPU/GPU platforms. 3) The irregularity of graphs can result in severe resource underutilization and load-imbalance problems.
   This paper presents a GNNear accelerator to tackle these challenges. GNNear adopts a DIMM-based memory system to provide sufficient memory capacity. To match the heterogeneous nature of GNN training, we offload the memory-intensive Reduce operations to in-DIMM Near-Memory-Engines (NMEs), making full use of the high aggregated local bandwidth. We adopt a Centralized-Acceleration-Engine (CAE) to process the computation-intensive Update operations. We further propose several optimization strategies to deal with the irregularity of input graphs and improve GNNear's performance. Comprehensive evaluations on 16 GNN training tasks demonstrate that GNNear achieves 30.8x / 2.5x geomean speedup and 79.6x / 7.3x (geomean) higher energy efficiency compared to Xeon E5-2698-v4 CPU and NVIDIA V100 GPU.
C1 [Zhou, Zhe] Peking Univ, Sch Integrated Circuits, Sch Comp Sci, Beijing, Peoples R China.
   [Li, Cong] Peking Univ, Sch Integrated Circuits, Beijing, Peoples R China.
   [Wei, Xuechao] Peking Univ, Sch Comp Sci, Alibaba Grp, Beijing, Peoples R China.
   [Wang, Xiaoyang] Peking Univ, Sch Comp Sci, Beijing, Peoples R China.
   [Sun, Guangyu] Peking Univ, Sch Integrated Circuits, Beijing Adv Innovat Ctr Integrated Circuits, Beijing, Peoples R China.
RP Sun, GY (corresponding author), Peking Univ, Sch Integrated Circuits, Beijing Adv Innovat Ctr Integrated Circuits, Beijing, Peoples R China.
EM zhou.zhe@pku.edu.cn; leesou@pku.edu.cn; xuechao.wei@pku.edu.cn;
   yaoer@pku.edu.cn; gsun@pku.edu.cn
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Alandoli Mohammed, 2016, 2016 7 INT C COMP SC, P1, DOI DOI 10.1109/CSIT.2016.7549467
   [Anonymous], PYRAPL
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   Asghari-Moghaddam H, 2016, INT SYMP MICROARCH
   Bojchevski A, 2018, Arxiv, DOI arXiv:1707.03815
   Cai ZK, 2021, PROCEEDINGS OF THE SIXTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS '21), P130, DOI 10.1145/3447786.3456233
   Chen JX, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3248-y
   Chen J, 2018, Arxiv, DOI arXiv:1801.10247
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XB, 2020, Arxiv, DOI arXiv:2009.12495
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen Zhaodong, 2020, IEEE ACM INT C COMP
   Chi YZ, 2016, PROC INT CONF DATA, P409, DOI 10.1109/ICDE.2016.7498258
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Dai GH, 2019, IEEE T COMPUT AID D, V38, P640, DOI 10.1109/TCAD.2018.2821565
   DGL, DGL FRAM
   Duran Alberto Garcia, 2017, ADV NEURAL INFORM PR, P5119
   Fan SH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2478, DOI 10.1145/3292500.3330673
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Fey Matthias, 2019, ICLR WORKSHOP REPRES
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gandhi S, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P551
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Ge L, 2019, IEEE INT CONF MOB DA, P234, DOI 10.1109/MDM.2019.00-52
   Geng T, 2020, Arxiv, DOI arXiv:1908.10834
   Geng Tong, 2021, MICRO54 54 ANN IEEE, P1051
   Gibert J, 2012, PATTERN RECOGN, V45, P3072, DOI 10.1016/j.patcog.2012.01.009
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu P, 2020, ANN I S COM, P804, DOI 10.1109/ISCA45697.2020.00071
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Hamilton WL, 2017, ADV NEUR IN, V30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henrion Isaac, 2017, NEURAL MESSAGE PASSI
   Hewlett Packard, CACTI
   Hong B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P682, DOI 10.1109/MICRO.2018.00061
   Hsieh K, 2016, CONF PROC INT SYMP C, P204, DOI 10.1109/ISCA.2016.27
   Hu WH, 2021, Arxiv, DOI arXiv:2005.00687
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Intel, INT VTUN PROF
   Jia Zhihao, 2020, MLSYS, P187
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jouppi Norman P, 2021, ANN INT S COMP ARCH
   Kalamkar D, 2019, Arxiv, DOI [arXiv:1905.12322, DOI 10.48550/ARXIV.1905.12322]
   Ke L., 2021, IEEE MICRO
   Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070
   Kim D, 2018, IEEE T COMPUT AID D, V37, P2360, DOI 10.1109/TCAD.2018.2858358
   Kim Jin Hyun, 2021, 2021 IEEE HOT CHIPS, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lee YS, 2021, IEEE ACCESS, V9, P68561, DOI 10.1109/ACCESS.2021.3077294
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Li S, 2020, IEEE COMPUT ARCHIT L, V19, P106, DOI 10.1109/LCA.2020.2973991
   Liang SW, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415645
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Liu Liu, 2021, MICRO 54 54 ANN IEEE, P1309
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X, 2022, IEEE-CAA J AUTOMATIC, V9, P205, DOI 10.1109/JAS.2021.1004311
   Lo YC, 2018, DRUG DISCOV TODAY, V23, P1538, DOI 10.1016/j.drudis.2018.05.010
   Ma LX, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P443
   Md V, 2021, Arxiv, DOI arXiv:2104.06700
   Meaney PJ, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2429031
   Micron, 32GB X72 ECC DR 288
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mirhoseini A, 2020, Arxiv, DOI arXiv:2004.10746
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Mohoney J, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P533
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nie W, 2021, IEEE T MULTIMEDIA
   Park J., 2021, MICRO, P268, DOI 10.1145
   Pytorch, PYT PROF
   Qian GC, 2021, PROC CVPR IEEE, P11678, DOI 10.1109/CVPR46437.2021.01151
   Stevens JR, 2021, Arxiv, DOI arXiv:2103.10836
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rjzamora, PYNVML
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schuiki F, 2019, IEEE T COMPUT, V68, P484, DOI 10.1109/TC.2018.2876312
   Shchur O., 2018, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Xinkai, 2021, IEEE T COMPUT AID D
   Stokes JM, 2020, CELL, V180, P688, DOI 10.1016/j.cell.2020.01.021
   Sun WY, 2021, CONF PROC INT SYMP C, P237, DOI 10.1109/ISCA52012.2021.00027
   Szklarczyk D, 2019, NUCLEIC ACIDS RES, V47, pD607, DOI 10.1093/nar/gky1131
   Thorpe John, 2021, 15 SYSTEMS DESIGN IM, V21, P495
   Tripathy A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/sc41405.2020.00074
   Wang HR, 2020, Arxiv, DOI arXiv:2005.00406
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang X, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P950, DOI 10.1145/3292500.3330989
   Wang Y, 2018, IEEE T PARALL DISTR, V29, P1428, DOI 10.1109/TPDS.2018.2791440
   Wang YK, 2021, Arxiv, DOI arXiv:2006.06608
   Wang Zhao, 2020, C ADV COMP ARCH, P73
   Welling M., 2016, P INT C LEARN REPR
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Xie XF, 2021, INT S HIGH PERF COMP, P570, DOI 10.1109/HPCA51647.2021.00055
   Xu K, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337923
   Xu QG, 2020, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR42600.2020.00570
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yin SY, 2019, IEEE T PARALL DISTR, V30, P146, DOI 10.1109/TPDS.2018.2858230
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zeng H., 2020, ICLR
   Zeng HQ, 2020, Arxiv, DOI arXiv:1907.04931
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhai ZL, 2020, IEEE ACCESS, V8, P65591, DOI 10.1109/ACCESS.2020.2985279
   Zhang BY, 2020, IEEE INT CONF ASAP, P61, DOI 10.1109/ASAP49362.2020.00019
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang D., 2014, P 23 INT S HIGH PERF, P85
   Zhang G, 2019, PR MACH LEARN RES, V97
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhao J, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2347, DOI 10.1145/3292500.3330686
   Zhao L, 2020, IEEE T INTELL TRANSP, V21, P3848, DOI 10.1109/TITS.2019.2935152
   Zhou Z, 2021, DES AUT CON, P1009, DOI 10.1109/DAC18074.2021.9586181
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu R, 2019, PROC VLDB ENDOW, V12, P2094, DOI 10.14778/3352063.3352127
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
NR 123
TC 1
Z9 1
U1 1
U2 1
PY 2022
BP 54
EP 68
DI 10.1145/3559009.3569670
UT WOS:001071492700004
DA 2023-11-16
ER

PT J
AU Kang, D
   Oh, J
   Choi, J
   Yi, Y
   Ha, S
AF Kang, Duseok
   Oh, Jinwoo
   Choi, Jongwoo
   Yi, Youngmin
   Ha, Soonhoi
TI Scheduling of Deep Learning Applications Onto Heterogeneous Processors
   in an Embedded Device
SO IEEE ACCESS
DT Article
DE Deep learning scheduling; genetic algorithm; heterogeneous processor;
   mobile device
AB As the need for on-device machine learning is increasing recently, embedded devices tend to be equipped with heterogeneous processors that include a multi-core CPU, a GPU, and/or a DNN accelerator called a Neural Processing Unit (NPU). In the scheduling of multiple deep learning (DL) applications in such embedded devices, there are several technical challenges. First, a task can be mapped onto a single core or any number of available cores. So we need to consider various possible configurations of CPU cores. Second, embedded devices usually apply Dynamic Voltage and Frequency Scaling (DVFS) to reduce energy consumption at run-time. We need to consider the effect of DVFS in the profiling of task execution times. Third, to avoid overheat condition, it is recommended to limit the core utilization. Lastly, some cores will be shut-down at run-time if core utilization is not high enough, in case the hot-plugging option is turned on. In this paper, we propose a scheduling technique based on Genetic Algorithm to run DL applications on heterogeneous processors, considering all those issues. First, we aim to optimize the throughput of a single deep learning application. Next, we aim to find the Pareto optimal scheduling of multiple DL applications in terms of the response time of each DL application and overall energy consumption under the given throughput constraints of DL applications. The proposed technique is verified with real DL networks running on two embedded devices, Galaxy S9 and HiKey970.
C1 [Kang, Duseok; Oh, Jinwoo; Choi, Jongwoo; Ha, Soonhoi] Seoul Natl Univ, Dept Comp Engn, Seoul 08826, South Korea.
   [Yi, Youngmin] Univ Seoul, Dept Elect & Comp Engn, Seoul 02504, South Korea.
RP Ha, S (corresponding author), Seoul Natl Univ, Dept Comp Engn, Seoul 08826, South Korea.
EM sha@snu.ac.kr
CR Abadi M, 2015, PRELIMINARY WHITE PA
   Ali HI, 2015, 23RD EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED, AND NETWORK-BASED PROCESSING (PDP 2015), P701, DOI 10.1109/PDP.2015.57
   Alzantot Moustafa, 2017, MobiSys, V2017, P7, DOI 10.1145/3089801.3089805
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Arabnejad H, 2014, IEEE T PARALL DISTR, V25, P682, DOI 10.1109/TPDS.2013.57
   BARUAH SK, 1990, PROCEEDINGS : 11TH REAL-TIME SYSTEMS SYMPOSIUM, P182, DOI 10.1109/REAL.1990.128746
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Frumusanu A., 2018, SAMSUNG GALAXY S9 S9
   Henan Zhao, 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Howard A. G., 2017, ABS170404861 CORR
   Huang GL, 2017, IEEE ICC
   Iandola F.N., 2016, CORR ABS160207360
   Kang D., 2018, P INT C COMP AID DES, P1
   Lane N. D., 2016, P 15 INT C INF PROC, P1
   Liu Y, 2017, INT J EMBED SYST, V9, P147, DOI 10.1504/IJES.2017.083734
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/344188
   Pangrle B. M., 1987, Proceedings of the 1987 IEEE International Conference on Computer Design: VLSI in Computers and Processors - ICCD '87 (Cat. No.87CH2473-7), P42
   Roy SK, 2019, INT SYMP OBJECT COMP, P185, DOI 10.1109/ISORC.2019.00042
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sun K, 2019, 33RD INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2019), P453, DOI [10.1109/ICOIN.2019.8718131, 10.1109/icoin.2019.8718131]
   Tae-ho Shin, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P165, DOI 10.1109/ASPDAC.2011.5722178
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Xie GQ, 2016, J SYST ARCHITECT, V70, P3, DOI 10.1016/j.sysarc.2016.04.008
   Yang H, 2009, DES AUT TEST EUROPE, P69
NR 29
TC 20
Z9 20
U1 1
U2 5
PY 2020
VL 8
BP 43980
EP 43991
DI 10.1109/ACCESS.2020.2977496
UT WOS:000524710900050
DA 2023-11-16
ER

PT J
AU Panchbhaiyye, V
   Ogunfunmi, T
AF Panchbhaiyye, Vineet
   Ogunfunmi, Tokunbo
TI An Efficient FIFO Based Accelerator for Convolutional Neural Networks
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Convolution neural networks; FPGA; Machine learning; Dataflow
AB Over the last decade, Convolutional Neural Networks (CNNs) have become the go to technique to perform tasks in deep learning applications such as computer vision, speech recognition, etc. LeCun et al (Nature 521(7553), 436-44) 2015. Even though CNNs are very efficient at these tasks they are not suitable for embedded applications due to the limited power budget. In this work we present an improved architecture to process the convolution layers in a CNN. This work is based on our earlier architecture which uses FIFO (First In First Out memory)s to accelerate CNNs. Panchbhaiyye and Ogunfunmi 2020. The architecture presented takes advantage of sparsity in CNN layer's inputs and outputs to achieve performance improvement. We evaluate the proposed improvement on 16 bit floating point and 8 bit integer data types and find that this leads to more than 13% improvement in the processing time of convolution layers for VGG16 with float16 data type. Also, we show how this architecture can be used to compute fully connected layers. Overall we are able to exceed the performance of state-of-the-art architectures by more than 1.65x using an inexpensive Pynq Z1 board running at 100Mhz.
C1 [Panchbhaiyye, Vineet; Ogunfunmi, Tokunbo] Santa Clara Univ, Dept Elect & Comp Engn, 500 El Camino Real, Santa Clara, CA 95053 USA.
RP Ogunfunmi, T (corresponding author), Santa Clara Univ, Dept Elect & Comp Engn, 500 El Camino Real, Santa Clara, CA 95053 USA.
EM vpanchbhaiyye@scu.edu; togunfunmi@scu.edu
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], P 14 INT C ART INT S
   Ardakani A, 2018, IEEE T CIRCUITS-I, V65, P1349, DOI 10.1109/TCSI.2017.2757036
   ARM, 2010, AMBA 4 AXI4 STREAM P
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Digilent, 2019, PYNQ Z1 REF MAN
   Dumoulin V., 2018, GUIDE CONVOLUTION AR
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Han Song, 2016, ICLR
   Han SY, 2018, INT J DIGIT EARTH, V11, P451, DOI 10.1080/17538947.2017.1330366
   Hennessy J.L., 2017, COMPUTER ARCHITECTUR
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lin DD, 2016, PR MACH LEARN RES, V48
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Nair V., 2010, ICML, P807
   Panchbhaiyye V, 2020, INT CONF ACOUST SPEE, P1758, DOI [10.1109/icassp40776.2020.9053228, 10.1109/ICASSP40776.2020.9053228]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang XF, 2020, IEEE COMMUN SURV TUT, V22, P869, DOI 10.1109/COMST.2020.2970550
   Xilinx, 2018, PYNQ PYTH LIB V2 4
   Xilinx, VIVADO DESIGN SUITE
NR 27
TC 4
Z9 4
U1 2
U2 21
PD OCT
PY 2021
VL 93
IS 10
SI SI
BP 1117
EP 1129
DI 10.1007/s11265-020-01632-0
EA FEB 2021
UT WOS:000619890800001
DA 2023-11-16
ER

PT C
AU Wöhrle, H
   Alvarez, MD
   Schlenke, F
   Walsemann, A
   Karagounis, M
   Kirchner, F
AF Woehrle, Hendrik
   Alvarez, Mariela De Lucas
   Schlenke, Fabian
   Walsemann, Alexander
   Karagounis, Michael
   Kirchner, Frank
GP IEEE
TI Surrogate Model based Co-Optimization of Deep Neural Network Hardware
   Accelerators
SO 2021 IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)
CY AUG 09-11, 2021
CL ELECTR NETWORK
DE FDX/FDSOI; hardware acceleration; deep learning; bayesian optimization
AB In this paper, we present an ASIC based on 22FDX/FDSOI technology for the detection of atrial fibrillation in human electrocardiograms using neural networks. The ASIC consists of a RISC-V core for supporting software components and an application-specific machine learning IP core (ML-IP), which is used to implement the computationally intensive inference. The ASIC was designed for maximum energy efficiency. A special feature of the ML-IP is its modular, generic and scalable design of the ML-IP which allows to specify the quantization of each computational operation, the degree of parallelization and the architecture of the neural network. This in turn allows the use of ML-based optimization techniques to perform co-optimization for hardware design and architecture of the neural network (NNs). Here, a multi-objective optimization of the overall system is performed with respect to computational efficiency at a given classification accuracy and speed by using a multi-objective optimization, which is carried out using a probabilistic surrogate model. This model tries to find the optimal neural network architecture with a minimum number of training, simulation and evaluation steps.
C1 [Woehrle, Hendrik; Schlenke, Fabian] Dortmund Univ Appl Sci & Arts, Dept Informat Technol, Dortmund, Germany.
   [Alvarez, Mariela De Lucas; Kirchner, Frank] Univ Bremen, Dept Math & Comp Sci, Bremen, Germany.
   [Walsemann, Alexander; Karagounis, Michael] Dortmund Univ Appl Sci & Arts, Fac Elect Engn, Dortmund, Germany.
RP Wöhrle, H (corresponding author), Dortmund Univ Appl Sci & Arts, Dept Informat Technol, Dortmund, Germany.
EM hendrik.woehrle@fh-dortmund.de; delucas@uni-bremen.de;
   fabian.schlenke@fh-dortmund.de; alexander.walsemann@fh-dortmund.de;
   michael.karagounis@fh-dortmund.de; frank.kirchner@uni-bremen.de
CR Bader J, 2011, EVOL COMPUT, V19, P45, DOI 10.1162/EVCO_a_00009
   Bergstra J., 1994, ALGORITHMS HYPER PAR
   Bergstra J, 2012, RANDOM SEARCH HYPER
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Guerreiro AP, 2016, EVOL COMPUT, V24, P521, DOI 10.1162/EVCO_a_00188
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Koehler F, 2010, EUR J HEART FAIL, V12, P1354, DOI 10.1093/eurjhf/hfq199
   Kumar S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040626
   Lo CY, 2018, PROC INT CONF ADV, P105, DOI 10.1109/ATC.2018.8587580
   Magyar A, 2015, 2 RISC V WORKSH
   Ozaki Y., 2020, GENETIC EVOLUTIONARY, P9
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Snoek J., 2012, ADV NEURAL INFORM PR, V25, P1
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039
   Wohrle H., 2017, SENSORS SWITZERLAND, V17
NR 18
TC 2
Z9 2
U1 0
U2 4
PY 2021
BP 40
EP 45
DI 10.1109/MWSCAS47672.2021.9531708
UT WOS:000784758700010
DA 2023-11-16
ER

PT C
AU Moshovos, A
   Albericio, J
   Judd, P
   Delmas, A
   Sharify, S
   Mahmoud, M
   Hetherington, T
   Nikolic, M
   Stuart, DM
   Siu, K
   Poulos, Z
   Aamodt, T
   Jerger, NE
AF Moshovos, Andreas
   Albericio, Jorge
   Judd, Patrick
   Delmas, Alberto
   Sharify, Sayeh
   Mahmoud, Mostafa
   Hetherington, Tayler
   Nikolic, Milos
   Stuart, Dylan Malone
   Siu, Kevin
   Poulos, Zissis
   Aamodt, Tor
   Jerger, Natalie Enright
GP IEEE
TI Identifying and Exploiting Ineffectual Computations to Enable Hardware
   Acceleration of Deep Learning
SO 2018 16TH IEEE INTERNATIONAL NEW CIRCUITS AND SYSTEMS CONFERENCE
   (NEWCAS)
SE IEEE International New Circuits and Systems Conference
DT Proceedings Paper
CT 16th IEEE International New Circuits and Systems Conference (NEWCAS)
CY JUN 24-27, 2018
CL Montreal, CANADA
AB This article summarizes somde of our work on hardware accelerators lir inference with Deep Learning Neural Networks (DNNs). Early success in hardware acceleration for DNNs exploited the computation structure and the significant reuse in their access stream. Our approach to further boost benefits has been to first identify properties in the value stream of DNNs which we can exploit at the hardware level to improve execution time, reduce off- and on-chip communication and storage, resulting in higher energy efficiency and execution time reduction. We have been focusing on properties that are difficult or impossible to discern in advance. These properties include values that are zero or near zero and that prove ineffectual, values that have reduced precision needs, or even the hit-level content of values that lead to ineffectual computations. The presented designs cover a spectrum of choices in terms of area cost, energy efficiency, and relative execution time performance and target a variety of hardware devices from embedded systems to server class machines. A key characteristic of these designs is that they reward but do not requires advances in model design that increase the aforementioned properties (such as reduced precision or sparsity) and thus provide a safe path to innovation.
C1 [Moshovos, Andreas; Judd, Patrick; Delmas, Alberto; Sharify, Sayeh; Mahmoud, Mostafa; Nikolic, Milos; Stuart, Dylan Malone; Siu, Kevin; Poulos, Zissis; Jerger, Natalie Enright] Univ Toronto, Toronto, ON, Canada.
   [Albericio, Jorge; Judd, Patrick] NVIDIA, Toronto, ON, Canada.
   [Hetherington, Tayler; Aamodt, Tor] Univ British Columbia, Vancouver, BC, Canada.
RP Moshovos, A (corresponding author), Univ Toronto, Toronto, ON, Canada.
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Courbariaux M, 2015, ADV NEURAL INFORM PR
   Delmas A., 2018, CORR
   Delmas Alberto, 2017, CORR
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Han S., 2016, ARXIV160201528CS
   Iandola Forrest N., 2016, P IEEE C COMPUTER VI
   Jonghong Kim, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7510, DOI 10.1109/ICASSP.2014.6855060
   Judd P., 2015, ARXIV151105236V4CSLG
   Judd P., 2016, MICRO 49
   Judd P, 2016, P 2016 INT C SUPERCO, P1
   Lascorz A. D., 2018, CORR
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park Jongsoo, 2017, ICLR
   Sharify S., 2018, CORR
   Sharify S., 2017, CORR
   Sharify S, 2018, DES AUT CON, DOI 10.1145/3195970.3196072
   Venkatesh G., 2016, CORR
   Warden Peter, 2016, LOW PRECISION MATRIX
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zhang SJ, 2016, INT SYMP MICROARCH
NR 24
TC 1
Z9 1
U1 0
U2 1
PY 2018
BP 356
EP 360
UT WOS:000458806300083
DA 2023-11-16
ER

PT J
AU Alagappan, G
   Ong, JR
   Yang, ZF
   Ang, TYL
   Zhao, WJ
   Jiang, Y
   Zhang, WZ
   Png, CE
AF Alagappan, Gandhi
   Ong, Jun Rong
   Yang, Zaifeng
   Ang, Thomas Yong Long
   Zhao, Weijiang
   Jiang, Yang
   Zhang, Wenzu
   Png, Ching Eng
TI Leveraging AI in Photonics and Beyond
SO PHOTONICS
DT Article
DE AI; photonics; soft computing; inverse design; photonics computing;
   photonics accelerator; forward; inverse model; deep learning; machine
   learning; neural networks; electromagnetics; microwave; computational
   electromagnetics; EMC; EMI; quantum computing
ID NEURAL-NETWORK; MODELING APPROACH; GAUSSIAN PROCESS; INVERSE DESIGN;
   MICROWAVE; OPTIMIZATION; CLASSIFICATION; EQUIVALENT; CIRCUITS; HYBRID
AB Artificial intelligence (AI) techniques have been spreading in most scientific areas and have become a heated focus in photonics research in recent years. Forward modeling and inverse design using AI can achieve high efficiency and accuracy for photonics components. With AI-assisted electronic circuit design for photonics components, more advanced photonics applications have emerged. Photonics benefit a great deal from AI, and AI, in turn, benefits from photonics by carrying out AI algorithms, such as complicated deep neural networks using photonics components that use photons rather than electrons. Beyond the photonics domain, other related research areas or topics governed by Maxwell's equations share remarkable similarities in using the help of AI. The studies in computational electromagnetics, the design of microwave devices, as well as their various applications greatly benefit from AI. This article reviews leveraging AI in photonics modeling, simulation, and inverse design; leveraging photonics computing for implementing AI algorithms; and leveraging AI beyond photonics topics, such as microwaves and quantum-related topics.
C1 [Alagappan, Gandhi; Ong, Jun Rong; Yang, Zaifeng; Ang, Thomas Yong Long; Zhao, Weijiang; Jiang, Yang; Zhang, Wenzu; Png, Ching Eng] ASTAR, Inst High Performance Comp, Dept Elect & Photon, Singapore 138632, Singapore.
RP Png, CE (corresponding author), ASTAR, Inst High Performance Comp, Dept Elect & Photon, Singapore 138632, Singapore.
EM gandhi@ihpc.a-star.edu.sg; ongjr@ihpc.a-star.edu.sg;
   yang_zaifeng@ihpc.a-star.edu.sg; thomas-ang@ihpc.a-star.edu.sg;
   zhaow@ihpc.a-star.edu.sg; Jiang_Yang@ihpc.a-star.edu.sg;
   zhangwz@ihpc.a-star.edu.sg; pngce@ihpc.a-star.edu.sg
CR AI and Compute,, 2018, AI COMP
   Alagappan G, 2021, NEURAL COMPUT APPL, V33, P2195, DOI 10.1007/s00521-020-05061-9
   Alagappan G, 2019, J OPT SOC AM B, V36, P2636, DOI 10.1364/JOSAB.36.002636
   Alagappan G, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/ab00d5
   Alagappan G, 2019, J MOD OPTIC, V66, P557, DOI 10.1080/09500340.2018.1552331
   Alkhateeb A, 2018, IEEE ACCESS, V6, P37328, DOI 10.1109/ACCESS.2018.2850226
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ambs Pierre, 2010, Advances in Optical Technologies, DOI 10.1155/2010/372652
   An SS, 2020, OPT EXPRESS, V28, P31932, DOI 10.1364/OE.401960
   [Anonymous], 2017, MAKING AI WORK EVERY
   [Anonymous], NEW YORK TIMES
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   Arjovsky M, 2016, PR MACH LEARN RES, V48
   August M, 2017, PHYS REV A, V95, DOI 10.1103/PhysRevA.95.012335
   Bangari V, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2945540
   Banner R, 2018, ADV NEURAL INFORM PR, P5151
   Barmada S, 2020, IEEE T MAGN, V56, DOI 10.1109/TMAG.2019.2957197
   Bhardwaj S, 2019, IEEE ANTENN WIREL PR, V18, P2244, DOI 10.1109/LAWP.2019.2933181
   BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108
   Boyd R., 2020, NONLINEAR OPTICS, V4th ed.
   Bulgarevich DS, 2021, SCI REP-UK, V11, P1
   Cao Y, 2003, SIAM J SCI COMPUT, V24, P1076, DOI 10.1137/S1064827501380630
   Cao ZW, 2019, IEEE ACCESS, V7, P135023, DOI 10.1109/ACCESS.2019.2932749
   CAULFIELD HJ, 1989, P IEEE, V77, P1573, DOI 10.1109/5.40669
   Cavin RK, 2012, P IEEE, V100, P1720, DOI 10.1109/JPROC.2012.2190155
   Ceperic V., 2012, P INT S EL COMP, P1
   Cerezo M, 2021, NAT REV PHYS, V3, P625, DOI 10.1038/s42254-021-00348-9
   Chakraborty I, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.014063
   Chen J, 2018, PROC CVPR IEEE, P6286, DOI 10.1109/CVPR.2018.00658
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P4889, DOI 10.1109/TIP.2018.2839524
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen SYC, 2020, IEEE ACCESS, V8, P141007, DOI 10.1109/ACCESS.2020.3010470
   Chen X., 2018, COMPUTATIONAL METHOD
   Chen XD, 2020, PROG ELECTROMAGN RES, V167, P67
   Chen XZ, 2020, IEEE ACCESS, V8, P146450, DOI 10.1109/ACCESS.2020.3015043
   Chen Y., 2020, ARXIV200404815
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Chu HS, 2007, 2007 WORKSHOP ON COMPUTATIONAL ELECTROMAGNETICS IN TIME-DOMAIN, P163
   Chu HS, 2007, INT J RF MICROW C E, V17, P179, DOI 10.1002/mmce.20212
   Coarer FDL, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2836985
   Colburn S, 2021, COMMUN PHYS-UK, V4, DOI 10.1038/s42005-021-00568-6
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   De Ridder S, 2020, IEEE T ELECTROMAGN C, V62, P2538, DOI 10.1109/TEMC.2020.2980790
   Denholm SJ, 2020, J DAIRY SCI, V103, P9355, DOI 10.3168/jds.2020-18328
   Devabhaktuni V, 2013, IEEE T ELECTROMAGN C, V55, P385, DOI 10.1109/TEMC.2012.2214223
   DRAGONE C, 1989, J LIGHTWAVE TECHNOL, V7, P479, DOI 10.1109/50.16884
   Driscoll JB, 2018, IEEE INT CONF GROUP
   Elbir AM, 2020, IEEE T WIREL COMMUN, V19, P1677, DOI 10.1109/TWC.2019.2956146
   Erricolo D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ELECTROMAGNETICS IN ADVANCED APPLICATIONS (ICEAA), P1377, DOI [10.1109/ICEAA.2019.8879110, 10.1109/iceaa.2019.8879110]
   Es-saidi S., 2021, HYBRID FLATLAND META
   Ewe W.B., 2021, ARXIV210912279
   Fang MYS, 2019, OPT EXPRESS, V27, P14009, DOI 10.1364/OE.27.014009
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Feng F, 2016, IEEE T MICROW THEORY, V64, P60, DOI 10.1109/TMTT.2015.2504099
   Gao J, 2020, IEEE ACCESS, V8, P211380, DOI 10.1109/ACCESS.2020.3039269
   Gianfagna C, 2017, J ELECTRON MATER, V46, P4963, DOI 10.1007/s11664-017-5487-8
   Giannakis I., 2018, P 17 INT C GROUND PE, P1
   Giannakis I, 2019, IEEE T GEOSCI REMOTE, V57, P4417, DOI 10.1109/TGRS.2019.2891206
   Gibson W.C., 2021, METHOD MOMENTS ELECT
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodman W, 2005, INTRO FOURIER OPTICS, V3rd
   Guo LS, 2019, 2019 INTERNATIONAL APPLIED COMPUTATIONAL ELECTROMAGNETICS SOCIETY SYMPOSIUM - CHINA (ACES), VOL 1, DOI 10.23919/aces48530.2019.9060707
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   Haug T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/abc81f
   Hayt W., 2020, ENG ELECTROMAGNETICS
   He Kaiming, 2016, PROC CVPR IEEE
   Hecht E., 2017, OPTICS
   Home,, LUM COMP
   Huang AD, 2016, IEEE T MICROW THEORY, V64, P2519, DOI 10.1109/TMTT.2016.2586055
   Huang H, 2020, IEEE T VEH TECHNOL, V69, P1065, DOI 10.1109/TVT.2019.2949122
   Huang HJ, 2019, IEEE T VEH TECHNOL, V68, P3027, DOI 10.1109/TVT.2019.2893928
   Huang QL, 2018, IEEE T ELECTROMAGN C, V60, P1640, DOI 10.1109/TEMC.2018.2797132
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Hubara I, 2018, J MACH LEARN RES, V18
   Hughes TW, 2018, ACS PHOTONICS, V5, P4781, DOI 10.1021/acsphotonics.8b01522
   Hung SY, 2020, IEEE T COMP PACK MAN, V10, P314, DOI 10.1109/TCPMT.2019.2956485
   Inampudi S, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5033327
   Isaksson M, 2005, IEEE T MICROW THEORY, V53, P3422, DOI 10.1109/TMTT.2005.855742
   Jain SK, 2016, INT J MICROW WIREL T, V8, P1111, DOI 10.1017/S1759078715000616
   Jiang JQ, 2021, NAT REV MATER, V6, P679, DOI 10.1038/s41578-020-00260-1
   Jiang JQ, 2019, ACS NANO, V13, P8872, DOI 10.1021/acsnano.9b02371
   Jiang JQ, 2019, NANO LETT, V19, P5366, DOI 10.1021/acs.nanolett.9b01857
   Jiang Y., 2021, PROC IEEE INT JOINT
   Jiang Y, 2019, IEEE T MICROW THEORY, V67, P565, DOI 10.1109/TMTT.2018.2882481
   Jin J. M., 2015, FINITE ELEMENT METHO, P243
   Jin J, 2020, IEEE ACCESS, V8, P82273, DOI 10.1109/ACCESS.2020.2991890
   Jin J, 2019, IEEE T MICROW THEORY, V67, P4140, DOI 10.1109/TMTT.2019.2932738
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kim C, 2020, IEEE ACCESS, V8, P188853, DOI 10.1109/ACCESS.2020.3031607
   Kim H, 2018, IEEE T ELECTROMAGN C, V60, P2049, DOI 10.1109/TEMC.2017.2782704
   Kingma Diederik P, 2013, ARXIV13126114
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Kong J. A., 1975, THEORY ELECTROMAGNET
   Kudyshev ZA, 2021, ACS PHOTONICS, V8, P34, DOI 10.1021/acsphotonics.0c00960
   Kuo MJ, 2008, 2008 ASIA-PACIFIC SYMPOSIUM ON ELECTROMAGNETIC COMPATIBILITY AND 19TH INTERNATIONAL ZURICH SYMPOSIUM ON ELECTROMAGNETIC COMPATIBILITY, VOLS 1 AND 2, P670, DOI 10.1109/APEMC.2008.4559964
   Lai P.Y., 2021, SCI REP-UK, V11, P1
   Larochelle H., 2011, AISTATS, V15, P29
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li S., 2019, ARXIV191008721
   Li SH, 2019, ASIA PACIF MICROWAVE, P96, DOI [10.1109/APMC46564.2019.9038488, 10.1109/apmc46564.2019.9038488]
   Li YS, 2019, IEEE T COMP PACK MAN, V9, P1244, DOI 10.1109/TCPMT.2019.2920974
   Lillicrap T. P., 2015, INT C LEARNING REPRE
   Lim AEJ, 2014, IEEE J SEL TOP QUANT, V20, DOI 10.1109/JSTQE.2013.2293274
   Lin T, 2020, IEEE WIREL COMMUN LE, V9, P103, DOI 10.1109/LWC.2019.2943466
   Lio GE, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8030065
   Lio GE, 2021, ADV MATER, V33, DOI 10.1002/adma.202008644
   Liu, 2019, ARXIV190102069
   Liu W, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120755
   Liu WC, 2019, DES AUT TEST EUROPE, P1483, DOI [10.23919/date.2019.8715195, 10.23919/DATE.2019.8715195]
   Liu WY, 2017, IEEE T MICROW THEORY, V65, P2043, DOI 10.1109/TMTT.2017.2657501
   Liu ZC, 2018, NANO LETT, V18, P6570, DOI 10.1021/acs.nanolett.8b03171
   Liu ZH, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8110489
   Lockwood O., 2020, P AAAI C ART INT INT, V16, P245, DOI DOI 10.1609/AIIDE.V16I1.7437
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Ma W, 2021, NAT PHOTONICS, V15, P77, DOI 10.1038/s41566-020-0685-y
   Ma W, 2018, ACS NANO, V12, P6326, DOI 10.1021/acsnano.8b03569
   Magerl M, 2015, 2015 10th International Workshop on the Electromagnetic Compatibility of Integrated Circuits, P258, DOI 10.1109/EMCCompo.2015.7358368
   Malkiel I, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0060-7
   Maniloff E, 2019, 2019 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC)
   Mao LC, 2019, IEEE ACCESS, V7, P172231, DOI 10.1109/ACCESS.2019.2956508
   Massa A, 2019, IEEE ANTENN WIREL PR, V18, P2225, DOI 10.1109/LAWP.2019.2916369
   Mehrabian A, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2957443
   Mehrabian A, 2018, INT SOC DESIGN CONF, P169
   Mellit A, 2010, ENERG CONVERS MANAGE, V51, P771, DOI 10.1016/j.enconman.2009.10.034
   Mesaritakis C, 2019, OPT LETT, V44, P1218, DOI 10.1364/OL.44.001218
   Mesaritakis C, 2013, J OPT SOC AM B, V30, P3048, DOI 10.1364/JOSAB.30.003048
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Minkov M, 2020, ACS PHOTONICS, V7, P1729, DOI 10.1021/acsphotonics.0c00327
   Miscuglio M, 2019, APL MATER, V7, DOI 10.1063/1.5109689
   Mkadem F, 2011, IEEE T MICROW THEORY, V59, P913, DOI 10.1109/TMTT.2010.2098041
   Monzó-Cabrera J, 2008, IEEE T MICROW THEORY, V56, P2972, DOI 10.1109/TMTT.2008.2007318
   Nadell CC, 2019, OPT EXPRESS, V27, P27523, DOI 10.1364/OE.27.027523
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Nejadriahi H., 2017, ARXIV171102500
   Ohira M, 2021, IEEE MICROW WIREL CO, V31, P638, DOI 10.1109/LMWC.2021.3062874
   Ong JR, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2020.2982990
   Özbay AG, 2021, DATA-CENTRIC ENG, V2, DOI 10.1017/dce.2021.7
   Paudel U, 2020, OPT EXPRESS, V28, P1225, DOI 10.1364/OE.379264
   Peng HT, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2840448
   Pfau D, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.033429
   Pilozzi L, 2021, NANOTECHNOLOGY, V32, DOI 10.1088/1361-6528/abd508
   Pilozzi L, 2018, COMMUN PHYS-UK, V1, DOI 10.1038/s42005-018-0058-8
   Poulton CV, 2019, IEEE J SEL TOP QUANT, V25, DOI 10.1109/JSTQE.2019.2908555
   Pozar D.M., 2011, MICROWAVE ENG
   Qi ST, 2020, IEEE J MULTISCALE MU, V5, P83, DOI 10.1109/JMMCT.2020.2995811
   Qiang XG, 2018, NAT PHOTONICS, V12, P534, DOI 10.1038/s41566-018-0236-y
   Rayas-Sánchez JE, 2004, IEEE T MICROW THEORY, V52, P420, DOI 10.1109/TMTT.2003.820897
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Regué JR, 2001, IEEE T ELECTROMAGN C, V43, P520, DOI 10.1109/15.974631
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roshani S., 2021, J I ELECT COMPUT, V3, P1, DOI [10.33969/JIEC.2021.31001, DOI 10.33969/JIEC.2021.31001]
   Sacher WD, 2015, J LIGHTWAVE TECHNOL, V33, P901, DOI 10.1109/JLT.2015.2392784
   Saleh B. E. A., 2007, FUNDAMENTALS PHOTONI
   Sarma S.D., 2019, ARXIV190303516
   Schierholz M, 2021, IEEE ACCESS, V9, P34423, DOI 10.1109/ACCESS.2021.3061788
   Sekhri E, 2020, 15TH INTERNATIONAL CONFERENCE MECHATRONIC SYSTEMS AND MATERIALS, MSM'20, P147, DOI 10.1109/msm49833.2020.9202393
   Shanmukhappa T, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351818
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shi D, 2021, IEEE T ELECTROMAGN C, V63, P443, DOI 10.1109/TEMC.2020.3019801
   Shi D, 2018, IEEE T ELECTROMAGN C, V60, P1621, DOI 10.1109/TEMC.2018.2797053
   Shixiang Gu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3389, DOI 10.1109/ICRA.2017.7989385
   Shu YF, 2019, IEEE T MICROW THEORY, V67, P1790, DOI 10.1109/TMTT.2019.2905238
   Steinbrecher GR, 2019, NPJ QUANTUM INFORM, V5, DOI 10.1038/s41534-019-0174-7
   Sun J., 2013, IEEE J SEL TOP QUANT, V20, P264, DOI [10.1109/JSTQE.2013.2293316, DOI 10.1109/JSTQE.2013.2293316]
   Taflove A, 2005, ELECTRICAL ENGINEERING HANDBOOK, P629, DOI 10.1016/B978-012170960-0/50046-3
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tak J, 2018, IEEE ANTENN WIREL PR, V17, P2008, DOI 10.1109/LAWP.2018.2857807
   Takiguchi K, 2011, OPT LETT, V36, P1140, DOI 10.1364/OL.36.001140
   Tangsopha W, 2017, INT ELECT ENG CONGR
   Trinchero R, 2018, IEEE T ELECTROMAGN C, V60, P1627, DOI 10.1109/TEMC.2018.2797481
   Tsang L., 2004, SCATTERING ELECTROMA, VVolume 27
   Tucker RS, 2010, NAT PHOTONICS, V4, P405, DOI 10.1038/nphoton.2010.162
   Ulaby F. T., 2015, FUNDAMENTALS APPL EL, V7th
   Vandoorne K, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4541
   Vaswani A, 2017, ADV NEUR IN, V30
   Waltman V.E, VOSVIEWER
   Wang ZY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P53, DOI 10.1109/CBS.2018.8612197
   Wang ZY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2145, DOI 10.1109/ROBIO.2015.7419091
   Watson PM, 1997, IEEE T MICROW THEORY, V45, P2515, DOI 10.1109/22.643868
   Wiecha PR, 2020, NANO LETT, V20, P329, DOI 10.1021/acs.nanolett.9b03971
   Williamson IAD, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2930455
   Wise DF, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.010316
   Wittek P, 2014, QUANTUM MACHINE LEARNING: WHAT QUANTUM COMPUTING MEANS TO DATA MINING, P1
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Yang L, 2012, OPT EXPRESS, V20, P13560, DOI 10.1364/OE.20.013560
   Yang ZF, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8578, DOI 10.1109/ICASSP39728.2021.9414745
   Yang ZF, 2020, IEEE I C VI COM I PR, P467, DOI [10.1109/VCIP49819.2020.9301791, 10.1109/vcip49819.2020.9301791]
   Yao HM, 2020, IEEE ACCESS, V8, P21028, DOI 10.1109/ACCESS.2020.2969569
   Yao HM, 2019, IEEE ANTENN WIREL PR, V18, P192, DOI 10.1109/LAWP.2018.2885570
   Yao HM, 2017, IEEE ANTENNAS PROP, P973, DOI 10.1109/APUSNCURSINRSM.2017.8072529
   Yao HM, 2016, IEEE C ELECTR PERFOR, P171, DOI 10.1109/EDAPS.2016.7893155
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   You J.B., 2021, ARXIV210900288
   Zhang S., 2016, IEEE MTT S INT MICRO, P1
   Zhang X.M., 2019, ARXIV190402165
   Zhao P, 2020, IEEE T MICROW THEORY, V68, P1390, DOI 10.1109/TMTT.2019.2963639
   Zhu L, 2016, IEEE MICROW WIREL CO, V26, P131, DOI 10.1109/LMWC.2016.2516761
NR 200
TC 5
Z9 5
U1 6
U2 44
PD FEB
PY 2022
VL 9
IS 2
AR 75
DI 10.3390/photonics9020075
UT WOS:000766535500001
DA 2023-11-16
ER

PT C
AU Delestrac, P
   Torres, L
   Novo, D
AF Delestrac, Paul
   Torres, Lionel
   Novo, David
BE Fabelo, H
   Ortega, S
   Skavhaug, A
TI Demystifying the TensorFlow Eager Execution of Deep Learning Inference
   on a CPU-GPU Tandem
SO 2022 25TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD)
SE EUROMICRO Conference Proceedings
DT Proceedings Paper
CT 25th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2022
CL Maspalomas, SPAIN
DE ML frameworks; TensorFlow eager execution; profiling; CPU-GPU tandem
AB Machine Learning (ML) frameworks are tools that facilitate the development and deployment of ML models. These tools are major catalysts of the recent explosion in ML models and hardware accelerators thanks to their high programming abstraction. However, such an abstraction also obfuscates the runtime execution of the model and complicates the understanding and identification of performance bottlenecks. In this paper, we demystify how a modern ML framework manages code execution from a high-level programming language. We focus our work on the TensorFlow eager execution, which remains obscure to many users despite being the simplest mode of execution in TensorFlow. We describe in detail the process followed by the runtime to run code on a CPU-GPU tandem. We propose new metrics to analyze the framework's runtime performance overhead. We use our metrics to conduct in-depth analysis of the inference process of two Convolutional Neural Networks (CNNs) (LeNet-5 and ResNet-50) and a transformer (BERT) for different batch sizes. Our results show that GPU kernels execution need to be long enough to exploit thread parallelism, and effectively hide the runtime overhead of the ML framework.
C1 [Delestrac, Paul; Torres, Lionel; Novo, David] Univ Montpellier, CNRS, LIRMM, Montpellier, France.
RP Delestrac, P (corresponding author), Univ Montpellier, CNRS, LIRMM, Montpellier, France.
EM paul.delestrac@lirmm.fr; lionel.torres@lirmm.fr; david.novo@lirmm.fr
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Agrawal A., 2019, P MACHINE LEARNING S
   Chen TQ, 2015, Arxiv, DOI arXiv:1512.01274
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S, 2014, Arxiv, DOI arXiv:1410.0759
   cloud.google.com, IN DEPTH LOOK GOOGLE
   developer.nvidia. com, CUDA RELEASE 10 2 89
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   docs.nvidia.com, NVIDIA CUPTI
   Elshawi R, 2021, CLUSTER COMPUT, V24, P2017, DOI 10.1007/s10586-021-03240-4
   gite.lirmm. fr, TENSORFLOW EAGER RUN
   github.com, TENSORFLOW LARGE SCA
   Gleeson J., 2021, P MACHINE LEARNING S
   Guennebaud G., 2010, EIGEN V3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   huggingface. co, BERT BASE MODEL UNCA
   Kirk D, 2007, P INT S MEMORY MANAG
   Larsen Rasmus Munk, 2019, TENSORFLOW GRAPH OPT
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li C., 2020, 2020 IEEE 13 INT C C
   Li C, 2020, P INT PARALLEL DISTR
   mxnet.apache.org, MXNET DOCUMENTATION
   Paszke A., 2019, P ADV NEUR INF PROC, P8024
   pytorch.org, PYTORCH PROFILER
   Tensorboard.dev, US
   tensorflow.org, TENSORFLOW PROFILER
   tensorflow.org, TENSORFLOW KERAS APP
   tensorflow.org, TENSORFLOW GUIDE CRE
   tensorflow.org, ALL SYMBOLS TENSORFL
NR 30
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 446
EP 455
DI 10.1109/DSD57027.2022.00066
UT WOS:000946536500047
DA 2023-11-16
ER

PT C
AU Ding, RY
   Cheng, GY
   Wang, SY
   Ding, AA
   Fei, YS
AF Ding, Ruyi
   Cheng Gongye
   Wang, Siyue
   Ding, Aidong Adam
   Fei, Yunsi
GP ACM
TI EMShepherd: Detecting Adversarial Samples via Side-channel Leakage
SO PROCEEDINGS OF THE 2023 ACM ASIA CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY, ASIA CCS 2023
DT Proceedings Paper
CT 18th ACM ASIA Conference on Computer and Communications Security (ASIA
   CCS)
CY JUL 10-14, 2023
CL Melbourne, AUSTRALIA
DE Side-channel attacks; Adversarial machine learning; Neural network
   hardware
AB Deep Neural Networks (DNN) are vulnerable to adversarial perturbations - small changes crafted deliberately on the input to mislead the model for wrong predictions. Adversarial attacks have disastrous consequences for deep learning empowered critical applications. Existing defense and detection techniques both require extensive knowledge of the model, testing inputs and even execution details. They are not viable for general deep learning implementations where the model internal is unknown, a common 'black-box' scenario for model users. Inspired by the fact that electromagnetic (EM) emanations of a model inference are dependent on both operations and data and may contain footprints of different input classes, we propose a framework, EMShepherd, to capture EM traces of model execution, perform processing on traces and exploit them for adversarial detection. Only benign samples and their EM traces are used to train the adversarial detector: a set of EM classifiers and class-specific unsupervised anomaly detectors. When the victim model system is under attack by an adversarial example, the model execution will be different from executions for the known classes, and the EM trace will be different. We demonstrate that our air-gapped EMShepherd can effectively detect different adversarial attacks on a commonly used FPGA deep learning accelerator for both Fashion MNIST and CIFAR-10 datasets. It achieves a 100% detection rate on most types of adversarial samples, which is comparable to the state-of-the-art 'white-box' software-based detectors.
C1 [Ding, Ruyi; Cheng Gongye; Wang, Siyue; Ding, Aidong Adam; Fei, Yunsi] Northeastern Univ, Boston, MA 02115 USA.
RP Ding, RY (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM ding.ruy@northeastern.edu; gongye.c@northeastern.edu;
   wang.siy@northeastern.edu; a.ding@northeastern.edu;
   y.fei@northeastern.edu
CR aaronia- shop, 2022, PROBE SET PBS 2 INCL
   Agrawal D, 2002, LECT NOTES COMPUT SC, V2523, P29
   Agrawal D., 2002, INT WKSHP CRYPTOGRAP
   [Anonymous], 2021, TENSORFLOW
   Avnet, 2022, ULTRA96 V2
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Bojarski M, 2016, Arxiv, DOI [arXiv:1604.07316, DOI 10.48550/ARXIV.1604.07316]
   Carlini N., 2017, AISEC CCS, P3
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chari S, 2002, LECT NOTES COMPUT SC, V2523, P13
   Chmielewski L, 2021, LECT NOTES COMPUT SC, V12809, P96, DOI 10.1007/978-3-030-81645-2_7
   Das D, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317934
   deepai, 2019, F SCORE DEFINITION D
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Feinman R, 2017, Arxiv, DOI arXiv:1703.00410
   Forsyth David, 2011, COMPUTER VISION MODE
   Foster KR, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-94
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghosal Deepanway, 2017, INT C IMAGE INFORM P, P1
   Grosse K, 2017, Arxiv, DOI arXiv:1702.06280
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/ARXIV.1512.03385]
   Howard A. G., 2017, ABS170404861 CORR
   Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299, DOI 10.1109/TKDE.2005.50
   intel, 2020, RUNNING AVERAGE POWE
   Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572
   Jiang PT, 2021, IEEE T IMAGE PROCESS, V30, P5875, DOI 10.1109/TIP.2021.3089943
   Kingma DP., 2017, ARXIV
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kurakin Alexey, 2016, CORR
   Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615
   Lipp Moritz, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P355, DOI 10.1109/SP40001.2021.00063
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Ma SQ, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23415
   Ma XJ, 2018, Arxiv, DOI arXiv:1801.02613
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Manning Christopher, 1999, FDN STAT NATURAL PRO
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Bhagoji AN, 2017, Arxiv, DOI arXiv:1704.02654
   Parkhi Omkar M, 2015, DEEP FACE RECOGNITIO, DOI 10.5244/C.29.41
   Rauber Jonas, 2017, WORKSHOP RELIABLE MA
   Redmon J, 2016, Arxiv, DOI arXiv:1506.02640
   Richens JG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17419-7
   Selvaraju R.R., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1611.07450
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, 10.48550/ARXIV.1409.4842, DOI 10.48550/ARXIV.1409.4842]
   Tao GH, 2018, Arxiv, DOI arXiv:1810.11580
   Teledyne LeCroy, 2022, US
   Tramer F., 2020, ADV NEURAL INFORM PR, P1633
   ultra96, 2021, WELCOME ULTRA96 PYNQ
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinogradova K, 2020, AAAI CONF ARTIF INTE, V34, P13943
   Wang SY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3264699
   Wang X, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6013
   Wang ZB, 2019, IEEE INFOCOM SER, P2512, DOI [10.1109/INFOCOM.2019.8737416, 10.1109/infocom.2019.8737416]
   xilinx, 2020, ZYNQ DPU V3 2 IP PRO
   xilinx, 2022, VITIS
   Xu WL, 2017, Arxiv, DOI arXiv:1704.01155
   Yang YJ, 2022, Arxiv, DOI arXiv:2201.09650
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
   Zhang YC, 2021, IEEE T INF FOREN SEC, V16, P4377, DOI 10.1109/TIFS.2021.3106169
   Zhou D., 2021, P IEEE CVF INT C COM, P7878
   Zhu J, 2020, IEEE ACCESS, V8, P83224, DOI 10.1109/ACCESS.2020.2988311
NR 65
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 300
EP 313
DI 10.1145/3579856.3582827
UT WOS:001053857900024
DA 2023-11-16
ER

PT J
AU Marchisio, A
   Mrazek, V
   Massa, A
   Bussolino, B
   Martina, M
   Shafique, M
AF Marchisio, Alberto
   Mrazek, Vojtech
   Massa, Andrea
   Bussolino, Beatrice
   Martina, Maurizio
   Shafique, Muhammad
TI RoHNAS: A Neural Architecture Search Framework With Conjoint
   Optimization for Adversarial Robustness and Hardware Efficiency of
   Convolutional and Capsule Networks
SO IEEE ACCESS
DT Article
DE Robustness; Perturbation methods; Optimization; Computer architecture;
   Security; Routing; Graphics processing units; Adversarial machine
   learning; Deep learning; High performance computing; Hardware
   acceleration; Adversarial robustness; energy efficiency; latency;
   memory; hardware-aware neural architecture search; evolutionary
   algorithm; deep neural networks; capsule networks
ID LEARNING-SYSTEMS; CHALLENGES; TRENDS
AB Neural Architecture Search (NAS) algorithms aim at finding efficient Deep Neural Network (DNN) architectures for a given application under given system constraints. DNNs are computationally-complex as well as vulnerable to adversarial attacks. In order to address multiple design objectives, we propose RoHNAS, a novel NAS framework that jointly optimizes for adversarial-robustness and hardware-efficiency of DNNs executed on specialized hardware accelerators. Besides the traditional convolutional DNNs, RoHNAS additionally accounts for complex types of DNNs such as Capsule Networks. For reducing the exploration time, RoHNAS analyzes and selects appropriate values of adversarial perturbation for each dataset to employ in the NAS flow. Extensive evaluations on multi - Graphics Processing Unit (GPU) - High Performance Computing (HPC) nodes provide a set of Pareto-optimal solutions, leveraging the tradeoff between the above-discussed design objectives. For example, a Pareto-optimal DNN for the CIFAR-10 dataset exhibits 86.07% accuracy, while having an energy of 38.63 mJ, a memory footprint of 11.85 MiB, and a latency of 4.47 ms.
C1 [Marchisio, Alberto] Tech Univ Wien TU Wien, Inst Comp Engn, Embedded Comp Syst Grp, A-1040 Vienna, Austria.
   [Mrazek, Vojtech] Brno Univ Technol, Fac Informat Technol, Evolvable Hardware Res Grp, Brno 60190, Czech Republic.
   [Massa, Andrea; Bussolino, Beatrice; Martina, Maurizio] Politecn Torino, VLSI Lab, Dept Elect & Telecommun, I-10129 Turin, Italy.
   [Shafique, Muhammad] New York Univ Abu Dhabi, Div Engn, eBrain Lab, Abu Dhabi, U Arab Emirates.
RP Marchisio, A (corresponding author), Tech Univ Wien TU Wien, Inst Comp Engn, Embedded Comp Syst Grp, A-1040 Vienna, Austria.
EM alberto.marchisio@tuwien.ac.at
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Achararit P, 2020, IEEE ACCESS, V8, P165319, DOI 10.1109/ACCESS.2020.3022327
   Barata C, 2019, I S BIOMED IMAGING, P841, DOI [10.1109/ISBI.2019.8759561, 10.1109/isbi.2019.8759561]
   Capra M, 2020, IEEE ACCESS, V8, P225134, DOI 10.1109/ACCESS.2020.3039858
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Cheng CH, 2018, DES AUT TEST EUROPE, P1005
   Dave S., 2022, ABS220409514 CORR, P1
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Goodfellow I., 2016, ARXIV170100160, DOI DOI 10.1038/NATURE14539
   Goodfellow Ian J., 2015, EXPLAINING HARNESSIN
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   Guesmi A, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P990, DOI 10.1145/3445814.3446747
   Guo MH, 2020, PROC CVPR IEEE, P628, DOI 10.1109/CVPR42600.2020.00071
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jiang WW, 2020, IEEE T COMPUT AID D, V39, P4154, DOI 10.1109/TCAD.2020.3012863
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kotyan S., 2021, PROC WORKSHOP ARTIF, V2640, P1
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kurakin Alexey, 2018, ICLR, DOI DOI 10.1201/9781351251389-8
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Liu Q, 2018, ASIA S PACIF DES AUT, P721, DOI 10.1109/ASPDAC.2018.8297407
   Lu Q., 2019, ABS191100105, P1
   Madry Aleksander, 2018, DEEP LEARNING MODELS
   Marchisio Alberto, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P553, DOI 10.1109/ISVLSI.2019.00105
   Marchisio A, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415731
   Marchisio A, 2021, IEEE T VLSI SYST, V29, P716, DOI 10.1109/TVLSI.2021.3059518
   Marchisio A, 2021, IEEE T COMPUT AID D, V40, P1768, DOI 10.1109/TCAD.2020.3030610
   Marchisio A, 2019, DES AUT TEST EUROPE, P964, DOI [10.23919/DATE.2019.8714922, 10.23919/date.2019.8714922]
   Marcus M. P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Pearson K., 1985, P R SOC LOND, V58, P240, DOI [DOI 10.1098/RSPL.1895.0041, 10.1098/rspl.1895.0041]
   Pham H, 2018, PR MACH LEARN RES, V80
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Sabour S., 2017, NEURAL INFORM PROCES
   Sekanina L, 2021, IEEE ACCESS, V9, P151337, DOI 10.1109/ACCESS.2021.3126685
   Sha~que M., 2021, PROC IEEEACM INT C C, P1, DOI [10.1109/ICCAD51958.2021.9643539, DOI 10.1109/ICCAD51958.2021.9643539]
   Shafique M, 2020, IEEE DES TEST, V37, P30, DOI 10.1109/MDAT.2020.2971217
   Stamoulis D, 2020, LECT NOTES ARTIF INT, V11907, P481, DOI 10.1007/978-3-030-46147-8_29
   Sun K, 2020, IEEE ACCESS, V8, P96920, DOI 10.1109/ACCESS.2020.2996282
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Venkatraman S. R., 2020, CORR, P1
   Wang DL, 2021, PROC CVPR IEEE, P6414, DOI 10.1109/CVPR46437.2021.00635
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zanc R, 2019, INT C INTELL COMP CO, P459, DOI [10.1109/ICCP48234.2019.8959715, 10.1109/iccp48234.2019.8959715]
   Zhang, 2019, P 56 ANN DES AUT C
   Zhang LJ, 2020, CURR PSYCHOL, V39, P1138, DOI 10.1007/s12144-019-0155-1
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zoph B., 2017, INT C LEARNING REPRE, P1
NR 53
TC 2
Z9 2
U1 0
U2 2
PY 2022
VL 10
BP 109043
EP 109055
DI 10.1109/ACCESS.2022.3214312
UT WOS:000870222300001
DA 2023-11-16
ER

PT J
AU Guo, Q
   Qian, YH
   Liang, XY
   Chen, JY
   Cheng, HH
AF Guo, Qian
   Qian, Yuhua
   Liang, Xinyan
   Chen, Junyu
   Cheng, Honghong
TI Multi-granulation Multi-scale Relation Network for Abstract Reasoning
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
DT Article
DE Multi-granulation; Multi-scale; Non-descending path; Abstract reasoning;
   Relation network
ID DECISION; ACCELERATOR
AB A Abstract reasoning, one of the representative works of logic learning, is to make machines intelligent. To test the intelligence of machines, researchers have proposed multiple benchmark data sets and these date sets mainly consist of a few simple geometries and traced reasoning paths. There are three issues for these data sets: (1) it is relatively easy for machines to reason the right answer from the simple geometries; (2) due to the limited number of geometric shapes, these data sets are prone to disclosure of information about reasoning; (3) all traced reasoning paths in these data sets have been known beforehand, some state-of-the-art reasoning models are specially designed according to these paths. Hence, these benchmark data sets cannot truly reflect the reasoning ability of reasoning models. To address these issues, we propose a Fashion Non-descending Path data set (FNP). FNP is designed using a mass of complex samples from Fashion-MNIST data set as objects of FNP and the non-descending path that is a more complex path as the variation directions of logical patterns. For gaining reasoning performance on FNP, inspired by the multi-granulation and multi-scale ideas, we propose a multi-granulation multi-scale relation network (M2RN) to consider the multi-wise relations rather than the simple pair-wise relations. Experimental results show that the M2RN is effective for abstract reasoning task.
C1 [Guo, Qian; Qian, Yuhua; Liang, Xinyan; Chen, Junyu; Cheng, Honghong] Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan 030006, Shanxi, Peoples R China.
   [Qian, Yuhua] Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.
   [Guo, Qian; Qian, Yuhua; Liang, Xinyan; Chen, Junyu] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
   [Cheng, Honghong] Shanxi Univ Finance & Econ, Sch Informat, Taiyuan 030012, Peoples R China.
RP Qian, YH (corresponding author), Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan 030006, Shanxi, Peoples R China.; Qian, YH (corresponding author), Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.; Qian, YH (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
EM czguoqian@163.com; jinchengqyh@126.com; liangxinyan48@163.com;
   jade199868@163.com; chhsxdx@163.com
CR [Anonymous], 2017, ARXIV171001692
   [Anonymous], 2017, ARXIV 170807747
   [成红红 Cheng Honghong], 2020, [中国科学. 信息科学, Scientia Sinica Informationis], V50, P824
   Dai WZ, 2019, ADV NEUR IN, V32
   Guo Q, 2019, 2019 IEEE INT C DAT, P620, DOI [10.1109/ICDMW.2019.00094, DOI 10.1109/ICDMW.2019.00094]
   Hou WH, 2021, INT J MACH LEARN CYB, V12, P859, DOI 10.1007/s13042-020-01206-3
   Huang YX, 2020, IEEE DATA MINING, P1070, DOI 10.1109/ICDM50108.2020.00127
   Jahrens M, 2020, IEEE IJCNN, DOI 10.1109/IJCNN48605.2020.9207319
   Jahrens M, 2019, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON APPLICATIONS OF INTELLIGENT SYSTEMS (APPIS 2019), DOI 10.1145/3309772.3309782
   Jiang ZH, 2020, INT J APPROX REASON, V119, P122, DOI 10.1016/j.ijar.2019.12.013
   Li FJ, 2019, ARTIF INTELL, V273, P37, DOI 10.1016/j.artint.2018.12.007
   Liang, IEEE T PATTERN ANAL, DOI 10.1109/TPAMI.2021.3125995
   Liang XY, 2021, IEEE T EVOLUT COMPUT, V25, P883, DOI 10.1109/TEVC.2021.3064943
   Liu KY, 2020, INT J MACH LEARN CYB, V11, P2149, DOI 10.1007/s13042-020-01107-5
   Pang JF, 2020, INT J APPROX REASON, V117, P122, DOI 10.1016/j.ijar.2019.11.008
   Qian YH, 2017, INT J APPROX REASON, V82, P119, DOI 10.1016/j.ijar.2016.12.008
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Qian YH, 2010, INFORM SCIENCES, V180, P949, DOI 10.1016/j.ins.2009.11.023
   Santoro A., 2017, ADV NEURAL INFORM PR, P4974
   Santoro Adam, 2018, INT C MACH LEARN, P4477
   Tawhid MA, 2020, INT J MACH LEARN CYB, V11, P573, DOI 10.1007/s13042-019-00996-5
   Wang D, 2020, INT J APPROX REASON, V127, P33, DOI 10.1016/j.ijar.2020.08.010
   Wang JT, 2020, IEEE T FUZZY SYST, V28, P887, DOI 10.1109/TFUZZ.2019.2953024
   Wang Y, 2020, IEEE T FUZZY SYST, V28, P1395, DOI 10.1109/TFUZZ.2019.2936801
   Wu WZ, 2017, INFORM SCIENCES, V378, P282, DOI 10.1016/j.ins.2016.03.041
   Wu WZ, 2011, INFORM SCIENCES, V181, P3878, DOI 10.1016/j.ins.2011.04.047
   Yang L, 2020, INT J APPROX REASON, V122, P47, DOI 10.1016/j.ijar.2020.04.003
   Ye DJ, 2021, INT J MACH LEARN CYB, V12, P661, DOI 10.1007/s13042-020-01195-3
   Yu H, 2020, INT J MACH LEARN CYB, V11, P1003, DOI 10.1007/s13042-019-00988-5
   Yu H, 2019, INT J APPROX REASON, V115, P32, DOI 10.1016/j.ijar.2019.09.001
   Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8
   Zhang C, 2019, PROC CVPR IEEE, P5312, DOI 10.1109/CVPR.2019.00546
   Zhao H, 2019, IEEE T FUZZY SYST, V27, P1891, DOI 10.1109/TFUZZ.2019.2892349
   Zheng K., 2019, P ADV NEUR INF PROC, P5842
NR 34
TC 4
Z9 4
U1 4
U2 17
PD JUN
PY 2022
VL 13
IS 6
BP 1751
EP 1762
DI 10.1007/s13042-021-01484-5
EA JAN 2022
UT WOS:000739230200001
DA 2023-11-16
ER

PT J
AU Yeung, GF
   Borowiec, D
   Yang, RY
   Friday, A
   Harper, R
   Garraghan, P
AF Yeung, Gingfung
   Borowiec, Damian
   Yang, Renyu
   Friday, Adrian
   Harper, Richard
   Garraghan, Peter
TI Horus: Interference-Aware and Prediction-Based Scheduling in Deep
   Learning Systems
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Graphics processing units; Interference; Kernel; Predictive models;
   Computational modeling; Production; Load modeling; Distributed systems;
   deep learning; interference; GPU utilization; cloud computing; workload
   prediction
ID SCALE
AB To accelerate the training of Deep Learning (DL) models, clusters of machines equipped with hardware accelerators such as GPUs are leveraged to reduce execution time. State-of-the-art resource managers are needed to increase GPU utilization and maximize throughput. While co-locating DL jobs on the same GPU has been shown to be effective, this can incur interference causing slowdown. In this article we propose Horus: an interference-aware and prediction-based resource manager for DL systems. Horus proactively predicts GPU utilization of heterogeneous DL jobs extrapolated from the DL model's computation graph features, removing the need for online profiling and isolated reserved GPUs. Through micro-benchmarks and job co-location combinations across heterogeneous GPU hardware, we identify GPU utilization as a general proxy metric to determine good placement decisions, in contrast to current approaches which reserve isolated GPUs to perform online profiling and directly measure GPU utilization for each unique submitted job. Our approach promotes high resource utilization and makespan reduction; via real-world experimentation and large-scale trace driven simulation, we demonstrate that Horus outperforms other DL resource managers by up to 61.5 percent for GPU resource utilization, 23.7-30.7 percent for makespan reduction and 68.3 percent in job wait time reduction.
C1 [Yeung, Gingfung; Borowiec, Damian; Friday, Adrian; Harper, Richard; Garraghan, Peter] Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4YW, England.
   [Yang, Renyu] Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
RP Yang, RY (corresponding author), Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM g.yeung1@lancaster.ac.uk; d.borowiec@lancaster.ac.uk;
   ryang1@leeds.ac.uk; a.friday@lancaster.ac.uk; r.harper@lancaster.ac.uk;
   p.garraghan@lancaster.ac.uk
CR A. M. T, SHAR TASK MACH TRANS
   Amazon Web Services Inc, 2020, AM EC2 P3 ID MACH LE
   [Anonymous], 2018, P 12 USENIX C OPERAT
   [Anonymous], 2011, P 2011 USENIX ANN TE
   [Anonymous], 2016, P INT C LEARN REPR I
   [Anonymous], 2012, P 21 INT S HIGHPERFO
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai H., 2018, P INT C LEARN REPR
   Chen Q, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P17, DOI 10.1145/3037697.3037700
   Chen Q, 2016, ACM SIGPLAN NOTICES, V51, P681, DOI 10.1145/2954679.2872368
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen Y, 2017, P 31 INT C NEURAL IN, P4467, DOI DOI 10.5555/3294996.3295200
   Cho K, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1/D14-1179, 10.3115]
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Dube P, 2019, INT SYM COMP ARCHIT, P160, DOI 10.1109/SBAC-PAD.2019.00035
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Google, 2020, GOOGL CLOUD GPUS PRI
   Gu JC, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P485
   Guz Z, 2009, IEEE COMPUT ARCHIT L, V8, P25, DOI 10.1109/L-CA.2009.4
   Han D, 2017, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR.2017.668
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hightower K, 2017, KUBERNETES RUNNING D
   Howard A. G., 2017, ABS170404861 CORR
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F.N., 2016, CORR ABS160207360
   Jeon M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P947
   Jia Xianyan, 2018, ARXIV180711205
   Jog Adwait, 2014, GPGPU 7, DOI [10.1145/2576779.2576780, DOI 10.1145/2576779.2576780]
   Ke G., 2017, ADV NEURAL INFORM PR, V30, P3149
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Luo Liang, 2020, P MACH LEARN SYST 20, P82
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mars J., 2013, ISCA, P619
   Mars J, 2011, INT SYMP MICROARCH, P248
   Merity S., 2016, P INT C LEARN REPR
   Microsoft Corporation, 2020, AZ VM SIZ GPU AZ VIR
   Novakovic Dejan, 2013, USENIX ATC, P219
   PAREKH AK, 1994, IEEE ACM T NETWORK, V2, P137, DOI 10.1109/90.298432
   Paszke A., 2019, P ADV NEUR INF PROC
   Peng YH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P16, DOI 10.1145/3341301.3359642
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen HC, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P322, DOI 10.1145/3341301.3359658
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thinakaran P., 2019, P 2019 IEEE INT C CL, P1
   Ting-An Yeh, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P173, DOI 10.1145/3369583.3392679
   Ukidave Y, 2016, INT PARALL DISTRIB P, P353, DOI 10.1109/IPDPS.2016.73
   Vavilapalli VK, 2013, P ACM SOCC, DOI 10.1145/2523616.2523633
   Wang H, 2020, IEEE INT ON LINE, DOI [10.1109/iolts50870.2020.9159708, 10.1109/ISCAS45731.2020.9180522]
   Wang MD, 2019, I S WORKL CHAR PROC, P189, DOI 10.1109/IISWC47752.2019.9042047
   Wang SQ, 2021, IEEE T PARALL DISTR, V32, P2144, DOI 10.1109/TPDS.2021.3062721
   Wang Yu, 2020, P MACHINE LEARNING S, V2, P30
   Xiao WC, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P533
   Xiao WC, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P595
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu X., 2019, P 11 USENIX C HOT TO, P14
   Yang RY, 2020, IEEE T PARALL DISTR, V31, P1499, DOI 10.1109/TPDS.2020.2970013
   Yangrui Chen, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P507, DOI 10.1145/3419111.3421307
   Yeung G, 2020, LECT NOTES COMPUT SC, V12453, P492, DOI 10.1007/978-3-030-60239-0_33
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang DL, 2020, PROC VLDB ENDOW, V13, P3125, DOI 10.14778/3415478.3415539
NR 67
TC 19
Z9 19
U1 3
U2 18
PD JAN 1
PY 2022
VL 33
IS 1
BP 88
EP 100
DI 10.1109/TPDS.2021.3079202
UT WOS:000668795000005
DA 2023-11-16
ER

PT C
AU Fagbohungbe, O
   Qian, LJ
AF Fagbohungbe, Omobayode
   Qian, Lijun
GP IEEE
TI Impact of <i>L</i><sub>1</sub> Batch Normalization on Analog Noise
   Resistant Property of Deep Learning Models
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
DE Batch Normalization; Deep Learning; Hardware Implemented Neural Network;
   Analog Device; Additive White Gaussian Noise
ID ACCELERATORS
AB Analog hardware has become a popular choice for machine learning on resource-constrained devices recently due to its fast execution and energy efficiency. However, the inherent presence of noise in analog hardware and the negative impact of the noise on deployed deep neural network (DNN) models limit their usage. The degradation in performance due to the noise calls for the novel design of DNN models that have excellent noise-resistant property, leveraging the properties of the fundamental building block of DNN models. In this work, the use of L-1 or TopK BatchNorm type, a fundamental DNN model building block, in designing DNN models with excellent noise-resistant property is proposed. Specifically, a systematic study has been carried out by training DNN models with L-1/TopK BatchNorm type, and the performance is compared with DNN models with L-2 BatchNorm types. The resulting model noise-resistant property is tested by injecting additive noise to the model weights and evaluating the new model inference accuracy due to the noise. The results show that L-1 and TopK BatchNorm type has excellent noise-resistant property, and there is no sacrifice in performance due to the change in the BatchNorm type from L-2 to L-1/TopK BatchNorm type.
C1 [Fagbohungbe, Omobayode; Qian, Lijun] Prairie View A&M Univ, Texas A&M Univ Syst, CREDIT Ctr, Prairie View, TX 77446 USA.
   [Fagbohungbe, Omobayode; Qian, Lijun] Prairie View A&M Univ, Texas A&M Univ Syst, Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
RP Fagbohungbe, O (corresponding author), Prairie View A&M Univ, Texas A&M Univ Syst, CREDIT Ctr, Prairie View, TX 77446 USA.; Fagbohungbe, O (corresponding author), Prairie View A&M Univ, Texas A&M Univ Syst, Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
EM ofagbohungbe@pvamu.edu
CR [Anonymous], 2017, NIPS
   [Anonymous], 2018, NEURIPS
   BJORCK J, 2018, NEURIPS, V31
   Bo GM, 2000, IEEE IJCNN, P66, DOI 10.1109/IJCNN.2000.860751
   Burr Geoffrey W., 2021, IEEE Spectrum, V58, P44, DOI 10.1109/MSPEC.2021.9641759
   Chang HY, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934050
   Charan G, 2020, IEEE J EXPLOR SOLID-, V6, P27, DOI 10.1109/JXCDC.2020.2987605
   Chen A, 2020, 2020 IEEE ELECTRON DEVICES TECHNOLOGY AND MANUFACTURING CONFERENCE (EDTM 2020), DOI 10.1109/edtm47692.2020.9117896
   Fagbohungbe O., 2021, EFFECT BATCH NORMALI
   Fagbohungbe O., 2022, IMPACT LEARNING RATE
   Fagbohungbe O., 2021, IEEE T EMERGING TOPI
   Fagbohungbe O. I., 2020, BENCHMARKING INFEREN
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   He Kaiming, 2016, PROC CVPR IEEE
   Hinton Geoffrey, 2015, ARXIV150302531
   Huang Gao, 2018, DENSELY CONNECTED CO
   HUANG K, 2020, FUNCTIONAL ERROR COR
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Joshi V., 2019, ACCURATE DEEP NEURAL
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kariyappa S, 2021, IEEE T ELECTRON DEV, V68, P4356, DOI 10.1109/TED.2021.3089987
   Klachko M., 2019, IMPROVING NOISE TOLE
   Kourtis K., 2020, COMPILING NEURAL NET
   Li HC, 2019, ADV MATER SCI ENG, V2019, DOI 10.1155/2019/2190627
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Maghazeh A, 2013, 2013 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (IC-SAMOS), P1, DOI 10.1109/SAMOS.2013.6621099
   Merolla P., 2016, DEEP NEURAL NETWORKS
   Onasami O., 2022, UNDERWATER ACOUSTIC
   Qiao S., 2019, MICROBATCH TRAINING
   Qin M., 2018, JOIG, V6, P181, DOI DOI 10.18178/JOIG.6.2.181-186
   SALIMANS T, 2016, NIPS, V29
   Schmid A, 1999, IEE P-CIRC DEV SYST, V146, P345, DOI 10.1049/ip-cds:19990685
   Upadhyaya P., 2019, ERROR CORRECTION NOI, V10
   Upadhyaya P., 2019, ERROR CORRECTION HAR
   Wu S, 2019, IEEE T NEUR NET LEAR, V30, P2043, DOI 10.1109/TNNLS.2018.2876179
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xiao TP, 2020, APPL PHYS REV, V7, DOI 10.1063/1.5143815
   XIE S, 2017, AGGREGATED RESIDUAL
   Yang B, 2022, IEEE T IND INFORM, V18, P531, DOI 10.1109/TII.2021.3075444
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
   Zhou C., 2001, NOISY MACHINES UNDER
   Zhou C., 2021, ANALOGNETS ML HW COD
NR 42
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/IJCNN55064.2022.9892222
UT WOS:000867070902105
DA 2023-11-16
ER

PT J
AU Cho, W
   Kim, H
   Kim, D
   Kim, S
   Kwon, I
AF Cho, Woosung
   Kim, Hyeonmin
   Kim, Duckhyun
   Kim, SongHyun
   Kwon, Inyong
TI Reproduction strategy of radiation data with compensation of data loss
   using a deep learning technique
SO NUCLEAR ENGINEERING AND TECHNOLOGY
DT Article
DE Deep learning; U-net algorithm; Radiation map; Sensor network system;
   Reproduction
ID CIRCUIT; DAMAGE
AB In nuclear-related facilities, such as nuclear power plants, research reactors, accelerators, and nuclear waste storage sites, radiation detection, and mapping are required to prevent radiation overexposure. Sensor network systems consisting of radiation sensor interfaces and wxireless communication units have become promising tools that can be used for data collection of radiation detection that can in turn be used to draw a radiation map. During data collection, malfunctions in some of the sensors can occasionally occur due to radiation effects, physical damage, network defects, sensor loss, or other reasons. This paper proposes a reproduction strategy for radiation maps using a U-net model to compensate for the loss of radiation detection data. To perform machine learning and verification, 1,561 simulations and 417 measured data of a sensor network were performed. The reproduction results show an accuracy of over 90%. The proposed strategy can offer an effective method that can be used to resolve the data loss problem for conventional sensor network systems and will specifically contribute to making initial responses with preserved data and without the high cost of radiation leak accidents at nuclear facilities.
   (c) 2021 Korean Nuclear Society, Published by Elsevier Korea LLC. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Cho, Woosung; Kim, SongHyun] POSTECH, Dept Adv Nucl Engn, 77 Cheongam Ro, Pohang 37673, South Korea.
   [Kim, Hyeonmin; Kim, Duckhyun; Kwon, Inyong] Korea Atom Energy Res Inst, 111 Daedeok Daero,989 Beon Gil, Daejeon 34057, South Korea.
RP Kwon, I (corresponding author), Korea Atom Energy Res Inst, 111 Daedeok Daero,989 Beon Gil, Daejeon 34057, South Korea.
EM ikwon@kaeri.re.kr
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   [Anonymous], 2017, ARXIV170404861V1CSCV
   [Anonymous], 2017, METHOD STOCHASTIC OP
   BRUCKER G, 1965, IEEE T NUCL SCI, VNS12, P69, DOI 10.1109/TNS.1965.4323901
   Choi K, 2019, SEMISUPERVISED LEARN
   Fetahovic I, 2013, INT J PHOTOENERGY, V2013, DOI 10.1155/2013/170269
   Fleetwood DM, 2013, IEEE T NUCL SCI, V60, P1706, DOI 10.1109/TNS.2013.2259260
   Goodfellow I.J., 2014, NIPS NEWS PHYSL SCI, V27
   He K., 2015, ARXIV151203385V1CSCV
   Jeon H, 2020, IEEE T NUCL SCI, V67, P1738, DOI 10.1109/TNS.2020.3002421
   Kim D, 2020, NUCL INSTRUM METH A, V954, DOI 10.1016/j.nima.2018.10.205
   Kim S, 2020, NUCL INSTRUM METH A, V954, DOI 10.1016/j.nima.2018.10.151
   Kwon I, 2014, IEEE J SOLID-ST CIRC, V49, P2054, DOI 10.1109/JSSC.2014.2328658
   Lee C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102765
   Lehtinen J., 2018, ARXIV180304189V3CSCV
   Liu G., 2018, ARXIV ARXIV180407723
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   MCNP Team, 2017, LAUR1729011 MCNP TEA
   Nazeri K., 2019, ARXIV190100212V3
   Pavlovsky R., 2018, ARXIV190105038V1PHYS
   Ronneberger O., 2015, RECOGNIT CVPR, DOI 10.1007/978-3-319-24574-4MedicalImageComputingandComputer-AssistedIntervention
   Simonyan K., 2014, VERY DEEP CONVOLUTIO
   Tan M., 2019, ARXIV190511946V3CSLG
   Towler J, 2012, REMOTE SENS-BASEL, V4, P1995, DOI 10.3390/rs4071995
   Ware A. R., 1988, Nuclear Europe, V8, P20
   Zakaria A, 2017, PROCEDIA COMPUT SCI, V105, P81, DOI 10.1016/j.procs.2017.01.203
NR 26
TC 0
Z9 0
U1 1
U2 2
PD JUL
PY 2021
VL 53
IS 7
BP 2229
EP 2236
DI 10.1016/j.net.2021.01.012
UT WOS:000662965700003
DA 2023-11-16
ER

PT J
AU Chen, YG
   Zhang, LH
   Ai, ZH
   Long, YF
   Weldengus, TM
   Zheng, XB
   Wang, D
   Wang, HW
   Zhai, YT
   Huang, YQ
   Le, X
   Peng, YX
   Jiang, J
AF Chen, Yangguan
   Zhang, Longhan
   Ai, Zhehong
   Long, Yifan
   Weldengus, Temesgen Muruts
   Zheng, Xubin
   Wang, Di
   Wang, Haowen
   Zhai, Yiteng
   Huang, Yuqing
   Le, Xiao
   Peng, Yaxuan
   Jiang, Jing
TI Robot-accelerated development of a colorimetric CO2 sensing array with
   wide ranges and high sensitivity via multi-target Bayesian optimizations
SO SENSORS AND ACTUATORS B-CHEMICAL
DT Article
DE Colorimetric sensor; Design -Build -Test -Machine learning process; High
   -throughput; Algorithm -driven autonomous system; Multi -target
   optimization
ID CARBON-DIOXIDE; POLYETHYLENE-GLYCOL; HEALTH; NH3
AB The one-variable-at-a-time method for sensor R&D has received extensive research effort, yet it has reached the local maxima for specific sensing characteristics. To achieve the quasi-global maxima for suitable sensors, we developed the Design-Build-Test-Machine learning (DBTM) method for efficiently developing sensors on de-mand. In addition, the automation of the preparation and characterization processes frees researchers from labor-intensive work, generates adequate high-quality data, and enables researchers to discover valuable information in high-dimensional space. As a proof-of-concept, we built a high-throughput algorithm-driven autonomous system (HAAS) that supports the DBTM approach for developing a CO2 sensor. With the DBTM approach, we can simultaneously optimize multiple sensor units, each for a specific concentration interval. Therefore, such array can achieve an extensive range and sound sensitivity. Our work demonstrates the superiority of the DBTM method for multi-target and multi-variable sensor development. In contrast to single target optimization in other research areas, multiple characteristics should be improved for sensors. Our multi-target optimization algorithm optimizes four sensor characteristics. Our sensor array could rapidly detect CO2 concentrations from 400 ppm 30 % with a root mean square error (RMSE) of 0.27 %. The DBTM method is anticipated to be a new paradigm and accelerator of practical application for sensors after the initial proof of the sensing mechanism.
C1 [Chen, Yangguan; Zhang, Longhan; Ai, Zhehong; Long, Yifan; Weldengus, Temesgen Muruts; Jiang, Jing] Zhejiang Lab, Res Ctr Intelligent Sensing Syst, Hangzhou 311100, Zhejiang, Peoples R China.
   [Ai, Zhehong] Univ Chinese Acad Sci, Hangzhou Inst Adv Study, Hangzhou 310024, Zhejiang, Peoples R China.
   [Zheng, Xubin; Wang, Di] Zhejiang Lab, Res Ctr Sensing Mat & Devices, Hangzhou 311100, Zhejiang, Peoples R China.
   [Wang, Haowen] AntGroup, Alipay, Intelligence Dept Merchants Operat, Shanghai 201299, Peoples R China.
   [Zhai, Yiteng] Zhejiang Lab, Res Ctr Fintech, Hangzhou 311100, Zhejiang, Peoples R China.
   [Huang, Yuqing; Le, Xiao; Peng, Yaxuan] MegaRobo Technol Co Ltd, Shanghai 201210, Peoples R China.
RP Jiang, J (corresponding author), Zhejiang Lab, Res Ctr Intelligent Sensing Syst, Hangzhou 311100, Zhejiang, Peoples R China.
EM jiangj@zhejianglab.com
CR Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Chao HJ, 2003, ENVIRON HEALTH PERSP, V111, P1242, DOI 10.1289/ehp.5697
   Chaterjee S, 2019, ENVIRON CHEM LETT, V17, P465, DOI 10.1007/s10311-018-0774-z
   Chatterjee C, 2015, J MATER CHEM A, V3, P5642, DOI 10.1039/c4ta06321j
   Chen Y, 2015, BIOSENS BIOELECTRON, V67, P477, DOI 10.1016/j.bios.2014.09.010
   Chugh T, 2020, IEEE C EVOL COMPUTAT
   Davey AK, 2021, SENSOR ACTUAT B-CHEM, V344, DOI 10.1016/j.snb.2021.130313
   Fisk WJ, 2000, ANNU REV ENERG ENV, V25, P537, DOI 10.1146/annurev.energy.25.1.537
   Guo Z, 2012, J AM CHEM SOC, V134, P17846, DOI 10.1021/ja306891c
   Gupta A, 2018, IEEE TETCI, V2, P51, DOI 10.1109/TETCI.2017.2769104
   HamediRad M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13189-z
   Huang WW, 2022, ENVIRON TECHNOL, V43, P4545, DOI 10.1080/09593330.2021.1958012
   Kaya GG, 2021, TURK J CHEM, V45, P2013, DOI 10.3906/kim-2101-45
   Knowles J, 2006, IEEE T EVOLUT COMPUT, V10, P50, DOI 10.1109/TEVC.2005.851274
   Ko K, 2020, SCI TOTAL ENVIRON, V729, DOI 10.1016/j.scitotenv.2020.138786
   Lee JY, 2022, J ENVIRON MANAGE, V312, DOI 10.1016/j.jenvman.2022.114893
   Leibovich-Raveh T., 2018, J NUMER COGN, V4, P429, DOI [10.5964/jnc.v4i2.74, DOI 10.5964/JNC.V4I2.74]
   Li Z, 2019, CHEM REV, V119, P231, DOI 10.1021/acs.chemrev.8b00226
   Lin YQ, 2020, MAT SCI SEMICON PROC, V107, DOI 10.1016/j.mssp.2019.104820
   Liu Z, 2022, JOULE, V6, P834, DOI 10.1016/j.joule.2022.03.003
   MacLeod BP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz8867
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Miller DD, 2016, J PHYS CHEM C, V120, P25489, DOI 10.1021/acs.jpcc.6b09506
   Molina A, 2020, SYNTHETIC MET, V270, DOI 10.1016/j.synthmet.2020.116602
   Raccuglia P, 2016, NATURE, V533, P73, DOI 10.1038/nature17439
   Ramachandran RP, 2022, J STORED PROD RES, V96, DOI 10.1016/j.jspr.2022.101950
   Rezk MY, 2020, NANOMATERIALS-BASEL, V10, DOI 10.3390/nano10112251
   Saleh TA, 2021, TRENDS ENVIRON ANAL, V32, DOI 10.1016/j.teac.2021.e00142
   Saliu F, 2018, SENSOR ACTUAT B-CHEM, V258, P1117, DOI 10.1016/j.snb.2017.12.007
   Seifrid M, 2022, ACCOUNTS CHEM RES, V55, P2454, DOI [10.1021/acs.accounts.2c002202454, 10.1021/acs.accounts.2c00220]
   Shevlin M, 2017, ACS MED CHEM LETT, V8, P601, DOI 10.1021/acsmedchemlett.7b00165
   Steiner S, 2019, SCIENCE, V363, P144, DOI 10.1126/science.aav2211
   Wang LX, 2019, ACS SUSTAIN CHEM ENG, V7, P14785, DOI 10.1021/acssuschemeng.9b02798
   Xia GM, 2017, SENSOR ACTUAT B-CHEM, V244, P252, DOI 10.1016/j.snb.2016.12.143
   Zhang YN, 2018, SENSOR ACTUAT B-CHEM, V255, P3216, DOI 10.1016/j.snb.2017.09.148
   Zhu Q, 2022, NATL SCI REV, V9, DOI 10.1093/nsr/nwac190
NR 36
TC 0
Z9 0
U1 7
U2 7
PD SEP 1
PY 2023
VL 390
AR 133942
DI 10.1016/j.snb.2023.133942
EA MAY 2023
UT WOS:001007452700001
DA 2023-11-16
ER

PT J
AU Wang, K
   Song, TT
   Wang, YT
   Fang, CW
   He, JY
   Nirmalathas, A
   Lim, C
   Wong, E
   Kandeepan, S
AF Wang, Ke
   Song, Tingting
   Wang, Yitong
   Fang, Chengwei
   He, Jiayuan
   Nirmalathas, Ampalavanapillai
   Lim, Christina
   Wong, Elaine
   Kandeepan, Sithamparanathan
TI Evolution of Short-Range Optical Wireless Communications
SO JOURNAL OF LIGHTWAVE TECHNOLOGY
DT Article
DE Wireless communication; Optical transmitters; Optical receivers;
   High-speed optical techniques; Optical fibers; Communication system
   security; Wireless fidelity; Optical wireless communications; optical
   MIMO; machine learning; underwater optical wireless communications;
   optical wireless vehicular communications
ID VISIBLE-LIGHT COMMUNICATION; GENERALIZED SPATIAL MODULATION; PERFORMANCE
   ANALYSIS; ORTHOGONAL-FILTERS; DATA-TRANSMISSION; POWER-EFFICIENT;
   MULTIUSER MIMO; SYSTEM; VLC; LINKS
AB The optical wireless communication (OWC) technology explores the broad unregulated optical spectrum to provide high-speed wireless communications, and the visible, ultraviolet and near-infrared wavelength ranges all have been investigated. Compared with the conventional radio frequency (RF) band, the spectrum in OWC systems is much less congested and the interference is much lower. The OWC technology also provides enhanced physical layer security due to the natural confinement of optical beams that makes it difficult to intercept the transmitted signal. Hence, the OWC technology has been widely studied and considered as a promising candidate in future beyond-5G communications. The OWC technology has been considered for both long-range and short-range applications, and in this paper we will introduce the fundamentals and recent developments of short-range OWC systems. In particular, we will focus on the key short-range OWC applications in indoor personal or local area communications, underwater wireless communications, wireless data center networks, and vehicular communications. We will also introduce some recent widely studied advanced techniques to boost the performance of short-range OWC systems, including the spatial domain diversity, multiplexing and modulation principles to improve the system robustness and data rate, and the machine learning algorithms and hardware accelerators to suppress both linear and nonlinear effects to improve OWC signal quality and bit-error-rate performance.
C1 [Wang, Ke; Song, Tingting; Fang, Chengwei; Kandeepan, Sithamparanathan] RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia.
   [He, Jiayuan] RMIT Univ, Sch Comp Technol, Melbourne, Vic 3000, Australia.
   [Song, Tingting; Nirmalathas, Ampalavanapillai; Lim, Christina; Wong, Elaine] Univ Melbourne, Dept Elect & Elect Engn, Melbourne, Vic 3010, Australia.
RP Wang, K (corresponding author), RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia.
EM ke.wang@rmit.edu.au; tingtings@unimelb.edu.au;
   s3587959@student.rmit.edu.au; s3643273@student.rmit.edu.au;
   jiayuan.he@rmit.edu.au; nirmalat@unimelb.edu.au;
   chrislim@unimelb.edu.au; ewon@unimelb.edu.au;
   kandeepan.sithamparanathan@rmit.edu.au
CR Aboagye S, 2021, IEEE COMMUN LETT, V25, P3913, DOI 10.1109/LCOMM.2021.3114594
   Abu Bakar AH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024526
   Al-Ghamdi AG, 2004, IEEE T COMMUN, V52, P37, DOI 10.1109/TCOMM.2003.822160
   Ali W, 2019, IEEE PHOTONIC TECH L, V31, P805, DOI 10.1109/LPT.2019.2905647
   Aljada M, 2006, OPT EXPRESS, V14, P6823, DOI 10.1364/OE.14.006823
   Alresheedi MT, 2011, IEEE J SEL AREA COMM, V29, P1328, DOI 10.1109/JSAC.2011.110620
   Arvanitakis GN, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2019.2959656
   Bariah L, 2020, IEEE ACCESS, V8, P174792, DOI 10.1109/ACCESS.2020.3019590
   Bechadergue Bastien, 2019, 2019 Global LIFI Congress (GLC), DOI 10.1109/GLC.2019.8864116
   Berenguer PW, 2018, IEEE J SEL AREA COMM, V36, P185, DOI 10.1109/JSAC.2017.2774618
   Bergen MH, 2017, J LIGHTWAVE TECHNOL, V35, P3877, DOI 10.1109/JLT.2017.2723978
   Bian R, 2019, J LIGHTWAVE TECHNOL, V37, P2418, DOI 10.1109/JLT.2019.2906464
   Biswas Abhijit, 2019, OSA LAS C 2019 LTH1B, DOI 10.1055/s-0039-1695666
   Bober KL, 2021, J LIGHTWAVE TECHNOL, V39, P3420, DOI 10.1109/JLT.2021.3069186
   Buzzi S, 2019, IEEE T COMMUN, V67, P3323, DOI 10.1109/TCOMM.2019.2896122
   Cailean AM, 2017, IEEE COMMUN SURV TUT, V19, P2681, DOI 10.1109/COMST.2017.2706940
   Cailean AM, 2015, IEEE SENS J, V15, P4632, DOI 10.1109/JSEN.2015.2425473
   Cao ZZ, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0177-3
   Chaudhry AU, 2021, IEEE CONSUM ELECTR M, V10, P21, DOI 10.1109/MCE.2020.3029772
   Chaudhry AU, 2021, IEEE VEH TECHNOL MAG, V16, P48, DOI 10.1109/MVT.2021.3063706
   Chen C, 2021, IEEE T COMMUN, V69, P1175, DOI 10.1109/TCOMM.2020.3035405
   Chen HJ, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2748152
   Chen J., 2022, IEEE PHOTON J, V14, P1
   Cheng CL, 2019, IEEE ANTENNAS PROP, P2145, DOI [10.1109/apusncursinrsm.2019.8889030, 10.1109/APUSNCURSINRSM.2019.8889030]
   Chi N, 2020, IEEE VEH TECHNOL MAG, V15, P93, DOI 10.1109/MVT.2020.3017153
   Chi N, 2018, OPT EXPRESS, V26, P26700, DOI 10.1364/OE.26.026700
   CHU TS, 1987, IEEE COMMUN MAG, V25, P4, DOI 10.1109/MCOM.1987.1093675
   Cossu G, 2015, OPT EXPRESS, V23, P15700, DOI 10.1364/OE.23.015700
   Cui Y, 2011, IEEE WIREL COMMUN, V18, P46, DOI 10.1109/MWC.2011.6108333
   Dabiri MT, 2021, IEEE T VEH TECHNOL, V70, P8926, DOI 10.1109/TVT.2021.3098389
   Dang SP, 2020, NAT ELECTRON, V3, P20, DOI 10.1038/s41928-019-0355-6
   Dhatchayeny DR, 2019, IEEE SENS J, V19, P5594, DOI 10.1109/JSEN.2019.2906898
   Di YJ, 2021, 2021 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Do TH, 2019, IEEE ACCESS, V7, P95797, DOI 10.1109/ACCESS.2019.2928600
   Du J, 2021, OPT EXPRESS, V29, P783, DOI 10.1364/OE.416117
   Elzanaty A, 2020, IEEE T COMMUN, V68, P6388, DOI 10.1109/TCOMM.2020.3006575
   Eso E, 2021, IEEE PHOTONIC TECH L, V33, P908, DOI 10.1109/LPT.2021.3086836
   Fath T, 2013, IEEE T COMMUN, V61, P733, DOI 10.1109/TCOMM.2012.120512.110578
   Feng F, 2019, OPT LETT, V44, P6009, DOI 10.1364/OL.44.006009
   Fu CF, 2022, OPT EXPRESS, V30, P18743, DOI 10.1364/OE.457784
   GFELLER FR, 1979, P IEEE, V67, P1474, DOI 10.1109/PROC.1979.11508
   Haas H., 2018, REV PHYS, V3, P26, DOI [10.1016/j.revip.2017.10.001, DOI 10.1016/J.REVIP.2017.10.001]
   Haas H, 2016, J LIGHTWAVE TECHNOL, V34, P1533, DOI 10.1109/JLT.2015.2510021
   Halawi S, 2019, IEEE T COMMUN, V67, P4252, DOI 10.1109/TCOMM.2019.2904503
   Hamza AS, 2019, IEEE COMMUN SURV TUT, V21, P1346, DOI 10.1109/COMST.2018.2876805
   Hasan MK, 2022, IEEE T INTELL TRANSP, V23, P6260, DOI 10.1109/TITS.2021.3086409
   He JY, 2020, PHOTONICS-BASEL, V7, DOI 10.3390/photonics7040105
   He JY, 2020, J LIGHTWAVE TECHNOL, V38, P4632, DOI 10.1109/JLT.2020.2994576
   He JY, 2019, OPT LETT, V44, P3745, DOI 10.1364/OL.44.003745
   Hong Y, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Hu M, 2019, J LIGHTWAVE TECHNOL, V37, P4940, DOI 10.1109/JLT.2019.2926218
   Huang SM, 2022, IEEE WCNC, P2316, DOI 10.1109/WCNC51071.2022.9771959
   Huang XH, 2021, J LIGHTWAVE TECHNOL, V39, P4351, DOI 10.1109/JLT.2021.3073395
   Jamali MV, 2017, IEEE PHOTONIC TECH L, V29, P462, DOI 10.1109/LPT.2017.2657228
   Jiang R, 2020, IEEE ACCESS, V8, P20363, DOI 10.1109/ACCESS.2020.2967461
   Jungnickel V, 2002, IEEE J SEL AREA COMM, V20, P631, DOI 10.1109/49.995522
   Jungnickel V, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Kahn JM, 1998, IEEE COMMUN MAG, V36, P88, DOI 10.1109/35.735884
   Kahn JM, 1997, P IEEE, V85, P265, DOI 10.1109/5.554222
   Kaymak Y, 2019, IEEE COMMUN LETT, V23, P814, DOI 10.1109/LCOMM.2019.2904031
   Khalighi MA, 2014, IEEE COMMUN SURV TUT, V16, P2231, DOI 10.1109/COMST.2014.2329501
   Khan FN, 2019, J LIGHTWAVE TECHNOL, V37, P493, DOI 10.1109/JLT.2019.2897313
   Koonen T, 2018, J LIGHTWAVE TECHNOL, V36, P4486, DOI 10.1109/JLT.2018.2834374
   Koonen T, 2018, J LIGHTWAVE TECHNOL, V36, P1459, DOI 10.1109/JLT.2017.2787614
   Koonen T, 2016, J LIGHTWAVE TECHNOL, V34, P4802, DOI 10.1109/JLT.2016.2574855
   Kumar CR, 2017, IEEE PHOTONIC TECH L, V29, P921, DOI 10.1109/LPT.2017.2694462
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H, 2018, OPT EXPRESS, V26, P18131, DOI 10.1364/OE.26.018131
   Lee H, 2018, OPT EXPRESS, V26, P6222, DOI 10.1364/OE.26.006222
   Lee J, 2021, OPT EXPRESS, V29, P26165, DOI 10.1364/OE.427250
   Lee J, 2020, OPT EXPRESS, V28, P13384, DOI 10.1364/OE.391050
   Li MF, 2017, CHIN OPT LETT, V15, DOI 10.3788/COL201715.050604
   Li XB, 2017, IEEE COMMUN LETT, V21, P382, DOI 10.1109/LCOMM.2016.2625300
   Lian J, 2017, J LIGHTWAVE TECHNOL, V35, P5024, DOI 10.1109/JLT.2017.2765462
   Lin BJ, 2017, IEEE PHOTONIC TECH L, V29, P579, DOI 10.1109/LPT.2017.2669079
   Liu L., 2020, P 2020 OPT FIB COMM, DOI DOI 10.1364/OFC.2020.M1J.4
   Liu YF, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P509, DOI 10.1109/ICCT.2018.8599895
   Lorrière N, 2020, J LIGHTWAVE TECHNOL, V38, P3822, DOI 10.1109/JLT.2020.2981554
   Ma S, 2019, IEEE ACCESS, V7, P30588, DOI 10.1109/ACCESS.2019.2903375
   Majlesein B., 2018, 2018 11 INT S COMM S, P1, DOI 10.1109/CSNDSP.2018.8471869
   Mamun SA, 2018, IEEE T GREEN COMMUN, V2, P1174, DOI 10.1109/TGCN.2018.2838525
   MARSH GW, 1994, IEEE PHOTONIC TECH L, V6, P1268, DOI 10.1109/68.329659
   Matheus LEM, 2019, IEEE COMMUN SURV TUT, V21, P3204, DOI 10.1109/COMST.2019.2913348
   Miao P, 2019, IEEE ACCESS, V7, P71436, DOI 10.1109/ACCESS.2019.2919983
   Thieu MD, 2019, IEEE ACCESS, V7, P69873, DOI 10.1109/ACCESS.2019.2918338
   Musumeci F, 2019, IEEE COMMUN SURV TUT, V21, P1383, DOI 10.1109/COMST.2018.2880039
   Narmanlioglu O, 2018, COMPUT COMMUN, V120, P138, DOI 10.1016/j.comcom.2018.02.003
   Naser S, 2022, IEEE WIREL COMMUN, V29, P48, DOI 10.1109/MWC.005.00334
   Ning J, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3089781
   Nirmalathas Ampalavanapillai, 2021, IEEE/OSA Journal of Optical Communications and Networking, V13, pA178, DOI 10.1364/JOCN.403485
   Nirmalathas TA, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Ozyurt AB, 2023, IEEE SYST J, V17, P1591, DOI 10.1109/JSYST.2022.3179183
   Park KH, 2013, IEEE T COMMUN, V61, P1535, DOI 10.1109/TCOMM.2013.012913.110290
   Pathak PH, 2015, IEEE COMMUN SURV TUT, V17, P2047, DOI 10.1109/COMST.2015.2476474
   Perera A., 2021, PROC IEEE 16 INT C I, P58
   Pohl V, 2000, PIMRC 2000: 11TH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1 AND 2, PROCEEDINGS, P297, DOI 10.1109/PIMRC.2000.881437
   Qiu Y, 2018, IEEE WIREL COMMUN, V25, P178, DOI 10.1109/MWC.2017.1700051
   Rajagopal S, 2012, IEEE COMMUN MAG, V50, P72, DOI 10.1109/MCOM.2012.6163585
   Safi H, 2020, J LIGHTWAVE TECHNOL, V38, P5036, DOI 10.1109/JLT.2020.2997806
   Shah SAA, 2018, IEEE COMMUN MAG, V56, P111, DOI 10.1109/MCOM.2018.1700467
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shen SQ, 2022, IEEE T WIREL COMMUN, V21, P6271, DOI 10.1109/TWC.2022.3148169
   Shi P, 2020, OPT EXPRESS, V28, P38733, DOI 10.1364/OE.410283
   Song HJ, 2021, IEEE MICROW MAG, V22, P88, DOI 10.1109/MMM.2021.3056935
   Song TL, 2019, J LIGHTWAVE TECHNOL, V37, P5170, DOI 10.1109/JLT.2019.2929801
   Song TT, 2020, J LIGHTWAVE TECHNOL, V38, P4250, DOI 10.1109/JLT.2020.2988669
   Stepniak G, 2015, J LIGHTWAVE TECHNOL, V33, P4413, DOI 10.1109/JLT.2015.2472575
   Sun C, 2019, IEEE T COMMUN, V67, P2188, DOI 10.1109/TCOMM.2018.2883622
   Sun X, 2021, IEEE ACCESS, V9, P80897, DOI 10.1109/ACCESS.2021.3085117
   Sung JY, 2022, J LIGHTWAVE TECHNOL, V40, P4150, DOI 10.1109/JLT.2022.3158733
   Tanaka Y, 2003, IEICE T COMMUN, VE86B, P2440
   Tawfik MM, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3104819
   Teli S, 2017, IEEE COMMUN MAG, V55, P156, DOI 10.1109/MCOM.2017.1600923
   Nguyen T, 2018, IEEE COMMUN MAG, V56, P213, DOI 10.1109/MCOM.2018.1700134
   Turan B, 2022, IEEE T VEH TECHNOL, V71, P10110, DOI 10.1109/TVT.2022.3181160
   Turan B, 2021, IEEE T VEH TECHNOL, V70, P9659, DOI 10.1109/TVT.2021.3107835
   Uysal M., 2018, IEEE 802 11BB REFERE
   Wang J., 2017, 2017 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2017.8007838
   Wang JM, 2019, OPT EXPRESS, V27, P12171, DOI 10.1364/OE.27.012171
   Wang K, 2022, IEEE PHOTONIC TECH L, V34, P455, DOI 10.1109/LPT.2022.3165162
   Wang K, 2021, OPT EXPRESS, V29, P4582, DOI 10.1364/OE.409395
   Wang K, 2020, IEEE PHOTONIC TECH L, V32, P1373, DOI 10.1109/LPT.2020.3026343
   Wang K, 2020, OPT LETT, V45, P4980, DOI 10.1364/OL.396718
   Wang K, 2019, J LIGHTWAVE TECHNOL, V37, P5988, DOI 10.1109/JLT.2019.2944639
   Wang K, 2019, J LIGHTWAVE TECHNOL, V37, P619, DOI 10.1109/JLT.2018.2889252
   Wang K, 2019, J LIGHTWAVE TECHNOL, V37, P627, DOI 10.1109/JLT.2018.2881728
   Wang K, 2014, OPT LETT, V39, P5717, DOI 10.1364/OL.39.005717
   Wang K, 2011, OPT EXPRESS, V19, P21321, DOI 10.1364/OE.19.021321
   Wang L, 2021, LASER PHOTONICS REV, V15, DOI 10.1002/lpor.202000406
   Wang TQ, 2013, J LIGHTWAVE TECHNOL, V31, P3302, DOI 10.1109/JLT.2013.2281592
   Wang X, 2018, IEEE COMMUN SURV TUT, V20, P1616, DOI 10.1109/COMST.2018.2844322
   Wang YG, 2014, IEEE COMMUN LETT, V18, P1719, DOI 10.1109/LCOMM.2014.2349990
   Wang YL, 2017, IEEE T COMMUN, V65, P1708, DOI 10.1109/TCOMM.2017.2654249
   Wei ZX, 2022, J LIGHTWAVE TECHNOL, V40, P5083, DOI 10.1109/JLT.2022.3172921
   Werfli K, 2018, J LIGHTWAVE TECHNOL, V36, P1944, DOI 10.1109/JLT.2018.2796503
   Wu XP, 2020, IEEE T WIREL COMMUN, V19, P8211, DOI 10.1109/TWC.2020.3020160
   Xiao L, 2019, IEEE T COMMUN, V67, P6994, DOI 10.1109/TCOMM.2019.2930247
   Xie EY, 2020, IEEE PHOTONIC TECH L, V32, P499, DOI 10.1109/LPT.2020.2981827
   Xing FY, 2020, IEEE T WIREL COMMUN, V19, P251, DOI 10.1109/TWC.2019.2943867
   You Q, 2021, CHIN OPT LETT, V19, DOI 10.3788/COL202119.120602
   Younus SH, 2019, IEEE ACCESS, V7, P1126, DOI 10.1109/ACCESS.2018.2886398
   Zeadally Sherali, 2020, IEEE Communications Standards Magazine, V4, P11, DOI 10.1109/MCOMSTD.001.1900044
   Zeng ZQ, 2017, IEEE COMMUN SURV TUT, V19, P204, DOI 10.1109/COMST.2016.2618841
   Zhang SJ, 2021, IEEE PHOTONIC TECH L, V33, P773, DOI 10.1109/LPT.2021.3095163
   Zhang XB, 2018, OPT LETT, V43, P723, DOI 10.1364/OL.43.000723
   Zhang Y, 2019, IEEE J SEL TOP QUANT, V25, DOI 10.1109/JSTQE.2019.2910415
   Zhao X, 2018, IEEE ACCESS, V6, P34004, DOI 10.1109/ACCESS.2018.2847744
   Zhao XS, 2021, IEEE J SEL TOP QUANT, V27, DOI 10.1109/JSTQE.2020.2991756
   Zinda T., 2018, PROC INT S COMMUN SY, P1
NR 150
TC 2
Z9 2
U1 9
U2 9
PD FEB 15
PY 2023
VL 41
IS 4
BP 1019
EP 1040
DI 10.1109/JLT.2022.3215590
UT WOS:000992271600001
DA 2023-11-16
ER

PT C
AU Yu, J
   Kim, J
   Seo, E
AF Yu, Junyeol
   Kim, Jongseok
   Seo, Euiseong
GP IEEE
TI Know Your Enemy To Save Cloud Energy: Energy-Performance
   Characterization of Machine Learning Serving
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
ID POWER
AB The proportion of machine learning (ML) inference in modern cloud workloads is rapidly increasing, and graphic processing units (GPUs) are the most preferred computational accelerators for it. The massively parallel computing capability of GPUs is well-suited to the inference workloads but consumes more power than conventional CPUs. Therefore, GPU servers contribute significantly to the total power consumption of a data center. However, despite their heavy power consumption, GPU power management in cloud-scale has not yet been actively researched. In this paper, we reveal three findings about energy efficiency of ML inference clusters in the cloud. (1) GPUs of different architectures have comparative advantages in energy efficiency to each other for a set of ML models. (2) The energy efficiency of a GPU set may significantly vary depending on the number of active GPUs and their clock frequencies even when producing the same level of throughput. (3) The service level objective(SLO)-blind dynamic voltage and frequency scaling (DVFS) driver of commercial GPUs maintain an immoderately high clock frequency. Based on these implications, we propose a hierarchical GPU resource management approach for cloudscale inference services. The proposed approach consists of energy-aware cluster allocation, intra-cluster node scaling, intranode GPU scaling and GPU clock scaling schemes considering the inference service architecture hierarchy. We evaluated our approach with its prototype implementation and cloud-scale simulation. The evaluation with real-world traces showed that the proposed schemes can save up to 28.3% of the cloud-scale energy consumption when serving five ML models with 105 servers having three different kinds of GPUs.
C1 [Yu, Junyeol; Kim, Jongseok; Seo, Euiseong] Sungkyunkwan Univ, Dept Comp Sci & Engn, Seoul, South Korea.
RP Yu, J (corresponding author), Sungkyunkwan Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM junyeol.yu@skku.edu; ks77sj@skku.edu; euiseong@skku.edu
CR Abe Y, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.23
   Abe Yuki, 2012, WORKSH POW AW COMP S
   Ali A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00073
   [Anonymous], 2021, NVIDIA TRIT INF SERV
   [Anonymous], 2021, ARCH TEAM TWITT STRE
   [Anonymous], 2021, OR TOOLS GOOGL OPT T
   Arafa Y, 2020, 17TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2020 (CF 2020), P60, DOI 10.1145/3387902.3392613
   Bari MAS, 2018, PROCEEDINGS OF 2018 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2018), P83, DOI [10.1109/PMBS.2018.8641666, 10.1109/PMBS.2018.00013]
   Brewer EA, 2015, P 6 ACM S CLOUD COMP, P167, DOI [10.1145/2806777.2809955, DOI 10.1145/2806777.2809955]
   Bridges RA, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2962131
   Crankshaw Daniel, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P477, DOI 10.1145/3419111.3421285
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Dakkak A, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P46, DOI 10.1145/3330345.3331057
   DEMERS A, 1989, COMP COMM R, V19, P1, DOI 10.1145/75247.75248
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Fan D, 2020, AWS MACHINE LEARNING
   Fielding Roy Thomas, 2000, ARCHITECTURAL STYLES, Patent No. AAI9980887
   Frazelle J., 2020, ACM QUEUE, V18, P5
   Ge R, 2013, PROC INT CONF PARAL, P826, DOI 10.1109/ICPP.2013.98
   Gebhart M, 2012, INT SYMP MICROARCH, P96, DOI 10.1109/MICRO.2012.18
   Gebhart M, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P235, DOI 10.1145/2024723.2000093
   Gueyoung Jung, 2013, 2013 IEEE Ninth World Congress on Services (SERVICES), P456, DOI 10.1109/SERVICES.2013.55
   Gujarati A, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P443
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hodak M, 2019, IEEE INT CONF BIG DA, P1814, DOI 10.1109/BigData47090.2019.9005632
   Jahanshahi A, 2020, IEEE COMPUT ARCHIT L, V19, P139, DOI 10.1109/LCA.2020.3023723
   Kleinschmidt SP, 2018, IEEE INT SYMP SAFE
   Koo G, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P307, DOI 10.1145/3079856.3080239
   Krumke SO, 2013, EUR J OPER RES, V228, P46, DOI 10.1016/j.ejor.2013.01.027
   Kundakcioglu OE., 2009, ENCY OPTIMIZATION, P1153, DOI [DOI 10.1007/978-0-387-74759-0_200, DOI 10.1007/978-0-387-74759-0200]
   Lashgar A, 2013, LECT NOTES COMPUT SC, V7767, P134, DOI 10.1007/978-3-642-36424-2_12
   Li Y, 2020, IEEE INFOCOM SER, P1668, DOI [10.1109/INFOCOM41043.2020.9155267, 10.1109/infocom41043.2020.9155267]
   Masanet E, 2020, SCIENCE, V367, P984, DOI 10.1126/science.aba3758
   Mei X., 2013, P WORKSHOP POWER AWA, DOI [10.1145/2525526.2525852, DOI 10.1145/2525526.2525852]
   Mei XX, 2017, DIGIT COMMUN NETW, V3, P89, DOI 10.1016/j.dcan.2016.10.001
   Minsoo Rhu, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P86, DOI 10.1145/2540708.2540717
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2636342
   Nabavinejad SM, 2019, IEEE COMPUT ARCHIT L, V18, P136, DOI 10.1109/LCA.2019.2942020
   Narayanan D., 2020, P WORKSHOP DISTRIBUT
   Petrillo F, 2016, LECT NOTES COMPUT SC, V9936, P157, DOI 10.1007/978-3-319-46295-0_10
   Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397
   Seo W, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3460352
   Shehabi A., 2016, US DATA CTR ENERGY U
   Shen K, 2013, ACM SIGPLAN NOTICES, V48, P65, DOI 10.1145/2499368.2451124
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spetko M, 2021, ENERGIES, V14, DOI 10.3390/en14020376
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang ZH, 2019, E-ENERGY'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON FUTURE ENERGY SYSTEMS, P315, DOI 10.1145/3307772.3328315
   Wang Y, 2012, DES AUT TEST EUROPE, P300
   Yadwadkar NJ, 2017, PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC '17), P452, DOI 10.1145/3127479.3131614
   Yao CR, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6064
   Yeung G., 2020, 12 USENIX WORKSH HOT
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang MJ, 2019, PROCEEDINGS OF THE 2019 USENIX CONFERENCE ON OPERATIONAL MACHINE LEARNING, P5
   Zhao JS, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2541228.2541231
NR 58
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 842
EP 854
DI 10.1109/HPCA56546.2023.10070943
UT WOS:000982303200062
DA 2023-11-16
ER

PT J
AU Koo, Y
   Kim, S
   Ha, YG
AF Koo, Yongbon
   Kim, Sunghoon
   Ha, Young-guk
TI OpenCL-Darknet: implementation and optimization of OpenCL-based deep
   learning object detection framework
SO WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS
DT Article
DE deep learning; image processing; object detection; parallel programming;
   OpenCL
ID HISTOGRAMS
AB Object detection is a technology that deals with recognizing classes of objects and their location. It is used in many different areas, such as in face-detecting systems [16, 34, 37], surveillance tools [9], human-machine interfaces [17], and self-driving cars [18, 23, 25, 26, 30]. These days, deep learning object detection approaches have achieved significantly better performance than the classical feature-based algorithms. Darknet [31] is a deep learning object detection framework, which is well known for its fast speed and simple structure. Unfortunately, Darknet can only work with Nvidia CUDA [6] for accelerating its deep learning calculations. For this reason, users have only limited options of selecting appropriate graphic cards. Open computing language (OpenCL) [35], an open standard for cross-platform, parallel programming of heterogeneous systems, is available for the general hardware accelerators. However, many deep learning frameworks including Darknet have no support for OpenCL. In our previous paper, we presented OpenCL-Darknet [19], which transformed the CUDA-based Darknet into an open standard OpenCL backend. The original OpenCL-Darknet successfully showed its ability for the general graphics processing unit (GPU) hardware. However, it could not achieve competitive performance compared with the CUDA version, and it only supported a limited platform. In this study, we improved the performance of OpenCL-Darknet with several optimization techniques and added support for various architectures. We also evaluated OpenCL-Darknet not only in AMD R7 accelerated processing unit (APU) with OpenCL 2.0, but also in Nvidia GPU and ARM Mali embedded GPU with OpenCL 1.2 Profile. The evaluation using the standard object detection datasets showed that our advanced OpenCL-Darknet reduced the processing time by at most 50% on average for various deep learning object detection networks compared with our original implementation. We also showed that our OpenCL deep learning framework has competitiveness compared with the CUDA-based one.
C1 [Koo, Yongbon; Kim, Sunghoon] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon, South Korea.
   [Ha, Young-guk] Konkuk Univ, 120 Neungdong Ro, Seoul, South Korea.
RP Ha, YG (corresponding author), Konkuk Univ, 120 Neungdong Ro, Seoul, South Korea.
EM ybkoo@etri.re.kr; saint@etri.re.kr; ygha@konkuk.ac.kr
CR [Anonymous], CLBLAS
   [Anonymous], CUBLAS
   [Anonymous], CLRNG
   Badía JM, 2019, J SUPERCOMPUT, V75, P1284, DOI 10.1007/s11227-018-2422-6
   Barry D., 2019, XYOLO MODEL REAL TIM
   Beck Kent, 2002, TEST DRIVEN DEV EXAM
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Everingham M., PASCAL VISUAL OBJECT
   Geiger A., 2012, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern. Recognit, DOI 10.1109/CVPR.2012.6248074
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu J., 2016, P 4 INT WORKSH OPENC
   Haseljic H., 2018, P 2018 IEEE INT C IM
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Ji Y, 2018, ETRI J, V40, P435, DOI 10.4218/etrij.2018-0066
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim J, 2015, ETRI J, V37, P793, DOI 10.4218/etrij.15.0114.0076
   Koo Y., 2018, P 1 INT WORKSH DRIV
   Koo Y, 2015, IEEE INT VEH SYM, P394, DOI 10.1109/IVS.2015.7225717
   Lee W, 2018, INT J WEB GRID SERV, V14, P273
   Liao LL, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225107
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Noh S, 2018, IEEE T INTELL TRANSP, V19, P58, DOI 10.1109/TITS.2017.2691346
   Noh S, 2015, ETRI J, V37, P1032, DOI 10.4218/etrij.15.0114.0095
   Nugteren C., 2017, CLTUNE GENERIC AUTOT
   Nugteren C., 2017, CLBLAST TUNED OPENCL
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Park M, 2015, ETRI J, V37, P617, DOI 10.4218/etrij.15.0114.0123
   Redmon J., DARKNET OPEN SOURCE
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 37
TC 6
Z9 6
U1 3
U2 17
PD JUL
PY 2021
VL 24
IS 4
SI SI
BP 1299
EP 1319
DI 10.1007/s11280-020-00778-y
EA FEB 2020
UT WOS:000516001700002
DA 2023-11-16
ER

PT C
AU Shah, M
   Neff, R
   Wu, HC
   Minutoli, M
   Tumeo, A
   Becchi, M
AF Shah, Milan
   Neff, Reece
   Wu, Hancheng
   Minutoli, Marco
   Tumeo, Antonino
   Becchi, Michela
GP ACM
TI Accelerating Random Forest Classification on GPU and FPGA
SO 51ST INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING, ICPP 2022
SE Proceedings of the International Conference on Parallel Processing
DT Proceedings Paper
CT 51st International Conference on Parallel Processing (ICPP)
CY AUG 29-SEP 01, 2022
CL ELECTR NETWORK
DE random forest classification; GPU; FPGA
AB Random Forests (RFs) are a commonly used machine learning method for classification and regression tasks spanning a variety of application domains, including bioinformatics, business analytics, and software optimization. While prior work has focused primarily on improving performance of the training of RFs, many applications, such as malware identification, cancer prediction, and banking fraud detection, require fast RF classification.
   In this work, we accelerate RF classification on GPU and FPGA. In order to provide efficient support for large datasets, we propose a hierarchical memory layout suitable to the GPU/FPGA memory hierarchy. We design three RF classification code variants based on that layout, and we investigate GPU- and FPGA-specific considerations for these kernels. Our experimental evaluation, performed on an Nvidia Xp GPU and on a Xilinx Alveo U250 FPGA accelerator card using publicly available datasets on the scale of millions of samples and tens of features, covers various aspects. First, we evaluate the performance benefits of our hierarchical data structure over the standard compressed sparse row (CSR) format. Second, we compare our GPU implementation with cuML, a machine learning library targeting Nvidia GPUs. Third, we explore the performance/accuracy tradeoff resulting from the use of different tree depths in the RF. Finally, we perform a comparative performance analysis of our GPU and FPGA implementations. Our evaluation shows that, while reporting the best performance on GPU, our code variants outperform the CSR baseline both on GPU and FPGA. For high accuracy targets, our GPU implementation yields a 5-9x speedup over CSR, and up to a 2x speedup over Nvidia's cuML library.
C1 [Shah, Milan; Neff, Reece; Wu, Hancheng; Becchi, Michela] North Carolina State Univ, Raleigh, NC 27695 USA.
   [Minutoli, Marco; Tumeo, Antonino] Pacific Northwest Natl Lab, Richland, WA USA.
RP Shah, M (corresponding author), North Carolina State Univ, Raleigh, NC 27695 USA.
EM mkshah5@ncsu.edu; rwneff@ncsu.edu; hwu16@ncsu.edu;
   marco.minutoli@pnnl.gov; Antonino.Tumeo@pnnl.gov; mbecchi@ncsu.edu
CR Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Black Paul E, 2020, DADS ON LINE DICT AL
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Cheng C, 2013, I C FIELD PROG LOGIC
   Dua D., 2017, UCI MACHINE LEARNING
   Goldfarb M, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503223
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Karras Tero, 2012, THINKING PARALLEL 2
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lin X, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P415, DOI 10.1145/3060403.3060416
   Marron Diego, 2014, P 21 EUR C ART INT
   Mei XX, 2017, IEEE T PARALL DISTR, V28, P72, DOI 10.1109/TPDS.2016.2549523
   Melikoglu O, 2019, Arxiv, DOI [arXiv:1912.01556, 10.48550/ARXIV.1912.01556, DOI 10.48550/ARXIV.1912.01556]
   Nakahara H, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P289, DOI 10.1109/FPT.2016.7929555
   Pavlyk Oleksandr, 2020, ACCELERATE YOUR SCIK
   Raschka S, 2020, Arxiv, DOI arXiv:2002.04803
   SINGH JP, 1995, J PARALLEL DISTR COM, V27, P118, DOI 10.1006/jpdc.1995.1077
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Wen ZY, 2020, J MACH LEARN RES, V21
   Wu HC, 2017, INT C PAR DISTRIB SY, P586, DOI 10.1109/ICPADS.2017.00082
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3545008.3545067
UT WOS:001062754200004
DA 2023-11-16
ER

PT J
AU Huang, BH
   Gonzalez-Zacarias, C
   Guitron, SS
   Aslam, A
   Biedron, SG
   Brown, K
   Bolin, T
AF Huang, Bohong
   Gonzalez-Zacarias, Clio
   Guitron, Salvador Sosa
   Aslam, Aasma
   Biedron, Sandra G.
   Brown, Kevin
   Bolin, Trudy
TI Artificial Intelligence-Assisted Design and Virtual Diagnostic for the
   Initial Condition of a Storage-Ring-Based Quantum Information System
SO IEEE ACCESS
DT Article
DE Curve fitting; ion beams; lasers; machine learning; nonlinear equations;
   particle accelerators; phonons; quantum computing; storage rings
ID NEURAL-NETWORKS; ION; PHYSICS
AB Developments in Artificial Intelligence (AI) are helping to solve complex physical problems that otherwise may be too computationally demanding to solve using traditional approaches. Universal Approximation Theorems tell us that we can model any physical system if we can approximate the system with some continuous function (i.e., compact convergence topology and algorithmically generated sets of functions, such as the convolutional neural network), whether for an arbitrary depth or arbitrary width neural network. We consider the problem of solving a set of N coupled algebraic equations as N becomes very large and apply machine learning (ML) to solve this problem for any value of N. The physical problem we are focusing on is to model the equilibrium positions of ions in an ion trap. A storage ring quantum computer could contain well over tens of thousands of ions. Quickly determining the equilibrium positions will be important to minimize the time to target and observe each ion. As each ion serves as a single qubit, this is important for setting and measuring the individual qubit states. The phonon modes from a collection of ions acts as another qubit, useful for gate operations. Measuring the phonon modes, where ions are oscillating around their respective equilibrium positions also means understanding the equilibrium positions very well. Turning all of this into a virtual diagnostic allows real time prediction and comparison to ensure unique definition of each ion.
C1 [Huang, Bohong] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
   [Gonzalez-Zacarias, Clio] Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Guitron, Salvador Sosa; Aslam, Aasma; Biedron, Sandra G.; Bolin, Trudy] Univ New Mexico, Elect & Comp Engn Dept, Albuquerque, NM 87106 USA.
   [Biedron, Sandra G.] Univ New Mexico, Mech Engn Dept, Albuquerque, NM 87106 USA.
   [Biedron, Sandra G.; Bolin, Trudy] Element Aero, Chicago, IL 60643 USA.
   [Brown, Kevin] SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Brown, Kevin] Brookhaven Natl Lab, Collider Accelerator Dept, Upton, NY 11973 USA.
RP Huang, BH (corresponding author), SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
EM bohong.huang@stonybrook.edu
CR [Anonymous], 2018, NATL STRATEGIC OVERV
   [Anonymous], 1994, PRINCIPLES QUANTUM M
   [Anonymous], 2005, NEURAL NETWORKS METH, DOI DOI 10.1007/3-540-28847-3
   Bar-Sinai Y, 2019, P NATL ACAD SCI USA, V116, P15344, DOI 10.1073/pnas.1814058116
   Biedron S. G., 2019, P 10 INT PART ACC C, P1
   Biedron S. G., 2018, P 12 INT WORKSH PERS, P1
   Bollinger J., 1991, LASER COOLING TRAPPE
   Brown KA, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.054701
   BROWN LS, 1986, REV MOD PHYS, V58, P233, DOI 10.1103/RevModPhys.58.233
   Dirac P. A. M, 1981, PRINCIPLES QUANTUM M, V27
   Drewsen M, 2015, PHYSICA B, V460, P105, DOI 10.1016/j.physb.2014.11.050
   Edelen A., 2018, ARXIV181103172
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Foot C. J., 2007, ATOMIC PHYS
   Grif ~ths D. J., 2004, INTRO QUANTUM MECH, V2nd
   Gyongyosi L, 2019, COMPUT SCI REV, V31, P51, DOI 10.1016/j.cosrev.2018.11.002
   Hanuka A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82473-0
   James DFV, 1998, APPL PHYS B-LASERS O, V66, P181, DOI 10.1007/s003400050373
   King DB, 2015, ACS SYM SER, V1214, P1
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Marquet C, 2003, APPL PHYS B-LASERS O, V76, P199, DOI 10.1007/s00340-003-1097-7
   More J. J., 1980, FORTRAN, DOI DOI 10.2172/6997568, Patent No. CMP00068642
   Newville M., 2014, ZENODO
   Nielsen M. A., 2002, QUANTUM INFORM QUANT
   Paszke A, 2019, ADV NEUR IN, V32
   PAUL W, 1990, REV MOD PHYS, V62, P531, DOI 10.1103/RevModPhys.62.531
   RAFAC R, 1991, P NATL ACAD SCI USA, V88, P483, DOI 10.1073/pnas.88.2.483
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   SCHIFFER JP, 1993, PHYS REV LETT, V70, P818, DOI 10.1103/PhysRevLett.70.818
   Schramm U, 2002, PLASMA PHYS CONTR F, V44, pB375, DOI 10.1088/0741-3335/44/12B/326
   Sessler A. M., 1996, LBL38278, V7, P93
   Steane A, 1997, APPL PHYS B-LASERS O, V64, P623, DOI 10.1007/s003400050225
   Stevens R., 2020, REPORT DEP ENERGY DO
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
NR 36
TC 1
Z9 1
U1 1
U2 5
PY 2022
VL 10
BP 14350
EP 14358
DI 10.1109/ACCESS.2022.3147727
UT WOS:000753403200001
DA 2023-11-16
ER

PT J
AU Hsia, SC
   Wang, SH
   Yeh, JY
   Chang, CY
AF Hsia, Shih-Chang
   Wang, Szu-Hong
   Yeh, Jen-Yu
   Chang, Chuan-Yu
TI A Smart Leaf Blow Robot Based on Deep Learning Model
SO IEEE ACCESS
DT Article
DE Leaf recognition; robot; blow machine; recognition; convolutional neural
   networks (CNNs)
ID RECOGNITION; CIRCUIT; MEMORY
AB Although leaves are everywhere in the world, and they also play a vital role in our daily life, they tend to fall all over the ground in due course, thereby making it difficult for pedestrians and vehicles to move. In this paper, an automatic leaf blower was designed and based on the concept of convolutional neural network(CNN). This system can automatically collect leaves into a garbage bag. A four-wheel driving robot was implemented to drive a blow machine. The control sensors of this robot mainly include a camera, ultrasound, the electronic compass and acceleration. Besides, an ultra-wide band located module was used to obtain the position of the current robot during the working process. Also, the computer vision was employed to recognize whether the leaves are on the ground. For this, ResNet50 deep CNN was used as the training model to recognize the fallen leaves. Since there are many kinds of trees, their leaves are different shape. We collected the images of these leaves as dataset for training, and the recognition rate achieved 92.5%. The obtained result was sent to the controller to control the moving direction of the robot. For the real-time operation, the embedded system was used to sense the leaf data to decide the movement made by the machine based on a control algorithm. The CNN model was implemented with an accelerator on the embedded system for the real-time purpose, which the recognition speed can achieve 20 frames per second form the camera. The automatic leaf blow machine can be possibly used in an effective way instead of human power.
C1 [Hsia, Shih-Chang; Wang, Szu-Hong; Yeh, Jen-Yu; Chang, Chuan-Yu] Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Touliu 64002, Yunlin, Taiwan.
RP Hsia, SC (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Touliu 64002, Yunlin, Taiwan.
EM hsia@yuntech.edu.tw
CR alldatasheet, US
   Ashok S, 2020, 2020 5 INT C COMMUNI, P979, DOI [10.1109/ICCES48766.2020.9137986, DOI 10.1109/ICCES48766.2020.9137986]
   decawave.com, UWB MANUAL
   Gargade A, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P267, DOI [10.1109/iccmc.2019.8819867, 10.1109/ICCMC.2019.8819867]
   Ghosh P, 2020, IEEE T MOBILE COMPUT, V19, P1260, DOI 10.1109/TMC.2019.2909020
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsia S.-C., 2020, IEEE ACCESS, V8
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   itdaan.com, US
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946
   Kim J, 2016, IEEE T IND ELECTRON, V63, P3616, DOI 10.1109/TIE.2016.2523460
   leafsnap.com, LEAFSNAP DATASET
   Lim J, 2015, INT CONF ELECTRO INF, P621, DOI 10.1109/EIT.2015.7293407
   Codizar AL, 2016, INT CONF INFORM INTE
   makita.com, ELECT BLOW MACHINE D
   Sun JW, 2021, IEEE T BIOMED CIRC S, V15, P606, DOI 10.1109/TBCAS.2021.3090786
   youtu.be, US
   Zhang LK, 2018, 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY ROBOTICS (ICT-ROBOT)
   Zhang YT, 2021, IEEE T BIOMED CIRC S, V15, P978, DOI 10.1109/TBCAS.2021.3108354
   Zhao YF, 2022, IEEE ACM T COMPUT BI, V19, P1817, DOI 10.1109/TCBB.2021.3056683
NR 20
TC 0
Z9 0
U1 1
U2 1
PY 2023
VL 11
BP 111956
EP 111962
DI 10.1109/ACCESS.2023.3307136
UT WOS:001086206300001
DA 2023-11-16
ER

PT J
AU Yantir, HE
   Eltawil, AM
   Kurdahi, FJ
AF Yantir, Hasan Erdem
   Eltawil, Ahmed M.
   Kurdahi, Fadi J.
TI Hybrid Approximate Computing Approach for Associative In-Memory
   Processors
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Meroristor; in-memory computing; resistive associative processor (RAP);
   approximate computing; memristance scaling; approximate computing;
   approximate storage; architecture
AB The complexity of the computational problems is rising faster than the computational platforms' capabilities which are also becoming increasingly costly to operate due to their increased need for energy. This forces researchers to find alternative paradigms and methods for efficient computing. One promising paradigm is accelerating compute-intensive kernels using in-memory computing accelerators, where data movements are significantly reduced. Another increasingly popular method for improving energy efficiency is approximate computing. In this paper, we propose a methodology for efficient approximate in-memory computing. To maximize energy savings for a given approximation constraints, a hybrid approach is presented combining both voltage and precision scaling. This can be applied to an associative memory-based architecture that can be implemented today using CMOS memories (SRAM) but can be seamlessly scaled to emerging ReRAM-based memory technology later with minimal effort. For the evaluation of the proposed methodology, a diverse set of domains is covered, such as image processing, machine learning, machine vision, and digital signal processing. When compared to full-precision, unsealed implementations, average energy savings of 5.17x and 59.11x, and speedups of 2.1x and 3.24x in SRAM-based and ReRAM-based architectures, respectively, are reported.
C1 [Yantir, Hasan Erdem; Eltawil, Ahmed M.; Kurdahi, Fadi J.] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
RP Yantir, HE (corresponding author), Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
EM hyantir@uci.edu; aeltawil@uci.edu; kurdahi@uci.edu
CR Agrawal A., 2016, P IEEE INT C REB COM, P1, DOI DOI 10.1109/ICRC.2016.7738674
   [Anonymous], CISC VIS NETW IND GL
   [Anonymous], 1968, 3X3 ISOTROPIC GRADIE
   [Anonymous], 2011, P DATE
   [Anonymous], 1991, ASS COMPUTING PROGRA
   [Anonymous], ACM COMPUT SURV
   [Anonymous], TECH REP
   [Anonymous], 4M 512 K 8 BIT SPI M
   [Anonymous], 1T1R PROD PIC EMB RE
   Arizona State University, 2012, PREDICTIVE TECHNOLOG
   Borkar S, 2013, INT PARALL DISTRIB P, P3, DOI 10.1109/IPDPS.2013.121
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Foster C. C., 1976, CONTENT ADDRESSABLE
   Imani M, 2018, IEEE T MULTI-SCALE C, V4, P17, DOI 10.1109/TMSCS.2017.2665462
   Imani M, 2019, IEEE T EMERG TOP COM, V7, P271, DOI 10.1109/TETC.2016.2642057
   Imani M, 2016, DES AUT TEST EUROPE, P1327
   Karpuzcu U.R., 2012, DEPENDABLE SYSTEMS N, P1
   Karpuzcu UR, 2013, IEEE MICRO, V33, P6, DOI 10.1109/MM.2013.71
   Kim KM, 2016, SCI REP-UK, V6, DOI 10.1038/srep20085
   Kim Y, 2017, ICCAD-IEEE ACM INT, P25, DOI 10.1109/ICCAD.2017.8203756
   Li J, 2014, IEEE J SOLID-ST CIRC, V49, P896, DOI 10.1109/JSSC.2013.2292055
   Miao F, 2011, ADV MATER, V23, P5633, DOI 10.1002/adma.201103379
   Misailovic S., 2010, P 32 ACMIEEE INT C S, V1, P25, DOI DOI 10.1145/1806799.1806808
   Pinckney Nathaniel, 2013, 2013 Symposium on VLSI Circuits, pC290
   Rahimi A, 2015, DES AUT TEST EUROPE, P1497
   Roy K, 2013, IEEE INT SYMP DESIGN, P5, DOI 10.1109/DDECS.2013.6549776
   SCHERSON ID, 1989, J PARALLEL DISTR COM, V6, P69, DOI 10.1016/0743-7315(89)90043-9
   Schinkel D., 2007, IEEE INT SOLID STATE, P314, DOI DOI 10.1109/ISSCC.2007.373420
   Sidiroglou-Douskos S., 2011, 19 ACM SIGSOFT, P124, DOI DOI 10.1145/2025113.2025133
   Sinha S, 2012, DES AUT CON, P283
   Taha MMA, 2016, IEEE INT SYMP NANO, P159
   Venkataramani S, 2012, DES AUT CON, P796
   Yakopcic C, 2013, IEEE T COMPUT AID D, V32, P1201, DOI 10.1109/TCAD.2013.2252057
   Yantir HE, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126526
   Yantir HE, 2016, PR IEEE COMP DESIGN, P49, DOI 10.1109/ICCD.2016.7753260
   Yavits L, 2015, IEEE COMPUT ARCHIT L, V14, P148, DOI 10.1109/LCA.2014.2374597
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
   Yazdanbakhsh A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P482, DOI 10.1145/2830772.2830810
   Yazdanbakhsh A, 2015, DES AUT TEST EUROPE, P812
   Zhao HY, 2017, ICCAD-IEEE ACM INT, P268, DOI 10.1109/ICCAD.2017.8203788
NR 41
TC 17
Z9 18
U1 0
U2 6
PD DEC
PY 2018
VL 8
IS 4
BP 758
EP 769
DI 10.1109/JETCAS.2018.2852701
UT WOS:000454224200008
DA 2023-11-16
ER

PT J
AU Turkkan, G
   Bilici, N
   Sertel, H
   Keskus, Y
   Alkaya, S
   Tavli, B
   Ozkirim, M
   Fayda, M
AF Turkkan, Gorkem
   Bilici, Nazli
   Sertel, Huseyin
   Keskus, Yavuz
   Alkaya, Sercan
   Tavli, Busra
   Ozkirim, Muge
   Fayda, Merdan
TI Clinical utility of a 1.5 T magnetic resonance imaging-guided linear
   accelerator during conventionally fractionated and hypofractionated
   prostate cancer radiotherapy
SO FRONTIERS IN ONCOLOGY
DT Article
DE adaptive radiotherapy; fractionated radiotherapy; MRI-guided
   radiotherapy; MRI-LINAC; prostate cancer
AB PurposeTo report our initial experience with 1.5 T magnetic resonance imaging (MRI) linear accelerator (LINAC) in prostate cancer radiotherapy in terms of its use in a radiation oncology clinic. MethodsThe medical records of 14 prostate cancer patients treated with MRI-guided radiotherapy were retrospectively evaluated. The fraction time, adapt-to-position (ATP):adapt-to-shape (ATS) usage rate, machine-associated treatment interruption rate, median gamma pass rate, the percentage of planning target volume receiving at least 95% of the prescription dose coverage value of each ATS fraction, the effect of the learning curve on the fraction time and radiation-related acute gastrointestinal and genitourinary toxicities were evaluated. ResultsFourteen patients have completed their treatment receiving a total of 375 fractions. Six patients (42%) were treated with the moderately hypofractionated regimen, five patients (36%) with conventionally fractionated, and three patients (22%) with the ultra-hypofractionated radiotherapy regimens. The ATP : ATS usage ratio was 3:372. The median fraction time was 46 min (range, 24-81 min). For the 3%/3 mm criterion, median gamma pass rate was 99.4% (range, 94.6-100%). Machine-related treatment interruptions were observed in 11 (2.9%) of 375 fractions, but this interruption rate decreased from 4.1% to 0.8%, after an upgrade. Three patients (22%) had gastrointestinal and five patients (36%) had genitourinary toxicity. No >= grade 3 toxicity was observed. Conclusion1.5 T MRI-LINAC device could be used as a conventional LINAC device, when the conditions of the radiotherapy center are appropriate. MRI-guided prostate radiotherapy is safe and feasible, and high-quality studies with a larger number of patients and long-term results are needed to better evaluate this new technology.
C1 [Turkkan, Gorkem; Fayda, Merdan] Istinye Univ, Fac Med, Dept Radiat Oncol, Istanbul, Turkey.
   [Turkkan, Gorkem; Bilici, Nazli; Sertel, Huseyin; Keskus, Yavuz; Alkaya, Sercan; Tavli, Busra; Ozkirim, Muge; Fayda, Merdan] Liv Hosp Ulus, Dept Radiat Oncol, Istanbul, Turkey.
RP Turkkan, G (corresponding author), Istinye Univ, Fac Med, Dept Radiat Oncol, Istanbul, Turkey.; Turkkan, G (corresponding author), Liv Hosp Ulus, Dept Radiat Oncol, Istanbul, Turkey.
EM gorkemturkkan@gmail.com
CR Alongi F, 2020, RADIAT ONCOL, V15, DOI 10.1186/s13014-020-01510-w
   Bertelsen AS, 2019, ACTA ONCOL, V58, P1352, DOI 10.1080/0284186X.2019.1627417
   Brand DH, 2019, LANCET ONCOL, V20, P1531, DOI 10.1016/S1470-2045(19)30569-8
   de Leon J, 2022, J MED IMAG RADIAT ON, V66, P138, DOI 10.1111/1754-9485.13336
   Felisi M, 2021, TUMORI J, V107, pNP41, DOI 10.1177/0300891621997549
   Jemal A, 2009, CA-CANCER J CLIN, V59, P225, DOI [10.3322/caac.20006, 10.3322/caac.21332, 10.3322/caac.21387, 10.3322/caac.21601, 10.3322/caac.20073, 10.3322/caac.21254]
   Keizer DMD, 2020, RADIOTHER ONCOL, V151, P88, DOI 10.1016/j.radonc.2020.06.044
   Kontaxis C, 2017, MED PHYS, V44, P5034, DOI 10.1002/mp.12467
   Mahmood F, 2017, PHYS MED BIOL, V62, P2990, DOI 10.1088/1361-6560/aa5249
   Marks LB, 2010, INT J RADIAT ONCOL, V76, pS10, DOI 10.1016/j.ijrobp.2009.07.1754
   Mönnich D, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba5ec
   Murray J, 2019, CLIN TRANSL RAD ONCO, V18, P68, DOI 10.1016/j.ctro.2019.03.006
   Pathmanathan AU, 2018, INT J RADIAT ONCOL, V100, P361, DOI 10.1016/j.ijrobp.2017.10.020
   Winkel D, 2019, CLIN TRANSL RAD ONCO, V18, P54, DOI 10.1016/j.ctro.2019.04.001
   Yang B, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/abfa80
NR 15
TC 1
Z9 1
U1 0
U2 1
PD AUG 16
PY 2022
VL 12
AR 909402
DI 10.3389/fonc.2022.909402
UT WOS:000847326500001
DA 2023-11-16
ER

PT C
AU Andriyanov, NA
AF Andriyanov, N. A.
GP IEEE
TI Analysis of the Acceleration of Neural Networks Inference on Intel
   Processors Based on OpenVINO Toolkit
SO 2020 SYSTEMS OF SIGNAL SYNCHRONIZATION, GENERATING AND PROCESSING IN
   TELECOMMUNICATIONS (SYNCHROINFO)
DT Proceedings Paper
CT Conference on Systems of Signal Synchronization, Generating and
   Processing in Telecommunications (SYNCHROINFO)
CY JUL 01-03, 2020
CL Svetlogorsk, RUSSIA
DE object detection; pattern recognition; neural networks; machine
   learning; neural network inference; CPU; Intel; OpenVINO; Toolkit;
   SSD_MobileNet; COCO dataset
AB The article studies the performance of a trained neural network SSD_MobileNet_V2_COCO. It is proposed to use the OpenVINO Toolkit to increase network performance. Performance evaluation is calculated by the reciprocal of the frame processing time, which characterizes the number of frames processed per second. Dataset COCO ( by Microsoft) was used as the source dataset. In this case, 200 images were selected from this dataset, and during processing all images were reduced to the same sizes 300x300. Studies shown that the use of OpenVINO has increased the performance of the neural network SSD_MobileNet_V2_COCO by 130 times on average. At the same time, in contrast to starting a network using TensorFlow only, the variance of network performance using OpenVINO is significantly increased. However, the use of such an accelerator remains appropriate on Intel processors.
C1 [Andriyanov, N. A.] JSC RPC Istok, Fryazino, Russia.
   [Andriyanov, N. A.] Ulyanovsk State Tech Univ, Ulyanovsk, Russia.
RP Andriyanov, NA (corresponding author), JSC RPC Istok, Fryazino, Russia.; Andriyanov, NA (corresponding author), Ulyanovsk State Tech Univ, Ulyanovsk, Russia.
EM nikita-and-nov@mail.ru
CR Albawi S, 2017, I C ENG TECHNOL
   Almakady Y, 2020, COMPUT VIS IMAGE UND, V194, DOI 10.1016/j.cviu.2020.102931
   Andriyanov N. A., 2018, Journal of Physics: Conference Series, V1096, DOI 10.1088/1742-6596/1096/1/012036
   Andriyanov N.A., 2018, CEUR WORKSHOP PROC, V2210, P219
   [Anonymous], E RESOURSE
   Song G, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102916
   Vasilev K. K., 2020, INTELL SYST REF LIB, V175, P11, DOI [10.1007/978-3-030-33795-7_2, DOI 10.1007/978-3-030-33795-7_2]
   Vasiliev K, 2018, PROCEDIA COMPUT SCI, V126, P49, DOI 10.1016/j.procs.2018.07.208
   Wu Q, 2017, CHIN AUTOM CONGR, P6522, DOI 10.1109/CAC.2017.8243952
   Zheltov S.Yu., 2020, IMAGE PROCESSING ANA
NR 10
TC 15
Z9 15
U1 0
U2 0
PY 2020
DI 10.1109/synchroinfo49631.2020.9166067
UT WOS:000728179900048
DA 2023-11-16
ER

PT C
AU Luo, YY
   Wang, XY
   Ogrenci-Memik, S
   Memik, G
   Yoshii, K
   Beckman, P
AF Luo, Yingyi
   Wang, Xiaoyang
   Ogrenci-Memik, Seda
   Memik, Gokhan
   Yoshii, Kazutomo
   Beckman, Pete
GP IEEE
TI Minimizing Thermal Variation in Heterogeneous HPC Systems with FPGA
   Nodes
SO 2018 IEEE 36TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 36th IEEE International Conference on Computer Design (ICCD)
CY OCT 07-10, 2018
CL Orlando, FL
AB The presence of FPGAs in data centers has been growing due to their superior performance as accelerators. Thermal management, particularly battling the cooling cost in these high performance systems, is a primary concern. Introduction of new heterogeneous components only adds further complexities to thermal modeling and management. The thermal behavior of multi-FPGA systems deployed within large compute clusters is little explored. In this paper, we first show that the thermal behaviors of different FPGAs of the same generation can vary due to their physical locations in a rack and process variation, even though they are running the same tasks. We present a machine learning based model to capture the thermal behavior of a multi-node FPGA cluster. We then propose to mitigate thermal variation and hotspots across the cluster by proactive task placement guided by our thermal model. Our experiments show that through proper placement of tasks on the multi-FPGA system, we can reduce the peak temperature by up to 11.50 degrees C with no impact on performance.
C1 [Luo, Yingyi; Wang, Xiaoyang; Ogrenci-Memik, Seda; Memik, Gokhan] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
   [Yoshii, Kazutomo; Beckman, Pete] Argonne Natl Lab, Math & Comp Sci Div, Argonne, IL 60439 USA.
RP Luo, YY (corresponding author), Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
EM yingyi@u.northwestern.edu; xiaoyangwang2018@u.northwestern.edu;
   seda@eecs.northwestern.edu; memik@eecs.northwestern.edu;
   kazutomo@mcs.anl.gov; beckman@anl.gov
CR [Anonymous], 2006, TECH REP
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631
   Bauer Michael, 2012, P INT C HIGH PERFORM, P66
   Caulfield AM, 2016, INT SYMP MICROARCH
   Coskun AK, 2007, DES AUT TEST EUROPE, P1659
   Dai Jun, 2014, OPTIMUM COOLING DATA, P1
   Diamos Gregory F., 2008, P 17 INT S HIGH PERF, P197, DOI DOI 10.1145/1383422.1383447
   Ebrahimi K, 2014, RENEW SUST ENERG REV, V31, P622, DOI 10.1016/j.rser.2013.12.007
   I. Corp, 2017, INT FPGA SDK OPENCL
   Jing C, 2013, MICROPROCESS MICROSY, V37, P590, DOI 10.1016/j.micpro.2013.05.001
   Kleinberg EM, 1996, ANN STAT, V24, P2319
   Kleinberg EM, 2000, IEEE T PATTERN ANAL, V22, P473, DOI 10.1109/34.857004
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lian Tuu Yeh R. C. C., 2002, THERMAL MANAGEMENT M
   Mambretti J, 2015, 2015 INTERNATIONAL CONFERENCE ON CLOUD COMPUTING RESEARCH AND INNOVATION (ICCCRI), P73, DOI 10.1109/ICCCRI.2015.10
   Mangalagiri Prasanth, 2008, 2008 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), P722, DOI 10.1109/ICCAD.2008.4681656
   Murali S., 2007, 2007 5th IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P111
   Ogrenci-Memik S., 2016, MAT CIRCUITS DEVICES
   Smoyer J.L., 2018, HEAT TRANSFER ENG, V0, P1
   Spitaels J., 2005, DYNAMIC POWER VARIAT, V5
   Tang QH, 2008, IEEE T PARALL DISTR, V19, P1458, DOI 10.1109/TPDS.2008.111
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   VanGilder J. W., 2009, P WORKSH EN EFF DES, V11, P1
   Zhang K., 2017, IEEE T PARALLEL DIST
   Zhang KC, 2015, INT PARALL DISTRIB P, P1139, DOI 10.1109/IPDPS.2015.37
NR 25
TC 3
Z9 3
U1 0
U2 1
PY 2018
BP 537
EP 544
DI 10.1109/ICCD.2018.00086
UT WOS:000458293200075
DA 2023-11-16
ER

PT C
AU Choi, WH
   Chiu, PF
   Ma, W
   Hemink, G
   Hoang, TT
   Lueker-Boden, M
   Bandic, Z
AF Choi, Won Ho
   Chiu, Pi-Feng
   Ma, Wen
   Hemink, Gertjan
   Tung Thanh Hoang
   Lueker-Boden, Martin
   Bandic, Zvonimir
GP IEEE
TI An In-flash Binary Neural Network Accelerator with SLC NAND Flash Array
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
DE NAND Flash; Binarized Neural Network (BNN); In-Memory Computing; Machine
   Learning
AB An SLC NAND array based in-flash computing core is proposed for enabling vector-matrix multiplications in binarized neural network (BNN) and binary weight network (BWN). Two SLC NAND floating gate (FG) cells in the same string store complementary data to encode binarized weight value of a single synapse for realizing the BNN algorithm. By activating multiple BLs and WLs across block and/or plane levels, the performance of vector-matrix multiplications is significantly accelerated.
   The system architecture using in-flash computing core for BNN/BWN acceleration is introduced. A wide range of BNN/BWN models can be efficiently mapped to a scalable array of in-flash computing core. An in-flash computing core is able to achieve an estimated peak energy efficiency of 2.56 TOP/s/W for BNN, 292.6 GOP/s/W for 8-b input based BWN by customizing the numbers of word-lines (WLs)/BLs/blocks/planes.
C1 [Choi, Won Ho; Chiu, Pi-Feng; Ma, Wen; Hemink, Gertjan; Tung Thanh Hoang; Lueker-Boden, Martin; Bandic, Zvonimir] Western Digital Res, Milpitas, CA 95035 USA.
RP Choi, WH (corresponding author), Western Digital Res, Milpitas, CA 95035 USA.
CR [Anonymous], 2019, NVIDIA T4 TENSOR COR
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheong W, 2018, ISSCC DIG TECH PAP I, P338, DOI 10.1109/ISSCC.2018.8310322
   Chiu PF, 2019, IEEE INT SYMP CIRC S
   Gonugondla SK, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351458
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Mohan V, 2013, IEEE T COMPUT AID D, V32, P1031, DOI 10.1109/TCAD.2013.2249557
   Rastegari Mohammad, 2018, ARXIV160305279V4
   Wang PN, 2019, IEEE T VLSI SYST, V27, P988, DOI 10.1109/TVLSI.2018.2882194
NR 10
TC 7
Z9 8
U1 1
U2 1
PY 2020
UT WOS:000706854700103
DA 2023-11-16
ER

PT C
AU Rasoori, S
   Akella, V
AF Rasoori, Sandeep
   Akella, Venkatesh
GP ACM
TI Scalable Hardware Accelerator for Mini-Batch Gradient Descent
SO PROCEEDINGS OF THE 2018 GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI'18)
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 23-25, 2018
CL Chicago, IL
DE Stochastic Gradient Descent; Mini-Batch Gradient Descent; Machine
   Learning; FPGA; CPU; Embedded Memories; Caches
AB Iterative first-order methods that use gradient information form the core computation kernels of modern statistical data analytic engines, such as MADLib, Impala, Google Brain, GraphLab, MLlib in Spark, among others. Even the most advanced parallel stochastic gradient descent algorithm, such as Hogwild is not very scalable on conventional chip multiprocessors because of the bottlenecks induced by the memory system when sharing large model vectors. We propose a scalable architecture for large scale parallel gradient descent on a Field Programmable Gate Array (FPGA) by taking advantage of the large amount of embedded memory in modern FPGAs. We propose a novel data layout mechanism that eliminates the need for expensive synchronization and locking of shared data, which makes the architecture scalable. A 32-PE system on the Stratix V FPGA shows about 5x improvement in performance compared to state-of-the-art implementation on a 14 core/28 thread Intel Xeon CPU with 64 GB memory and operating at 2.6 GHz.
C1 [Rasoori, Sandeep; Akella, Venkatesh] Univ Calif Davis, Elect & Comp Engn Dept, Davis, CA 95616 USA.
RP Rasoori, S (corresponding author), Univ Calif Davis, Elect & Comp Engn Dept, Davis, CA 95616 USA.
EM srasoori@ucdavis.edu; akella@ucdavis.edu
CR [Anonymous], 2015, ACCELERATING DEEP CO
   [Anonymous], 2015, 32 ICML
   [Anonymous], 1985, CALIFORNIA U SAN DIE, DOI DOI 10.21236/ADA164453
   [Anonymous], 2017, ARXIV170103534
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Choi YJ, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/3286191
   Li HY, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/6786184
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Mutnury B., 2010, 2010 IEEE 19th Conference on Electrical Performance of Electronic Packaging and Systems (EPEPS 2010), P265, DOI 10.1109/EPEPS.2010.5642789
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Recht Benjamin, 2011, ADV NEURAL INFORM PR, V24, P693
   Sallinen S, 2016, INT PARALL DISTRIB P, P873, DOI 10.1109/IPDPS.2016.107
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Zhang C, 2014, PROC VLDB ENDOW, V7, P1283, DOI 10.14778/2732977.2733001
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2016, IEEE SYM PARA DISTR, P148, DOI 10.1109/IPDPSW.2016.117
   Zhang H., 2016, HOGWILD NEW MECH DEC
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Ziakas Dimitrios, 2010, HIGH PERF INT HOTI 2, P1
NR 23
TC 1
Z9 1
U1 0
U2 1
PY 2018
BP 159
EP 164
DI 10.1145/3194554.3194559
UT WOS:000515794900030
DA 2023-11-16
ER

PT J
AU Mao, WD
   Yang, PX
   Wang, ZF
AF Mao, Wendong
   Yang, Peixiang
   Wang, Zhongfeng
TI FTA-GAN: A Computation-Efficient Accelerator for GANs With Fast
   Transformation Algorithm
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Deconvolution; Generative adversarial networks; Convolution; Kernel;
   Hardware; Generators; Memory management; Deconvolution; fast algorithm;
   generative adversarial network (GAN); hardware architecture; transposed
   convolution
ID NEURAL-NETWORKS; ARCHITECTURE
AB Nowadays, generative adversarial network (GAN) is making continuous breakthroughs in many machine learning tasks. The popular GANs usually involve computation-intensive deconvolution operations, leading to limited real-time applications. Prior works have brought several accelerators for deconvolution, but all of them suffer from severe problems, such as computation imbalance and large memory requirements. In this article, we first introduce a novel fast transformation algorithm (FTA) for deconvolution computation, which well solves the computation imbalance problem and removes the extra memory requirement for overlapped partial sums. Besides, it can reduce the computation complexity for various types of deconvolutions significantly. Based on FTA, we develop a fast computing core (FCC) and the corresponding computing array so that the deconvolution can be efficiently computed. We next optimize the dataflow and storage scheme to further reuse on-chip memory and improve the computation efficiency. Finally, we present a computation-efficient hardware architecture for GANs and validate it on several GAN benchmarks, such as deep convolutional GAN (DCGAN), energy-based GAN (EBGAN), and Wasserstein GAN (WGAN). The experimental results show that our design can reach 2211 GOPS under 185-MHz working frequency on Intel Stratix 10SX field-programmable gate array (FPGA) board with satisfactory visual results. In brief, the proposed design can achieve more than 2x hardware efficiency improvement over previous designs, and it can reduce the storage requirement drastically.
C1 [Mao, Wendong; Yang, Peixiang; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Peoples R China.
RP Wang, ZF (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Peoples R China.
EM wdmao@smail.nju.edu.cn; pxyang@smail.nju.edu.cn; zfwang@nju.edu.cn
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Brophy E., 2019, ARXIV190205624
   Chang JW, 2020, IEEE T CIRC SYST VID, V30, P281, DOI 10.1109/TCSVT.2018.2888898
   Chang JW, 2018, ASIA S PACIF DES AUT, P343, DOI 10.1109/ASPDAC.2018.8297347
   Chen YD, 2018, IEEE WCNC
   Courbariaux M., 2016, J MACH LEARN RES
   Di XK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020286
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dosovitskiy Alexey, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157170
   Esteban Cristobal, 2017, ARXIV170602633
   Gudovskiy D. A., 2017, SHIFTCNN GEN LOW PRE
   [何新智 He Xinzhi], 2019, [真空科学与技术学报, Chinese Journal of Vacuum Science and Technology], V39, P361
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   Huang D, 2020, AAAI CONF ARTIF INTE, V34, P4174
   Im D. J., 2016, ARXIV160205110
   Jung-Woo Chang, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P283, DOI 10.1109/ASP-DAC47756.2020.9045214
   Kim T, 2017, PR MACH LEARN RES, V70
   Kodali N., 2017, ARXIV
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li J., 2016, ARXIV161208220
   Liu SL, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242900
   Liu WJ, 2019, IEEE INT SYMP CIRC S
   Liu X., 2018, ARXIV PREPRINT ARXIV
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Mao WD, 2020, IEEE T VLSI SYST, V28, P1867, DOI 10.1109/TVLSI.2020.3000519
   Mao WG, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3345439
   Parhi K. K., 1999, VLSI DIGITAL SIGNAL, P228
   Qian BA, 2021, IEEE T IMAGE PROCESS, V30, P4894, DOI 10.1109/TIP.2021.3076275
   Radford A., 2016, ARXIV PREPRINT ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tonfat J., 2012, 3 IEEE LAT AM S CIRC, P1
   Wang HN, 2019, INT CONF ACOUST SPEE, P1448, DOI 10.1109/ICASSP.2019.8683512
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Xu DW, 2020, IEEE T COMPUT, V69, P1172, DOI 10.1109/TC.2020.3001033
   Xu DW, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240810
   Xu WH, 2020, IEEE T COMPUT AID D, V39, P4894, DOI 10.1109/TCAD.2020.2973355
   Yan JL, 2018, IEEE T COMPUT AID D, V37, P2519, DOI 10.1109/TCAD.2018.2857258
   Yang PX, 2020, IEEE INT NEW CIRC, P210, DOI [10.1109/NEWCAS49341.2020.9159773, 10.1109/newcas49341.2020.9159773]
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang X, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07334-1
   Zhao J., 2017, P 5 INT C LEARN REPR, P100, DOI DOI 10.1109/TCSVT.2017.2710120
   Zhao RZ, 2017, LECT NOTES COMPUT SC, V10216, P255, DOI 10.1007/978-3-319-56258-2_22
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 47
TC 2
Z9 3
U1 1
U2 14
PD JUN
PY 2023
VL 34
IS 6
BP 2978
EP 2992
DI 10.1109/TNNLS.2021.3110728
EA SEP 2021
UT WOS:000732072000001
DA 2023-11-16
ER

PT C
AU Sun, Z
   Pedretti, G
   Ielmini, D
AF Sun, Zhong
   Pedretti, Giacomo
   Ielmini, Daniele
GP IEEE
TI Fast solution of linear systems with analog resistive switching memory
   (RRAM)
SO PROCEEDINGS OF THE 2019 FOURTH IEEE INTERNATIONAL CONFERENCE ON
   REBOOTING COMPUTING (ICRC)
DT Proceedings Paper
CT 4th IEEE International Conference on Rebooting Computing (ICRC)
CY NOV 06-08, 2019
CL San Mateo, CA
DE in-memory computing; linear system; resistive memory; time complexity
AB The in-memory solution of linear systems with analog resistive switching memory in one computational step has been recently reported. In this work, we investigate the time complexity of solving linear systems with the circuit, based on the feedback theory of amplifiers. The result shows that the computing time is explicitly independent on the problem size N, rather it is dominated by the minimal eigenvalue of an associated matrix. By addressing the Toeplitz matrix and the Wishart matrix, we show that the computing time increases with log(N) or N-1/2, respectively, thus indicating a significant speed-up of in-memory computing over classical digital computing for solving linear systems. For sparse positive-definite matrix that is targeted by a quantum computing algorithm, the in-memory computing circuit also shows a computing time superiority. These results support in-memory computing as a strong candidate for fast and energy-efficient accelerators of big data analytics and machine learning.
C1 [Sun, Zhong; Pedretti, Giacomo; Ielmini, Daniele] Politecn Milan, DEIB, Milan, Italy.
   [Sun, Zhong; Pedretti, Giacomo; Ielmini, Daniele] IU NET, Milan, Italy.
RP Sun, Z (corresponding author), Politecn Milan, DEIB, Milan, Italy.; Sun, Z (corresponding author), IU NET, Milan, Italy.
EM zhong.sun@polimi.it; giacomo.pedretti@polimi.it;
   daniele.ielmini@polimi.it
CR Bhatia R, 2007, PRINC SER APPL MATH, P1
   Golub Gene H, 2013, MATRIX COMPUTATIONS, P4, DOI DOI 10.56021/9781421407944
   Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Press W., 2007, NUMERICAL RECIPES AR, V3rd, DOI DOI 10.2277/052143064X
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Razavi B., 2001, DESIGN ANALOG CMOS I
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/nnano.2017.83, 10.1038/NNANO.2017.83]
   Shewchuk JR, 1994, INTRO CONJUGATE GRAD
   SILVERSTEIN JW, 1985, ANN PROBAB, V13, P1364, DOI 10.1214/aop/1176992819
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
NR 15
TC 1
Z9 1
U1 0
U2 3
PY 2019
BP 120
EP 124
DI 10.1109/icrc.2019.8914709
UT WOS:000535357800015
DA 2023-11-16
ER

PT C
AU Abdelouahab, K
   Pelcat, M
   Berry, F
AF Abdelouahab, Kamel
   Pelcat, Maxime
   Berry, Francois
GP ACM
TI PhD Forum: Why TanH is a Hardware Friendly Activation Function for CNNs
SO 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017)
DT Proceedings Paper
CT 11th International Conference on Distributed Smart Cameras (ICDSC)
CY SEP 05-07, 2017
CL Stanford Univ, Palo Alto, CA
HO Stanford Univ
AB Convolutional Neural Networks (CNNs) [1] are the state of the art of image classification that improved accuracy and robustness of machine vision systems at the price of a very high computational cost. This motivated multiple research efforts to investigate the applicability of approximate computing and more particularly, fixed point-arithmetic for CNNs. In all this approaches, a recurrent problem is that the learned parameters in deep fraCNN layers have a significantly lower numerical dynamic range when compared to the feature maps, which prevents from using of a low bit-width representation in deep layers. In this paper, we demonstrate that using the TanH activation function is way to prevent this issue. To support this demonstration, three benchmark CNN models are trained with the TanH function. These models are then quantized using the same bit-width across all the layers. In the case of FPGA based accelerators, this approach infers the minimal amount of logic elements to deploy CNNs.
C1 [Abdelouahab, Kamel; Berry, Francois] Inst Pascal, Clermont Ferrand, France.
   [Pelcat, Maxime] IETR, Rennes, France.
RP Abdelouahab, K (corresponding author), Inst Pascal, Clermont Ferrand, France.
CR Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Courbariaux Matthieu., 2014, TRAINING DEEP NEURAL
   DARRYLDLIN Darryl D Lin, FIXED POINT QUANTIZA
   David JP, 2007, IEEE T COMPUT, V56, P1308, DOI 10.1109/TC.2007.1084.
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Netzer Y., 2011, ADV NEURAL INFORM PR, P1
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
NR 14
TC 7
Z9 8
U1 0
U2 2
PY 2017
BP 199
EP 201
DI 10.1145/3131885.3131937
UT WOS:000716998900032
DA 2023-11-16
ER

PT J
AU Giraldo, JSP
   Lauwereins, S
   Badami, K
   Verhelst, M
AF Giraldo, Juan Sebastian P.
   Lauwereins, Steven
   Badami, Komail
   Verhelst, Marian
TI Vocell: A 65-nm Speech-Triggered Wake-Up SoC for 10-μW Keyword Spotting
   and Speaker Verification
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Keyword spotting (KWS); machine learning (ML) hardware; speaker
   verification (SV); speech recognition
ID RECOGNITION
AB The use of speech-triggered wake-up interfaces has grown significantly in the last few years for use in ubiquitous and mobile devices. Since these interfaces must always be active, power consumption is one of their primary design metrics. This article presents a complete mixed-signal system-on-chip, capable of directly interfacing to an analog microphone and performing keyword spotting (KWS) and speaker verification (SV), without any need for further external accesses. Through the use of: 1) an integrated single-chip digital-friendly design; b) hardware-aware algorithmic optimization; and c) memory- and power-optimized accelerators, ultra-low power is achieved while maintaining high accuracy for speech recognition tasks. The 65-nm implementation achieves 18.3- $\mu \text{W}$ worst case power consumption or 10.6- $\mu \text{W}$ power for typical real-time scenarios, $10\times $ below state of the art (SoA).
C1 [Giraldo, Juan Sebastian P.; Verhelst, Marian] KU Leuven ICTS, Dept Elect Engn, B-3001 Heverlee, Belgium.
   [Lauwereins, Steven] Televic Rail, B-8870 Izegem, Belgium.
   [Badami, Komail] CSEM Zurich, CH-8005 Zurich, Switzerland.
RP Giraldo, JSP (corresponding author), KU Leuven ICTS, Dept Elect Engn, B-3001 Heverlee, Belgium.
EM giraldo@esat.kuleuven.be
CR [Anonymous], P IEEE TRENDS SPEECH
   [Anonymous], P C SYST MACH LEARN
   Badami K, 2018, SYMP VLSI CIRCUITS, P241, DOI 10.1109/VLSIC.2018.8502343
   Badami KMH, 2016, IEEE J SOLID-ST CIRC, V51, P291, DOI 10.1109/JSSC.2015.2487276
   Baljekar P, 2014, IEEE W SP LANG TECH, P536, DOI 10.1109/SLT.2014.7078631
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Chen ZH, 2018, SPEECH COMMUN, V102, P100, DOI 10.1016/j.specom.2018.08.001
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INT CONF ACOUST SPEE, P4237, DOI 10.1109/ICASSP.2009.4960564
   Dufaux Alain, 2000, P 10 EUR SIGN PROC C, P1
   Giraldo JSP, 2018, PROC EUR SOLID-STATE, P166, DOI 10.1109/ESSCIRC.2018.8494342
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Harpe P, 2015, ISSCC DIG TECH PAP I, V58, P382, DOI 10.1109/ISSCC.2015.7063086
   Hubara I, 2018, J MACH LEARN RES, V18
   Kumari R. S. S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI DOI 10.17485/ijst/2016/v9i19/93870
   Lane ND, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P117, DOI 10.1145/2699343.2699349
   Nasrabadi N.M., 2007, PATTERN RECOGN, V16, DOI 10.1117/1.2819119
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Qiu HQ, 2018, INT CONF INFO SCI, P138, DOI 10.1109/ICIST.2018.8426169
   Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072
   Shahud M., 2018, 2018 IEEERSJ INT C I, P1, DOI DOI 10.1109/IROS.2018.8593841
   Su Y, 2007, IEEE I CONF COMP VIS, P1815
   Sun M, 2016, IEEE W SP LANG TECH, P474, DOI 10.1109/SLT.2016.7846306
   Wang JC, 2015, IEEE T VLSI SYST, V23, P1355, DOI 10.1109/TVLSI.2014.2335112
   Yuan M, 2006, MICROPROCESS MICROSY, V30, P155, DOI 10.1016/j.micpro.2005.10.001
NR 25
TC 44
Z9 44
U1 2
U2 7
PD APR
PY 2020
VL 55
IS 4
BP 868
EP 878
DI 10.1109/JSSC.2020.2968800
UT WOS:000522446300004
DA 2023-11-16
ER

PT J
AU Biswas, A
   Chandrakasan, AP
AF Biswas, Avishek
   Chandrakasan, Anantha P.
TI CONV-SRAM: An Energy-Efficient SRAM With In-Memory Dot-Product
   Computation for Low-Power Convolutional Neural Networks
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article; Proceedings Paper
CT 65th IEEE International Solid-State Circuits Conference (ISSCC)
CY FEB 11-15, 2018
CL San Francisco, CA
DE Analog computing; binary weights; convolutional neural networks (CNNs);
   dot-product; edge-computing; energy-efficient SRAM; in-memory
   computation; machine learning (ML)
ID ACCELERATOR; PROCESSOR
AB This paper presents an energy-efficient static random access memory (SRAM) with embedded dot-product computation capability, for binary-weight convolutional neural networks. A 10T bit-cell-based SRAM array is used to store the 1-b filter weights. The array implements dot-product as a weighted average of the bitline voltages, which are proportional to the digital input values. Local integrating analogto- digital converters compute the digital convolution outputs, corresponding to each filter. We have successfully demonstrated functionality (> 98% accuracy) with the 10 000 test images in the MNIST hand-written digit recognition data set, using 6-b inputs/outputs. Compared to conventional full-digital implementations using small bitwidths, we achieve similar or better energy efficiency, by reducing data transfer, due to the highly parallel in-memory analog computations.
C1 [Biswas, Avishek] Texas Instruments Inc, Kilby Labs, Dallas, TX 75243 USA.
   [Chandrakasan, Anantha P.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
RP Biswas, A (corresponding author), Texas Instruments Inc, Kilby Labs, Dallas, TX 75243 USA.
EM avishek.biswas@alum.mit.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Biswas A., 2018, THESIS
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Biswas A, 2016, PROC EUR SOLID-STATE, P433, DOI 10.1109/ESSCIRC.2016.7598334
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   Duan CH, 2017, IEEE J SOLID-ST CIRC, V52, P2703, DOI 10.1109/JSSC.2017.2731814
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Moons B, 2018, IEEE CUST INTEGR CIR
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 24
TC 180
Z9 184
U1 4
U2 32
PD JAN
PY 2019
VL 54
IS 1
SI SI
BP 217
EP 230
DI 10.1109/JSSC.2018.2880918
UT WOS:000457637300020
DA 2023-11-16
ER

PT J
AU Ang, JA
   Barker, KJ
   Vrabie, DL
   Kestor, G
AF Ang, James A.
   Barker, Kevin J.
   Vrabie, Draguna L.
   Kestor, Gokcen
TI Codesign for Extreme Heterogeneity: Integrating Custom Hardware With
   Commodity Computing Technology to Support Next-Generation HPC Converged
   Workloads
SO IEEE INTERNET COMPUTING
DT Article
DE Computational modeling; Data models; Biological system modeling;
   Computer architecture; Software engineering; Heterogeneous networks;
   Hardware
ID NETWORK
AB The future of high-performance computing (HPC) will be driven by the convergence of physical simulation, artificial intelligence, machine learning, and data science computing capabilities. While computational performance gains afforded by technology scaling, as predicted by Moore's Law, have enabled large-scale HPC system design and deployment using commodity CPU and GPU processing components, emerging technologies will be required to effectively support such converged workloads. These emerging technologies will integrate commodity computing components with custom processing and networking accelerators into ever-more heterogeneous architectures resulting in a diverse ecosystem of industry technology developers, university, and U.S. Government researchers. In this article, we describe efforts at the U.S. Department of Energy's Pacific Northwest National Laboratory to construct an end-to-end codesign framework that lays a groundwork for such an ecosystem, including notable outcomes, remaining challenges, and future opportunities.
C1 [Ang, James A.; Barker, Kevin J.; Vrabie, Draguna L.; Kestor, Gokcen] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
RP Ang, JA (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99354 USA.
EM ang@pnnl.gov; kevin.barker@pnnl.gov; draguna.vrabie@pnnl.gov;
   gokcen.kestor@pnnl.gov
CR Ang J. A., 2021, 1822199 OSTI US DOE, DOI [10.2172/1822199, DOI 10.2172/1822199]
   [Anonymous], 2020, US
   Ghosh Sreedip, 2021, 2021 6th International Conference for Convergence in Technology (I2CT), DOI 10.1109/I2CT51068.2021.9418065
   Gioiosa R, 2020, GPGPU'20: PROCEEDINGS OF THE 13TH ANNUAL WORKSHOP ON GENERAL PURPOSE PROCESSING USING GRAPHICS PROCESSING UNIT (GPU), P1, DOI 10.1145/3366428.3380770
   Guan S, 2021, PROC VLDB ENDOW, V14, P2875, DOI 10.14778/3476311.3476367
   King E, 2022, 2022 AMERICAN CONTROL CONFERENCE (ACC), P2194, DOI 10.23919/ACC53348.2022.9867379
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Lin HQ, 2018, IEEE ACCESS, V6, P18345, DOI 10.1109/ACCESS.2018.2817921
   Mutlu Erdal, 2020, INT WORKSH LANG COMP, P87
   Nandanoori SP, 2021, IEEE DECIS CONTR P, P5059, DOI 10.1109/CDC45484.2021.9682872
   Nandanoori SP, 2022, IEEE ACCESS, V10, P32337, DOI 10.1109/ACCESS.2022.3160710
   Pernot P, 2022, J CHEM PHYS, V156, DOI 10.1063/5.0084302
   Pidko EA, 2017, ACS CATAL, V7, P4230, DOI 10.1021/acscatal.7b00290
   Spurgeon SR, 2021, NAT MATER, V20, P274, DOI 10.1038/s41563-020-00833-z
   Stinis P., 2020, PROC AAAI SPRING S C
   Tallent Nathan R., 2016, 2016 IEEE International Conference on Networking, Architecture and Storage (NAS), P1, DOI 10.1109/NAS.2016.7549392
   Tan C, 2020, PR IEEE COMP DESIGN, P381, DOI 10.1109/ICCD50377.2020.00070
NR 18
TC 0
Z9 0
U1 1
U2 1
PD JAN 1
PY 2023
VL 27
IS 1
BP 7
EP 14
DI 10.1109/MIC.2022.3217423
UT WOS:000937154400002
DA 2023-11-16
ER

PT C
AU Shi, YB
   Wang, MQ
   Chen, SY
   Wei, JH
   Wang, ZF
AF Shi, Yubo
   Wang, Meiqi
   Chen, Siyi
   Wei, Jinghe
   Wang, Zhongfeng
GP IEEE
TI Transform-Based Feature Map Compression for CNN Inference
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 22-28, 2021
CL Daegu, SOUTH KOREA
DE CNN; Feature Map; Compression; Hardware Accelerator; Inference
AB To achieve higher accuracy in machine learning tasks, very deep convolutional neural networks (CNNs) are designed recently. However, the large memory access of deep CNNs will lead to high power consumption. A variety of hardware-friendly compression methods have been proposed to reduce the data transfer bandwidth by exploiting the sparsity of feature maps. Most of them focus on designing a specialized encoding format to increase the compression ratio. Differently, we observe and exploit the sparsity distinction between activations in earlier and later layers to improve the compression ratio. We propose a novel hardware-friendly transform-based method named 1D-Discrete Cosine Transform on Channel dimension with Masks (DCT-CM), which intelligently combines DCT, masks, and a coding format to compress activations. The proposed algorithm achieves an average compression ratio of 2.9x (53% higher than the state-of-the-art transform-based feature map compression works) during inference on ResNet-50 with an 8-bit quantization scheme.
C1 [Shi, Yubo; Wang, Meiqi; Chen, Siyi; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
   [Wei, Jinghe] China Key Syst & Integrated Circuit Co Ltd, Wuxi, Jiangsu, Peoples R China.
RP Shi, YB (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
EM mf1923134@smail.nju.edu.cn; mqwang@smail.nju.edu.cn;
   mg1923066@smail.nju.edu.cn; pume1975_cnjs@sina.co; zfwang@nju.edu.cn
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2014, 3 INT C LEARNING REP
   Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489
   Cavigelli L, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P279, DOI [10.1109/AICAS.2019.8771562, 10.1109/aicas.2019.8771562]
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   El-Banna H, 2003, INT C MICROELECTRON, P278
   Evans RD, 2020, ANN I S COM, P860, DOI 10.1109/ISCA45697.2020.00075
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gudovskiy Denis, 2018, ARXIV180805285
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hauck Edward L., 1986, DATA COMPRESSION USI
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596541
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   MOFFAT A, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P274
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rhu M., 2016, 2016 49 ANN IEEEACM, P1, DOI DOI 10.1109/MICRO.2016.7783721
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Saito, 2018, CHAINER CIFAR10 VARI
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tumeo A, 2007, IEEE COMP SOC ANN, P331, DOI 10.1109/ISVLSI.2007.13
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zeng X, 2020, IEEE T COMPUT, V69, P968, DOI 10.1109/TC.2020.2978475
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang Y, 2014, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2014.121
   Zoph B, 2016, ARXIV161101578
NR 34
TC 0
Z9 0
U1 2
U2 5
PY 2021
DI 10.1109/ISCAS51556.2021.9401133
UT WOS:000696765400079
DA 2023-11-16
ER

PT C
AU Gambardella, G
   Kappauf, J
   Blott, M
   Doehring, C
   Kumm, M
   Zip, P
   Vissers, K
AF Gambardella, Giulio
   Kappauf, Johannes
   Blott, Michaela
   Doehring, Christoph
   Kumm, Martin
   Zip, Peter
   Vissers, Kees
GP IEEE
TI Efficient Error-Tolerant Quantized Neural Network Accelerators
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON DEFECT AND FAULT TOLERANCE IN VLSI
   AND NANOTECHNOLOGY SYSTEMS (DFT)
SE IEEE International Symposium on Defect and Fault Tolerance in VLSI
   Systems
DT Proceedings Paper
CT IEEE International Symposium on Defect and Fault Tolerance in VLSI and
   Nanotechnology Systems (DFT)
CY OCT 02-04, 2019
CL European Space Res& Technol Ctr, Noordwijk, NETHERLANDS
HO European Space Res& Technol Ctr
DE neural networks; safety; automotive; FPGA; quantized neural networks
AB Neural Networks are currently one of the most widely deployed machine learning algorithms. In particular, Convolutional Neural Networks (CNNs), are gaining popularity and are evaluated for deployment in safety critical applications such as self driving vehicles. Modern CNNs feature enormous memory bandwidth and high computational needs, challenging existing hardware platforms to meet throughput, latency and power requirements. Functional safety and error tolerance need to be considered as additional requirement in safety critical systems. In general, fault tolerant operation can be achieved by adding redundancy to the system, which is further exacerbating the computational demands. Furthermore, the question arises whether pruning and quantization methods for performance scaling turn out to be counterproductive with regards to fail safety requirements. In this work we present a methodology to evaluate the impact of permanent faults affecting Quantized Neural Networks (QNNs) and how to effectively decrease their effects in hardware accelerators. We use FPGA-based hardware accelerated error injection, in order to enable the fast evaluation. A detailed analysis is presented showing that QNNs containing convolutional layers are by far not as robust to faults as commonly believed and can lead to accuracy drops of up to 10%. To circumvent that, we propose two different methods to increase their robustness: 1) selective channel replication which adds significantly less redundancy than used by the common triple modular redundancy and 2) a fault-aware scheduling of processing elements for folded implementations.
C1 [Gambardella, Giulio; Kappauf, Johannes; Blott, Michaela; Vissers, Kees] Xilinx Res Labs, Dublin, Ireland.
   [Doehring, Christoph] Coburg Univ, Coburg, Germany.
   [Kumm, Martin] Fulda Univ Appl Sci, Fulda, Germany.
   [Zip, Peter] Univ Kassel, Digital Technol Grp, Kassel, Germany.
RP Gambardella, G (corresponding author), Xilinx Res Labs, Dublin, Ireland.
EM giuliog@xilinx.com; ohannes@xilinx.com; mblott@xilinx.com;
   doch1501@stud.hs-coburg.de; martin.kumm@cs.hs-fulda.de;
   zipf@uni-kassel.de; kees.vissers@xilinx.com
CR Bengio, 2016, ABS160202830 CORR
   Blott M., 2018, FINN R END TO END DE
   Bosio A., 2018, ARC 18, P1
   dos Santos FF, 2017, I C DEPENDABLE SYST, P169, DOI 10.1109/DSN-W.2017.47
   Gehr T, 2018, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2018.00058
   Goble WM, 1999, RELIAB ENG SYST SAFE, V66, P145, DOI 10.1016/S0951-8320(99)00031-9
   Guo K., 2017, SURVEY FPGA BASED NE
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Jha S, 2018, ARC 18, P1, DOI [DOI 10.15398/JLM.V7I2.214, 10.15398/jlm.v7i2.214]
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Nunez-Yanez J, 2019, IEEE T COMPUT, V68, P676, DOI 10.1109/TC.2018.2879333
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Singh AP, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN SYSTEM TESTING AND VALIDATION LIFECYCLE, P7, DOI 10.1109/VALID.2009.32
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Wu B., 2017, CORR
NR 17
TC 11
Z9 12
U1 0
U2 0
PY 2019
DI 10.1109/dft.2019.8875314
UT WOS:000591800600007
DA 2023-11-16
ER

PT C
AU Leon, V
   Makris, G
   Xydis, S
   Pekmestzi, K
   Soudris, D
AF Leon, Vasileios
   Makris, Georgios
   Xydis, Sotirios
   Pekmestzi, Kiamal
   Soudris, Dimitrios
GP IEEE
TI MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN
   Hardware Accelerators
SO 2022 IEEE 13TH LATIN AMERICAN SYMPOSIUM ON CIRCUITS AND SYSTEMS (LASCAS)
DT Proceedings Paper
CT 13th Latin America Symposium on Circuits and System (LASCAS)
CY APR 01-04, 2022
CL Puerto Varas, CHILE
DE Approximate Computing; Inexact Multipliers; ASIC; Deep Neural Networks;
   ResNet; CIFAR-10; TensorFlow
ID DESIGN
AB Nowadays, the rapid growth of Deep Neural Network (DNN) architectures has established them as the defacto approach for providing advanced Machine Learning tasks with excellent accuracy. Targeting low-power DNN computing, this paper examines the interplay of fine-grained error resilience of DNN workloads in collaboration with hardware approximation techniques, to achieve higher levels of energy efficiency. Utilizing the state-of-the-art ROUP approximate multipliers, we systematically explore their fine-grained distribution across the network according to our layer-, filter-, and kernel-level approaches, and examine their impact on accuracy and energy. We use the ResNet-8 model on the CIFAR-10 dataset to evaluate our approximations. The proposed solution delivers up to 54% energy gains in exchange for up to 4% accuracy loss, compared to the baseline quantized model, while it provides 2x energy gains with better accuracy versus the state-of-the-art DNN approximations.
C1 [Leon, Vasileios; Makris, Georgios; Pekmestzi, Kiamal; Soudris, Dimitrios] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
   [Xydis, Sotirios] Harokopio Univ Athens, Dept Informat & Telemat, Athens 17778, Greece.
RP Leon, V (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
EM vleon@microlab.ntua.gr; gmakris@microlab.ntua.gr; sxydis@hua.gr;
   pekmes@microlab.ntua.gr; dsoudris@microlab.ntua.gr
CR Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Hernández-Araya D, 2020, IEEE LAT AMER SYMP
   Koster U., 2017, ADV NEURAL INFORM PR, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Lentaris G, 2020, IEEE I C ELECT CIRC, DOI 10.1109/icecs49266.2020.9294869
   Leon V., 2021, IEEE INT C ELECT CIR, P1, DOI DOI 10.1109/ICECS53924.2021.9665462
   Leon V, 2021, 2021 10TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST), DOI 10.1109/MOCAST52088.2021.9493421
   Leon V, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317793
   Leon V, 2018, IEEE T VLSI SYST, V26, P421, DOI 10.1109/TVLSI.2017.2767858
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Venkataramani S, 2020, P IEEE, V108, P2232, DOI 10.1109/JPROC.2020.3029453
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 61
EP 64
DI 10.1109/LASCAS53948.2022.9789055
UT WOS:000948189700012
DA 2023-11-16
ER

PT C
AU Tine, BP
   Yalamanchili, S
   Kim, H
AF Tine, Blaise-Pascal
   Yalamanchili, Sudhakar
   Kim, Hyesoon
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI Tango: An Optimizing Compiler for Just-In-Time RTL Simulation
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB With Moore's law coming to an end, the advent of hardware specialization presents a unique challenge for a much tighter software and hardware co-design environment to exploit domain-specific optimizations and increase design efficiency. This trend is further accentuated by rapid-pace of innovations in Machine Learning and Graph Analytic, calling for a faster product development cycle for hardware accelerators and the importance of addressing the increasing cost of hardware verification. The productivity of software-hardware co-design relies upon better integration between the software and hardware design methodologies, but more importantly in the effectiveness of the design tools and hardware simulators at reducing the development time. In this work, we developed Tango, an Optimizing compiler for Just-in-Time RTL simulation. Tango implements unique hardware-centric compiler transformations to speed up runtime code generation in a software-hardware co-design environment where hardware simulation speed is critical. Tango achieves a 6x average speedup compared to the state-of-the-art simulators.
C1 [Tine, Blaise-Pascal; Yalamanchili, Sudhakar; Kim, Hyesoon] Georgia Tech, Atlanta, GA 30332 USA.
RP Tine, BP (corresponding author), Georgia Tech, Atlanta, GA 30332 USA.
EM blaise.tine@gatech.edu; sudah@gatech.edu; hyesoon@cc.gatech.edu
CR Bachrach J., DAC 12
   DARPA, 2017, INT DES EL ASS ID
   *IEEE, 2006, 13642005 IEEE
   Kim D., DATE 11
   Korobeynikov A., 2007, IMPROVING SWITCH LOW
   Kupriyanov A., SCOPES 07
   Kupriyanov F. H. Alexey, 2004, AUTOMATIC OPTIMIZED
   Kupriyanov F. H. Alexey, 2004, HIGH SPEED EVENT DRI
   Li L., PADS 07
   Lockhart D, 2014, INT SYMP MICROARCH, P280, DOI 10.1109/MICRO.2014.50
   Panda PR, 2001, ISSS'01: 14TH INTERNATIONAL SYMPOSIUM ON SYSTEM SYNTHESIS, P75, DOI 10.1109/ISSS.2001.957916
   Qian H., ICCAD 11
   Snyder W., VERILATOR
   Synopsys, VCS IND HIGH PERF SI
   Williams Stephen, ICARUS VERILOG
NR 15
TC 0
Z9 0
U1 0
U2 0
PY 2020
BP 157
EP 162
UT WOS:000610549200028
DA 2023-11-16
ER

PT J
AU Song, J
   Jeong, H
   Jeong, J
AF Song, Jaehyun
   Jeong, Hwanjin
   Jeong, Jinkyu
TI Performance Optimization of Object Tracking Algorithms in OpenCV on GPUs
SO APPLIED SCIENCES-BASEL
DT Article
DE GPU; OpenCL; OpenCV; optimization; kernel occupancy
AB Machine-learning-based computer vision is increasingly versatile and being leveraged by a wide range of smart devices. Due to the limited performance/energy budget of computing units in smart devices, the careful implementation of computer vision algorithms is critical. In this paper, we analyze the performance bottleneck of two well-known computer vision algorithms for object tracking: object detection and optical flow in the Open-source Computer Vision library (OpenCV). Based on our in-depth analysis of their implementation, we found the current implementation fails to utilize Open Computing Language (OpenCL) accelerators (e.g., GPUs). Based on the analysis, we propose several optimization strategies and apply them to the OpenCL implementation of object tracking algorithms. Our evaluation results demonstrate the performance of the object detection is improved by up to 86% and the performance of the optical flow by up to 10%. We believe our optimization strategies can be applied to other computer vision algorithms implemented in OpenCL.
C1 [Song, Jaehyun; Jeong, Hwanjin; Jeong, Jinkyu] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 16419, South Korea.
   [Jeong, Hwanjin] Woowabros, Seoul 05544, South Korea.
RP Jeong, J (corresponding author), Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 16419, South Korea.
EM jaehyun.song@csi.skku.edu; hwanjinjeong@woowahan.com; jinkyu@skku.edu
CR Aby P. K., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P250, DOI 10.1109/ICSCCN.2011.6024553
   [Anonymous], AMD GPU PROFILER
   [Anonymous], 2015, OPEN SOURCE COMPUTER
   [Anonymous], 2013, KHRONOS OPENCL REFER
   [Anonymous], OPENGPU CODEXL
   [Anonymous], AMD ACCELERATED PARA
   [Anonymous], OPENCV 3 0
   [Anonymous], 2016, NVIDIA CUDA PROGR GU
   [Anonymous], CISC VIS NETW IND GL
   [Anonymous], NVIDIA GPU PROFILER
   Arya Z., 2020, INT J ENG RES APPL, V10, P13
   Bastani F, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1907, DOI 10.1145/3318464.3389692
   Battaglia F, 2009, IEEE T CONSUM ELECTR, V55, P2436, DOI 10.1109/TCE.2009.5373821
   Chai Y, 2010, IEEE T CONSUM ELECTR, V56, P510, DOI 10.1109/TCE.2010.5505963
   Cho J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143217
   Chun JB, 2008, IEEE T CONSUM ELECTR, V54, P1479, DOI 10.1109/TCE.2008.4711190
   Coelho F, 1997, ACM SIGPLAN NOTICES, V32, P168, DOI 10.1145/263767.263786
   de Melo A. C., 2010, LINUX K
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gaster B., 2012, HETEROGENEOUS COMPUT
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   Itseez, 2016, OP SOURC COMP VIS LI
   Kadir K, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P335, DOI 10.1109/ICE2T.2014.7006273
   Karimi-Mansoub S., 2019, P 4 INT C ADV SIGNAL, P23
   Li N, 2016, OPEN SOURCE COMPUTER
   Li SS, 2021, IEEE T CONSUM ELECTR, V67, P129, DOI 10.1109/TCE.2021.3077241
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mistry P., 2019, P INT WORKSH OPENCL
   Munshi A, 2011, OPENCL PROGRAMMING G
   NVIDIA, 2021, NVIDIA CUDA C PROGR
   Ping Gao, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P620, DOI 10.1109/IASP.2010.5476045
   Poudel Pramod, 2010, 2010 42nd Southeastern Symposium on System Theory (SSST 2010), P51, DOI 10.1109/SSST.2010.5442803
   Rabbah R.M., 2003, ACM T EMBED COMPUT S, V2, P186, DOI [10.1145/643470.643474, DOI 10.1145/643470.643474]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Saez-Mingorance B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175923
   Singhal N, 2010, IEEE IMAGE PROC, P4481, DOI 10.1109/ICIP.2010.5651740
   Soo S., 2014, OBJECT DETECTION USI, V2, P1
   Sung HW, 2016, INT CONF PARA PROC, P59, DOI 10.1109/ICPPW.2016.24
   Ullah MB, 2020, IEEE REGION 10 SYMP, P552
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WANG L, 1990, PATTERN RECOGN, V23, P905, DOI 10.1016/0031-3203(90)90135-8
NR 43
TC 1
Z9 1
U1 4
U2 14
PD AUG
PY 2022
VL 12
IS 15
AR 7801
DI 10.3390/app12157801
UT WOS:000838863200001
DA 2023-11-16
ER

PT J
AU Cisbani, E
   Del Dotto, A
   Fanelli, C
   Williams, M
   Alfred, M
   Barbosa, F
   Barion, L
   Berdnikov, V
   Brooks, W
   Cao, T
   Contalbrigo, M
   Danagoulian, S
   Datta, A
   Demarteau, M
   Denisov, A
   Diefenthaler, M
   Durum, A
   Fields, D
   Furletova, Y
   Gleason, C
   Grosse-Perdekamp, M
   Hattawy, M
   He, X
   van Hecke, H
   Higinbotham, D
   Horn, T
   Hyde, C
   Ilieva, Y
   Kalicy, G
   Kebede, A
   Kim, B
   Liu, M
   McKisson, J
   Mendez, R
   Nadel-Turonski, P
   Pegg, I
   Romanov, D
   Sarsour, M
   da Silva, CL
   Stevens, J
   Sun, X
   Syed, S
   Towell, R
   Xie, J
   Zhao, ZW
   Zihlmann, B
   Zorn, C
AF Cisbani, E.
   Del Dotto, A.
   Fanelli, C.
   Williams, M.
   Alfred, M.
   Barbosa, F.
   Barion, L.
   Berdnikov, V
   Brooks, W.
   Cao, T.
   Contalbrigo, M.
   Danagoulian, S.
   Datta, A.
   Demarteau, M.
   Denisov, A.
   Diefenthaler, M.
   Durum, A.
   Fields, D.
   Furletova, Y.
   Gleason, C.
   Grosse-Perdekamp, M.
   Hattawy, M.
   He, X.
   van Hecke, H.
   Higinbotham, D.
   Horn, T.
   Hyde, C.
   Ilieva, Y.
   Kalicy, G.
   Kebede, A.
   Kim, B.
   Liu, M.
   McKisson, J.
   Mendez, R.
   Nadel-Turonski, P.
   Pegg, I
   Romanov, D.
   Sarsour, M.
   da Silva, C. L.
   Stevens, J.
   Sun, X.
   Syed, S.
   Towell, R.
   Xie, J.
   Zhao, Z. W.
   Zihlmann, B.
   Zorn, C.
TI AI-optimized detector design for the future Electron-Ion Collider: the
   dual-radiator RICH case
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Detector design and construction technologies and materials; Cherenkov
   detectors
AB Advanced detector R&D requires performing computationally intensive and detailed simulations as part of the detector-design optimization process. We propose a general approach to this process based on Bayesian optimization and machine learning that encodes detector requirements. As a case study, we focus on the design of the dual-radiator Ring Imaging Cherenkov (dRICH) detector under development as a potential component of the particle-identification system at the future Electron-Ion Collider (EIC). The EIC is a US-led frontier accelerator project for nuclear physics, which has been proposed to further explore the structure and interactions of nuclear matter at the scale of sea quarks and gluons. We show that the detector design obtained with our automated and highly parallelized framework outperforms the baseline dRICH design within the assumptions of the current model. Our approach can be applied to any detector R&D, provided that realistic simulations are available.
C1 [Cisbani, E.] INFN, Sez Roma, I-00185 Rome, Italy.
   [Cisbani, E.] Ist Super Sanita, I-00161 Rome, Italy.
   [Del Dotto, A.] Lab Nazl Frascati, Via Enrico Fermi 40, I-00044 Frascati, Italy.
   [Fanelli, C.; Barbosa, F.; Diefenthaler, M.; Furletova, Y.; Higinbotham, D.; McKisson, J.; Romanov, D.; Zihlmann, B.; Zorn, C.] Jefferson Lab, Newport News, VA 23606 USA.
   [Fanelli, C.; Williams, M.] MIT, Lab Nucl Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Alfred, M.] Howard Univ, Washington, DC 20059 USA.
   [Barion, L.; Contalbrigo, M.] INFN, Sez Ferrara, I-44100 Ferrara, Italy.
   [Berdnikov, V; Horn, T.; Kalicy, G.; Pegg, I] Catholic Univ Amer, Washington, DC 20064 USA.
   [Brooks, W.; Mendez, R.] Univ Tecn Federico Santa Maria, Valparaiso, Chile.
   [Cao, T.] Univ New Hampshire, Durham, NH 03824 USA.
   [Danagoulian, S.; Kebede, A.] North Carolina A&T State Univ, Greensboro, NC 27411 USA.
   [Datta, A.; Fields, D.] Univ New Mexico, Albuquerque, NM 87131 USA.
   [Demarteau, M.] Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
   [Denisov, A.; Durum, A.] Inst High Energy Phys, Protvino, Russia.
   [Gleason, C.; Ilieva, Y.] Univ South Carolina, Columbia, SC 29208 USA.
   [Grosse-Perdekamp, M.] Univ Illinois, Urbana, IL 61801 USA.
   [Hattawy, M.; Hyde, C.] Old Dominion Univ, Norfolk, VA 23529 USA.
   [He, X.; Sarsour, M.; Sun, X.; Syed, S.] Georgia State Univ, Atlanta, GA 30303 USA.
   [van Hecke, H.; Liu, M.; da Silva, C. L.] Los Alamos Natl Lab, Los Alamos, NM 87545 USA.
   [Kim, B.] CUNY City Coll, New York, NY 10031 USA.
   [Nadel-Turonski, P.] SUNY Stony Brook, Stony Brook, NY 11794 USA.
   [Stevens, J.] Coll William & Mary, Williamsburg, VA USA.
   [Towell, R.] Abilene Christian Univ, Abilene, TX 79601 USA.
   [Xie, J.] Argonne Natl Lab, Argonne, IL 60439 USA.
   [Zhao, Z. W.] Duke Univ, Durham, NC 27708 USA.
RP Fanelli, C (corresponding author), Jefferson Lab, Newport News, VA 23606 USA.; Fanelli, C (corresponding author), MIT, Lab Nucl Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM cfanelli@mit.edu
CR Abadi M., 2016, PROC 12 USENIX C OPE
   ABJEAN R, 1995, NUCL INSTRUM METH A, V354, P417, DOI 10.1016/0168-9002(94)01006-4
   Accardi A, 2016, EUR PHYS J A, V52, DOI 10.1140/epja/i2016-16268-9
   Adinolfi M, 2013, EUR PHYS J C, V73, DOI 10.1140/epjc/s10052-013-2431-9
   Akopov N, 2002, NUCL INSTRUM METH A, V479, P511, DOI 10.1016/S0168-9002(01)00932-9
   [Anonymous], 2013, P 12 PYTH SCI C
   [Anonymous], JINST
   Aschenauer E., 2019, ELECT ION COLLIDER D
   BELLMAN R, 1952, P NATL ACAD SCI USA, V38, P716, DOI 10.1073/pnas.38.8.716
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Brochu E., 2010, COMPUT SCI
   Brochu Eric, 2010, P 2010 ACM SIGGRAPH, P103, DOI DOI 10.2312/SCA/SCA10/103-112
   Contalbrigo M, 2017, NUCL INSTRUM METH A, V876, P168, DOI 10.1016/j.nima.2017.02.068
   Del Dotto A, 2017, NUCL INSTRUM METH A, V876, P237, DOI 10.1016/j.nima.2017.03.032
   Eric Brochu, 2008, ADV NEURAL INFORM PR, V20, P409
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Hutter Frank, 2011, Learning and Intelligent Optimization. 5th International Conference, LION 5. Selected Papers, P507, DOI 10.1007/978-3-642-25566-3_40
   Ilten P, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/04/P04028
   Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147
   Kalicy G, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/04/C04018
   Knudde N., 2017, ARXIV PREPRINT ARXIV
   LHCb collaboration, 2003, CERNLHCC2003030 LHCB
   Lizotte D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P944
   Nappi E, 2005, RIV NUOVO CIMENTO, V28, P1, DOI 10.1393/ncr/i2006-10004-6
   National Academies of Sciences, ASS US BAS EL COLL S, DOI DOI 10.17226/25171
   Ngatchou P, 2005, P 13 INT C INT SYST, p84 , DOI DOI 10.1109/ISAP.2005.1599245
   Pereira SA, 2016, EUR PHYS J A, V52, DOI 10.1140/epja/i2016-16023-4
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Romanov D., 2019, JLEIC DETECTOR SIMUL
   Snoek J., 2012, ADV NEURAL INF PROCE, V25, P2951, DOI DOI 10.5555/2999325.2999464
   Snoek J, 2015, PR MACH LEARN RES, V37, P2171
   Srinivas N, 2012, IEEE T INFORM THEORY, V58, P3250, DOI 10.1109/TIT.2011.2182033
   Ungaro M., GEANT4 M CARLO GEMC
   Wong CP, 2017, NUCL INSTRUM METH A, V871, P13, DOI 10.1016/j.nima.2017.07.001
   YPSILANTIS T, 1994, NUCL INSTRUM METH A, V343, P30, DOI 10.1016/0168-9002(94)90532-0
NR 35
TC 11
Z9 11
U1 2
U2 7
PD MAY
PY 2020
VL 15
IS 5
AR P05009
DI 10.1088/1748-0221/15/05/P05009
UT WOS:000534740900009
DA 2023-11-16
ER

PT J
AU Weidner, J
   Horn, J
   Kabat, CN
   Stathakis, S
   Geissler, P
   Wolf, U
   Poppinga, D
AF Weidner, Jan
   Horn, Julian
   Kabat, Christopher Nickolas
   Stathakis, Sotirios
   Geissler, Philipp
   Wolf, Ulrich
   Poppinga, Daniela
TI Artificial intelligence based deconvolving on megavoltage photon beam
   profiles for radiotherapy applications
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE artificial intelligence; profile measurement; dosimetry; deconvolution
ID RESPONSE FUNCTIONS; DECONVOLUTION; CONVOLUTION; DOSIMETRY; SIZE
AB Objective. The aim of this work is an AI based approach to reduce the volume effect of ionization chambers used to measure high energy photon beams in radiotherapy. In particular for profile measurements, the air-filled volume leads to an inaccurate measurement of the penumbra. Approach. The AI-based approach presented in this study was trained with synthetic data intended to cover a wide range of realistic linear accelerator data. The synthetic data was created by randomly generating profiles and convolving them with the lateral response function of a Semiflex 3D ionization chamber. The neuronal network was implemented using the open source tensorflow.keras machine learning framework and a U-Net architecture. The approach was validated on three accelerator types (Varian TrueBeam, Elekta VersaHD, Siemens Artiste) at FF and FFF energies between 6 MV and 18 MV at three measurement depths. For each validation, a Semiflex 3D measurement was compared against a microDiamond measurement, and the AI processed Semiflex 3D measurement was compared against the microDiamond measurement. Main results. The AI approach was validated with dataset containing 306 profiles measured with Semiflex 3D ionization chamber and microDiamond. In 90% of the cases, the AI processed Semiflex 3D dataset agrees with the microDiamond dataset within 0.5 mm/2% gamma criterion. 77% of the AI processed Semiflex 3D measurements show a penumbra difference to the microDiamond of less than 0.5 mm, 99% of less than 1 mm. Significance. This AI approach is the first in the field of dosimetry which uses synthetic training data. Thus, the approach is able to cover a wide range of accelerators and the whole specified field size range of the ionization chamber. The application of the AI approach offers an quality improvement and time saving for measurements in the water phantom, in particular for large field sizes.
C1 [Weidner, Jan; Horn, Julian; Poppinga, Daniela] PTW Freiburg GmbH, Freiburg, Germany.
   [Kabat, Christopher Nickolas; Stathakis, Sotirios] Univ Texas Hlth San Antonio, Dept Radiat Oncol, Div Med Phys, San Antonio, TX USA.
   [Geissler, Philipp; Wolf, Ulrich] Univ Hosp Leipzig, Dept Radiotherapy, Div Med Phys, Leipzig, Germany.
RP Weidner, J; Poppinga, D (corresponding author), PTW Freiburg GmbH, Freiburg, Germany.
EM jan.weidner@ptwdosimetry.com; daniela.poppinga@ptwdosimetry.com
CR [Anonymous], Z MED PHYS
   Bednarz G, 2002, PHYS MED BIOL, V47, P3643, DOI 10.1088/0031-9155/47/20/306
   Delfs B, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aadd3d
   Fox C, 2010, MED PHYS, V37, P477, DOI 10.1118/1.3284529
   Garcia-Vicente F, 1998, MED PHYS, V25, P202, DOI 10.1118/1.598182
   Herrup D, 2005, MED PHYS, V32, P3636, DOI 10.1118/1.2128086
   King DB, 2015, ACS SYM SER, V1214, P1
   Laub WU, 2003, MED PHYS, V30, P341, DOI 10.1118/1.1544678
   Liu H, 2018, MED PHYS, V45, P5586, DOI 10.1002/mp.13230
   Looe HK, 2010, PHYS MED BIOL, V55, P3981, DOI 10.1088/0031-9155/55/14/003
   Looe HK, 2013, Z MED PHYS, V23, P129, DOI 10.1016/j.zemedi.2012.12.010
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Mund K, 2021, J APPL CLIN MED PHYS, V22, P161, DOI 10.1002/acm2.13411
   Mund K, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12865
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönfeld AB, 2021, J APPL CLIN MED PHYS, V22, P64, DOI 10.1002/acm2.13447
   Ulmer W, 2003, PHYS MED BIOL, V48, P707, DOI 10.1088/0031-9155/48/6/302
NR 17
TC 0
Z9 0
U1 1
U2 3
PD MAR 21
PY 2022
VL 67
IS 6
AR 06NT01
DI 10.1088/1361-6560/ac594d
UT WOS:000769724800001
DA 2023-11-16
ER

PT C
AU Zeng, SL
   Guo, KY
   Fang, SX
   Kang, JL
   Xie, DL
   Shan, Y
   Wang, Y
   Yang, HZ
AF Zeng, Shulin
   Guo, Kaiyuan
   Fang, Shaoxia
   Kang, Junlong
   Xie, Dongliang
   Shan, Yi
   Wang, Yu
   Yang, Huazhong
GP IEEE
TI An Efficient Reconfigurable Framework for General Purpose CNN-RNN Models
   on FPGAs
SO 2018 IEEE 23RD INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING
   (DSP)
SE International Conference on Digital Signal Processing
DT Proceedings Paper
CT 23rd IEEE International Conference on Digital Signal Processing (DSP)
CY NOV 19-21, 2018
CL Shanghai, PEOPLES R CHINA
DE framework; FPGA; CNN; RNN; optimization
AB Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) have made great progress in machine learning community. Combining CNN and RNN can accomplish more general and complex tasks. Many specially designed hardware accelerators on FPGA or ASIC have been proposed for CNN or RNN, yet few of them focus on CNN-RNN-based models for general purpose applications. In this paper, we propose a complete design framework for deploying general-purpose CNN-RNN-based models on FPGAs. We use Deephi Aristotle and Descartes IPs to build an efficient and reconfigurable hardware system with the support of Deephi's toolchains and Xilinx SDSoC environment. We also design a CNN-RNN-based co-optimization method which can find the IP configuration to achieve the maximum throughput under the given FPGA resources and neural network models. Our implementation on the Xilinx MEG FPGA achieves the throughput of 690.76GOPS and the energy efficiency of 86.34GOPS/W on LRCN network.
C1 [Zeng, Shulin; Guo, Kaiyuan; Wang, Yu; Yang, Huazhong] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
   [Zeng, Shulin; Guo, Kaiyuan; Wang, Yu; Yang, Huazhong] Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.
   [Zeng, Shulin; Fang, Shaoxia; Kang, Junlong; Xie, Dongliang; Shan, Yi; Wang, Yu] Deephi Technol Co Ltd, Beijing, Peoples R China.
RP Zeng, SL (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.; Zeng, SL (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.; Zeng, SL (corresponding author), Deephi Technol Co Ltd, Beijing, Peoples R China.
EM cengsl14@mails.tsinghua.edu.cn; yu-wang@tsinghua.edu.cn
CR [Anonymous], 2016, ICLR
   Chen LC., 2014, COMPLEX VARIABLES TH, V7, P357, DOI 10.1080/17476938708814211
   Donahue B, 2015, 2015 IEEE AEROSPACE CONFERENCE
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo Kaiwen, 2017, IEEE T VISUALIZATION, V99, P1
   Han S., 2017, ESE EFFICIENT SPEECH
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kathail V, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P4, DOI 10.1145/2847263.2847284
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Yin SY, 2017, SYMP VLSI CIRCUITS, pC26, DOI 10.23919/VLSIC.2017.8008534
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang X., 2017, FLUORESCENCE SPECTRO, P1, DOI DOI 10.3390/S17122719
NR 16
TC 4
Z9 4
U1 1
U2 6
PY 2018
UT WOS:000458909600261
DA 2023-11-16
ER

PT J
AU Kang, MG
   Lim, S
   Gonugondla, S
   Shanbhag, NR
AF Kang, Mingu
   Lim, Sungmin
   Gonugondla, Sujan
   Shanbhag, Naresh R.
TI An In-Memory VLSI Architecture for Convolutional Neural Networks
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Convolutional neural networks (CNN); in-memory computing; machine
   learning; analog processing; accelerator
ID ENERGY-EFFICIENT; PROCESSOR; MODE
AB This paper presents an energy-efficient and high throughput architecture for convolutional neural networks (CNN). Architectural and circuit techniques are proposed to address the dominant energy and delay costs associated with data movement in CNNs. The proposed architecture employs a deep in-memory architecture, to embed energy-efficient low swing mixed-signal computations in the periphery of the SRAM bitcell array. An efficient data access pattern and a mixed-signal multiplier are proposed to exploit data reuse opportunities in convolution. Silicon-validated energy, delay, and behavioral models of the proposed architecture are developed and employed to perform large-scale system simulations. System-level simulations using these models show >97% detection accuracy on the MNIST data set, along with 4.9x and 2.4x improvements in energy efficiency and throughput, respectively, leading to 11.9x reduction in energy-delay product as compared with a conventional (SRAM + digital processor) architecture.
C1 [Kang, Mingu] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Lim, Sungmin; Gonugondla, Sujan; Shanbhag, Naresh R.] Univ Illinois, Coordinated Sci Lab, Champaign, IL 61801 USA.
RP Kang, MG (corresponding author), IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM supermingu@gmail.com; sungmin3@illinois.edu; gonugon2@illinois.edu;
   shanbhag@illinois.edu
CR Bong K, 2017, ISSCC DIG TECH PAP I, P248, DOI 10.1109/ISSCC.2017.7870354
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Jung Kuk Kim, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC50, DOI 10.1109/VLSIC.2015.7231323
   Kang M., 2016, 481 PJ DECISION 3 4
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kang MG, 2016, IEEE T BIOMED CIRC S, V10, P855, DOI 10.1109/TBCAS.2016.2545402
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kang MG, 2015, IEEE INT SYMP CIRC S, P2505, DOI 10.1109/ISCAS.2015.7169194
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Kim K, 2009, IEEE J SOLID-ST CIRC, V44, P136, DOI 10.1109/JSSC.2008.2007157
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1998, MNIST DATABASE HANDW
   LeCun Y, 1995, INT C ARTIFICIAL NEU
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Murmann B, 2015, 2015 49TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, P1341, DOI 10.1109/ACSSC.2015.7421361
   Oh J, 2013, IEEE J SOLID-ST CIRC, V48, P2894, DOI 10.1109/JSSC.2013.2280238
   Park S, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P81, DOI 10.1109/GCCE.2015.7398741
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Rieutort-Louis W, 2016, IEEE J SOLID-ST CIRC, V51, P281, DOI 10.1109/JSSC.2015.2489842
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Yamaoka M, 2005, IEEE J SOLID-ST CIRC, V40, P186, DOI 10.1109/JSSC.2004.838014
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 34
TC 39
Z9 42
U1 0
U2 10
PD SEP
PY 2018
VL 8
IS 3
SI SI
BP 494
EP 505
DI 10.1109/JETCAS.2018.2829522
UT WOS:000444565900012
DA 2023-11-16
ER

PT C
AU Huang, XM
   Zhou, YT
AF Huang, Xinming
   Zhou, Yuteng
GP IEEE
TI A 20 TOp/s/W Binary Neural Network Accelerator
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
AB This paper presents the hardware architecture and VLSI implementation of a binarized neural network (BNN). As a modification of convolutional neural network (CNN), BNN constrains all activations and weights to be +1 or -1, making it very appealing to low-power ASIC design. In this paper, BNN is proven to be highly power efficient and accurate for computer vision tasks. We use pedestrian and car detections as examples to showcase the capability of the BNN chip design. The total memory use of all weights in the BNN is only 22K bytes, which is significantly less than a typical convolutional neural network. Evaluated using INRIA and CIFAR-10 datasets, our BNN chip can achieve an average accuracy of 96.5%, which is much higher than traditional computer vision approaches such as histogram of oriented gradients with support vector machine. Our design achieves a power efficiency of 20 TOp/s/w, far exceeding most of the mainstream CNN chips. Therefore, the proposed low power hardware architecture of BNN enables deep learning on mobile embedded platforms.
C1 [Huang, Xinming; Zhou, Yuteng] Worcester Polytech Inst, Dept Elect & Comp Engn, Worcester, MA 01609 USA.
   [Huang, Xinming] Nantong Univ, Sch Informat & Elect, Nantong, Peoples R China.
RP Huang, XM (corresponding author), Worcester Polytech Inst, Dept Elect & Comp Engn, Worcester, MA 01609 USA.; Huang, XM (corresponding author), Nantong Univ, Sch Informat & Elect, Nantong, Peoples R China.
EM xhuang@wpi.edu; ytchou@wpi.edu
CR B. - P. Network, 1989, HANDWR DIG REC
   Bengio, 2016, ABS160202830 CORR
   Cavigelli L., 2015, P 25 EDITION GREAT L, P199, DOI [10.1145/2742060.2743766, DOI 10.1145/2742060.2743766]
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hosang J., 2014, BMVC
   Iandola F.N., 2016, SQUEEZENET ALEXNET L
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kim L. W., 2017, IEEE T NEURAL NETWOR
   lotte S, 2015, ARXIV150203167
   Okuda N, 2014, SPRINGERBRIEF BIOL, P1, DOI 10.1007/978-4-431-54150-9
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Pham PH, 2012, MIDWEST SYMP CIRCUIT, P1044, DOI 10.1109/MWSCAS.2012.6292202
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI [DOI 10.1145/2485922.2485925, 10.1145/2485922.2485925]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STOICA G. V., 2015, HIGH PERFORMANCE CUD
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 23
TC 0
Z9 0
U1 0
U2 2
PY 2019
UT WOS:000483076402153
DA 2023-11-16
ER

PT J
AU Hsiao, PY
   Lin, SY
   Huang, SS
AF Hsiao, Pei-Yung
   Lin, Shih-Yu
   Huang, Shih-Shinh
TI An FPGA based human detection system with embedded platform
SO MICROELECTRONIC ENGINEERING
DT Article
DE FPGA circuit design; Real-time embedded system; Human detection; HOG;
   SVM; Adaboost
AB Focusing on the computing speed of the practical machine learning based human detection system at the testing (detecting) stage to reach the real-time requirement in an embedded platform, the idea of iterative computing HOG with FPGA circuit design is proposed. The completed HOG accelerator contains gradient calculation circuit module and histogram accumulation circuit module. The linear SVM classification algorithm producing a number of necessary weak classifiers is combined with Adaboost algorithm to establish a strong classifier. The human detection is successfully implemented on a portable embedded platform to reduce the system cost and size. Experimental result shows that the performance error of accuracy appears merely about 0.1-0.4% in comparison between the presented FPGA based HW/SW co-design and the PC based pure software. Meanwhile, the computing speed achieves the requirement of a real-time embedded system, 15 fps. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Hsiao, Pei-Yung; Lin, Shih-Yu] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
   Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung, Taiwan.
RP Hsiao, PY (corresponding author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
EM pyhsiao@nuk.edu.tw
CR Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2009, INTELLIGENT INFORM H, DOI [10.1109/IIH-MSP.2009.216, DOI 10.1109/IIH-MSP.2009.216]
   Bauer S., 2009, P MPC WORKSHOP, P49
   Chen PY, 2014, IEEE T INTELL TRANSP, V15, P656, DOI 10.1109/TITS.2013.2284666
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gokhan K.G., 2013, MICROPROCESS MICROSY, V37, P270
   Hsiao P.Y., 2006, IEE P-COMPUT DIG T, V153, P1871
   Zhu Q., 2006, CVPR, P1491, DOI 10.1109/CVPR.2006.119
NR 10
TC 17
Z9 18
U1 0
U2 6
PD APR 20
PY 2015
VL 138
BP 42
EP 46
DI 10.1016/j.mee.2015.01.018
UT WOS:000355035000010
DA 2023-11-16
ER

PT C
AU Nosova, S
   Norkina, A
   Medvedeva, O
   Abramov, A
   Makar, S
   Lozik, N
   Fadeicheva, G
AF Nosova, Svetlana
   Norkina, Anna
   Medvedeva, Olga
   Abramov, Andrey
   Makar, Svetlana
   Lozik, Nina
   Fadeicheva, Galina
BE Klimov, VV
   Kelley, DJ
TI Artificial Intelligence Technology as an Economic Accelerator of
   Business Process
SO BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES 2021
SE Studies in Computational Intelligence
DT Proceedings Paper
CT 12th Annual International Conference of the
   Biologically-Inspired-Cognitive-Architectures-Society (BICA) on
   Biologically Inspired Cognitive Architectures
CY SEP 12-19, 2021
CL ELECTR NETWORK
DE Artificial intelligence; Digital economy; Business processes; Strategy
AB The article covers a range of problems related to the need to use artificial intelligence (AI) technology, on the one hand, as an economic accelerator of business processes in conditions of high competition in the global market, and as conditions for the growth of the economy as a whole. The main purpose of the article is to prove the feasibility of developing a conceptual framework that reveals the value of AI technology in areas such as probabilistic thinking, machine learning and computer vision to help managers better understand how promising achievements can be achieved that can eliminate some limitations in business growth and create a new wave of opportunities in the socio-economic development of the country. The results of the study confirmed that AI technology: firstly, helps to create an innovative product, better serve customers, allocate employees to solve more creative tasks, reduce costs and get high results; secondly, it gives a clear incentive to its developers, companies, politicians and users to solve the socio-economic problems facing them; thirdly, removes restrictions in obtaining massive datasets based on global cooperation in the field of digital transformation. An assessment of the possibility of using the experience of AI technology development in advanced countries has been proposed and a number of measures have been developed to adapt the development of foreign AI technology to meet the requirements of the national program of the digital economy of Russia in response to the COVID-19 pandemic.
C1 [Nosova, Svetlana; Norkina, Anna] Natl Res Nucl Univ MEPHI, Kashirskoe Shossestr 31, Moscow 115409, Russia.
   [Medvedeva, Olga; Abramov, Andrey] State Univ Management, Ryazansky Prospektstr 99, Moscow 109542, Russia.
   [Makar, Svetlana; Lozik, Nina] Financial Univ Govt Russian Federat, Leningradsky Prospectstr 49, Moscow 125599, Russia.
   [Fadeicheva, Galina] Acad Lab & Social Relat, Lobachevskystr 90, Moscow 119454, Russia.
RP Nosova, S (corresponding author), Natl Res Nucl Univ MEPHI, Kashirskoe Shossestr 31, Moscow 115409, Russia.
EM SSNosova@mephi.ru
CR Abercrombie C., 2017, ACCELERATING ENTERPR
   Agrawal A, 2017, MIT SLOAN MANAGE REV, V58, P23
   AI HLEG,, 2019, ETH GUID TRUSTW AI
   [Anonymous], NATL STRATEGY DEV AR
   [Anonymous], 2017, CNBC
   [Anonymous], 2020, KEY INDICATORS THERU
   [Anonymous], 2021, RUSSIA GLOBAL POLITI, V2, DOI [10.31278/1810-6439-2021-19-2-106-119, DOI 10.31278/1810-6439-2021-19-2-106-119]
   Bataller C., 2016, TODAY
   Brock JKU, 2019, CALIF MANAGE REV, V61, P110, DOI 10.1177/1536504219865226
   Brynjolfsson E., 2017, HARVARD BUSINESS REV, P3
   Brynjolfsson E, 2017, SCIENCE, V358, P1530, DOI 10.1126/science.aap8062
   Chui M., 2018, MCKINSEY GLOBAL I
   Chui M., 2018, MCKIN Q
   Gillham J., 2018, MACROECONOMIC IMPACT
   Gouvernement Artificial intelligence, 2018, MAK FRANC LEAD
   Huang MH, 2019, CALIF MANAGE REV, V61, P43, DOI 10.1177/0008125619863436
   Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leitch J., 2016, LEADERSHIP-LONDON
   Nosova S., 2021, PROCEDIA COMPUT SCI, V190, P651, DOI [10.1016/j.procs.2021.06.076, DOI 10.1016/J.PROCS.2021.06.076]
   Nosova S.S., 2018, ESPACIOS, V39, P11
   Nosova S.S., 2021, FUNDAMENTALS DIGITAL, P378
   Nosova S.S., 2019, EC ENTREPRENEURSHIP, V13, P1204
   Nosova Svetlana, 2021, PROCEDIA COMPUT SCI, V190, P657, DOI [10.1016/j.procs.2021.06.077, DOI 10.1016/J.PROCS.2021.06.077]
   Russell S, 2010, ARTIF INTELL, V3rd
   Samsonovich A.V., 2016, SCI VERGE CREATING E
NR 27
TC 1
Z9 1
U1 5
U2 6
PY 2022
VL 1032
BP 355
EP 366
DI 10.1007/978-3-030-96993-6_39
UT WOS:000833484200039
DA 2023-11-16
ER

PT C
AU Das, IJ
   Morales, J
   Francescon, P
AF Das, Indra J.
   Morales, Johnny
   Francescon, Paolo
BE MassillonJL, G
   Fossion, R
   RosadoMendez, IM
   AvilaRodriguez, MA
   LopezPerez, DA
TI Small Field Dosimetry: What Have We Learnt?
SO MEDICAL PHYSICS: FOURTEENTH MEXICAN SYMPOSIUM ON MEDICAL PHYSICS
SE AIP Conference Proceedings
DT Proceedings Paper
CT 14th Mexican Symposium on Medical Physics
CY MAR 18-21, 2016
CL Mexico City, MEXICO
ID SIMULATED CORRECTION FACTORS; OUTPUT FACTOR MEASUREMENT; DETECTOR
   DOSE-RESPONSE; TOTAL SCATTER FACTORS; FOCAL SPOT SIZE; MONTE-CARLO;
   PHOTON FIELDS; RELATIVE DOSIMETRY; RADIOSURGERY SYSTEM;
   LINEAR-ACCELERATOR
AB Small field x-ray beam dosimetry is difficult due to a number of challenges that include a lack of lateral electronic equilibrium, source occlusion, high dose gradients, and detector volume averaging. This has become more apparent with a rapid increase in the number of treatment machines that deliver small x-ray fields which are used for precision radiotherapy techniques such as stereotactic radiosurgery (SRS) and SBRT. A large body of literature is now in small fields, but with a lot of contradiction. There is also a large collection of micro-detectors that are being advocated for dosimetry. This review provides an update on small field dosimetry, recommendations for measurements and updates on recent commercial detectors on the market. It is recommended that detectors that are small volume and tissue equivalent are best suited for small field dosimetry which are plastic scintillators, synthetic diamond detectors and possibly Gafchromic films.
C1 [Das, Indra J.] NYU, Langone Med Ctr, Dept Radiat Oncol, 160 East,34th St, New York, NY 10016 USA.
   [Morales, Johnny] Chris OBrien Lifehouse, Dept Radiat Oncol, Missenden Rd, Camperdown, NSW 2050, Australia.
   [Francescon, Paolo] Osped Vicenza, Dept Radiat Oncol, Viale Rodolfi, I-36100 Vicenza, Italy.
RP Das, IJ (corresponding author), NYU, Langone Med Ctr, Dept Radiat Oncol, 160 East,34th St, New York, NY 10016 USA.
EM indra.das@nyumc.org; johnny.morales@lh.org.au;
   paolo.francescon@ulssvicenza.it
CR Alfonso R, 2008, MED PHYS, V35, P5179, DOI 10.1118/1.3005481
   Almond PR, 1999, MED PHYS, V26, P1847, DOI 10.1118/1.598691
   [Anonymous], 2013, MED PHYS, DOI DOI 10.1118/1.4814982
   Araki F, 2006, MED PHYS, V33, P2955, DOI 10.1118/1.2219774
   Azangwe G, 2014, MED PHYS, V41, DOI 10.1118/1.4883795
   Bassinet C, 2013, MED PHYS, V40, DOI 10.1118/1.4811139
   Beddar A.S., 2009, CLIN DOSIMETRY MEASU, P891
   Benmakhlouf H, 2015, PHYS MED BIOL, V60, P3959, DOI 10.1088/0031-9155/60/10/3959
   Benmakhlouf H, 2014, MED PHYS, V41, DOI 10.1118/1.4868695
   Bogdanich W, 2010, NY TIMES
   Bouchard H, 2004, MED PHYS, V31, P2454, DOI 10.1118/1.1781333
   Bouchard H, 2015, MED PHYS, V42, P6048, DOI 10.1118/1.4930798
   Bouchard H, 2015, MED PHYS, V42, P6033, DOI 10.1118/1.4930053
   Bouchard H, 2012, PHYS MED BIOL, V57, P3333, DOI 10.1088/0031-9155/57/11/3333
   Bouchard H, 2012, MED PHYS, V39, P1473, DOI 10.1118/1.3684952
   Bouchard H, 2011, PHYS MED BIOL, V56, P2617, DOI 10.1088/0031-9155/56/8/018
   Bouchard H, 2009, MED PHYS, V36, P4654, DOI 10.1118/1.3213518
   Chalkley A, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20130768
   Cranmer-Sargison G, 2013, PHYS MED BIOL, V58, P7343, DOI 10.1088/0031-9155/58/20/7343
   Cranmer-Sargison G, 2011, MED PHYS, V38, P6592, DOI 10.1118/1.3658572
   Cranmer-Sargison G, 2011, RADIOTHER ONCOL, V100, P429, DOI 10.1016/j.radonc.2011.09.002
   Czarnecki D, 2012, METROLOGIA, V49, pS215, DOI 10.1088/0026-1394/49/5/S215
   Das I.J., MED PHYS IN PRESS
   Das I J, 2000, J RADIOSURG, V3, P177, DOI DOI 10.1023/A:1009594509115
   Das IJ, 1996, RADIOTHER ONCOL, V38, P61, DOI 10.1016/0167-8140(95)01674-0
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Das IJ, 2008, MED PHYS, V35, P206, DOI 10.1118/1.2815356
   Dieterich S, 2011, MED PHYS, V38, P4166, DOI 10.1118/1.3592647
   Fenwick JD, 2013, PHYS MED BIOL, V58, P2901, DOI 10.1088/0031-9155/58/9/2901
   Francescon P, 2014, PHYS MED BIOL, V59, pN11, DOI 10.1088/0031-9155/59/6/N11
   Francescon P, 2012, PHYS MED BIOL, V57, P3741, DOI 10.1088/0031-9155/57/12/3741
   Francescon P, 2011, MED PHYS, V38, P6513, DOI 10.1118/1.3660770
   Francescon P, 2008, MED PHYS, V35, P504, DOI 10.1118/1.2828195
   Francescon P, 2014, MED PHYS, V41, DOI 10.1118/1.4895978
   Francescon P, 2009, J APPL CLIN MED PHYS, V10, P147, DOI 10.1120/jacmp.v10i1.2939
   Gago-Arias A, 2013, MED PHYS, V40, DOI 10.1118/1.4773047
   Gambaccini M, 2011, NUCL INSTRUM METH B, V269, P1157, DOI 10.1016/j.nimb.2011.02.089
   García-Garduño OA, 2014, MED PHYS, V41, DOI 10.1118/1.4892176
   IAEA, 2000, TECHN REP SER IAEA
   Kamio Y, 2014, PHYS MED BIOL, V59, P4973, DOI 10.1088/0031-9155/59/17/4973
   Kumar S, 2015, PHYS MED BIOL, V60, P8187, DOI 10.1088/0031-9155/60/20/8187
   Lárraga-Gutiérrez JM, 2012, MED PHYS, V39, P6111, DOI 10.1118/1.4752211
   Liu PZY, 2014, RADIOTHER ONCOL, V112, P442, DOI 10.1016/j.radonc.2014.08.009
   LUTZ WR, 1988, MED PHYS, V15, P614, DOI 10.1118/1.596214
   Mancosu P, 2015, MED PHYS, V42, P5035, DOI 10.1118/1.4927569
   Moignier C, 2014, MED PHYS, V41, DOI 10.1118/1.4881098
   Morales JE, 2014, MED PHYS, V41, DOI 10.1118/1.4895827
   Morin J, 2013, MED PHYS, V40, DOI 10.1118/1.4772190
   MUNRO P, 1988, MED PHYS, V15, P517, DOI 10.1118/1.596295
   Pantelis E, 2008, MED PHYS, V35, P2312, DOI 10.1118/1.2919099
   Papaconstadopoulos P, 2014, PHYS MED BIOL, V59, P5937, DOI 10.1088/0031-9155/59/19/5937
   Sauer OA, 2007, MED PHYS, V34, P1983, DOI 10.1118/1.2734383
   Scott AJD, 2009, MED PHYS, V36, P3132, DOI 10.1118/1.3152866
   Sham E, 2008, MED PHYS, V35, P3317, DOI 10.1118/1.2936335
   Sterpin E, 2012, MED PHYS, V39, P4066, DOI 10.1118/1.4722752
   Sterpin E, 2010, RADIOTHER ONCOL, V94, P229, DOI 10.1016/j.radonc.2009.12.018
   Tyler M, 2013, PHYS MED BIOL, V58, P7595, DOI 10.1088/0031-9155/58/21/7595
   Underwood TSA, 2015, PHYS MED BIOL, V60, P6669, DOI 10.1088/0031-9155/60/17/6669
   Wang LLW, 2007, MED PHYS, V34, P485, DOI 10.1118/1.2426407
   Wilcox EE, 2007, MED PHYS, V34, P1967, DOI 10.1118/1.2734384
NR 60
TC 21
Z9 21
U1 0
U2 10
PY 2016
VL 1747
AR 060001
DI 10.1063/1.4954111
UT WOS:000380810000024
DA 2023-11-16
ER

PT J
AU Zhang, YC
   Yasaei, R
   Chen, H
   Li, Z
   Al Faruque, MA
AF Zhang, Yicheng
   Yasaei, Rozhin
   Chen, Hao
   Li, Zhou
   Al Faruque, Mohammad Abdullah
TI Stealing Neural Network Structure Through Remote FPGA Side-Channel
   Analysis
SO IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY
DT Article
DE Field programmable gate arrays; Cloud computing; Computational modeling;
   Analytical models; Integrated circuit modeling; Hardware; Inverters;
   Deep neural network; cloud FPGA; side-channel analysis; hardware trojan
ID ATTACKS
AB Deep Neural Network (DNN) models have been extensively developed by companies for a wide range of applications. The development of a customized DNN model with great performance requires costly investments, and its structure (layers and hyper-parameters) is considered intellectual property and holds immense value. However, in this paper, we found the model secret is vulnerable when a cloud-based FPGA accelerator executes it. We demonstrate an end-to-end attack based on remote power side-channel analysis and machine-learning-based secret inference against different DNN models. The evaluation result shows that an attacker can reconstruct the layer and hyper-parameter sequence at over 90% accuracy using our method, which can significantly reduce her model development workload. We believe the threat presented by our attack is tangible, and new defense mechanisms should be developed against this threat.
C1 [Zhang, Yicheng; Yasaei, Rozhin; Chen, Hao; Li, Zhou; Al Faruque, Mohammad Abdullah] Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92617 USA.
RP Zhang, YC (corresponding author), Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92617 USA.
EM yichez16@uci.edu
CR Ahmed Qazi Arbab, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P127, DOI 10.1007/978-3-030-17227-5_10
   Ahmed QA, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1490, DOI 10.23919/DATE51398.2021.9474026
   Al-Aghbari AA, 2019, IEEE ACCESS, V7, P38009, DOI 10.1109/ACCESS.2019.2906910
   Amazon, AMAZON EC2 F1 INSTAN
   Amazon, AWS EC2 FPGA HDK SDK
   [Anonymous], 2015, TINY IMAGENET VISUAL
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Bengio, 2016, ABS160202830 CORR
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chen F., 2014, PES GEN M C EXP JUL, P1
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Christ M, 2018, NEUROCOMPUTING, V307, P72, DOI 10.1016/j.neucom.2018.03.067
   Dai GH, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P330, DOI 10.1109/FPT.2014.7082811
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubey A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P197, DOI [10.1109/host45689.2020.9300276, 10.1109/HOST45689.2020.9300276]
   Duddu V., 2018, CORR
   Elnaggar R, 2019, DES AUT TEST EUROPE, P7, DOI [10.23919/DATE.2019.8714904, 10.23919/date.2019.8714904]
   Faezi S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1484, DOI 10.23919/DATE51398.2021.9474076
   Faezi S, 2021, IEEE T INF FOREN SEC, V16, P2697, DOI 10.1109/TIFS.2021.3062989
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Giechaskiel I., 2019, ACM T RECONFIGURABLE, V12, P1
   Giechaskiel I, 2020, P IEEE S SECUR PRIV, P1728, DOI 10.1109/SP40000.2020.00070
   Giechaskiel I, 2019, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD46524.2019.00010
   Gnad Dennis R. E., 2018, 2018 International Conference on Field-Programmable Technology (FPT). Proceedings, P286, DOI 10.1109/FPT.2018.00055
   Google, GOOGLE COMPUTE ENGIN
   Hong S., 2018, ARXIV PREPRINT ARXIV
   Hu X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P385, DOI 10.1145/3373376.3378460
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   King DB, 2015, ACS SYM SER, V1214, P1
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Krautter J., 2019, P IEEEACM INT C COMP, P1
   Krautter J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3328222
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, P USENIX SECUR S, P601
   La TM, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3402937
   Lippmann R. P., 1987, IEEE ASSP Magazine, V4, P4, DOI 10.1145/44571.44572
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Mangard S, 2004, LECT NOTES COMPUT SC, V2964, P222
   Mangard S, 2002, LECT NOTES COMPUT SC, V2587, P343
   Mbongue JM, 2020, IEEE INT CONF ASAP, P125, DOI 10.1109/ASAP49362.2020.00030
   Mbongue JM, 2018, PR IEEE COMP DESIGN, P242, DOI 10.1109/ICCD.2018.00044
   Microsoft, AZURE FPGA INFERENCE
   Moini S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1639, DOI 10.23919/DATE51398.2021.9473915
   Moini S, 2021, IEEE J EM SEL TOP C, V11, P357, DOI 10.1109/JETCAS.2021.3074608
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Naghibijouybari H, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P2139, DOI 10.1145/3243734.3243831
   Papernot N, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P399, DOI 10.1109/EuroSP.2018.00035
   Popp T, 2007, IEEE DES TEST COMPUT, V24, P535, DOI 10.1109/MDT.2007.200
   Provelengios G, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P292, DOI 10.1145/3289602.3293923
   Rish I, 2001, IJCAI 2001 WORK EMPI, V3, P41
   Ristenpart T, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P199
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Schellenberg F, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240841
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sugawara T, 2019, ELECTRON LETT, V55, P640, DOI 10.1049/el.2019.0163
   Tarafdar Naif, 2019, HARDWARE ACCELERATOR, P9
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Vaishnav A, 2018, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2018.00031
   Wang BH, 2018, P IEEE S SECUR PRIV, P36, DOI 10.1109/SP.2018.00038
   Weerasinghe J, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P1078, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.199
   Wei JY, 2020, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN48063.2020.00031
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   xilinx, ZEDBOARD
   Xillybus, XILLYBUS PRODUCT BRI
   Yan MJ, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2003
   Yasaei R, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1504, DOI 10.23919/DATE51398.2021.9474174
   Yasaei R, 2021, DES AUT CON, P217, DOI 10.1109/DAC18074.2021.9586150
   Yasaei R, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415672
   Yoshida K, 2019, ANN IEEE SYM FIELD P, P318, DOI 10.1109/FCCM.2019.00059
   Yu HG, 2020, 27TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2020), DOI 10.14722/ndss.2020.24178
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
   Yuan X., 2020, ARXIV200909560
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang K, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P927, DOI 10.1145/3287324.3287475
   Zhang YQ, 2011, P IEEE S SECUR PRIV, P313, DOI 10.1109/SP.2011.31
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zhu YK, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1973
NR 81
TC 14
Z9 14
U1 0
U2 12
PY 2021
VL 16
BP 4377
EP 4388
DI 10.1109/TIFS.2021.3106169
UT WOS:000692567600007
DA 2023-11-16
ER

PT J
AU Golcarenarenji, G
   Martinez-Alpiste, I
   Wang, Q
   Alcaraz-Calero, JM
AF Golcarenarenji, Gelayol
   Martinez-Alpiste, Ignacio
   Wang, Qi
   Alcaraz-Calero, Jose Maria
TI Robust real-time traffic light detector on small-form platform for
   autonomous vehicles
SO JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS
DT Article; Early Access
DE Autonomous vehicle; computer vision; modified YOLO; traffic light
   detection
ID RECOGNITION; NETWORK
AB Timely and accurate detection and recognition of traffic lights are critical for Autonomous Vehicles (AVs) to avoid crashes due to red light running. This paper integrates a new robust machine learning based solution by combining a Convolutional Neural Network (CNN) with computer vision techniques to achieve a real-time traffic light detector. The proposed detection and recognition algorithm is capable of recognizing traffic lights on low-power small-form platforms, which are lightweight, portable, and can be mounted on AVs in daylight scenarios. The LISA open-source dataset is utilized with augmentation methods to increase the accuracy of the solution. The proposed approach achieves 93.42% of accuracy at a speed of 30.01 Frames Per Second (FPS) on an NVIDIA Jetson Xavier platform without using hardware accelerators such as FPGA. This solution is expected to promote the quicker adoption and wider deployment of AVs by increasing the chances of avoiding crashes and ultimately saving lives.
C1 [Golcarenarenji, Gelayol; Martinez-Alpiste, Ignacio; Wang, Qi; Alcaraz-Calero, Jose Maria] Univ West Scotland, Sch Comp Engn & Phys Sci, Paisley, Scotland.
   [Golcarenarenji, Gelayol] Univ Portsmouth, Sch Comp, Portsmouth, England.
   [Golcarenarenji, Gelayol] Univ West Scotland, Sch Comp Engn & Phys Sci, High St, Paisley, Scotland.
RP Golcarenarenji, G (corresponding author), Univ West Scotland, Sch Comp Engn & Phys Sci, High St, Paisley, Scotland.
EM gollygolkar@gmail.com
CR Alexey, 2017, YOLOMARK
   Alexey, 2020, DARKNET
   Binangkit J.L., 2016, 10 INT C TEL SYST SE, P1, DOI DOI 10.1109/TSSA.2016.7871074
   Bochkovskiy A., 2020, PREPRINT
   Chen XF, 2021, J INTELL TRANSPORT S, V25, P533, DOI 10.1080/15472450.2021.1871611
   Chen ZL, 2016, IEEE INTEL TRANSP SY, V8, P28, DOI 10.1109/MITS.2016.2605381
   Dai JF, 2016, Arxiv, DOI [arXiv:1605.06409, DOI 10.48550/ARXIV.1605.06409]
   Fernández C, 2018, IEEE INT C INTELL TR, P248, DOI 10.1109/ITSC.2018.8569914
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gouda M, 2023, J INTELL TRANSPORT S, V27, P643, DOI 10.1080/15472450.2022.2074792
   He WP, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163225
   Hirabayashi M, 2019, ROBOT AUTON SYST, V111, P62, DOI 10.1016/j.robot.2018.10.004
   IIHS, 2012, RED LIGHT RUNNING
   INRIA's project-team IMARA Mines ParisTech's CAOR, 2009, TRAFFIC LIGHT RECOGN
   Jensen MB, 2017, IEEE COMPUT SOC CONF, P882, DOI 10.1109/CVPRW.2017.122
   John V, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2286, DOI 10.1109/ITSC.2014.6958056
   John V, 2016, 2016 ASIA-PACIFIC CONFERENCE ON INTELLIGENT ROBOT SYSTEMS (ACIRS 2016), P204, DOI 10.1109/ACIRS.2016.7556213
   Ju MR, 2019, IEEE ACCESS, V7, P85771, DOI 10.1109/ACCESS.2019.2924960
   Kim HK, 2018, J ADV TRANSPORT, DOI 10.1155/2018/2365414
   Kim J, 2018, IEEE INT C INTELL TR, P280, DOI 10.1109/ITSC.2018.8569575
   Kohavi R., 1995, P 14 INT JOINT C ART, P5
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loshchilov Ilya, 2016, ARXIV160803983
   Martinez-Alpiste I, 2019, IEEE WCNC
   Martinez-Alpiste I, 2020, J FIELD ROBOT, V37, P404, DOI 10.1002/rob.21921
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Müller J, 2018, IEEE INT C INTELL TR, P266, DOI 10.1109/ITSC.2018.8569683
   Oliveira-Santos, 2019, P 2019 INT JOINT C N, P1
   Ou Yangze, 2022, Proceedings of the 12th International Conference on Computer Engineering and Networks. Lecture Notes in Electrical Engineering (961), P1354, DOI 10.1007/978-981-19-6901-0_143
   Ouyang ZC, 2020, IEEE T MOBILE COMPUT, V19, P300, DOI 10.1109/TMC.2019.2892451
   Ozcelik Z, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P424, DOI 10.1109/UBMK.2017.8093430
   Pon AD, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P102, DOI 10.1109/CRV.2018.00024
   Redmon J., 2018, ARXIV
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Saini S, 2017, IEEE INT VEH SYM, P606, DOI 10.1109/IVS.2017.7995785
   Tsai MY, 2022, 2022 IEEE 31ST INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS (ISIE), P594, DOI 10.1109/ISIE51582.2022.9831510
   Vaidya B., 2019, P COMPUTER VISION IM, P82
   Van Etten A, 2018, Arxiv, DOI arXiv:1805.09512
   Wang C., 2022, ARXIV
   Wang CY, 2019, IEEE INT CONF COMP V, P2477, DOI 10.1109/ICCVW.2019.00303
   Weber M, 2018, IEEE INT C INTELL TR, P255, DOI 10.1109/ITSC.2018.8569794
   Weber M, 2016, IEEE INT VEH SYM, P342, DOI 10.1109/IVS.2016.7535408
   Yudin D, 2018, MEDD C EMBED COMPUT, P242
NR 46
TC 0
Z9 0
U1 11
U2 11
PD 2023 APR 24
PY 2023
DI 10.1080/15472450.2023.2205018
EA APR 2023
UT WOS:000980360500001
DA 2023-11-16
ER

PT C
AU Miro-Panades, I
   Tain, B
   Christmann, JF
   Coriat, D
   Lemaire, R
   Jany, C
   Martineau, B
   Chaix, F
   Quelen, A
   Pluchart, E
   Noel, JP
   Boumchedda, R
   Makosiej, A
   Montoya, M
   Bacles-Min, S
   Briand, D
   Philippe, JM
   Valentian, A
   Heitzmann, F
   Beigne, E
   Clermidy, F
AF Miro-Panades, Ivan
   Tain, Benoit
   Christmann, Jean-Frederic
   Coriat, David
   Lemaire, Romain
   Jany, Clement
   Martineau, Baudouin
   Chaix, Fabrice
   Quelen, Anthony
   Pluchart, Emmanuel
   Noel, Jean-Philippe
   Boumchedda, Reda
   Makosiej, Adam
   Montoya, Maxime
   Bacles-Min, Simone
   Briand, David
   Philippe, Jean-Marc
   Valentian, Alexandre
   Heitzmann, Frederic
   Beigne, Edith
   Clermidy, Fabien
GP IEEE
TI SamurAI: a 1.7MOPS-36GOPS Adaptive Versatile IoT Node with 15,000x
   Peak-to-Idle Power Reduction, 207ns Wake-up Time and 1.3TOPS/W ML
   Efficiency
SO 2020 IEEE SYMPOSIUM ON VLSI CIRCUITS
SE Symposium on VLSI Circuits-Digest of Papers
DT Proceedings Paper
CT IEEE Symposium on VLSI Circuits
CY JUN 15-19, 2020
CL ELECTR NETWORK
AB IoT node application requirements are torn between sporadic data-logging and energy-hungry data processing (e.g. image classification). This paper presents a versatile IoT node covering this gap in processing and energy by leveraging two on-chip sub-systems: a low power, clock-less, event-driven Always-Responsive (AR) part and an energy-efficient On-Demand (OD) part. The AR contains a 1.7MOPS event-driven, asynchronous Wake-up Controller (WuC) with 207ns wake-up time optimized for short sporadic computing. OD combines a deep-sleep RISC-V CPU and 1.3TOPS/W Machine Learning (ML) and crypto accelerators for more complex tasks. The node can perform up to 36GOPS while achieving 15,000x reduction from peak-to-idle power consumption. The interest of this versatile architecture is demonstrated with 105 mu W daily average power on an applicative classification scenario.
C1 [Miro-Panades, Ivan; Christmann, Jean-Frederic; Coriat, David; Lemaire, Romain; Pluchart, Emmanuel; Noel, Jean-Philippe; Bacles-Min, Simone; Valentian, Alexandre; Clermidy, Fabien] Univ Grenoble Alpes, LIST, CEA, Grenoble, France.
   [Tain, Benoit; Briand, David; Philippe, Jean-Marc] Univ Paris Saclay, LIST, CEA, Gif Sur Yvette, France.
   [Jany, Clement; Martineau, Baudouin; Chaix, Fabrice; Quelen, Anthony; Boumchedda, Reda; Makosiej, Adam; Montoya, Maxime; Heitzmann, Frederic; Beigne, Edith] Univ Grenoble Alpes, LETI, CEA, Grenoble, France.
   [Boumchedda, Reda] STMicroelectronics, Crolles, France.
RP Miro-Panades, I (corresponding author), Univ Grenoble Alpes, LIST, CEA, Grenoble, France.
EM ivan.miro-panades@cea.fr
CR Bang S., 2017, ISSCC
   Boumchedda R., 2018, L SSC
   Carbon A., 2018, DATE
   Christmann J.-F., 2019, JLPEA
   Lallement G., 2018, JSSC
   Myers J., 2016, JSSC
   Paul S., 2017, JSSC
   Pletcher N. M., 2008, ISSCC
   Pu Yu, 2018, JSSC
   Pullini A., 2019, JSSC
NR 10
TC 11
Z9 11
U1 0
U2 0
PY 2020
UT WOS:000621657500100
DA 2023-11-16
ER

PT C
AU Vandebon, J
   Coutinho, JGF
   Luk, W
   Nurvitadhi, E
   Naik, M
AF Vandebon, Jessica
   Coutinho, Jose G. F.
   Luk, Wayne
   Nurvitadhi, Eriko
   Naik, Mishali
BE Hannig, F
   Navaridas, J
   Koch, D
   Abdelhadi, A
TI SLATE: Managing Heterogeneous Cloud Functions
SO 2020 IEEE 31ST INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2020)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 31st IEEE International Conference on Application-Specific Systems,
   Architectures and Processors (ASAP)
CY JUL 06-08, 2020
CL Univ Manchester, Dept Comp Sci, Manchester, ENGLAND
HO Univ Manchester, Dept Comp Sci
AB This paper presents SLATE, a fully-managed, heterogeneous Function-as-a-Service (FaaS) system for deploying serverless functions onto heterogeneous cloud infrastructures. We extend the traditional homogeneous FaaS execution model to support heterogeneous functions, automating and abstracting runtime management of heterogeneous compute resources in order to improve cloud tenant accessibility to specialised, accelerator resources, such as FPGAs and GPUs. In particular, we focus on the mechanisms required for heterogeneous scaling of deployed function instances to guarantee latency objectives while minimising cost. We develop a simulator to validate and evaluate our approach, considering case-study functions in three application domains: machine learning, bio-informatics, and physics. We incorporate empirically derived performance models for each function implementation targeting a hardware platform with combined computational capacity of 24 FPGAs and 12 CPU cores. Compared to homogeneous CPU and homogeneous FPGA functions, simulation results achieve respectively a cost improvement for non-uniform task traffic of up to 8.7 times and 1.7 times, while maintaining specified latency objectives.
C1 [Vandebon, Jessica; Coutinho, Jose G. F.; Luk, Wayne] Imperial Coll London, London, England.
   [Nurvitadhi, Eriko; Naik, Mishali] Intel Corp, San Jose, CA USA.
RP Vandebon, J (corresponding author), Imperial Coll London, London, England.
EM jessica.vandebon17@imperial.ac.uk; gabriel.figueiredo@imperial.ac.uk;
   w.luk@imperial.ac.uk; eriko.nurvitadhi@intel.com; mishali.naik@intel.com
CR Amazon Web Services, AMAZON EC2
   Amazon Web Services, AWS LAMBDA SERVERLES
   Apache Software Foundation, OPEN SOURCE SERVERLE
   Arram J, 2017, IEEE ACM T COMPUT BI, V14, P668, DOI 10.1109/TCBB.2016.2535385
   Asiatici M, 2017, IEEE ACCESS, V5, P1900, DOI 10.1109/ACCESS.2017.2661582
   Google Cloud Platform, CLOUD FUNCTIONS
   Graepel T., 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Kubeless, KUBERNETES NATIVE SE
   Maxeler, 2015, N BODY PARTICLE SIMU
   Mbongue JM, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P862, DOI 10.1109/CLOUD.2018.00122
   Microsoft Azure, AZURE FUNCTIONS SERV
   Vandebon J, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P162, DOI 10.1109/ICFPT47387.2019.00027
NR 12
TC 2
Z9 2
U1 0
U2 1
PY 2020
BP 141
EP 148
DI 10.1109/ASAP49362.2020.00032
UT WOS:000618062800023
DA 2023-11-16
ER

PT J
AU Riera, M
   Arnau, JM
   González, A
AF Riera, Marc
   Arnau, Jose Maria
   Gonzalez, Antonio
TI CREW: Computation reuse and efficient weight storage for
   hardware-accelerated MLPs and RNNs
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Machine learning; Deep neural networks; Computation reuse; Accelerators;
   Low energy
ID NEURAL-NETWORKS
AB Deep Neural Networks (DNNs) have achieved tremendous success for cognitive applications. The core operation in a DNN is the dot product between quantized inputs and weights. Prior works exploit the weight/input repetition that arises due to quantization to avoid redundant computations in Convolutional Neural Networks (CNNs). However, in this paper we show that their effectiveness is severely limited when applied to FullyConnected (FC) layers, which are commonly used in state-of-the-art DNNs, as it is the case of modern Recurrent Neural Networks (RNNs) and Transformer models. To improve energy-efficiency of FC computation we present CREW, a hardware accelerator that implements Computation Reuse and an Efficient Weight Storage mechanism to exploit the large number of repeated weights in FC layers. CREW first performs the multiplications of the unique weights by their respective inputs and stores the results in an on-chip buffer. The storage requirements are modest due to the small number of unique weights and the relatively small size of the input compared to convolutional layers. Next, CREW computes each output by fetching and adding its required products. To this end, each weight is replaced offline by an index in the buffer of unique products. Indices are typically smaller than the quantized weights, since the number of unique weights for each input tends to be much lower than the range of quantized weights, which reduces storage and memory bandwidth requirements. Overall, CREW greatly reduces the number of multiplications and provides significant savings in model memory footprint and memory bandwidth usage. We evaluate CREW on a diverse set of modern DNNs. On average, CREW provides 2.61x speedup and 2.42x energy savings over a TPU-like accelerator. Compared to UCNN, a state-of-art computation reuse technique, CREW achieves 2.10x speedup and 2.08x energy savings on average.
C1 [Riera, Marc; Arnau, Jose Maria; Gonzalez, Antonio] Univ Politecn Catalunya UPC, Barcelona, Spain.
RP Riera, M (corresponding author), Univ Politecn Catalunya UPC, Barcelona, Spain.
EM mriera@ac.upc.edu
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2014, ARXIV
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cho K, 2014, EMNLP 2014 2014 C EM, DOI [DOI 10.3115/V1/D14-1179, 10.3115]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Garland J, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3233300
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P933, DOI [10.1109/MICR0.2018.00080, 10.1109/MICRO.2018.00080]
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Imani M, 2020, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA47549.2020.00011
   Jiao X, 2018, DES AUT TEST EUROPE, P1223, DOI 10.23919/DATE.2018.8342202
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuchaiev O, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P41
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   KUNG SY, 1989, J PARALLEL DISTR COM, V6, P358, DOI 10.1016/0743-7315(89)90065-8
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luong T., 2015, P 2015 C EMP METH NA, P1412
   Micron, 2001, MICR LPDDR4 SYST POW
   Mittal S, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102041
   Moolchandani D, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101887
   Ning L, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P438, DOI 10.1145/3330345.3330384
   Ondrej Bojar, 2016, P 1 C MACHINE TRANSL, DOI DOI 10.18653/V1/W16-2301
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paszke A, 2019, ADV NEUR IN, V32
   Pattanayak S, 2021, J SYST ARCHITECT, V116, DOI 10.1016/j.sysarc.2021.102031
   Povey D., 2011, PROC ASRU
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Riera M, 2022, J SYST ARCHITECT, V122, DOI 10.1016/j.sysarc.2021.102336
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Samajdar Ananda, 2018, ARXIV
   Synopsys, 1986, SYN DES COMP DES LIB
   Vaswani A, 2017, ADV NEUR IN, V30
   Widrow B, 1996, IEEE T INSTRUM MEAS, V45, P353, DOI 10.1109/19.492748
   Wu Y., 2016, ARXIV
   Xia M, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.101991
   Yasoubi A, 2017, IEEE COMPUT ARCHIT L, V16, P72, DOI 10.1109/LCA.2016.2521654
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang JJ, 2015, IEEE INTELL SYST, V30, P16, DOI 10.1109/MIS.2015.69
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang XH, 2014, INT CONF ACOUST SPEE
   Zhou A, 2017, ARXIV
   Zhou S, 2016, ARXIV
   Zhu C., 2017, INT C LEARN REPR ICL, P1
NR 54
TC 0
Z9 0
U1 0
U2 0
PD AUG
PY 2022
VL 129
AR 102604
DI 10.1016/j.sysarc.2022.102604
EA JUN 2022
UT WOS:000855031800007
DA 2023-11-16
ER

PT J
AU Jiang, HW
   Huang, SS
   Li, WT
   Yu, SM
AF Jiang, Hongwu
   Huang, Shanshi
   Li, Wantong
   Yu, Shimeng
TI ENNA: An Efficient Neural Network Accelerator Design Based on ADC-Free
   Compute-In-Memory Subarrays
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Compute-in-memory; ADC-free; pulse-width-modulation; heterogeneous 3D
   integration
AB Compute-in-memory (CIM) is an attractive solution for machine learning hardware acceleration since it merges computation directly into memory arrays, performing parallel multiply-and-accumulate (MAC) operations. The primary challenge in the reported CIM designs is the analog-to-digital converters (ADCs) that digitize analog MAC values for further processing, causing accuracy loss, excessive power dissipation, latency penalty, and area overhead. In this work, we propose ENNA, a novel CIM architecture based on an ADC-free subarray design, implementing inter-array data processing in an analog manner. A lightweight input encoding scheme based on pulse-width modulation (PWM) is proposed to improve the throughput. We taped-out a prototype macro and validated the proposed ADC-free RRAM array design in TSMC 40nm process. Based on the measured silicon data, we explore the system-level performance with a partition between analog and digital processing at a level higher than the sub-array. The evaluation results show that the proposed accelerator can achieve 73.6 similar to 46.4 TOPS/VV energy efficiency and 2.3 similar to 7 TOPS throughput (normalized to binary operation) tested on various DNN models. Furthermore, we project the proposed design using a heterogeneous 3D integration (H3D) scheme, showing a 3x similar to 37x throughput improvement depending on different tasks and similar to 50% reduced area overhead compared to 2D design.
C1 [Jiang, Hongwu; Huang, Shanshi; Li, Wantong; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Jiang, HW (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM hjiang318@gatech.edu; shimeng.yu@ece.gatech.edu
CR Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Cheng-Xin Xue, 2021, 2021 IEEE International Solid- State Circuits Conference (ISSCC), P245, DOI 10.1109/ISSCC42613.2021.9365769
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hubara I, 2016, ADV NEUR IN, V29
   Jia HY, 2021, ISSCC DIG TECH PAP I, V64, P236, DOI 10.1109/ISSCC42613.2021.9365788
   Jiang Hongwu, 2022, 2022 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits), P266, DOI 10.1109/VLSITechnologyandCir46769.2022.9830211
   Jiang HW, 2022, IEEE DES TEST, V39, P48, DOI 10.1109/MDAT.2021.3050715
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jourdain A, 2020, ELEC COMP C, P42, DOI 10.1109/ECTC32862.2020.00020
   Khaddam-Aljameh R, 2022, IEEE J SOLID-ST CIRC, V57, P1027, DOI 10.1109/JSSC.2022.3140414
   Kim T, 2020, IEEE T ELECTRON DEV, V67, P1394, DOI 10.1109/TED.2020.2964640
   Li WT, 2021, PROC EUR S-STATE DEV, P79, DOI 10.1109/ESSDERC53440.2021.9631810
   Li WT, 2021, IEEE CUST INTEGR CIR, DOI 10.1109/CICC51472.2021.9431558
   Lu A., 2021, FRONTIERS ARTIF INTE, V4, P70
   Mikolajick T, 2020, IEEE T ELECTRON DEV, V67, P1434, DOI 10.1109/TED.2020.2976148
   Peng X., 2020, IEDM, P30, DOI DOI 10.1109/TCSI.2018.2828611
   Peng XC, 2019, INT EL DEVICES MEET
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Vanhoucke Vincent, 2011, DEEP LEARNING UNSUPE
   Wu P.-C., 2022, IEEE INT SOLID STATE, V65, P1
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yoon JH, 2021, ISSCC DIG TECH PAP I, V64, P404, DOI 10.1109/ISSCC42613.2021.9365926
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
   Yue JS, 2021, ISSCC DIG TECH PAP I, V64, P238, DOI 10.1109/ISSCC42613.2021.9365958
   Zhu Z., 2019, PROC 56 ANN DESIGN A, P1
NR 31
TC 2
Z9 2
U1 9
U2 24
PD JAN
PY 2023
VL 70
IS 1
BP 353
EP 363
DI 10.1109/TCSI.2022.3208755
EA OCT 2022
UT WOS:000869042500001
DA 2023-11-16
ER

PT J
AU Jiang, ZW
   Yin, SH
   Seo, JS
   Seok, M
AF Jiang, Zhewei
   Yin, Shihui
   Seo, Jae-Sun
   Seok, Mingoo
TI C3SRAM: An In-Memory-Computing SRAM Macro Based on Robust Capacitive
   Coupling Computing Mechanism
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Transistors; Capacitors; Random access memory; Computer architecture;
   Neural networks; Couplings; Acceleration; Analog-mixed-signal (AMS)
   computing; capacitive coupling; in-memory computing (IMC); machine
   learning accelerator; neural network; SRAM
ID ACCELERATOR; NETWORK
AB This article presents C3SRAM, an in-memory-computing SRAM macro. The macro is an SRAM module with the circuits embedded in bitcells and peripherals to perform hardware acceleration for neural networks with binarized weights and activations. The macro utilizes analog-mixed-signal (AMS) capacitive-coupling computing to evaluate the main computations of binary neural networks, binary-multiply-and-accumulate operations. Without the need to access the stored weights by individual row, the macro asserts all its rows simultaneously and forms an analog voltage at the read bitline node through capacitive voltage division. With one analog-to-digital converter (ADC) per column, the macro realizes fully parallel vector-matrix multiplication in a single cycle. The network type that the macro supports and the computing mechanism it utilizes are determined by the robustness and error tolerance necessary in AMS computing. The C3SRAM macro is prototyped in a 65-nm CMOS. It demonstrates an energy efficiency of 672 TOPS/W and a speed of 1638 GOPS (20.2 TOPS/mm(2)), achieving 3975x better energy-delay product than the conventional digital baseline performing the same operation. The macro achieves 98.3% accuracy for MNIST and 85.5% for CIFAR-10, which is among the best in-memory computing works in terms of energy efficiency and inference accuracy tradeoff.
C1 [Jiang, Zhewei; Seok, Mingoo] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   [Yin, Shihui; Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
RP Seok, M (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
EM ms4415@columbia.edu
CR [Anonymous], 2017, 2017 S VLSI CIRC
   [Anonymous], ARXIV170905306
   [Anonymous], REL PHYS S IRPS 2011
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   Eckert C, 2019, IEEE MICRO, V39, P11, DOI 10.1109/MM.2019.2908101
   Gambardella G., 2019, P IEEE INT S DEF FAU, P1
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Parveen F, 2018, ASIA S PACIF DES AUT, P361, DOI 10.1109/ASPDAC.2018.8297350
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Yin SH, 2020, IEEE T VLSI SYST, V28, P48, DOI 10.1109/TVLSI.2019.2940649
   Zabihi M, 2019, IEEE T COMPUT, V68, P1159, DOI 10.1109/TC.2018.2858251
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhao Y, 2017, ADVANCES IN ENERGY AND ENVIRONMENT RESEARCH, P345
   Zhou Shuchang, 2016, ARXIV160606160
NR 43
TC 107
Z9 110
U1 2
U2 20
PD JUL
PY 2020
VL 55
IS 7
BP 1888
EP 1897
DI 10.1109/JSSC.2020.2992886
UT WOS:000543984900014
DA 2023-11-16
ER

PT J
AU Shin, G
   Kim, J
   Kim, JY
AF Shin, Gyeongcheol
   Kim, Junsoo
   Kim, Joo-Young
TI OpenMDS: An Open-Source Shell Generation Framework for High-Performance
   Design on Xilinx Multi-Die FPGAs
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Field programmable gate arrays; Kernel; Hardware; Pipeline processing;
   Timing; Routing; Registers; FPGA; shell; design automation; open-source;
   high-performance design; multi-die FPGA
AB FPGA is a promising platform in designing hardware due to its design flexibility and fast development cycle, despite the device's limited hardware resources. To address this, latest FPGAs have adopted a multi-die architecture that employs multiple dies in a single device to provide abundant hardware resources. However, the multi-die architecture causes critical timing issues when signal paths cross the die-to-die boundaries, adding another design challenge in using FPGA. We propose OpenMDS, an open-source shell generation framework for high-performance design on Xilinx multi-die FPGAs. Based on the user's design requirements, it generates an optimized shell for the target FPGA via die-level kernel encapsulation, automated bus pipelining, and customized floorplanning. To evaluate our shell generation, we compare its implementation results against Xilinx's Vitis framework. As a result, OpenMDS uses average 20% less logic resources than Vitis for the same shell functionality. To show its practicality, we use OpenMDS for the design of machine learning accelerator that contains multiple systolic-array processors. OpenMDS achieves 247MHz and 235MHz kernel frequency and 400MHz and 429MHz memory bus frequency for U50 and U280, respectively, for the accelerator design over 90% logic utilization, claiming up to 12.27% and 22.92% higher kernel and memory bus frequency over Vitis.
C1 [Shin, Gyeongcheol; Kim, Junsoo; Kim, Joo-Young] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
RP Kim, JY (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
EM skc228@kaist.ac.kr; junsoo999@kaist.ac.kr; jooyoung1203@kaist.ac.kr
CR [Anonymous], AMAZON EC2 F1 INSTAN
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Dua A, 2020, ANN IEEE SYM FIELD P, P231, DOI 10.1109/FCCM48280.2020.00064
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Licheng Guo, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P81, DOI 10.1145/3431920.3439289
   Nasiri E, 2016, IEEE T VLSI SYST, V24, P1821, DOI 10.1109/TVLSI.2015.2478280
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Voss N, 2019, ANN IEEE SYM FIELD P, P78, DOI 10.1109/FCCM.2019.00021
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
NR 10
TC 0
Z9 0
U1 0
U2 0
PD JUL-DEC
PY 2022
VL 21
IS 2
BP 101
EP 104
DI 10.1109/LCA.2022.3202016
UT WOS:000861415100001
DA 2023-11-16
ER

PT C
AU Wijeratne, S
   Kannan, R
   Prasanna, V
AF Wijeratne, Sasindu
   Kannan, Rajgopal
   Prasanna, Viktor
GP IEEE
TI Reconfigurable Low-latency Memory System for Sparse Matricized Tensor
   Times Khatri-Rao Product on FPGA
SO 2021 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 20-24, 2021
CL ELECTR NETWORK
DE MTTKRP; Memory Systems; Shared Memory; FPGA; Tensor Decomposition
AB Tensor decomposition has become an essential tool in many applications in various domains, including machine learning. Sparse Matricized Tensor Times Khatri-Rao Product (MTTKRP) is one of the most computationally expensive kernels in tensor computations. Despite having significant computational parallelism, MTTKRP is a challenging kernel to optimize due to its irregular memory access characteristics. This paper focuses on a multi-faceted memory system, which explores the spatial and temporal locality of the data structures of MTTKRP. Further, users can reconfigure our design depending on the behavior of the compute units used in the FPGA accelerator. Our system efficiently accesses all the MTTKRP data structures while reducing the total memory access time, using a distributed cache and Direct Memory Access (DMA) subsystem. Moreover, our work improves the memory access time by 3.5x compared with commercial memory controller IPs. Also, our system shows 2x and 1.26x speedups compared with cache-only and DMA-only memory systems, respectively.
C1 [Wijeratne, Sasindu; Prasanna, Viktor] Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Kannan, Rajgopal] US Army Res Lab, Los Angeles, CA USA.
RP Wijeratne, S (corresponding author), Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
EM kangaram@usc.edu; rajgopal.kannan.civ@mail.mil; prasanna@usc.edu
CR Ahmed N. K., 2020, ABS201006277 CORR
   Asiatici M, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P310, DOI 10.1145/3289602.3293901
   Asiatici M, 2019, I C FIELD PROG LOGIC, P254, DOI 10.1109/FPL.2019.00049
   Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489
   BENNETT J, 2007, SIGKDD EXPLOR NEWSL, V9, P51, DOI DOI 10.1145/1345448.1345459
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Chen Z., 2021, DEEP TRANSFER TENSOR
   Cheng ZY, 2020, INT CONF ACOUST SPEE, P3292, DOI [10.1109/icassp40776.2020.9053292, 10.1109/ICASSP40776.2020.9053292]
   Fernandes S, 2021, ARTIF INTELL REV, V54, P2891, DOI 10.1007/s10462-020-09916-4
   Gil A. D. S., 2010, Proceedings 2010 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2010), P250, DOI 10.1109/ReConFig.2010.26
   Hong D, 2020, SIAM REV, V62, P133, DOI 10.1137/18M1203626
   Intel, EXT MEM INT INT ARR
   Kjolstad F, 2019, INT SYM CODE GENER, P180, DOI [10.1109/cgo.2019.8661185, 10.1109/CGO.2019.8661185]
   Kolda TG, 2020, SIAM J MATH DATA SCI, V2, P1066, DOI 10.1137/19M1266265
   LAM MS, 1991, SIGPLAN NOTICES, V26, P63, DOI 10.1145/106973.106981
   Ma XY, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P227, DOI 10.1145/3020078.3021743
   McKee S A., 2004, COMPUTING FRONTIERS, P162, DOI DOI 10.1145/977091.977115
   Mondelli M., 2019, 22 INT C ARTIFICIAL, P1051
   Nisa I, 2019, INT PARALL DISTRIB P, P123, DOI 10.1109/IPDPS.2019.00023
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Taguchi Y, 2019, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2395-8
   Volos S., 2016, EFFECTIVE DRAM CACHE
   Wen FX, 2020, INT CONF ACOUST SPEE, P4572, DOI [10.1109/icassp40776.2020.9053619, 10.1109/ICASSP40776.2020.9053619]
   Wijeratne S., 2021, PROGRAMMABLE FPGA BA
   Xilinx, ALV U250 DAT CTR ACC
   Xilinx, ULTR ARCH FPGAS MEM
   Zhang R., HARDWARE IMPLEMENTAT
   Zhang RZ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286199
NR 30
TC 1
Z9 1
U1 1
U2 1
PY 2021
DI 10.1109/HPEC49654.2021.9622851
UT WOS:000766311400067
DA 2023-11-16
ER

PT J
AU Ullah, S
   Rehman, S
   Shafique, M
   Kumar, A
AF Ullah, Salim
   Rehman, Semeen
   Shafique, Muhammad
   Kumar, Akash
TI High-Performance Accurate and Approximate Multipliers for FPGA-Based
   Hardware Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Field programmable gate arrays; Table lookup; Delays; Computer
   architecture; Performance gain; IP networks; Reed-Solomon codes;
   Accelerators; approximate computing; high performance; multipliers;
   neural networks; reduced area
ID DESIGN; POWER
AB Multiplication is one of the widely used arithmetic operations in a variety of applications, such as image/video processing and machine learning. FPGA vendors provide high-performance multipliers in the form of DSP blocks. These multipliers are not only limited in number and have fixed locations on FPGAs but can also create additional routing delays and may prove inefficient for smaller bit-width multiplications. Therefore, FPGA vendors additionally provide optimized soft IP cores for multiplication. However, in this work, we advocate that these soft multiplier IP cores for FPGAs still need better designs to provide high-performance and resource efficiency. Toward this, we present generic area-optimized, low-latency accurate, and approximate softcore multiplier architectures, which exploit the underlying architectural features of FPGAs, i.e., lookup table (LUT) structures and fast-carry chains to reduce the overall critical path delay (CPD) and resource utilization of multipliers. Compared to Xilinx multiplier LogiCORE IP, our proposed unsigned and signed accurate architecture provides up to 25% and 53% reduction in LUT utilization, respectively, for different sizes of multipliers. Moreover, with our unsigned approximate multiplier architectures, a reduction of up to 51% in the CPD can be achieved with an insignificant loss in output accuracy when compared with the LogiCORE IP. For illustration, we have deployed the proposed multiplier architecture in accelerators used in image and video applications, and evaluated them for area and performance gains. Our library of accurate and approximate multipliers is opensource and available online at https://cfaed.tu-dresden.de/pd-downloads to fuel further research and development in this area, facilitate reproducible research, and thereby enabling a new research direction for the FPGA community.
C1 [Ullah, Salim; Kumar, Akash] Tech Univ Dresden, Chair Processor Design, D-01062 Dresden, Germany.
   [Rehman, Semeen] Tech Univ Wien, Inst Comp Technol, A-1040 Vienna, Austria.
   [Shafique, Muhammad] New York Univ Abu Dhabi, Div Engn, Abu Dhabi, U Arab Emirates.
RP Kumar, A (corresponding author), Tech Univ Dresden, Chair Processor Design, D-01062 Dresden, Germany.
EM salim.ullah@tu-dresden.de; semeen.rehman@tuwien.ac.at;
   muhammad.shafique@nyu.edu; akash.kumar@tu-dresden.de
CR [Anonymous], 2013, P 23 INT C FIELD PRO
   [Anonymous], 2017, VIVADO DESIGN SUITE
   [Anonymous], 2015, LOGICORE IP V12 0
   [Anonymous], 2016, MNIST CNN
   [Anonymous], 2019, SIPI IMAGE DATABASE
   [Anonymous], 2020, INTEGER ARITHMETIC I
   [Anonymous], 2016, 7 SERIES FPGAS CONFI
   [Anonymous], 2018, 7 SER DSP48E1 SLIC
   BAUGH CR, 1973, IEEE T COMPUT, VC 22, P1045, DOI 10.1109/T-C.1973.223648
   Beuchat JL, 2008, IEEE T COMPUT, V57, P1600, DOI 10.1109/TC.2008.102
   Bhardwaj K, 2015, INT SYM QUAL ELECT, P263
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   Brunie N., 2013, P 23 INT C FIELD PRO, P1
   Chippa VK, 2013, DES AUT CON
   Dadda L, 1965, ALTA FREQ, V34, P349
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Kahng AB, 2012, DES AUT CON, P820
   Kakacak A, 2017, INTEGRATION, V57, P147, DOI 10.1016/j.vlsi.2016.12.012
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kumm M, 2017, P S COMP ARITHM, P131, DOI 10.1109/ARITH.2017.35
   Kumm M, 2015, P S COMP ARITHM, P18, DOI 10.1109/ARITH.2015.17
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Lin CH, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P33, DOI 10.1109/ICCD.2013.6657022
   Liu C, 2014, DES AUT TEST EUROPE
   MILLER B, 1992, PROCEEDINGS OF THE 35TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P158, DOI 10.1109/MWSCAS.1992.271307
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mody J, 2015, PROCEEDINGS OF 2015 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Parandeh-Afshar H., 2011, 2011 International Conference on Field Programmable Logic and Applications, P225, DOI 10.1109/FPL.2011.48
   Parandeh-Afshar H, 2009, I C FIELD PROG LOGIC, P242, DOI 10.1109/FPL.2009.5272301
   Parhami B., 2010, COMPUTER ARITHMETIC
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Ullah S, 2021, IEEE EMBED SYST LETT, V13, P41, DOI 10.1109/LES.2020.2995053
   Ullah S, 2021, IEEE T COMPUT, V70, P384, DOI 10.1109/TC.2020.2988404
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3195996
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Verma AK, 2008, DES AUT TEST EUROPE, P1092
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Walters EG, 2016, COMPUTERS, V5, DOI 10.3390/computers5040020
   Zitzler E, 2007, LECT NOTES COMPUT SC, V4403, P862
NR 44
TC 13
Z9 13
U1 2
U2 9
PD FEB
PY 2022
VL 41
IS 2
BP 211
EP 224
DI 10.1109/TCAD.2021.3056337
UT WOS:000744531400005
DA 2023-11-16
ER

PT C
AU Ryan, J
   Okazaki, D
   Dallow, M
   Dezfouli, B
AF Ryan, John
   Okazaki, Daniel
   Dallow, Michael
   Dezfouli, Behnam
GP IEEE
TI NavSense: A Navigation Tool for Visually Impaired
SO 2019 IEEE GLOBAL HUMANITARIAN TECHNOLOGY CONFERENCE (GHTC)
SE IEEE Global Humanitarian Technology Conference Proceedings
DT Proceedings Paper
CT 9th Annual IEEE Global Humanitarian Technology Conference (IEEE GHTC)
CY OCT 17-20, 2019
CL IEEE Reg 6, Seattle Sect, Seattle, WA
HO IEEE Reg 6, Seattle Sect
DE Blindness; Accessibility; Computer Vision; Machine Learning; Object
   Recognition; Image Classification
AB The visually impaired rely heavily on hearing and touching (with their cane) to navigate through life. These senses cannot make up for the loss of vision when identifying objects in the user's path. In this paper, we propose NavSense, an assistive device that supplements existing technology to improve navigation and peace of mind in day to day life. NavSense relies on range detection, computer vision, and hardware acceleration mechanisms to provide real-time object identification and context to the user through auditory feedback. In particular, we use four hardware platforms - Raspberry Pi 3 B+, Coral Accelerator, Coral Development Board, and Intel Neural Computer Stick - to compare the efficiency of object detection in terms of time and energy during setup and inference phases. Based on these results, it is possible to tailor the design for specific energy accuracy requirements. Also, we have implemented and used NavSense in real-world scenarios to show its effectiveness.
C1 [Ryan, John; Okazaki, Daniel; Dallow, Michael; Dezfouli, Behnam] Santa Clara Univ, Dept Comp Sci & Engn, Santa Clara, CA 95053 USA.
RP Ryan, J (corresponding author), Santa Clara Univ, Dept Comp Sci & Engn, Santa Clara, CA 95053 USA.
EM jcryan@scu.edu; dtokazaki@scu.edu; mdallow@scu.edu; bdezfouli@scu.edu
CR Amirtharaj I., 2018, J AMB INTEL HUM COMP, P1
   [Anonymous], 2019, GETTING STARTED ULTR
   [Anonymous], YOLO REAL TIME OBJEC
   [Anonymous], 2018, OPENCV LIB
   [Anonymous], 2018, INTEL NEURAL COMPUTE
   [Anonymous], 2018, VIS IMP BLINDN
   [Anonymous], 2018, INTEL DISTRIBUTION O
   [Anonymous], 2019, YOLO VS SSD DEEP LEA
   chuanqi305, 2018, MOBILENETV2 SSDLITE
   Dezfouli B., 2018, J NETW COMPUT APPL, V121
   Elmannai W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030565
   Hollemans M., MOBILENET VERSION 2
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Magid S. A., 2019, ARXIV190211119
   Manduchi R., 2011, RES PRACTICE VISUAL, V4, P1
   RapidWareTech, 2016, RAPIDWARETECH PYTTSX
   Thorne B., 2009, PYTHON PAPERS MONOGR, V1
   Torres R. Mastachi, 2018, COMMUNICATION
   Xilinx, 2019, XIL BNN PYNQ
   Xilinx, 2018, XIL QNN MO PYNQ
   Xilinx, 2019, XIL FINN
   Xilinx, 2019, XIL PYNQ COMP VIS
NR 22
TC 1
Z9 1
U1 0
U2 1
PY 2019
BP 71
EP 78
DI 10.1109/ghtc46095.2019.9033125
UT WOS:000568648200013
DA 2023-11-16
ER

PT C
AU Anwar, A
   Raychowdhury, A
   Hatcher, R
   Rakshit, T
AF Anwar, Aqeel
   Raychowdhury, Arijit
   Hatcher, Ryan
   Rakshit, Titash
GP IEEE
TI XBAROPT - Enabling ultra-pipelined, novel STT MRAM based
   processing-in-memory DNN accelerator
SO 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   CIRCUITS AND SYSTEMS (AICAS 2020)
DT Proceedings Paper
CT 2nd IEEE International Conference on Artificial Intelligence Circuits
   and Systems (AICAS)
CY AUG 31-SEP 04, 2020
CL ELECTR NETWORK
AB An explosion in big data driven machine learning (ML) applications in conjunction with a severe slowdown of Moore's Law are prompting the search for alternative application-specific hardware fabrics. With its focus on bringing the compute inside memory bitcells, processing-in-memory (PIM) has been proposed to accelerate ML inference applications. In this paper, we present a modular, end-to-end simulation framework that is required to find a power-performance optimized solution for PIM based architectures for a given application. Our simulation framework encompasses multiple levels of hierarchies including device bitcell, array, memory hierarchy, dataflow, data re-use and algorithm-to-system mapping. Novel concepts at two levels of the hierarchy are introduced and evaluated: 1. Logic embeddable, high Ion/Ioff Magnetic Tunnel Junction (MTJ) bitcell and 2. Cycle accurate inter and intra layer pipelined operation for high performance and low power operations. Results are compared to pure digital custom ASIC implementation showing orders of magnitude improvements in power-performance on widely accepted MLPerf benchmarks.
C1 [Anwar, Aqeel; Raychowdhury, Arijit] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Hatcher, Ryan; Rakshit, Titash] Samsung Semicond Inc, San Jose, CA USA.
RP Anwar, A (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
CR Jain K. R. A. R. Shubham, 2019, ARXIV PREPRINT ARXIV
   Jiang ZZ, 2016, IEEE T ELECTRON DEV, V63, P1884, DOI 10.1109/TED.2016.2545412
   Lee YK, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P181, DOI 10.1109/VLSIT.2018.8510623
   Liu XX, 2015, DES AUT CON, DOI 10.1145/2744769.2744900
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Noguchi H., 2013, S VLSI CIRCUITS, pC108
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Samajdar A., 2018, COMPUTING RES REPOSI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Taha TM, 2013, IEEE IJCNN
   Yakopcic C, 2013, IEEE IJCNN
   Yongtae Kim, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P328, DOI 10.1109/SOCC.2012.6398336
NR 13
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 36
EP 40
DI 10.1109/aicas48895.2020.9073792
UT WOS:000720328700008
DA 2023-11-16
ER

PT C
AU Lou, WQ
   Wang, C
   Gong, L
   Zhou, XH
AF Lou, Wenqi
   Wang, Chao
   Gong, Lei
   Zhou, Xuehai
BE Yew, PC
   Stenstrom, P
   Wu, J
   Gong, X
   Li, T
TI RV-CNN: Flexible and Efficient Instruction Set for CNNs Based on RISC-V
   Processors
SO ADVANCED PARALLEL PROCESSING TECHNOLOGIES (APPT 2019)
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 13th International Symposium on Advanced Parallel Processing
   Technologies (APPT)
CY AUG 15-16, 2019
CL Tianjin, PEOPLES R CHINA
DE CNN; RISC-V; Domain-specific instructions; FPGA
AB Convolutional Neural Network (CNN) has gained significant attention in the field of machine learning, particularly due to its high accuracy in character recognition and image classification. Nevertheless, due to the computation-intensive and memory-intensive character of CNN, general-purpose processors which usually need to support various workloads are not efficient for CNN implementation. Therefore, a great deal of emerging CNN-specific hardware accelerators is able to improve efficiency. Although existing accelerators are significantly efficient, they are often inflexible or require complex controllers to handle calculations and data transfer. In this paper, we analyze classical CNN applications and design a domain-specific instruction set of 9 matrix instructions, called RV-CNN, based on the promising RISC-V architecture. By abstracting CNN into instructions, our design possesses a higher code density and provides sufficient flexibility and efficiency for CNN than general-purpose ISAs. Specifically, the proposed instructions are extended to RISC-V ISA as custom instructions. Besides, we also introduce micro-architectural optimizations to increase computational density and reduce the required memory bandwidth. Finally, we implement the architecture with the extended ISA and evaluate it with LeNet-5 on the datasets (MNIST, Caltech101, and Cifar-10). Results show that compared with the Intel Core i7 processor and Tesla k40c GPU, our design has 36.09x and 11.42x energy efficiency ratio and 6.70x and 1.25x code density respectively.
C1 [Lou, Wenqi; Wang, Chao; Gong, Lei; Zhou, Xuehai] Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
RP Lou, WQ (corresponding author), Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
EM louwenqi@mail.ustc.edu.cn; cswang@ustc.edu.cn;
   leigong0203@mail.ustc.edu.cn; xhzhou@ustc.edu.cn
CR Banakar R., 2002, INT S HARDW SOFTW CO
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Conti F, 2016, J SIGNAL PROCESS SYS, V84, P339, DOI 10.1007/s11265-015-1070-9
   Flamand E, 2018, IEEE INT CONF ASAP, P69
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gong L, 2018, IEEE T COMPUT AID D, V37, P2601, DOI 10.1109/TCAD.2018.2857078
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   Simonyan K., 2015, ARXIV
   Sun Y., 2014, NEURIPS, P1988
   Wang C, 2017, IEEE T PARALL DISTR, V28, P2993, DOI 10.1109/TPDS.2017.2701828
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 17
TC 6
Z9 6
U1 0
U2 17
PY 2019
VL 11719
BP 3
EP 14
DI 10.1007/978-3-030-29611-7_1
UT WOS:000612917100001
DA 2023-11-16
ER

PT J
AU Tortorella, Y
   Bertaccini, L
   Benini, L
   Rossi, D
   Conti, F
AF Tortorella, Yvan
   Bertaccini, Luca
   Benini, Luca
   Rossi, Davide
   Conti, Francesco
TI RedMule: A mixed-precision matrix-matrix operation engine for flexible
   and energy-efficient on-chip linear algebra and TinyML training
   acceleration
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
DT Article
DE General Matrix-Matrix Multiplication; General Matrix-Matrix Operations;
   Hardware accelerator; Embedded-systems; Online-learning; TinyML
ID HIGH-PERFORMANCE; ARCHITECTURE; FRAMEWORK
AB The increasing interest in TinyML, i.e., near-sensor machine learning on power budgets of a few tens of mW, is currently pushing toward enabling TinyML-class training as opposed to inference only. Current training algorithms, based on various forms of error and gradient backpropagation, rely on floatingpoint matrix operations to meet the precision and dynamic range requirements. So far, the energy and power cost of these operations has been considered too high for TinyML scenarios. This paper addresses the open challenge of near-sensor training on a few mW power budget and presents RedMulE - Reduced-Precision Matrix Multiplication Engine, a low-power specialized accelerator conceived for multi-precision floating-point General Matrix-Matrix Operations (GEMM-Ops) acceleration, supporting FP16, as well as hybrid FP8 formats, with {sign, exponent, mantissa} = ({1, 4, 3}, {1, 5, 2}). We integrate RedMule into a Parallel Ultra-Low-Power (PULP) cluster containing eight energy-efficient RISC-V cores sharing a tightly-coupled data memory and implement the resulting system in a 22 nm technology. At its best efficiency point (@ 470 MHz, 0.65 V), the RedMulE-augmented PULP cluster achieves 755 GFLOPS/W and 920 GFLOPS/W during regular General Matrix-Matrix Multiplication (GEMM), and up to 1.19 TFLOPS/W and 1.67 TFLOPS/W when executing GEMM-Ops, respectively, for FP16 and FP8 input/output tensors. In its best performance point (@ 613 MHz, 0.8 V), RedMulE achieves up to 58.5 GFLOPS and 117 GFLOPS for FP16 and FP8, respectively, with 99.4% utilization of the array of Computing Elements and consuming less than 60 mW on average, thus enabling on-device training of deep learning models in TinyML application scenarios while retaining the flexibility to tackle other classes of common linear algebra problems efficiently.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Tortorella, Yvan; Benini, Luca; Rossi, Davide; Conti, Francesco] Univ Bologna, Bologna, Italy.
   [Bertaccini, Luca; Benini, Luca] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Tortorella, Y (corresponding author), Univ Bologna, Bologna, Italy.
EM yvan.tortorella@unibo.it; lbertaccini@iis.ee.ethz.ch;
   lbenini@iis.ee.ethz.ch; davide.rossi@unibo.it; f.conti@unibo.it
CR Agrawal A, 2021, ISSCC DIG TECH PAP I, V64, P144, DOI 10.1109/ISSCC42613.2021.9365791
   Aleskog C, 2022, ALGORITHMS, V15, DOI 10.3390/a15110419
   Anders M, 2018, SYMP VLSI CIRCUITS, P39, DOI 10.1109/VLSIC.2018.8502333
   Banbury C, 2021, arXiv
   Bertaccini L, 2022, P S COMP ARITHM, P1, DOI 10.1109/ARITH54963.2022.00010
   Bian HD, 2021, FUTURE GENER COMP SY, V116, P371, DOI 10.1016/j.future.2020.10.036
   Burrello A, 2021, I SYMPOS LOW POWER E, DOI 10.1109/ISLPED52811.2021.9502494
   Cioflan C, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC ERA, P82, DOI 10.1109/AICAS54282.2022.9869990
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Fox S., 2021, INT C LEARNING REPRE
   Frenkel C, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.629892
   Garofalo Angelo, 2022, IEEE Open Journal of the Solid-State Circuits Society, V2, P231, DOI 10.1109/OJSSCS.2022.3210082
   Gilbert JR, 2008, COMPUT SCI ENG, V10, P20, DOI 10.1109/MCSE.2008.45
   Gilbert JR, 2007, LECT NOTES COMPUT SC, V4699, P260
   Gonzalez A, 2021, PROC EUR SOLID-STATE, P259, DOI 10.1109/ESSCIRC53450.2021.9567768
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo J, 2022, IEEE J SOLID-ST CIRC, DOI 10.1109/JSSC.2022.3220195
   Houshmand Pouya, 2023, IEEE Journal of Solid-State Circuits, P203, DOI 10.1109/JSSC.2022.3214064
   Jin Y, 2021, FUTURE GENER COMP SY, V125, P908, DOI 10.1016/j.future.2021.07.010
   Kim S, 2022, IEEE T CIRCUITS-I, V69, P1494, DOI 10.1109/TCSI.2021.3138092
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Mach S, 2021, IEEE T VLSI SYST, V29, P774, DOI 10.1109/TVLSI.2020.3044752
   Mazumder AN, 2021, IEEE J EM SEL TOP C, V11, P532, DOI 10.1109/JETCAS.2021.3129415
   Mehrooz G., 2020, INT C GEOGRAPHICAL I
   Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433
   Mohri M., 2002, Journal of Automata, Languages and Combinatorics, V7, P321
   Nadalini D, 2022, LECT NOTES COMPUT SC, V13511, P200, DOI 10.1007/978-3-031-15074-6_13
   Noune Badreddine., 2022, ARXIV
   NVIDIA, 2022, NVID H100 TENS COR G
   NVIDIA, 2021, TRAIN MIX PREC NVID
   Oh J, 2020, SYMP VLSI CIRCUITS, DOI 10.1109/vlsicircuits18222.2020.9162917
   Park J, 2022, IEEE J SOLID-ST CIRC, V57, P965, DOI 10.1109/JSSC.2021.3103603
   Pedram A, 2012, IEEE T COMPUT, V61, P1724, DOI 10.1109/TC.2012.132
   Ramanathan V., 2020, ONLINE ON DEVICE MCU
   Ravaglia L, 2021, IEEE J EM SEL TOP C, V11, P789, DOI 10.1109/JETCAS.2021.3121554
   Ravaglia L, 2020, IEEE WRK SIG PRO SYS, P53, DOI 10.1109/sips50750.2020.9195220
   Ren HY, 2021, Arxiv, DOI arXiv:2103.08295
   Reuther A, 2022, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC55821.2022.9926331
   Rodriguez Perez A.F., 2018, LOWER NUMERICAL PREC
   Rossi D, 2022, IEEE J SOLID-ST CIRC, V57, P127, DOI 10.1109/JSSC.2021.3114881
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Sedukhin SG, 2012, LECT NOTES COMPUT SC, V7203, P225, DOI 10.1007/978-3-642-31464-3_23
   Shin D, 2018, IEEE MICRO, V38, P85, DOI 10.1109/MM.2018.053631145
   Suk S., 1983, COMPUT VIS GRAPH IMA, P400, DOI [10.1016/0734-189X(84)90221-4, DOI 10.1016/0734-189X(84)90221-4]
   Sun X., 2019, HYBRID 8 BIT FLOATIN
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Tortorella Y, 2022, DES AUT TEST EUROPE, P1099, DOI 10.23919/DATE54114.2022.9774759
   Van Baalen M, 2023, Arxiv, DOI arXiv:2303.17951
   Venkataramani S, 2021, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA52012.2021.00021
   Wang Naigang, 2018, ARXIV181208011, P7686
   Wang Y, 2022, IEEE J SOLID-ST CIRC, V57, P3164, DOI 10.1109/JSSC.2022.3174411
   Zhang Y., 2022, ISCA 22 P 49 ANN INT
   Zhao YW, 2021, CONF PROC INT SYMP C, P706, DOI 10.1109/ISCA52012.2021.00061
   Zhou Z, 2019, P IEEE, V107, P1738, DOI 10.1109/JPROC.2019.2918951
NR 55
TC 0
Z9 0
U1 1
U2 1
PD DEC
PY 2023
VL 149
BP 122
EP 135
DI 10.1016/j.future.2023.07.002
EA JUL 2023
UT WOS:001050884000001
DA 2023-11-16
ER

PT J
AU Gao, C
   Xu, XF
   Yang, ZZ
   Lin, LW
   Li, J
AF Gao, Chi
   Xu, Xiaofei
   Yang, Zhizou
   Lin, Liwei
   Li, Jian
TI QZRAM: A Transparent Kernel Memory Compression System Design for
   Memory-Intensive Applications with QAT Accelerator Integration
SO APPLIED SCIENCES-BASEL
DT Article
DE memory compression; memory-intensive application; NLP; OOM; QAT
ID PERFORMANCE
AB In recent decades, memory-intensive applications have experienced a boom, e.g., machine learning, natural language processing (NLP), and big data analytics. Such applications often experience out-of-memory (OOM) errors, which cause unexpected processes to exit without warning, resulting in negative effects on a system's performance and stability. To mitigate OOM errors, many operating systems implement memory compression (e.g., Linux's ZRAM) to provide flexible and larger memory space. However, these schemes incur two problems: (1) high-compression algorithms consume significant CPU resources, which inevitably degrades application performance; and (2) compromised compression algorithms with low latency and low compression ratios result in insignificant increases in memory space. In this paper, we propose QZRAM, which achieves a high-compression-ratio algorithm without high computing consumption through the integration of QAT (an ASIC accelerator) into ZRAM. To enhance hardware and software collaboration, a page-based parallel write module is introduced to serve as a more efficient request processing flow. More importantly, a QAT offloading module is introduced to asynchronously offload compression to the QAT accelerator, reducing CPU computing resource consumption and addressing two challenges: long CPU idle time and low usage of the QAT unit. The comprehensive evaluation validates that QZRAM can reduce CPU resources by up to 49.2% for the FIO micro-benchmark, increase memory space (1.66x) compared to ZRAM, and alleviate the memory overflow phenomenon of the Redis benchmark.
C1 [Gao, Chi] Chengdu Aircraft Design Inst, Dept 15, Chengdu 610041, Peoples R China.
   [Xu, Xiaofei] China Aeronaut Radio Elect Res Inst, Elect Dept, Shanghai 200233, Peoples R China.
   [Yang, Zhizou; Li, Jian] Shanghai Jiao Tong Univ, Shanghai Key Lab Scalable Comp & Syst, Shanghai 200240, Peoples R China.
   [Lin, Liwei] Fujian Key Lab Big Data Min & Applicat, Fuzhou 350118, Peoples R China.
   [Lin, Liwei] Fujian Univ Technol, Sch Comp Sci & Math, Fuzhou 350118, Peoples R China.
RP Li, J (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Scalable Comp & Syst, Shanghai 200240, Peoples R China.
EM li-jian@sjtu.edu.cn
CR Abel D.I.J., 2020, CALGARY CORPUS
   Burrows M., 1994, P DIG SRC RES REP CI
   Choi H, 2021, INT C PATT RECOG, P5482, DOI 10.1109/ICPR48806.2021.9412102
   Collet Y., 2016, FACEBOOK CODE, V1
   Collet Y., 2020, LZ4 COMPRESSION ALGO
   Eddelbuettel D, 2022, Arxiv, DOI arXiv:2203.06559
   Ekman M, 2005, CONF PROC INT SYMP C, P74, DOI 10.1109/ISCA.2005.6
   Gupta N., 2020, ZRAM PROJECT LINUX F
   Harnik D, 2014, IEEE DATA COMPR CONF, P223, DOI 10.1109/DCC.2014.66
   Hu XK, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P163
   Intel Intel® QAT, 2022, INT QAT PERF SCAL EF
   Jennings S., 2013, ZSWAP COMPRESSED SWA
   kernel.org, 2009, ZPOOL
   Kim S, 2017, INT CONFER PARA, P206, DOI 10.1109/PACT.2017.12
   Kuon I, 2007, FOUND TRENDS ELECTRO, V2, P135, DOI 10.1561/1000000005
   Lee S, 2011, IEEE T CONSUM ELECTR, V57, P1732, DOI 10.1109/TCE.2011.6131148
   Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Oberhumer M., 2013, DATA COMPRESSION LIB
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Panwar G, 2022, INT SYMP MICROARCH, P992, DOI 10.1109/MICRO56248.2022.00073
   Park S, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P52, DOI 10.1145/3445814.3446722
   Pekhimnko Gennady, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P172, DOI 10.1145/2540708.2540724
   Plauth M., 2018, P 2018 6 INT S COMP
   Qian C., 2018, P 15 ACM INT C COMP, P121
   Sanchez D., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P187, DOI 10.1109/MICRO.2010.20
   Siddiq ML, 2022, 2022 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED SOFTWARE ENGINEERING (NLBSE 2022), P33, DOI 10.1145/3528588.3528660
   Smith M.J.S., 1997, APPL SPECIFIC INTEGR, VVolume 7
   Tremaine RB, 2001, IBM J RES DEV, V45, P271, DOI 10.1147/rd.452.0271
   Zhao JS, 2015, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2808233
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 31
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 13
IS 18
AR 10526
DI 10.3390/app131810526
UT WOS:001076946200001
DA 2023-11-16
ER

PT C
AU Plagwitz, P
   Hannig, F
   Ströbel, M
   Strohmeyer, C
   Teich, J
AF Plagwitz, Patrick
   Hannig, Frank
   Stroebel, Martin
   Strohmeyer, Christoph
   Teich, Juergen
GP IEEE Comp Soc
TI A Safari through FPGA-based Neural Network Compilation and Design
   Automation Flows
SO 2021 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2021)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 29th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 09-12, 2021
CL ELECTR NETWORK
ID LANGUAGE; COMPILER
AB Thanks to the enormous computing power of GPUs, Machine Learning (ML) based on artificial neural networks has found its way into many important application fields. Sophisticated compiler infrastructures facilitate the task of mapping neural networks onto these accelerators. Recently, new developments have also led to compilation and design automation flows that target FPGA-based accelerators. Although not being as mature as their GPU counterparts, there exists a multitude of published and actively developed approaches with differing support levels for network classes, file formats, and target platforms. Neural network exchange file formats advance jointly with the modeling frameworks. In this paper, we take a quick safari through the jungle of neural network compilation flows for FPGA-based targets by reporting qualitative and quantitative metrics. For comparison, we study the classes of supported neural network architectures of each approach, and the corresponding compatibility of exchange formats, emphasizing ONNX, by examining available conversion tools. Besides, we look at several non-functional properties, including FPGA resource utilization and performance numbers for selected neural networks, but also soft criteria such as licensing, community support, and development activity. Finally, we also assess and discuss some deficiencies currently still affecting some approaches. We hope that our study supports interested readers to orient themselves in the jungle of available flows concerning both functionality and usability, as well as to guide further development and research activities in the endeavor of automated ML acceleration on FPGAs.
C1 [Plagwitz, Patrick; Hannig, Frank; Teich, Juergen] Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Comp Sci, Erlangen, Germany.
   [Stroebel, Martin; Strohmeyer, Christoph] Schaeffler Technol AG & Co KG, Herzogenaurach, Germany.
RP Plagwitz, P (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Comp Sci, Erlangen, Germany.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   [Anonymous], 2016, DOREFANET TRAINING L
   [Anonymous], ZYNQ 7000 SOC
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   FINN, VERS AF783DB8D COMM
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Lattice Semiconductor, ICE40 LP HX LM LOW P
   Lattice Semiconductor, LATT SENSAI STACK
   Lemieux G. G. F., 2019, COMPUTING RES REPOSI
   Li ZS, 2017, IEEE INT SYMP PARAL, P143, DOI 10.1109/ISPA/IUCC.2017.00030
   MathWorks, HDLCODER
   MathWorks, DEEP LEARN PROC IP C
   Membarth R, 2016, IEEE T PARALL DISTR, V27, P210, DOI 10.1109/TPDS.2015.2394802
   Moreau T., 2019, COMPUTING RES REPOSI
   Paszke A, 2019, ADV NEUR IN, V32
   Petrica L, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P48, DOI 10.1109/ICFPT51103.2020.00016
   Plagwitz P, 2019, 2019 INT C RECONFIGU, P1, DOI [10. 1109 / ReConFig48160.2019.8994778, DOI 10.1109/RECONFIG48160.2019.8994778]
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767
   Reiche O, 2017, ICCAD-IEEE ACM INT, P1026, DOI 10.1109/ICCAD.2017.8203894
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Seo M., 2016, COMPUTING RES REPOSI
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Simons T, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060661
   Simonyan K., 2015, VERY DEEP CONVOLUTIO, V1, P3
   Streit F, 2020, PROD ENG-RES DEV, V14, P365, DOI 10.1007/s11740-020-00964-x
   Symbiotic EDA, MARLANN SIMPL FPGA M
   The Linux Foundation, OP NEUR NETW EXCH ON
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Xilinx, GETT START FINN DOC
   xilinx, VITIS
   Xilinx, VIT AI MOD ZOO
   Xing Y, 2020, IEEE T COMPUT AID D, V39, P2668, DOI 10.1109/TCAD.2019.2930577
   Xu JW, 2018, MICROPROCESS MICROSY, V60, P196, DOI 10.1016/j.micpro.2018.03.007
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 41
TC 7
Z9 7
U1 1
U2 1
PY 2021
BP 10
EP 19
DI 10.1109/FCCM51124.2021.00010
UT WOS:000681289100002
DA 2023-11-16
ER

PT J
AU Abeed, MA
   Bandyopadhyay, S
AF Abeed, Md. Ahsanul
   Bandyopadhyay, Supriyo
TI Low Energy Barrier Nanomagnet Design for Binary Stochastic Neurons:
   Design Challenges for Real Nanomagnets With Fabrication Defects
SO IEEE MAGNETICS LETTERS
DT Article
DE Spin electronics; low energy barrier magnets; binary stochastic neurons;
   correlation time; pinning currents; effect of defects
AB Much attention has been focused on the design of low energy barrier nanomagnets (LBMs), whose magnetizations vary randomly in time owing to thermal noise, for use in binary stochastic neurons (BSNs) that serve as hardware accelerators for machine learning. The performance of BSNs depends on two important parameters: the correlation time tau(c) associated with the random magnetization dynamics in an LBM, and the spin-polarized pinning current I-p, which stabilizes the magnetization of an LBM in a chosen direction within a chosen time. We show that common fabrication defects in LBMs make these two parameters unpredictable because they are strongly sensitive to the defects. That makes the design of BSNs with real LBMs very challenging. Unless the LBMs are fabricated with extremely tight control, the BSNs that use them could be unreliable or suffer from poor yield.
C1 [Abeed, Md. Ahsanul; Bandyopadhyay, Supriyo] Virginia Commonwealth Univ, Dept Elect & Comp Engn, Med Coll Virginia Campus, Richmond, VA 23284 USA.
RP Bandyopadhyay, S (corresponding author), Virginia Commonwealth Univ, Dept Elect & Comp Engn, Med Coll Virginia Campus, Richmond, VA 23284 USA.
EM sbandy@vcu.edu
CR Abeed MA, 2017, IEEE T ELECTRON DEV, V64, P2417, DOI 10.1109/TED.2017.2679604
   Ahmad H, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/40/401001
   [Anonymous], 1964, PHYS MAGNETISM
   Bass J, 2007, J PHYS-CONDENS MAT, V19, DOI 10.1088/0953-8984/19/18/183201
   Bautin VA, 2017, AIP ADV, V7, DOI 10.1063/1.4979889
   Bhanja S, 2016, NAT NANOTECHNOL, V11, P177, DOI [10.1038/nnano.2015.245, 10.1038/NNANO.2015.245]
   Biswas AK, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/28/285201
   Biswas AK, 2014, SCI REP-UK, V4, DOI 10.1038/srep07553
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Chakraborty I, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2839097
   D'Souza N, 2016, NANO LETT, V16, P1069, DOI 10.1021/acs.nanolett.5b04205
   D'Souza N, 2012, IEEE T NANOTECHNOL, V11, P896, DOI 10.1109/TNANO.2012.2204769
   Debashis P, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2860547
   Faria R, 2017, IEEE MAGN LETT, V8, DOI 10.1109/LMAG.2017.2685358
   Hassan O, 2019, IEEE MAGN LETT, V10, DOI 10.1109/LMAG.2019.2910787
   Khasanvis S, 2015, COMPUTER, V48, P54, DOI 10.1109/MC.2015.367
   Khasanvis S, 2015, IEEE T NANOTECHNOL, V14, P980, DOI 10.1109/TNANO.2015.2439618
   Liu LQ, 2012, SCIENCE, V336, P555, DOI 10.1126/science.1218197
   Mellnik AR, 2014, NATURE, V511, P449, DOI 10.1038/nature13534
   Miron IM, 2010, NAT MATER, V9, P230, DOI [10.1038/NMAT2613, 10.1038/nmat2613]
   Munira K, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/24/245202
   Nasrin S, 2019, IEEE ELECTR DEVICE L, V40, P345, DOI 10.1109/LED.2018.2889881
   Patil A. D., ARXIV170206119
   Pervaiz AZ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11011-8
   Ralph DC, 2008, J MAGN MAGN MATER, V320, P1190, DOI 10.1016/j.jmmm.2007.12.019
   Roy K, 2011, APPL PHYS LETT, V99, DOI 10.1063/1.3624900
   Roy U, 2016, IEEE T MAGN, V52, DOI 10.1109/TMAG.2016.2580532
   Sharad M, 2014, IEEE T NANOTECHNOL, V13, P23, DOI 10.1109/TNANO.2013.2286424
   Shiota Y, 2017, APPL PHYS LETT, V111, DOI 10.1063/1.4990680
   Shiota Y, 2009, APPL PHYS EXPRESS, V2, DOI 10.1143/APEX.2.063001
   Sutton B, 2017, SCI REP-UK, V7, DOI 10.1038/srep44370
   Vansteenkiste A, 2014, AIP ADV, V4, DOI 10.1063/1.4899186
   Winters D, 2019, ARXIV190509322
   Yamanouchi M, 2004, NATURE, V428, P539, DOI 10.1038/nature02441
NR 34
TC 20
Z9 20
U1 0
U2 11
PY 2019
VL 10
DI 10.1109/LMAG.2019.2929484
UT WOS:000560387800001
DA 2023-11-16
ER

PT J
AU Liu, LL
   Shen, LY
   Yang, Y
   Schüler, E
   Zhao, W
   Wetzstein, G
   Xing, L
AF Liu, Lianli
   Shen, Liyue
   Yang, Yong
   Schueler, Emil
   Zhao, Wei
   Wetzstein, Gordon
   Xing, Lei
TI Modeling linear accelerator (Linac) beam data by implicit neural
   representation learning for commissioning and quality assurance
   applications
SO MEDICAL PHYSICS
DT Article; Early Access
DE beam data modeling; Linac commissioning; machine learning; quality
   assurance
ID QUANTITATIVE-EVALUATION; DOSE CALCULATIONS; PHOTON; ORGANS; QA
AB BackgroundLinear accelerator (Linac) beam data commissioning and quality assurance (QA) play a vital role in accurate radiation treatment delivery and entail a large number of measurements using a variety of field sizes. How to optimize the effort in data acquisition while maintaining high quality of medical physics practice has been sought after. PurposeWe propose to model Linac beam data through implicit neural representation (NeRP) learning. The potential of the beam model in predicting beam data from sparse measurements and detecting data collection errors was evaluated, with the goal of using the beam model to verify beam data collection accuracy and simplify the commissioning and QA process. Materials and MethodsNeRP models with continuous and differentiable functions parameterized by multilayer perceptrons (MLPs) were used to represent various beam data including percentage depth dose (PDD) and profiles of 6 MV beams with and without flattening filter. Prior knowledge of the beam data was embedded into the MLP network by learning the NeRP of a vendor-provided "golden" beam dataset. The prior-embedded network was then trained to fit clinical beam data collected at one field size and used to predict beam data at other field sizes. We evaluated the prediction accuracy by comparing network-predicted beam data to water tank measurements collected from 14 clinical Linacs. Beam datasets with intentionally introduced errors were used to investigate the potential use of the NeRP model for beam data verification, by evaluating the model performance when trained with erroneous beam data samples. ResultsLinac beam data predicted by the model agreed well with water tank measurements, with averaged Gamma passing rates (1%/1 mm passing criteria) higher than 95% and averaged mean absolute errors less than 0.6%. Beam data samples with measurement errors were revealed by inconsistent beam predictions between networks trained with correct versus erroneous data samples, characterized by a Gamma passing rate lower than 90%. ConclusionA NeRP beam data modeling technique has been established for predicting beam characteristics from sparse measurements. The model provides a valuable tool to verify beam data collection accuracy and promises to simplify commissioning/QA processes by reducing the number of measurements without compromising the quality of medical physics service.
C1 [Liu, Lianli; Yang, Yong; Schueler, Emil; Zhao, Wei; Xing, Lei] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94304 USA.
   [Shen, Liyue; Wetzstein, Gordon; Xing, Lei] Stanford Univ, Dept Elect Engn, Palo Alto, CA 94304 USA.
RP Liu, LL (corresponding author), Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94304 USA.
EM llliu@stanford.edu; lei@stanford.edu
CR Beyer GP, 2013, J APPL CLIN MED PHYS, V14, P273, DOI 10.1120/jacmp.v14i1.4077
   Chan MF, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.577620
   Chen YB, 2021, PROC CVPR IEEE, P8624, DOI 10.1109/CVPR46437.2021.00852
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Das IJ, 2012, MED PHYS, V39, P569, DOI 10.1118/1.3658740
   Dupont E, 2021, Arxiv, DOI arXiv:2103.03123
   Dupont E, 2022, Arxiv, DOI [arXiv:2102.04776, 10.1016/j.lwt.2022.113600]
   Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170
   Fan JW, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba165
   Hrbacek J, 2007, MED PHYS, V34, P2917, DOI 10.1118/1.2745239
   Ibbott GS, 2008, INT J RADIAT ONCOL, V71, pS71, DOI 10.1016/j.ijrobp.2007.08.083
   Ibragimov B, 2017, MED PHYS, V44, P547, DOI 10.1002/mp.12045
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Liu LL, 2022, MED PHYS, V49, P6110, DOI 10.1002/mp.15822
   Liu LL, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac1f37
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Narayanasamy G, 2016, J APPL CLIN MED PHYS, V17, P179, DOI 10.1120/jacmp.v17i1.5799
   Netherton T, 2019, MED PHYS, V46, P4304, DOI 10.1002/mp.13723
   Qureshi AH, 2021, Arxiv, DOI arXiv:2106.01352
   Shen LY, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3177134
   Shen LY, 2019, NAT BIOMED ENG, V3, P880, DOI 10.1038/s41551-019-0466-4
   Shen Tianchang, 2021, ADV NEURAL INFORM PR, P2
   Sitzmann V, 2019, ADV NEUR IN, V32
   Sitzmann Vincent, 2020, ADV NEURAL INFORM PR, V33, P7462, DOI [DOI 10.1109/WACV51458.2022.00234, DOI 10.5555/3495724.3496350]
   Smilowitz JB, 2015, J APPL CLIN MED PHYS, V16, P14, DOI 10.1120/jacmp.v16i5.5768
   Song Y, 2020, RADIOTHER ONCOL, V145, P186, DOI 10.1016/j.radonc.2020.01.020
   Tancik M., 2020, NEURIPS, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Vasudevan V, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac6b10
   Venselaar J, 2001, RADIOTHER ONCOL, V60, P191, DOI 10.1016/S0167-8140(01)00377-2
   Zhao W, 2020, RADIOTHER ONCOL, V153, P122, DOI 10.1016/j.radonc.2020.09.057
   Zhao W, 2019, INT J RADIAT ONCOL, V105, P432, DOI 10.1016/j.ijrobp.2019.05.071
NR 32
TC 0
Z9 0
U1 2
U2 8
PD 2023 JAN 14
PY 2023
DI 10.1002/mp.16212
EA JAN 2023
UT WOS:000915128600001
DA 2023-11-16
ER

PT J
AU Al Badawi, A
   Veeravalli, B
   Aung, KMM
   Hamadicharef, B
AF Al Badawi, Ahmad
   Veeravalli, Bharadwaj
   Aung, Khin Mi Mi
   Hamadicharef, Brahim
TI Accelerating subset sum and lattice based public-key cryptosystems with
   multi-core CPUs and GPUs
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article
DE Lattice cryptography; Post-quantum cryptography; Public-key
   cryptosystem; Subset sum; Learning with errors; GPGPU programming;
   Parallel polynomial multiplier
AB Post-quantum cryptosystems based on subset sum and lattice problems have gained much attention from researchers due to their simple construction, their resistance to quantum attacks, the new potential applications they provide, and above all, the mathematical security proofs that rigorously relate them to computational hard problems. However, the computational complexity of these cryptosystems is still high compared to classic number-theoretical ones, which may impede their adoption on a large scale. We studied the performance of three public-key cryptosystems based on subset sum, learning with errors and ring learning with errors problems. We provide a systematic study for choosing their parameters to guarantee sufficient security levels and detail an asymptotic comparison between them in terms of storage and running time complexities. We accelerate the running time of these cryptosystems by exploiting the inherent parallelism in computations through a GPGPU-based parallel implementation. The cryptosystems are implemented using C++ on Intel(R) Xeon(R) multi-core 64-bit processors machine with CUDA-enabled Tesla K80 GPUs. The parallel implementation is based on OpenCL framework and can run on arbitrary hardware platform accelerators with minor changes. Several optimizations and efficient algorithms were used to compute the core operations in each cryptosystem to achieve optimum performance. The ring learning with errors based cryptosystem showed the best performance while the Subset Sum cryptosystem showed the highest speedup gain for the encryption primitive. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Al Badawi, Ahmad; Veeravalli, Bharadwaj] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
   [Al Badawi, Ahmad; Aung, Khin Mi Mi; Hamadicharef, Brahim] ASTAR, DSI, Connexis North Lobby 1 Fusionopolis Way, Singapore 138632, Singapore.
RP Al Badawi, A (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
EM ahmad@u.nus.edu; elebv@nus.edu.sg; mi_mi_aung@dsi.a-star.edu.sg;
   brahim-hamad@dsi.a-star.edu.sg
CR Aguilar-Melchor C, 2016, LECT NOTES COMPUT SC, V9610, P341, DOI 10.1007/978-3-319-29485-8_20
   Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Akavik A, 2009, LECT NOTES COMPUT SC, V5444, P474
   Albrecht MR, 2015, J MATH CRYPTOL, V9, P169, DOI 10.1515/jmc-2015-0016
   [Anonymous], 1996, POLYNOMIAL ALGORITHM, DOI DOI 10.1007/978-3-7091-6571-3
   [Anonymous], 2019, NIST SPECIAL PUBLICA, DOI DOI 10.6028/NIST.SP.800-57PT1R4
   [Anonymous], 2016, NAS LAUNCH QUANT COM
   [Anonymous], 2012, IEEE C HIGH PERFORMA, DOI [10.1109/HPEC.2012.6408660, DOI 10.1109/PEAM.2012.6612493]
   Baladron J, 2012, COMPUT SCI ENG, V14, P40, DOI 10.1109/MCSE.2011.119
   Bennett CH, 1997, SIAM J COMPUT, V26, P1510, DOI 10.1137/S0097539796300933
   Bernstein D. J., 2009, POSTQUANTUM CRYPTOGR, P1, DOI [DOI 10.1007/978-3-540-88702-7_1, 10.1007/978-3-540-88702-7, DOI 10.1007/978-3-540-88702-7]
   CHOR B, 1988, IEEE T INFORM THEORY, V34, P901, DOI 10.1109/18.21214
   Coster MJ, 1992, COMPUT COMPLEX, V2, P111, DOI DOI 10.1007/BF01201999
   Crandall R., 2006, PRIME NUMBERS COMPUT
   de Clercq R, 2015, DES AUT TEST EUROPE, P339
   Du CH, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P9, DOI 10.1145/2902961.2902969
   Garey M., 1979, COMPUTERS INTRACTABI
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Halderman JA, 2009, COMMUN ACM, V52, P91, DOI 10.1145/1506409.1506429
   Hallgren Sven, 2008, POSTQUANTUM CRYPTOGR, P15, DOI [10.1007/978-3-540-88702-7_2, DOI 10.1007/978-3-540-88702-7_2]
   Hamasho S, 2014, IEICE T FUND ELECTR, VE97A, P298, DOI 10.1587/transfun.E97.A.298
   Jain A, 2014, ADV INTELL SYST, V299, P375, DOI 10.1007/978-3-319-07995-0_37
   Laine K., 2015, IACR CRYPTOL, V2015, P176
   LENSTRA AK, 1982, MATH ANN, V261, P515, DOI 10.1007/BF01457454
   Lindner R., 2016, TU DARMSTADT LATTICE
   Liu Z, 2015, LECT NOTES COMPUT SC, V9293, P663, DOI 10.1007/978-3-662-48324-4_33
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Lyubashevsky V, 2013, LECT NOTES COMPUT SC, V7881, P35, DOI 10.1007/978-3-642-38348-9_3
   Lyubashevsky V, 2010, LECT NOTES COMPUT SC, V5978, P382, DOI 10.1007/978-3-642-11799-2_23
   Lyubashevsky V, 2009, LECT NOTES COMPUT SC, V5677, P577, DOI 10.1007/978-3-642-03356-8_34
   MERKLE RC, 1978, IEEE T INFORM THEORY, V24, P525, DOI 10.1109/TIT.1978.1055927
   Michalakes J, 2008, PARALLEL PROCESS LET, V18, P531, DOI 10.1142/S0129626408003557
   Mingjie Liu, 2013, Topics in Cryptology - CT-RSA 2013. The Cryptographers Track at the RSA Conference 2013. Proceedings, P293, DOI 10.1007/978-3-642-36095-4_19
   Poppelmann Thomas, 2012, Progress in Cryptology - LATINCRYPT 2012. Proceedings of the 2nd International Conference on Cryptology and Information Security in Latin America, P139, DOI 10.1007/978-3-642-33481-8_8
   Regev O., 2010, CCC
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Rehman T., 2011, OPENCL OPTIMIZATION
   Rupp K., 2012, GPU ACCELERATED NONN, P77
   SCHNORR CP, 1994, MATH PROGRAM, V66, P181, DOI 10.1007/BF01581144
   Shamir A., 1983, Advances in Cryptology, Proceedings of Crypto 82, P279
   Shor P. W., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), P124, DOI 10.1109/SFCS.1994.365700
   Shoup V., 2009, COMPUTATIONAL INTRO, DOI [10.1017/CB0978051181, DOI 10.1017/CB0978051181]
   Shoup V., 2001, NTL LIB DOING NUMBER
   Vaudenay S, 1998, LECT NOTES COMPUT SC, V1462, P243, DOI 10.1007/BFb0055732
   Walter J., 2002, UBLAS BOOST BASIC LI
NR 45
TC 4
Z9 4
U1 0
U2 8
PD SEP
PY 2018
VL 119
BP 179
EP 190
DI 10.1016/j.jpdc.2018.04.014
UT WOS:000435425500015
DA 2023-11-16
ER

PT C
AU Park, YR
   Kim, JH
   Do, J
   Kim, JY
AF Park, Yeo-Reum
   Kim, Ji-Hoon
   Do, Jaeyoung
   Kim, Joo-Young
GP IEEE
TI A Dual-Mode Similarity Search Accelerator based on Embedding Compression
   for Online Cross-Modal Image-Text Retrieval
SO 2022 IEEE 30TH INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM
   COMPUTING MACHINES (FCCM 2022)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT IEEE 30th International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 15-18, 2022
CL New York, NY
AB Image-text retrieval (ITR) that identifies the relevant images for a given text query, or vice versa, is the fundamental task in emerging vision-and-language machine learning applications. Recently, the cross-modal approach that extracts image and text features in separate reasoning pipelines but performs the similarity search on the same embedding representation is proposed for the real-time ITR system. However, the similarity search that finds the most relevant data in huge data embeddings for a given query becomes the bottleneck of the ITR system. In this paper, we propose a dual-mode similarity search accelerator that can solve the computational hurdle for online image-to-text and text-to-image retrieval service. We propose an embedding compression scheme that removes the sparsity in the text embeddings, further eliminating the time-consuming masking operations in the later processing pipeline. Combining with the data quantization from 32-bit floating-point to 8bit integer, we reduce the target dataset size by 95.1% with less than 0.1% accuracy loss for 1024-dimensional embedding features. In addition, we propose a streamlined similarity search data flow for both query types, which minimizes the required memory bandwidth with maximal data reuse. The query and data embeddings are guaranteed to be fetched only once from the external memory with the optimized data flow. Based on the proposed data representation and flow, we design a scalable similarity search accelerator that includes multiple ITR kernels. Each ITR kernel has modular design, composed of a separate memory access module and a computing module. The computing module supports pipelined operations of the four similarity search tasks: dot product calculation, data reordering, partial score aggregation, and ranking. We double the number of processing operations in the computing module with the DSP packing technique. Finally, we implement the proposed accelerator with six ITR kernels on the Xilinx Alveo U280 FPGA card. It shows 2.98 tera operations per second (TOPS) performance at 186 MHz, achieving 526/144 and 1163/306 queries per second (QPS) performance for image-to-text and text-to-image retrieval on MS-COCO 1K/5K benchmark. It is up to 359.0x and 13.9x faster and 503.6x and 68.7x more energy-efficient than the baseline and optimized GPU implementation on Nvidia Titan RTX, respectively.
C1 [Park, Yeo-Reum; Kim, Ji-Hoon; Kim, Joo-Young] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daegeon, South Korea.
   [Do, Jaeyoung] Amazon Alexa AI, Kirkland, WA 98033 USA.
RP Park, YR (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daegeon, South Korea.
EM summerpark@kaist.ac.kr; jihoon0708@kaist.ac.kr; domjae@amazon.com;
   jooyoung1203@kaist.ac.kr
CR Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   DeMicheli G, 1997, P IEEE, V85, P349, DOI 10.1109/5.558708
   Devlin J., 2018, ARXIV, DOI 10.18653/v1/N19-1423
   Google, GOOGL IM
   Guo KY, 2016, IEEE HOT CHIP SYMP
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Li Xiujun, 2020, EUR C COMP VIS, P121
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520
   Lu Jiasen, 2019, ARXIV
   Messina, 2020, TERAN
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Messina N, 2021, INT C PATT RECOG, P5222, DOI 10.1109/ICPR48806.2021.9413172
   Microsoft, BING IM TREND
   Monmasson E, 2007, IEEE T IND ELECTRON, V54, P1824, DOI 10.1109/TIE.2007.898281
   Paszke A, 2019, ADV NEUR IN, V32
   Qi D., 2020, ARXIV
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Teich J, 2012, P IEEE, V100, P1411, DOI 10.1109/JPROC.2011.2182009
   Vaswani A, 2017, ADV NEUR IN, V30
   Xilinx, 2017, DEEP LEARN INT8 OPT
   Yang YF, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P23, DOI 10.1145/3289602.3293902
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
NR 28
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 99
EP 107
DI 10.1109/FCCM53951.2022.9786159
UT WOS:000856347400012
DA 2023-11-16
ER

PT C
AU Ibrahim, KZ
   Nguyen, T
   Nam, HA
   Bhimji, W
   Farrell, S
   Oliker, L
   Rowan, M
   Wright, NJ
   Williams, S
AF Ibrahim, Khaled Z.
   Tan Nguyen
   Hai Ah Nam
   Bhimji, Wahid
   Farrell, Steven
   Oliker, Leonid
   Rowan, Michael
   Wright, Nicholas J.
   Williams, Samuel
GP IEEE Comp Soc
TI Architectural Requirements for Deep Learning Workloads in HPC
   Environments
SO PROCEEDINGS OF PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH
   PERFORMANCE COMPUTER SYSTEMS (PMBS 2021)
DT Proceedings Paper
CT 12th International Workshop on Performance Modeling, Benchmarking and
   Simulation of High Performance Computer Systems held as part of the 33rd
   ACM/IEEE International Conference for High Performance Computing,
   Networking, Storage and Analysis
CY NOV 14-19, 2021
CL St Louis, MO
AB Scientific machine learning (SciML) promises to have a transformational impact on scientific exploration, by combining state-of-the-art AI methods with the latest generation of supercomputers. However, to efficiently leverage ML techniques on high-performance computing (HPC) systems, it is critical to understand the performance characteristics of the underlying algorithms on modern computational systems. In this work, we present a new methodology for developing a detailed performance understanding of ML benchmarks. To demonstrate our approach we investigate two emerging SciML benchmark applications from cosmology and climate, ComsoFlow and DeepCAM, as well as ResNet-50, a well-known image classification model. We develop and validate performance models that explore the key architectural artifacts, including memory requirements, data reuse, and performance efficiency across both single- and multiple-GPU computations. Our methodology also focuses on the complexity of data-movement across storage and memory hierarchies, and leverages our performance models to capture key components of runtime execution while highlighting design tradeoffs. Although our work focuses on image-processing methods on GPU-based HPC systems, our approach is applicable to a variety of ML algorithmic domains and emerging AI accelerators. Overall, our insights will help computer architects and data scientists understand performance bottlenecks and optimization opportunities to improve SciML design and system efficiency.
C1 [Ibrahim, Khaled Z.; Tan Nguyen; Hai Ah Nam; Bhimji, Wahid; Farrell, Steven; Oliker, Leonid; Rowan, Michael; Wright, Nicholas J.; Williams, Samuel] Lawrence Berkeley Natl Lab, NERSC CRD, Berkeley, CA 94720 USA.
RP Ibrahim, KZ (corresponding author), Lawrence Berkeley Natl Lab, NERSC CRD, Berkeley, CA 94720 USA.
CR Adolf R, 2016, I S WORKL CHAR PROC, P148
   [Anonymous], 1995, LOGGP INCORPORATING
   [Anonymous], 2021, HYPERION RES
   [Anonymous], 2020, MLSYS
   Baker Nathan, 2019, WORKSH REP BAS RES N, V2
   Ben-Nun T, 2019, INT PARALL DISTRIB P, P66, DOI 10.1109/IPDPS.2019.00018
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Cordery M., 2013, PMBS SC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dongarra J., HPL AI MIXED PRECISI, P2021
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang Z., 2020, HPC AI500 METHODOLOG
   Kurth T, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Li C, 2020, INT PARALL DISTRIB P, P326, DOI 10.1109/IPDPS47924.2020.00042
   Mathuriya A, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Patel T, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356183
   Ren Y., 2019, PERFORMANCE ANAL DEE
   Tesla NVIDIA, 2017, NVIDIA, P108
   Vazhkudai SS, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Wang Y., 2020, HIERARCHICAL ROOFLIN
   Wang Y. E., 2019, ARXIV190710701
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
NR 22
TC 4
Z9 4
U1 0
U2 0
PY 2021
BP 7
EP 17
DI 10.1109/PMBS54543.2021.00007
UT WOS:000758429300002
DA 2023-11-16
ER

PT C
AU Huang, LY
   Zang, X
   Gong, Y
   Yuan, B
AF Huang, Lingyi
   Zang, Xiao
   Gong, Yu
   Yuan, Bo
GP IEEE
TI Hardware Architecture of Graph Neural Network-enabled Motion Planner
   (Invited Paper)
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
DE Motion Planning; Neural Network; Hardware Accelerator
ID PROCESSOR
AB Motion planning aims to find a collision-free trajectory from the start to goal configurations of a robot. As a key cognition task for all the autonomous machines, motion planning is fundamentally required in various real-world robotic applications, such as 2-D/3-D autonomous navigation of unmanned mobile and aerial vehicles and high degree-of-freedom (DoF) autonomous manipulation of industry/medical robot arms and graspers.
   Motion planning can be performed using either non-learning-based classical algorithms or learning-based neural approaches. Most recently, the powerful capabilities of deep neural networks (DNNs) make neural planners become very attractive because of their superior planning performance over the classical methods. In particular, graph neural network (GNN)-enabled motion planner has demonstrated the state-of-the-art performance across a set of challenging high-dimensional planning tasks, motivating the efficient hardware acceleration to fully unleash its potential and promote its widespread deployment in practical applications.
   To that end, in this paper we perform preliminary study of the efficient accelerator design of the GNN-based neural planner, especially for the neural explorer as the key component of the entire planning pipeline. By performing in-depth analysis on the different design choices, we identify that the hybrid architecture, instead of the uniform sparse matrix multiplication (SpMM)-based solution that is popularly adopted in the existing GNN hardware, is more suitable for our target neural explorer. With a set of optimization on microarchitecture and dataflow, several design challenges incurred by using hybrid architecture, such as extensive memory access and imbalanced workload, can be efficiently mitigated. Evaluation results show that our proposed customized hardware architecture achieves order-of-magnitude performance improvement over the CPU/GPU-based implementation with respect to area and energy efficiency in various working environments.
C1 [Huang, Lingyi; Zang, Xiao; Gong, Yu; Yuan, Bo] Rutgers State Univ, Piscataway, NJ 08854 USA.
RP Huang, LY (corresponding author), Rutgers State Univ, Piscataway, NJ 08854 USA.
EM lingyi.huang@rutgers.edu; xz514@scarletmail.rutgers.edu;
   yg430@scarletmail.rutgers.edu; bo.yuan@soe.rutgers.edu
CR Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Bency MJ, 2019, IEEE INT C INT ROBOT, P3965, DOI [10.1109/IROS40897.2019.8968089, 10.1109/iros40897.2019.8968089]
   Chen BH, 2020, Arxiv, DOI arXiv:1903.00070
   Chung CE, 2020, ISSCC DIG TECH PAP I, P324
   Deng CH, 2021, CONF PROC INT SYMP C, P1110, DOI 10.1109/ISCA52012.2021.00090
   Deng CH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P264, DOI 10.1145/3307650.3322258
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Duchon F, 2014, PROCEDIA ENGINEER, V96, P59, DOI 10.1016/j.proeng.2014.12.098
   Everson LR, 2021, IEEE J SOLID-ST CIRC, V56, P2281, DOI 10.1109/JSSC.2020.3048726
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Huang Lingyi, 2022, GLSVLSI '22: Proceedings of the Great Lakes Symposium on VLSI 2022, P373, DOI 10.1145/3526241.3530367
   Karaman S, 2011, IEEE INT CONF ROBOT, P1478
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Khan A, 2020, Arxiv, DOI arXiv:2006.06248
   Kim Y, 2016, ISSCC DIG TECH PAP I, V59, P258, DOI 10.1109/ISSCC.2016.7418005
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   LaValle SM, 2001, ALGORITHMIC AND COMPUTATIONAL ROBOTICS: NEW DIRECTIONS, P293
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Lian SQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196020
   Liao SY, 2019, AAAI CONF ARTIF INTE, P4287
   Murray S, 2016, INT SYMP MICROARCH
   Nair R.S., 2020, 11 INT C COMP COMM N, P1
   Qureshi AH, 2019, IEEE INT CONF ROBOT, P2118, DOI [10.1109/icra.2019.8793889, 10.1109/ICRA.2019.8793889]
   Rodríguez S, 2006, IEEE INT CONF ROBOT, P895
   Tamosiunaite Minija, 2020, ARXIV
   Thrun, 2005, PRINCIPLES ROBOT MOT
   Toma AI, 2021, Arxiv, DOI arXiv:2105.00312
   Xiao S., 2017, P IEEE INT C FIELD P, P1
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yang X, 2020, Arxiv, DOI arXiv:1809.04070
   Yin M, 2021, PROC CVPR IEEE, P10669, DOI 10.1109/CVPR46437.2021.01053
   Yin M, 2021, PROC CVPR IEEE, P12080, DOI 10.1109/CVPR46437.2021.01191
   Yin Miao, 2022, P IEEECVF C COMPUTER, P12299
   Yu C, 2021, PROC IEEE CUSTOM INT, P1
   Yu C., 2021, ADV NEURAL INFORM PR, P4274
   Zang Xiao, 2022, 2022 IEEERSJ INT C I
   Zhang BY, 2020, IEEE INT CONF ASAP, P61, DOI 10.1109/ASAP49362.2020.00019
   Zhang Z, 2014, INT J SMART HOME, V8, P75
NR 41
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3508352.3561113
UT WOS:000981574300103
DA 2023-11-16
ER

PT C
AU Xue, RX
   Wang, MQ
   Wang, ZF
AF Xue, Ruixin
   Wang, Meiqi
   Wang, Zhongfeng
BE Pimenidis, E
   Angelov, P
   Jayne, C
   Papaleonidas, A
   Aydin, M
TI Boosting Both Robustness and Hardware Efficiency via Random Pruning Mask
   Selection
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2022, PT I
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 31st International Conference on Artificial Neural Networks (ICANN)
CY SEP 06-09, 2022
CL Univ W England, Bristol, ENGLAND
HO Univ W England
DE Model compression; Network pruning; Adversarial machine learning; Deep
   learning
AB Deep neural networks (DNNs) are notorious for two key drawbacks: the vulnerability against adversarial attacks and the prohibitive cost of storage and computation, which greatly hinders DNNs' deployment on safety-critical yet resource-limited platforms. Although researchers have proposed adversary-aware pruning methods where adversarial training and network pruning are studied jointly to improve the robustness of pruned networks, they failed to attain a double-win, i.e., the achieved robustness is still limited and cannot surpass that of dense networks. In this work, pursuing a win-win in robustness and efficiency, we demonstrate that the robustness of pruned networks can be easily boosted by leveraging the stochastic policy. More specifically, we propose a Random Mask Selection (RMS) strategy where pruning masks are randomly sampled during inference to confuse attackers. Furthermore, a necessary hardware-aware algorithm optimization is introduced to eliminate the potential hardware overhead of RMS, and thus ensures a convenient implementation of RMS on existing hardware accelerators without sacrificing processing speed or power efficiency. Extensive experiments show that our approach achieves a double-win in robustness and compactness compared to dense models and outperforms the SOTA adversary-aware pruning method in terms of robustness.
C1 [Xue, Ruixin; Wang, Meiqi; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
RP Wang, MQ; Wang, ZF (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
EM rxxue@smail.nju.edu.cn; mqwang@smail.nju.edu.cn; zfwang@nju.edu.cn
CR [Anonymous], 2015, P IEEE INT C COMPUTE
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Feinman R, 2017, Arxiv, DOI arXiv:1703.00410
   Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194
   Fu Y., 2021, ADV NEURAL INF PROCE, V34, P20
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Guo YW, 2018, ADV NEUR IN, V31
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Osborne M. J., 1994, COURSE GAME THEORY, DOI DOI 10.1016/j.neuropsychologia.2004.04.015
   Sehwag Vikash, 2020, ARXIV200210509
   Rakin AS, 2019, Arxiv, DOI arXiv:1905.13074
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Ye SK, 2019, IEEE I CONF COMP VIS, P111, DOI 10.1109/ICCV.2019.00020
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/icassp40776.2020.9053977, 10.1109/ICASSP40776.2020.9053977]
NR 19
TC 0
Z9 0
U1 1
U2 1
PY 2022
VL 13529
BP 49
EP 60
DI 10.1007/978-3-031-15919-0_5
UT WOS:000866210600005
DA 2023-11-16
ER

PT J
AU Wang, Z
   Xiao, YH
   Liao, K
   Li, TT
   Song, H
   Chen, HS
   Uddin, SMZ
   Mao, D
   Wang, FF
   Zhou, ZP
   Yuan, B
   Jiang, W
   Fontaine, NK
   Agrawal, A
   Willner, AE
   Hu, XY
   Gu, TY
AF Wang, Zi
   Xiao, Yahui
   Liao, Kun
   Li, Tiantian
   Song, Hao
   Chen, Haoshuo
   Uddin, S. M. Zia
   Mao, Dun
   Wang, Feifan
   Zhou, Zhiping
   Yuan, Bo
   Jiang, Wei
   Fontaine, Nicolas K.
   Agrawal, Amit
   Willner, Alan E.
   Hu, Xiaoyong
   Gu, Tingyi
TI Metasurface on integrated photonic platform: from mode converters to
   machine learning
SO NANOPHOTONICS
DT Review
DE deep learning; metasurface; silicon photonics
ID INVERSE DESIGN; WAVE-GUIDE; DIFFRACTIVE OPTICS; NEURAL-NETWORK; SILICON;
   POLARIZATION; PHASE; RESOLUTION; GENERATION; PROJECTION
AB Integrated photonic circuits are created as a stable and small form factor analogue of fiber-based optical systems, from wavelength-division multiplication transceivers to more recent mode-division multiplexing components. Silicon nanowire waveguides guide the light in a way that single and few mode fibers define the direction of signal flow. Beyond communication tasks, on-chip cascaded interferometers and photonic meshes are also sought for optical computing and advanced signal processing technology. Here we review an alternative way of defining the light flow in the integrated photonic platform, using arrays of subwavelength meta-atoms or metalines for guiding the diffraction and interference of light. The integrated metasurface system mimics free-space optics, where on-chip analogues of basic optical components are developed with foundry compatible geometry, such as low-loss lens, spatial-light modulator, and other wavefront shapers. We discuss the role of metasurface in integrated photonic signal processing systems, introduce the design principles of such metasurface systems for low loss compact mode conversion, mathematical operation, diffractive optical systems for hyperspectral imaging, and tuning schemes of metasurface systems. Then we perceive reconfigurability schemes for metasurface framework, toward optical neural networks and analog photonic accelerators.
C1 [Wang, Zi; Xiao, Yahui; Uddin, S. M. Zia; Mao, Dun; Gu, Tingyi] Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19711 USA.
   [Wang, Zi; Agrawal, Amit] NIST, Phys Measurement Lab, Gaithersburg, MD 20899 USA.
   [Liao, Kun; Wang, Feifan; Zhou, Zhiping; Hu, Xiaoyong] Peking Univ, Beijing 100871, Peoples R China.
   [Li, Tiantian] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
   [Song, Hao; Willner, Alan E.] Univ South Calif, Dept Elect & Comp Engn, Los Angeles, CA 90089 USA.
   [Willner, Alan E.] Univ South Calif, Dept Phys & Astron, Los Angeles, CA 90089 USA.
   [Chen, Haoshuo; Fontaine, Nicolas K.] Nokia Bell Labs, 600 Mt Ave, Murray Hill, NJ 07974 USA.
   [Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   [Jiang, Wei] Nanjing Univ, Coll Engn & Appl Sci, Nanjing 210093, Peoples R China.
RP Gu, TY (corresponding author), Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19711 USA.
EM tingyigu@udel.edu
CR Abbas MA, 2022, NANOSCALE, V14, P6425, DOI 10.1039/d1nr08400c
   Abdollahramezani S, 2020, NANOPHOTONICS-BERLIN, V9, P4075, DOI 10.1515/nanoph-2020-0285
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Arbabi A, 2017, NAT PHOTONICS, V11, P415, DOI [10.1038/NPHOTON.2017.96, 10.1038/nphoton.2017.96]
   Arbabi A, 2015, NAT NANOTECHNOL, V10, P937, DOI [10.1038/nnano.2015.186, 10.1038/NNANO.2015.186]
   Arbabi A, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8069
   Arbabi E, 2017, OPTICA, V4, P625, DOI 10.1364/OPTICA.4.000625
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   Backer AS, 2019, OPT EXPRESS, V27, P30308, DOI 10.1364/OE.27.030308
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Chandrasekar R, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.2.020901
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Chen C, 2021, NANOPHOTONICS-BERLIN, V10, P2481, DOI 10.1515/nanoph-2021-0137
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XZ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms2207
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cheng M, 2017, DES AUT CON, DOI 10.1145/3061639.3062326
   Cheng-Shun Hsiao, 2021, 2021 3rd International Conference on Computer Communication and the Internet (ICCCI), P1, DOI 10.1109/ICCCI51764.2021.9486782
   Chih YD, 2021, ISSCC DIG TECH PAP I, V64, P252, DOI 10.1109/ISSCC42613.2021.9365766
   Choi C, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202007210
   Chrostowski L, 2015, SILICON PHOTONICS DESIGN, P1
   Delaney M, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg3500
   Domínguez A, 2015, IEEE PULSE, V6, P38, DOI 10.1109/MPUL.2014.2366903
   Fan YL, 2017, ACS NANO, V11, P4599, DOI 10.1021/acsnano.7b00150
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Feng CH, 2022, Arxiv, DOI arXiv:2111.06705
   Feng L, 2013, NAT MATER, V12, P108, DOI [10.1038/NMAT3495, 10.1038/nmat3495]
   Gok G, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.233904
   Guo C, 2018, OPTICA, V5, P251, DOI 10.1364/OPTICA.5.000251
   Guo JS, 2020, LASER PHOTONICS REV, V14, DOI 10.1002/lpor.202000058
   Happ TD, 2001, OPT LETT, V26, P1102, DOI 10.1364/OL.26.001102
   Huang LL, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3808
   Jahani S, 2016, NAT NANOTECHNOL, V11, P23, DOI [10.1038/nnano.2015.304, 10.1038/NNANO.2015.304]
   Jalali B, 2006, J LIGHTWAVE TECHNOL, V24, P4600, DOI 10.1109/JLT.2006.885782
   Jin ZW, 2021, ELIGHT, V1, DOI 10.1186/s43593-021-00005-9
   Khaddam-Aljameh R., 2021, 2021 S VLSI CIRCUITS, P1, DOI 10.23919/VLSICircuits52068.2021.9492362
   Khorasaninejad M, 2016, NANO LETT, V16, P3732, DOI 10.1021/acs.nanolett.6b01097
   Khorasaninejad M, 2016, SCIENCE, V352, P1190, DOI 10.1126/science.aaf6644
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Knag P. C, 2020, 2020 IEEE S VLSI CIR, P1
   Kruk S., 2018, C LASERS ELECTRO OPT
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lassaline N, 2020, NATURE, V582, P506, DOI 10.1038/s41586-020-2390-x
   Lee BG, 2010, 2010 23RD ANNUAL MEETING OF THE IEEE PHOTONICS SOCIETY, P564, DOI 10.1109/PHOTONICS.2010.5699012
   Lee BG, 2012, J LIGHTWAVE TECHNOL, V30, P886, DOI 10.1109/JLT.2012.2183853
   Lee D, 2022, ELIGHT, V2, DOI 10.1186/s43593-021-00008-6
   Li CL, 2019, NANOPHOTONICS-BERLIN, V8, P227, DOI 10.1515/nanoph-2018-0161
   Li JX, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17390-3
   Li L., 2022, ELIGHT, V2, P7
   Li T., 2021, C LASERS ELECTRO OPT
   Li ZY, 2017, NAT NANOTECHNOL, V12, P675, DOI [10.1038/nnano.2017.50, 10.1038/NNANO.2017.50]
   Liao K, 2020, NANOPHOTONICS-BERLIN, V9, P3315, DOI 10.1515/nanoph-2020-0069
   Lin DM, 2014, SCIENCE, V345, P298, DOI 10.1126/science.1253213
   Lin J, 2013, SCIENCE, V340, P331, DOI 10.1126/science.1233746
   Liu C, 2021, ACS PHOTONICS, V8, P716, DOI 10.1021/acsphotonics.0c01929
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Liu Y., 2021, OPTICAL FIBER COMMUN
   Liu YZ, 2017, OPT EXPRESS, V25, P17201, DOI 10.1364/OE.25.017201
   Luo LW, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4069
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Miscuglio M, 2020, OPTICA, V7, P1812, DOI 10.1364/OPTICA.408659
   Molesky S, 2018, NAT PHOTONICS, V12, P659, DOI 10.1038/s41566-018-0246-9
   Neshev D, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0058-1
   Ni XJ, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3807
   Osgood R., 2021, PRINCIPLES PHOTONIC
   Pang K, 2021, NANO LETT, V21, P5907, DOI 10.1021/acs.nanolett.1c00550
   Piggott AY, 2015, NAT PHOTONICS, V9, P374, DOI [10.1038/NPHOTON.2015.69, 10.1038/nphoton.2015.69]
   Pors A, 2015, NANO LETT, V15, P791, DOI 10.1021/nl5047297
   Ren YX, 2016, SCI REP-UK, V6, DOI 10.1038/srep33306
   Richardson DJ, 2013, NAT PHOTONICS, V7, P354, DOI [10.1038/nphoton.2013.94, 10.1038/NPHOTON.2013.94]
   Saito D., 2021, PROC S VLSI CIRCUITS, P1, DOI DOI 10.23919/VLSICIRCUITS52068.2021.9492479
   Sanchis P, 2002, OPT EXPRESS, V10, P1391, DOI 10.1364/OE.10.001391
   Sayal A, 2019, ISSCC DIG TECH PAP I, V62, P228, DOI 10.1109/ISSCC.2019.8662510
   Shen B, 2015, NAT PHOTONICS, V9, P378, DOI [10.1038/nphoton.2015.80, 10.1038/NPHOTON.2015.80]
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silva A, 2014, SCIENCE, V343, P160, DOI [10.1126/science.1242818, 10.1126/science.124405]
   Skivesen N, 2007, OPT EXPRESS, V15, P3169, DOI 10.1364/OE.15.003169
   Soref R, 2006, IEEE J SEL TOP QUANT, V12, P1678, DOI 10.1109/JSTQE.2006.883151
   Soref R, 2010, NAT PHOTONICS, V4, P495, DOI 10.1038/nphoton.2010.171
   Stern B, 2015, OPTICA, V2, P530, DOI 10.1364/OPTICA.2.000530
   Sun SL, 2012, NAT MATER, V11, P426, DOI [10.1038/nmat3292, 10.1038/NMAT3292]
   Sun WJ, 2016, LIGHT-SCI APPL, V5, DOI 10.1038/lsa.2016.3
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tu FB, 2018, CONF PROC INT SYMP C, P340, DOI 10.1109/ISCA.2018.00037
   Vakil A, 2011, SCIENCE, V332, P1291, DOI 10.1126/science.1202691
   Wada K, 2002, PROC SPIE, V4870, P437, DOI 10.1117/12.475558
   Wang C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02189-6
   Wang FF, 2020, CONF LASER ELECTR
   Wang HW, 2019, ADV OPT MATER, V7, DOI 10.1002/adom.201801191
   Wang L, 2018, NANO LETT, V18, P3978, DOI 10.1021/acs.nanolett.8b01460
   Wang NN, 2021, OPT LETT, V46, P4088, DOI 10.1364/OL.427386
   Wang ZW, 2021, 2021 5TH IEEE ELECTRON DEVICES TECHNOLOGY & MANUFACTURING CONFERENCE (EDTM), DOI 10.1109/EDTM50988.2021.9420957
   Wang Z, 2017, OPT LETT, V42, P2746, DOI 10.1364/OL.42.002746
   Wang Z, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29856-7
   Wang Z, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11578-y
   Wu C., 2021, HARNESSING OPTOELECT
   Xiao YH, 2021, J OPT MICROSYST, V1, DOI 10.1117/1.JOM.1.2.024001
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yamamoto K, 2021, IEEE J SOLID-ST CIRC, V56, P165, DOI 10.1109/JSSC.2020.3027702
   Yan BN, 2017, ICCAD-IEEE ACM INT, P541, DOI 10.1109/ICCAD.2017.8203824
   Yang R, 2020, OPT LETT, V45, P5640, DOI 10.1364/OL.405446
   Yao CN, 2020, ADV OPT MATER, V8, DOI 10.1002/adom.202000529
   Yao K, 2019, NANOPHOTONICS-BERLIN, V8, P339, DOI 10.1515/nanoph-2018-0183
   Yu NF, 2014, NAT MATER, V13, P139, DOI [10.1038/nmat3839, 10.1038/NMAT3839]
   Yulaev A, 2019, ACS PHOTONICS, V6, P2902, DOI 10.1021/acsphotonics.9b01000
   Zarei S, 2020, OPT EXPRESS, V28, P36668, DOI 10.1364/OE.404386
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang JH, 2021, OPT EXPRESS, V29, P32196, DOI 10.1364/OE.439106
   Zhang JF, 2019, SYMP VLSI CIRCUITS, pC306, DOI 10.23919/VLSIC.2019.8778193
   Zheng GX, 2015, NAT NANOTECHNOL, V10, P308, DOI [10.1038/nnano.2015.2, 10.1038/NNANO.2015.2]
   Zhou Y, 2020, ADV OPT MATER, V8, DOI 10.1002/adom.201901523
   Zhou Y, 2020, NAT PHOTONICS, V14, P316, DOI 10.1038/s41566-020-0591-3
   Zhu R., 2022, ELIGHT, V2, P10
   Zhu TF, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15391
NR 114
TC 5
Z9 6
U1 62
U2 201
PD AUG 17
PY 2022
VL 11
IS 16
BP 3531
EP 3546
DI 10.1515/nanoph-2022-0294
EA JUL 2022
UT WOS:000827396000001
DA 2023-11-16
ER

PT C
AU Jang, H
   Kim, J
   Jo, JE
   Lee, J
   Kim, J
AF Jang, Hanhwi
   Kim, Joonsung
   Jo, Jae-Eon
   Lee, Jaewon
   Kim, Jangwoo
GP ACM
TI MnnFast: A Fast and Scalable System Architecture for Memory-Augmented
   Neural Networks
SO PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA '19)
DT Proceedings Paper
CT 46th International Symposium on Computer Architecture (ISCA) / Workshop
   on Computer Architecture Education (WCAE)
CY JUN 22-26, 2019
CL Phoenix, AZ
DE Memory Networks; Attention-based Neural Networks; Machine Learning;
   Parallel Algorithm; Computation/Dataflow Optimization; Accelerator;
   Algorithm-Hardware Co-Design; Architecture
ID ACCELERATOR
AB Memory-augmented neural networks are getting more attention from many researchers as they can make an inference with the previous history stored in memory. Especially, among these memory-augmented neural networks, memory networks are known for their huge reasoning power and capability to learn from a large number of inputs rather than other networks. As the size of input datasets rapidly grows, the necessity of large-scale memory networks continuously arises. Such large-scale memory networks provide excellent reasoning power; however, the current computer infrastructure cannot achieve scalable performance due to its limited system architecture.
   In this paper, we propose MnnFast, a novel system architecture for large-scale memory networks to achieve fast and scalable reasoning performance. We identify the performance problems of the current architecture by conducting extensive performance bottleneck analysis. Our in-depth analysis indicates that the current architecture suffers from three major performance problems: high memory bandwidth consumption, heavy computation, and cache contention. To overcome these performance problems, we propose three novel optimizations. First, to reduce the memory bandwidth consumption, we propose a new column-based algorithm with streaming which minimizes the size of data spills and hides most of the offchip memory accessing overhead. Second, to decrease the high computational overhead, we propose a zero-skipping optimization to bypass a large amount of output computation. Lastly, to eliminate the cache contention, we propose an embedding cache dedicated to efficiently cache the embedding matrix.
   Our evaluations show that MnnFast is significantly effective in various types of hardware: CPU, GPU, and FPGA. MnnFast improves the overall throughput by up to 5.38x, 4.34x, and 2.01x on CPU, GPU, and FPGA respectively. Also, compared to CPU-based MnnFast, our FPGA-based MnnFast achieves 6.54x higher energy efficiency.
C1 [Jang, Hanhwi; Jo, Jae-Eon] POSTECH Pohang, Dept Comp Sci & Engn, Pohang, South Korea.
   [Kim, Joonsung; Lee, Jaewon; Kim, Jangwoo] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
RP Kim, J (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
EM hanhwi@postech.ac.kr; joonsung90@snu.ac.kr; jojaeeon@postech.ac.kr;
   lee.jaewon@snu.ac.kr; jangwoo@snu.ac.kr
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Akram R, 2017, I S WORKL CHAR PROC, P116, DOI 10.1109/IISWC.2017.8167765
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, ICCAD IEEE ACM INT, DOI DOI 10.1145/3240765.3240796
   [Anonymous], 2018, CONF PROC INT SYMP C, DOI DOI 10.1109/ISCA.2018.00068
   [Anonymous], 6 INT C LEARN REPR I
   [Anonymous], 2018, ARXIV181006807
   [Anonymous], 6 INT C LEARN REPR I
   [Anonymous], ICCAD IEEE ACM INT
   [Anonymous], P 14 EUROSYST C 2019
   [Anonymous], INT 64 LA 32 ARCH SO
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2018, P 36 INT C MACH LEAR
   [Anonymous], CORR
   [Anonymous], 49 ANN IEEE ACM INT
   [Anonymous], 2018, CORR
   [Anonymous], 2011, BREAKING COPPERSMITH
   [Anonymous], CORR
   [Anonymous], 7 INT C LEARN REPR I
   [Anonymous], CORR
   [Anonymous], CORR
   [Anonymous], 2018, CONF PROC INT SYMP C, DOI DOI 10.1109/ISCA.2018.00051
   [Anonymous], 2016, CORR
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bertran R, 2017, PR IEEE COMP DESIGN, P601, DOI 10.1109/ICCD.2017.105
   Bin Altaf MS, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P375, DOI [10.1145/3079856.3080216, 10.1145/3140659.3080216]
   Boston B, 2015, ACM SIGPLAN NOTICES, V50, P470, DOI [10.1145/2814270.2814301, 10.1145/2858965.2814301]
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3296957.3173212, 10.1145/3173162.3173212]
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chin T.-W., 2018, ARXIV181000518
   Davies M., 2008, CORPUS CONT AM ENGLI
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Ding RZ, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P35, DOI 10.1145/3060403.3060465
   Donato M, 2018, DES AUT CON, DOI 10.1145/3195970.3196083
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Franchetti F, 2018, P IEEE, V106, P1935, DOI 10.1109/JPROC.2018.2873289
   Fuchs A, 2018, CONF PROC INT SYMP C, P353, DOI 10.1109/ISCA.2018.00038
   Gadioli D, 2019, IEEE T COMPUT, V68, P713, DOI 10.1109/TC.2018.2883597
   Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053
   Gysel P., 2016, ARXIV160403168
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hill P, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P786, DOI 10.1145/3123939.3123970
   Iandola F.N., 2016, CORR ABS160207360
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Kung J, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P403, DOI 10.1145/3079856.3080252
   Lee JH, 2018, IEEE T COMPUT, V67, P861, DOI 10.1109/TC.2017.2780237
   Lin MY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240800
   Lin SC, 2018, ACM SIGPLAN NOTICES, V53, P751, DOI [10.1145/3296957.3173191, 10.1145/3173162.3173191]
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Miller AH, 2016, ACL, P1400, DOI 10.18653/v1/d16-1147
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Perais A, 2014, INT S HIGH PERF COMP, P428, DOI 10.1109/HPCA.2014.6835952
   Reagen, 2017, ARXIV PREPRINT ARXIV
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Reagen B, 2017, I SYMPOS LOW POWER E
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Sampson A., 2015, SUMMIT ADV PROGRAMMI, P262, DOI DOI 10.4230/LIPICS.SNAPL.2015.262
   San Miguel J, 2014, INT SYMP MICROARCH, P127, DOI 10.1109/MICRO.2014.22
   Shao YS, 2015, IEEE MICRO, V35, P58, DOI 10.1109/MM.2015.50
   Song MC, 2018, INT S HIGH PERF COMP, P92, DOI 10.1109/HPCA.2018.00018
   Song MC, 2018, INT S HIGH PERF COMP, P66, DOI 10.1109/HPCA.2018.00016
   Stamoulis D, 2018, DES AUT TEST EUROPE, P19
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Venkatagiri R, 2018, I C DEPEND SYS NETWO, P598, DOI 10.1109/DSN.2018.00067
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang Q, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503219
   Weston J., 2015, ARXIV150205698
   Weston J., 2014, ARXIV14103916
   Wu CP, 2017, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2017.88
   Xianyi Z., 2012, 2012 IEEE 18 INT C P, P684, DOI DOI 10.1109/ICPADS.2012.97
   Yazdanbakhsh A, 2018, CONF PROC INT SYMP C, P650, DOI 10.1109/ISCA.2018.00060
   Yazdanbakhsh A, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2836168
   Yazdani R, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P69, DOI [10.1145/3123939.3124542, 10.1145/3123939.31.24542]
   Yazdani R, 2018, CONF PROC INT SYMP C, P790, DOI 10.1109/ISCA.2018.00071
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhu YH, 2017, IEEE MICRO, V37, P15
NR 87
TC 27
Z9 27
U1 0
U2 0
PY 2019
BP 250
EP 263
DI 10.1145/3307650.3322214
UT WOS:000521059600020
DA 2023-11-16
ER

PT J
AU Eldafrawy, M
   Boutros, A
   Yazdanshenas, S
   Betz, V
AF Eldafrawy, Mohamed
   Boutros, Andrew
   Yazdanshenas, Sadegh
   Betz, Vaughn
TI FPGA Logic Block Architectures for Efficient Deep Learning Inference
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Deep neural networks; FPGA; CAD tools
AB Reducing the precision of deep neural network (DNN) inference accelerators can yield large efficiency gains with little or no accuracy degradation compared to half or single precision floating-point by enabling more multiplication operations per unit area. A wide range of precisions fall on the pareto-optimal curve of hardware efficiency vs. accuracy with no single precision dominating, making the variable precision capabilities of FPGAs very valuable. We propose three types of logic block architectural enhancements and fully evaluate a total of six architectures that improve the area efficiency of multiplications and additions implemented in the soft fabric. Increasing the LUT fracturability and adding two adders to the ALM (4-bit Adder Double Chain architecture) leads to a 1.5x area reduction for arithmetic heavy machine learning (ML) kernels, while increasing their speed. In addition, this architecture also reduces the logic area of general applications by 6%, while increasing the critical path delay by only 1%. However, our highest impact option, which adds a 9-bit shadow multiplier to the logic clusters, reduces the area and critical path delay of ML kernels by 2.4x and 1.2x, respectively. These large gains come at a cost of 15% logic area increase for general applications.
C1 [Eldafrawy, Mohamed; Boutros, Andrew; Yazdanshenas, Sadegh; Betz, Vaughn] Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.
RP Eldafrawy, M (corresponding author), Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.
EM mohamed.eldafrawy@mail.utoronto.ca; andrew.boutros@mail.utoronto.ca;
   sadegh.yazdanshenas@mail.utoronto.ca; vaughn@ece.utoronto.ca
CR Ahmed E, 2004, IEEE T VLSI SYST, V12, P288, DOI 10.1109/TVLSI.2004.824300
   [Anonymous], 2015, P 2015 ACMSIGDA INT
   [Anonymous], 2019, INTEL STRATIX 10 MX
   [Anonymous], 2018, ARXIV180201548
   [Anonymous], 2017, CORR
   [Anonymous], 2001, P 2001 ACMSIGDA 9 IN
   [Anonymous], 2018, ADV NEUR IN
   BAUGH CR, 1973, IEEE T COMPUT, VC 22, P1045, DOI 10.1109/T-C.1973.223648
   Betz V, 1998, IEEE DES TEST COMPUT, V15, P10, DOI 10.1109/54.655177
   Betz V, 1997, PROCEEDINGS OF THE IEEE 1997 CUSTOM INTEGRATED CIRCUITS CONFERENCE, P551, DOI 10.1109/CICC.1997.606687
   Boutin A, 2019, FETAL DIAGN THER, V45, P69, DOI 10.1159/000487301
   Boutros A., 2018, TRETS, V11, P3
   Boutros A, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P94, DOI 10.1145/3289602.3293912
   Burich M., 2012, P INT S FIELD PROGR
   Cao Y., 2018, PREDICTIVE TECHNOLOG
   Chandrakar S., 2015, P 2015 ACM SIGDA INT, P108
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Intel Corporation, 2017, UGS10LAB INT CORP
   Intel Corporation, 2005, STRAT GX TRANS US GU
   Jamieson P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY, PROCEEDINGS, P1, DOI 10.1109/FPT.2006.270384
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuon I, 2011, IEEE T VLSI SYST, V19, P71, DOI 10.1109/TVLSI.2009.2031318
   Langhammer M, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P202, DOI 10.1145/3289602.3293927
   Lewis D, 2005, HLTH INFORMAT SER, P1
   Lewis D, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P159, DOI 10.1145/2847263.2847267
   Lewis David, 2003, P 2003 ACM SIGDA 11, P12, DOI [10.1145/611817.611821, DOI 10.1145/611817.611821]
   Luu J, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2617593
   Masson C, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P34, DOI 10.1109/FPT.2013.6718327
   Mike W., 2019, VIRTEX ULTRASCALE HB
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   ROSE J, 1993, P IEEE, V81, P1013, DOI 10.1109/5.231340
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Trimberger SM, 2015, P IEEE, V103, P318, DOI 10.1109/JPROC.2015.2392104
   Xilinx Corporation, 2007, VIRT 2 PRO VIRT 2 PR
   Xilinx Corporation, 2007, VIRT 2 PLATF FPGA US
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Yazdanshenas S, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3301298
   Yazdanshenas S, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P9, DOI 10.1109/FPT.2017.8280115
NR 42
TC 11
Z9 11
U1 0
U2 6
PD SEP
PY 2020
VL 13
IS 3
AR 12
DI 10.1145/3393668
UT WOS:000583746200002
DA 2023-11-16
ER

PT C
AU Liu, GD
   Wang, S
   Bao, YG
AF Liu, Guodong
   Wang, Sa
   Bao, Yungang
BE Lee, J
   Cohen, A
TI SEER: A Time Prediction Model for CNNs from GPU Kernel's View
SO 30TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION
   TECHNIQUES (PACT 2021)
SE International Conference on Parallel Architectures and Compilation
   Techniques
DT Proceedings Paper
CT 30th International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY SEP 26-29, 2021
CL ELECTR NETWORK
DE machine learning; neural network; performance model; GPU
AB With the deepening of research and increasing size of data sets, deep neural networks have become larger and larger. To reduce the training time of large neural networks, researchers propose to optimize neural networks from different levels. When performing optimizations, prior knowledge about execution time of each part of the network can help avoid repeatedly time-consuming testing and profiling process. However it is quite challenging to build an accurate iteration time prediction model, due to opaque underlying implementation of network operators and complex architecture of accelerators. In this paper, we propose SEER, an iteration time prediction model for CNNs, targeting on GPU platforms. We propose to categorize convolution kernels into three different types: Compute-bound, DRAM-bound and Under-utilized, then we build performance model for each type respectively. We combined analytical models and learning-based models to make the performance model accurate and in line with GPU execution model. Experimental results show that, our model achieves 14.71% prediction error on convolution kernels and up to 1.79% prediction error for the overall computation time in one iteration of common CNNs. Besides, when used for selecting the best convolution algorithm, our model shows 7.14% lower error rate than cuDNN's official algorithm picker.
C1 [Liu, Guodong; Wang, Sa; Bao, Yungang] Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Liu, Guodong; Wang, Sa; Bao, Yungang] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Bao, Yungang] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Wang, Sa] Chinese Acad Sci, Inst Comp Technol Nanjing, Nanjing, Peoples R China.
RP Liu, GD (corresponding author), Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.; Liu, GD (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM liuguodong19z@ict.ac.cn; wangsa@ict.ac.cn; baoyg@ict.ac.cn
CR Abadi M., 2016, 12 USENIX S OP SYST, P265, DOI 10.5555/3026877.3026899
   [Anonymous], 2017, ACML
   Baghdadi R., 2021, P MACH LEARNING SYST, V3
   Breiman L, 2017, CLASSIFICATION REGRE, DOI DOI 10.1201/9781315139470
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chilimbi T., 2014, P 11 USENIX S OP SYS, P571, DOI DOI 10.1108/01439911111122716
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jia ZH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P47, DOI 10.1145/3341301.3359630
   Justus D, 2018, IEEE INT CONF BIG DA, P3873, DOI 10.1109/BigData.2018.8622396
   Kaufman S., 2021, P MACH LEARNING SYST, V3
   Kothapalli K, 2009, 16TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING (HIPC), PROCEEDINGS, P463, DOI 10.1109/HIPC.2009.5433179
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2014, ABS14045997 CORR
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li M., 2014, P 11 USENIX S OP SYS, V14, P583, DOI DOI 10.1145/2640087.2644155
   LITTLE JDC, 1961, OPER RES, V9, P383, DOI 10.1287/opre.9.3.383
   Mathieu Michael, 2013, ARXIV13125851
   Mendis C, 2019, PR MACH LEARN RES, V97
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   NVIDIA, CUDA OCC CAL
   NVIDIA, 2020, CUDA PROGR GUID
   NVIDIA, 2020, GPU PERF BACKGR USER
   Paszke Adam, 2017, AUTOMATIC DIFFERENTI
   Pei Z., 2019, IEEE ACCESS, V7, p64 788
   Qi H., 2017, P 5 INT C LEARN REPR
   Seber G.A.F., 2003, NONLINEAR REGRESSION
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Volkov Vasily, 2016, THESIS UC BERKELEY
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhang Y, 2011, INT S HIGH PERF COMP, P382, DOI 10.1109/HPCA.2011.5749745
NR 35
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 173
EP 185
DI 10.1109/PACT52795.2021.00020
UT WOS:000758464500013
DA 2023-11-16
ER

PT J
AU Di Guglielmo, G
   Fahim, F
   Herwig, C
   Valentin, MB
   Duarte, J
   Gingu, C
   Harris, P
   Hirschauer, J
   Kwok, M
   Loncar, V
   Luo, YY
   Miranda, L
   Ngadiuba, J
   Noonan, D
   Ogrenci-Memik, S
   Pierini, M
   Summers, S
   Tran, N
AF Di Guglielmo, Giuseppe
   Fahim, Farah
   Herwig, Christian
   Valentin, Manuel Blanco
   Duarte, Javier
   Gingu, Cristian
   Harris, Philip
   Hirschauer, James
   Kwok, Martin
   Loncar, Vladimir
   Luo, Yingyi
   Miranda, Llovizna
   Ngadiuba, Jennifer
   Noonan, Daniel
   Ogrenci-Memik, Seda
   Pierini, Maurizio
   Summers, Sioni
   Tran, Nhan
TI A Reconfigurable Neural Network ASIC for Detector Front-End Data
   Compression at the HL-LHC
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article
DE Detectors; Artificial neural networks; Task analysis; Training; Field
   programmable gate arrays; Data compression; Computer architecture;
   Application-specific integrated circuit (ASIC); artificial intelligence
   (AI); autoencoder; hardware accelerator; high-level synthesis (HLS);
   Large Hadron Collider (LHC); machine learning (ML); single-event effect
   (SEE) mitigation
AB Despite advances in the programmable logic capabilities of modern trigger systems, a significant bottleneck remains in the amount of data to be transported from the detector to off-detector logic where trigger decisions are made. We demonstrate that a neural network (NN) autoencoder model can be implemented in a radiation-tolerant application-specific integrated circuit (ASIC) to perform lossy data compression alleviating the data transmission problem while preserving critical information of the detector energy profile. For our application, we consider the high-granularity calorimeter from the Compact Muon Solenoid (CMS) experiment at the CERN Large Hadron Collider. The advantage of the machine learning approach is in the flexibility and configurability of the algorithm. By changing the NN weights, a unique data compression algorithm can be deployed for each sensor in different detector regions and changing detector or collider conditions. To meet area, performance, and power constraints, we perform quantization-aware training to create an optimized NN hardware implementation. The design is achieved through the use of high-level synthesis tools and the hls4ml framework and was processed through synthesis and physical layout flows based on a low-power (LP)-CMOS 65-nm technology node. The flow anticipates 200 Mrad of ionizing radiation to select gates and reports a total area of 3.6 mm(2) and consumes 95 mW of power. The simulated energy consumption per inference is 2.4 nJ. This is the first radiation-tolerant on-detector ASIC implementation of an NN that has been designed for particle physics applications.
C1 [Di Guglielmo, Giuseppe] Columbia Univ, Comp Sci Dept, New York, NY 10027 USA.
   [Fahim, Farah; Herwig, Christian; Gingu, Cristian; Hirschauer, James; Miranda, Llovizna; Tran, Nhan] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Fahim, Farah; Valentin, Manuel Blanco; Luo, Yingyi; Ogrenci-Memik, Seda; Tran, Nhan] Northwestern Univ, Elect & Comp Engn Dept, Evanston, IL 60208 USA.
   [Duarte, Javier] Univ Calif San Diego, Phys Dept, La Jolla, CA 92093 USA.
   [Harris, Philip] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Kwok, Martin] Brown Univ, Phys Dept, Providence, RI 02912 USA.
   [Loncar, Vladimir; Pierini, Maurizio; Summers, Sioni] CERN, CH-1211 Geneva, Switzerland.
   [Loncar, Vladimir] Inst Phys Belgrade, Belgrade 11080, Serbia.
   [Ngadiuba, Jennifer] CALTECH, Pasadena, CA 91125 USA.
   [Noonan, Daniel] Florida Inst Technol, Melbourne, FL 32901 USA.
RP Tran, N (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM ntran@fnal.gov
CR Albertsson K, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/2/022008
   Alía RG, 2018, IEEE T NUCL SCI, V65, P448, DOI 10.1109/TNS.2017.2776107
   [Anonymous], 2015, COGNITIVE SCI, DOI DOI 10.1111/COGS.12280
   Bourilkov D, 2019, INT J MOD PHYS A, V34, DOI 10.1142/S0217751X19300199
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Casas LMJ, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/02/C02039
   Chatrchyan S., 2008, P JINST, V3
   CMS Collaboration, 2017, PHASE 2 UPGRADE CMS, DOI [DOI 10.17181/CERN.IV8M.1JY2, 10.17181/CERN.IV8M.1JY2]
   CMS collaboration, 2020, CERNLHCC2020004 CMS
   CMS Team, CMSSW GITHUB
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dodd PE, 2010, IEEE T NUCL SCI, V57, P1747, DOI 10.1109/TNS.2010.2042613
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Fulkerson D., 2006, U.S. Patent, Patent No. [11 136 920, 11136920]
   Glorot X., 2011, PMLR, Vvol 15, P315
   Gong R, 2008, J ELECTRON TEST, V24, P57, DOI 10.1007/s10836-007-5029-z
   Habinc S., 2002, FPGA00301 GAISL RES
   Huhtinen M, 1996, THESIS HELSINKI U TE
   Karbachevsky A., SUSTAINABILITY-BASEL, V13, P717
   Komiske PT, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.041801
   Kuboyama S., 2009, U.S. Patent, Patent No. [7 504 850, 7504850]
   LYONS RE, 1962, IBM J RES DEV, V6, P200, DOI 10.1147/rd.62.0200
   Maharrey JA, 2018, IEEE T NUCL SCI, V65, P1872, DOI 10.1109/TNS.2017.2783239
   Mentor/Siemens, 2020, CAT HIGH LEV SYNTH V
   Mentor/Siemens, 2020, HLSLIBS OP SOURC HIG
   Mentor/Siemens, 2020, CAT HIGH LEV SYNTH
   Nair V., 2010, PROC 27 INT C INT C
   OSHWA, 2020, RES RED SPI SIGN NAM
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Schrimpf R.D., 2004, RAD EFFECTS SOFT ERR, V12
   Summers, 2020, ARXIV200610159
   Xilinx, 2020, VIV HIGH LEV SYNTH
NR 32
TC 16
Z9 16
U1 2
U2 8
PD AUG
PY 2021
VL 68
IS 8
BP 2179
EP 2186
DI 10.1109/TNS.2021.3087100
PN 1-3
UT WOS:000687247300092
DA 2023-11-16
ER

PT C
AU Goswami, P
   Shahshahani, M
   Bhatia, D
AF Goswami, Pingakshya
   Shahshahani, Masoud
   Bhatia, Dinesh
GP IEEE Comp Soc
TI Robust Estimation of FPGA Resources and Performance from CNN Models
SO 2022 35TH INTERNATIONAL CONFERENCE ON VLSI DESIGN (VLSID 2022) HELD
   CONCURRENTLY WITH 2022 21ST INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS
   (ES 2022)
SE International Conference on VLSI Design
DT Proceedings Paper
CT 35th International Conference on VLSI Design (VLSID) / 21st
   International Conference on Embedded Systems (ES)
CY FEB 26-MAR 02, 2022
CL ELECTR NETWORK
DE High Level Synthesis; Machine Learning; Convolution Neural Network;
   Estimation
AB Field-Programmable Gate Arrays (FPGAs) are becoming increasingly popular for implementing convolutional neural networks (CNNs) due to their low latency and very high energy efficiency. However, most FPGAs are resource-scarce and efficient mapping of CNN can quickly become a challenging task. The requirement of FPGA resources, latency, and power is affected by many parameters, including the CNN architecture and the level of computational parallelism. In practice, a software designer first explores various CNN architectures in software to improve architecture's validation accuracy. Once an architecture is finalized, the designer ports the architecture design to FPGA for inference acceleration. The mapping process undergoes performance optimization by tweaking many design-related parameters during the design space exploration and changing the operating frequencies. The entire process is highly time-consuming. In this paper, we have presented a machine learning-based two-stage estimator for assisting in designing an FPGA-based CNN accelerator. Our Global Predictor assists in making accurate estimates of FPGA resource requirements and design latency from CNN architecture and hyperparameters expressed in Python. This assists in choosing a subset of high validation accuracy and feasible designs for mapping on FPGA. Our Detailed Predictor assists in making accurate estimates of FPGA post-route resource requirements, design latency, and final clock period for the chosen subset of designs after applying high-level synthesis level (pragma and frequency) optimizations. Our proposed estimation methodology enables a software engineer to obtain rapid and accurate estimates of the final implementation Quality of Results without executing FPGA design flows. We trained and tested our model for Xilinx Zynq Ultrascale+ and Kintex-7 devices. We achieved an average prediction error of less than 9% and 4% for stages one and two, respectively.
C1 [Goswami, Pingakshya; Shahshahani, Masoud; Bhatia, Dinesh] Univ Texas Dallas, Dept Elect Engn, Richarson, TX 75080 USA.
RP Goswami, P (corresponding author), Univ Texas Dallas, Dept Elect Engn, Richarson, TX 75080 USA.
EM pingakshya.goswami@utdallas.edu; masoud.shahshahani@utdallas.edu;
   dinesh@utdallas.edu
CR [Anonymous], 2021, COMETML
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Makrani HM, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P727, DOI 10.1145/3287624.3288756
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   Meeuws R., 2011, 2011 International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS XI), P140, DOI 10.1109/SAMOS.2011.6045455
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   pytorch, PYTORCH
   Shahshahani M, 2021, I CONF VLSI DESIGN, P322, DOI 10.1109/VLSID51830.2021.00060
   tensorflow, TENSORFLOW
   XGBoost, 2021, XGBOOST DOCUMENTATIO
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
   Ye H., 2020, HYBRIDDNN FRAMEWORK
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao JR, 2017, ICCAD-IEEE ACM INT, P430, DOI 10.1109/ICCAD.2017.8203809
   Zuo W., 2013, P ACMSIGDA FPGA
NR 17
TC 1
Z9 1
U1 1
U2 4
PY 2022
BP 144
EP 149
DI 10.1109/VLSID2022.2022.00038
UT WOS:000861447800026
DA 2023-11-16
ER

PT C
AU Abdelsalam, AM
   Elsheikh, A
   David, JP
   Langlois, JMP
AF Abdelsalam, Ahmed M.
   Elsheikh, Ahmed
   David, Jean-Pierre
   Langlois, J. M. Pierre
GP IEEE
TI POLYBiNN: A Scalable and Efficient Combinatorial Inference Engine for
   Neural Networks on FPGA
SO 2018 CONFERENCE ON DESIGN AND ARCHITECTURES FOR SIGNAL AND IMAGE
   PROCESSING (DASIP)
SE Conference on Design and Architectures for Signal and Image Processing
DT Proceedings Paper
CT 12th Conference on Design and Architectures for Signal and Image
   Processing (DASIP)
CY OCT 10-12, 2018
CL Porto, PORTUGAL
DE Deep Learning; FPGAs; Decision Trees; Hardware Accelerators; Binary
   Classifiers
AB Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) have gained significant popularity in several classification and regression applications. The massive computation and memory requirements of deep NN architectures pose particular challenges for their FPGA implementation. Moreover, programming FPGAs requires hardware-specific knowledge that many machine-learning researchers do not possess. To make the power and versatility of FPGAs available to a wider deep learning user community and to improve DNN design efficiency, we introduce POLYBiNN, a scalable and efficient combinatorial inference engine for DNNs and CNNs. POLYBiNN is composed of a stack of decision trees, which are binary classifiers by nature, and utilizes AND-OR gates instead of multipliers and accumulators. POLYBiNN drastically cuts the hardware consumption down while maintaining high accuracy, and it is a memory free inference engine. We also propose a tool that generates automatically a low-level hardware description of the trained POLYBiNN for a given application. We evaluate POLYBiNN for the MNIST dataset when implemented in a ZYNQ-7000 ZC706 FPGA platform. The system achieves a throughput of up to 100 million image classifications per second with 90 ns latency on the MNIST dataset with 97.18% accuracy. The power consumption of PLOYBiNN is less than 1.2 W. We also show how POLYBiNN can be used in the fully connected layers of a CNN and apply this approach to the CIFAR-10 dataset.
C1 [Abdelsalam, Ahmed M.; Langlois, J. M. Pierre] Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
   [Elsheikh, Ahmed] Polytech Montreal, Dept Math & Ind Engn, Montreal, PQ, Canada.
   [David, Jean-Pierre] Polytech Montreal, Dept Elect Engn, Montreal, PQ, Canada.
RP Abdelsalam, AM (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM ahmed.abdelsalam@polymtl.ca; ahmed.elsheikh@polymtl.ca;
   jean-pierre.david@polymtl.ca; pierre.langlois@polymtl.ca
CR Akers S. B., 1978, IEEE T COMPUTERS
   Alemdar H., 2017, IEEE INT JOINT C NEU
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], 1998, P IEEE
   [Anonymous], 2016, ICLR
   Cheng Y., 2017, 171009282 ARXIV
   Courbariaux M., 2016, 160202830 ARXIV
   Deng L., 2017, 170509283 ARXIV
   Duda R.O., 2012, PATTERN CLASSIFICATI
   Hunter D., 2012, IEEE T IND INFORM
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   LeCun Yann, 2015, NATURE
   Lorena A. C., 2008, ARTIFICIAL INTELLIGE
   Misra J., 2010, NEUROCOMPUTING
   Nakahara H., 2017, IEEE INT C FIELD PRO
   Nurvitadhi E., 2017, ACM SIGDA INT S FIEL
   Rastegari M., 2016, SPRING EUR C COMP VI
   Robert C., 2014, MACHINE LEARNING PRO
   Struharik J.R., 2011, IEEE INT S INT SYST
   Sze V., 2017, P IEEE
   Tang P. T. P., 1991, IEEE S COMP AR JUN
   Umuroglu Y., 2017, ACM SIGDA INT S FIEL
   Zhao R., 2017, ACM SIGDA INT S FIEL
NR 23
TC 3
Z9 3
U1 0
U2 2
PY 2018
BP 19
EP 24
UT WOS:000459877300004
DA 2023-11-16
ER

PT C
AU Seal, SK
   Lim, SH
   Wang, DL
   Hinkle, J
   Lunga, D
   Tsaris, A
AF Seal, Sudip K.
   Lim, Seung-Hwan
   Wang, Dali
   Hinkle, Jacob
   Lunga, Dalton
   Tsaris, Aristeidis
GP ACM
TI Toward Large-Scale Image Segmentation on Summit
SO PROCEEDINGS OF THE 49TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING,
   ICPP 2020
SE Proceedings of the International Conference on Parallel Processing
DT Proceedings Paper
CT 49th International Conference on Parallel Processing (ICPP)
CY AUG 17-20, 2020
CL Edmonton, CANADA
DE applied machine learning; scalable data analytics; deep neural networks;
   model parallel; image segmentation; U-Net; pipeline
AB Semantic segmentation of images is an important computer vision task that emerges in a variety of application domains such as medical imaging, robotic vision and autonomous vehicles to name a few. While these domain-specific image analysis tasks involve relatively small image sizes (similar to 10(2) x 10(2)), there are many applications that need to train machine learning models on image data with extents that are orders of magnitude larger (similar to 10(4) x 10(4)). Training deep neural network (DNN) models on large extent images is extremely memory-intensive and often exceeds the memory limitations of a single graphical processing unit, a hardware accelerator of choice for computer vision workloads. Here, an efficient, sample parallel approach to train U-Net models on large extent image data sets is presented. Its advantages and limitations are analyzed and near-linear strong-scaling speedup demonstrated on 256 nodes (1536 GPUs) of the Summit supercomputer. Using a single node of the Summit supercomputer, an early evaluation of a recently released model parallel framework called GPipe is demonstrated to deliver similar to 2X speedup in executing a U-Net model with an order of magnitude larger number of trainable parameters than reported before. Performance bottlenecks for pipelined training of U-Net models are identified and mitigation strategies to improve the speedups are discussed. Together, these results open up the possibility of combining both approaches into a unified scalable pipelined and data parallel algorithm to efficiently train U-Net models with very large receptive fields on data sets of ultra-large extent images.
C1 [Seal, Sudip K.; Lim, Seung-Hwan] Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN 37830 USA.
   [Wang, Dali] Oak Ridge Natl Lab, Environm Sci Div, Oak Ridge, TN USA.
   [Hinkle, Jacob] Oak Ridge Natl Lab, Computat Sci & Engn Div, Oak Ridge, TN USA.
   [Lunga, Dalton] Oak Ridge Natl Lab, Natl Secur Emerging Technol, Oak Ridge, TN USA.
   [Tsaris, Aristeidis] Oak Ridge Natl Lab, Natl Ctr Computat Sci, Oak Ridge, TN USA.
RP Seal, SK (corresponding author), Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN 37830 USA.
CR Chen TQ, 2016, Arxiv, DOI [arXiv:1604.06174, DOI 10.48550/ARXIV.1604.06174]
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Dryden N, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356207
   Huang Yanping, 2019, 33 C NEUR INF PROC S
   Kim C, 2020, Arxiv, DOI arXiv:2004.09910
   Luo WJ, 2016, ADV NEUR IN, V29
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shazeer Noam, 2018, 32RD C NEUR INF PROC
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 12
TC 1
Z9 1
U1 0
U2 0
PY 2020
AR 27
DI 10.1145/3404397.3404468
UT WOS:001062717800071
DA 2023-11-16
ER

PT J
AU Cruz-Chú, ER
   Hosseinizadeh, A
   Mashayekhi, G
   Fung, R
   Ourmazd, A
   Schwander, P
AF Cruz-Chu, Eduardo R.
   Hosseinizadeh, Ahmad
   Mashayekhi, Ghoncheh
   Fung, Russell
   Ourmazd, Abbas
   Schwander, Peter
TI Selecting XFEL single-particle snapshots by geometric machine learning
SO STRUCTURAL DYNAMICS-US
DT Article
ID IMAGING EXPERIMENTS; MAXIMUM-LIKELIHOOD; ALGORITHMS; CLASSIFICATION;
   PERSPECTIVES; SYMMETRIES
AB A promising new route for structural biology is single-particle imaging with an X-ray Free-Electron Laser (XFEL). This method has the advantage that the samples do not require crystallization and can be examined at room temperature. However, high-resolution structures can only be obtained from a sufficiently large number of diffraction patterns of individual molecules, so-called single particles. Here, we present a method that allows for efficient identification of single particles in very large XFEL datasets, operates at low signal levels, and is tolerant to background. This method uses supervised Geometric Machine Learning (GML) to extract low-dimensional feature vectors from a training dataset, fuse test datasets into the feature space of training datasets, and separate the data into binary distributions of "single particles" and "non-single particles." As a proof of principle, we tested simulated and experimental datasets of the Coliphage PR772 virus. We created a training dataset and classified three types of test datasets: First, a noise-free simulated test dataset, which gave near perfect separation. Second, simulated test datasets that were modified to reflect different levels of photon counts and background noise. These modified datasets were used to quantify the predictive limits of our approach. Third, an experimental dataset collected at the Stanford Linear Accelerator Center. The single-particle identification for this experimental dataset was compared with previously published results and it was found that GML covers a wide photon-count range, outperforming other single-particle identification methods. Moreover, a major advantage of GML is its ability to retrieve single particles in the presence of structural variability.
C1 [Cruz-Chu, Eduardo R.; Hosseinizadeh, Ahmad; Mashayekhi, Ghoncheh; Fung, Russell; Ourmazd, Abbas; Schwander, Peter] Univ Wisconsin, Dept Phys, 3135 N Maryland Ave, Milwaukee, WI 53211 USA.
RP Schwander, P (corresponding author), Univ Wisconsin, Dept Phys, 3135 N Maryland Ave, Milwaukee, WI 53211 USA.
EM pschwan@uwm.edu
CR Allahgholi A, 2019, J SYNCHROTRON RADIAT, V26, P74, DOI 10.1107/S1600577518016077
   Aquila A, 2015, STRUCT DYNAM-US, V2, DOI 10.1063/1.4918726
   Assalauova D., 2020, ARXIV200608345
   Ayyer K, 2016, J APPL CRYSTALLOGR, V49, P1320, DOI 10.1107/S1600576716008165
   Ayyer K, 2015, STRUCT DYNAM-US, V2, DOI 10.1063/1.4919301
   Bielecki J, 2020, STRUCT DYNAM-US, V7, DOI 10.1063/4.0000024
   Bobkov SA, 2015, J SYNCHROTRON RADIAT, V22, P1345, DOI 10.1107/S1600577515017348
   Bogan MJ, 2008, NANO LETT, V8, P310, DOI 10.1021/nl072728k
   Bohne S, 2019, REV SCI INSTRUM, V90, DOI 10.1063/1.5080428
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Damiani D, 2016, J APPL CRYSTALLOGR, V49, P672, DOI 10.1107/S1600576716004349
   Daurer BJ, 2016, J APPL CRYSTALLOGR, V49, P1042, DOI 10.1107/S1600576716005926
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DePonte DP, 2008, J PHYS D APPL PHYS, V41, DOI 10.1088/0022-3727/41/19/195505
   Ekeberg T, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.098102
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferguson AL, 2010, P NATL ACAD SCI USA, V107, P13597, DOI 10.1073/pnas.1003293107
   FIENUP JR, 1982, APPL OPTICS, V21, P2758, DOI 10.1364/AO.21.002758
   Fung R, 2020, LANCET DIGIT HEALTH, V2, pE368, DOI 10.1016/S2589-7500(20)30131-X
   Giannakis D, 2012, OPT EXPRESS, V20, P12799, DOI 10.1364/OE.20.012799
   Gisriel C, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12955-3
   Halavanau A, 2019, J SYNCHROTRON RADIAT, V26, P635, DOI 10.1107/S1600577519002492
   Hosseinizadeh A, 2015, STRUCT DYNAM-US, V2, DOI 10.1063/1.4919740
   Hosseinizadeh A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0326
   Hosseinizadeh A, 2017, NAT METHODS, V14, P877, DOI [10.1038/NMETH.4395, 10.1038/nmeth.4395]
   Ignatenko A., 2020, ARXIV200807288
   Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223
   Loh ND, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.225501
   Loh NTD, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.026705
   Lundholm IV, 2018, IUCRJ, V5, P531, DOI 10.1107/S2052252518010047
   Maia FRNC, 2012, NAT METHODS, V9, P854, DOI 10.1038/nmeth.2110
   Marchesini S, 2003, PHYS REV B, V68, DOI 10.1103/PhysRevB.68.140101
   Munke A, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.64
   Pandey S, 2020, NAT METHODS, V17, P73, DOI 10.1038/s41592-019-0628-z
   Peplow M, 2017, NATURE, V544, P408, DOI 10.1038/544408a
   Poudyal I, 2020, STRUCT DYN-US, V7, DOI 10.1063/1.5144516
   Reddy HKN, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.79
   Rose M, 2018, IUCRJ, V5, P727, DOI 10.1107/S205225251801120X
   Scheres SHW, 2005, J MOL BIOL, V348, P139, DOI 10.1016/j.jmb.2005.02.031
   Schwander P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0567
   Schwander P, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/3/035007
   Schwander P, 2012, OPT EXPRESS, V20, P12827, DOI 10.1364/OE.20.012827
   Shi YC, 2019, IUCRJ, V6, P331, DOI 10.1107/S2052252519001854
   Sobolev E, 2020, COMMUN PHYS-UK, V3, DOI 10.1038/s42005-020-0362-y
   Spence JCH, 2012, REP PROG PHYS, V75, DOI 10.1088/0034-4885/75/10/102601
   Strüder L, 2010, NUCL INSTRUM METH A, V614, P483, DOI 10.1016/j.nima.2009.12.053
   Yoon CH, 2011, OPT EXPRESS, V19, P16542, DOI 10.1364/OE.19.016542
   Zimmermann J, 2019, PHYS REV E, V99, DOI 10.1103/PhysRevE.99.063309
NR 48
TC 5
Z9 5
U1 1
U2 7
PD JAN
PY 2021
VL 8
IS 1
AR 014701
DI 10.1063/4.0000060
UT WOS:000630134900001
DA 2023-11-16
ER

PT C
AU Zhao, M
   Agarwal, N
   Basant, A
   Gedik, B
   Pan, S
   Ozdal, M
   Komuravelli, R
   Pan, J
   Bao, TS
   Lu, HW
   Narayanan, S
   Langman, J
   Wilfong, K
   Rastogi, H
   Wu, CJ
   Kozyrakis, C
   Pol, P
AF Zhao, Mark
   Agarwal, Niket
   Basant, Aarti
   Gedik, Bugra
   Pan, Satadru
   Ozdal, Mustafa
   Komuravelli, Rakesh
   Pan, Jerry
   Bao, Tianshu
   Lu, Haowei
   Narayanan, Sundaram
   Langman, Jack
   Wilfong, Kevin
   Rastogi, Harsha
   Wu, Carole-Jean
   Kozyrakis, Christos
   Pol, Parik
GP ACM
TI Understanding Data Storage and Ingestion for Large-Scale Deep
   Recommendation Model Training
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
DE Machine learning systems; databases; distributed systems; data
   ingestion; data storage
AB Datacenter-scale AI training clusters consisting of thousands of domain-specific accelerators (DSA) are used to train increasingly-complex deep learning models. These clusters rely on a data storage and ingestion (DSI) pipeline, responsible for storing exabytes of training data and serving it at tens of terabytes per second. As DSAs continue to push training efficiency and throughput, the DSI pipeline is becoming the dominating factor that constrains the overall training performance and capacity. Innovations that improve the efficiency and performance of DSI systems and hardware are urgent, demanding a deep understanding of DSI characteristics and infrastructure at scale.
   This paper presents Meta's end-to-end DSI pipeline, composed of a central data warehouse built on distributed storage and a Data PreProcessing Service that scales to eliminate data stalls. We characterize how hundreds of models are collaboratively trained across geo-distributed datacenters via diverse and continuous training jobs. These training jobs read and heavily filter massive and evolving datasets, resulting in popular features and samples used across training jobs. We measure the intense network, memory, and compute resources required by each training job to preprocess samples during training. Finally, we synthesize key takeaways based on our production infrastructure characterization. These include identifying hardware bottlenecks, discussing opportunities for heterogeneous DSI hardware, motivating research in datacenter scheduling and benchmark datasets, and assimilating lessons learned in optimizing DSI infrastructure.
C1 [Zhao, Mark; Agarwal, Niket; Basant, Aarti; Gedik, Bugra; Pan, Satadru; Ozdal, Mustafa; Komuravelli, Rakesh; Pan, Jerry; Bao, Tianshu; Lu, Haowei; Narayanan, Sundaram; Langman, Jack; Wilfong, Kevin; Rastogi, Harsha; Wu, Carole-Jean; Pol, Parik] Meta, Menlo Pk, CA 94025 USA.
   [Kozyrakis, Christos] Stanford Univ, Stanford, CA USA.
RP Zhao, M (corresponding author), Meta, Menlo Pk, CA 94025 USA.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Acun B, 2021, INT S HIGH PERF COMP, P802, DOI 10.1109/HPCA51647.2021.00072
   Agrawal P, 2019, INT CONF MANAGE DATA, P1803, DOI 10.1145/3299869.3314050
   Akidau T, 2015, PROC VLDB ENDOW, V8, P1792
   [Anonymous], 2008, OSDI 08
   [Anonymous], 2022, MILAN CORES AMD
   [Anonymous], 2022, MODULE TF DATA EXPT
   [Anonymous], 2022, INTRO RES SUPERCLUST
   [Anonymous], 2022, DATASETS DEEP LEARNI
   [Anonymous], 2022, ENTERPRISE FEATURE S
   [Anonymous], 2022, VELOX
   [Anonymous], 2022, TORCHARROW
   [Anonymous], 2020, MLSYS
   [Anonymous], 2022, TFRECORD
   [Anonymous], 2022, PERSISTENT KEY VALUE
   [Anonymous], 2022, DOWNLOAD CRITEO 1TB
   Apache arrow, US
   Apache Avro, 2022, US
   Apache ORC, 2022, US
   Apache Parquet, 2022, US
   Armbrust M, 2020, PROC VLDB ENDOW, V13, P3411, DOI 10.14778/3415478.3415560
   AWS, 2022, AWS EC2 TRN1 INST
   Barroso Luiz Andre, 2018, SYNTHESIS LECT COMPU, V13, pi
   Carole-JeanWu Robin, 2020, ARXIV
   Chen DH, 2016, INT SYM CODE GENER, P12, DOI 10.1145/2854038.2854044
   Choi D, 2020, ARXIV
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dageville B, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P215, DOI 10.1145/2882903.2903741
   DALI, 2022, SUPP OP
   Das T., 2012, PROC 9 USENIX S NETW, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dunn J., 2016, INTRO FBLEARNER FLOW
   Farrington N, 2013, OPT INTERCONNECT C, P49
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Habana, 2022, HAB HOM
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He X., 2014, P 8 INT WORKSHOP DAT, P1, DOI [DOI 10.1145/2648584.2648589, 10.1145/2648584.2648589]
   Jiarui Fang, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P389, DOI 10.1145/3437801.3441578
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kakaraparthy A., 2019, P 11 USENIX WORKSH H
   Kanev S, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P158, DOI 10.1145/2749469.2750392
   Karpathiotakis Manolis, 2019, SCRIBE TRANSPORTING
   Kaufman S, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382579
   Knowles S., 2021, 2021 IEEE HOT CHIPS, P1
   Krizhevsky A., 2014, ARXIV
   Kumar AV, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P283
   Kumar S, 2021, ARXIV
   Lee G, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P537
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Maeng Kiwan, 2021, P MACHINE LEARNING S, V3, P637
   Marchukov Mark, 2017, LOGDEVICE DISTRIBUTE
   Medvedev I., 2019, POWERED INSTAGRAMS E
   Melnik S, 2010, PROC VLDB ENDOW, V3, P330
   MLCommons, 2021, MLPERF TRAIN V1 1 RE
   Mohan Jayashree, PROC VLDB ENDOW
   Moore Samuel, 2021, HERES GOOGLES TPU V4
   Mudigere Dheevatsa, 2022, 2022 ACM IEEE 49 ANN
   Murray DG, 2021, PROC VLDB ENDOW, V14, P2945, DOI 10.14778/3476311.3476374
   Murray DG, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P439, DOI 10.1145/2517349.2522738
   Nakandala S, 2020, PROC VLDB ENDOW, V13, P2159, DOI 10.14778/3407790.3407816
   Naumov Maxim, ARXIV
   NVIDIA, 2021, DAT LOAD LIB DALI
   Pan Satadru, 19 USENIX C FILE STO, P217
   Paszke A, 2019, ADV NEUR IN, V32
   Petrov Alexander, 2020, SCAL 2020 MAST COOK
   Prabhakar R., 2021, HOT CHIPS, P1, DOI DOI 10.1109/HCS52781.2021.9567250
   Roy A, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P123, DOI 10.1145/2785956.2787472
   Ruder S., OVERVIEW GRADIENT DE, DOI DOI 10.48550/ARXIV.1609.04747
   Sethi Geet, 2022, P 27 ACM INT C ARCHI
   Sethi R, 2019, PROC INT CONF DATA, P1802, DOI 10.1109/ICDE.2019.00196
   SINGH A, 2015, COMPUT COMMUN REV, P15
   Sriraman A, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P733, DOI 10.1145/3373376.3378450
   TensTorrent, 2022, TENST
   Tesla, 2022, TESL ART INT
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Wang LP, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404472
   Wang Yu, 2020, P MACHINE LEARNING S, V2, P30
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Xin D, 2021, INT CONF MANAGE DATA, P2639, DOI 10.1145/3448016.3457566
   Yang CC, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P235, DOI 10.1109/HiPC.2019.00037
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zhang Cyril, 2020, ADV NEURAL INFORM PR, V33, P10282
   Zhao WJ, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P319, DOI 10.1145/3357384.3358045
   Zhu Y, 2019, IEEE INT C CL COMP, P34, DOI 10.1109/cluster.2019.8891023
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
NR 88
TC 1
Z9 1
U1 1
U2 1
PY 2022
BP 1042
EP 1057
DI 10.1145/3470496.3533044
UT WOS:000852702500072
DA 2023-11-16
ER

PT J
AU Kaspi, O
   Israelsohn-Azulay, O
   Zidon, Y
   Rosengarten, H
   Krmpotic, M
   Gouasmia, S
   Radovic, IB
   Jalkanen, P
   Liski, A
   Mizohata, K
   Räisänen, J
   Girshevitz, O
   Senderowitz, H
AF Kaspi, Omer
   Israelsohn-Azulay, Osnat
   Zidon, Yigal
   Rosengarten, Hila
   Krmpotic, Matea
   Gouasmia, Sabrina
   Radovic, Iva Bogdanovic
   Jalkanen, Pasi
   Liski, Anna
   Mizohata, Kenichiro
   Raisanen, Jyrki
   Girshevitz, Olga
   Senderowitz, Hanoch
TI Inter-laboratory workflow for forensic applications: Classification of
   car glass fragments
SO FORENSIC SCIENCE INTERNATIONAL
DT Article
DE PIXE; Car window glass fragments; Machine Learning; Forensics
ID REFRACTIVE-INDEX
AB The International Atomic Energy Agency (IAEA) has coordinated a research project titled "Enhancing Nuclear Analytical Techniques to Meet the Needs of Forensics Sciences" (CRP F11021) with the aim of empowering accelerator and reactor based techniques for applications in forensic sciences. One of the key topics of this project was the analysis and classification of forensic glass specimens using Ion Beam Analysis (IBA) techniques and in particular, Particle Induced X-ray Emission (PIXE).
   To this end, glass fragments from car windows from different car models and manufacturers provided by the Israeli police force were subjected to PIXE measurements at three laboratories to determine their elemental compositions and possible glass corrosion. Major and trace elements were measured and given as an input to machine learning (ML) algorithms in order to develop classification models to determine the origin of the glass samples.
   First, we have developed ML models based on the results obtained at each lab. These models successfully classified glass fragments into different car models with an accuracy > 80% on external test sets. Next, we demonstrated that following an appropriate pre-processing step, results from different labs could be combined into a single unified database for the derivation of a classification model. This model demonstrates good performances that matches or surpasses the performances of models derived from the individual labs. This finding paves the way towards establishing an international database that is composed of measurements from various PIXE labs. We believe that using this methodology of combining various sources of measurements will improve models' performances and generality and will make the models accessible to law enforcement agencies around the world. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Kaspi, Omer; Senderowitz, Hanoch] Bar Ilan Univ, Dept Chem, IL-5290002 Ramat Gan, Israel.
   [Israelsohn-Azulay, Osnat; Zidon, Yigal; Rosengarten, Hila] Israel Police HQ, Toolmarks & Mat Lab, Tel Aviv, Israel.
   [Krmpotic, Matea; Gouasmia, Sabrina; Radovic, Iva Bogdanovic] Rudjer Boskovic Inst, Div Expt Phys, Lab Ion Beam Interact, Bijenicka Cesta 54, HR-10000 Zagreb, Croatia.
   [Jalkanen, Pasi; Liski, Anna; Mizohata, Kenichiro; Raisanen, Jyrki] Univ Helsinki, Dept Phys, POB 43, FI-00014 Helsinki, Finland.
   [Girshevitz, Olga] Bar Ilan Univ, Bar Ilan Inst Nanotechnol & Adv Mat, IL-5290002 Ramat Gan, Israel.
RP Senderowitz, H (corresponding author), Bar Ilan Univ, Dept Chem, IL-5290002 Ramat Gan, Israel.; Girshevitz, O (corresponding author), Bar Ilan Univ, Bar Ilan Inst Nanotechnol & Adv Mat, IL-5290002 Ramat Gan, Israel.
EM Olga.Girshevitz@biu.ac.il; Hanoch.Senderowitz@biu.ac.il
CR Aitken CGG, 2006, COMPUT STAT DATA AN, V50, P2571, DOI 10.1016/j.csda.2005.04.005
   Aitken CGG, 2004, J ROY STAT SOC C, V53, P109, DOI 10.1046/j.0035-9254.2003.05271.x
   Aitken CGG, 2007, J FORENSIC SCI, V52, P412, DOI 10.1111/j.1556-4029.2006.00358.x
   Caddy B., 2001, FORENSIC EXAMINATION
   Civici N, 2013, ROM REP PHYS, V65, P1265
   Embrechts P., 1996, MW J AM STAT ASS, V91
   Erlich Y, 2018, SCIENCE, V362, P690, DOI 10.1126/science.aau4832
   Han Liu, 2019, Journal of Non-Crystalline Solids: X, V4, P43, DOI 10.1016/j.nocx.2019.100036
   Iqbal S.A. A. Salman, 2016, INTECHOPEN NO FORENS, P13
   Kaspi O, 2021, TALANTA, V234, DOI 10.1016/j.talanta.2021.122608
   Kraus MA, 2020, GLASS STRUCT ENG, V5, P247, DOI 10.1007/s40940-020-00132-8
   Maxwell V. M., 2001, J FORENSIC IDENT, V51, P597
   Park S, 2019, FORENSIC SCI INT, V305, DOI 10.1016/j.forsciint.2019.110003
   Park S, 2019, ANN APPL STAT, V13, P1068, DOI 10.1214/18-AOAS1211
   Pawluk-Kolc M, 2008, FORENSIC SCI INT, V174, P222, DOI 10.1016/j.forsciint.2007.04.229
   Pawluk-Kolc M, 2006, FORENSIC SCI INT, V160, P53, DOI 10.1016/j.forsciint.2005.08.016
   Pfaender H.G., 2012, SCHOTT GUIDE GLASS
   Rossy Q, 2013, FORENSIC SCI INT, V230, P137, DOI 10.1016/j.forsciint.2012.10.010
   Scholes S. R., 1975, MODERN GLASS PRACTIC, V7th ed.
   Stone J.V., 2018, INDEP COMPON ANAL, DOI [10.7551/mitpress/3717.003.0017, DOI 10.7551/MITPRESS/3717.003.0017]
   Tallón-Ballesteros AJ, 2014, STUD COMPUT INTELL, V555, P413, DOI 10.1007/978-3-319-05885-6_17
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Zadora G., 2001, Z ZAGADNIEN NAUK SAD, V45, P36
NR 24
TC 5
Z9 5
U1 1
U2 7
PD APR
PY 2022
VL 333
AR 111216
DI 10.1016/j.forsciint.2022.111216
EA FEB 2022
UT WOS:000820862500004
DA 2023-11-16
ER

PT J
AU Yang, YS
   Gong, NY
   Xie, KY
   Liu, QF
AF Yang, Yushan
   Gong, Nuoya
   Xie, Keying
   Liu, Qingfei
TI Predicting Gasoline Vehicle Fuel Consumption in Energy and Environmental
   Impact Based on Machine Learning and Multidimensional Big Data
SO ENERGIES
DT Article
DE fuel consumption; energy and environmental; machine learning
ID DRIVER BEHAVIOR; CO2 EMISSIONS; MODELS; TORQUE
AB The underestimation of fuel consumption impacts various aspects. In the vehicle market, manufacturers often advertise fuel economy for marketing. In fact, the fuel consumption reference value provided by the manufacturer is quite different from the real-world fuel consumption of the vehicles. The divergence between reference fuel consumption and real-world fuel consumption also has negative effect on the aspects of policy and environment. In order to effectively promote the sustainable development of transport, it is urged to recognize the real-world fuel consumption of vehicles. The gaps in previous studies includes small sample size, single data dimension, and lack of feature weight evaluation. To fill the research gap, in this study, we conduct a comparative analysis through building five regression models to forecast the real-world fuel consumption rate of light-duty gasoline vehicles in China based on big data from the perspectives of vehicle factors, environment factors, and driving behavior factors. Results show that the random forest regression model performs best among the five candidate models, with a mean absolute error of 0.630 L/100 km, a mean absolute percentage error of 7.5%, a mean squared error of 0.805, an R squared of 0.776, and a 10-fold cross-validation score of 0.791. Further, we capture the most important features affecting fuel consumption among the 25 factors from the above three perspectives. According to the relative weight of each factor in the most optimal model, the three most important factors are brake and accelerator habits, engine power, and the fuel economy consciousness of vehicle owners in sequence.
C1 [Yang, Yushan] Beijing Univ Posts & Telecommun, Sch Econ & Management, Beijing 100876, Peoples R China.
   [Gong, Nuoya] Beijing Int Studies Univ, Coll Japanese, Beijing 100024, Peoples R China.
   [Xie, Keying] Beijing Wuzi Univ, Sch Econ, Beijing 101149, Peoples R China.
   [Xie, Keying] Beijing Inst Fash Technol, Sch Fash Commun, Beijing 100029, Peoples R China.
   [Liu, Qingfei] Natl Univ Def Technol, Undergrad Sch, Changsha 410073, Peoples R China.
RP Liu, QF (corresponding author), Natl Univ Def Technol, Undergrad Sch, Changsha 410073, Peoples R China.
EM yangyushan@bupt.edu.cn; 2020220207@stu.bisu.edu.cn;
   2019103026@bwu.edu.cn; shenliulei12@nudt.edu.cn
CR Agarap AF, 2018, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1803.08375
   Ahn KG, 2008, TRANSPORT RES D-TR E, V13, P151, DOI 10.1016/j.trd.2008.01.005
   Barth Matthew, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P684, DOI 10.1109/ITSC.2007.4357672
   Ben Dror M, 2019, ENERG POLICY, V128, P8, DOI 10.1016/j.enpol.2018.12.039
   Ben-Chaim M, 2013, ENERGIES, V6, P117, DOI 10.3390/en6010117
   Biggs D., 1988, ARFCOM MODELS ESTIMA
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chen KD, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063199
   Christoffersen P, 2004, J FINANC ECON, V72, P291, DOI 10.1016/j.jfineco.2003.02.001
   Duarte GO, 2016, TRANSPORT RES D-TR E, V44, P43, DOI 10.1016/j.trd.2016.02.009
   Ehsani M, 2016, RENEW SUST ENERG REV, V53, P1638, DOI 10.1016/j.rser.2015.08.062
   EI-Shawarby I, 2005, TRANSPORT RES D-TR E, V10, P13, DOI 10.1016/j.trd.2004.09.002
   Ericsson E, 2001, TRANSPORT RES D-TR E, V6, P325, DOI 10.1016/S1361-9209(01)00003-7
   EVANS L, 1979, HUM FACTORS, V21, P389, DOI 10.1177/001872087902100401
   Fontaras G, 2017, PROG ENERG COMBUST, V60, P97, DOI 10.1016/j.pecs.2016.12.004
   Gao YC, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12041492
   Greenwood ID, 2007, J TRANSP ENG-ASCE, V133, P96, DOI 10.1061/(ASCE)0733-947X(2007)133:2(96)
   Haworth N., 2001, P AUSTR ROAD SAF RES
   He CR, 2016, J COMPUT NONLIN DYN, V11, DOI 10.1115/1.4033895
   Hjellvik MA, 2019, IN C IND ENG ENG MAN, P1067, DOI [10.1109/ieem44572.2019.8978605, 10.1109/IEEM44572.2019.8978605]
   HOOKER JN, 1988, TRANSPORT RES A-POL, V22, P183, DOI 10.1016/0191-2607(88)90036-2
   Jahirul M., 2009, INT J MECH MATER ENG, V4, P249
   Joumard R., 1995, 01487191 SAE INT, DOI [10.4271/950928, DOI 10.4271/950928]
   Kamal MAS, 2011, IEEE T INTELL TRANSP, V12, P783, DOI 10.1109/TITS.2011.2112648
   Karagöz Y, 2019, INT J HYDROGEN ENERG, V44, P31621, DOI 10.1016/j.ijhydene.2019.10.019
   Kashinath K, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0093
   Ke GL, 2017, ADV NEUR IN, V30
   Li YW, 2019, IEEE ACCESS, V7, P63395, DOI 10.1109/ACCESS.2019.2914378
   Liu Y., 2018, P SAE INT WCX WORLD, P1
   Luján JM, 2019, ENERG CONVERS MANAGE, V199, DOI 10.1016/j.enconman.2019.111987
   Masters T., 1993, PRACTICAL NEURAL NET
   McGrawHill, 1988, FUNDAMENTALS INTERNA
   Ostrouchov N., 1978, P SAE INT 1978 AUT E, P1
   Parlak A, 2006, APPL THERM ENG, V26, P824, DOI 10.1016/j.applthermaleng.2005.10.006
   Pavlovic J, 2016, APPL ENERG, V177, P661, DOI 10.1016/j.apenergy.2016.05.110
   Pekula N., 2003, SAE TRANSACTIONS, V112, P148
   Perrotta F, 2017, IEEE INT CONF BIG DA, P3810, DOI 10.1109/BigData.2017.8258382
   Ping P, 2019, IEEE ACCESS, V7, P78515, DOI 10.1109/ACCESS.2019.2920489
   Plotkin SE, 2001, ENERG POLICY, V29, P1073, DOI 10.1016/S0301-4215(01)00051-9
   Rahimi-Gorji M, 2017, J BRAZ SOC MECH SCI, V39, P375, DOI 10.1007/s40430-016-0539-1
   Rahman A, 2017, ENERG BUILDINGS, V152, P341, DOI 10.1016/j.enbuild.2017.07.017
   Redsell M., 1993, P I MECH ENG D-J AUT, DOI [10.1243/PIME_PROC_1993_207_155_02, DOI 10.1243/PIME_PROC_1993_207_155_02]
   Renouf M., 1979, PREDICTION FUEL CONS
   Sánchez M, 2006, 2006 6TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS PROCEEDINGS, P331, DOI 10.1109/ITST.2006.288906
   Silva CM, 2006, TRANSPORT RES D-TR E, V11, P377, DOI 10.1016/j.trd.2006.07.004
   Sriwardene A.S., 2016, P 2016 13 INT C EL E, P1
   Syahputra Ramadoni, 2016, Journal of Theoretical and Applied Information Technology, V86, P138
   Tietge U, 2017, ENERG POLICY, V103, P212, DOI 10.1016/j.enpol.2017.01.021
   Togun N, 2010, APPL ENERG, V87, P3401, DOI 10.1016/j.apenergy.2010.04.027
   Togun NK, 2010, APPL ENERG, V87, P349, DOI 10.1016/j.apenergy.2009.08.016
   Van Mierlo J, 2004, P I MECH ENG D-J AUT, V218, P43, DOI 10.1243/095440704322829155
   Walnum HJ, 2015, TRANSPORT RES D-TR E, V36, P107, DOI 10.1016/j.trd.2015.02.016
   Wang JH, 2016, APPL ENERG, V170, P394, DOI 10.1016/j.apenergy.2016.02.124
   Wang YC, 2020, FUEL, V278, DOI 10.1016/j.fuel.2020.118340
   Wickramanayake S, 2016, 2ND INTERNATIONAL MERCON 2016 MORATUWA ENGINEERING RESEARCH CONFERENCE, P90, DOI 10.1109/MERCon.2016.7480121
   Wu T, 2020, ENERGY, V190, DOI 10.1016/j.energy.2019.116388
   Yao Y, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/9263605
   Ying X, 2018, CHINA PERSPECT-SER, P1, DOI 10.1088/1742-6596/1168/2/022022
   Zeng IY, 2021, ENERGIES, V14, DOI 10.3390/en14237915
   Zhao X, 2022, RESOUR CONSERV RECY, V176, DOI 10.1016/j.resconrec.2021.105959
   Zhou BY, 2018, MITIG ADAPT STRAT GL, V23, P735, DOI 10.1007/s11027-017-9757-9
   Zhou M, 2016, TRANSPORT RES D-TR E, V49, P203, DOI 10.1016/j.trd.2016.09.008
   Ziólkowski J, 2021, ENERGIES, V14, DOI 10.3390/en14092639
   Zou FY, 2019, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2019.01138
NR 64
TC 4
Z9 4
U1 10
U2 31
PD MAR
PY 2022
VL 15
IS 5
AR 1602
DI 10.3390/en15051602
UT WOS:000768317500001
DA 2023-11-16
ER

PT J
AU Athreyas, N
   Song, W
   Perot, B
   Xia, QF
   Mathew, A
   Gupta, J
   Gupta, D
   Yang, JJ
AF Athreyas, Nihar
   Song, Wenhao
   Perot, Blair
   Xia, Qiangfei
   Mathew, Abbie
   Gupta, Jai
   Gupta, Dev
   Yang, J. Joshua
TI Memristor-CMOS Analog Coprocessor for Acceleration of High-Performance
   Computing Applications
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Analog coprocessor; crossbar; electronic design automation; hardware
   accelerator; machine vision; memristor; modeling and simulation; partial
   differential equations; PSpice systems option; vector matrix
   multiplication
AB Vector matrix multiplication computation underlies major applications in machine vision, deep learning, and scientific simulation. These applications require high computational speed and are run on platforms that are size, weight, and power constrained. With the transistor scaling coming to an end, existing digital hardware architectures will not be able to meet this increasing demand. Analog computation with its rich set of primitives and inherent parallel architecture can be faster, more efficient, and compact for some of these applications. One such primitive is a memristor-CMOS crossbar array-based vector matrix multiplication. In this article, we develop a memristor-CMOS analog coprocessor architecture that can handle floating-point computation. To demonstrate the working of the analog coprocessor at a system level, we use a new electronic design automation tool called PSpice Systems Option, which performs integrated cosimulation of MATLAB/Simulink and PSpice. It is shown that the analog coprocessor has a superior performance when compared to other processors, and a speedup of up to 12 x when compared to projected GPU performance is observed. Using the new PSpice Systems Option tool, various application simulations for image processing and solutions to partial differential equations are performed on the analog coprocessor model.
C1 [Athreyas, Nihar] Univ Massachusetts, Dept Elect & Comp Engn, Amherst & Spero Devices, 318 Codman Hill Rd,Apt 26E, Boxboro, MA 01719 USA.
   [Perot, Blair] Univ Massachusetts, Dept Mech Engn, Boxboro, MA 01719 USA.
   [Song, Wenhao; Xia, Qiangfei; Yang, J. Joshua] Univ Massachusetts, Dept Elect & Comp Engn, Boxboro, MA 01719 USA.
   [Mathew, Abbie; Gupta, Jai] Spero Devices, Acton, MA USA.
RP Athreyas, N (corresponding author), Univ Massachusetts, Dept Elect & Comp Engn, Amherst & Spero Devices, 318 Codman Hill Rd,Apt 26E, Boxboro, MA 01719 USA.
EM nathreya@umass.edu; wrong@umass.edu; perot@umass.edu; qxia@umass.edu;
   amathew@sperodevices.com; jgupta@sperodevices.com; jjyang@umass.edu
CR [Anonymous], 2011, 2011 DESIGN AUTOMATI
   [Anonymous], 2005, DIGITAL VIDEO QUALIT
   Athreyas N, 2019, J REAL-TIME IMAGE PR, V16, P1607, DOI 10.1007/s11554-017-0669-4
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   BOSER BE, 1991, IEEE J SOLID-ST CIRC, V26, P2017, DOI 10.1109/4.104196
   Chen P.-Y., 2015, IEEE DESIGN AUTOMATI
   Chi P., 2016, P INT S COMP ARCH IS
   Choi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10492
   Chua LO, 2012, P IEEE, V100, P1920, DOI 10.1109/JPROC.2012.2190814
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Chung F, 2000, J COMB THEORY A, V91, P191, DOI 10.1006/jcta.2000.3094
   De Simone F., 2008, SPIE OPTICS PHOTONIC
   Devereux V. G., 1989, Limiting of YUV digital video signals
   Dosselmann R, 2011, SIGNAL IMAGE VIDEO P, V5, P81, DOI 10.1007/s11760-009-0144-1
   Genov R, 2003, IEEE T NEURAL NETWOR, V14, P1426, DOI 10.1109/TNN.2003.816345
   Genov R, 2001, IEEE T CIRCUITS-II, V48, P930, DOI 10.1109/82.974781
   Gonzalez RC, 2002, DIGITAL IMAGE PROCES, Vsecond
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harpe P., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P472, DOI 10.1109/ISSCC.2012.6177096
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   Hu M., 2016, P DAC 53
   Jain AK, 1989, FUNDAMENTALS DIGITAL, P150
   Jiang H., 2016, SCI REPORTS, V6
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KUB FJ, 1990, IEEE J SOLID-ST CIRC, V25, P207, DOI 10.1109/4.50305
   Lewis D., 2004, DESIGNCON
   Lin WT, 2014, IEEE J SOLID-ST CIRC, V49, P708, DOI 10.1109/JSSC.2014.2301769
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Mitchell L., 1993, JPEG STILL IMAGE DAT
   Moon K. K., 1990, P IEEE CUST INT CIRC
   Nvidia, 2016, NVID TESL P100
   Pan X., 2011, ICMAT, V52, p[8, 1559]
   Parvizi M, 2016, IEEE T MICROW THEORY, V64, P1843, DOI 10.1109/TMTT.2016.2562003
   Shafiee A., P ISCA, P14
   Sheridan P. M., 2016, IEEE T NEURAL NETWOR, V27, p[11, 1]
   Sheridan P, 2014, IEEE INT SYMP CIRC S, P1078, DOI 10.1109/ISCAS.2014.6865326
   Sohmers T., 2017, REX NEOARCHITECTURE
   Stam J., P SIGGRAPH, P121
   Strachan JP, 2013, IEEE T ELECTRON DEV, V60, P2194, DOI 10.1109/TED.2013.2264476
   Tang H-Z, 2012, THESIS
   Vatanjou AA, 2015, PROCEEDINGS OF THE SIXTH ASIA SYMPOSIUM ON QUALITY ELECTRONIC DESIGN ASQED 2015, P7, DOI 10.1109/ACQED.2015.7273999
   Yang BD, 2015, IEEE T CIRCUITS-I, V62, P1564, DOI 10.1109/TCSI.2015.2418837
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang S, 2015, IEEE INT CONF COMMUN
   Yi Wei, 2014, NATURE COMMUNICATION, V7, P1
NR 45
TC 5
Z9 5
U1 2
U2 31
PD OCT
PY 2018
VL 14
IS 3
AR 38
DI 10.1145/3269985
UT WOS:000457140900007
DA 2023-11-16
ER

PT C
AU Moolchandani, D
   Kundu, J
   Ruelens, F
   Vrancx, P
   Evenblij, T
   Perumkunnil, M
AF Moolchandani, Diksha
   Kundu, Joyjit
   Ruelens, Frederik
   Vrancx, Peter
   Evenblij, Timon
   Perumkunnil, Manu
GP IEEE
TI AMPeD: An Analytical Model for Performance in Distributed Training of
   Transformers
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE, ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY APR 23-25, 2023
CL Raleigh, NC
AB Transformers are a class of machine learning models that have piqued high interest recently due to a multitude of reasons. They can process multiple modalities efficiently and have excellent scalability. Despite these obvious advantages, training these large models is very time-consuming. Hence, there have been efforts to speed up the training process using efficient distributed implementations. Many different types of parallelism have been identified that can be employed standalone or in combination. However, naively combining different parallelization schemes can incur significant communication overheads, thereby potentially defeating the purpose of distributed training. Thus, it becomes vital to predict the right mapping of different parallelisms to the underlying system architecture. In this work, we propose AMPeD, an analytical model for performance in distributed training of transformers. It exposes all the transformer model parameters, potential parallelism choices (along with their mapping onto the system), the accelerator as well as system architecture specifications as tunable knobs, thereby enabling hardware-software co-design. With the help of 3 case studies, we show that the combinations of parallelisms predicted to be efficient by AMPeD conform with the results from the state-of-the-art literature. Using AMPeD, we also show that future distributed systems consisting of optical communication substrates can train large models up to 4x faster as compared to the current state-of-the-art systems without modifying the peak computational power of the accelerators. Finally, we validate AMPeD with in-house experiments on real systems and via published literature. The max. observed error is limited to 12%. The model is available here: https://github.com/CSA-infra/AMPeD
C1 [Moolchandani, Diksha; Kundu, Joyjit; Ruelens, Frederik; Vrancx, Peter; Evenblij, Timon; Perumkunnil, Manu] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
RP Moolchandani, D (corresponding author), Interuniv Microelect Ctr IMEC, Leuven, Belgium.
EM diksha.moolchandani@imec.be; joyjit.kundu@imec.be;
   frederik.ruelens@imec.be; peter.vrancx@imec.be; timon.evenblij@imec.be;
   manu.perumkunnil@imec.be
CR Arnab A., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.15691
   Bouzidi H, 2021, PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2021 (CF 2021), P54, DOI 10.1145/3457388.3458666
   Choquette J., 2022, 2022 IEEE HOT CHIPS, P1
   Du N., 2022, ICML
   G. V. Research, 2022, DEEP LEARN MARK SIZ
   Geoffrey X. Y., 2021, USENIX ATC, V21
   Gianniti E., 2018, SBAC PAD
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Gulati A, 2020, Arxiv, DOI [arXiv:2005.08100, DOI 10.48550/ARXIV.2005.08100]
   Harris N. C., 2022, 2022 IEEE HOT CHIPS, P1
   He JA, 2021, Arxiv, DOI arXiv:2103.13262
   Huang YP, 2019, Arxiv, DOI arXiv:1811.06965
   Karpathy A., 2022, MINGPT PYTORCH RE IM
   Kim C, 2020, Arxiv, DOI arXiv:2004.09910
   Krizhevsky A, 2014, Arxiv, DOI [arXiv:1404.5997, DOI 10.48550/ARXIV.1404.5997]
   Lepikhin D, 2020, Arxiv, DOI arXiv:2006.16668
   Lym S, 2019, INT SYM PERFORM ANAL, P293, DOI 10.1109/ISPASS.2019.00041
   Ma ZX, 2022, PPOPP'22: PROCEEDINGS OF THE 27TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P192, DOI 10.1145/3503221.3508417
   Moolchandani D., 2022, ACM T ARCHIT CODE OP, V19, P1
   Moralis-Pegios M, 2021, IET OPTOELECTRON, V15, P102, DOI 10.1049/ote2.12018
   Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Nvidia, 2022, OPT LIN FULL CONN LA
   NVIDIA, 2020, NVID A100 TENS COR G
   Pati S, 2022, I S WORKL CHAR PROC, P296, DOI 10.1109/IISWC55918.2022.00033
   Qi Hang, 2016, PALEO PERFORMANCE MO
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024
   Rashidi S, 2020, INT SYM PERFORM ANAL, P81, DOI 10.1109/ISPASS48437.2020.00018
   Shaheen Z, 2020, Arxiv, DOI [arXiv:2010.12871, 10.48550/arXiv.2010.12871]
   Keskar NS, 2017, Arxiv, DOI arXiv:1609.04836
   Van Campenhout J., 2021, 2021 ACMIEEE SLIP
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Wang Q, 2019, Arxiv, DOI [arXiv:1906.01787, DOI 10.48550/ARXIV.1906.01787]
   Wang XH, 2022, Arxiv, DOI arXiv:2110.05722
   Wolf T, 2020, Arxiv, DOI [arXiv:1910.03771, DOI 10.48550/ARXIV.1910.03771]
   Yan F, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1355, DOI 10.1145/2783258.2783270
   Yu M., 2022, ARXIV
   Zhang Y., 2012, IEEE ISORCW
NR 38
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 306
EP 315
DI 10.1109/ISPASS57527.2023.00037
UT WOS:001017781500028
DA 2023-11-16
ER

PT J
AU Liu, LB
   Wang, Q
   Zhu, WP
   Mo, HY
   Wang, TC
   Yin, SY
   Shi, YY
   Wei, SJ
AF Liu, Leibo
   Wang, Qiang
   Zhu, Wenping
   Mo, Huiyu
   Wang, Tianchen
   Yin, Shouyi
   Shi, Yiyu
   Wei, Shaojun
TI A Face Alignment Accelerator Based on Optimized Coarse-to-Fine Shape
   Searching
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
DT Article
DE Cascaded regression; face alignment; landmark detection
ID REGRESSION; ROBUST
AB The coarse-to-fine shape searching (CFSS) framework is a recently developed algorithm that achieves relatively high accuracy in face alignment by alleviating the poor initialization problem facing traditional cascaded regression approaches. However, its high computational complexity and memory access demands make it difficult for CFSS to satisfy the requirements of real-time processing. To address this issue, a fast shape searching face alignment (F-SSFA) accelerator is presented based on the optimization of the CFSS algorithm and an efficient hardware implementation. First, the learning-based low-dimensional speeded-up robust features method, based on the correlations between the SURF features and the regression targets, is introduced to distill the feature set down to the only most distinct features to reduce the computing load. Second, the partial keypoints Euclidean distance and shape affine transformation are introduced to replace feature extraction and support vector machine classification, thereby accelerating the shape searching process. Compared with CFSS, F-SSFA achieves a 5.8x speedup while achieving similar accuracy. Moreover, a VLSI architecture is proposed to realize the fixed-point F-SSFA algorithm. Multiple descriptors located in adjacent regions are simultaneously generated in a single access to the corresponding image data. Therefore, repeated memory access operations are avoided. The optimal parameter configuration for hardware implementation is also exploited based on a tradeoff between accuracy and hardware performance. Simulated with TSMC 65-nm 1P8M technology within a 3.6 mm(2) area, a post-layout simulation shows that 700 fps can be achieved while consuming 300 mW at 200 MHz.
C1 [Liu, Leibo; Wang, Qiang; Mo, Huiyu; Yin, Shouyi; Wei, Shaojun] Tsinghua Univ, Inst Microelect, Beijing 100084, Peoples R China.
   [Zhu, Wenping] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.
   [Wang, Tianchen; Shi, Yiyu] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Wang, Tianchen; Shi, Yiyu] Univ Notre Dame, Dept Elect Engn, Notre Dame, IN 46556 USA.
RP Zhu, WP (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.
EM zhuwp@semi.ac.cn
CR Alabort-i-Medina J, 2014, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2014.439
   An L, 2012, INT C PATT RECOG, P2885
   [Anonymous], FACIAL FEATURE POINT
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Bong K, 2017, ISSCC DIG TECH PAP I, P248, DOI 10.1109/ISSCC.2017.7870354
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Chen CR, 2011, IEEE T VLSI SYST, V19, P1937, DOI 10.1109/TVLSI.2010.2069575
   Chen HC, 2013, INTELL SYST SER, P1, DOI [10.1155/2013/213234, 10.1016/B978-0-12-404702-0.00001-X, 10.1007/978-3-642-38868-2_1]
   Chen PY, 2014, IEEE T INTELL TRANSP, V15, P656, DOI 10.1109/TITS.2013.2284666
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, P BRIT MACH VIS C, P1, DOI [DOI 10.5244/C.20.95.CITESEER, DOI 10.5244/C.20.95]
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Dongsuk Jeon, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC48, DOI 10.1109/VLSIC.2015.7231322
   Fan X, 2018, IEEE T MULTIMEDIA, V20, P567, DOI 10.1109/TMM.2017.2751143
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P145, DOI 10.1109/TSMCC.2009.2035631
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Hemmati M, 2014, 2014 17TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P543, DOI 10.1109/DSD.2014.60
   Hori Y, 2007, IEEE J SOLID-ST CIRC, V42, P790, DOI 10.1109/JSSC.2007.891675
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Kim HI, 2014, INT CONF DIGIT SIG, P562, DOI 10.1109/ICDSP.2014.6900728
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Li J, 2016, IEEE T CIRCUITS SYST, V27, P907
   Lindner C, 2015, IEEE T PATTERN ANAL, V37, P1862, DOI 10.1109/TPAMI.2014.2382106
   Liu SF, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P1, DOI 10.1109/GSIS.2013.6714728
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zhan J, 2014, DES AUT CON, DOI 10.1145/2593069.2593165
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 45
TC 6
Z9 6
U1 1
U2 7
PD AUG
PY 2019
VL 29
IS 8
BP 2467
EP 2481
DI 10.1109/TCSVT.2018.2867499
UT WOS:000480310500021
DA 2023-11-16
ER

PT J
AU Yang, XK
   Sha, S
AF Yang, Xiaokun
   Sha, Shi
TI Exploiting Energy-Quality (E-Q) Tradeoffs: A Case Study on
   Color-to-Grayscale Converters with Approximate Design on FPGA
SO JOURNAL OF CIRCUITS SYSTEMS AND COMPUTERS
DT Article
DE Approximate design; energy-quality (E-Q) tradeoff; field programmable
   gate array (FPGA); register-transfer level (RTL)
AB Today, field programmable gate array (FPGA) is becoming widely used as computational accelerators in many application domains such as image/video processing, machine learning, and data mining. The inherent tolerance to the imprecise computation in such domains potentially provides an opportunity to trade quality of the results for higher energy efficiency. Therefore, this paper proposes a systematic methodology aiming to find the optimal energy saving corresponding to different quality bound, by approximating register-transfer level (RTL) designs on FPGA. As a case study, first, we investigate imprecise design on two submodules - adders and multipliers. By integrating the two combinational submodules with finite state machines (FSMs), several designs on a sequential circuit - color-to-grayscale converter - are further presented to offer a diverse range of energy consumption related to different quality constrains. Through this, we are able to set energy-quality (E-Q) parameters of our proposed methodology and configure the approximation knobs, capable of maximizing energy savings within different application-based quality margins. Experimental result demonstrates that leveraging E-Q leads to an average 1.37-2.16x savings in energy for modest loss in application output quality (<3%), and 2.31-2.50x energy savings for impact on relaxed quality constraints (3-7.5%).
C1 [Yang, Xiaokun] Univ Houston Clear Lake, Engn Dept, 2700 Bay Area Blvd, Houston, TX 77058 USA.
   [Sha, Shi] Wilkes Univ, Elect Engn, 84 West South St, Wilkes Barre, PA 18766 USA.
RP Yang, XK (corresponding author), Univ Houston Clear Lake, Engn Dept, 2700 Bay Area Blvd, Houston, TX 77058 USA.
EM YangXia@uhcl.edu; shi.sha@wilkes.edu
CR Angizi S., 2017, 2017 18 INT S QUAL E, P1
   [Anonymous], 2016, 49 ANN IEEEACM INT S, DOI DOI 10.1109/MICRO.2016.7783710
   Anusha G, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102940
   Bose S., 2019, IEEE T CIRCUITS SYST, V67, P1
   Ebrahimi-Azandaryani F, 2020, IEEE T CIRCUITS-II, V67, P137, DOI 10.1109/TCSII.2019.2901060
   Gara B., 2017, J ELECT TEST, V33, P479
   He H., 2019, 21 INT C ARTIFICIAL, P129
   Hu JJ, 2019, INTEGRATION, V65, P370, DOI 10.1016/j.vlsi.2017.09.003
   Imani S.M., 2019, 2019 DES AUT TEST EU, P1
   Jung M, 2016, DES AUT CON, DOI 10.1145/2897937.2905002
   Leipnitz M. T., 2019, 2019 56 ACM IEEE DES, P1
   Leipnitz MT, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358182
   Li BJ, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P1, DOI 10.1145/2934872.2934897
   Liu B, 2019, IEEE ACCESS, V7, P82453, DOI 10.1109/ACCESS.2019.2924340
   Liu SL, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ENVIRONMENT, ENERGY AND APPLICATIONS (IAEA 2019), P1, DOI [10.1145/3323716.3323717, 10.1109/globalsip45357.2019.8969491]
   Lotfi A, 2016, DES AUT TEST EUROPE, P1279
   Mahapatra A, 2019, INTEGRATION, V64, P1, DOI 10.1016/j.vlsi.2018.03.011
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Padma A, 2020, MICROPROCESSORS, V73, P1
   Raghunathan V., 2015, DES AUT TEST EUR C E, P89
   Raha A, 2017, DES AUT CON, DOI 10.1145/3061639.3062333
   Raha A, 2016, IEEE T VLSI SYST, V24, P846, DOI 10.1109/TVLSI.2015.2424212
   Sinha S, 2016, IEEE T VLSI SYST, V24, P2665, DOI 10.1109/TVLSI.2016.2520979
   Vaca Kevin, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P378, DOI 10.1109/ISVLSI.2019.00075
   Vahdat S, 2019, IEEE T VLSI SYST, V27, P1161, DOI 10.1109/TVLSI.2018.2890712
   Van Toan N, 2020, IEEE ACCESS, V8, P25481, DOI 10.1109/ACCESS.2020.2970968
   Xu WB, 2018, IEEE T VLSI SYST, V26, P1112, DOI 10.1109/TVLSI.2018.2803081
   Yang TX, 2018, INT SYM QUAL ELECT, P347, DOI 10.1109/ISQED.2018.8357311
   Yang X., INT C ALG COMP SYST, P138
   Yang XK, 2019, INT SYM QUAL ELECT, P110, DOI 10.1109/ISQED.2019.8697816
   Yang XK, 2016, INTEGRATION, V52, P23, DOI 10.1016/j.vlsi.2015.07.012
   Zhang YX, 2019, IEEE COMP SOC ANN, P373, DOI 10.1109/ISVLSI.2019.00074
   Zhang YX, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON ALGORITHMS, COMPUTING AND SYSTEMS (ICACS 2018), P138, DOI 10.1145/3242840.3242852
NR 33
TC 1
Z9 1
U1 0
U2 1
PD MAR 30
PY 2021
VL 30
IS 4
AR 2150062
DI 10.1142/S0218126621500626
UT WOS:000639969200019
DA 2023-11-16
ER

PT J
AU Saragada, PK
   Manna, S
   Singh, A
   Das, BP
AF Saragada, Prasanna Kumar
   Manna, Subhashish
   Singh, Amandeep
   Das, Bishnu Prasad
TI A Configurable 10T SRAM-Based IMC Accelerator With Scaled-Voltage-Based
   Pulse Count Modulation for MAC and High-Throughput XAC
SO IEEE TRANSACTIONS ON NANOTECHNOLOGY
DT Article
DE Random access memory; Discharges (electric); Computer architecture;
   Capacitors; Voltage; Phase change materials; Transistors; Hardware
   accelerator; In-memory computation (IMC); machine learning algorithm;
   multiply-and-accumulate (MAC); SRAM; XNOR-and-accumulate (XAC)
ID MEMORY; ARCHITECTURE; WEIGHT; TOPS/W; ARRAY
AB This work proposes a 10T SRAM-based in-memory computation (IMC) architecture that can be configured to perform linear multiply-and-accumulate (MAC) operations and high-throughput XNOR-and-accumulate (XAC) operations. The IMC-MAC operation is performed by using the proposed scaled-voltage-based pulse count modulation (PCM) technique, which improves the linearity and signal margin of the MAC operation. The IMC-XAC operation is performed by using the proposed single capacitor discharge (SCD) approach with various advantages such as no deterministic error in XAC output, low latency, and less variation compared to the traditional charge sharing (TCS)-based XAC operation. The post-layout simulations of the proposed IMC architecture in a 65-nm CMOS process shows that the IMC architecture achieves a signal margin of 44.3 mV using the proposed scaled-voltage-based PCM approach in IMC-MAC mode whereas 37% less variation using the proposed SCD approach in IMC-XAC mode. In IMC-MAC mode, we achieve a 54.6 GOPS, 273 TOPS/W, and 98.67%/88.72% classification accuracy on MNIST/CIFAR-10 dataset using the convolution neural network (CNN)/ResNet20 algorithm. In IMC-XAC mode, we achieve a 3276.8 GOPS, 1092.2 TOPS/W, and 97.12% classification accuracy on the MNIST dataset using the binary neural network (BNN) algorithm.
C1 [Saragada, Prasanna Kumar; Manna, Subhashish; Singh, Amandeep; Das, Bishnu Prasad] Indian Inst Technol IIT Roorkee, Dept Elect & Commun Engn, Roorkee 247667, India.
RP Das, BP (corresponding author), Indian Inst Technol IIT Roorkee, Dept Elect & Commun Engn, Roorkee 247667, India.
EM skumar1@ec.iitr.ac.in; s_manna@ece.iitr.ac.in; a_singh@ece.iitr.ac.in;
   bishnu.das@ece.iitr.ac.in
CR Agrawal A, 2019, IEEE T CIRCUITS-I, V66, P3064, DOI 10.1109/TCSI.2019.2907488
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Giacomin E, 2021, IEEE T NANOTECHNOL, V20, P873, DOI 10.1109/TNANO.2021.3132224
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Jain S, 2021, IEEE J SOLID-ST CIRC, V56, P2981, DOI 10.1109/JSSC.2021.3092759
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Lee E, 2021, IEEE T CIRCUITS-I, V68, P3305, DOI 10.1109/TCSI.2021.3080042
   Lin ZT, 2021, IEEE J SOLID-ST CIRC, V56, P2550, DOI 10.1109/JSSC.2021.3063719
   Luo YC, 2021, IEEE T NANOTECHNOL, V20, P243, DOI 10.1109/TNANO.2021.3066319
   Mu J, 2022, IEEE T CIRCUITS-I, V69, P2412, DOI 10.1109/TCSI.2022.3152653
   Okumura S, 2019, S VLSI TECH, pC248
   Saragada PK, 2022, IEEE T VLSI SYST, V30, P1473, DOI 10.1109/TVLSI.2022.3199396
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Sinangil ME, 2021, IEEE J SOLID-ST CIRC, V56, P188, DOI 10.1109/JSSC.2020.3031290
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yu CS, 2020, IEEE CUST INTEGR CIR
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2023
VL 22
BP 222
EP 227
DI 10.1109/TNANO.2023.3269946
UT WOS:000988462600001
DA 2023-11-16
ER

PT C
AU Xydis, S
   Christoforidis, E
   Soudris, D
AF Xydis, Sotirios
   Christoforidis, Eleftherios
   Soudris, Dimitrios
GP IEEE
TI DDOT: Data Driven Online Tuning for energy efficient acceleration
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
DE Auto-tuning; data-driven energy optimization; manycore architectures;
   accelerated computing
ID PARETO ITERATIVE REFINEMENT
AB Modern accelerator platforms, are characterised by high micro-architectural complexity that affects both performance and energy consumption. Programmers usually are facing the problem of reasoning on differing trade-offs among the set of various code variants and their parameters configuration. While maximal configurations are usually adequate for performance optimization, this is not the case when optimizing for energy efficiency. Thus, efficient tuning methodologies accompanied with automated tools are of great importance for a quick and concrete evaluation of the explored design space. However, existing tuning frameworks are usually application-specific, i.e. performing well only on a priori known applications/workloads, and requiring heavy offline exploration and sampling procedures. In this paper, we present DDOT an online and scalable auto-tuning framework that enables the extraction of energy efficient tuning, with minimal online application characterisation. Instead of analyzing every application against every tuning configuration, it adopts a data driven approach, utilizing collaborative filtering, that quickly and with high accuracy configures the compilerand runtime-tuning parameters by identifying similarities to previously optimized applications. We evaluate DDOT efficiency utilizing as driving vehicle the Intel Phi accelerator platform, and compare it with state-of-art iterative and machine-learning tuning strategies as well with the exact optimal configurations of the derived solution space, through which we show that with minimal online characterisation, e.g. only either two or four online evaluations, DDOT finds tuning configurations that achieve more than 94% in respect to the optimal.
C1 [Xydis, Sotirios] Harokopio Univ Athens, Dept Informat & Telemat, Athens, Greece.
   [Christoforidis, Eleftherios; Soudris, Dimitrios] Natl Tech Univ Athens, Elect & Comp Engn, Athens, Greece.
RP Xydis, S (corresponding author), Harokopio Univ Athens, Dept Informat & Telemat, Athens, Greece.
EM sxydis@hua.gr; eleftherios.christoforidis@gmail.com;
   dsoudris@microlab.ntua.gr
CR [Anonymous], 2010, 23TH INT C ARCHITECT
   [Anonymous], 2013, ISCA
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Ashouri AH, 2016, ACM T ARCHIT CODE OP, V13, DOI 10.1145/2928270
   BAILEY DH, 1991, SUPERCOMPUTING 91, P158
   Cavazos J, 2007, INT SYM CODE GENER, P185
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen Y, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2355585.2355594
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Fursin G, 2011, INT J PARALLEL PROG, V39, P296, DOI 10.1007/s10766-010-0161-2
   Ganapathi Archana, 2009, P 1 USENIX C HOT TOP, P1
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kulkarni PA, 2009, ACM T ARCHIT CODE OP, V6, DOI 10.1145/1509864.1509865
   Kwon J, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3323919
   Leather H, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2536688
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Luk CK, 2011, IEEE SOFTWARE, V28, P39, DOI 10.1109/MS.2011.2
   Mishra N, 2015, ACM SIGPLAN NOTICES, V50, P267, DOI [10.1145/2775054.2694373, 10.1145/2694344.2694373]
   Muralidharan S, 2016, ACM SIGPLAN NOTICES, V51, P325, DOI 10.1145/2954679.2872411
   Palermo G, 2009, IEEE T COMPUT AID D, V28, P1816, DOI 10.1109/TCAD.2009.2028681
   Putt J, 2008, TRENDS ISS CRIME CRI, P1
   Radojkovic P, 2016, IEEE T COMPUT, V65, P256, DOI 10.1109/TC.2015.2417533
   Tiwari A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P879, DOI 10.1109/IPDPS.2011.86
   Tiwari A, 2009, INT PARALL DISTRIB P, P796
   Treibig J., 2010, 2010 39th International Conference on Parallel Processing Workshops (ICPPW), P207, DOI 10.1109/ICPPW.2010.38
   Triantafyllis S, 2003, INT SYM CODE GENER, P204, DOI 10.1109/CGO.2003.1191546
   Xydis S, 2015, IEEE T COMPUT AID D, V34, P155, DOI 10.1109/TCAD.2014.2363392
NR 27
TC 0
Z9 0
U1 0
U2 0
PY 2020
UT WOS:000628528400238
DA 2023-11-16
ER

PT J
AU Huang, SS
   Jiang, HW
   Peng, XC
   Li, WT
   Yu, SM
AF Huang, Shanshi
   Jiang, Hongwu
   Peng, Xiaochen
   Li, Wantong
   Yu, Shimeng
TI Secure XOR-CIM Engine: Compute-In-Memory SRAM Architecture With Embedded
   XOR Encryption
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Cryptography; Engines; Computational modeling; Random access memory;
   System-on-chip; Encryption; Computer architecture; Compute-in-memory
   (CIM); hardware accelerator; machine learning security; static
   random-access memory (SRAM); XOR encryption
ID MACRO; NETWORKS
AB Compute-in-memory (CIM), where information can be processed and stored at the same locations, is emerging as a promising paradigm to address the memory wall bottleneck in traditional Von Neumann architectures. Static random-access memory (SRAM) has been demonstrated as a mature candidate for CIM accelerator for deep neural networks (DNNs) due to its availability in advanced technology nodes. However, as SRAM is volatile and could not hold weight after power down, the necessity for downloading models from the cloud to inference engine causes potential threats such as model leaking. Also, saving raw weights of the DNN model stationary in the memory cells will increase the vulnerabilities. This work aims at developing a secure inference engine with a lightweight yet effective countermeasure to protect the DNN models in SRAM-based CIM architecture. We propose a secure XOR-CIM engine with a modified reverse secure sketch protocol to enable on-chip authentication and key processing for XOR-based stream cipher encrypted models. In the XOR-CIM core, we modify the six-transistor SRAM bit cell with dual wordlines to implement XOR decryption without sacrificing the parallel computation's efficiency. The evaluations at 28 nm show that the XOR-CIM could enhance security, achieving comparable energy efficiency and no throughput loss, with negligible area overhead compared with the normal-CIM design without encryption.
C1 [Huang, Shanshi; Jiang, Hongwu; Peng, Xiaochen; Li, Wantong; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shuang406@gatech.edu; shimeng.yu@ece.gatech.edu
CR Arnaud F, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371934
   Baldanzi L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071869
   Barker E. B., 2007, NIST SPECIAL PUBLICA, DOI [DOI 10.6028/NIST.SP.800-90AR1, 10.6028/NIST.SP.800- 90Ar1]
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Cai Y, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942041
   Chang J, 2017, ISSCC DIG TECH PAP I, P206, DOI 10.1109/ISSCC.2017.7870333
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chou CC, 2018, ISSCC DIG TECH PAP I, P478
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helfmeier C, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE-ORIENTED SECURITY AND TRUST (HOST), P1, DOI 10.1109/HST.2013.6581556
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Huang SS, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415678
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Jiang HW, 2020, IEEE T COMPUT, V69, P944, DOI 10.1109/TC.2020.2980533
   Jindal K, 2014, INT C ADV COMPUT COM, P398, DOI 10.1109/ACCT.2014.46
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Lu MY, 2018, IEEE TRUST BIG, P1464, DOI 10.1109/TrustCom/BigDataSE.2018.00204
   Matt C, 2013, IEEE INT SYMP INFO, P2706, DOI 10.1109/ISIT.2013.6620718
   Peng XC, 2019, INT EL DEVICES MEET
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Roel M, 2012, PHYS UNCLONABLE FUNC
   Shiu YS, 2011, IEEE WIREL COMMUN, V18, P66, DOI 10.1109/MWC.2011.5751298
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Simonyan K., 2015, 3 INT C LEARNING REP, P1
   Song T, 2018, ISSCC DIG TECH PAP I, P198, DOI 10.1109/ISSCC.2018.8310252
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   van de Leest Vincent, 2012, Cryptography and Security: From Theory to Applications. Essays Dedicated to Jean-Jacques Quisquater on the Occasion of His 65th Birthday: LNCS 6805, P300, DOI 10.1007/978-3-642-28368-0_20
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang CF, 2020, IEEE T COMPUT AID D, V39, P2192, DOI 10.1109/TCAD.2019.2937817
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhou Shuchang, 2016, ARXIV160606160
NR 41
TC 5
Z9 5
U1 2
U2 8
PD DEC
PY 2021
VL 29
IS 12
BP 2027
EP 2039
DI 10.1109/TVLSI.2021.3120296
UT WOS:000722717800005
DA 2023-11-16
ER

PT J
AU Moini, S
   Tian, SQ
   Holcomb, D
   Szefer, J
   Tessier, R
AF Moini, Shayan
   Tian, Shanquan
   Holcomb, Daniel
   Szefer, Jakub
   Tessier, Russell
TI Power Side-Channel Attacks on BNN Accelerators in Remote FPGAs
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Field programmable gate arrays; Convolution; Neural networks; Kernel;
   Feature extraction; Circuits and systems; Side-channel attacks; Remote
   attacks; deep neural networks; convolutional neural networks;
   side-channel attacks; power attacks; time-to-digital converters (TDCs)
ID NEURAL-NETWORKS
AB To lower cost and increase the utilization of Cloud Field-Programmable Gate Arrays (FPGAs), researchers have recently been exploring the concept of multi-tenant FPGAs, where multiple independent users simultaneously share the same remote FPGA. Despite its benefits, multi-tenancy opens up the possibility of malicious users co-locating on the same FPGA as a victim user, and extracting sensitive information. This issue becomes especially serious when the user is running a machine learning algorithm that is processing sensitive or private information. To demonstrate the dangers, this paper presents a remote, power-based side-channel attack on a deep neural network accelerator running in a variety of Xilinx FPGAs and also on Cloud FPGAs using Amazon Web Services (AWS) F1 instances. This work in particular shows how to remotely obtain voltage estimates as a deep neural network inference circuit executes, and how the information can be used to recover the inputs to the neural network. The attack is demonstrated with a binarized convolutional neural network used to recognize handwriting images from the MNIST handwritten digit database. With the use of precise time-to-digital converters for remote voltage estimation, the MNIST inputs can be successfully recovered with a maximum normalized cross-correlation of 79% between the input image and the recovered image on local FPGA boards and 72% on AWS F1 instances. The attack requires no physical access nor modifications to the FPGA hardware.
C1 [Moini, Shayan; Holcomb, Daniel; Tessier, Russell] Univ Massachusetts Amherst, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
   [Tian, Shanquan; Szefer, Jakub] Yale Univ, Dept Elect Engn, New Haven, CT 06511 USA.
RP Moini, S (corresponding author), Univ Massachusetts Amherst, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
EM smoini@umass.edu; shanquan.tian@yale.edu; dholcomb@umass.edu;
   jakub.szefer@yale.edu; tessier@umass.edu
CR Amazon, 2020, AM AWS F1
   [Anonymous], 2008, P 2 INT WORKSH HIGH
   [Anonymous], 2017, ARXIV 170807747
   [Anonymous], 2018, P DES AUT TEST EUR C
   Boutros A, 2020, INT C FIELD PROGR TE, P1
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chen F., 2014, PES GEN M C EXP JUL, P1
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Ding K, 2020, BINARIZED DENSE CONV
   Giechaskiel I, 2020, P IEEE S SECUR PRIV, P1728, DOI 10.1109/SP40000.2020.00070
   Giechaskiel I, 2019, I C FIELD PROG LOGIC, P45, DOI 10.1109/FPL.2019.00017
   Giechaskiel I, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P15, DOI 10.1145/3196494.3196518
   Giechaskil I, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3322483
   Glamocanin O, 2020, DES AUT TEST EUROPE, P1007, DOI 10.23919/DATE48585.2020.9116481
   Gnad D. R. E, 2019, VOLTAGE BASED COVERT
   Hashimoto, 2020, P 13 INN SOFTW ENG C, P1
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Hubara I., 2016, ADV NEURAL INFORM PR, P4114, DOI DOI 10.5555/3157382.3157557
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Krautter J., 2019, P IEEEACM INT C COMP, P1
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   NewAE Technology, 2020, CW1173 CHIPWHISPERER
   NewAE Technology, 2020, CW305 CHIPWHISPERER
   O'Flynn C, 2014, LECT NOTES COMPUT SC, V8622, P243, DOI 10.1007/978-3-319-10175-0_17
   Provelengios G, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P292, DOI 10.1145/3289602.3293923
   Ramesh Chethan, 2018, 2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), P45, DOI 10.1109/FCCM.2018.00016
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Satoh, 2020, SAKURA G FPGA BOARD
   Satoh, 2016, SAKURA X FPGA BOARD
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szefer J., 2021, P DES AUT TEST EUR C, P1
   Vaishnav A, 2018, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2018.00031
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weerasinghe J., 2015, P IEEE 12 INT C UB I, P1
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xilinx, 2020, VCU118 EV BOARD
   Xilinx, 2020, ZCU104 EV BOARD
   Xilinx, 2019, UG973 VIV DES SUIT U
   Yoshida K, 2019, ANN IEEE SYM FIELD P, P318, DOI 10.1109/FCCM.2019.00059
   Zeng SL, 2020, ANN IEEE SYM FIELD P, P102, DOI 10.1109/FCCM48280.2020.00023
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu W, 2019, ADV COMPUT MATH, V45, P3217, DOI 10.1007/s10444-019-09734-5
   Zick K. M., 2013, P ACMSIGDA INT S FIE, P101
NR 44
TC 20
Z9 20
U1 0
U2 10
PD JUN
PY 2021
VL 11
IS 2
BP 357
EP 370
DI 10.1109/JETCAS.2021.3074608
UT WOS:000660634800011
DA 2023-11-16
ER

PT C
AU Lee, J
   Watanabe, Y
   Sato, M
AF Lee, Jinpil
   Watanabe, Yutaka
   Sato, Mitsuhisa
BE Fan, X
   DeSupinski, BR
   Sinnen, O
   Giacaman, N
TI OpenMP Task Generation for Batched Kernel APIs
SO OPENMP: CONQUERING THE FULL HARDWARE SPECTRUM, IWOMP 2019
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 15th International Workshop on OpenMP (IWOMP)
CY SEP 11-13, 2019
CL Auckland, NEW ZEALAND
DE OpenMP; Task parallelism; Accelerator; Batched BLAS
AB The demand for calculating many small computation kernels is getting significantly important in the HPC area not only for the traditional numerical applications but also recent machine learning applications. While many-core accelerators such as GPUs are power-efficient compute platforms, a large amount of code modification is required. Batched kernel APIs such as batched BLAS can schedule numerical kernels efficiently on the target hardware while it still needs manual code modification. In this paper, we propose a code translation technique to generate batched kernel APIs in a high-level programming model. We use OpenMP task parallelism to specify dependency among numerical kernels. The user adds the task directives to specify tasks so that the compiler can recognize numerical kernels. The compiler detects conventional numerical kernels in the code and creates a unique batch ID for each kernel. When the task runtime detects tasks with the same batch ID, they are merged into a batch. The current implementation supports NVIDIA GPUs and batched BLAS in cuBLAS. DGEMM kernels can be detected and translated into batched DGEMM. A trivial DGEMM loop and blocked Cholesky decomposition code are used for performance evaluation. The evaluation result shows that batched DGEMM improves the performance when the matrix size is small and the number of DGEMM kernels is large. The time for DGEMMs in blocked Cholesky decomposition is 4 times faster than sequential execution when using batched DGEMM (4096x4096 matrix, tile size 128), however the overall performance is improved 36% because of task/batch management overhead.
C1 [Lee, Jinpil; Sato, Mitsuhisa] RIKEN Ctr Computat Sci, Kobe, Hyogo, Japan.
   [Watanabe, Yutaka; Sato, Mitsuhisa] Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki, Japan.
RP Lee, J (corresponding author), RIKEN Ctr Computat Sci, Kobe, Hyogo, Japan.
EM jinpil.lee@riken.jp; ywatanabe@hpcs.cs.tsukuba.ac.jp; msato@riken.jp
CR [Anonymous], ARGOBOTS OFFICIAL RE
   [Anonymous], Omni Compiler Infrastructure
   Dongarra J., 2018, BATCHED BLAS BASIC L
   Dongarra J, 2016, PROPOSED API BATCHED
   Dongarra J, 2017, PROCEDIA COMPUT SCI, V108, P495, DOI 10.1016/j.procs.2017.05.138
   Jin C, 2018, PROCEEDINGS OF 2018 IEEE/ACM 4TH INTERNATIONAL WORKSHOP ON EXTREME SCALE PROGRAMMING MODELS AND MIDDLEWARE (ESPM2 2018), P62, DOI 10.1109/ESPM2.2018.00012
   Muddukrishna Ananya, 2013, OpenMP in the Era of Low Power Devices and Accelerators. 9th International Workshop on OpenMP, IWOMP 2013. Proceedings: LNCS 8122, P156, DOI 10.1007/978-3-642-40698-0_12
   Olivier SL, 2009, LECT NOTES COMPUT SC, V5568, P63, DOI 10.1007/978-3-642-02303-3_6
   Relton S.D., 2016, COMP POTENTIAL INTER
   Watanabe Y, 2018, LECT NOTES COMPUT SC, V11128, P96, DOI 10.1007/978-3-319-98521-3_7
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2019
VL 11718
BP 262
EP 273
DI 10.1007/978-3-030-28596-8_18
UT WOS:000655479100018
DA 2023-11-16
ER

PT C
AU Ko, GG
   Chai, Y
   Rutenbar, RA
   Brooks, D
   Wei, GY
AF Ko, Glenn G.
   Chai, Yuji
   Rutenbar, Rob A.
   Brooks, David
   Wei, Gu-Yeon
BE Sourdis, I
   Bouganis, CS
   Alvarez, C
   Toledo, L
   Valero, P
   Martorell, X
TI Accelerating Bayesian Inference on Structured Graphs Using Parallel
   Gibbs Sampling
SO 2019 29TH INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 29th International Conference on Field-Programmable Logic and
   Applications (FPL)
CY SEP 09-13, 2019
CL Barcelona, SPAIN
DE bayesian inference; markov chain monte carlo; gibbs sampling; hardware
   accelerator; markov random field
AB Bayesian models and inference is a class of machine learning that is useful for solving problems where the amount of data is scarce and prior knowledge about the application allows you to draw better conclusions. However, Bayesian models often requires computing high-dimensional integrals and finding the posterior distribution can be intractable. One of the most commonly used approximate methods for Bayesian inference is Gibbs sampling, which is a Markov chain Monte Carlo (MCMC) technique to estimate target stationary distribution. The idea in Gibbs sampling is to generate posterior samples by iterating through each of the variables to sample from its conditional given all the other variables fixed. While Gibbs sampling is a popular method for probabilistic graphical models such as Markov Random Field (MRF), the plain algorithm is slow as it goes through each of the variables sequentially. In this work, we describe a binary label MRF Gibbs sampling inference architecture and extend it to 64-label version capable of running multiple perceptual applications, such as sound source separation and stereo matching. The described accelerator employs a chromatic scheduling of variables to parallelize all the conditionally independent variables to 257 samplers, implemented on the FPGA portion of a CPU-FPGA SoC. For real-time streaming sound source separation task, we show the hybrid CPU-FPGA implementation is 230x faster than a commercial mobile processor, while maintaining a recommended latency under 50 ms. The 64-label version showed 137x and 679x speedups for binary label MRF Gibbs sampling inference and 64 labels, respectively.
C1 [Ko, Glenn G.; Chai, Yuji; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Cambridge, MA 02138 USA.
   [Rutenbar, Rob A.] Univ Pittsburgh, Pittsburgh, PA USA.
RP Ko, GG (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM gko@seas.harvard.edu; yuc927@g.harvard.edu; rutenbar@pitt.edu;
   dbrooks@eecs.harvard.edu; guyeon@eecs.harvard.edu
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   [Anonymous], P VLDB ENDOW
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250
   Das S, 2015, IEEE INT SYMP CIRC S, P2704, DOI 10.1109/ISCAS.2015.7169244
   De Sa C., 2018, ARXIV180606086
   De Sa C, 2016, PR MACH LEARN RES, V48
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gonzalez J., 2011, P 14 INT C ARTIFICIA, P324
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Johnson M. J., 2013, PROC INT C NEURAL IN, V2, P2715
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim S, 2012, IEEE INT SYMP INTELL, P1, DOI 10.1109/ISIC.2012.6398245
   Kingma Diederik P, 2013, ARXIV13126114
   Ko GG, 2019, ANN IEEE SYM FIELD P, P334, DOI 10.1109/FCCM.2019.00075
   Ko GG, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3183351
   Ko GG, 2017, INT CONF ACOUST SPEE, P2477, DOI 10.1109/ICASSP.2017.7952602
   Koller D., 2009, PROBABILISTIC GRAPHI
   LI SZ, 1995, MARKOV RANDOM FIELD
   Mansinghka V. K., 2008, STOCHASTIC DIGITAL C, V2069
   Newman D, 2009, J MACH LEARN RES, V10, P1801
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Terenin A., 2015, ASYNCHRONOUS DISTRIB
   Terenin A., STAT COMPUTING, P1
   Tkacik TE, 2002, LECT NOTES COMPUT SC, V2523, P450
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945
NR 30
TC 4
Z9 4
U1 0
U2 0
PY 2019
BP 159
EP 165
DI 10.1109/FPL.2019.00033
UT WOS:000518670300023
DA 2023-11-16
ER

PT C
AU Liu, SL
   Zeng, CL
   Fan, HX
   Ng, HC
   Meng, JX
   Que, ZQ
   Niu, XY
   Luk, W
AF Liu, Shuanglong
   Zeng, Chenglong
   Fan, Hongxiang
   Ng, Ho-Cheung
   Meng, Jiuxi
   Que, Zhiqiang
   Niu, Xinyu
   Luk, Wayne
GP IEEE
TI Memory-Efficient Architecture for Accelerating Generative Networks on
   FPGA
SO 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT
   2018)
DT Proceedings Paper
CT 17th International Conference on Field-Programmable Technology (FPT)
CY DEC 10-14, 2018
CL Naha, JAPAN
AB Generative adversarial networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks: a generative network (generator) and a discriminative network (discriminator). These two networks compete with each other to perform better at their respective tasks. The generator is typically a deconvolutional neural network and the discriminator is a convolutional neural network (CNN). Deconvolution performs a fundamentally new type of mathematical operation which differs from convolution. While the FPGA-based CNN accelerators have been widely studied in prior work, the acceleration of deconvolutional networks on FPGA is rarely explored. This paper proposes a novel parametrized deconvolutional architecture based on an FPGA-friendly method, in contrast to the transposed convolution implementation in CPUs and GPUs. Hardware design templates which map this architecture to FPGAs are provided with configurable deconvolutional layer parameters. Furthermore, a memory-efficient architecture with a new tiling method is proposed to accelerate the generator of GANs, by storing all intermediate data in on-chip memories to significantly reduce off-chip data transfers. The performance of the proposed accelerator is evaluated using a variety of GANs on a Xilinx Zynq 706 board, which shows 2.3x higher speed and 8.2x offchip memory access reduction than an optimized Vanilla FPGA design. Compared to the respective implementations on CPUs and GPUs, the achieved improvements are in the range of 30x92x in speed over an Intel 8-core i7-950 CPU, and 8x-108x in terms of Performance-per-Watt over an NVIDIA Titan X GPU.
C1 [Liu, Shuanglong; Fan, Hongxiang; Ng, Ho-Cheung; Meng, Jiuxi; Que, Zhiqiang; Luk, Wayne] Imperial Coll London, Dept Comp, London, England.
   [Zeng, Chenglong] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
   [Niu, Xinyu] Corerain Technol Ltd, Shenzhen, Peoples R China.
RP Liu, SL; Fan, HX (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM s.liu13@imperial.ac.uk; zengchenglong@tju.edu.cn;
   h.fan17@imperial.ac.uk; h.ng16@imperial.ac.uk;
   jiuxi.meng16@imperial.ac.uk; z.que@imperial.ac.uk;
   xinyu.niu@corerain.com; w.luk@imperial.ac.uk
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   [Anonymous], 2017, ARXIV170704993
   Aydonat U., 2017, PROC ACM SIGDA INT S, DOI 10.1145/3020078.3021738
   Chang JW, 2018, ASIA S PACIF DES AUT, P343, DOI 10.1109/ASPDAC.2018.8297347
   Dosovitskiy A, 2017, IEEE T PATTERN ANAL, V39, P692, DOI 10.1109/TPAMI.2016.2567384
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Ghasemzadeh M., 2018, FCCM
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Jalalifar S. A., 2018, ARXIV180307461
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kreutz-Delgado K., 2017, ARXIV170502583
   Li G, 2018, DES AUT TEST EUROPE, P1163, DOI 10.23919/DATE.2018.8342188
   Liu S., 2018, FPGA, P293
   Liu S., 2018, ACM T RECONFIGURABLE
   Liu SL, 2017, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2017.9
   Liu SL, 2017, IEEE T COMPUT, V66, P745, DOI 10.1109/TC.2016.2630682
   Liu SL, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P191, DOI 10.1109/FPT.2014.7082775
   Liu SL, 2015, 2015 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (FPT), P120, DOI 10.1109/FPT.2015.7393138
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Osindero S., 2014, ARXIV14111784
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Radford A., 2016, ARXIV PREPRINT ARXIV
   Yazdanbakhsh A, 2018, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2018.00019
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhao R., 2018, ASAP
NR 25
TC 13
Z9 13
U1 0
U2 5
PY 2018
BP 33
EP 40
DI 10.1109/FPT.2018.00016
UT WOS:000491322000008
DA 2023-11-16
ER

PT J
AU Rybaniec, R
   Przygoda, K
   Cichalewski, W
   Ayvazyan, V
   Branlard, J
   Butkowski, L
   Pfeiffer, S
   Schmidt, C
   Schlarb, H
   Sekutowicz, J
AF Rybaniec, Radoslaw
   Przygoda, Konrad
   Cichalewski, Wojciech
   Ayvazyan, Valeri
   Branlard, Julien
   Butkowski, Lukasz
   Pfeiffer, Sven
   Schmidt, Christian
   Schlarb, Holger
   Sekutowicz, Jacek
TI FPGA-Based RF and Piezocontrollers for SRF Cavities in CW Mode
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article
DE Control systems; field programmable gate arrays (FPGAs); superconducting
   accelerators
ID ACTIVE NOISE-CONTROL; CONTROL SYSTEMS
AB Modern digital low level radio frequency (RF) control systems used to stabilize the accelerating field in facilities, such as free electron laser in Hamburg or the European X-ray free electron laser, are based on the field programmable gate array (FPGA) technology. Presently, these accelerator facilities are operated with pulsed RF. In the future, these facilities will operate with the continuous wave (CW), which requires significant modifications on the real-time feedbacks realized within the FPGA. For example, higher loaded quality factor of the superconducting RF cavities operated in the CW mode requires sophisticated resonance control methods. However, iterative learning techniques widely used for machines operated in pulsed mode are not applicable for the CW. In addition, the mechanical characteristic of the cavities now have a much more important impact on the choice of the feedback scheme. To overcome the limitations of classical proportional-integral controllers, a novel real-time adaptive feed-forward algorithm is implemented in the FPGA. Also, the high power RF amplifier, which is an inductive output tube (IOT) for CW operation instead of a klystron for the pulsed mode, has a major impact on the design and implementation of the firmware for regulation. In this paper, we report on our successful approach to control the multicavity vector sum with an ultrahigh precision (amplitude error <0.01% rms and phase stability <0.02 degrees rms), using a single IOT source and the individual resonance control through piezoactuators. Performance measurements of the proposed solution were conducted at the cryomodule test bench facility.
C1 [Rybaniec, Radoslaw] Warsaw Univ Technol, PL-00661 Warsaw, Poland.
   [Rybaniec, Radoslaw; Przygoda, Konrad; Ayvazyan, Valeri; Branlard, Julien; Butkowski, Lukasz; Pfeiffer, Sven; Schmidt, Christian; Schlarb, Holger; Sekutowicz, Jacek] DESY, D-22607 Hamburg, Germany.
   [Cichalewski, Wojciech] Lodz Univ Technol, PL-90924 Lodz, Poland.
RP Rybaniec, R (corresponding author), Warsaw Univ Technol, PL-00661 Warsaw, Poland.
EM rrybanie@mion.elka.pw.edu.pl
CR Branlard J., 2013, P 14 INT C ACCELERAT, P1239
   Branlard J, 2013, MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, MIXDES 2013, P109
   Brinkmann R., 2006, XFEL EUR XRAY FREE E
   Butkowski L., 2015, P 15 INT C ACC LARG, DOI [10.18429/JACoW-ICALEPCS2015-WEPGF074, DOI 10.18429/JACOW-ICALEPCS2015-WEPGF074]
   Carcagno R., 2003, THP39 FERM NAT ACC L, P726
   Cichalewski W., 2008, THESIS
   DESY. Hamburg, 2007, FLASH THE FREE EL LA
   Kandil TH, 2005, NUCL INSTRUM METH A, V550, P514, DOI 10.1016/j.nima.2005.05.060
   Kugeler O., 2007, P 41 ADV ICFA BEAM D, P85
   Kuo SM, 2006, IEEE T AUDIO SPEECH, V14, P1857, DOI 10.1109/TSA.2005.858524
   Kuo SM, 1996, IEEE T SPEECH AUDI P, V4, P96, DOI 10.1109/89.486059
   Kuo SM, 1999, P IEEE, V87, P943, DOI 10.1109/5.763310
   Kuo SM., 1995, ACTIVE NOISE CONTROL
   Ljung L., 1999, SYSTEM IDENTIFICATIO, V2nd
   Neumann A., 2007, P WORKSH RF SUP BEIJ, P377
   Przygoda K., 2011, THESIS
   Przygoda K., 2012, MEAS AUTOM MONITOR, V58, P668
   Przygoda K., IEEE T NUCL IN PRESS
   Rutkowski I, 2015, IEEE T NUCL SCI, V62, P3186, DOI 10.1109/TNS.2015.2499382
   Rutkowski I, 2013, IEEE T NUCL SCI, V60, P3609, DOI 10.1109/TNS.2013.2278372
   Rybaniec R., 2014, P 5 INT PART ACC C, P2456
   Rybaniec R., 2015, P 6 INT PART ACC C, P15
   Schilcher T., 1998, THESIS
   Schmidt C., 2010, THESIS
   Sekutowicz J, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.050701
   Volder J. E., 1959, ELECT COMPUTERS IRE, VEC-8, P330, DOI DOI 10.1109/TEC.1959.5222693
   Xilinx Inc, 2014, UG479 XIL INC
   [No title captured]
NR 28
TC 12
Z9 12
U1 1
U2 9
PD JUN
PY 2017
VL 64
IS 6
BP 1382
EP 1388
DI 10.1109/TNS.2017.2687981
PN 1
UT WOS:000404973000029
DA 2023-11-16
ER

PT J
AU Puente, V
   Gregorio, JA
AF Puente, Valentin
   Angel Gregorio, Jose
TI CLASSIC: A cortex-inspired hardware accelerator
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article
DE Cortex; Cortical learning algorithm; Packet-switched network;
   Neuroscience; Computer architecture
ID NEURONS; SPARSE; MICROCIRCUITS; PLASTICITY
AB This work explores the feasibility of specialized hardware implementing the Cortical Learning Algorithm (CLA) in order to fully exploit its inherent advantages. This algorithm, which is inspired by the current understanding of the mammalian neo-cortex, is the basis of the Hierarchical Temporal Memory (HTM). In contrast to other machine learning (ML) approaches, the structure is not application dependent and relies on fully unsupervised continuous learning. We hypothesize that a hardware implementation will be able not only to extend the existing practical uses of these ideas to broader scenarios but also to exploit CLA's hardware-friendly characteristics.
   The architecture proposed will enable the system size to be scaled up compared to a state-of-the-art CLA software implementation. It may be possible to improve performance by 4 orders of magnitude and energy efficiency by up to 8 orders of magnitude.
   Given the problem's complex nature, we found that the most demanding issue, from a scalability standpoint, is the massive degree of connectivity required. We propose to use a packet-switched network to tackle this. The paper addresses the fundamental issues of such an approach, proposing solutions to achieve a scalable proposal. We will analyze cost and performance when using well-known architectural techniques and tools. The results obtained suggest that even with CMOS technology, under constrained cost, it might be possible to implement a large-scale system. We found that the proposed solutions enable a saving of similar to 90% of the original communication costs running either synthetic or realistic workloads. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Puente, Valentin; Angel Gregorio, Jose] Univ Cantabria, Comp Architecture, Dept Comp & Elect, Santander, Spain.
RP Puente, V (corresponding author), Univ Cantabria, Comp Architecture, Dept Comp & Elect, Santander, Spain.
EM vpuente@unican.es
CR Abad P., 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P99, DOI 10.1109/NOCS.2012.19
   Abadi M., 2016, P 12 USENIX S OP SYS, P265
   Anderson CT, 2010, NAT NEUROSCI, V13, P739, DOI 10.1038/nn.2538
   [Anonymous], 2014, CUDNN EFFICIENT PRIM
   [Anonymous], 2016, IEEE SPECTRUM
   [Anonymous], 2015, DEEP LEARNING LTD NU
   [Anonymous], 2015, PROPERTIES SPARSE DI
   [Anonymous], 2016, EIE EFFICIENT INFERE
   Bahrampour S., 2015, COMP STUDY CAFFE NEO
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Briggs F, 2010, FRONT NEURAL CIRCUIT, V4, DOI 10.3389/neuro.04.003.2010
   Bruno RM, 2002, J NEUROSCI, V22, P10966
   Buxhoeveden DP, 2002, BRAIN, V125, P935, DOI 10.1093/brain/awf110
   Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639
   Cassidy AS, 2014, INT CONF HIGH PERFOR, P27, DOI 10.1109/SC.2014.8
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Clascá F, 2012, EUR J NEUROSCI, V35, P1524, DOI 10.1111/j.1460-9568.2012.08033.x
   Cui YW, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00111
   Cui YW, 2016, NEURAL COMPUT, V28, P2474, DOI 10.1162/NECO_a_00893
   de Nó RL, 1934, J PSYCHOL NEUROL, V46, P113
   DeSieno D., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P117, DOI 10.1109/ICNN.1988.23839
   Ding L, 2012, PROCEEDINGS OF ISCRAM ASIA 2012 CONFERENCE ON INFORMATION SYSTEMS FOR CRISIS RESPONSE AND MANAGEMENT, P201
   Duato J., 1997, INTERCONNECTION NETW
   El-Boustani S, 2018, SCIENCE, V360, P1349, DOI 10.1126/science.aao0862
   Grienberger C, 2015, TRENDS NEUROSCI, V38, P45, DOI 10.1016/j.tins.2014.11.002
   Hawkins J, 2017, FRONT NEURAL CIRCUIT, V11, DOI 10.3389/fncir.2017.00081
   Hawkins J, 2016, FRONT NEURAL CIRCUIT, V10, DOI 10.3389/fncir.2016.00023
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jerger NE, 2008, CONF PROC INT SYMP C, P229, DOI 10.1109/ISCA.2008.12
   Kumar A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/2976742
   Lavin A, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P38, DOI 10.1109/ICMLA.2015.141
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lewis M, 2019, FRONT NEURAL CIRCUIT, V13, DOI 10.3389/fncir.2019.00022
   Mnatzaganian J., 2016, MATH FORMALIZATION H, P1
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pietron M, 2016, LECT NOTES ARTIF INT, V9920, P396, DOI 10.1007/978-3-319-47160-0_36
   Puente V, 2004, CONF PROC INT SYMP C, P198, DOI 10.1109/ISCA.2004.1310775
   Puente V, 2001, J PARALLEL DISTR COM, V61, P1180, DOI 10.1006/jpdc.2001.1746
   Rinkus GJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00160
   Sherman SM, 2014, NEUROSCIENTIST, V20, P136, DOI 10.1177/1073858413478490
   Sin W., 2002, NATURE, V2112, P2108
   Theophilou I., 2015, GEN PAULI CONSTRAINT
   Thomson AM, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00013
   VanEssen DC, 1997, J NEUROSCI, V17, P7079
   Vélez-Fort M, 2014, NEURON, V83, P1431, DOI 10.1016/j.neuron.2014.08.001
   Walter F, 2017, IEEE INT SYMP CIRC S, P2715
   Wixted JT, 2014, P NATL ACAD SCI USA, V111, P9621, DOI 10.1073/pnas.1408365111
NR 50
TC 1
Z9 1
U1 0
U2 3
PD DEC
PY 2019
VL 134
BP 140
EP 152
DI 10.1016/j.jpdc.2019.08.009
UT WOS:000489358200012
DA 2023-11-16
ER

PT J
AU Arora, A
   Bhamburkar, A
   Borda, A
   Anand, T
   Sehgal, R
   Hanindhito, B
   Gaillardon, PE
   Kulkarni, J
   John, LK
AF Arora, Aman
   Bhamburkar, Atharva
   Borda, Aatman
   Anand, Tanmay
   Sehgal, Rishabh
   Hanindhito, Bagus
   Gaillardon, Pierre-Emmanuel
   Kulkarni, Jaydeep
   John, Lizy K.
TI CoMeFa: Deploying Compute-in-Memory on FPGAs for Deep Learning
   Acceleration
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; Processing-In-Memory; Compute-In-Memory; Block RAM; Deep Learning;
   Machine Learning
ID SRAM; RAM; NM
AB Block random access memories (BRAMs) are the storage houses of FPGAs, providing extensive on-chip memory bandwidth to the compute units implemented using logic blocks and digital signal processing slices. We propose modifying BRAMs to convert them to CoMeFa (Compute-in-Memory Blocks for FPGAs) random access memories (RAMs). These RAMs provide highly parallel compute-in-memory by combining computation and storage capabilities in one block. CoMeFa RAMs utilize the true dual-port nature of FPGA BRAMs and contain multiple configurable single-bit bit-serial processing elements. CoMeFa RAMs can be used to compute with any precision, which is extremely important for applications like deep learning (DL). Adding CoMeFa RAMs to FPGAs significantly increases their compute density while also reducing data movement. We explore and propose two architectures of these RAMs: CoMeFa-D (optimized for delay) and CoMeFa-A (optimized for area). Compared to existing proposals, CoMeFa RAMs do not require changing the underlying static RAM technology like simultaneously activating multiple wordlines on the same port, and are practical to implement. CoMeFa RAMs are especially suitable for parallel and compute-intensive applications like DL, but these versatile blocks find applications in diverse applications like signal processing and databases, among others. By augmenting an Intel Arria 10-like FPGA with CoMeFa-D (CoMeFa-A) RAMs at the cost of 3.8% (1.2%) area, and with algorithmic improvements and efficient mapping, we observe a geomean speedup of 2.55x (1.85x) across microbenchmarks from various applications and a geomean speedup of up to 2.5x across multiple deep neural networks. Replacing all or some BRAMs with CoMeFa RAMs in FPGAs can make them better accelerators of DL workloads.
C1 [Arora, Aman; Sehgal, Rishabh; Hanindhito, Bagus; Kulkarni, Jaydeep; John, Lizy K.] Univ Texas, Elect & Comp Engn, 2501 Speedway C0803, Austin, TX 78712 USA.
   [Bhamburkar, Atharva] Birla Inst Technol & Sci, Dept Elect & Elect Engn, Pilani KK Birla Goa Campus,NH 17B, Zuarinagar 403726, Goa, India.
   [Borda, Aatman; Anand, Tanmay] Birla Inst Technol & Sci, Dept Elect & Elect Engn, VidyaVihar Campus, Pilani 333031, Rajasthan, India.
   [Gaillardon, Pierre-Emmanuel] Dept Elect & Comp Engn, 50 S Cent Campus Dr,Rm 2110 MEB, Salt Lake City, UT 84112 USA.
RP Arora, A (corresponding author), Univ Texas, Elect & Comp Engn, 2501 Speedway C0803, Austin, TX 78712 USA.
EM aman.kbm@utexas.edu; f20190456@goa.bits-pilani.ac.in;
   borda.aatman@gmail.com; tanmay.anand29@gmail.com;
   sehgal.rish@utexas.edu; hanindhito@bagus.my.id;
   pierre-emmanuel.gaillardon@utah.edu; jaydeep@austin.utexas.edu;
   ljohn@ece.utexas.edu
CR Achronix, 2019, SPEEDSTER7T FPGAS
   Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agrawal A, 2018, IEEE T CIRCUITS-I, V65, P4219, DOI 10.1109/TCSI.2018.2848999
   Altera, 2015, DES FILT HIGH PERF
   Arizona State University, 2012, PREDICTIVE TECHNOLOG
   Arora Aman, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P23, DOI 10.1145/3431920.3439282
   ARORA A, 2021, P 2021 31 INT C FIEL, DOI DOI 10.1109/FPL53798.2021.00068
   ARORA A, 2022, P 2022 IEEE 30 ANN I, P1, DOI DOI 10.1109/FCCM53951.2022.9786179
   Arora A, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3529650
   Arora Aman, 2021, P 2021 55 ASILOMAR C, P1156, DOI [10.1109/IEEECONF53345.2021.9723277, DOI 10.1109/IEEECONF53345.2021.9723277]
   Boutros A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P10, DOI 10.1109/ICFPT51103.2020.00011
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Eldafrawy M, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3393668
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Gauchi R., 2020, P ACMIEEE INT S LOW, P121, DOI [10.1145/3370748.3406550, DOI 10.1145/3370748.3406550]
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Intel, 2020, INT ARR 10 DEV DAT
   Intel, 2021, INT ARR 10 TRANSC PH
   Intel, 2021, INT ARR 10 DEV OV
   Intel, 2021, INT ARR 10 PROD TABL
   Intel, 2016, HYBR MEM CUB CONTR I
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Ju L, 2018, IEEE T COMPUT AID D, V37, P2661, DOI 10.1109/TCAD.2018.2857261
   Kang MG, 2020, P IEEE, V108, P2251, DOI 10.1109/JPROC.2020.3034117
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Landy A, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/2996459
   Landy A, 2015, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2015.53
   Langhammer Martin, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P57, DOI 10.1145/3431920.3439293
   Lewis D., 2013, P ACMSIGDA INT S FIE, P147, DOI 10.1145
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Narang S., 2016, BAIDU DEEPBENCH
   NCSU, 2018, FREEPDK45
   Prakash Shvetank, 2022, ARXIV
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Sun X, 2019, ADV NEUR IN, V32
   Tatsumura K, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3154425
   TYHACH J, 2015, P 2015 IEEE CUST INT, P1, DOI DOI 10.1109/CICC.2015.7338368
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Wang XW, 2021, ANN IEEE SYM FIELD P, P88, DOI 10.1109/FCCM51124.2021.00018
   Xilinx, 2018, AI ENG THEIR APPL
   Xilinx, 2021, ULTRASCALE ARCHITECT
   Yazdanshenas S, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3301298
   Yazdanshenas S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P115, DOI 10.1145/3020078.3021731
   Yi-Chung Chen, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P367, DOI 10.1109/FPL.2012.6339206
NR 56
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 16
IS 3
AR 50
DI 10.1145/3603504
UT WOS:001056398200017
DA 2023-11-16
ER

PT C
AU Mahon, S
   Varrette, S
   Plugaru, V
   Pinel, F
   Bouvry, P
AF Mahon, Sean
   Varrette, Sebastien
   Plugaru, Valentin
   Pinel, Frederic
   Bouvry, Pascal
BE Lefevre, L
   Varela, CA
   Pallis, G
   Toosi, AN
   Rana, O
   Buyya, R
TI Performance Analysis of Distributed and Scalable Deep Learning
SO 2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND
   INTERNET COMPUTING (CCGRID 2020)
DT Proceedings Paper
CT 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid)
CY MAY 11-14, 2020
CL Melbourne, AUSTRALIA
AB With renewed global interest for Artificial Intelligence (AI) methods, the past decade has seen a myriad of new programming models and tools that enable better and faster Machine Learning (ML). More recently, a subset of ML known as Deep Learning (DL) raised an increased interest due to its inherent ability to tackle efficiently novel cognitive computing applications. DL allows computational models that are composed of multiple processing layers to learn in an automated way representations of data with multiple levels of abstraction, and can deliver higher predictive accuracy when trained on larger data sets. Based on Artificial Neural Networks (ANN), DL is now at the core of state of the art voice recognition systems (which enable easy control over e.g. Internet-of- Things (IoT) smart home appliances for instance), self-driving car engine, online recommendation systems. The ecosystem of DL frameworks is fast evolving, as well as the DL architectures that are shown to perform well on specialized tasks and to exploit GPU accelerators. For this reason, the frequent performance evaluation of the DL ecosystem is required, especially since the advent of novel distributed training frameworks such as Horovod allowing for scalable training across multiple computing resources.
   In this paper, the scalability evaluation of the reference DL frameworks (Tensorflow, Keras, MXNet, and PyTorch) is performed over up-to-date High Performance Computing (HPC) resources to compare the efficiency of different implementations across several hardware architectures (CPU and GPU). Experimental results demonstrate that the DistributedDataParallel features in the Pytorch library seem to be the most efficient framework for distributing the training process across many devices, allowing to reach a throughput speedup of 10.11 when using 12 NVidia Tesla V100 GPUs when training Resnet44 on the CIFAR10 dataset.
C1 [Mahon, Sean] Trinity Coll Dublin, Dublin, Ireland.
   [Varrette, Sebastien; Bouvry, Pascal] Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust SnT, 2 Ave Univ, L-4365 Esch Sur Alzette, Luxembourg.
   [Plugaru, Valentin; Pinel, Frederic] Univ Luxembourg, Comp Sci & Commun CSC Res Unit, 2 Ave Univ, L-4365 Esch Sur Alzette, Luxembourg.
RP Mahon, S (corresponding author), Trinity Coll Dublin, Dublin, Ireland.
CR Abadi M, 2015, PRELIMINARY WHITE PA
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2010, ARTIF INTELL
   Banko M, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P26, DOI 10.3115/1073012.1073017
   Ben-Nun T, 2019, INT PARALL DISTRIB P, P66, DOI 10.1109/IPDPS.2019.00018
   Chollet F., 2015, KERAS
   Coleman CA, 2017, DAWNBENCH END TO END
   Collobert R., 2011, BIGLEARN NIPS WORKSH
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hestness Joel, 2017, ARXIV171200409
   Krizhevsky A., 2009, REP T 2009
   Paszke A, 2019, ADV NEUR IN, V32
   Patarasuk P, 2009, J PARALLEL DISTR COM, V69, P117, DOI 10.1016/j.jpdc.2008.09.002
   Poess M, 2019, COMPANION OF THE 2019 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '19), P17, DOI 10.1145/3302541.3313098
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Varrette S, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P959, DOI 10.1109/HPCSim.2014.6903792
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma S., 2019, DEMYSTIFYING MLPERF
NR 19
TC 3
Z9 3
U1 1
U2 3
PY 2020
BP 760
EP 766
DI 10.1109/CCGrid49817.2020.00-13
UT WOS:000649540400080
DA 2023-11-16
ER

PT C
AU Crafton, B
   Spetalnick, S
   Murali, G
   Krishna, T
   Lim, SK
   Raychowdhury, A
AF Crafton, Brian
   Spetalnick, Samuel
   Murali, Gauthaman
   Krishna, Tushar
   Lim, Sung-Kyu
   Raychowdhury, Arijit
GP IEEE
TI Breaking Barriers: Maximizing Array Utilization for Compute In-Memory
   Fabrics
SO 2020 IFIP/IEEE 28TH INTERNATIONAL CONFERENCE ON VERY LARGE SCALE
   INTEGRATION (VLSI-SOC)
SE IEEE-IFIP International Conference on VLSI and System-on-Chip
DT Proceedings Paper
CT IFIP/IEEE 28th International Conference on Very Large Scale Integration
   (VLSI-SOC)
CY OCT 05-09, 2020
CL ELECTR NETWORK
AB Compute in-memory (CIM) is a promising technique that minimizes data transport, the primary performance bottleneck and energy cost of most data intensive applications. This has found wide-spread adoption in accelerating neural networks for machine learning applications. Utilizing a crossbar architecture with emerging non-volatile memories (eNVM) such as dense resistive random access memory (RRAM) or phase change random access memory (PCRAM), various forms of neural networks can be implemented to greatly reduce power and increase on chip memory capacity. However, compute in-memory faces its own limitations at both the circuit and the device levels. Although compute in-memory using the crossbar architecture can greatly reduce data transport, the rigid nature of these large fixed weight matrices forfeits the flexibility of traditional CMOS and SRAM based designs. In this work, we explore the different synchronization barriers that occur from the CIM constraints. Furthermore, we propose a new allocation algorithm and data flow based on input data distributions to maximize utilization and performance for compute-in memory based designs. We demonstrate a 7.47x performance improvement over a naive allocation method for CIM accelerators on ResNet18.
C1 [Crafton, Brian; Spetalnick, Samuel; Murali, Gauthaman; Krishna, Tushar; Lim, Sung-Kyu; Raychowdhury, Arijit] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Crafton, B (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM brian.crafton@gatech.edu; arijit.raychowdhury@ece.gatech.edu
CR Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Crafton B., 2020, ARXIV PREPRINT ARXIV
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Peng XC, 2020, IEEE T CIRCUITS-I, V67, P1333, DOI 10.1109/TCSI.2019.2958568
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Wu JY., 2018, 2018 IEEE INT EL DEV, P27
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
NR 9
TC 3
Z9 3
U1 2
U2 4
PY 2020
BP 123
EP 128
DI 10.1109/VLSI-SOC46417.2020.9344086
UT WOS:000658853800022
DA 2023-11-16
ER

PT C
AU Milojicic, D
   Bresniker, K
   Campbell, G
   Faraboschi, P
   Strachan, JP
   Williams, S
AF Milojicic, Dejan
   Bresniker, Kirk
   Campbell, Gary
   Faraboschi, Paolo
   Strachan, John Paul
   Williams, Stan
GP IEEE
TI Computing In-Memory, Revisited
SO 2018 IEEE 38TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS)
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 38th IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY JUL 02-05, 2018
CL Vienna Univ Technol, Vienna, AUSTRIA
HO Vienna Univ Technol
DE Architecture; computing; memory; interconnects; accelerators;
   programming; configuring; performance; scaling
ID ARCHITECTURE
AB The Von Neumann's architecture has been the dominant computing paradigm ever since its inception in the mid-forties. It revolves around the concept of a "stored program" in memory, and a central processing unit that executes the program. As an alternative, Processing-In-Memory (PIM) ideas have been around for at least two decades, however with very limited adoption. Today, three trends are creating a compelling motivation to take a second look. Novel devices such as memristor blur the boundary between memory and compute, effectively providing both in the same element. Power efficiency has become very important, both in the datacenter and at the edge. Machine learning applications driven by a data-flow model have become ubiquitous. In this paper, we sketch our Computing-In-Memory (CIM) vision, and its substantial performance and power improvement potential. Compared to PIM models, CIM more clearly separates computing from memory. We then discuss the programming model, which we consider the biggest challenge. We close by describing how CIM impacts non-functional characteristics, such as reliability, scale, and configurability.
C1 [Milojicic, Dejan; Campbell, Gary; Faraboschi, Paolo; Strachan, John Paul; Williams, Stan] Hewlett Packard Labs, Syst Lab, Palo Alto, CA 94304 USA.
   [Bresniker, Kirk] Hewlett Packard Labs, Off CTO, Palo Alto, CA USA.
RP Milojicic, D (corresponding author), Hewlett Packard Labs, Syst Lab, Palo Alto, CA 94304 USA.
EM dejan.milojicic@hpe.com; kirk.bresniker@hpe.com; gary.campbell@hpe.com;
   paolo.faraboschi@hpe.com; john-paul.strachan@hpe.com;
   stan.williams@hpe.com
CR Achermann R., P ACM 16 WORKSH HOT, P118
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], IEEE COMPUTER ARCHIT
   [Anonymous], 2013, SIGPLAN WORKSH MEM S
   [Anonymous], 2018, IEEE TECHNOLOGY TREN
   [Anonymous], 2004, PROC WMPI
   Asanovic K., 2006, LANDSCAPE PARALLEL C
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Bruel P., 2017, 2 INT C REB COMP WAS
   Budiu M, 2004, ACM SIGPLAN NOTICES, V39, P14, DOI 10.1145/1037187.1024396
   Chacos Brad, PC WORLD
   Chen W. H., 2017, IEDM, DOI [10.1109/IEDM.2017.8268468, DOI 10.1109/IEDM.2017.8268468]
   Cong J, 2014, IEEE T VLSI SYST, V22, P864, DOI 10.1109/TVLSI.2013.2259512
   Conte Thomas A., 2018, COMPUTER, V51
   Culler D., 1999, PARALLEL COMPUTER AR
   Dally W.J., 2004, PRINCIPLES PRACTICES
   DeBenedictis EP, 2017, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC.2017.8091044
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Dou CM, 2017, INT CONF ASIC, P140, DOI 10.1109/ASICON.2017.8252431
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Farabet Clement, 2011, PROC IEEE COMPUT SOC, P109
   Faraboschi Paolo, 2015, 15 WORKSH HOT TOP OP
   Foster C. C., 1976, CONTENT ADDRESSABLE
   Goldstein SC, 2000, COMPUTER, V33, P70, DOI 10.1109/2.839324
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo Q, 2011, INT SYMP MICROARCH, P339
   Hall Mary, P 1999 ACM IEEE C SU, P57
   Hsieh K., 2016, TRANSPARENT OFFLOADI
   Hsueh F.-K., 2017, INT EL DEVICES MEET
   Hwu W-m., 2016, HETEROGENEOUS SYSTEM
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Khodabandehloo G, 2012, IEEE T VLSI SYST, V20, P750, DOI 10.1109/TVLSI.2011.2109404
   Khoram S, 2017, ISPD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P43, DOI 10.1145/3036669.3038242
   Kogge PM, WORKSH MIX LOG DRAM
   Kogge PM, INN ARCH FUT GEN HIG, P35
   Krommydas K, 2016, J SIGNAL PROCESS SYS, V85, P373, DOI 10.1007/s11265-015-1051-z
   Leibin Ni, 2017, ACM Journal on Emerging Technologies in Computing Systems, V13, DOI 10.1145/2996192
   McMenamin Adrian, 2013, END DENNARD SCALING
   Mei B., 2003, LECT NOTES COMPUTER, V2778
   Milojicic Dejan, 2016, Computer, V49, P43, DOI 10.1109/MC.2016.19
   Milojicic DS, 2000, ACM COMPUT SURV, V32, P241, DOI 10.1145/367701.367728
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Moghaddam H. A., 2016, INT S MICROARCHITECT, P1
   Moore G. E., 1965, ELECTRONICS
   Moore GE, 2006, UNDERSTANDING MOORES, P67
   Morad A, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2845084
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Patterson D. A., 2013, COMPUTER ORG DESIGN
   Pell O., 2013, MAXIMUM PERFORMANCE, P747
   Picorel J, 2017, INT CONFER PARA, P303, DOI 10.1109/PACT.2017.56
   Schaller B., 1996, ORIGIN NATURE IMPLIC
   SCHERSON ID, 1989, J PARALLEL DISTR COM, V6, P69, DOI 10.1016/0743-7315(89)90043-9
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Singh H., 2000, IEEE T COMPUTERS, V49
   Skarlatos D, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P302, DOI 10.1145/3123939.3124540
   The OpenSPL Consortium, 2013, TECHNICAL REPORT
   Torrellas J., 2012, COMP DES ICCD 2012 I, P3
   Trancoso P., 2015, ACM INT C COMP FRONT
   vonNeumann J., 1945, REPORT EDVAC
   Watson Robert N. M., 2015, P 36 IEEE S SEC PRIV
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Yang SS, 2015, ATMOS POLLUT RES, V6, P52, DOI 10.5094/APR.2015.007
   Yavits L, 2015, IEEE COMPUT ARCHIT L, V14, P148, DOI 10.1109/LCA.2014.2374597
   Yavits L, 2015, IEEE T COMPUT, V64, P368, DOI 10.1109/TC.2013.220
   Yu JY, 2017, AEBMR ADV ECON, V48, P71
   Zha Y, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967069
   Zhang D., 2014, P 23 INT S HIGH PERF, P85
   Zhang J, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON ADVANCED EDUCATION AND TECHNOLOGY AND MANAGEMENT SCIENCE (AETMS 2016), P1, DOI 10.1109/ICSSSM.2016.7538472
NR 70
TC 10
Z9 10
U1 1
U2 4
PY 2018
BP 1300
EP 1309
DI 10.1109/ICDCS.2018.00130
UT WOS:000541051900120
DA 2023-11-16
ER

PT J
AU Majernik, N
   Andonian, G
   Lynn, W
   Kim, S
   Lorch, C
   Roussel, R
   Doran, S
   Wisniewski, E
   Whiteford, C
   Piot, P
   Power, J
   Rosenzweig, JB
AF Majernik, N.
   Andonian, G.
   Lynn, W.
   Kim, S.
   Lorch, C.
   Roussel, R.
   Doran, S.
   Wisniewski, E.
   Whiteford, C.
   Piot, P.
   Power, J.
   Rosenzweig, J. B.
TI Beam shaping using an ultrahigh vacuum multileaf collimator and
   emittance exchange beamline
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB We report the development of a multileaf collimator (MLC) for charged particle beams, based on independently actuated tungsten strips that can selectively scatter unwanted particles. The MLC is used in conjunction with an emittance exchange beamline to rapidly generate highly variable longitudinal bunch profiles. The developed MLC consists of 40 independent leaves that are 2 mm wide and can move up to 10 mm and operates in an ultrahigh vacuum environment, enabled by novel features such as magnetically coupled actuation. An experiment at the Argonne Wakefield Accelerator, which previously used inflexible, laser-cut masks for beam shaping before an emittance exchange beamline, was conducted to test functionality. The experiment demonstrated myriad transverse mask silhouettes, as measured on a scintillator downstream of the MLC, and the corresponding longitudinal profiles after emittance exchange, as measured using a transverse-deflecting cavity. Rapidly changing between mask shapes enables expeditious execution of various experiments without the downtime associated with traditional methods. The many degrees of freedom of the MLC can enable the optimization of experimental figures of merit using feed-forward control and advanced machine learning methods.
C1 [Majernik, N.; Andonian, G.; Lynn, W.; Lorch, C.; Rosenzweig, J. B.] Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
   [Kim, S.; Doran, S.; Wisniewski, E.; Whiteford, C.; Piot, P.; Power, J.] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Roussel, R.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Piot, P.] Northern Illinois Univ, De Kalb, IL 60115 USA.
RP Majernik, N (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
EM NMajernik@g.ucla.edu
CR Adelmann A., 2009, P 23 PARTICLE ACCELE
   Andonian G, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.054802
   Andonian G, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3592579
   Antipov S, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.134802
   Bane K. L., 1985, SLACPUB3662
   Barber S. K., 2015, THESIS U CALIFORNIA
   BOYER AL, 1992, MED PHYS, V19, P1255, DOI 10.1118/1.596757
   Chiadroni E, 2017, NUCL INSTRUM METH A, V865, P139, DOI 10.1016/j.nima.2017.01.017
   Ding Y, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.100703
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Emma P, 2006, PHYS REV SPEC TOP-AC, V9, DOI 10.1103/PhysRevSTAB.9.100702
   England RJ, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.214802
   Ferrari E, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.080701
   Gao Q, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.114801
   Ge YY, 2014, MED PHYS, V41, DOI 10.1118/1.4873682
   Ha G, 2022, REV MOD PHYS, V94, DOI 10.1103/RevModPhys.94.025006
   Ha G, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.104801
   Ha G, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.121301
   JORDAN TJ, 1994, PHYS MED BIOL, V39, P231, DOI 10.1088/0031-9155/39/2/002
   Lemery F, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.081301
   Loisch G, 2018, NUCL INSTRUM METH A, V909, P107, DOI 10.1016/j.nima.2018.02.043
   Loisch G, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.064801
   Majernik N, 2021, Arxiv, DOI arXiv:2107.00125
   Mitchell C, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.060703
   Muggli P, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.054801
   Piot P, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.034801
   Rosenzweig JB, 2010, AIP CONF PROC, V1299, P500, DOI 10.1063/1.3520373
   Roussel R, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.044802
   Scheinker A, 2022, IEEE T CONTR SYST T, V30, P2261, DOI 10.1109/TCST.2021.3136133
   Sudar N, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.051301
   Sun YE, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.234801
   Sun Y.-E, 2007, 2007 IEEE Particle Accelerator Conference, P3441, DOI 10.1109/PAC.2007.4440452
   Xiang D, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.114001
   Yakimenko V, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.101301
NR 34
TC 0
Z9 0
U1 2
U2 3
PD FEB 22
PY 2023
VL 26
IS 2
AR 022801
DI 10.1103/PhysRevAccelBeams.26.022801
UT WOS:000936523400003
DA 2023-11-16
ER

PT C
AU Krulis, M
   Kratochvíl, M
AF Krulis, Martin
   Kratochvil, Miroslav
GP ACM
TI Detailed Analysis and Optimization of CUDA K-means Algorithm
SO PROCEEDINGS OF THE 49TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING,
   ICPP 2020
SE Proceedings of the International Conference on Parallel Processing
DT Proceedings Paper
CT 49th International Conference on Parallel Processing (ICPP)
CY AUG 17-20, 2020
CL Edmonton, CANADA
DE k-means; clustering; cuda; performance optimization
ID MEANS CLUSTERING-ALGORITHM
AB K-means is one of the most frequently used algorithms for unsupervised clustering data analysis. Individual steps of the k-means algorithm include nearest neighbor finding, efficient distance computation, and cluster-wise reduction, which may be generalized to many other purposes in data analysis, visualization, and machine learning. Efficiency of the available implementations of k-means computation steps therefore directly affect many other applications. In this work, we examine the performance limits in the context of modern massively parallel GPU accelerators. Despite the existence of many published papers on this topic, we have found that crucial performance aspects of the GPU implementations remain unaddressed, including the optimizations for memory bandwidth, cache limits, and workload dispatching on problem instances of varying cluster count, dataset size, and dimensionality. We present a detailed analysis of individual computation steps and propose several optimizations that improve the overall performance on contemporary GPU architectures. Our open-source prototype exhibits significant speedup over the current state-of-the-art implementations in virtually all practical scenarios.
C1 [Krulis, Martin; Kratochvil, Miroslav] Charles Univ Prague, Dept Software Engn, Fac Math & Phys, Prague, Czech Republic.
RP Krulis, M (corresponding author), Charles Univ Prague, Dept Software Engn, Fac Math & Phys, Prague, Czech Republic.
EM krulis@ksi.mff.cuni.cz; kratochvil@ksi.mff.cuni.cz
CR Aghaeepour N, 2011, CYTOM PART A, V79A, P6, DOI 10.1002/cyto.a.21007
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Chiranjeevi K, 2018, IMAGE ANAL STEREOL, V37, P35, DOI 10.5566/ias.1611
   Cuomo S, 2019, COMPUT ELECTR ENG, V75, P262, DOI 10.1016/j.compeleceng.2017.12.002
   Dafonte C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051419
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Ding YF, 2015, PR MACH LEARN RES, V37, P579
   Farivar Reza, 2008, Proceedings of the 2008 International Conference on Parallel and Distributed Processing Techniques and Applications. (PDPTA 2008), P340
   Jain A.K., 1988, ALGORITHMS CLUSTERIN
   Kaufman L, 2009, FINDING GROUPS DATA
   Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105
   Kratochvíl M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71
   Krulis M, 2017, MULTIMED TOOLS APPL, V76, P11859, DOI 10.1007/s11042-016-3677-7
   Krulis M, 2016, MULTIMED TOOLS APPL, V75, P8071, DOI 10.1007/s11042-015-2726-y
   Li SR, 2015, LECT NOTES COMPUT SC, V9371, P259, DOI 10.1007/978-3-319-25087-8_25
   Li Y, 2013, J COMPUT SYST SCI, V79, P216, DOI 10.1016/j.jcss.2012.05.004
   Lutz Clemens, 2018, Datenbank-Spektrum, V18, P157, DOI 10.1007/s13222-018-0293-x
   Mahajan M, 2012, THEOR COMPUT SCI, V442, P13, DOI 10.1016/j.tcs.2010.05.034
   Nelson J, 2019, PROCEEDINGS OF THE TENTH INTERNATIONAL WORKSHOP ON PROGRAMMING MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM 2019), P11, DOI 10.1145/3303084.3309488
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Redmond SJ, 2007, PATTERN RECOGN LETT, V28, P965, DOI 10.1016/j.patrec.2007.01.001
   Shalom SAA, 2008, LECT NOTES COMPUT SC, V5182, P166, DOI 10.1007/978-3-540-85836-2_16
   Van Gassen S, 2015, CYTOM PART A, V87A, P636, DOI 10.1002/cyto.a.22625
   Zheng X, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0309-3
NR 25
TC 3
Z9 3
U1 0
U2 0
PY 2020
AR 69
DI 10.1145/3404397.3404426
UT WOS:001062717800029
DA 2023-11-16
ER

PT J
AU Rakka, M
   Fouda, ME
   Kanj, R
   Kurdahi, F
AF Rakka, Mariam
   Fouda, Mohammed E.
   Kanj, Rouwaida
   Kurdahi, Fadi
TI DT2CAM: A Decision Tree to Content Addressable Memory Framework
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Ternary content addressable memory; decision tree; machine learning;
   hardware compiler; synthesizer
AB Decision trees are powerful tools for data classification. Accelerating the decision tree search is crucial for on-theedge applications with limited power and latency budget. In this article, we propose a content-addressable memory compiler for decision tree inference acceleration. We propose a novel '' adaptiveprecision '' scheme that results in a compact implementation and enables an efficient bijective mapping to ternary content addressable memories while maintaining high inference accuracies. We also develop a resistive-based functional synthesizer to map the decision tree to resistive content addressable memory arrays and perform functional simulations for energy, latency, and accuracy evaluations. We study the decision tree accuracy under hardware non-idealities including device defects, manufacturing variability, and input encoding noise. We test our framework on various decision tree datasets including Give Me Some Credit, Titanic, and COVID-19. Our results reveal up to 42.4% energy savings and up to 17.8x better energy-delay-area product compared to the state-ofart hardware accelerators, and up to 333 million decisions per sec for the pipelined implementation.
C1 [Rakka, Mariam; Fouda, Mohammed E.; Kurdahi, Fadi] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
   [Fouda, Mohammed E.] Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza 3247010, Egypt.
   [Kanj, Rouwaida] Amer Univ Beirut, ECE Dept, Beirut 11072020, Lebanon.
RP Fouda, ME (corresponding author), Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.; Fouda, ME (corresponding author), Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza 3247010, Egypt.
EM mrakka@uci.edu; foudam@uci.edu; rk105@aub.edu.lb; kurdahi@uci.edu
CR [Anonymous], TIT PROB
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bussmann N, 2021, COMPUT ECON, V57, P203, DOI 10.1007/s10614-020-10042-0
   Chen TW, 2012, IEEE T VLSI SYST, V20, P2329, DOI 10.1109/TVLSI.2011.2170203
   Chiu PF, 2016, IEEE ASIAN SOLID STA, P181, DOI 10.1109/ASSCC.2016.7844165
   Dua D., 2017, UCI MACHINE LEARNING
   Fouda M. E., 2022, IN MEMORY ASSOCIATIV
   Kaggle, ABOUT US
   Kak S, 2016, CIRC SYST SIGNAL PR, V35, P1419, DOI 10.1007/s00034-015-0120-7
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Lee KJ, 2015, IEEE J SOLID-ST CIRC, V50, P1059, DOI 10.1109/JSSC.2014.2380790
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Pedretti G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25873-0
   Rakka M, 2021, IEEE T CIRCUITS-II, V68, P762, DOI 10.1109/TCSII.2020.3017477
   Rakka M., 2022, THESIS U CALIFORNIA
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Xu B, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0448-0
   Yeo I, 2019, IEEE T ELECTRON DEV, V66, P2937, DOI 10.1109/TED.2019.2914460
NR 20
TC 0
Z9 0
U1 0
U2 0
PD JUL-SEP
PY 2023
VL 11
IS 3
BP 805
EP 810
DI 10.1109/TETC.2023.3261748
UT WOS:001063339400019
DA 2023-11-16
ER

PT J
AU Wang, GQ
   Zhang, PF
   Wang, DX
   Chen, HM
   Li, TR
AF Wang, Guoqiang
   Zhang, Pengfei
   Wang, Dexian
   Chen, Hongmei
   Li, Tianrui
TI Fast attribute reduction via inconsistent equivalence classes for
   large-scale data
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
DT Article
DE Rough set; Attribute reduction; Granular computing; Hash table; Big data
ID DEPENDENCY CALCULATION TECHNIQUE; ROUGH SET; FEATURE-SELECTION;
   INDISCERNIBILITY; UNCERTAINTY; ACCELERATOR; ALGORITHMS; ENTROPY
AB Feature selection, also known as attribute reduction, plays a crucial role in machine learning and data mining tasks. Rough set theory-based feature selection methods have gained popularity due to their ability to handle imprecise and inconsistent data, ease of implementation, and generation of highly interpretable results. However, these methods still suffer from high computational cost when dealing with large-scale datasets with high dimensions. To overcome this shortcoming, we propose a fast attribute reduction method based on inconsistent equivalence classes. The presented method can accelerate those attribute reduction algorithms whose importance measures used can be computed using only inconsistent equivalence classes. Our proposed method improves attribute reduction efficiency through three key aspects: 1) transforming the original dataset into an equivalently simplified version with fewer samples, 2) accelerating the computation of core attributes, and 3) expediting the forward selection process by removing redundant objects and attributes. Experimental results demonstrate the high computational efficiency of our proposed method.
C1 [Wang, Guoqiang; Chen, Hongmei; Li, Tianrui] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Wang, Guoqiang; Chen, Hongmei; Li, Tianrui] Southwest Jiaotong Univ, Inst Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Wang, Guoqiang; Chen, Hongmei; Li, Tianrui] Southwest Jiaotong Univ, Natl Engn Lab Integrated Transportat Big Data Appl, Chengdu 611756, Peoples R China.
   [Zhang, Pengfei] Chengdu Univ Tradit Chinese Med, Sch Intelligent Med, Chengdu 611137, Peoples R China.
RP Li, TR (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
EM gqwang18@163.com; feifeihappy55@163.com; gqwang18@163.com;
   hmchen@swjtu.edu.cn; trli@swjtu.edu.cn
CR An S, 2021, INT J APPROX REASON, V139, P130, DOI 10.1016/j.ijar.2021.09.014
   Chen DG, 2012, IEEE T KNOWL DATA EN, V24, P2080, DOI 10.1109/TKDE.2011.89
   Chen Z, 2022, INT J APPROX REASON, V140, P75, DOI 10.1016/j.ijar.2021.09.016
   Dai JH, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101951
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   Deng TQ, 2022, INT J APPROX REASON, V151, P251, DOI 10.1016/j.ijar.2022.09.012
   Fan J, 2017, INFORM SCIENCES, V397, P15, DOI 10.1016/j.ins.2017.02.032
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Ge H, 2017, INT J APPROX REASON, V82, P56, DOI 10.1016/j.ijar.2016.11.016
   Hu QH, 2007, LECT NOTES COMPUT SC, V4426, P96
   Hu QH, 2010, IEEE T SYST MAN CY B, V40, P137, DOI 10.1109/TSMCB.2009.2024166
   HU XH, 1995, COMPUT INTELL-US, V11, P323, DOI 10.1111/j.1467-8640.1995.tb00035.x
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   Lei L, 2018, APPL SOFT COMPUT, V62, P923, DOI 10.1016/j.asoc.2017.09.029
   Leung Y, 2006, EUR J OPER RES, V168, P164, DOI 10.1016/j.ejor.2004.03.032
   Li Y, 2023, INT J APPROX REASON, V160, DOI 10.1016/j.ijar.2023.108974
   Liang JY, 2014, IEEE T KNOWL DATA EN, V26, P294, DOI 10.1109/TKDE.2012.146
   Liang JY, 2013, KNOWL-BASED SYST, V44, P90, DOI 10.1016/j.knosys.2013.01.027
   Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635
   Liu KY, 2022, INT J APPROX REASON, V148, P57, DOI 10.1016/j.ijar.2022.05.011
   Liu Y, 2020, INT J APPROX REASON, V118, P1, DOI 10.1016/j.ijar.2019.11.010
   Luo C, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118554
   Mao H, 2023, EXPERT SYST APPL, V234, DOI 10.1016/j.eswa.2023.121062
   Meng ZQ, 2016, INFORM SCIENCES, V330, P226, DOI 10.1016/j.ins.2015.09.057
   Thuy NN, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.106999
   Thuy NN, 2019, EXPERT SYST APPL, V137, P308, DOI 10.1016/j.eswa.2019.06.071
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Qian J, 2011, INT J APPROX REASON, V52, P212, DOI 10.1016/j.ijar.2010.07.011
   Qian J, 2015, KNOWL-BASED SYST, V73, P18, DOI 10.1016/j.knosys.2014.09.001
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2018, INT J APPROX REASON, V97, P38, DOI 10.1016/j.ijar.2018.01.008
   Qian YH, 2015, FUZZY SET SYST, V258, P61, DOI 10.1016/j.fss.2014.04.029
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Raza MS, 2018, PATTERN RECOGN, V81, P309, DOI 10.1016/j.patcog.2018.04.009
   Raza MS, 2018, INT J APPROX REASON, V92, P175, DOI 10.1016/j.ijar.2017.10.012
   Raza MS, 2016, INFORM SCIENCES, V343, P41, DOI 10.1016/j.ins.2016.01.044
   Sang BB, 2022, IEEE T FUZZY SYST, V30, P1683, DOI 10.1109/TFUZZ.2021.3064686
   Skowron A., 1992, DISCERNIBILITY MATRI, V11, P331, DOI [10.1007/978-94-015-7975-9_21, DOI 10.1007/978-94-015-7975-9_21]
   Slezak D, 2002, FUND INFORM, V53, P365
   Sowkuntla P, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106677
   Stanczyk U, 2020, INT J APPROX REASON, V125, P187, DOI 10.1016/j.ijar.2020.07.005
   Stepaniuk J, 2023, INT J APPROX REASON, V155, P1, DOI 10.1016/j.ijar.2023.01.003
   Teng SH, 2016, INFORM SCIENCES, V326, P297, DOI 10.1016/j.ins.2015.07.052
   Wang DX, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101884
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GQ, 2021, INFORM SCIENCES, V571, P475, DOI 10.1016/j.ins.2021.05.007
   Wei W, 2015, KNOWL-BASED SYST, V86, P261, DOI 10.1016/j.knosys.2015.06.013
   Xiao JY, 2022, INT J APPROX REASON, V148, P117, DOI 10.1016/j.ijar.2022.05.012
   Yao JT, 2022, INT J APPROX REASON, V140, P1, DOI 10.1016/j.ijar.2021.09.011
   Yao YY, 2022, INT J APPROX REASON, V142, P231, DOI 10.1016/j.ijar.2021.11.012
   Yao YY, 2009, INFORM SCIENCES, V179, P867, DOI 10.1016/j.ins.2008.11.020
   Yu B, 2023, INT J APPROX REASON, V157, P88, DOI 10.1016/j.ijar.2023.03.002
   Zhang D, 2022, INT J APPROX REASON, V150, P98, DOI 10.1016/j.ijar.2022.08.005
   Zhang HY, 2023, INT J APPROX REASON, V154, P200, DOI 10.1016/j.ijar.2022.12.010
   Zhang PF, 2023, IEEE T FUZZY SYST, V31, P2975, DOI 10.1109/TFUZZ.2023.3238803
   Zhang PF, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3193929
   Zhang PF, 2022, INT J APPROX REASON, V140, P7, DOI 10.1016/j.ijar.2021.09.017
   Zhao J, 2020, INFORM SCIENCES, V536, P431, DOI 10.1016/j.ins.2020.03.092
   Zhao J, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107517
NR 59
TC 0
Z9 0
U1 1
U2 1
PD DEC
PY 2023
VL 163
AR 109039
DI 10.1016/j.ijar.2023.109039
EA OCT 2023
UT WOS:001087921700001
DA 2023-11-16
ER

PT J
AU Mannocci, P
   Pedretti, G
   Giannone, E
   Melacarne, E
   Sun, Z
   Ielmini, D
AF Mannocci, Piergiulio
   Pedretti, Giacomo
   Giannone, Elisabetta
   Melacarne, Enrico
   Sun, Zhong
   Ielmini, Daniele
TI A Universal, Analog, In-Memory Computing Primitive for Linear Algebra
   Using Memristors
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Linear systems; Integrated circuit modeling; Linear regression;
   Mathematical models; Covariance matrices; Bandwidth; SPICE; In-memory
   computing; resistive memory; hardware accelerator; linear regression;
   linear systems
ID LEAST-SQUARES ESTIMATE
AB The increasing demand for data-intensive computing applications, such as artificial intelligence (AI) and more specifically machine learning (ML), raises the need for novel computing hardware architectures capable of massive parallelism in performing core algebraic operations. Among the new paradigms, in-memory computing (IMC) with analogue devices is attracting significant interest for its large-scale integration potential, together with unrivaled speed and energy performance. Here, we present a fully-analogue, universal primitive capable of executing linear algebra operations such as regression, generalized least-square minimization and linear system solution with and without preconditioning. We study the impact of the main circuit parameters on accuracy and bandwidth with analytical closed-form expressions and SPICE simulations. Scaling challenges due to parasitic resistance/capacitance and their impact on key parameters such as bandwidth and accuracy are discussed. Finally, a comparison with existing solvers belonging to the same IMC framework is made to assess advantages and disadvantages of the proposed circuit.
C1 [Mannocci, Piergiulio; Giannone, Elisabetta; Melacarne, Enrico; Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
   [Pedretti, Giacomo] Hewlett Packard Labs, Milpitas, CA 95035 USA.
   [Sun, Zhong] Peking Univ PKU, Sch Integrated Circuits, Inst Artificial Intelligence, Beijing 100871, Peoples R China.
RP Mannocci, P; Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
EM piergiulio.mannocci@polimi.it; daniele.ielmini@polimi.it
CR [Anonymous], 2013, INT TECHNOLOGY ROADM
   [Anonymous], 1989, ANALOG VLSI NEURAL S
   Barthelemy H, 1997, ELECTRON LETT, V33, P1662, DOI 10.1049/el:19971170
   BUNCH JR, 1980, LINEAR ALGEBRA APPL, V34, P341, DOI 10.1016/0024-3795(80)90172-X
   Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Fouda ME, 2018, IEEE T CIRCUITS-I, V65, P270, DOI 10.1109/TCSI.2017.2714101
   Golub GH, 2000, J COMPUT APPL MATH, V123, P35, DOI 10.1016/S0377-0427(00)00413-1
   Golub GH, 1998, SIAM J SCI COMPUT, V19, P530, DOI 10.1137/S106482759529382X
   Horn R. A., 2012, MATRIX ANAL, DOI DOI 10.1017/CBO9781139020411
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   LOVELL MC, 1963, J AM STAT ASSOC, V58, P993, DOI 10.2307/2283327
   Luo YCA, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329062
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   MUCHA I, 1992, ELECTRON LETT, V28, P2071, DOI 10.1049/el:19921327
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Parthipan A, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P702, DOI [10.1109/iccmc.2019.8819641, 10.1109/ICCMC.2019.8819641]
   Pedretti G, 2021, IEEE T ELECTRON DEV, V68, P4379, DOI 10.1109/TED.2021.3095430
   Pedretti G, 2020, IEEE J EXPLOR SOLID-, V6, P89, DOI 10.1109/JXCDC.2020.2992691
   Small J. S., 2013, ANALOGUE ALTERNATIVE, P1930
   Truong SN, 2019, MICROMACHINES-BASEL, V10, DOI 10.3390/mi10100671
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P2945, DOI 10.1109/TED.2020.2992435
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Tisseur F, 2001, SIAM REV, V43, P235, DOI 10.1137/S0036144500381988
   UYENOYAMA MK, 1995, GENETICS, V139, P975
   Wang AL, 2018, INTEGRATION, V62, P246, DOI 10.1016/j.vlsi.2018.03.010
   Williams M. R, 1985, PRENTICE HALL SERIES
   Wu W, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P103, DOI 10.1109/VLSIT.2018.8510690
   Yalavarthy PK, 2007, MED PHYS, V34, P2085, DOI 10.1118/1.2733803
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 39
TC 9
Z9 9
U1 5
U2 15
PD DEC
PY 2021
VL 68
IS 12
BP 4889
EP 4899
DI 10.1109/TCSI.2021.3122278
UT WOS:000724482800010
DA 2023-11-16
ER

PT C
AU Rolandi, PA
AF Rolandi, Pablo A.
BE Munoz, SG
   Laird, CD
   Realff, MJ
TI THE UNREASONABLE EFFECTIVENESS OF EQUATIONS: ADVANCED MODELING FOR
   BIOPHARMACEUTICAL PROCESS DEVELOPMENT
SO PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON FOUNDATIONS OF
   COMPUTER-AIDED PROCESS DESIGN
SE Computer Aided Chemical Engineering
DT Proceedings Paper
CT 9th International Conference on the Foundations of Computer Aided
   Process Design (FOCAPD)
CY JUL 14-18, 2019
CL CO
DE Biotechnology; biopharmaceutical product and process development;
   process systems engineering; first principles modeling; computer-aided
   product and process design; community of practice
ID DESIGN; SYSTEMS; CHROMATOGRAPHY; OPTIMIZATION; UNCERTAINTY; STRATEGIES;
   PREDICTION; FRAMEWORK; BEHAVIOR; PRODUCT
AB Advanced modeling based on first principles approaches is an effective methodology for designing biopharmaceutical process and product systems that are reliable, efficient, agile, and differentiated. However, the industrial modeling practice has stagnated despite significant advances in other fields, and the digital accelerators (computing power, storage capacity, and bandwidth) have created a shifting landscape for the foundations of process systems engineering. This article argues for a stronger emphasis on modeling lifecycle frameworks as well as a clear focus on systematic value creation through greater immediate application and sustained utilization of models and advanced modeling methodologies. Convergence between first principles modeling, experimental methods, and machine learning techniques is postulated as the main direction for innovation. Modeling patterns are presented as a novel mechanism to create and reuse effective modeling abstractions. A community-centric approach to collaboration between industry, vendors, and academia is required to deliver these significant innovation needs.
C1 [Rolandi, Pablo A.] Amgen Inc, Proc Dev, Digital Integrat & Predict Technol, Cambridge, MA 02142 USA.
RP Rolandi, PA (corresponding author), Amgen Inc, Proc Dev, Digital Integrat & Predict Technol, Cambridge, MA 02142 USA.
CR [Anonymous], 2011, DAKOTA MULTILEVEL PA
   Au SK, 2001, PROBABILIST ENG MECH, V16, P263, DOI 10.1016/S0266-8920(01)00019-4
   Banerjee S, 2017, J CHROMATOGR A, V1511, P45, DOI 10.1016/j.chroma.2017.06.059
   Basu P, 2013, LEADING PHARM OPERAT, P445
   Betancourt M., 2017, ARXIV170102434STATME
   Bonvin D, 2016, IND ENG CHEM RES, V55, P6891, DOI 10.1021/acs.iecr.5b04801
   CHEN R. T., 2018, ADV NEURAL INFORM PR, P6571
   Cickovski T, 2005, 27 INT C SOFTW ENG
   Close EJ, 2014, CHEM ENG SCI, V116, P284, DOI 10.1016/j.ces.2014.03.010
   Coley CW, 2017, J CHEM INF MODEL, V57, P1757, DOI 10.1021/acs.jcim.6b00601
   Coley CW, 2017, ACS CENTRAL SCI, V3, P434, DOI 10.1021/acscentsci.7b00064
   Cooney B., 2016, BIOPROCESS INT, P28
   Courtois F, 2016, MABS-AUSTIN, V8, P99, DOI 10.1080/19420862.2015.1112477
   Crowell LE, 2018, NAT BIOTECHNOL, V36, P988, DOI 10.1038/nbt.4262
   Diedrich J, 2017, J CHROMATOGR A, V1525, P60, DOI 10.1016/j.chroma.2017.09.039
   DONALDSON JR, 1987, TECHNOMETRICS, V29, P67, DOI 10.2307/1269884
   Estefan J. A, 2008, INCOSE MBSE INITIATI, V25
   European Medicines Agency, 2012, POINTS CONS ICH Q8 Q
   Foss BA, 1998, J PROCESS CONTR, V8, P325, DOI 10.1016/S0959-1524(98)00018-3
   Galleguillos SN, 2017, COMPUT STRUCT BIOTEC, V15, P212, DOI 10.1016/j.csbj.2017.01.005
   Gamma Erich, 1994, DESIGN PATTERNS ELEM, V1st
   García-Muñoz S, 2015, ORG PROCESS RES DEV, V19, P1012, DOI 10.1021/acs.oprd.5b00158
   Gilsing V, 2006, RES POLICY, V35, P1, DOI 10.1016/j.respol.2005.06.007
   Glen KE, 2018, BIOCHEM ENG J, V133, P28, DOI 10.1016/j.bej.2018.01.033
   Goodman J, 2010, COMM APP MATH COM SC, V5, P65, DOI 10.2140/camcos.2010.5.65
   Guyon I., 2018, HAL01906197
   Halevy A., 2009, IEEE INTELLIGENT SYS
   Hariharan P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178749
   Hase F., 2019, CHEM SCI
   Hefzi H, 2016, CELL SYST, V3, P434, DOI 10.1016/j.cels.2016.10.020
   Hong MS, 2018, COMPUT CHEM ENG, V110, P106, DOI 10.1016/j.compchemeng.2017.12.007
   Johnson FT, 2005, COMPUT FLUIDS, V34, P1115, DOI 10.1016/j.compfluid.2004.06.005
   Klatt KU, 2009, COMPUT CHEM ENG, V33, P536, DOI 10.1016/j.compchemeng.2008.09.002
   KLEIJNEN JPC, 1995, EUR J OPER RES, V82, P145, DOI 10.1016/0377-2217(94)00016-6
   Kreutz C, 2012, BMC SYST BIOL, V6, DOI 10.1186/1752-0509-6-120
   Lee JH, 2018, COMPUT CHEM ENG, V114, P111, DOI 10.1016/j.compchemeng.2017.10.008
   Lee SL, 2015, J PHARM INNOV, V10, P191, DOI 10.1007/s12247-015-9215-8
   LeVeque RJ, 2012, COMPUT SCI ENG, V14, P13, DOI 10.1109/MCSE.2012.38
   Leweke S, 2018, COMPUT CHEM ENG, V113, P274, DOI 10.1016/j.compchemeng.2018.02.025
   Love KR, 2018, CURR OPIN BIOTECH, V53, P50, DOI 10.1016/j.copbio.2017.12.010
   Marzouk YM, 2007, J COMPUT PHYS, V224, P560, DOI 10.1016/j.jcp.2006.10.010
   Miller D.C., 2018, COMPUT AIDED CHEM EN, V44, P2209, DOI DOI 10.1016/B978-0-444-64241-7.50363-3
   Mockus L, 2011, INFORMATICA-LITHUAN, V22, P537
   Morresi T., 2018, ADV THEOR SIMUL, P1
   Muñoz SG, 2016, CHEM ENG RES DES, V109, P532, DOI 10.1016/j.cherd.2016.03.005
   Nagy ZK, 2007, J PROCESS CONTR, V17, P229, DOI 10.1016/j.jprocont.2006.10.008
   Olofsson S, 2018, ARXIV181002561V2SCMS
   Papaioannou V, 2016, FLUID PHASE EQUILIBR, V416, P104, DOI 10.1016/j.fluid.2015.12.041
   Patterson EA, 2017, PROG BIOPHYS MOL BIO, V129, P13, DOI 10.1016/j.pbiomolbio.2016.08.007
   Rios LM, 2013, J GLOBAL OPTIM, V56, P1247, DOI 10.1007/s10898-012-9951-y
   Rodríguez-Gómez G, 2004, Proceedings of the Fourth IASTED International Conference on Modelling, Simulation, and Optimization, P247
   Saltelli A, 2006, RELIAB ENG SYST SAFE, V91, P1109, DOI 10.1016/j.ress.2005.11.014
   Samsatli NJ, 2001, AICHE J, V47, P2277, DOI 10.1002/aic.690471013
   Sculley D, 2015, ADV NEURAL INFORM PR, V28, P1
   Seely J. E, 2012, BIOPROCESS INT
   Sharp Phillip. A., 2011, 3 REVOLUTION CONVERG
   Shen DYE, 2016, AICHE J, V62, P3310, DOI 10.1002/aic.15373
   Shukla AA, 2017, BIOENG TRANSL MED, V2, P58, DOI 10.1002/btm2.10061
   Simulation Interoperability Standards Organization, 2012, GUID GEN METH VER VA, V2
   Smith RL, 2009, J AM STAT ASSOC, V104, P97, DOI 10.1198/jasa.2009.0007
   Stephanopoulos G, 2011, CHEM ENG SCI, V66, P4272, DOI 10.1016/j.ces.2011.05.049
   Storer T. I. M, 2017, BRIDGING CHASM SURVE, V50, P4
   Teeters M, 2011, BIOTECHNOL BIOENG, V108, P1338, DOI 10.1002/bit.23067
   Tinner F., 2016, BLENDED FINANCE BLEN, P1
   Van Norman Gail A, 2016, JACC Basic Transl Sci, V1, P399, DOI 10.1016/j.jacbts.2016.06.003
   Vasileiadis M, 2015, CHEM ENG SCI, V121, P60, DOI 10.1016/j.ces.2014.08.058
   Venkatasubramanian V., 2019, AICHE J, V65, P1
   Villaverde AF, 2015, BMC SYST BIOL, V9, DOI 10.1186/s12918-015-0144-4
   Welch CJ, 2017, ORG PROCESS RES DEV, V21, P414, DOI 10.1021/acs.oprd.6b00427
   WIGNER EP, 1960, COMMUN PUR APPL MATH, V13, P1, DOI 10.1002/cpa.3160130102
   Yu LX, 2008, PHARM RES, V25, P781, DOI 10.1007/s11095-007-9511-1
NR 71
TC 5
Z9 5
U1 0
U2 4
PY 2019
VL 47
BP 137
EP 150
DI 10.1016/B978-0-12-818597-1.50023-0
UT WOS:000495451900023
DA 2023-11-16
ER

PT C
AU Jaswal, MK
   Roy, SK
AF Jaswal, Manpreet Kaur
   Roy, Subir Kumar
GP IEEE
TI DynRP- Non-Intrusive Profiler for Dynamic Reconfigurability
SO 2020 24TH INTERNATIONAL SYMPOSIUM ON VLSI DESIGN AND TEST (VDAT)
SE International Symposium on VLSI Design and Test-VDAT
DT Proceedings Paper
CT 24th International Symposium on VLSI Design and Test (VDAT)
CY JUL 23-25, 2020
CL Bhubaneswar, INDIA
DE Dynamic reconfiguration; FPGA; non-intrusive profiling;
   hardware-software partitioning
AB Emerging technological areas such as machine learning, speech recognition, computer vision, autonomous robots, AI, bioinformatics involving big data, require implementation in complex heterogeneous accelerator platforms, to be able to handle data explosion with higher efficiency, lower power, and better performance. Dynamic reconfiguration in such platforms can help in run-time optimization to meet the design goals. The required optimal platform configuration can be achieved by a flexible design space exploration and appropriate task partitioning obtained through profiling computation and communication of processes in application code. This paper focuses on profiling, it being the key to the success of obtaining optimal platform configurations. It points to existing profiling techniques, their pros and cons vis-a-vis dynamic reconfigurable architectures, and the challenges in their design for obtaining optimal profiling performance. It further outlines desirable specifications for a profiler to allow dynamic real-time profiling for effective use of dynamic reconfiguration. DynRP, a non-intrusive hardware profiler for dynamic reconfiguration is proposed based on the desirable specifications, followed by its design and implementation details.
C1 [Jaswal, Manpreet Kaur; Roy, Subir Kumar] Int Inst Informat Technol Bangalore, Bangalore, Karnataka, India.
RP Jaswal, MK (corresponding author), Int Inst Informat Technol Bangalore, Bangalore, Karnataka, India.
EM manpreet.jaswal@iiitb.org; subir@iiitb.ac.in
CR [Anonymous], 2007, P 4 INT C COMP FRONT
   [Anonymous], POW BENCHM SUIT
   [Anonymous], 2004, PROC ACMSIGDA 12 INT
   [Anonymous], CHSTONE BENCHM SUIT
   Belwal Meena, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7294022
   Compton K, 2002, ACM COMPUT SURV, V34, P171, DOI 10.1145/508352.508353
   Gajski DD, 2009, EMBEDDED SYSTEM DESIGN: MODELING, SYNTHESIS AND VERIFICATION, P1, DOI 10.1007/978-1-4419-0504-8_1
   Gericota MG, 2008, IEEE T VLSI SYST, V16, P1545, DOI 10.1109/TVLSI.2008.2001141
   Kumar N. P., 2016, THESIS
   Mu JQ, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2442116.2442135
   Shannon L, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, PROCEEDINGS, P231, DOI 10.1109/FPT.2004.1393273
   Tessier R, 2015, P IEEE, V103, P332, DOI 10.1109/JPROC.2014.2386883
   Tong J. G., 2007, P 19 INT C MICR DEC, P253
   Wang C., 2017, ARXIV171204771
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/vdat50263.2020.9190415
UT WOS:000629199100028
DA 2023-11-16
ER

PT C
AU Deng, CH
   Yin, M
   Liu, XY
   Wang, XD
   Yuan, B
AF Deng, Chunhua
   Yin, Miao
   Liu, Xiao-Yang
   Wang, Xiaodong
   Yuan, Bo
GP IEEE
TI High-performance Hardware Architecture for Tensor Singular Value
   Decomposition
SO 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 38th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 04-10, 2019
CL Westminster, CO
DE Tensor decomposition; t-SVD; hardware architecture
AB Tensor provides a brief and natural representation for large-scale multidimensional data by way of appropriate low-rank approximations, thus we can discover significant latent structures of complex data and generalize data representation. To date, tensor has gained tremendous success in various science and technology fields, especially in machine learning and big data applications. However, tensor computation, especially tensor decomposition, is usually expensive due to the inherent large-size characteristic of tensors, and hence would potentially hinder their future wide deployment. In this paper, we develop a hardware architecture to accelerate tensor singular value decomposition (t-SVD), which is a new tensor decomposition technique that has been successfully applied to high-dimensional data classification and video recovery. Specifically, design consideration of each key computing unit is analyzed and discussed. Then, the proposed t-SVD hardware architecture is implemented and synthesized using CMOS 28nm technology. Comparison with real-world CPU-based implementations shows that the proposed hardware accelerator is expected to provide average 14x speedup on various t-SVD workloads.
C1 [Deng, Chunhua; Yin, Miao; Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08901 USA.
   [Liu, Xiao-Yang; Wang, Xiaodong] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
RP Deng, CH (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08901 USA.
EM chunhua.deng@rutgers.edu; miao.yin@rutgers.edu; xl2427@columbia.edu;
   xw2008@columbia.edu; bo.yuan@soe.rutgers.edu
CR a Harshman R., 1970, UCLA WORKING PAPERS, V16, P1, DOI DOI 10.1134/S0036023613040165
   Brent R. P., 1982, TECH REP
   CARROLL JD, 1970, PSYCHOMETRIKA, V35
   Cavallaro J. R., 1988, J PARALLEL DISTRIBUT, V5
   Dongarra J, 2018, SIAM REV, V60, P808, DOI 10.1137/17M1117732
   Hu Y., 2015, P 23 ACM INT C MULT
   Jia C., 2016, IEEE T IMAGE PROCESS, V25
   Jiang F, 2018, AAAI CONF ARTIF INTE, P3326
   Kilmer M. E., 2011, LINEAR ALGEBRA ITS A, V435
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kim YD, 2015, ARXIV151106530
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Lebedev V, 2015, 3 INT C LEARNING REP
   Li S., 2015, INT C IM PROC ICIP
   Liao S., 2019, INT C AC SPEECH SIGN
   Lim L.-H., 2010, COMPTES RENDUS MECAN, V338
   Liu X.-Y., 2015, IEEE T MOBILE COMPUT, V15
   Novikov A., 2015, TENSORIZING NEURAL N, P442
   Oseledets I. V., 2011, SIAM J SCI COMPUTING, V33
   Tao D., 2017, IEEE T IMAGE PROCESS, V27
   Tucker L. R., 1966, PSYCHOMETRIKA, V31
   Wang WQ, 2018, PROC CVPR IEEE, P9329, DOI 10.1109/CVPR.2018.00972
   Yang Y., 2017, P 34 INT C MACH LEAR, V70
   Zhang Z., 2014, P IEEE C COMP VIS PA
   Zhao Q., 2016, ARXIV
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2019
UT WOS:000524676400041
DA 2023-11-16
ER

PT J
AU Lumpkin, AH
   Thurman-Keup, R
   Edstrom, D
   Prieto, P
   Ruan, J
   Jacobson, B
   Sikora, J
   Diaz-Cruz, J
   Edelen, A
   Zhou, F
AF Lumpkin, A. H.
   Thurman-Keup, R.
   Edstrom, D.
   Prieto, P.
   Ruan, J.
   Jacobson, B.
   Sikora, J.
   Diaz-Cruz, J.
   Edelen, A.
   Zhou, F.
TI Submacropulse electron-beam dynamics correlated with higher-order modes
   in a Tesla-type cryomodule
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB Experiments were performed at the Fermilab Accelerator Science and Technology facility to elucidate the effects of long-range wakefields in TESLA-type superconducting rf cavities. In particular, we investigated the higher-order modes (HOMs) generated in the eight, nine-cell cavities of a cryomodule (CM) due to off-axis steering with correctors located -4 m upstream of the CM. We have observed correlated submacropulse centroid slews of a few hundred microns and centroid oscillations at -240 kHz in the rf beam-position-monitor data after the CM. The entrance energy into the CM was 25 MeV, and the exit energy was 100 MeV with 125 pC/bunch and 400 pC/bunch in 50-bunch pulse trains. These experimental results were evaluated for machine learning training aspects which will be used to inform the commissioning plan for the Linac Coherent Light Source-II injector CM. With an entrance beam energy of < 1 MeV in this case (or for -6 MeV at the European X-ray Free-electron Laser injector), the HOM-effect mitigation would be particularly critical.
C1 [Lumpkin, A. H.; Thurman-Keup, R.; Edstrom, D.; Prieto, P.; Ruan, J.] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Jacobson, B.; Sikora, J.; Diaz-Cruz, J.; Edelen, A.; Zhou, F.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94720 USA.
   [Diaz-Cruz, J.] Univ New Mexico, Albuquerque, NM 87131 USA.
RP Lumpkin, AH (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM lumpkin@fnal.gov
CR Church M., 2013, TM2568 FERM NAT ACC
   Diaz-Cruz Jorge, 2021, P 12 INT PARTICLE AC
   Eddy N., 2011, P 10 EUR WORKSH BEAM
   Edelen A., ARXIV181103172
   Emma P., 2017, PROCEEDINGSOF 38 INT
   Fartoukh S., 1999, Proceedings of the 1999 Particle Accelerator Conference (Cat. No.99CH36366), P922, DOI 10.1109/PAC.1999.795401
   Frisch J, 2006, AIP CONF PROC, V868, P313
   Hellert T, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.123501
   Hellert Thorsten, 2017, P DESY SEMINAR
   Junhao Wei, 2021, NUCL INSTRUM METHO A, V1000, P165246
   Lumpkin AH, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.054401
   Lumpkin AH, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.064401
   Lumpkin A. H., 2021, P 12 INT PARTICLE AC
   Lumpkin A. H., 2021, P 12 INT PARTICLE AC
   Ruan J., 2013, P IPAC 13 SHANGH CHI, P3061
   Seeman J. T., P 1987 PARTICLE ACCE, P1349
   Sikora J., 2021, P 12 INT PARTICLE AC
   Thurman-Keup R., 2021, P 12 INT PARTICLE AC
   Wanzenberg R., 2001, DESYTESLA200133
   Wanzenberg Rainer, 2009, P SPL HOM WORKSHOP
   Wei JH, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082804
   Weise H., 2017, P 2017 FREE EL LAS C, P9, DOI 10.18429/JACoW-FEL2017-MOC03
   Zhang P, 2012, REV SCI INSTRUM, V83, DOI 10.1063/1.4748517
   Zhou F., 2017, P INT PARTICLE ACCEL
NR 24
TC 2
Z9 2
U1 0
U2 1
PD JUN 24
PY 2022
VL 25
IS 6
AR 064402
DI 10.1103/PhysRevAccelBeams.25.064402
UT WOS:000824311900001
DA 2023-11-16
ER

PT C
AU Zhang, KQ
   Zhang, XY
   Zhang, Z
AF Zhang, Kaiqi
   Zhang, Xiyuan
   Zhang, Zheng
GP IEEE
TI Tucker Tensor Decomposition on FPGA
SO 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 38th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 04-10, 2019
CL Westminster, CO
ID UNCERTAINTY QUANTIFICATION; SINGULAR-VALUE
AB Tensor computation has emerged as a powerful mathematical tool for solving high-dimensional and/or extreme-scale problems in science and engineering. The last decade has witnessed tremendous advancement of tensor computation and its applications in machine learning and big data. However, its hardware optimization on resource-constrained devices remains an (almost) unexplored field. This paper presents an hardware accelerator for a classical tensor computation framework, Tucker decomposition. We study three modules of this architecture: tensor-times-matrix (TTM), matrix singular value decomposition (SVD), and tensor permutation, and implemented them on Xilinx FPGA for prototyping. In order to further reduce the computing time, a warm-start algorithm for the Jacobi iterations in SVD is proposed. A fixed-point simulator is used to evaluate the performance of our design. Some synthetic data sets and a real MRI data set are used to validate the design and evaluate its performance. We compare our work with state-of-the-art software toolboxes running on both CPU and GPU, and our work shows 2.16-30.2x speedup on the cardiac MRI data set.
C1 [Zhang, Kaiqi; Zhang, Xiyuan; Zhang, Zheng] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
RP Zhang, KQ (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM kzhang70@ucsb.edu; xiyuanzhang@ucsb.edu; zhengzhang@ece.ucsb.edu
CR Ahmedsaid A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P35, DOI 10.1109/FPT.2003.1275729
   Amira A., 2001, Field Programmable Logic and Applications. 11th International Conference, FPL 2001. Proceedings (Lecture Notes in Computer Science Vol.2147), P101
   [Anonymous], 2005, PROC ACM SIGDA 13 IN
   Bader B.W., 2015, MATLAB TENSOR TOOLBO
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   BRENT RP, 1985, SIAM J SCI STAT COMP, V6, P69, DOI 10.1137/0906007
   Chien JT, 2018, IEEE T NEUR NET LEAR, V29, P1998, DOI 10.1109/TNNLS.2017.2690379
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   DEMMEL J, 1992, SIAM J MATRIX ANAL A, V13, P1204, DOI 10.1137/0613074
   Ding HS, 2017, PROC INT CONF DOC, P507, DOI 10.1109/ICDAR.2017.89
   HANSEN ER, 1963, J SOC IND APPL MATH, V11, P448, DOI 10.1137/0111032
   Hawkins C., 2019, ARXIV190510478
   HEMKUMAR ND, 1992, 1992 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-6, P1061, DOI 10.1109/ISCAS.1992.230297
   Hitchcock F.L., 1927, J MATH PHYS CAMB, V6, P164, DOI DOI 10.1002/SAPM192761164
   Irick KM, 2008, ANN IEEE SYM FIELD P, P304, DOI 10.1109/FCCM.2008.40
   Jing Li, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166928
   KAPTEYN A, 1986, PSYCHOMETRIKA, V51, P269, DOI 10.1007/BF02293984
   Kaya O, 2016, PROC INT CONF PARAL, P103, DOI 10.1109/ICPP.2016.19
   Kim YD, 2015, ARXIV151106530
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kolda TG, 2008, IEEE DATA MINING, P363, DOI 10.1109/ICDM.2008.89
   Kossaifi Jean, 2018, CORR
   KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599
   Lebedev V, 2015, 3 INT C LEARNING REP
   Li J, 2011, INT J MACH LEARN CYB, V2, P89, DOI 10.1007/s13042-011-0017-0
   Lingala SG, 2011, IEEE T MED IMAGING, V30, P1042, DOI 10.1109/TMI.2010.2100850
   Novikov A., 2015, TENSORIZING NEURAL N, P442
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Rahmati M, 2008, IEEE INT CONF ASAP, P185, DOI 10.1109/ASAP.2008.4580176
   Roohi SF, 2016, IEEE IMAGE PROC, P1769, DOI 10.1109/ICIP.2016.7532662
   Saito D., 2011, P INT C SPEECH COMM
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Smith S, 2017, INT PARALL DISTRIB P, P1058, DOI 10.1109/IPDPS.2017.84
   Stanislaus J. L. V. M., 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P671, DOI 10.1109/ICCNC.2013.6504167
   Tucker L.R., 1963, PROBLEMS MEASURING C, V15, P122
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Vasilescu MAO, 2002, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2002.1048350
   Volder J. E., 1959, ELECT COMPUTERS IRE, VEC-8, P330, DOI DOI 10.1109/TEC.1959.5222693
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Yang YC, 2017, PR MACH LEARN RES, V70
   Zhang Z, 2017, IEEE T COMP PACK MAN, V7, P687, DOI 10.1109/TCPMT.2016.2628703
   Zhang Z, 2015, IEEE T COMPUT AID D, V34, P63, DOI 10.1109/TCAD.2014.2369505
   Zhu JH, 2003, LECT NOTES COMPUT SC, V2778, P1062
NR 43
TC 4
Z9 4
U1 0
U2 0
PY 2019
DI 10.1109/iccad45719.2019.8942103
UT WOS:000524676400062
DA 2023-11-16
ER

PT C
AU Barbareschi, M
   De Benedictis, A
   Mazzeo, A
   Vespoli, A
AF Barbareschi, Mario
   De Benedictis, Alessandra
   Mazzeo, Antonino
   Vespoli, Antonino
BE Xhafa, F
   Barolli, L
   Li, J
   Yoshihisa, T
   Ogiela, MR
TI Mobile Traffic Analysis exploiting a Cloud Infrastructure and Hardware
   Accelerators
SO 2014 NINTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND
   INTERNET COMPUTING (3PGCIC)
DT Proceedings Paper
CT NINTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND
   INTERNET COMPUTING (3PGCIC)
CY NOV 08-10, 2014
CL BWCCA, Guangzhou, PEOPLES R CHINA
HO BWCCA
AB Recently, traffic analysis and measurements have been used to characterize, from a security point of view, applications' and network behavior to avoid intrusion attempts, malware injections and data theft. Since most of the generated data traffic is from the embedded mobile devices, the analysis techniques have to cope on the one hand with the scarce computing capabilities and battery limitation of the devices, and on the other hand with tight performance constraints due to the huge generated traffic. In recent years, several machine learning approaches have been proposed in the literature, providing different levels of accuracy and requiring high computation resources to extract the analytic model from available training set. In this paper, we discuss a traffic analysis architecture that exploits FPGA technology to efficiently implement a hardware traffic analyzer on mobile devices, and a cloud infrastructure for the dynamic generation and updating of the data model based on ongoing mis-classification events. Finally, we provide a case study based on the implementation of the proposed traffic analyzer on a Xilinx Zynq 7000 architecture and Android OS, and show an overview of the proposed cloud infrastructure.
C1 [Barbareschi, Mario; De Benedictis, Alessandra; Mazzeo, Antonino; Vespoli, Antonino] Univ Naples Federico II, Dept Elect Engn & Informat Technol, I-80125 Naples, NA, Italy.
RP Barbareschi, M (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, I-80125 Naples, NA, Italy.
EM mario.barbareschi@unina.it; alessandra.debenedictis@unina.it;
   antonino.mazzeo@unina.it; antonino.vespoli@unina.it
CR Amato Flora, 2013, Algorithms and Architectures for Parallel Processing. 13th International Conference, ICA3PP 2013. Proceedings: LNCS 8286, P125, DOI 10.1007/978-3-319-03889-6_14
   Amato F, 2014, STUD COMPUT INTELL, V511, P289, DOI 10.1007/978-3-319-01571-2_34
   [Anonymous], 2000, ARCHITECTURAL STYLES
   [Anonymous], 2013, CISCO VISUAL NETWORK
   [Anonymous], 2010, 10 ACM SIGCOMM C INT
   [Anonymous], SOFT COMPUTING
   [Anonymous], FIELD PROGR LOG APPL
   Barbareschi Mario, 2013, Algorithms and Architectures for Parallel Processing. 13th International Conference, ICA3PP 2013. Proceedings: LNCS 8286, P141, DOI 10.1007/978-3-319-03889-6_16
   Barbareschi M., 2014, INF REUS INT IRI 201
   Barbareschi M., 2013, ZEDROID ANDROID 2 2
   Casola Valentina, 2013, 2013 IEEE 14th International Conference on Information Reuse & Integration (IRI), P22, DOI 10.1109/IRI.2013.6642449
   Casola V., 2014, INTEGRATION REUSABLE, P299
   G. Inc, 2007, ANDR SOURC WEB SIT
   Hongwei Luo, 2012, 2012 1st IEEE International Conference on Communications in China (ICCC 2012), P214, DOI 10.1109/ICCChina.2012.6356880
   Hur M, 2012, 2012 14 AS PAC NETW, P1
   Jeong H, 2014, MACH VISION APPL, V25, P1501, DOI 10.1007/s00138-014-0629-y
   Lee S., 2011, P 13 AS PAC NETW OP, P1, DOI [10.1109/ICISA.2011.5772401, DOI 10.1007/S11042-011-0850-X]
   Salah Saber, 2011, 2011 International Conference on Mobile IT Convergence (ICMIC), P15
NR 18
TC 3
Z9 3
U1 0
U2 0
PY 2014
BP 414
EP 419
DI 10.1109/3PGCIC.2014.86
UT WOS:000380474400071
DA 2023-11-16
ER

PT C
AU Zhang, JL
   Beckwith, N
   Li, J
AF Zhang, Jialiang
   Beckwith, Nicholas
   Li, Jing (Jane)
GP IEEE Comp Soc
TI GORDON: Benchmarking Optane DC Persistent Memory Modules on FPGAs
SO 2021 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2021)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 29th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 09-12, 2021
CL ELECTR NETWORK
AB Scalable nonvolatile memory DIMMs become commercially available on FPGAs with the release of Intel's Optane DC Persistent Memory (DCPM) product. This new class of memory combines the benefits of DRAM-like solid-state memory (fast, byte addressable) and Flash-like persistent storage (cost-effective, non-volatile), making FPGA highly competitive in accelerating large-scale machine learning and data analytics applications. Despite of the great promise, the performance characteristics of Optane DCPM remains relatively alien to FPGA developers compared to conventional DDRx DRAM or SSD. Recent preliminary studies all use CPU-based systems running full OS stack that limits their ability to characterize the detailed performance characteristics of the Optane DCPM. To fully exploit the advantages of Optane DCPM in FPGA-based accelerator design, we present the first FPGA-based Optane DCPM profiling framework, named GORDON1 on Stratix 10 DX FPGA. By leveraging the flexibility of the FPGA in building custom logic and the FPGA-specific features for Optane DCPM, GORDON addresses the fundamental limitations of prior CPU-based profiling. The detailed understanding on Optane DCPM may also benefit system design and optimization beyond FPGAs using CPUs and GPUs.
C1 [Zhang, Jialiang; Beckwith, Nicholas; Li, Jing (Jane)] Univ Penn, Elect & Syst Engn, Philadelphia, PA 19104 USA.
RP Zhang, JL (corresponding author), Univ Penn, Elect & Syst Engn, Philadelphia, PA 19104 USA.
EM jlzhang@seas.upenn.edu; nickbeck@seas.upenn.edu; janeli@seas.upenn.edu
CR [Anonymous], 2019, 2019 IEEE HOT CHIPS, pI, DOI [10.1109/HOTCHIPS.2019.8875668, DOI 10.1109/HOTCHIPS.2019.8875668]
   [Anonymous], 2020, IPMCTL
   [Anonymous], 2019, INTEL OPTANE PERSIST
   [Anonymous], 2020, INTEL FPGA DDR T MEM
   Intel<(R)> stratix<(R), 2020, 10 DX DEV OV 10 DX DEV OV
   Intel<(R)> stratix<(R), 2020, 10 DX DEV KIT US GUI 10 DX DEV KIT US GUI
   Peng IB, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P304, DOI 10.1145/3357526.3357568
   Tuck J, 2006, INT SYMP MICROARCH, P409
   Wang ZX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P496, DOI 10.1109/MICRO50266.2020.00049
   Yang J, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P169
NR 10
TC 2
Z9 2
U1 0
U2 0
PY 2021
BP 97
EP 105
DI 10.1109/FCCM51124.2021.00019
UT WOS:000681289100011
DA 2023-11-16
ER

PT C
AU Sivkov, I
   Seewald, P
   Lazzaro, A
   Hutter, J
AF Sivkov, Ilia
   Seewald, Patrick
   Lazzaro, Alfio
   Hutter, Jurg
BE Foster, I
   Joubert, GR
   Kucera, L
   Nagel, WE
   Peters, F
TI DBCSR: A Blocked Sparse Tensor Algebra Library
SO PARALLEL COMPUTING: TECHNOLOGY TRENDS
SE Advances in Parallel Computing
DT Proceedings Paper
CT Conference on Parallel Computing - Technology Trends (ParCo)
CY SEP 10-13, 2019
CL Charles Univ, Prague, CZECH REPUBLIC
HO Charles Univ
DE sparse matrix-matrix multiplications; sparse tensor algebra;
   multi-threading; MPI parallelization; accelerators
AB Advanced algorithms for large-scale electronic structure calculations are mostly based on processing multi-dimensional sparse data. Examples are sparse matrix-matrix multiplications in linear-scaling Kohn-Sham calculations or the efficient determination of the exact exchange energy. When going beyond mean field approaches, e.g. for Moller-Plesset perturbation theory, RPA and Coupled-Cluster methods, or the GW methods, it becomes necessary to manipulate higher-order sparse tensors. Very similar problems are also encountered in other domains, like signal processing, data mining, computer vision, and machine learning. With the idea that the most of the tensor operations can be mapped to matrices, we have implemented sparse tensor algebra functionalities in the frames of the sparse matrix linear algebra library DBCSR (Distributed Block Compressed Sparse Row). DBCSR has been specifically designed to efficiently perform blocked-sparse matrix operations, so it becomes natural to extend its functionality to include tensor operations. We describe the newly developed tensor interface and algorithms. In particular, we introduce the tensor contraction based on a fast rectangular sparse matrix multiplication algorithm.
C1 [Sivkov, Ilia; Seewald, Patrick; Lazzaro, Alfio; Hutter, Jurg] Univ Zurich, Dept Chem, Zurich, Switzerland.
   [Lazzaro, Alfio] Cray Switzerland GmbH, Zurich, Switzerland.
RP Sivkov, I (corresponding author), Univ Zurich, Dept Chem, Zurich, Switzerland.
EM ilia.sivkov@chem.uzh.ch; patrick.seewald@chem.uzh.ch; alazzaro@cray.com;
   hutter@chem.uzh.ch
CR [Anonymous], 1969, THESIS
   Bethune Iain, 2017, ADV PARALLEL COMPUTI, P47
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   Cormen T. H., 2001, INTRO ALGORITHMS
   Demmel J, 2013, INT PARALL DISTRIB P, P261, DOI 10.1109/IPDPS.2013.80
   Epifanovsky E, 2013, J COMPUT CHEM, V34, P2293, DOI 10.1002/jcc.23377
   Heinecke A., 2016, P INT C HIGH PERF CO
   Hutter J, 2014, WIRES COMPUT MOL SCI, V4, P15, DOI 10.1002/wcms.1159
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Landry W., 2003, Scientific Programming, V11, P273
   Lazzaro Alfio, P PLATF ADV SCI COMP
   Lewis Cannada A, 2015, ARXIV151001156
   Rajbhandari S., 2013, PREPRINT
   Schutt Ole, 2015, ELECT STRUCTURE CALC
   Solomonik E., 2015, ETH ZURICH, V36
   Solomonik Edgar, 2015, ARXIV151200066
   VandeVondele J, 2012, J CHEM THEORY COMPUT, V8, P3565, DOI 10.1021/ct200897x
   Wilhelm J, 2016, J CHEM THEORY COMPUT, V12, P5851, DOI 10.1021/acs.jctc.6b00840
NR 18
TC 0
Z9 0
U1 0
U2 3
PY 2020
VL 36
BP 331
EP 340
DI 10.3233/APC200058
UT WOS:000624288400031
DA 2023-11-16
ER

PT J
AU Hanuka, A
   Emma, C
   Maxwell, T
   Fisher, AS
   Jacobson, B
   Hogan, MJ
   Huang, Z
AF Hanuka, A.
   Emma, C.
   Maxwell, T.
   Fisher, A. S.
   Jacobson, B.
   Hogan, M. J.
   Huang, Z.
TI Accurate and confident prediction of electron beam longitudinal
   properties using spectral virtual diagnostics
SO SCIENTIFIC REPORTS
DT Article
AB Longitudinal phase space (LPS) provides a critical information about electron beam dynamics for various scientific applications. For example, it can give insight into the high-brightness X-ray radiation from a free electron laser. Existing diagnostics are invasive, and often times cannot operate at the required resolution. In this work we present a machine learning-based Virtual Diagnostic (VD) tool to accurately predict the LPS for every shot using spectral information collected non-destructively from the radiation of relativistic electron beam. We demonstrate the tool's accuracy for three different case studies with experimental or simulated data. For each case, we introduce a method to increase the confidence in the VD tool. We anticipate that spectral VD would improve the setup and understanding of experimental configurations at DOE's user facilities as well as data sorting and analysis. The spectral VD can provide confident knowledge of the longitudinal bunch properties at the next generation of high-repetition rate linear accelerators while reducing the load on data storage, readout and streaming requirements.
C1 [Hanuka, A.; Emma, C.; Maxwell, T.; Fisher, A. S.; Jacobson, B.; Hogan, M. J.; Huang, Z.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
RP Hanuka, A (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM adiha@slac.stanford.edu
CR Abadi M, 2015, PRELIMINARY WHITE PA
   Akutowicz EJ., 1957, P AM MATH SOC, V8, P234, DOI 10.2307/2033718
   [Anonymous], TECHNICAL DESIGN REP, DOI [10.2172/1340171, DOI 10.2172/1340171]
   [Anonymous], 1991, ITERATIVE CONSTRAINE, DOI [10.1016/0165-1684(91)90146-A, DOI 10.1016/0165-1684(91)90146-A]
   Behrens C, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4762
   Borland M., 2000, ADV PHOTON SOURCE LS, DOI [10.2172/761286, DOI 10.2172/761286]
   Charles T.K., 2018, COMPACT LINEAR COLLI
   Chollet F., 2015, KERAS, P3, DOI [10.1063/1.4960070, DOI 10.1063/1.4960070]
   Christie F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66220-5
   Di Mitri S, 2014, PHYS REP, V539, P1, DOI 10.1016/j.physrep.2014.01.005
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Emma C., 2019, IBIC, DOI [10.18429/JACoW-IBIC2019-THBO01, DOI 10.18429/JACOW-IBIC2019-THBO01]
   Emma P, 2010, NAT PHOTONICS, V4, P641, DOI [10.1038/nphoton.2010.176, 10.1038/NPHOTON.2010.176]
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Hemsing E, 2014, REV MOD PHYS, V86, P897, DOI 10.1103/RevModPhys.86.897
   Huang Z, 2018, NUCL INSTRUM METH A, V907, P182, DOI 10.1016/j.nima.2018.02.030
   LAI R, 1994, PHYS REV E, V50, pR3342, DOI 10.1103/PhysRevE.50.R3342
   LAI R, 1994, PHYS REV E, V50, pR4294, DOI 10.1103/PhysRevE.50.R4294
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Lockmann NM, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.112801
   Loos H., 2007, 2007 IEEE Particle Accelerator Conference, P4189, DOI 10.1109/PAC.2007.4440076
   Lu XH, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.032802
   Lykken J., 2007, ARXIV07091893
   Marcus G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.080702
   Marx D, 2018, NUCL INSTRUM METH A, V909, P374, DOI 10.1016/j.nima.2018.02.037
   Maxwell TJ, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.184801
   Mo MZ, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4960070
   Neuman C. P., 2000, Physical Review Special Topics-Accelerators and Beams, V3, DOI 10.1103/PhysRevSTAB.3.030701
   Qiang J, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.054402
   Ratner D, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.034801
   Raubenheimer TO., 2015, PROC 6 INT PARTICLE, P2434, DOI [10.18429/JACoW-IPAC2015-WEYC1, DOI 10.18429/JACOW-IPAC2015-WEYC1]
   Sanchez-Gonzalez A, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15461
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Schmidt B, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.062801
   Sekko E., 1996, 1996 8 EUR SIGN PROC, P1
   Snively EC, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.054801
   Sütterlin D, 2007, NUCL INSTRUM METH B, V264, P361, DOI 10.1016/j.nimb.2007.08.092
   Tang JY, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.134801
   Tenenbaum P., 2005, P 2005 PART ACC C, P4197, DOI [10.1109/PAC.2005.1591763, DOI 10.1109/PAC.2005.1591763]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wesch S, 2012, NUCL INSTRUM METH A, V665, P40, DOI 10.1016/j.nima.2011.11.037
   Yakimenko V, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.101301
   YANG GZ, 1994, APPL OPTICS, V33, P209, DOI 10.1364/AO.33.000209
   Zhang Z, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.050701
NR 47
TC 11
Z9 13
U1 1
U2 5
PD FEB 3
PY 2021
VL 11
IS 1
AR 2945
DI 10.1038/s41598-021-82473-0
UT WOS:000616967300028
DA 2023-11-16
ER

PT C
AU Huynh, TV
AF Thang Viet Huynh
BE Vinh, L
   Hoang, TA
   Hai, DT
TI Deep Neural Network Accelerator based on FPGA
SO 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS)
DT Proceedings Paper
CT 4th National-Foundation-for-Science-and-Technology-Development
   (NAFOSTED) Conference on Information and Computer Science (NICS)
CY NOV 24-25, 2017
CL Hanoi, VIETNAM
DE machine learning; deep neural network; MNIST; FPGA; floating-point
AB In this work, we propose an efficient architecture for the hardware realization of deep neural networks on reconfigurable computing platforms like FPGA. The proposed neural network architecture employs only one single physical computing layer to perform the whole computational fabric of fully-connected feedforward deep neural networks with customizable number of layers, number of neurons per layer and number of inputs. The inputs, weights and outputs of the network are represented in 16-bit half-precision floating-point number format. The network weights are hard-coded using on-chip memory of FPGA devices, allowing for very fast computation. For performance evaluation, the handwritten digit recognition application with MNIST database is performed, which reported a recognition rate of 97.20% and a peak performance of 15.81 kFPS when using a deep neural network of size 784-40-40-10 on the Xilinx Virtex-5 XC5VLX-110T device. When implementing a deep neural network of size 784-126-126-10 for MNIST database on the Xilinx ZynQ-7000 XC7Z045 device, the recognition rate is 98.16% and the peak performance is 15.90 kFPS.
C1 [Thang Viet Huynh] Univ Danang, Danang Univ Sci & Technol, Da Nang, Vietnam.
RP Huynh, TV (corresponding author), Univ Danang, Danang Univ Sci & Technol, Da Nang, Vietnam.
EM thanghv@dut.udn.vn
CR Huynh T. V., 2017, INT J COMPUT DIGIT S, V6
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Nedjah N, 2012, EXPERT SYST APPL, V39, P9191, DOI 10.1016/j.eswa.2012.02.085
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Huynh TV, 2014, 2014 IEEE FIFTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P291, DOI 10.1109/CCE.2014.6916717
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
NR 6
TC 12
Z9 14
U1 0
U2 3
PY 2017
BP 254
EP 257
UT WOS:000427402600045
DA 2023-11-16
ER

PT C
AU Wang, H
   Chen, XH
   Chen, XJ
   Zang, PL
   Liu, YQ
   Wang, LR
AF Wang, Hui
   Chen, Xiaohe
   Chen, Xinjian
   Zang, Peilin
   Liu, Yunqing
   Wang, Lirong
GP IEEE
TI Fall Detection Based on KPCA and 3D KPCA
SO 2016 IEEE TRUSTCOM/BIGDATASE/ISPA
SE IEEE Trustcom
DT Proceedings Paper
CT 15th IEEE Int Conf on Trust, Security and Privacy in Comp and Commun /
   10th IEEE Int Conf on Big Data Science and Engineering / 14th IEEE Int
   Symposium on Parallel and Distributed Proc with Applicat (IEEE
   Trustcom/BigDataSE/ISPA)
CY AUG 23-26, 2016
CL Tianjin, PEOPLES R CHINA
DE fall detection; KPCA; 3D KPCA; statistical features; AdaBoost
AB Falls in elderly remain a very important public health care issue. Many different techniques for automatic fall detection have been developed. The wearable devices based on tri-axial accelerator prove to be an effective tool for fall detection in recent years. The popular methods are mainly based on threshold techniques and machine learning techniques, in this paper the threshold techniques and AdaBoost classifier are combined for detection. Additionally, we propose an approach based on nonlinear statistical features to distinguish falls from normal activities of daily living (ADL) in this paper. A novel method 3D Kernel Principal Component Analysis (3D KPCA) improved by Kernel Principal Component Analysis (KPCA) for feature extraction is proposed, which can extract the statistical features without the loss of 3D data structure information. The fall detection based on KPCA and 3D KPCA algorithm for feature extraction is firstly proposed in this paper and the experiment conducted on the public database (UCI) shows the efficiency of the approach, which can successfully distinguish falls from ADL with the accuracy 95.957%.
C1 [Wang, Hui; Chen, Xinjian; Zang, Peilin; Liu, Yunqing; Wang, Lirong] Soochow Univ, Sch Elect & Informat Engn, Suzhou, Peoples R China.
   [Chen, Xiaohe] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Beijing, Peoples R China.
RP Wang, LR (corresponding author), Soochow Univ, Sch Elect & Informat Engn, Suzhou, Peoples R China.
EM wanghuiliuwen@foxmail.com
CR Begga R., 2005, J BIOMECHANICS, V38
   Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537
   Conte V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034473
   Gibsona R. M., 2016, APPL SOFT COMPUTING, V39
   He J., 2016, INT J DISTRIBUTED SE, V10
   Huang S., 2011, ACIS INT S SOFTW NET
   Igual R, 2015, MED ENG PHYS, V37, P870, DOI 10.1016/j.medengphy.2015.06.009
   Kaluzal B., 2010, LECT NOTES COMPUTER
   Lustrek M., 2009, INFORMATICA, V33, P205
   Medrano C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094811
   Ozdemirl A. T., 2014, SENSORS, V14
   Palmerini L., 2015, SENSORS, V15
   Wu J., 2007, HUMAN MOVEMENT SCI, V26
NR 13
TC 0
Z9 0
U1 1
U2 3
PY 2016
BP 2187
EP 2191
DI 10.1109/TrustCom.2016.334
UT WOS:000401929800297
DA 2023-11-16
ER

PT C
AU Scherer, M
   Eggimann, M
   Di Mauro, A
   Prasad, AS
   Conti, F
   Rossi, D
   Gómez, JT
   Li, ZY
   Sarwar, SS
   Wang, Z
   De Salvo, B
   Benini, L
AF Scherer, Moritz
   Eggimann, Manuel
   Di Mauro, Alfio
   Prasad, Arpan Suravi
   Conti, Francesco
   Rossi, Davide
   Gomez, Jorge Tomas
   Li, Ziyun
   Sarwar, Syed Shakib
   Wang, Zhao
   De Salvo, Barbara
   Benini, Luca
GP IEEE
TI Siracusa: A Low-Power On-Sensor RISC-V SoC for Extended Reality Visual
   Processing in 16nm CMOS
SO IEEE 49TH EUROPEAN SOLID STATE CIRCUITS CONFERENCE, ESSCIRC 2023
SE Proceedings of the European Solid-State Circuits Conference
DT Proceedings Paper
CT IEEE 49th European Solid-State Circuits Conference (ESSCIRC)
CY SEP 11-14, 2023
CL Lisbon, PORTUGAL
AB Extended Reality (XR) has become increasingly popular in recent years, with applications in entertainment, education, healthcare, and more. However, mass adoption of XR technology still faces several challenges in meeting stringent latency and power consumption requirements. On-sensor computing, where a capable XR processor is tightly packaged with an image sensor, is a promising technology that can help address these challenges as it provides several benefits, including reduced data analysis latency, low power consumption, small form factor, and greater privacy. This work introduces Siracusa, an on-camera computing platform for next-generation XR devices. Siracusa features a flexible mixed-precision Machine Learning (ML) accelerator and a cluster of application-tuned RISC-V cores, sharing a highly configurable on-chip memory hierarchy designed to minimize expensive data copies. As a result, Siracusa achieves a peak energy efficiency of 9.9 TOp/J for deep neural network (DNN) inference, an increase of 1.2 x compared to similar designs, while supporting complex, heterogeneous application workloads, which combine ML with conventional signal processing and control.
C1 [Scherer, Moritz; Eggimann, Manuel; Di Mauro, Alfio; Prasad, Arpan Suravi; Benini, Luca] Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, Zurich, Switzerland.
   [Conti, Francesco; Rossi, Davide; Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn, Bologna, Italy.
   [Gomez, Jorge Tomas; Li, Ziyun; Sarwar, Syed Shakib; Wang, Zhao; De Salvo, Barbara] Meta Real Labs Res, Pittsburgh, PA USA.
RP Scherer, M (corresponding author), Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, Zurich, Switzerland.
CR Abrash M, 2021, INT EL DEVICES MEET, DOI 10.1109/IEDM19574.2021.9720526
   Conti F., 2023, 2023 IEEE INT SOL ST, P21
   Di Mauro A., 2022, 2022 IEEE HOT CHIPS, P1
   Eki R, 2021, ISSCC DIG TECH PAP I, V64, P154, DOI 10.1109/ISSCC42613.2021.9365965
   GholamReza A, 2022, APPL GEOMAT, V14, P181, DOI 10.1007/s12518-021-00366-3
   Gomez J., 2022, DISTRIBUTED ON SENSO
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   Miro-Panades I, 2023, IEEE J SOLID-ST CIRC, V58, P1782, DOI 10.1109/JSSC.2022.3198505
   Murakami Hirotaka, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P104, DOI 10.1109/ISSCC42614.2022.9731607
   Rossi D, 2022, IEEE J SOLID-ST CIRC, V57, P127, DOI 10.1109/JSSC.2021.3114881
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 217
EP 220
DI 10.1109/ESSCIRC59616.2023.10268718
UT WOS:001088613100055
DA 2023-11-16
ER

PT C
AU Xie, Y
   Deng, CH
   Liao, SY
   Yuan, B
AF Xie, Yi
   Deng, Chunhua
   Liao, Siyu
   Yuan, Bo
BE Matthews, MB
TI Area-efficient K-Nearest Neighbor Design using Stochastic Computing
SO 2018 CONFERENCE RECORD OF 52ND ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS,
   AND COMPUTERS
SE Conference Record of the Asilomar Conference on Signals Systems and
   Computers
DT Proceedings Paper
CT 52nd Asilomar Conference on Signals, Systems, and Computers
CY OCT 28-NOV 01, 2018
CL Pacific Grove, CA
DE Stochastic Computing; K-Nearest Neighbor; Area efficient
AB Among various machine learning techniques, K Nearest Neighbor (KNN) has been widely exploited for many artificial intelligence applications. However, due to the intensive use of multiplications during its computing procedure, KNN algorithm is typically computation -intensive and thereby posing severe challenge for its efficiency in hardware performance in terms of area and power consumption. To address this challenge, this paper proposes to design an area -efficient low -power stochastic KNN hardware accelerator. By leveraging stochastic computing (SC) technique, the basic computation components of KNN classifier are replaced by simple stochastic logic circuits such as XNOR and MUX gate. Moreover, we propose a low-cost architecture for binary -to -stochastic (B -to -S) interface and develop an Approximate Parallel Accumulator (APA) for stochastic -to -binary (S -to -B) module, which can further improve the hardware performance for the stochastic design. Experimental results demonstrate that the proposed stochastic KNN design achieves higher area efficiency and lower power consumption as compared to the non -stochastic design. Also, it remains high task accuracy with negligible performance loss.
C1 [Xie, Yi; Deng, Chunhua; Liao, Siyu; Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
RP Xie, Y (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
CR [Anonymous], 1951, APPL MATH SERIES
   [Anonymous], IEEE T NANOTECHNOLOG
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Gaines B.R., 1969, ADV INFORM SYSTEMS S, V2, P37, DOI 10.1109/12.954505
   Imandoust Sadegh Bafandeh, 2013, THEORETICAL BACKGROU, V3, P605, DOI DOI 10.1016/J.JTBI.2009.08.004
   Jabbar MA, 2013, PROC TECH, V10, P85, DOI 10.1016/j.protcy.2013.12.340
   LeCun Y., 1998, MNIST DATABASE HANDW
   Ting PS, 2014, 2014 17TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P356, DOI 10.1109/DSD.2014.75
   Xie Y, 2017, IEEE T CIRCUITS-II, V64, P1382, DOI 10.1109/TCSII.2017.2746749
NR 9
TC 7
Z9 7
U1 0
U2 1
PY 2018
BP 782
EP 786
UT WOS:000467845100136
DA 2023-11-16
ER

PT J
AU Lay, LM
   Chuang, KC
   Wu, YY
   Giles, W
   Adamson, J
AF Lay, Lam M.
   Chuang, Kai-Cheng
   Wu, Yuyao
   Giles, William
   Adamson, Justus
TI Virtual patient-specific QA with DVH-based metrics
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE AI; artificial intelligence; IMRT QA
ID TRAJECTORY LOG FILES; IMRT QA; PASSING RATES; VMAT; VERIFICATION;
   PREDICTION; ALGORITHM; ERRORS
AB We demonstrate a virtual pretreatment patient-specific QA (PSQA) procedure that is capable of quantifying dosimetric effect on patient anatomy for both intensity modulated radiotherapy (IMRT) and volumetric modulated arc therapy (VMAT). A machine learning prediction model was developed to use linear accelerator parameters derived from the DICOM-RT plan to predict delivery discrepancies at treatment delivery (defined as the difference between trajectory log file and DICOM-RT) and was coupled with an independent Monte Carlo dose calculation algorithm for dosimetric analysis. Machine learning models for IMRT and VMAT were trained and validated using 120 IMRT and 206 VMAT fields of prior patients, with 80% assigned for iterative training and testing, and 20% for post-training validation. Various prediction models were trained and validated, with the final models selected for clinical implementation being a boosted tree and bagged tree for IMRT and VMAT, respectively. After validation, these models were then applied clinically to predict the machine parameters at treatment delivery for 7 IMRT plans from various sites (61 fields) and 10 VMAT multi-target intracranial radiosurgery plans (35 arcs) and compared to the dosimetric effect calculated directly from trajectory log files. Dose indices tracked for targets and organs at risk included dose received by 99%, 95%, and 1% of the volume, mean dose, percent of volume receiving 25%-100% of the prescription dose. The average coefficient of determination (r(2)) when comparing intra-field predicted and actual delivery error was 0.987 +/- 0.012 for IMRT and 0.895 +/- 0.095 for VMAT, whereas r(2) when comparing inter-field predicted versus actual delivery error was 0.982 for IMRT and 0.989 for VMAT. Regarding dosimetric analysis, r(2) when comparing predicted versus actual dosimetric changes for all dose indices was 0.966 for IMRT and 0.907 for VMAT. Prediction models can be used to anticipate the dosimetric effect calculated from trajectory files and have potential as a "delivery-free" pretreatment analysis to enhance PSQA.
C1 [Lay, Lam M.] Duke Univ, Med Phys Grad Program, Durham, NC 27710 USA.
   [Chuang, Kai-Cheng; Wu, Yuyao] Duke Kunshan Univ, Med Phys Grad Program, Kunshan, Peoples R China.
   [Giles, William; Adamson, Justus] Duke Univ, Dept Radiat Oncol, Med Ctr, 200 Trent Dr, Durham, NC 27710 USA.
RP Adamson, J (corresponding author), Duke Univ, Dept Radiat Oncol, Med Ctr, 200 Trent Dr, Durham, NC 27710 USA.
EM justus.adamson@duke.edu
CR Acharya S, 2016, INT J RADIAT ONCOL, V94, P394, DOI 10.1016/j.ijrobp.2015.10.015
   Agnew A, 2014, PHYS MED BIOL, V59, pN49, DOI 10.1088/0031-9155/59/9/N49
   Agnew CE, 2014, J APPL CLIN MED PHYS, V15, P204, DOI 10.1120/jacmp.v15i6.4994
   Bailey DW, 2009, MED PHYS, V36, P4089, DOI 10.1118/1.3187785
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boggula R, 2011, PHYS MED BIOL, V56, P7163, DOI 10.1088/0031-9155/56/22/011
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Chuang KC, 2021, MED PHYS, V48, P978, DOI 10.1002/mp.14670
   Chuang KC, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/abc86c
   Francis Kenney J., 1939, MATH STAT
   Gibbons JP, 2014, MED PHYS, V41, DOI 10.1118/1.4864244
   Granville DA, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab142e
   Henke LE, 2019, ADV RADIAT ONCOL, V4, P201, DOI 10.1016/j.adro.2018.10.003
   Hoffmann L, 2018, MED PHYS, V45, P3909, DOI 10.1002/mp.13053
   Huq MS, 2008, INT J RADIAT ONCOL, V71, pS170, DOI 10.1016/j.ijrobp.2007.06.081
   Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kry SF, 2019, MED PHYS, V46, P3700, DOI 10.1002/mp.13638
   Kry SF, 2014, INT J RADIAT ONCOL, V90, P1195, DOI 10.1016/j.ijrobp.2014.08.334
   KUTCHER GJ, 1994, MED PHYS, V21, P581, DOI 10.1118/1.597316
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Lamb J, 2017, CUREUS J MED SCIENCE, V9, DOI 10.7759/cureus.1618
   Lechner W, 2017, RADIOTHER ONCOL, V123, pS429, DOI 10.1016/S0167-8140(17)31242-2
   Létourneau D, 2004, RADIOTHER ONCOL, V70, P199, DOI 10.1016/j.radonc.2003.10.014
   Li JQ, 2019, INT J RADIAT ONCOL, V105, P893, DOI 10.1016/j.ijrobp.2019.07.049
   McDonald DG, 2017, J APPL CLIN MED PHYS, V18, P170, DOI 10.1002/acm2.12025
   Men CH, 2010, PHYS MED BIOL, V55, P4309, DOI 10.1088/0031-9155/55/15/008
   Miften M, 2018, MED PHYS, V45, pE53, DOI 10.1002/mp.12810
   Neal B, 2016, MED PHYS, V43, P2933, DOI 10.1118/1.4949002
   Nelms BE, 2007, J APPL CLIN MED PHYS, V8, P76, DOI 10.1120/jacmp.v8i3.2448
   Nelms BE, 2011, MED PHYS, V38, P1037, DOI 10.1118/1.3544657
   Olasolo-Alonso J, 2017, PHYS MEDICA, V33, P87, DOI 10.1016/j.ejmp.2016.12.013
   Ono T, 2019, MED PHYS, V46, P3823, DOI 10.1002/mp.13669
   Osman AFI, 2020, MED PHYS, V47, P1421, DOI 10.1002/mp.14014
   Park JM, 2019, RADIAT ONCOL, V14, DOI 10.1186/s13014-019-1441-7
   Rangaraj D, 2013, PRACT RADIAT ONCOL, V3, P80, DOI 10.1016/j.prro.2012.05.002
   Stasi M, 2012, MED PHYS, V39, P7626, DOI 10.1118/1.4767763
   Stern RL, 2011, MED PHYS, V38, P504, DOI 10.1118/1.3521473
   Sun BZ, 2013, PRACT RADIAT ONCOL, V3, pE199, DOI 10.1016/j.prro.2012.11.013
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Valdes G, 2021, MED PHYS, V48, P2701, DOI 10.1002/mp.14870
   Valdes G, 2017, J APPL CLIN MED PHYS, V18, P279, DOI 10.1002/acm2.12161
   Vazquez-Quino Luis Alberto, 2017, Proc (Bayl Univ Med Cent), V30, P276
   Wall Phillip D. H., 2020, Informatics in Medicine Unlocked, V18, P190, DOI 10.1016/j.imu.2020.100292
   Zaila A., 2016, PHYS MED, V32, P292, DOI [10.1016/j.ejmp.2016.07.122, DOI 10.1016/J.EJMP.2016.07.122]
   Zayegh A., 2018, DIGITAL SYSTEMS INTE, DOI 10.5772/intechopen.80416
   Zhen HM, 2011, MED PHYS, V38, P5477, DOI 10.1118/1.3633904
   Zhou ZH., 2009, ENCY BIOMETRICS, DOI [DOI 10.1007/978-0-387-73003-5_293, DOI 10.1007/978-0-387-73003-5293]
   Zhu TMC, 2021, MED PHYS, V48, pE808, DOI 10.1002/mp.15069
NR 49
TC 4
Z9 4
U1 1
U2 4
PD NOV
PY 2022
VL 23
IS 11
AR e13639
DI 10.1002/acm2.13639
EA MAY 2022
UT WOS:000795733800001
DA 2023-11-16
ER

PT C
AU Vargas, F
   Borba, D
   Benfica, JD
   Syed, RT
AF Vargas, Fabian
   Borba, Douglas
   Benfica, Juliano D'ornelas
   Syed, Rizwan Tariq
BE Savino, A
   Maniatakos, M
   DiCarlo, S
   Gizopoulos, D
TI Artificial Neural Network Accelerator for Classification of In-Field
   Conducted Noise in Integrated Circuits' DC Power Lines
SO 2023 IEEE 29TH INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN, IOLTS
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 29th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 03-05, 2023
CL Platanias, GREECE
DE Conducted noise; Electromagnetic interference (EMI); Transient fault;
   Machine learning; Signal integrity; Artificial neural networks; Robust
   embedded system
AB With the growing use of embedded systems in our daily lives and the increasing electromagnetic noise level in the environment in which these systems are exposed, the need for reliable operation is paramount. In this scenario, this work presents a study on the use of Artificial Neural Networks (ANNs) to perform in-field identification and classification of different types of noise conducted in the integrated circuit (IC) DC power lines according to a specific set of IEC standards. After identification, proactive actions can be taken to guarantee the expected IC robustness. Such actions can be, for instance, slow down IC clock frequency, increasing power supply voltage and/or activating error detection & correction (EDAC) functions during the period the system is operating under such noise exposition. Experimental results demonstrate that the ANN was able to identify and classify different types of conducted noise in power supply lines with a success rate ranging from 70 to 100% within a latency in the order of 995 ns.
C1 [Vargas, Fabian; Syed, Rizwan Tariq] IHP Leibniz Inst High Performance Microelect, Frankfurt, Germany.
   [Borba, Douglas] LABELO Specialized Elect Elect Labs, Porto Alegre, Brazil.
RP Vargas, F (corresponding author), IHP Leibniz Inst High Performance Microelect, Frankfurt, Germany.
EM vargas@ihp-microelectronics.com; douglasbeng@gmail.com;
   jbenfica@gmail.com; syed@ihp-microelectronics.com
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Amrutha J., 2018, 2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), P1547, DOI 10.1109/RTEICT42901.2018.9012614
   [Anonymous], 2012, 6100044 IEC EMC
   [Anonymous], 2000, 61000429 IEC EMC, VFirst
   [Anonymous], 2000, 6100042 IEC EMC, VFirst
   [Anonymous], 2005, 6100045 IEC EMC, VFirst
   Benfica J, 2020, MICROELECTRON RELIAB, V114, DOI 10.1016/j.microrel.2020.113884
   Benfica J, 2016, IEEE T NUCL SCI, V63, P1294, DOI 10.1109/TNS.2016.2523458
   Crouch A., 1999, DESIGN TEST DIGITAL
   github, GITHUB COM PUBL ACC
   Goerl R, 2019, MICROELECTRON RELIAB, V100, DOI 10.1016/j.microrel.2019.06.033
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Jin H, 2017, ELEC DES ADV PACKAG
   Kingma DP., 2017, ARXIV
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Medico R, 2019, IEEE T ELECTROMAGN C, V61, P352, DOI 10.1109/TEMC.2018.2821712
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/IOLTS59296.2023.10224874
UT WOS:001062141900012
DA 2023-11-16
ER

PT C
AU Rahimi, R
   Sadredini, E
   Stan, M
   Skadron, K
AF Rahimi, Reza
   Sadredini, Elaheh
   Stan, Mircea
   Skadron, Kevin
GP IEEE Comp Soc
TI Grapefruit: An Open-Source, Full-Stack, and Customizable Automata
   Processing on FPGAs
SO 28TH IEEE INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM COMPUTING
   MACHINES (FCCM)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 28th IEEE International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 03-06, 2020
CL Fayetteville, AR
ID MATCHING ENGINE; ARCHITECTURE; EFFICIENT; MEMORY
AB Regular expressions have been widely used in various application domains such as network security, machine learning, and natural language processing. Increasing demand for accelerated regular expressions, or equivalently finite automata, has motivated many efforts in designing FPGA accelerators. However, there is no framework that is publicly available, comprehensive, parameterizable, general, full-stack, and easy-to-use, all in one, for design space exploration for a wide range of growing pattern matching applications on FPGAs. In this paper, we present Grapefruit, the first open-source, full-stack, efficient, scalable, and extendable automata processing framework on FPGAs. Grapefruit is equipped with an integrated compiler with many parameters for automata simulation, verification, minimization, transformation, and optimizations. Our modular and standard design allows researchers to add capabilities and explore various features for a target application. Our experimental results show that the hardware generated by Grapefruit performs 9%-80% better than prior work that is not fully end-to-end and has 3.4x higher throughput in a multi-stride solution than a single-stride solution.
C1 [Rahimi, Reza; Stan, Mircea] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22904 USA.
   [Sadredini, Elaheh; Skadron, Kevin] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
RP Rahimi, R (corresponding author), Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22904 USA.
EM rahimi@virginia.edu; elaheh@virginia.edu; mircea@virginia.edu;
   skadron@virginia.edu
CR [Anonymous], 2014, P 9 DOCT WORKSH MATH
   [Anonymous], 2007, P 3 ACM IEEE S ARCH, DOI DOI 10.1145/1323548.1323573
   [Anonymous], 1961, RUSSIAN MATH SURVEYS
   [Anonymous], 2019, P 24 INT C ARCH SUPP
   [Anonymous], 2018, IISWC
   [Anonymous], 2016, TECH REP
   Atasu K, 2013, INT PARALL DISTRIB P, P1254, DOI 10.1109/IPDPS.2013.54
   Avalle M, 2016, IEEE ACM T NETWORK, V24, P1704, DOI 10.1109/TNET.2015.2429918
   Becchi M., 2008, P 4 ACM IEEE S ARCH, P50, DOI DOI 10.1145/1477942.1477950
   Becchi M, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2445572.2445576
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Bo C., 2018, 24 INT S HIGH PERF C
   Bo C, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3314576
   Bo CK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P311, DOI 10.1109/BigData.2016.7840617
   Brodie BC, 2006, CONF PROC INT SYMP C, P191, DOI 10.1145/1150019.1136500
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang Yu, 2006, ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS 2006), P93, DOI 10.1109/ANCS.2006.4579527
   Gogte V, 2016, INT SYMP MICROARCH
   Karakchi R, 2017, PROC INT CONF RECON
   Lenjani M, 2014, IET COMPUT DIGIT TEC, V8, P30, DOI 10.1049/iet-cdt.2011.0066
   Liu C., 2013, IEEE T COMPUTERS, V62
   Liu HY, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P251, DOI 10.1145/3373376.3378471
   Liu HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P908, DOI [10.1109/MICRO.2018.00078, 10.1109/MICR0.2018.00078]
   Liu TW, 2011, IEEE INFOCOM SER, P2129, DOI 10.1109/INFCOM.2011.5935024
   Paxson V, 1999, COMPUT NETW, V31, P2435, DOI 10.1016/S1389-1286(99)00112-7
   Putic M, 2017, IEEE MICRO, V37, P52, DOI 10.1109/MM.2017.6
   Roy I, 2016, IEEE ACM T COMPUT BI, V13, P99, DOI 10.1109/TCBB.2015.2430313
   Sadredini E., 2020, 25 INT C ARCH UNPUB
   Sadredini E., 2017, INT C SUP ICS
   Sadredini E, 2020, INT S HIGH PERF COMP, P86, DOI 10.1109/HPCA47549.2020.00017
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Tracy T, 2016, LECT NOTES COMPUT SC, V9697, P200, DOI 10.1007/978-3-319-41321-1_11
   Hieu TT, 2013, INT CONF UBIQ FUTUR, P252, DOI 10.1109/ICUFN.2013.6614821
   Vespa L, 2011, COMPUT J, V54, P285, DOI 10.1093/comjnl/bxq077
   Wadden J., 2016, IISWC
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wang K., 2015, IPDPS
   Wang K., 2017, INT J PARALLEL PROGR
   Wang K, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P135, DOI 10.1145/2903150.2903172
   Wang X., 2014, TECHNIQUES EFFICIENT
   Wang X, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P631
   Xie T., 2018, 50 C GOV MICR APPL C
   Xie T, 2017, I C FIELD PROG LOGIC
   Yamagaki N, 2008, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2008.4629920
   Yang YHE, 2012, IEEE T COMPUT, V61, P1013, DOI 10.1109/TC.2011.129
   Zhang Y, 2010, ACM SIGCOMM COMP COM, V40, P20, DOI 10.1145/1880153.1880157
   Zhou K, 2015, IEEE INT C SEMANT CO, P236, DOI 10.1109/ICOSC.2015.7050812
NR 48
TC 13
Z9 13
U1 0
U2 4
PY 2020
BP 138
EP 147
DI 10.1109/FCCM48280.2020.00027
UT WOS:000609774900018
DA 2023-11-16
ER

PT J
AU Sen, S
   Jain, S
   Venkataramani, S
   Raghunathan, A
AF Sen, Sanchari
   Jain, Shubham
   Venkataramani, Swagath
   Raghunathan, Anand
TI SPARCE: Sparsity Aware General-Purpose Core Extensions to Accelerate
   Deep Neural Networks
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Deep learning; deep neural networks; sparsity; general purpose
   processors
AB Deep Neural Networks (DNNs) have emerged as the method of choice for solving a wide range of machine learning tasks. The enormous computational demand posed by DNNs is a key challenge for computing system designers and has most commonly been addressed through the design of DNN accelerators. However, these specialized accelerators utilize large quantities of multiply-accumulate units and on-chip memory and are prohibitive in area and cost constrained systems such as wearable devices and IoT sensors. In this work, we take a complementary approach and improve the performance of DNNs on general-purpose processor (GPP) cores. We do so by exploiting a key attribute of DNNs, viz. sparsity or the prevalence of zero values. We propose Sparsity-aware Core Extensions (SPARCE)-a set of low-overhead micro-architectural and ISA extensions that dynamically detect whether an operand (e. g., the result of a load instruction) is zero and subsequently skip a set of future instructions that use it. To maximize performance benefits, SPARCE ensures that the instructions to be skipped are prevented fromeven being fetched, as squashing instructions comeswith a penalty (e. g., a pipeline stall). SPARCE consists of 2 keymicro-architectural enhancements. First, a Sparsity Register File (SpRF) is utilized to track registers that are zero. Next, a Sparsity-Aware Skip Address (SASA) Table is used to indicate instruction sequences that can be skipped, and to specify conditions on SpRF registers that trigger instruction skipping. When an instruction is fetched, SPARCE dynamically pre-identifies whether the following instruction(s) can be skipped, and if so appropriatelymodifies the program counter, thereby skipping the redundant instructions and improving performance. We model SPARCE using the gem5 architectural simulator, and evaluate our approach on 6 state-of-the-art image-recognition DNNs in the context of both training and inference using the Caffe deep learning framework. On a scalar microprocessor, SPARCE achieves 1.11x-1.96x speedups across both convolution and fully-connected layers that exhibit 10-90 percent sparsity. These speedups translate to 19-31 percent reduction in execution time at the overall application-level. We also evaluate SPARCE on a 4-way SIMD ARMv8 processor using the OpenBLAS library, and demonstrate that SPARCE achieves 8-15 percent reduction in the application-level execution time.
C1 [Sen, Sanchari; Jain, Shubham; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
   [Venkataramani, Swagath] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Sen, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
EM sen9@purdue.edu; jain130@purdue.edu; swagath.venkataramani@ibm.com;
   raghunathan@purdue.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2016, CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2014, CORR
   [Anonymous], 2015, NIPS
   [Anonymous], 2015, DEEP RESIDUAL LEARNI
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2016, CORR
   [Anonymous], 2014, CORR
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Iandola F.N., 2015, CORR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A, 2009, HDB SYST AUTOIMMUNE, V1, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park H, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2968476
   Perais A, 2016, ACM T COMPUT SYST, V34, DOI 10.1145/2870632
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Simonyan K., 2014, VERY DEEP CONVOLUTIO
   Sodani A, 1997, ACM COMP AR, P194, DOI 10.1145/384286.264200
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wen Wei, 2016, ADV NEURAL INFORM PR, P2074
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
NR 34
TC 19
Z9 19
U1 0
U2 6
PD JUN
PY 2019
VL 68
IS 6
BP 912
EP 925
DI 10.1109/TC.2018.2879434
UT WOS:000467523100008
DA 2023-11-16
ER

PT J
AU Abdelsalam, AM
   Elsheikh, A
   Chidambaram, S
   David, JP
   Langlois, JMP
AF Abdelsalam, Ahmed M.
   Elsheikh, Ahmed
   Chidambaram, Sivakumar
   David, Jean-Pierre
   Langlois, J. M. Pierre
TI POLYBiNN: Binary Inference Engine for Neural Networks using Decision
   Trees
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Deep learning; FPGAs; Decision trees; Hardware accelerators; Binary
   classifiers
AB Convolutional Neural Networks (CNNs) and Deep Neural Networks (DNNs) have gained significant popularity in several classification and regression applications. The massive computation and memory requirements of DNN and CNN architectures pose particular challenges for their FPGA implementation. Moreover, programming FPGAs requires hardware-specific knowledge that many machine-learning researchers do not possess. To make the power and versatility of FPGAs available to a wider deep learning user community and to improve DNN design efficiency, we introduce POLYBiNN, an efficient FPGA-based inference engine for DNNs and CNNs. POLYBiNN is composed of a stack of decision trees, which are binary classifiers in nature, and it utilizes AND-OR gates instead of multipliers and accumulators. POLYBiNN is a memory-free inference engine that drastically cuts hardware costs. We also propose a tool for the automatic generation of a low-level hardware description of the trained POLYBiNN for a given application. We evaluate POLYBiNN and the tool for several datasets that are normally solved using fully connected layers. On the MNIST dataset, when implemented in a ZYNQ-7000 ZC706 FPGA, the system achieves a throughput of up to 100 million image classifications per second with 90 ns latency and 97.26% accuracy. Moreover, POLYBiNN consumes 8x less power than the best previously published implementations, and it does not require any memory access. We also show how POLYBiNN can be used instead of the fully connected layers of a CNN and apply this approach to the CIFAR-10 dataset.
C1 [Abdelsalam, Ahmed M.; Langlois, J. M. Pierre] Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
   [Elsheikh, Ahmed] Polytech Montreal, Dept Math & Ind Engn, Montreal, PQ, Canada.
   [Chidambaram, Sivakumar; David, Jean-Pierre] Polytech Montreal, Dept Elect Engn, Montreal, PQ, Canada.
RP Abdelsalam, AM (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM ahmed.abdelsalam@polymtl.ca; ahmed.elsheikh@polymtl.ca;
   sivakumar.Chidambaram@polymtl.ca; jean-pierre.david@polymtl.ca;
   pierre.langlois@polymtl.ca
CR Abdelsalam A.M., 2018, IEEE DESIGN ARCHITEC
   Abdelsalam AM, 2018, PROC INT CONF RECON
   Akers S. B., 1978, IEEE T COMPUTERS
   Alemdar H., 2017, IEEE INT JOINT C NEU
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], WORLD SCI
   [Anonymous], 1998, P IEEE
   [Anonymous], 2016, ICLR
   Ba Jimmy, 2014, ADV NEURAL INFORM PR
   Breiman LF., 1983, CLASSIFICATION REGRE
   Cheng Yu, 2017, ARXIV171009282
   Courbariaux M., 2016, ARXIV160202830 COMP
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Deng L., 2017, ARXIV170509283
   Duda R.O., 2012, PATTERN CLASSIFICATI
   Furnkranz J, 2012, FDN RULE LEARNING
   Hastie T, 2008, ELEMENTS STAT LEARNI
   Hunter D., 2012, IEEE T IND INFORM
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V3, P6
   LeCun Yann, 2015, NATURE
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lorena A.C., 2008, REV COMBINATION BINA
   Misra J., 2010, NEUROCOMPUTING
   Nakahara H., 2017, IEEE INT C FIELD PRO
   Nurvitadhi E., 2017, ACM SIGDA INT S FIEL
   Rastegari M., 2016, SPRING EUR C COMP VI
   Robert C., 2014, MACHINE LEARNING PRO
   Struharik J.R., 2011, IEEE INT S INT SYST
   Sze V., 2017, P IEEE
   Tang P.T., 1991, IEEE S COMP AR
   Umuroglu Y., 2017, ACM SIGDA INT S FIEL
   Zhao R., 2017, ACM SIGDA INT S FIEL
NR 33
TC 2
Z9 2
U1 0
U2 6
PD JAN
PY 2020
VL 92
IS 1
BP 95
EP 107
DI 10.1007/s11265-019-01453-w
UT WOS:000516533900007
DA 2023-11-16
ER

PT J
AU Xu, Y
   Afshar, S
   Wang, RC
   Cohen, G
   Thakur, CS
   Hamilton, TJ
   van Schaik, A
AF Xu, Ying
   Afshar, Saeed
   Wang, Runchun
   Cohen, Gregory
   Singh Thakur, Chetan
   Hamilton, Tara Julia
   van Schaik, Andre
TI A Biologically Inspired Sound Localisation System Using a Silicon
   Cochlea Pair
SO APPLIED SCIENCES-BASEL
DT Article
DE electronic cochlea; neuromorphic engineering; sound localisation; onset
   detection; process innovation; ITD; ELM; CNN
ID CNN ACCELERATOR; SUPERIOR OLIVE; IMPLEMENTATION; DELAYS; MODEL
AB We present a biologically inspired sound localisation system for reverberant environments using the Cascade of Asymmetric Resonators with Fast-Acting Compression (CAR-FAC) cochlear model. The system exploits a CAR-FAC pair to pre-process binaural signals that travel through the inherent delay line of the cascade structures, as each filter acts as a delay unit. Following the filtering, each cochlear channel is cross-correlated with all the channels of the other cochlea using a quantised instantaneous correlation function to form a 2-D instantaneous correlation matrix (correlogram). The correlogram contains both interaural time difference and spectral information. The generated correlograms are analysed using a regression neural network for localisation. We investigate the effect of the CAR-FAC nonlinearity on the system performance by comparing it with a CAR only version. To verify that the CAR/CAR-FAC and the quantised instantaneous correlation provide a suitable basis with which to perform sound localisation tasks, a linear regression, an extreme learning machine, and a convolutional neural network are trained to learn the azimuthal angle of the sound source from the correlogram. The system is evaluated using speech data recorded in a reverberant environment. We compare the performance of the linear CAR and nonlinear CAR-FAC models with current sound localisation systems as well as with human performance.
C1 [Xu, Ying; Afshar, Saeed; Wang, Runchun; Cohen, Gregory; van Schaik, Andre] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Int Ctr Neuromorph Syst, Kingswood, NSW 2751, Australia.
   [Singh Thakur, Chetan] Indian Inst Sci, Dept Elect Syst Engn, Bangalore 560012, Karnataka, India.
   [Hamilton, Tara Julia] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW 2000, Australia.
RP Xu, Y; van Schaik, A (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Int Ctr Neuromorph Syst, Kingswood, NSW 2751, Australia.
EM ying.xu@westernsydney.edu.au; S.Afshar@westernsydney.edu.au;
   mark.wang@westernsydney.edu.au; G.Cohen@westernsydney.edu.au;
   csthakur@iisc.ac.in; tara.hamilton@uts.edu.au;
   a.vanschaik@westernsydney.edu.au
CR Al-Rfou Rami, 2016, ARXIV160502688
   [Anonymous], 2016, THEANO PYTHON FRAMEW
   Ashida G, 2011, CURR OPIN NEUROBIOL, V21, P745, DOI 10.1016/j.conb.2011.05.008
   BATRA R, 1989, J NEUROPHYSIOL, V61, P257, DOI 10.1152/jn.1989.61.2.257
   BHADKAMKAR N, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P1902, DOI 10.1109/ICNN.1993.298847
   Burnham D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P848
   Carlile S, 1997, HEARING RES, V114, P179, DOI 10.1016/S0378-5955(97)00161-5
   CASSEDAY JH, 1973, J ACOUST SOC AM, V54, P365, DOI 10.1121/1.1913586
   Escudero EC, 2018, NEUROCOMPUTING, V283, P129, DOI 10.1016/j.neucom.2017.12.041
   Chan VYS, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnins.2010.00196
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Cox F.M., P 2008 HCSNET WORKSH, P96
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Finger H, 2011, IEEE INT SYMP CIRC S, P2461
   Grech I, 2004, ANALOG INTEGR CIRC S, V41, P167, DOI 10.1023/B:ALOG.0000041634.92147.0d
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Grothe B, 2000, J COMP PHYSIOL A, V186, P413, DOI 10.1007/s003590050441
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   He Kaiming, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Heckmann M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P368, DOI 10.1109/IROS.2006.281758
   HENNING GB, 1974, J ACOUST SOC AM, V55, P84, DOI 10.1121/1.1928135
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Iwasa K, 2007, IEEE IJCNN, P902, DOI 10.1109/IJCNN.2007.4371078
   JEFFRESS LA, 1948, J COMP PHYSIOL PSYCH, V41, P35, DOI 10.1037/h0061495
   Jiang SL, 2020, J ENG-JOE, V2020, P511, DOI 10.1049/joe.2019.1207
   Joris PX, 2019, ANNU REV NEUROSCI, V42, P433, DOI 10.1146/annurev-neuro-080317-061925
   Joris PX, 1996, J NEUROPHYSIOL, V76, P2137, DOI 10.1152/jn.1996.76.4.2137
   Julián P, 2006, IEEE T VLSI SYST, V14, P207, DOI 10.1109/TVLSI.2005.863740
   Kala S, 2019, IEEE T VLSI SYST, V27, P2816, DOI 10.1109/TVLSI.2019.2941250
   Katsiamis AG, 2007, EURASIP J AUDIO SPEE, DOI 10.1155/2007/63685
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kugler M, 2008, LECT NOTES COMPUT SC, V4985, P577
   Kuwada S., 2012, LIMITS LIMITS EVERYW
   Lazzaro J, 1989, NEURAL COMPUT, V1, P47, DOI 10.1162/neco.1989.1.1.47
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Rayleigh,, 1907, PHILOS MAG, V13, P214, DOI 10.1080/14786440709463595
   Lyon RF, 2017, HUMAN AND MACHINE HEARING: EXTRACTING MEANING FROM SOUND, DOI 10.1017/9781139051699
   Lyon R. F., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P1148
   Lyon RF, 2011, J ACOUST SOC AM, V130, P3893, DOI 10.1121/1.3658470
   Ma N, 2017, IEEE-ACM T AUDIO SPE, V25, P2444, DOI 10.1109/TASLP.2017.2750760
   McDonnell MD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134254
   MEAD CA, 1991, IEEE T NEURAL NETWOR, V2, P230, DOI 10.1109/72.80333
   MIDDLEBROOKS JC, 1991, ANNU REV PSYCHOL, V42, P135, DOI 10.1146/annurev.ps.42.020191.001031
   Park TJ, 2004, J NEUROPHYSIOL, V92, P289, DOI 10.1152/jn.00961.2003
   Ponca M, 2001, SPRING COMP SCI, P212
   Ruder Sebastian, 2016, OVERVIEW GRADIENT DE
   Schauer C, 2000, INT CONF ACOUST SPEE, P865
   Seidner D, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MICROWAVES, COMMUNICATIONS, ANTENNAS AND ELECTRONIC SYSTEMS, P146
   SHAMMA SA, 1989, J ACOUST SOC AM, V86, P989, DOI 10.1121/1.398734
   Singh RK, 2019, IEEE T CIRCUITS-I, V66, P1805, DOI 10.1109/TCSI.2018.2868247
   Singh RK, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351394
   van Schaik A, 2004, ANALOG INTEGR CIRC S, V39, P267, DOI 10.1023/B:ALOG.0000029662.37528.c7
   van Schaik A, 2015, NEUROCOMPUTING, V149, P233, DOI 10.1016/j.neucom.2014.01.071
   WALLACH H, 1949, AM J PSYCHOL, V62, P315, DOI 10.2307/1418275
   Wang J, 2020, EURASIP J AUDIO SPEE, V2020, DOI 10.1186/s13636-020-0171-y
   Wang R, 2016, BIOMED CIRC SYST C, P560, DOI 10.1109/BioCAS.2016.7833856
   Wühle T, 2019, J AUDIO ENG SOC, V67, P92, DOI 10.17743/jaes.2018.0074
   Xiao Y., 2013, P IEEE 9 INT C SOGN
   Xu Y., 2016, IET 13 INT C DEV POW, P1
   Xu Y, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/iscas.2019.8702345
   Xu Y, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351367
   Xu Y, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00198
   Yin TCT, 2002, SPR HDB AUD, V15, P99
   Youssef K, 2013, IEEE INT C INT ROBOT, P2927, DOI 10.1109/IROS.2013.6696771
   Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191
   ZWISLOCKI J, 1956, J ACOUST SOC AM, V28, P860, DOI 10.1121/1.1908495
NR 66
TC 4
Z9 4
U1 3
U2 6
PD FEB
PY 2021
VL 11
IS 4
AR 1519
DI 10.3390/app11041519
UT WOS:000632083300001
DA 2023-11-16
ER

PT J
AU Wu, N
   Deng, L
   Li, GQ
   Xie, Y
AF Wu, Nan
   Deng, Lei
   Li, Guoqi
   Xie, Yuan
TI Core Placement Optimization for Multi-chip Many-core Neural Network
   Systems with Reinforcement Learning
SO ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS
DT Article
DE Multi-chip many-core architecture; neural network accelerator; core
   placement optimization; machine learning for system
ID DESIGN SPACE; ON-CHIP; REGRESSION
AB Multi-chip many-core neural network systems are capable of providing high parallelism benefited from decentralized execution, and they can be scaled to very large systems with reasonable fabrication costs. As multi-chip many-core systems scale up, communication latency related effects will take a more important portion in the system performance. While previous work mainly focuses on the core placement within a single chip, there are two principal issues still unresolved: the communication-related problems caused by the non-uniform, hierarchical on/off-chip communication capability in multi-chip systems, and the scalability of these heuristic-based approaches in a factorially growing search space. To this end, we propose a reinforcement-learning-based method to automatically optimize core placement through deep deterministic policy gradient, taking into account information of the environment by performing a series of trials (i.e., placements) and using convolutional neural networks to extract spatial features of different placements. Experimental results indicate that compared with a naive sequential placement, the proposed method achieves 1.99x increase in throughput and 50.5% reduction in latency; compared with the simulated annealing, an effective technique to approximate the global optima in an extremely large search space, our method improves the throughput by 1.22x and reduces the latency by 18.6%. We further demonstrate that our proposed method is capable to find optimal placements taking advantages of different communication properties caused by different system configurations, and work in a topology-agnostic manner.
C1 [Wu, Nan; Deng, Lei; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Li, Guoqi] Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
RP Deng, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM nanwu@ucsb.edu; leideng@ucsb.edu; liguoqi@mail.tsinghua.edu.cn;
   yuanxie@ucsb.edu
CR Addanki R., 2018, P NIPS MACH LEARN SY
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2010, MNIST HANDWRITTEN DI
   [Anonymous], 2019, P 36 INT C MACH LEAR
   [Anonymous], 2016, THE 49TH ANNUAL IEEE
   [Anonymous], 2010, PROC ANN IEEE INDIA
   [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   [Anonymous], 2017, PROXIMAL POLICY OPTI
   [Anonymous], 2018, ARXIV180904070
   [Anonymous], 2015, P ACM GREAT LAKES S
   Bailey PE, 2014, PROC INT CONF PARAL, P371, DOI 10.1109/ICPP.2014.46
   Beckmann N, 2017, INT S HIGH PERF COMP, P109, DOI 10.1109/HPCA.2017.43
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Beukema T, 2005, IEEE J SOLID-ST CIRC, V40, P2633, DOI 10.1109/JSSC.2005.856584
   Bhatia E, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P1, DOI 10.1145/3307650.3322207
   Boni A, 2001, IEEE J SOLID-ST CIRC, V36, P706, DOI 10.1109/4.913751
   Carrillo S, 2013, IEEE T PARALL DISTR, V24, P2451, DOI 10.1109/TPDS.2012.289
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Demme John, 2013, SIGARCH COMPUT ARCHI, P559, DOI [10.1145/2485922.2485970, DOI 10.1145/2508148.2485970]
   Deng L, 2020, IEEE J SOLID-ST CIRC, V55, P2228, DOI 10.1109/JSSC.2020.2970709
   Deng L, 2020, IEEE T COMPUT AID D, V39, P117, DOI 10.1109/TCAD.2018.2883959
   Ding Y, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P39, DOI 10.1145/3307650.3326633
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Fettes Q, 2019, IEEE T COMPUT, V68, P375, DOI 10.1109/TC.2018.2875476
   Gao Y., 2018, P INT C MACH LEARN, V80, P1662
   Gao Yuanxiang, 2018, ADV NEURAL INFORM PR, P9971
   Garey M., 1979, COMPUTERS INTRACTABI
   Garza E, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P27, DOI 10.1145/3307650.3322217
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hashemi Milad, 2018, P INT C MACH LEARN, P1924
   He K., 2015, ABS151203385 CORR
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hoffmann H, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P198, DOI 10.1145/2815400.2815403
   Hu JC, 2005, IEEE T COMPUT AID D, V24, P551, DOI 10.1109/TCAD.2005.844106
   Hu JC, 2003, ASP-DAC 2003: PROCEEDINGS OF THE ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, P233, DOI 10.1109/ASPDAC.2003.1195022
   Hwangbo J, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aau5872
   Ipek Engin, 2006, EFFICIENTLY EXPLORIN, V41
   Jiménez DA, 2011, 2011 IEEE 29TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P113, DOI 10.1109/ICCD.2011.6081385
   Jooya A, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P659, DOI 10.1109/HPCSim.2016.7568398
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim J, 2008, CONF PROC INT SYMP C, P77, DOI 10.1109/ISCA.2008.19
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee BC, 2007, INT S HIGH PERF COMP, P340
   Lee BC, 2008, INT SYMP MICROARCH, P270, DOI 10.1109/MICRO.2008.4771797
   Lee MKF, 2019, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3291054
   Lei T, 2003, EUROMICRO SYMPOSIUM ON DIGITAL SYSTEM DESIGN, PROCEEDINGS, P180
   Lillicrap T. P., 2015, INT C LEARNING REPRE
   Lin TR, 2019, IEEE COMPUT ARCHIT L, V18, P51, DOI 10.1109/LCA.2019.2905587
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mendis C., 2019, ADV NEURAL INFORM PR, P14598
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Mirhoseini Azalia, 2018, P 35 INT C MACH LEAR
   Mishra N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC COMPUTING (ICAC), P125, DOI 10.1109/ICAC.2017.29
   Mnih V., 2013, PLAYING ATARI DEEP R
   Murali S, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P896, DOI 10.1109/DATE.2004.1269002
   Ozsoy M, 2016, IEEE T COMPUT, V65, P3332, DOI 10.1109/TC.2016.2540634
   Painkras E, 2013, IEEE J SOLID-ST CIRC, V48, P1943, DOI 10.1109/JSSC.2013.2259038
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Rao N, 2018, INT SYM COMP ARCHIT, P1, DOI [10.1109/CAHPC.2018.8645914, 10.1109/SBAC-PAD.2018.00015]
   Sallab A. E.L., 2017, ELECT IMAGING, P70
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sharma PK, 2019, MICROPROCESS MICROSY, V64, P88, DOI 10.1016/j.micpro.2018.10.008
   Shen WT, 2007, NOCS 2007: FIRST INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, PROCEEDINGS, P317
   Shi Z, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P413, DOI 10.1145/3352460.3358319
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Silver D, 2014, P 31 INT C INT C MAC, V32
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Stock K, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086729
   Sutskever I., 2014, CORR, P3104
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Teran E, 2016, P 49 ANN IEEE ACM IN, P1
   Uhlenbeck GE, 1930, PHYS REV, V36, P0823, DOI 10.1103/PhysRev.36.823
   Urgese G, 2018, IEEE T EMERG TOP COM, V6, P317, DOI 10.1109/TETC.2016.2579605
   van Laarhoven P.J.M., 1987, SIMULATED ANNEALING, P7, DOI DOI 10.1007/978-94-015-7744-1_2
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
   Wang K, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P589, DOI 10.1145/3307650.3322274
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wenhao Jia, 2012, 2012 IEEE International Symposium on Performance Analysis of Systems & Software (ISPASS), P2, DOI 10.1109/ISPASS.2012.6189201
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wilson JM, 2018, ISSCC DIG TECH PAP I, P276, DOI 10.1109/ISSCC.2018.8310291
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
   Yigitbasi N, 2013, I S MOD ANAL SIM COM, P11, DOI 10.1109/MASCOTS.2013.9
   Zeng Y, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P305, DOI 10.1145/3132402.3132405
   Zhang Haitao, 2018, P 47 INT C PAR PROC, P32
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
NR 96
TC 7
Z9 8
U1 2
U2 13
PD FEB
PY 2021
VL 26
IS 2
AR 11
DI 10.1145/3418498
UT WOS:000620972000003
DA 2023-11-16
ER

PT J
AU Que, ZQ
   Zhu, YX
   Fan, HX
   Meng, JX
   Niu, XY
   Luk, W
AF Que, Zhiqiang
   Zhu, Yongxin
   Fan, Hongxiang
   Meng, Jiuxi
   Niu, Xinyu
   Luk, Wayne
TI Mapping Large LSTMs to FPGAs with Weight Reuse
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE LSTM; FPGA; Hardware architecture
AB Long-Short Term Memory (LSTM) can retain memory and learn from data sequences. It gives state-of-the-art accuracy in many applications such as speech recognition, natural language processing and video classifications. Field-Programmable Gate Arrays (FPGAs) have been used to speed up the inference of LSTMs, but FPGA-based LSTM accelerators are limited by the size of on-chip memory and the bandwidth of external memory on FPGA boards. We propose a novel hardware architecture to overcome data dependency and a new blocking-batching strategy to reuse the LSTM weights fetched from external memory to optimize the performance of systems with size-limited on-chip memory for large machine learning models. Evaluation results show that our architecture can achieve 20.8 GOPS/W, which is among the highest for the FPGA-based LSTM designs storing weights in off-chip memory. Our design achieves 1.65 times higher performance-per-watt efficiency and 2.48 times higher performance-per-DSP efficiency when compared with the current state-of-the-art designs of LSTM using weights stored in off-chip memory. Compared with CPU and GPU implementations, our FPGA implementation is 23.7 and 1.3 times faster while consuming 208 and 19.2 times lower energy respectively, which shows that our approach enables large LSTM systems to be processed efficiently on FPGAs with high performance and low power consumption.
C1 [Que, Zhiqiang; Fan, Hongxiang; Meng, Jiuxi; Luk, Wayne] Imperial Coll London, London, England.
   [Zhu, Yongxin] Chinese Acad Sci, Shanghai Adv Res Inst, Beijing, Peoples R China.
   [Niu, Xinyu] Corerain Technol Ltd, Shenzhen, Peoples R China.
RP Que, ZQ (corresponding author), Imperial Coll London, London, England.
EM z.que@imperial.ac.uk; zhuyongxin@sari.ac.cn; h.fan17@imperial.ac.uk;
   jiuxi.meng16@imperial.ac.uk; xinyu.niu@corerain.com;
   w.luk@imperial.ac.uk
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   [Anonymous], 2016, RECURRENT BATCH NORM
   Ardakani A., 2018, LEARNING SKIP INEFFE
   Chang A.X., 2015, RECURRENT NEURAL NET
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Eyben F., 2009, AUTOMATIC SPEECH REC
   Fan H., 2018, 28 INT C FIELD PROGR
   Fan H., 2019, IEEE 30 INT C APPL S
   Fan HX, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P17, DOI 10.1109/FPT.2018.00014
   Ferreira JC, 2016, PROC INT CONF RECON
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   Liu ZS, 2018, PROCEEDINGS OF THE ASME TURBO EXPO: TURBOMACHINERY TECHNICAL CONFERENCE AND EXPOSITION, 2018, VOL 2D
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nurvitadhi E., 2017, P ACM INT S FIELD PR
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Que Z., 2019, INT C FIELD PROGR TE
   Que ZQ, 2020, ANN IEEE SYM FIELD P, P10, DOI 10.1109/FCCM48280.2020.00011
   Que ZQ, 2019, IEEE INT CONF ASAP, P17, DOI 10.1109/ASAP.2019.00-42
   Rizakis M., 2018, APPROXIMATE FPGA BAS
   Rybalkin V., 2017, P C DES AUT TEST EUR
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Sun Z., 2018, IEEE INT C SMART CLO
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Xiong P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P13, DOI 10.1109/SmartCloud.2018.00011
   Zamir A. R., 2012, UCF101 DATASET 101 H
   Zhang C., 2019, P 2019 ACMSIGDA INT, DOI [10.1145/3289602.3293898, DOI 10.1145/3289602.3293898]
   Zhang M., 2018, 2018 USENIX ANN TECH
   Zhang X., 2017, FLUORESCENCE SPECTRO, P1, DOI DOI 10.3390/S17122719
   Zhao RZ, 2017, LECT NOTES COMPUT SC, V10216, P255, DOI 10.1007/978-3-319-56258-2_22
NR 36
TC 17
Z9 18
U1 0
U2 10
PD SEP
PY 2020
VL 92
IS 9
SI SI
BP 965
EP 979
DI 10.1007/s11265-020-01549-8
EA JUL 2020
UT WOS:000546872700002
DA 2023-11-16
ER

PT J
AU Ko, GG
   Rutenbar, RA
AF Ko, Glenn G.
   Rutenbar, Rob A.
TI Real-Time and Low-Power Streaming Source Separation Using Markov Random
   Field
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Real-time streaming; blind source separation; Markov random field;
   maximum a posteriori inference; Gibbs sampling
ID BLIND SIGNAL SEPARATION; FPGA; IMPLEMENTATION; ALGORITHM
AB Machine learning (ML) has revolutionized a wide range of recognition tasks, ranging from text analysis to speech to vision, most notably in cloud deployments. However, mobile deployment of these ideas involves a very different category of design problems. In this article, we develop a hardware architecture for a sound source separation task, intended for deployment on a mobile phone. We focus on a novel Markov random field (MRF) sound source separation algorithm that uses expectation-maximization and Gibbs sampling to learn MRF parameters on the fly and infer the best separation of sources. The intrinsically iterative algorithm suggests challenges for both speed and power. A real-time streaming FPGA implementation runs at 150MHz with 207KB RAM, achieves a speed-up of 22x over a software reference, performs with an SDR of up to 7.021dB with 1.601ms latency, and exhibits excellent perceived audio quality. A 45nm CMOS ASIC virtual prototype simulated at 20MHz shows that this architecture is small (<10 million gates) and consumes only 70mW, which is less than 2% of the power of an ARM Cortex-A9 software version. To the best of our knowledge, this is the first Gibbs sampling inference accelerator designed in conventional FPGA/ASIC technology that targets a realistic mobile perceptual application.
C1 [Ko, Glenn G.; Rutenbar, Rob A.] Univ Illinois, Urbana, IL 61801 USA.
   [Ko, Glenn G.] Harvard Univ, 33 Oxford St, Cambridge, MA 02138 USA.
   [Rutenbar, Rob A.] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
RP Ko, GG (corresponding author), Univ Illinois, Urbana, IL 61801 USA.; Ko, GG (corresponding author), Harvard Univ, 33 Oxford St, Cambridge, MA 02138 USA.
EM gko@seas.harvard.edu; rutenbar@pitt.edu
CR [Anonymous], 1998, INTRO MONTE CARLO ME
   [Anonymous], 2008, 2069 MITCSAILTR
   [Anonymous], TECHNICAL REPORT
   Bakos JD, 2010, COMPUT SCI ENG, V12, P80, DOI 10.1109/MCSE.2010.135
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Birchfield ST, 2005, INT CONF ACOUST SPEE, P1109
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Brewer TM, 2010, IEEE MICRO, V30, P70, DOI 10.1109/MM.2010.36
   Campbell D. R., 2005, Computing and Information Systems, V9, P48
   Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250
   Charoensak C, 2005, IEEE INT SYMP CIRC S, P5822, DOI 10.1109/ISCAS.2005.1465962
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   CULLER A, 1986, ANNU REV COMPUT SCI, V1, P225
   Das S, 2015, IEEE INT SYMP CIRC S, P2704, DOI 10.1109/ISCAS.2015.7169244
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dennis J. B., 1975, 2nd Annual Symposium on Computer Architecture, P126
   Detrey J, 2007, MICROPROCESS MICROSY, V31, P537, DOI 10.1016/j.micpro.2006.02.008
   Garofolo J. S., 1993, P LING DAT CONSTR
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GURD JR, 1985, COMMUN ACM, V28, P34, DOI 10.1145/2465.2468
   Gutierrez R, 2011, IEEE T VLSI SYST, V19, P2326, DOI 10.1109/TVLSI.2010.2081387
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Holma H., 2011, LTE UMTS EVOLUTION L
   Hyvarinen A., 2004, INDEPENDENT COMPONEN
   Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175
   Kim CM, 2003, IEEE T NEURAL NETWOR, V14, P1038, DOI 10.1109/TNN.2003.818381
   Kim M., 2012, P 9 INT C EXP EM TEC, P1, DOI DOI 10.1007/S00779-012-0543
   Ko GG, 2017, INT CONF ACOUST SPEE, P2477, DOI 10.1109/ICASSP.2017.7952602
   Koller D., 2009, PROBABILISTIC GRAPHI
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Minka T., 1998, EXPECTATION MAXIMIZA
   Mitchell J. N., 1962, IRE T ELECT COMPUTER, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   Pearl J., 1988, PROBABILISTIC REASON
   Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shyu KK, 2008, IEEE T NEURAL NETWOR, V19, P958, DOI 10.1109/TNN.2007.915115
   Suyi Li, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P469, DOI 10.1109/CSIE.2009.999
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Telecommunication Standardization Sector ITU, 2003, INT TEL CONN CIRC GE
   Tkacik Thomas E., 2003, HARDWARE RANDOM NUMB, P450, DOI [10.1007/3-540-36400-5_32, DOI 10.1007/3-540-36400-5_32]
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
NR 48
TC 4
Z9 4
U1 0
U2 2
PD JUL
PY 2018
VL 14
IS 2
SI SI
AR 17
DI 10.1145/3183351
UT WOS:000449159400004
DA 2023-11-16
ER

PT C
AU Abdelsalam, AM
   Boulet, F
   Demers, G
   Langlois, JMP
   Cheriet, F
AF Abdelsalam, Ahmed M.
   Boulet, Felix
   Demers, Gabriel
   Langlois, J. M. Pierre
   Cheriet, Farida
BE Andrews, D
   Cumplido, R
   Feregrino, C
   Stroobandt, D
TI An Efficient FPGA-based Overlay Inference Architecture for Fully
   Connected DNNs
SO 2018 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS
   (RECONFIG)
SE Proceedings International Conference on Reconfigurable Computing and
   FPGAs
DT Proceedings Paper
CT International Conference on Reconfigurable Computing and FPGAs
   (ReConFig)
CY DEC 03-05, 2018
CL Cancun, MEXICO
DE Deep Learning; FPGAs; Hardware Accelerators; Deep Neural Networks;
   Quantization
AB Deep Neural Networks (DNNs) have gained significant popularity in several classification and regression applications. The massive computation and memory requirements of DNNs pose special challenges for FPGA implementation. Moreover, programming FPGAs requires hardware-specific knowledge that many machine-learning researchers do not possess. To make the power and versatility of FPGAs available to a wider DNN user community and to improve DNN design efficiency, we introduce a Single hidden layer Neural Network (SNN) multiplication-free overlay architecture with fully connected DNN-level performance. This FPGA inference overlay can be used for applications that are normally solved with fully connected DNNs. The overlay avoids the time needed to synthesize, place, route and regenerate a new bitstream when the application changes. The SNN overlay inputs and activations are quantized to power-of-two values, which allows utilizing shift units instead of multipliers. Since the overlay is a SNN, we fill the FPGA chip with the maximum possible number of neurons that can work in parallel in the hidden layer. On a ZYNQ-7000 ZC706 FPGA, it is thus possible to implement 2450 neurons in the hidden layer and 30 neurons in the output layer. We evaluate the proposed architecture on typical benchmark datasets and demonstrate higher throughput with respect to the state-of-the-art while achieving the same accuracy.
C1 [Abdelsalam, Ahmed M.; Boulet, Felix; Demers, Gabriel; Langlois, J. M. Pierre; Cheriet, Farida] Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
RP Abdelsalam, AM (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM ahmed.abdelsalam@polymtl.ca; felix.boulet@polymtl.ca;
   gabriel.demers@polymtl.ca; pierre.langlois@polymtl.ca;
   farida.cheriet@polymtl.ca
CR Abdelsalam A. M., 2017, IEEE FCCM
   Alemdar H., 2017, IEEE INT JOINT C NEU
   [Anonymous], 2015, 151000149 ARXIV
   [Anonymous], 1998, P IEEE
   [Anonymous], 1991, NEURAL NETWORKS
   [Anonymous], 2016, ARXIV160702241
   Ba Jimmy, 2014, ADV NEURAL INFORM PR
   Brant A., 2012, IEEE FCCM
   Courbariaux M., 2016, 160202830 ARXIV
   Gudovskiy D. A., 2017, 170602393 ARXIV
   Gupta S., 2015, INT C MACH LEARN AUG
   Hunter D., 2012, IEEE T IND INFOR MAY
   Kwan H. K., 1993, IEEE MWSCAS
   Lacey G., 2016, 160204283 ARXIV
   LeCun Yann, 2015, NATURE
   Misra J., 2010, NEUROCOMPUTING
   Nurvitadhi E., 2017, ACM SIGDA ISFPGA
   Park J., 2016, IEEE ICASSP
   Rastegari M., 2016, SPRING EUR C COMP VI
   Razlighi M. S., 2017, IEEE DES AUT TEST EU
   Sze V., 2017, 170309039 ARXIV
   Sze V., 2016, 161207625 ARXIV
   Tann H., 2017, ACM ANN DES AUT C JU
   Umuroglu Y., 2017, ACM SIGDA ISFPGA
   Xilinx, AXI REF GUID
NR 25
TC 6
Z9 6
U1 0
U2 3
PY 2018
UT WOS:000462282700034
DA 2023-11-16
ER

PT J
AU Chammas, S
   Wang, Q
   Schneider, T
   Ihme, M
   Chen, YF
   Anderson, J
AF Chammas, Sheide
   Wang, Qing
   Schneider, Tapio
   Ihme, Matthias
   Chen, Yi-fan
   Anderson, John
TI Accelerating Large-Eddy Simulations of Clouds With Tensor Processing
   Units
SO JOURNAL OF ADVANCES IN MODELING EARTH SYSTEMS
DT Article
DE large-eddy simulation; stratocumulus clouds; tensor processing units;
   numerical methods
ID RADIATIVE-CONVECTIVE EQUILIBRIUM; GENERAL-CIRCULATION; HYDROLOGICAL
   CYCLE; ANELASTIC APPROXIMATION; NUMERICAL-SIMULATION; GLOBAL
   CIRCULATIONS; CLIMATE SENSITIVITY; SHALLOW CUMULUS; DYNAMICAL RANGE;
   STRATOCUMULUS
AB Clouds, especially low clouds, are crucial for regulating Earth's energy balance and mediating the response of the climate system to changes in greenhouse gas concentrations. Despite their importance for climate, they remain relatively poorly understood and are inaccurately represented in climate models. A principal reason is that the high computational expense of simulating them with large-eddy simulations (LES) has inhibited broad and systematic numerical experimentation and the generation of large data sets for training parametrization schemes for climate models. Here we demonstrate LES of low clouds on tensor processing units (TPUs), application-specific integrated circuits that were originally developed for machine learning applications. We show that TPUs in conjunction with tailored software implementations can be used to simulate computationally challenging stratocumulus clouds in conditions observed during the Dynamics and Chemistry of Marine Stratocumulus (DYCOMS) field study. The TPU-based LES code successfully reproduces clouds during DYCOMS and opens up the large computational resources available on TPUs to cloud simulations. The code enables unprecedented weak and strong scaling of LES, making it possible, for example, to simulate stratocumulus with 10x speedup over real-time evolution in domains with a 34.7 km x 53.8 km horizontal cross section. The results open up new avenues for computational experiments and for substantially enlarging the sample of LES available to train parameterizations of low clouds.
   The study of clouds has been impeded by, among other factors, limitations in our ability to simulate them rapidly and on sufficiently large domains. In particular, computational limitations in simulating low clouds are among the reasons for the difficulties of representing them accurately in climate models; this is one of the dominant uncertainties in climate predictions. This paper demonstrates how the large computing power available on tensor processing units (TPUs) (integrated circuits originally designed for machine learning applications) can be harnessed for simulating low clouds. We demonstrate the largest simulations of low clouds to date, with hundreds of billions of variables, and we document their fidelity to aircraft observations. The results open up the large computational resources available on TPUs, hitherto primarily used for machine learning, to the study of clouds in the climate system.
   We introduce a large-eddy simulation (LES) framework that runs on tensor processing units (TPUs, accelerators designed for machine learning)The fidelity of the LES is established by reproducing aircraft observations of nocturnal stratocumulus clouds over the PacificThe LES exhibit unprecedented scalability on TPUs, enabling the large-scale generation of training data for cloud parameterizations
C1 [Chammas, Sheide; Wang, Qing; Schneider, Tapio; Ihme, Matthias; Chen, Yi-fan; Anderson, John] Google LLC, Mountain View, CA 94043 USA.
   [Schneider, Tapio] CALTECH, Pasadena, CA USA.
   [Ihme, Matthias] Stanford Univ, Stanford, CA USA.
RP Chammas, S (corresponding author), Google LLC, Mountain View, CA 94043 USA.
EM sheide@google.com
CR Allen MR, 2002, NATURE, V419, P224, DOI 10.1038/nature01092
   Balaji V, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0085
   Bannon PR, 1996, J ATMOS SCI, V53, P3618, DOI 10.1175/1520-0469(1996)053<3618:OTAAFA>2.0.CO;2
   Belletti F, 2020, Arxiv, DOI arXiv:1906.02818
   Blossey PN, 2016, J ADV MODEL EARTH SY, V8, P1714, DOI 10.1002/2016MS000765
   Blossey PN, 2013, J ADV MODEL EARTH SY, V5, P234, DOI 10.1002/jame.20025
   Bony S, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2005GL023851
   Bretherton CS, 2015, PHILOS T R SOC A, V373, DOI 10.1098/rsta.2014.0415
   Bretherton CS, 1999, Q J ROY METEOR SOC, V125, P391, DOI 10.1002/qj.49712555402
   Brient F, 2016, J CLIMATE, V29, P5821, DOI 10.1175/JCLI-D-15-0897.1
   Brient F, 2016, CLIM DYNAM, V47, P433, DOI 10.1007/s00382-015-2846-0
   Bryan GH, 2004, MON WEATHER REV, V132, P2421, DOI 10.1175/1520-0493(2004)132<2421:AROIWP>2.0.CO;2
   Caldwell P, 2009, J ATMOS SCI, V66, P432, DOI 10.1175/2008JAS2785.1
   CESS RD, 1990, J GEOPHYS RES-ATMOS, V95, P16601, DOI 10.1029/JD095iD10p16601
   Cess RD, 1996, J GEOPHYS RES-ATMOS, V101, P12791, DOI 10.1029/96JD00822
   Charney JG., 1950, TELLUS, V2, P237, DOI [DOI 10.3402/TELLUSA.V2I4.8607, DOI 10.1111/J.2153-3490.1950.TB00336.X]
   Chou C, 2004, J CLIMATE, V17, P2688, DOI [10.1175/1520-0442(2004)017<2688:MOGWIO>2.0.CO;2, 10.1175/1520-0442(2004)017&lt;2688:MOGWIO&gt;2.0.CO;2]
   Couvreux F, 2021, J ADV MODEL EARTH SY, V13, DOI 10.1029/2020MS002217
   Cronin T., 2014, THESIS MIT
   Cronin TW, 2015, Q J ROY METEOR SOC, V141, P1017, DOI 10.1002/qj.2443
   Dufresne JL, 2008, J CLIMATE, V21, P5135, DOI 10.1175/2008JCLI2239.1
   DURRAN DR, 1982, J ATMOS SCI, V39, P2152, DOI 10.1175/1520-0469(1982)039<2152:OTEOMO>2.0.CO;2
   DURRAN DR, 1983, MON WEATHER REV, V111, P2341, DOI 10.1175/1520-0493(1983)111<2341:ACMFTS>2.0.CO;2
   Ham F., 2004, ANN RES BRIEFS, P3
   Held IM, 1999, TELLUS A, V51, P59, DOI 10.1034/j.1600-0870.1999.t01-1-00006.x
   HELD IM, 1993, J ATMOS SCI, V50, P3909, DOI 10.1175/1520-0469(1993)050<3909:RCEWET>2.0.CO;2
   Held IM, 1996, J ATMOS SCI, V53, P946, DOI 10.1175/1520-0469(1996)053<0946:ASTFHH>2.0.CO;2
   Held IM, 2006, J CLIMATE, V19, P5686, DOI 10.1175/JCLI3990.1
   Hourdin F, 2021, J ADV MODEL EARTH SY, V13, DOI 10.1029/2020MS002225
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KLEMP JB, 1978, J ATMOS SCI, V35, P78, DOI 10.1175/1520-0469(1978)035<0078:NSOHMW>2.0.CO;2
   LILLY DK, 1962, TELLUS, V14, P148, DOI 10.3402/tellusa.v14i2.9537
   Lopez-Gomez I, 2022, J ADV MODEL EARTH SY, V14, DOI 10.1029/2022MS003105
   Lu TJ, 2020, Arxiv, DOI arXiv:2002.03260
   MANABE S, 1975, J ATMOS SCI, V32, P3, DOI 10.1175/1520-0469(1975)032<0003:TEODTC>2.0.CO;2
   Manabe S., 1965, MON WEA REV, V93, P769, DOI [DOI 10.1175/1520-0493(1965)093<0769:SCOAGC>2.3.CO;2, 10.1175/1520-0493(1965)0932.3.CO;2]
   Matheou G, 2018, ATMOSPHERE-BASEL, V9, DOI 10.3390/atmos9100392
   Mellado JP, 2018, J ADV MODEL EARTH SY, V10, P1421, DOI 10.1029/2018MS001312
   Mellado JP, 2017, ANNU REV FLUID MECH, V49, P145, DOI 10.1146/annurev-fluid-010816-060231
   Mishra S, 2021, COMMUN COMPUT PHYS, V29, P1299, DOI 10.4208/cicp.OA-2020-0046
   Morinishi Y, 1998, J COMPUT PHYS, V143, P90, DOI 10.1006/jcph.1998.5962
   National Academies of Sciences Engineering and Medicine, 2022, AUT RES WORKFL ACC D
   O'Gorman PA, 2008, J CLIMATE, V21, P3815, DOI 10.1175/2007JCLI2065.1
   Pauluis O, 2008, J ATMOS SCI, V65, P2719, DOI 10.1175/2007JAS2475.1
   Pederson R, 2023, J CHEM THEORY COMPUT, V19, P25, DOI 10.1021/acs.jctc.2c00876
   Phillips N.A., 1954, TELLUS, V6, P273, DOI [10.1111/j.2153-3490.1954.tb01123.x, DOI 10.1111/J.2153-3490.1954.TB01123.X]
   PHILLIPS NA, 1956, Q J ROY METEOR SOC, V82, P123, DOI 10.1002/qj.49708235202
   Pierce C.D., 2001, PROGR VARIABLE APPRO
   Pressel KG, 2017, J ADV MODEL EARTH SY, V9, P1342, DOI 10.1002/2016MS000778
   Pressel KG, 2015, J ADV MODEL EARTH SY, V7, P1425, DOI 10.1002/2015MS000496
   Qingwang John, 2023, Zenodo, DOI 10.5281/ZENODO.7569544
   RANDALL DA, 1984, B AM METEOROL SOC, V65, P1290, DOI 10.1175/1520-0477(1984)065<1290:OFROSM>2.0.CO;2
   Rauber RM, 2007, B AM METEOROL SOC, V88, P1912, DOI 10.1175/BAMS-88-12-1912
   RHINES PB, 1979, ANNU REV FLUID MECH, V11, P401, DOI 10.1146/annurev.fl.11.010179.002153
   RHINES PB, 1975, J FLUID MECH, V69, P417, DOI 10.1017/S0022112075001504
   RIND D, 1992, NATURE, V358, P119, DOI 10.1038/358119a0
   Sandu I, 2011, J ATMOS SCI, V68, P1865, DOI 10.1175/2011JAS3614.1
   Schalkwijk J, 2015, B AM METEOROL SOC, V96, P715, DOI 10.1175/BAMS-D-14-00114.1
   Schneider T, 2006, J ATMOS SCI, V63, P1569, DOI 10.1175/JAS3699.1
   Schneider T, 2006, ANNU REV EARTH PL SC, V34, P655, DOI 10.1146/annurev.earth.34.031405.125144
   Schneider T, 2019, NAT GEOSCI, V12, P163, DOI 10.1038/s41561-019-0310-1
   Schneider T, 2017, NAT CLIM CHANGE, V7, P3, DOI 10.1038/nclimate3190
   Schneider T, 2010, REV GEOPHYS, V48, DOI 10.1029/2009RG000302
   Shen ZY, 2022, J ADV MODEL EARTH SY, V14, DOI 10.1029/2021MS002631
   Siebesma AP, 2003, J ATMOS SCI, V60, P1201, DOI 10.1175/1520-0469(2003)60<1201:ALESIS>2.0.CO;2
   Smagorinsky J., 1965, MON WEATHER REV, V93, P727, DOI DOI 10.1175/1520-0493(1965)093<0727:NRFANL>2.3.CO;2
   Smagorinsky J., 1963, MON WEATHER REV, V91, P99, DOI [10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2, DOI 10.1175/1520-0493(1963)091ANDLT;0099:GCEWTPANDGT;2.3.CO;2, 10.1175/1520-0493(1963)0912.3.CO;2]
   Sridhar A, 2022, GEOSCI MODEL DEV, V15, P6259, DOI 10.5194/gmd-15-6259-2022
   Stevens B, 2005, ANNU REV EARTH PL SC, V33, P605, DOI 10.1146/annurev.earth.33.092203.122658
   Stevens B, 2005, MON WEATHER REV, V133, P1443, DOI 10.1175/MWR2930.1
   Stevens B, 2003, Q J ROY METEOR SOC, V129, P3469, DOI 10.1256/qj.02.202
   Stevens DE, 1996, J COMPUT PHYS, V129, P284, DOI 10.1006/jcph.1996.0250
   STRAKA JM, 1993, INT J NUMER METH FL, V17, P1, DOI 10.1002/fld.1650170103
   Tan ZH, 2017, J ADV MODEL EARTH SY, V9, P19, DOI 10.1002/2016MS000804
   Tan ZH, 2016, J ADV MODEL EARTH SY, V8, P1565, DOI 10.1002/2016MS000655
   TAO WK, 1989, MON WEATHER REV, V117, P231, DOI 10.1175/1520-0493(1989)117<0231:AIWSA>2.0.CO;2
   Tompkins AM, 1998, Q J ROY METEOR SOC, V124, P2073, DOI 10.1002/qj.49712455013
   TRIPOLI GJ, 1981, MON WEATHER REV, V109, P1094, DOI 10.1175/1520-0493(1981)109<1094:TUOLLW>2.0.CO;2
   Vial J, 2013, CLIM DYNAM, V41, P3339, DOI 10.1007/s00382-013-1725-9
   Wang Q, 2022, COMPUT PHYS COMMUN, V274, DOI 10.1016/j.cpc.2022.108292
   Webb MJ, 2006, CLIM DYNAM, V27, P17, DOI 10.1007/s00382-006-0111-2
   Webb MJ, 2013, CLIM DYNAM, V40, P677, DOI 10.1007/s00382-012-1336-x
   Williams G. P., 1988, CLIM DYNAM, V3, P45, DOI 10.1007/BF01080901
   Williams G. P., 1988, CLIM DYNAM, V2, P205, DOI 10.1007/bf01371320
   Wing AA, 2018, GEOSCI MODEL DEV, V11, P793, DOI 10.5194/gmd-11-793-2018
   Wood R, 2012, MON WEATHER REV, V140, P2373, DOI 10.1175/MWR-D-11-00121.1
   ZALESAK ST, 1979, J COMPUT PHYS, V31, P335, DOI 10.1016/0021-9991(79)90051-2
   Zelinka MD, 2017, NAT CLIM CHANGE, V7, P674, DOI 10.1038/nclimate3402
   Zhang MH, 2013, J ADV MODEL EARTH SY, V5, P826, DOI 10.1002/2013MS000246
   Zhang MH, 2012, J ADV MODEL EARTH SY, V4, DOI 10.1029/2012MS000182
NR 90
TC 0
Z9 0
U1 0
U2 0
PD OCT
PY 2023
VL 15
IS 10
AR e2023MS003619
DI 10.1029/2023MS003619
UT WOS:001076336700001
DA 2023-11-16
ER

PT J
AU Kaul, A
   Luo, YD
   Peng, XC
   Manley, M
   Luo, YC
   Yu, SM
   Bakir, MS
AF Kaul, Ankit
   Luo, Yandong
   Peng, Xiaochen
   Manley, Madison
   Luo, Yuan-Chun
   Yu, Shimeng
   Bakir, Muhannad S.
TI 3-D Heterogeneous Integration of RRAM-Based Compute-In-Memory: Impact of
   Integration Parameters on Inference Accuracy
SO IEEE TRANSACTIONS ON ELECTRON DEVICES
DT Article
DE Reliability; Common Information Model (electricity); Solid modeling;
   Semiconductor device modeling; Benchmark testing; Performance
   evaluation; Junctions; 3-D heterogeneous integration (3-D-HI);
   compute-in-memory (CIM); emerging nonvolatile memory (eNVM);
   machine-learning accelerator; RRAM reliability; thermal-induced
   retention drift
ID SILICON; DESIGN
AB Three-dimensional heterogeneous integration (3-D-HI) has been proposed as a potential method to stack a large amount of embedded memory required in state-of-the-art compute-in-memory (CIM) artificial intelligence (AI) accelerators. While embedded nonvolatile memory, such as resistive RAM (RRAM), is a promising alternative to static random access memory (SRAM)/dynamic random access memory (DRAM) as a CIM synaptic device owing to high density, low leakage, and nondestructive read, thermal-induced device conductance drift remains a challenge. High-temperature-driven lower retention can be more significant in dense memory-logic 3-D integration due to increased volumetric power, which has not been studied in prior work. The scope of this work is to quantify the thermal impact of different 3-D-HI architectures on the reliability of 3-D-integrated binary RRAM devices for CIM applications. A device-integration-application reliability evaluation methodology is proposed, using which 3-D integration architectures and logic-memory partitioning configurations are benchmarked. Due to higher junction temperatures for memory tier in both five-tier monolithic 3-D (M3D) and five-tier through silicon via (TSV)-based 3-D compared to the 2-D baseline, the drop in inference accuracy at ten years is asymptotic to 80%. For our assumed device, integration, and application parameters, a three-tier configuration provides a balanced design option between thermal and application performance.
C1 [Kaul, Ankit; Luo, Yandong; Peng, Xiaochen; Manley, Madison; Luo, Yuan-Chun; Yu, Shimeng; Bakir, Muhannad S.] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Kaul, A (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM ankit.kaul@gatech.edu; mbakir@ece.gatech.edu
CR [Anonymous], 2016, PROC IEEE INT 3D SYS, DOI DOI 10.1109/3DIC.2016.7969996
   Athikulwongse K, 2010, ICCAD-IEEE ACM INT, P669, DOI 10.1109/ICCAD.2010.5654245
   Brunschwiler T, 2017, INT EL DEVICES MEET, DOI 10.1109/IEDM.2017.8268322
   Chen PY, 2015, IEEE T ELECTRON DEV, V62, P4022, DOI 10.1109/TED.2015.2492421
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Games W, 2020, ISSCC DIG TECH PAP I, P144
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaul A, 2022, PEDIATR NEPHROL, V37, P735, DOI 10.1007/s00467-021-05113-9
   Kaul A, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371983
   Kaul A, 2020, ELEC COMP C, P1459, DOI 10.1109/ECTC32862.2020.00231
   Kumar SS, 2017, IEEE T VLSI SYST, V25, P1549, DOI 10.1109/TVLSI.2016.2642587
   Lanza M, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800143
   LEE H, 2020, PROC IEEE GLOBECOM W, P1, DOI [DOI 10.1109/GCWkshps50303.2020.9367572, DOI 10.1109/GCWKSHPS50303.2020.9367572]
   Lee JC, 2016, INT SOC DESIGN CONF, P181, DOI 10.1109/ISOCC.2016.7799847
   Mathur R, 2021, IEEE J EXPLOR SOLID-, V7, P70, DOI 10.1109/JXCDC.2021.3092436
   Okoro C, 2007, ELEC COMP C, P249, DOI 10.1109/ECTC.2007.373805
   Peng XC, 2021, IEEE T ELECTRON DEV, V68, P5598, DOI 10.1109/TED.2021.3111857
   Peng XC, 2019, INT EL DEVICES MEET
   Rajan SK, 2021, IEEE T COMP PACK MAN, V11, P974, DOI 10.1109/TCPMT.2021.3082013
   Sarvey TE, 2019, IEEE T COMP PACK MAN, V9, P2393, DOI 10.1109/TCPMT.2019.2930481
   SHIM W, 2021, INT RELIAB PHY SYM
   Shulaker MM, 2017, NATURE, V547, P74, DOI 10.1038/nature22994
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SINHA S, 2020, INT EL DEVICES MEET
   Sun X, 2021, IEEE T ELECTRON DEV, V68, P5585, DOI 10.1109/TED.2021.3113300
   TUCKERMAN DB, 1981, ELECTRON DEVIC LETT, V2, P126, DOI 10.1109/EDL.1981.25367
   van Erp R, 2020, NATURE, V585, P211, DOI [10.1038/s41586-020-2666-1, 10.1038/s41586-020-2666]
   Wei TW, 2020, APPL THERM ENG, V164, DOI 10.1016/j.applthermaleng.2019.114535
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wu MX, 2015, SCI REP-UK, V5, DOI [10.1038/srep13504, 10.1038/srep10001]
   Zhang Y, 2014, IEEE T COMP PACK MAN, V4, P1914, DOI 10.1109/TCPMT.2014.2364742
NR 32
TC 2
Z9 2
U1 6
U2 6
PD FEB
PY 2023
VL 70
IS 2
BP 485
EP 492
DI 10.1109/TED.2022.3231570
EA DEC 2022
UT WOS:000910580100001
DA 2023-11-16
ER

PT C
AU Zhang, JL
   Swift, M
   Li, J
AF Zhang, Jialiang
   Swift, Michael
   Li, Jing (Jane)
BE Falsafi, B
   Ferdman, M
   Lu, S
   Weinisch, T
TI Software-Defined Address Mapping: A Case on 3D Memory
SO ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON
   ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 27th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY FEB 28-MAR 04, 2022
CL Lausanne, SWITZERLAND
DE Software defined memory; 3D memory; Address mapping
ID SCHEME
AB 3D-stacking memory such as High-Bandwidth Memory (HBM) and Hybrid Memory Cube (HMC) provides orders of magnitude more bandwidth and significantly increased channel-level parallelism (CLP) due to its new parallel memory architecture. However, it is challenging to fully exploit the abundant CLP for performance as the bandwidth utilization is highly dependent on address mapping in the memory controller. Unfortunately, CLP is very sensitive to a program's data access pattern, which is not made available to OS/hardware by existing mechanisms.
   In this work, we address these challenges with software-defined address mapping (SDAM) that, for the first time, enables user program to obtain a direct control of the low-level memory hardware in a more intelligent and fine-grained manner. In particular, we develop new mechanisms that can effectively communicate a program's data access properties to the OS and hardware and to use it to control data placement in hardware. To guarantee correctness and reduce overhead in storage and performance, we extend Linux kernel and C-language memory allocators to support multiple address mappings. For advanced system optimization, we develop machine learning methods that can automatically identify access patterns of major variables in a program and cluster these with similar access patterns to reduce the overhead for SDAM. We demonstrate the benefits of our design on real system prototype, comprising (1) a RISC-V processor, near memory accelerators and HBM modules using Xilinx FPGA platform, and (2) modified Linux and glibc. Our evaluation on standard CPU benchmarks and data-intensive benchmarks (for both CPU and accelerators) demonstrates 1.41x, 1.84x speedup on CPU and 2.58x on near memory accelerators in our system with SDAM compared to a baseline system that uses a fixed address mapping.
C1 [Zhang, Jialiang; Li, Jing (Jane)] Univ Penn, Philadelphia, PA 19104 USA.
   [Swift, Michael] Univ Wisconsin, Madison, WI USA.
RP Zhang, JL (corresponding author), Univ Penn, Philadelphia, PA 19104 USA.
EM jlzhang@seas.upenn.edu; swift@cs.wisc.edu; janeli@seas.upenn.edu
CR Akin B, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P131, DOI 10.1145/2749469.2750397
   [Anonymous], 2010, PROC IEEE 16 INT S H
   [Anonymous], 2017, ACM IEEE 44 ANN INT, P521
   [Anonymous], 2011, HIGH PERFORMANCE COM
   [Anonymous], 2011, P 2011 INT C UNS TRA
   Ayers G, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P513, DOI 10.1145/3373376.3378498
   Balkesen C, 2013, PROC INT CONF DATA, P362, DOI 10.1109/ICDE.2013.6544839
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Brasserl F, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P117
   Bugnion E, 1996, ACM SIGPLAN NOTICES, V31, P244, DOI 10.1145/248209.237195
   Calder B, 1998, ACM SIGPLAN NOTICES, V33, P139, DOI 10.1145/291006.291036
   Celio Christopher, BOOM V2
   Chatterjee N, 2014, INT CONF HIGH PERFOR, P128, DOI 10.1109/SC.2014.16
   ChiachenChou AamerJaleel, 2015, BATMAN MAXIMIZING BA
   Chilimbi TM, 1999, ACM SIGPLAN NOTICES, V34, P1, DOI 10.1145/301631.301633
   Dong Xuan, 2010, P 2010 ACM IEEE INT, P1, DOI DOI 10.1097/MPA.0B013E3181F82F3C
   Evans Jason, 2006, SCALABLE CONCURRENT
   Ghasempour M, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P362, DOI 10.1145/2989081.2989102
   Hashemi M., 2018, P INT C MACH LEARN, V80
   Henning John L, 2006, SIGARCH COMPUT ARCHI, V34, P1, DOI [DOI 10.1145/1186736.1186737, 10.1145/1186736.1186737]
   Hillenbrand M, 2017, PHYS ADDRESS DECODIN
   Intel, 2016, INT XEON PROC E7 V4
   JEDEC, 2012, JEDEC STAND DDR4 SDR
   JEDEC Standard, 2013, JESD235
   Ji X, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126917
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kannan S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P521, DOI 10.1145/3079856.3080245
   Lameter Christoph, 2013, QUEUE, V11, P40, DOI 10.1145/2508834.2513149
   Liu L, 2012, INT CONFER PARA, P367
   Liu YX, 2018, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2018.00024
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Meswani MR, 2015, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2015.7056027
   Min EX, 2018, IEEE ACCESS, V6, P39501, DOI 10.1109/ACCESS.2018.2855437
   Murphy Richard C, 2010, INTRO GRAPH 500, V19, P45
   Narayan A, 2018, INT PARALL DISTRIB P, P326, DOI 10.1109/IPDPS.2018.00042
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Phadke S, 2011, DES AUT TEST EUROPE, P956
   RAU BR, 1991, ACM COMP AR, V19, P74, DOI 10.1145/115953.115961
   Sudan K, 2010, ACM SIGPLAN NOTICES, V45, P219, DOI 10.1145/1735971.1736045
   Sungpack Hong, 2011, Proceedings 2011 International Conference on Parallel Architectures and Compilation Techniques (PACT), P78, DOI 10.1109/PACT.2011.14
   Vijaykumar N, 2018, CONF PROC INT SYMP C, P207, DOI 10.1109/ISCA.2018.00027
   Vijaykumar N, 2018, CONF PROC INT SYMP C, P829, DOI 10.1109/ISCA.2018.00074
   WOLF JL, 1993, IEEE T PARALL DISTR, V4, P70, DOI 10.1109/71.205654
   Wu Q, 2004, INT SYM CODE GENER, P315
   Xilinx, 2019, ULTRASCALE FPGA PROD
   Xilinx, 2019, AXI HIGH BANDW MEM C
   Zhang JL, 2019, ANN IEEE SYM FIELD P, P145, DOI 10.1109/FCCM.2019.00029
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P207, DOI 10.1145/3020078.3021737
   Zhang LX, 2001, IEEE T COMPUT, V50, P1117, DOI 10.1109/12.966490
   Zhang Z, 2000, INT SYMP MICROARCH, P32, DOI 10.1109/MICRO.2000.898056
NR 51
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 70
EP 83
DI 10.1145/3503222.3507774
UT WOS:000810486300006
DA 2023-11-16
ER

PT C
AU Ghiglio, P
   Dolinsky, U
   Goli, M
   Narasimhan, K
AF Ghiglio, Pietro
   Dolinsky, Uwe
   Goli, Mehdi
   Narasimhan, Kumudha
GP ACM
TI Improving performance of SYCL applications on CPU architectures using
   LLVM-directed compilation flow
SO PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL WORKSHOP ON PROGRAMMING
   MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM '22)
DT Proceedings Paper
CT 13th International Workshop on Programming Models and Applications for
   Multicores and Manycores (PMAM) part of PPoPP Conference
CY APR 02-06, 2022
CL Seoul, SOUTH KOREA
DE SYCL; parallel programming; multi-cores; software acceleration;
   portability; standards; compiler optimizations
AB The wide adoption of SYCL as an open-standard API for accelerating C++ software in domains such as HPC, Automotive, Artificial Intelligence, Machine Learning, and other areas necessitates efficient compiler and runtime support for a growing number of different platforms. Existing SYCL implementations provide support for various devices like CPUs, GPUs, DSPs, FPGAs, etc, typically via OpenCL or CUDA backends. While accelerators have increased the performance of user applications significantly, employing CPU devices for further performance improvement is beneficial due to the significant presence of CPUs in existing datacenters.
   SYCL applications on CPUs, currently go through an OpenCL backend. Though an OpenCL backend is valuable in supporting accelerators, it may introduce additional overhead for CPUs since the host and device are the same. Overheads like a run-time compilation of the kernel, transferring of input/output memory to/from the OpenCL device, invoking the OpenCL kernel, may not be necessary when running on the CPU. While some of these overheads (such as data transfer) can be avoided by modifying the application, it can introduce disparity in the SYCL application's ability to achieve performance portability on other devices.
   In this paper, we propose an alternate approach to running SYCL applications on CPUs. We bypass OpenCL and use a CPU-directed compilation flow, along with the integration of Whole Function Vectorization to generate optimized host and device code together in the same translation unit. We compare the performance of our approach - the CPU-directed compilation flow, with an OpenCL backend for existing SYCL-based applications, with no code modification. We run experiments across various CPU architectures to attest to the efficacy of our proposed approach.
C1 [Ghiglio, Pietro; Dolinsky, Uwe; Goli, Mehdi; Narasimhan, Kumudha] Codeplay Software Ltd, Edinburgh, Scotland.
RP Ghiglio, P (corresponding author), Codeplay Software Ltd, Edinburgh, Scotland.
EM pietro.ghiglio@codeplay.com; uwe@codeplay.com; mehdi.goli@codeplay.com;
   kumudha.narasimhan@codeplay.com
CR Aliaga JI., 2017, P 5 INT WORKSHOP OPE, DOI [10.1145/3078155.3078189, DOI 10.1145/3078155.3078189]
   Alpay A., 2020, IWOCL 20, DOI DOI 10.1145/3388333.3388658
   [Anonymous], ONEAPI DEEP NEURAL N
   [Anonymous], INTEL ONEAPI MATH KE
   [Anonymous], COMP SDK
   [Anonymous], ONEAPI SPECIFICATION
   [Anonymous], PORTABLE COMPUTING L
   [Anonymous], ONEDPL ONEAPI DPC LI
   [Anonymous], NVIDIA CUDA PROGRAMM
   [Anonymous], SYCL SPECIFICATION C
   [Anonymous], VECTORIZATION SIMD P
   Ashbaugh B., 2020, P INT WORKSHOP OPENC, P1
   Brown G., 2019, P INT WORKSHOP OPENC, P1
   Burns R, 2019, PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19), DOI 10.1145/3318170.3318183
   Computecpp community edition, US
   Copik M., 2017, P 5 INT WORKSH OPENC
   Deakin T., 2016, GPUSTREAM V2 0 BENCH
   Feng W., 2021, INT WORKSHOP OPENCL, P1
   Goli M., 2016, P 4 INT WORKSHOP OPE, P1
   Gozillon A., 2020, 2020 INT C HIGH PERF
   Hecbench, US
   Karrenberg Ralf, 2015, AUTOMATIC SIMD VECTO, P85
   Ke Y., 2021, INT C HIGH PERFORMAN
   Lattner C., 2008, BSD C, P5
   Lawson J, 2021, PARALLEL COMPUT, V107, DOI 10.1016/j.parco.2021.102813
   Murray A., 2020, P INTERNATIONALWORKS
   Pheatt C., 2008, J COMPUT SCI COLL, V23, P298
   Reinders James, 2021, DATA PARALLEL C MAST
   Sato M., 2020, P ISPDC, P1
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Thoman P., 2021, INTERNATIONALWORKSHO, P1
   Yamada Y., 2018, P INTENATIONAL S HIG, VVolume 30, P19
NR 32
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1
EP 10
DI 10.1145/3528425.3529099
UT WOS:000883489400001
DA 2023-11-16
ER

PT C
AU Long, L
   Bargo, T
   Renambot, L
   Brown, M
   Johnson, AE
AF Long, Lance
   Bargo, Timothy
   Renambot, Luc
   Brown, Maxine
   Johnson, Andrew E.
GP IEEE Comp Soc
TI Composable Infrastructures for an Academic Research Environment: Lessons
   Learned
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE composable infrastructure; deep learning; visutdization; resource
   management; workload management; user workflow; composable co-location;
   infrastructure as code
AB Composable infrastructure holds the promise of accelerating the pace of academic research and discovery by enabling researchers to tailor the resources of a machine (e.g., GPUs, storage, NICs), on-demand, to address application needs. We were first introduced to composable infrastructure in 2018, and at the same time, there was growing demand among our College of Engineering faculty for GPU systems for data science, artificial intelligence / machine learning / deep learning, and visualization. Many purchased their own individual desktop or deskside systems, a few pursued more costly cloud and IIPC solutions, and others looked to the College or campus computer center for GPU resources which, at the time, were scarce. After surveying the diverse needs of our faculty and studying product offerings by a few nascent startups in the composable infrastructure sector, we applied for and received a grant from the National Science Foundation in November 2019 to purchase a mid-scale system, configured to our specifications, for use by faculty and students for research and research training.
   This paper describes our corn posable infrastructure solution and implementation for our academic community. Given how modern workflows are progressively loosing to containers and cloud frameworks (using Kubernetes) and to programming notebooks (primarily Jupyter), both for ease of use and for ensuring reproducible experiments, we initially adapted these tools for our system. We have since made it simpler to use our system, and now provide our users with a public facing JupyterHub server. We also added an expansion chassis to our system to enable composable co-location, which is a shared central architecture in which our researchers can insert and integrate specialized resources (GPUs, accelerators, networking cards, etc.) needed for their research.
   In February 2020, installation of our system was finalized and made operational and we began providing access to faculty in the College of Engineering. Now, two years later, it is used by over 40 faculty and students plus some external collaborators for research and research training. Their use cases and experiences are briefly described in this paper. Composable infrastructure has proven to be a useful computational system for workload variability, uneven applications, and modern workflows in academic environments.
C1 [Long, Lance; Bargo, Timothy; Renambot, Luc; Brown, Maxine; Johnson, Andrew E.] Univ Illinois, Elect Visualizat Lab, Comp Sci, Chicago, IL 60607 USA.
RP Long, L (corresponding author), Univ Illinois, Elect Visualizat Lab, Comp Sci, Chicago, IL 60607 USA.
EM llong4@uic.edu; tbargo2@uic.edu; renambot@uic.edu; maxine@uic.edu;
   ajohnson@uic.edu
CR Altintas I, 2019, Arxiv, DOI arXiv:1903.06802
   [Anonymous], US
   [Anonymous], 2019, BUSINESS WIRE
   Baldin I, 2019, IEEE INTERNET COMPUT, V23, P38, DOI 10.1109/MIC.2019.2958545
   BROWN M, 2019, MERIT MIDSCALE ED RE, DOI DOI 10.1109/ICNP.2019.8888070
   Chen Zhongyi, 2022, 1 WORKSHOP COMPOSABL
   Davariashtiyani A, 2021, COMMUN MATER, V2, DOI 10.1038/s43246-021-00219-x
   Kane Daniel, 2022, UC SAN DIEGO NE 0120
   Keahey K, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P219
   Liu K., 2020, AS C COMP VIS ACCV K, P89, DOI [10.1007/978-3-030-69525-5_6, DOI 10.1007/978-3-030-69525-5_6]
   Liu MY, 2021, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR46437.2021.00960
   Lowe S. D., 2016, COMPOSABLE INFRASTRU
   Ragone M, 2022, COMP MATER SCI, V201, DOI 10.1016/j.commatsci.2021.110905
   Ragone M, 2021, J POWER SOURCES, V483, DOI 10.1016/j.jpowsour.2020.229108
   Trabucco JT, 2020, IEEE INT C BIOINFORM, P2379, DOI 10.1109/BIBM49941.2020.9313467
NR 15
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 1209
EP 1214
DI 10.1109/IPDPSW55747.2022.00208
UT WOS:000855041000141
DA 2023-11-16
ER

PT J
AU Bae, S
   Kim, H
   Lee, S
   Jung, Y
AF Bae, Seongwoo
   Kim, Haechan
   Lee, Seongjoo
   Jung, Yunho
TI FPGA Implementation of Keyword Spotting System Using Depthwise Separable
   Binarized and Ternarized Neural Networks
SO SENSORS
DT Article
DE binarized neural network; field-programmable gate array; keyword
   spotting; ternarized neural network
ID CHIP; PROCESSOR; MEMORY; CNN
AB Keyword spotting (KWS) systems are used for human-machine communications in various applications. In many cases, KWS involves a combination of wake-up-word (WUW) recognition for device activation and voice command classification tasks. These tasks present a challenge for embedded systems due to the complexity of deep learning algorithms and the need for optimized networks for each application. In this paper, we propose a depthwise separable binarized/ternarized neural network (DS-BTNN) hardware accelerator capable of performing both WUW recognition and command classification on a single device. The design achieves significant area efficiency by redundantly utilizing bitwise operators in the computation of the binarized neural network (BNN) and ternary neural network (TNN). In a complementary metal-oxide semiconductor (CMOS) 40 nm process environment, the DS-BTNN accelerator demonstrated significant efficiency. Compared with a design approach where BNN and TNN were independently developed and subsequently integrated as two separate modules into the system, our method achieved a 49.3% area reduction while yielding an area of 0.558 mm(2). The designed KWS system, which was implemented on a Xilinx UltraScale+ ZCU104 field-programmable gate array (FPGA) board, receives real-time data from the microphone, preprocesses them into a mel spectrogram, and uses this as input to the classifier. Depending on the order, the network operates as a BNN or a TNN for WUW recognition and command classification, respectively. Operating at 170 MHz, our system achieved 97.1% accuracy in BNN-based WUW recognition and 90.5% in TNN-based command classification.
C1 [Bae, Seongwoo; Kim, Haechan; Jung, Yunho] Korea Aerosp Univ, Sch Elect & Informat Engn, Goyang Si 10540, South Korea.
   [Lee, Seongjoo] Sejong Univ, Dept Semicond Syst Engn, Seoul 05006, South Korea.
   [Lee, Seongjoo] Sejong Univ, Inst Semicond & Syst IC, Seoul 05006, South Korea.
   [Lee, Seongjoo] Sejong Univ, Dept Convergence Engn Intelligent Drone, Seoul 05006, South Korea.
   [Jung, Yunho] Korea Aerosp Univ, Dept Smart Air Mobil, Goyang Si 10540, South Korea.
RP Jung, Y (corresponding author), Korea Aerosp Univ, Sch Elect & Informat Engn, Goyang Si 10540, South Korea.; Jung, Y (corresponding author), Korea Aerosp Univ, Dept Smart Air Mobil, Goyang Si 10540, South Korea.
EM tjddn1997@kau.kr; ft0241@kau.kr; seongjoo@sejong.ac.kr; yjung@kau.ac.kr
CR Adjoudani A, 2003, IEEE J SEL AREA COMM, V21, P440, DOI 10.1109/JSAC.2003.809724
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Blouw P, 2021, Arxiv, DOI arXiv:2009.04465
   Choi S, 2018, ISSCC DIG TECH PAP I, P220, DOI 10.1109/ISSCC.2018.8310263
   Chong YS, 2022, IEEE T CIRCUITS-II, V69, P1662, DOI 10.1109/TCSII.2021.3113259
   Courbariaux M, 2016, Arxiv, DOI arXiv:1602.02830
   Giraldo JSP, 2021, IEEE T VLSI SYST, V29, P2220, DOI 10.1109/TVLSI.2021.3120189
   Giraldo JSP, 2019, SYMP VLSI CIRCUITS, pC52, DOI 10.23919/VLSIC.2019.8777994
   Gong Y, 2020, IEEE ACCESS, V8, P205878, DOI 10.1109/ACCESS.2020.3037931
   Gupta H, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P498, DOI 10.1109/CONFLUENCE.2016.7508171
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   HERMANSKY H, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P800, DOI 10.1109/ACSSC.1991.186557
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Kepuska V., 2015, J COMPUT COMMUN, V3, P56677, DOI [10.4236/jcc.2015.36001, DOI 10.4236/JCC.2015.36001]
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu B, 2020, IEEE T CIRCUITS-I, V67, P4733, DOI 10.1109/TCSI.2020.2997913
   Miyashita D, 2017, IEEE J SOLID-ST CIRC, V52, P2679, DOI 10.1109/JSSC.2017.2712626
   Paszke A., 2019, ADV NEURAL INFORM PR
   Shan WW, 2021, IEEE J SOLID-ST CIRC, V56, P151, DOI 10.1109/JSSC.2020.3029097
   Song DD, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE 2018), P306, DOI 10.1109/ICISCE.2018.00071
   Sorensen PM, 2020, EURASIP J AUDIO SPEE, V2020, DOI 10.1186/s13636-020-00176-2
   Warden P, 2018, Arxiv, DOI arXiv:1804.03209
   Xiang LP, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS AND MICROSYSTEMS (ICICM 2019), P195, DOI [10.1109/icicm48536.2019.8977176, 10.1109/ICICM48536.2019.8977176]
   Yang L, 2019, PR GR LAK SYMP VLSI, P347, DOI 10.1145/3299874.3318034
   Zhang YD, 2018, Arxiv, DOI [arXiv:1711.07128, DOI 10.48550/ARXIV.1711.07128]
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
   Zhu LX, 2021, PROC EUR SOLID-STATE, P99, DOI 10.1109/ESSCIRC53450.2021.9567770
NR 28
TC 1
Z9 1
U1 1
U2 1
PD JUN
PY 2023
VL 23
IS 12
AR 5701
DI 10.3390/s23125701
UT WOS:001021106700001
DA 2023-11-16
ER

PT C
AU Gondimalla, A
   Chesnut, N
   Thottethodi, M
   Vijaykumar, TN
AF Gondimalla, Ashish
   Chesnut, Noah
   Thottethodi, Mithuna
   Vijaykumar, T. N.
GP Assoc Comp Machinery
TI SparTen: A Sparse Tensor Accelerator for Convolutional Neural Networks
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE Convolutional neural networks; Sparse tensors; Accelerators
AB Convolutional neural networks (CNNs) are emerging as powerful tools for image processing. Recent machine learning work has reduced CNNs' compute and data volumes by exploiting the naturally-occurring and actively-transformed zeros in the feature maps and filters. While previous semi-sparse architectures exploit one-sided sparsity either in the feature maps or the filters, but not both, a recent fully-sparse architecture, called Sparse CNN (SCNN), exploits two-sided sparsity to improve performance and energy over dense architectures. However, sparse vector-vector dot product, a key primitive in sparse CNNs, would be inefficient using the representation adopted by SCNN. The dot product requires finding and accessing non-zero elements in matching positions in the two sparse vectors - an inner join using the position as the key with a single value field. SCNN avoids the inner join by performing a Cartesian product capturing the relevant multiplications. However, SCNN's approach incurs several considerable overheads and is not applicable to non-unit-stride convolutions. Further, exploiting reuse in sparse CNNs fundamentally causes systematic load imbalance not addressed by SCNN. We propose SparTen which achieves efficient inner join by providing support for native two-sided sparse execution and memory storage. To tackle load imbalance, SparTen employs a software scheme, called greedy balancing, which groups filters by density via two variants, a software-only one which uses whole-filter density and a software-hardware hybrid which uses finer-grain density. Our simulations show that, on average, SparTen performs 4.7x, 1.8x, and 3x better than a dense architecture, one-sided sparse architecture, and SCNN, respectively. An FPGA implementation shows that SparTen performs 4.3x and 1.9x better than a dense architecture and a one-sided sparse architecture, respectively.
C1 [Gondimalla, Ashish; Thottethodi, Mithuna; Vijaykumar, T. N.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Gondimalla, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM agondima@purdue.edu; noachesnut11@gmail.com; mithuna@purdue.edu;
   vijay@ecn.purdue.edu
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M, 2016, INT SYMP MICROARCH
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 1965, MATH THEORY CONNECTI
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2016, ICLR
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   CLOS C, 1953, AT&T TECH J, V32, P406, DOI 10.1002/j.1538-7305.1953.tb01433.x
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farrell JA, 1998, IEEE J SOLID-ST CIRC, V33, P707, DOI 10.1109/4.668985
   Gibbs N. E., 1976, ACM Transactions on Mathematical Software, V2, P322, DOI 10.1145/355705.355707
   Gokhale V., 2017, 2017 IEEE INT S CIRC, P1, DOI [10.1109/ISCAS.2017.8050809, DOI 10.1109/ISCAS.2017.8050809]
   Han S., 2015, C NEUR INF PROC SYST
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2015, INDIAN J CHEM B
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd  P., 2018, ABS180303688 CORR
   Kim DH, 2016, INT J ADV MANUF TECH, V85, P1825, DOI 10.1007/s00170-015-8014-1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kung H. T., 2018, ABS181104770 CORR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lin YC, 2005, J PARALLEL DISTR COM, V65, P1585, DOI 10.1016/j.jpdc.2005.05.017
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Mahmoud M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P134, DOI 10.1109/MICRO.2018.00020
   Muralimanohar Naveen, 2009, S Q J MODERN FOREIGN
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Russakovsky O., 2014, IJCV
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Stine JE, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MICROELECTRONIC SYSTEMS EDUCATION, PROCEEDINGS, P173, DOI 10.1109/MSE.2007.44
   Tao J, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P23, DOI 10.1109/CompComm.2017.8322508
   Thottethodi M., 2019, WHY GPGPU IS LESS EF
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhuo Ling, 2005, P 2005 ACMSIGDA 13 I, P63
NR 44
TC 108
Z9 111
U1 1
U2 15
PY 2019
BP 151
EP 165
DI 10.1145/3352460.3358291
UT WOS:000519057400012
DA 2023-11-16
ER

PT C
AU Das, SK
   Sudhakaran, G
   Ashok, V
AF Das, Soumen Kumar
   Sudhakaran, G.
   Ashok, V.
BE Jana, D
   Pal, P
TI Learning Based Performance and Power Efficient Cluster Resource Manager
   for CPU-GPU Cluster
SO 2014 FOURTH INTERNATIONAL CONFERENCE OF EMERGING APPLICATIONS OF
   INFORMATION TECHNOLOGY (EAIT)
SE Proceedings International Conference on Emerging Applications of
   Information Technology (EAIT)
DT Proceedings Paper
CT Fourth International Conference on Emerging Applications of Information
   Technology
CY DEC 19-21, 2014
CL Indian Stat Inst, Kolkata, INDIA
HO Indian Stat Inst
DE High performance Cluster; CRM; Moldable Scheduler; Collocation; Resource
   Manager; petascale; green computing
AB The recent success in building petascale High Performance Computing (HPC) systems have produced the demand for efficient and optimized use of resources to increase the performance and reduce the power consumption. Including the above, the heterogeneous architectures of nowadays HPCs comprising a multicore CPU and many-core Accelerator like GPU(s) are facing another concern for using optimum utilization of each of these components. This paper presents the scheduling mechanism of the Cluster Resource Manager (CRM): i. Moldable job Scheduler (MS) which is able to mold the jobs with respect to the number of machines based on an preliminary initialized and auto updated heuristic knowledge-base of problem size, optimum machine count, execution duration to increase the utilization of the full cluster facility. ii) Collocation Aware and Power Efficient Resource Manager (CAPE-RM) manages collocation of CPU only and GPU accelerated jobs by monitoring the CPU load and memory usage. The emerging computation ability is followed by the huge amount of power consumption. Though the use of GPU(s) itself cut down the power to be needed by the only CPU based cluster but to make a green computing facility more power efficiency is desired. The CAPE-RM is designed to support the above by powering off the idle nodes by monitoring the total load to the facility and based on a simple statistic of the frequency of job submission.
C1 [Das, Soumen Kumar; Sudhakaran, G.; Ashok, V.] ISRO, Vikram Sarabhai Space Ctr, Govt India, Dept Space, Trivandrum, Kerala, India.
RP Das, SK (corresponding author), ISRO, Vikram Sarabhai Space Ctr, Govt India, Dept Space, Trivandrum, Kerala, India.
CR [Anonymous], P 18 S OP SYST PRINC
   [Anonymous], 2009, CLUSTER 09, DOI DOI 10.1109/CLUSTR.2009.5289193
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   Cirne W, 2002, J PARALLEL DISTR COM, V62, P1571, DOI 10.1006/jpdc.2002.1869
   Diamos G, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P353, DOI 10.1145/1854273.1854318
   Diamos Gregory F., 2008, P 17 INT S HIGH PERF, P197, DOI DOI 10.1145/1383422.1383447
   Dusseau A. C., 1996, Performance Evaluation Review, V24, P25, DOI 10.1145/233008.233020
   Feitelson DG, 2005, LECT NOTES COMPUT SC, V3277, P1
   Freund R. F. t., 1998, P 7 HET COMP WORKSH, P3
   Furlinger K., 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, P1377, DOI 10.1109/IPDPS.2011.289
   Hong CT, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P217, DOI 10.1145/1854273.1854303
   Kerr A., 2010, P 3 WORKSH GEN PURP, P31, DOI DOI 10.1145/1735688.1735696
   Maheswaran M, 1999, PROC HETER COMP WORK, P30, DOI 10.1109/HCW.1999.765094
   Naik V. K., 1993, Proceedings SUPERCOMPUTING '93, P824, DOI 10.1145/169627.169848
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Pinheiro E, 2003, COMPILERS AND OPERATING SYSTEMS FOR LOW POWER, P75
   Ravi Vignesh T., 2010, 24th ACM International Conference on Supercomputing 2010, P137
   Sabin G, 2005, 14th IEEE International Symposium on High Performance Distributed Computing, Proceedings, P144
   Sabin G, 2003, LECT NOTES COMPUT SC, V2862, P87
   Srinivasan S, 2002, LECT NOTES COMPUT SC, V2552, P174
   Sudhakaran, 2012, P ATIP A CRC WORKSH, P117
NR 21
TC 1
Z9 2
U1 0
U2 0
PY 2014
BP 161
EP 166
DI 10.1109/EAIT.2014.58
UT WOS:000380436200026
DA 2023-11-16
ER

PT J
AU Di Castro, M
   Ferre, M
   Masi, A
AF Di Castro, Mario
   Ferre, Manuel
   Masi, Alessandro
TI CERNTAURO: A Modular Architecture for Robotic Inspection and
   Telemanipulation in Harsh and Semi-Structured Environments
SO IEEE ACCESS
DT Article
DE Mobile robots; robot control; robot learning; robot sensing systems;
   robot vision system; telerobotics; human-robot interaction; intelligent
   systems; Internet of Things
ID BILATERAL TELEOPERATION; MOBILE MANIPULATION; SYSTEMS; TRANSPARENCY;
   STABILITY; OIL
AB Intelligent robotic systems are becoming essential for industries, nuclear plants, and for harsh environments in general, such as the European Organization for Nuclear Research (CERN) particles accelerator complex and experiments. In order to increase safety and machine availability, robots can perform repetitive, unplanned, and dangerous tasks, which humans either prefer to avoid or are unable to carry out due to hazards, size constraints, or the extreme environments in which they take place. Anovel robotic framework for autonomous inspections and supervised teleoperations in harsh environments is presented. The proposed framework covers all aspects of a robotic intervention, from the specification and operator training, the choice of the robot and its material in accordance with possible radiological contamination risks, to the realization of the intervention, including procedures and recovery scenarios. The robotic solution proposed in this paper is able to navigate autonomously, inspecting unknown environments in a safe way. A new real-time control system was implemented in order to guarantee a fast response to environmental changes and adaptation to different type of scenarios the robot may find in a semi-structured and hazardous environment. Components of the presented framework are: a novel bilateral master-slave control, a new robotic platform named CERNbot, and an advanced user-friendly multimodal human-robot interface, also used for the operators' offline training, allowing technicians not expert in robot operation to perform inspection/maintenance tasks. The proposed system has been tested and validated with real robotic interventions in the CERN hazardous particle accelerator complex.
C1 [Di Castro, Mario; Masi, Alessandro] CERN, European Org Nucl Res, CH-1211 Geneva, Switzerland.
   [Di Castro, Mario; Ferre, Manuel] Univ Politecn Madrid, CSIC, CAR, E-28006 Madrid, Spain.
RP Di Castro, M (corresponding author), CERN, European Org Nucl Res, CH-1211 Geneva, Switzerland.; Di Castro, M (corresponding author), Univ Politecn Madrid, CSIC, CAR, E-28006 Madrid, Spain.
EM mario.di.castro@cern.ch
CR Abadi M., 2016, P OSDI, V16, P1
   Altarelli M., 2006, TECH REP, P1, DOI DOI 10.1080/08940880601064968
   [Anonymous], 2014, HDB UNMANNED AERIAL
   [Anonymous], 2004, 35 INT S ROB PAR FRA
   [Anonymous], 2014, P IEEE NETW OP MAN S
   [Anonymous], 2016, 4 IND REVOLUTION
   [Anonymous], 2008, SPRINGER HDB ROBOTIC, DOI DOI 10.1007/978-3-540-30301-5
   Asaro PM, 2013, SOC SEMIOT, V23, P196, DOI 10.1080/10350330.2013.777591
   Bajracharya M, 2008, COMPUTER, V41, P44, DOI 10.1109/MC.2008.479
   Balta H., 2014, TECH REP
   Bicchi A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P348, DOI 10.1109/ROBOT.2000.844081
   Buckingham R., 2017, NATURE PHYS, V12, P391
   BUTTERWORTH GJ, 1989, FUSION ENG DES, V11, P231, DOI 10.1016/0920-3796(89)90021-5
   Callam A., 2015, INT AFFAIRS REV, V18
   Chao A, 2013, HDB ACCELERATOR PHYS
   Chen JYC, 2010, ERGONOMICS, V53, P940, DOI 10.1080/00140139.2010.500404
   Chitta S, 2012, IEEE ROBOT AUTOM MAG, V19, P58, DOI 10.1109/MRA.2012.2191995
   Cho Y, 2017, INT J HUM ROBOT, V14, DOI 10.1142/S0219843617500128
   Claeys C., 2013, RAD EFFECTS ADV SEMI, V57
   Cutkosky M. R., 2012, ROBOTIC GRASPING FIN, V6
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   de Cubber Geert, 2014, Applied Mechanics and Materials, V658, P599, DOI 10.4028/www.scientific.net/AMM.658.599
   De Novi G, 2010, IEEE AERO EL SYS MAG, V25, P32, DOI 10.1109/MAES.2010.5638803
   Di Castro M., 2018, P ICALEPCS, P1507
   Di Castro M., 2018, P 16 INT C AC LARG E, P709
   Di Castro M., P 3 INT C MECH ROB E, P6
   Di Castro M., 2014, IMEKO
   di Castro M, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 2, P50, DOI 10.5220/0006426700500055
   Dingus M.L., 1997, U.S. Patent, Patent No. [5 670469, 5670469]
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381
   Drake B. G., 2010, AER C 2010 IEEE, P1, DOI DOI 10.1109/AERO.2010.5446736
   Draper J.V., 1987, P INT TOP M ROB REM
   Ducimetiere L., 1995, Digest of Technical Papers. Tenth IEEE International Pulsed Power Conference (Cat. No.95CH35833), P1406, DOI 10.1109/PPC.1995.599814
   Feron E., 2008, SPRINGER HDB ROBOTIC, P1009
   Ferre M., 2007, ADV TELEROBOTICS, V31
   Friconneau JP, 2017, FUSION ENG DES, V124, P673, DOI 10.1016/j.fusengdes.2017.01.005
   Garage W., 2010, WILLOW GARAGE
   Goertz R.C., 1964, P 12 REM SYST TECHN, V12, P123
   García-Valdovinos LG, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/56810
   Guiochet J, 2017, ROBOT AUTON SYST, V94, P43, DOI 10.1016/j.robot.2017.04.004
   Gutierrez-Giles A., 2017, INT J CONTROL, P1
   Haddadi A, 2015, IEEE-ASME T MECH, V20, P2463, DOI 10.1109/TMECH.2014.2385637
   Hainsworth DW, 2001, AUTON ROBOT, V11, P19, DOI 10.1023/A:1011299910904
   Hashtrudi-Zaad K, 2002, IEEE T ROBOTIC AUTOM, V18, P108, DOI 10.1109/70.988981
   Hashtrudi-Zaad K, 2001, INT J ROBOT RES, V20, P419, DOI 10.1177/02783640122067471
   Helms E, 2002, IEEE ROMAN 2002, PROCEEDINGS, P399, DOI 10.1109/ROMAN.2002.1045655
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hoddeson L., 2009, AM J PHYS, V77, P671
   Hokayem PF, 2006, AUTOMATICA, V42, P2035, DOI 10.1016/j.automatica.2006.06.027
   HVILSHJ M, 2009, IEEE C EM TECHN FACT, P1
   Hvilshoj M, 2012, IND ROBOT, V39, P120, DOI 10.1108/01439911211201582
   Iida W, 2004, 8TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, PROCEEDINGS, P217, DOI 10.1109/AMC.2004.1297669
   Irizarry J, 2012, J INF TECHNOL CONSTR, V17, P194
   Jerald Jason, 2014, 2014 IEEE Virtual Reality (VR), P1, DOI 10.1109/VR.2014.6802117
   Joseph L., 2015, MASTERING ROS ROBOTI
   Kellerbauer A, 2008, NUCL INSTRUM METH B, V266, P351, DOI 10.1016/j.nimb.2007.12.010
   Khatib O., 2008, SPRINGER HDB ROBOTIC, P1127, DOI [10.1007/978-3-540-30301-5_50, DOI 10.1007/978-3-540-30301-5_50]
   Kostavelis I., 2017, LECT NOTES BUSINESS, V4, P43
   Langley KF, 2001, NUCL ENERG-J BR NUCL, V40, P189, DOI 10.1680/nuen.40.3.189.40068
   LAWRENCE DA, 1993, IEEE T ROBOTIC AUTOM, V9, P624, DOI 10.1109/70.258054
   Lefevre C., 2008, CERNDI0812015
   Leonard JJ, 2016, SPRINGER HANDBOOK OF OCEAN ENGINEERING, P341
   Lozano-Perez T., 2012, AUTONOMOUS ROBOT VEH
   Lunghi G., 2016, P 13 INT C INF CONTR, P1
   Lunghi G, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 2, P233, DOI 10.5220/0006395802330238
   Manion W.J., 1980, DOEEV101281 NUCL EN
   Manley J., 2008, OCEANS 2008 S, P1
   Marcastel F., 2013, OPENPHOCHART2013001
   Matolak DW, 2015, IEEE VEH TECHNOL MAG, V10, P79, DOI 10.1109/MVT.2015.2411191
   Meyer J-A., 2003, COGN SYST RES, V4, P283, DOI [DOI 10.1016/S1389-0417(03)00007-X, 10.1016/S1389-0417(03)00007-X]
   Murray J.W., 2017, BUILDING VIRTUAL REA
   NIEMEYER G, 1991, IEEE J OCEANIC ENG, V16, P152, DOI 10.1109/48.64895
   Özyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X
   Pedersen L., 2003, 20030054507 NASA
   Peer A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2350, DOI 10.1109/IROS.2008.4650582
   Pryor M., 2017, P 43 WAST MAN C, P4855
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Rombach M.P., 2014, SIAM J APPL MATH, V59, P619
   Rosheim M.E., 1994, ROBOT EVOLUTION DEV
   Rossi Maurizio, 2014, IEEE Sensors 2014. Proceedings, P1431, DOI 10.1109/ICSENS.2014.6985282
   Schuler J., 2013, INTEGRATION FORDER H, V104
   Sharkey N., 2011, LAW INNOVATION TECHN, V3, P229, DOI [10.5235/175799611798204914, DOI 10.5235/175799611798204914]
   Sheridan TB., 1992, TELEROBOTICS AUTOMAT
   Shukla A, 2016, ROBOT AUTON SYST, V75, P508, DOI 10.1016/j.robot.2015.09.013
   Shukla A, 2016, ROBOT AUTON SYST, V75, P490, DOI 10.1016/j.robot.2015.09.012
   Silv e rio J., 2017, LEARNING DEMONSTRATI
   Springer Paul., 2013, MILITARY ROBOTS DRON
   Suzuki A, 2013, IEEE T IND ELECTRON, V60, P177, DOI 10.1109/TIE.2012.2183832
   TAPAS, ROB EN LOG ASS SERV
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Tian GS, 2008, IEEE INT C ENG COMP, P69, DOI 10.1109/ICECCS.2008.39
   VALERI, VAL ADV COLL ROB IND
   Wild G, 2016, AEROSPACE, V3, DOI 10.3390/aerospace3030022
   Wu Y., 2017, P IEEE INFOCOM 2017, P1, DOI DOI 10.1007/978-981-10-3066-6_1
   Yim M, 2003, AUTON ROBOT, V14, P225, DOI 10.1023/A:1022287820808
   Yoshida K, 2009, IEEE ROBOT AUTOM MAG, V16, P20, DOI 10.1109/MRA.2009.934818
   Yoshida Tomoaki, 2014, FIELD SERVICE ROBOTI
NR 97
TC 34
Z9 34
U1 2
U2 13
PY 2018
VL 6
BP 37506
EP 37522
DI 10.1109/ACCESS.2018.2849572
UT WOS:000439698700084
DA 2023-11-16
ER

PT C
AU Xing, Y
   Lu, HX
   Gupta, A
   Malik, S
AF Xing, Yue
   Lu, Huaixi
   Gupta, Aarti
   Malik, Sharad
GP IEEE
TI Compositional Verification Using a Formal Component and Interface
   Specification
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
ID REASONING FRAMEWORK
AB Property-based specification such as SystemVerilog Assertions (SVA) uses mathematical logic to specify the temporal behavior of RTL designs which can then be formally verified using model checking algorithms. These properties are specified for a single component (which may contain other components in the design hierarchy). Composing design components that have already been verified r equires a dditional v erification since incorrect communication at their interface may invalidate the properties that have been checked for the individual components. This paper focuses on a specification f or t heir i nterface which can be checked individually for each component, and which guarantees that refinement-based p roperties c hecked f or each component continue to hold after their composition. We do this in the setting of the Instruction-level Abstraction (ILA) specification and verification methodology. The ILA methodology p rovides a uniform specification for processors, accelerators a nd general modules at the instruction-level, and the automatic generation of a complete set of correctness properties for checking that the RTL model is a refinement o f t he ILA s pecification. We add an interface specification to model the inter-ILA communication. Further, we use our interface specification to generate a s et of interface checking properties that check that the communication between the RTL components is correct. This provides the following guarantee: if each RTL component is a refinement of its ILA specification and the interface checks pass, then the RTL composition is a refinement o f t he I LA composition. We have applied the proposed methodology to six case studies including parts of large-scale designs such as parts of the FlexASR and NVDLA machine learning accelerators, demonstrating the practical applicability of our method.
C1 [Xing, Yue; Lu, Huaixi; Gupta, Aarti; Malik, Sharad] Princeton Univ, Princeton, NJ 08544 USA.
RP Xing, Y (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.
EM yuex@princeton.edu; huaixil@princeton.edu; aartig@cs.princeton.edu;
   sharad@princeton.edu
CR [Anonymous], 1985, LOGICS MODELS CONCUR, DOI [DOI 10.1007/978-3-642-82453-1_5, 10.1007/978-3-642-82453-1\5]
   Bourgeat T, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P243, DOI 10.1145/3385412.3385965
   Burch J. R., 1994, CAV
   Cadence Design Systems Inc., 2018, JASPERGOLD FORM PROP
   Cerny E., 2015, SVA POWER ASSERTIONS
   Choi J, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3110268
   Chou CT, 2004, LECT NOTES COMPUT SC, V3312, P382
   Christensen M, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P175, DOI 10.1145/3453483.3454037
   Clarke E. M., 2018, MODEL CHECKING
   de Alfaro L., 2001, Software Engineering Notes, V26, P109, DOI 10.1145/503271.503226
   De Alfaro Luca, 2001, EMSOFT 01, P148
   Giannakopoulou D., 2018, HDB MODEL CHECKING, P345, DOI 10.1007/978-3-319-10575-812
   Huang BY, 2019, LECT NOTES COMPUT SC, V11427, P351, DOI 10.1007/978-3-030-17462-0_21
   Huang BY, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3282444
   IEEE-Commission, 2005, 18502005 IEEE
   Jhala R, 2001, LECT NOTES COMPUT SC, V2102, P396
   Manolios P, 2005, IEEE IC CAD, P863, DOI 10.1109/ICCAD.2005.1560183
   Manolios P, 2008, IEEE T VLSI SYST, V16, P353, DOI 10.1109/TVLSI.2008.918120
   Mattarei C, 2018, PROCEEDINGS OF THE 2018 18TH CONFERENCE ON FORMAL METHODS IN COMPUTER AIDED DESIGN (FMCAD), P7
   McMillan KL, 1997, LECT NOTES COMPUT SC, V1254, P24
   Namjoshi KS, 2016, LECT NOTES COMPUT SC, V9636, P589, DOI 10.1007/978-3-662-49674-9_39
   Nikhil R, 2004, Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, Proceedings, P69
   NVIDIA, 2018, NVIDIA DEEP LEARN AC
   Olofsson A., 2016, EPIPHANY ELINK AXI
   Panda PR, 2001, ISSS'01: 14TH INTERNATIONAL SYMPOSIUM ON SYSTEM SYNTHESIS, P75, DOI 10.1109/ISSS.2001.957916
   Pnueli A., 1977, 18th Annual Symposium on Foundations of Computer Science, P46, DOI 10.1109/SFCS.1977.32
   Reid A, 2016, LECT NOTES COMPUT SC, V9780, P42, DOI 10.1007/978-3-319-41540-6_3
   Rose A., 2005, OPEN SYSTEMC INITIAT, P297
   Subramanyan P, 2015, PROCEEDINGS OF THE 15TH CONFERENCE ON FORMAL METHODS IN COMPUTER-AIDED DESIGN (FMCAD 2015), P160, DOI 10.1109/FMCAD.2015.7542266
   Talupur M, 2008, 2008 FORMAL METHODS IN COMPUTER-AIDED DESIGN, P69
   Tambe T, 2021, ISSCC DIG TECH PAP I, V64, P158, DOI 10.1109/ISSCC42613.2021.9366062
   Taylor MB, 2018, DES AUT CON, DOI 10.1145/3195970.3199848
   Teran S., 2016, 8051 MICROCONTROLLER
   Wright A. C., 2021, THESIS MIT
   Xilinx, 2019, VIVADO DESIGN SUITE
   Xing Y., 2021, DESIGN AUTOMATION TE
NR 36
TC 0
Z9 0
U1 2
U2 2
PY 2022
DI 10.1145/3508352.3549341
UT WOS:000981574300071
DA 2023-11-16
ER

PT C
AU Liao, HH
   Elmohr, MA
   Dong, X
   Qian, YJ
   Yang, WZ
   Shang, ZW
   Tan, Y
AF Liao, Haohao
   Elmohr, Mahmoud A.
   Dong, Xuan
   Qian, Yanjun
   Yang, Wenzhe
   Shang, Zhiwei
   Tan, Yin
GP IEEE
TI TurboHE: Accelerating Fully Homomorphic Encryption Using FPGA Clusters
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM,
   IPDPS
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
DE Fully homomorphic encryption; CKKS; NTT; FPGA Cluster; Hardware
   acceleration
AB With the burgeoning demands for cloud computing in various fields followed by the rising attention to sensitive data exposure, Fully Homomorphic Encryption (FHE) is gaining popularity as a potential solution to privacy protection. By performing computations directly on the ciphertext (encrypted data) without decrypting it, FHE can guarantee the security of data throughout its lifecycle without compromising the privacy. However, the excruciatingly slow speed of FHE scheme makes adopting it impractical in real life applications. Therefore, hardware accelerators come to the rescue to mitigate the problem. Among various hardware platforms, FPGA clusters are particularly promising because of their flexibility and ready availability at many cloud providers such as FPGA-as-a-Service (FaaS). Hence, reusing the existing infrastructure can greatly facilitate the implementation of FHE on the cloud. In this paper, we present TurboHE, the first hardware accelerator for FHE operations based on an FPGA cluster. TurboHE aims to boost the performance of CKKS, one of the fastest FHE schemes which is most suitable to machine learning applications, by accelerating its computationally intensive and frequently used operation: relinearization. The proposed scalable architecture based on hardware partitioning can be easily configured to accommodate high acceleration requirements for relinearization with very large CKKS parameters. As a demonstration, an implementation, which supports 32,768 polynomial coefficients and a coefficient bitwidth of 594 decomposed into 11 Residue Number System (RNS) components, was deployed on a cluster consisting of 9 Xilinx VU13P FPGAs. The cluster operated at 200 MHz and achieved 1096 times throughput compared with a single threaded CPU implementation. Moreover, the low level hardware components implemented in this work such as the NTT module can also be applied to accelerate other lattice-based cryptography schemes.
C1 [Liao, Haohao; Elmohr, Mahmoud A.; Dong, Xuan; Qian, Yanjun; Yang, Wenzhe; Shang, Zhiwei; Tan, Yin] Huawei Technol Canada, Markham, ON, Canada.
RP Liao, HH (corresponding author), Huawei Technol Canada, Markham, ON, Canada.
EM haohao.liao1@huawei.com; mahmoud.elmohr1@huawei.com;
   xuan.dong2@huawei.com; yanjun.qian1@huawei.com; wenzhe.yang@huawei.com;
   zhiwei.shang1@huawei.com; yin.tan@huawei.com
CR Almorsy Mohamed, 2016, ARXIV
   [Anonymous], 2012, IEEE C HIGH PERFORMA, DOI [10.1109/HPEC.2012.6408660, DOI 10.1109/PEAM.2012.6612493]
   Bobda C, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3506713
   Boemer Fabian, 2021, WAHC '21: Proceedings of the 9th on Workshop on Encrypted Computing & Applied Homomorphic Cryptography, P57, DOI 10.1145/3474366.3486926
   Chen H, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0397-z
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   confidentialcomputing, 2021, TECHN AN CONF COMP
   Gentry C, 2009, FULLY HOMOMORPHIC EN
   Gentry C, 2011, LECT NOTES COMPUT SC, V6632, P129, DOI 10.1007/978-3-642-20465-4_9
   github, 2022, MICR SEAL REL 4 0
   Hashizume K, 2013, J INTERNET SERV APPL, V4, DOI 10.1186/1869-0238-4-5
   Jung Hee Cheon, 2019, Selected Areas in Cryptography - SAC 2018. 25th International Conference. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11349), P347, DOI 10.1007/978-3-030-10970-7_16
   Jung W., 2021, IACR T CRYPTOGRAPH H, P114, DOI DOI 10.46586/TCHES.V2021.I4.114
   Lauter K, 2011, PROCEEDINGS OF THE 3RD ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'11), P113
   Longa P, 2016, LECT NOTES COMPUT SC, V10052, P124, DOI 10.1007/978-3-319-48965-0_8
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Morshed T, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P142, DOI [10.1109/host45689.2020.9300288, 10.1109/HOST45689.2020.9300288]
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Samardzic N, 2022, CONF PROC INT SYMP C, P173, DOI 10.1145/3470496.3527393
   Samardzic Nikola, 2021, MICRO54, P238, DOI 10.1145/3466752
   Tarafdar N., 2021, ACM T RECONFIG TECHN, V15, P1
   Turan F, 2020, IEEE T COMPUT, V69, P1185, DOI 10.1109/TC.2020.2988765
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
NR 24
TC 0
Z9 0
U1 3
U2 3
PY 2023
BP 788
EP 797
DI 10.1109/IPDPS54959.2023.00084
UT WOS:001035517300075
DA 2023-11-16
ER

PT C
AU Ravi, J
   Byna, S
   Koziol, Q
AF Ravi, John
   Byna, Suren
   Koziol, Quincey
GP IEEE Comp Soc
TI GPU Direct I/O with HDF5
SO PROCEEDINGS OF 2020 IEEE/ACM FIFTH INTERNATIONAL PARALLEL DATA SYSTEMS
   WORKSHOP (PDSW 2020)
DT Proceedings Paper
CT IEEE/ACM 5th International Parallel Data Systems Workshop (PDSW)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE GPU I/O; NVIDIA GPUDirect Storage (GDS); HDF5 GDS Virtual File Driver
   (VFD)
AB Exascale HPC systems are being designed with accelerators, such as GPUs, to accelerate parts of applications. In machine learning workloads as well as large-scale simulations that use GPUs as accelerators, the CPU (or host) memory is currently used as a buffer for data transfers between GPU (or device) memory and the file system. If the CPU does not need to operate on the data, then this is sub-optimal because it wastes host memory by reserving space for duplicated data. Furthermore, this "bounce buffer" approach wastes CPU cycles spent on transferring data. A new technique, NVIDIA GPUDirect Storage (GDS), can eliminate the need to use the host memory as a bounce buffer. Thereby, it becomes possible to transfer data directly between the device memory and the file system. This direct data path shortens latency by omitting the extra copy and enables higher-bandwidth. To take full advantage of GDS in existing applications, it is necessary to provide support with existing I/O libraries, such as HDF5 and MPI-IO, which are heavily used in applications.
   In this paper, we describe our effort of integrating GDS with HDF5, the top I/O library at NERSC and at DOE leadership computing facilities. We design and implement this integration using a HDF5 Virtual File Driver (VFD). The GDS VFD provides a file system abstraction to the application that allows HDF5 applications to perform I/O without the need to move data between CPUs and GPUs explicitly. We compare performance of the HDF5 GDS VFD with explicit data movement approaches and demonstrate superior performance with the GDS method.
C1 [Ravi, John] North Carolina State Univ, Raleigh, NC 27695 USA.
   [Byna, Suren; Koziol, Quincey] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
RP Ravi, J (corresponding author), North Carolina State Univ, Raleigh, NC 27695 USA.
EM jjravi@ncsu.edu; sbyna@lbl.gov; koziol@lbl.gov
CR Braam P., LUSTRE STORAGE ARCH
   Caswell Hal, 2001, pi
   Folk M., 2011, P EDBT ICDT 2011 WOR, P36, DOI DOI 10.1145/1966895.1966900
   Li Jianwei, 2003, P 2003 ACMIEEE C SUP, P39, DOI DOI 10.1109/SC.2003.10053
   Liu Q, 2014, CONCURR COMP-PRACT E, V26, P1453, DOI 10.1002/cpe.3125
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   ROMIO team at ANL, ROMIO HIGH PERF PORT
   Tang H., 2019, PDSW 2019 CONJUNCTIO
   The HDF Group, HDF5
   Walli Stephen R., 1995, STANDARDVIEW, V3, P11
   Zhao Z, AUTOMATIC LIB TRACKI
NR 11
TC 2
Z9 2
U1 0
U2 4
PY 2020
BP 28
EP 33
DI 10.1109/PDSW51947.2020.00010
UT WOS:000674887400005
DA 2023-11-16
ER

PT C
AU Clark, G
   Landis, G
   Barnes, E
   LaFuente, B
   Collins, K
AF Clark, Gilbert
   Landis, Geoffrey
   Barnes, Ethan
   LaFuente, Blake
   Collins, Kristina
GP IEEE
TI Testing a Neural Network Accelerator on a High-Altitude Balloon
SO 2019 IEEE COGNITIVE COMMUNICATIONS FOR AEROSPACE APPLICATIONS WORKSHOP
   (CCAAW)
DT Proceedings Paper
CT IEEE Cognitive Communications for Aerospace Applications Workshop
   (CCAAW)
CY JUN 25-26, 2019
CL Cleveland, OH
DE artificial intelligence; embedded systems; system verification
AB The cognitive communications project has been working to refine artificial intelligence and machine learning approaches to support their deployment and sustained use in space environments. It has historically been difficult to implement such techniques on space platforms, however, due to the computational requirements they levy onto general-purpose avionics hardware. While technologies exist to accelerate the computation of aspects of neural networks, such platforms have not historically been deployed in space environments. Given that testing payloads in such environments can be both cost- and time- prohibitive, high-altitude balloons can be used as a way to approximate a space environment at a much lower cost, thus providing a cost-effective way in which to test newer approaches to hardware acceleration for artificial intelligence which may be deployed onto spacecraft more directly.
   This paper describes a successful test of a commercial off-the-shelf neural network accelerator on a high-altitude balloon. It begins by explaining our selection criteria when evaluating different commercial neural network acceleration techniques: primary considerations include size, weight, and power (SWaP) as well as ease of integration. Next, the paper describes the development and implementation of an experimental flight test platform: flight and ground components are discussed. Afterward, the paper discusses the experimental payload itself: this includes the experimental procedure as well as the specific image and method used for testing. Finally, the paper concludes with an evaluation of both the experimental device tested at altitude as well as the flight test framework itself, identifying how the existing platform can be used to continue testing commercial off-the-shelf (COTS) solutions for acceleration.
C1 [Clark, Gilbert] NASA, Glenn Res Ctr, LCN Branch, Cleveland, OH 44135 USA.
   [Landis, Geoffrey] NASA, Glenn Res Ctr, LEX Branch, Cleveland, OH USA.
   [Barnes, Ethan; LaFuente, Blake; Collins, Kristina] NASA, Glenn Res Ctr, Intern, Cleveland, OH USA.
RP Clark, G (corresponding author), NASA, Glenn Res Ctr, LCN Branch, Cleveland, OH 44135 USA.
EM gilbert.j.clark@nasa.gov; geoffrey.landis@nasa.gov;
   ethancbarnes@gmail.com; blakelafuente@gmail.com;
   kristina.collins@case.edu
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Alawad M, 2018, IEEE T MULTI-SCALE C, V4, P888, DOI 10.1109/TMSCS.2018.2886266
   Amert T, 2017, REAL TIM SYST SYMP P, P104, DOI 10.1109/RTSS.2017.00017
   Ashton K., 2009, RFID J, V22, P97, DOI DOI 10.1145/2967977
   Bonomi F., 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Cavigelli L., 2015, P 25 EDITION GREAT L, P199, DOI [10.1145/2742060.2743766, DOI 10.1145/2742060.2743766]
   Cotton NJ, 2011, IEEE T IND ELECTRON, V58, P733, DOI 10.1109/TIE.2010.2098377
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Mankins JC, 2009, ACTA ASTRONAUT, V65, P1216, DOI 10.1016/j.actaastro.2009.03.058
   Moloney D, 2014, IEEE HOT CHIP SYMP
   Nagasubramanian G, 2001, J APPL ELECTROCHEM, V31, P99, DOI 10.1023/A:1004113825283
   Santoni F., 2002, COMMERCIAL LIION BAT, P502
   Vanhoucke Vincent, 2011, DEEP LEARNING UNSUPE
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1109/ccaaw.2019.8904886
UT WOS:000520123400002
DA 2023-11-16
ER

PT J
AU Amirsoleimani, A
   Alibart, F
   Yon, V
   Xu, JX
   Pazhouhandeh, MR
   Ecoffey, S
   Beilliard, Y
   Genov, R
   Drouin, D
AF Amirsoleimani, Amirali
   Alibart, Fabien
   Yon, Victor
   Xu, Jianxiong
   Pazhouhandeh, M. Reza
   Ecoffey, Serge
   Beilliard, Yann
   Genov, Roman
   Drouin, Dominique
TI In-Memory Vector-Matrix Multiplication in Monolithic Complementary
   Metal-Oxide-Semiconductor-Memristor Integrated Circuits: Design Choices,
   Challenges, and Perspectives
SO ADVANCED INTELLIGENT SYSTEMS
DT Review
DE complementary metal-oxide-semiconductor; inference; in-memory computing;
   memristors; redox-based random access memories; resistive switching
   memories; vector-matrix multiplications
ID RESISTIVE RAM; ENERGY; ACCELERATOR; ACCURACY
AB The low communication bandwidth between memory and processing units in conventional von Neumann machines does not support the requirements of emerging applications that rely extensively on large sets of data. More recent computing paradigms, such as high parallelization and near-memory computing, help alleviate the data communication bottleneck to some extent, but paradigm-shifting concepts are required. In-memory computing has emerged as a prime candidate to eliminate this bottleneck by colocating memory and processing. In this context, resistive switching (RS) memory devices is a key promising choice, due to their unique intrinsic device-level properties, enabling both storing and computing with a small, massively-parallel footprint at low power. Theoretically, this directly translates to a major boost in energy efficiency and computational throughput, but various practical challenges remain. A qualitative and quantitative analysis of several key existing challenges in implementing high-capacity, high-volume RS memories for accelerating the most computationally demanding computation in machine learning (ML) inference, that of vector-matrix multiplication (VMM), is presented. The monolithic integration of RS memories with complementary metal-oxide-semiconductor (CMOS) integrated circuits is presented as the core underlying technology. The key existing design choices in terms of device-level physical implementation, circuit-level design, and system-level considerations is reviewed and an outlook for future directions is provided.
C1 [Amirsoleimani, Amirali; Xu, Jianxiong; Pazhouhandeh, M. Reza; Genov, Roman] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada.
   [Alibart, Fabien; Yon, Victor; Ecoffey, Serge; Beilliard, Yann; Drouin, Dominique] Univ Sherbrooke, Inst Interdisciplinaire Innovat Technol 3IT, Sherbrooke, PQ J1K 0A5, Canada.
   [Alibart, Fabien; Yon, Victor; Ecoffey, Serge; Beilliard, Yann; Drouin, Dominique] CNRS UMI 3463 3IT, Lab Nanotechnol Nanosyst LN2, Sherbrooke, PQ J1K 0A5, Canada.
   [Alibart, Fabien] Univ Lille, Inst Elect Microelect & Nanotechnol IEMN, F-59650 Villeneuve Dascq, France.
RP Amirsoleimani, A (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada.; Alibart, F (corresponding author), Univ Sherbrooke, Inst Interdisciplinaire Innovat Technol 3IT, Sherbrooke, PQ J1K 0A5, Canada.; Alibart, F (corresponding author), CNRS UMI 3463 3IT, Lab Nanotechnol Nanosyst LN2, Sherbrooke, PQ J1K 0A5, Canada.; Alibart, F (corresponding author), Univ Lille, Inst Elect Microelect & Nanotechnol IEMN, F-59650 Villeneuve Dascq, France.
EM amirali.amirsoleimani@utoronto.ca; fabien.alibart@usherbrooke.ca
CR Adam G.C., 2018, NAT COMMUN, V9, P1
   Adam GC, 2017, IEEE T ELECTRON DEV, V64, P312, DOI 10.1109/TED.2016.2630925
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ambrogio S, 2014, IEEE T ELECTRON DEV, V61, P2920, DOI 10.1109/TED.2014.2330202
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 1996, P SUPERCOMPUTING
   [Anonymous], 2018, 2018 IEEE INT EL DEV
   Armasu L., 2018, MOVE GPUS STARTUPS C
   Azghadi MR, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900189
   Bavandpour M., 2019, ARXIV PREPRINT ARXIV
   Bavandpour M., 2020, IEEE J EXPL SOL STAT
   Bavandpour M., 2019, IEEE T VERY LARGE SC
   Bavandpour M, 2019, IEEE T CIRCUITS-II, V66, P1512, DOI 10.1109/TCSII.2019.2891688
   Bayat FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04482-4
   Bocquet M, 2018, INT EL DEVICES MEET
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai F., 2019, ARXIV PREPRINT ARXIV
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Carusone TC, 2011, ANALOG INTEGR CIRC S
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WH, 2019, NAT ELECTRON, V2, P420, DOI 10.1038/s41928-019-0288-0
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi S, 2017, NANO LETT, V17, P3113, DOI 10.1021/acs.nanolett.7b00552
   Choi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10492
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Cutress I., 2018, CAMBRICON MAKER HAUW
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   DeBole MV, 2019, COMPUTER, V52, P20, DOI 10.1109/MC.2019.2903009
   Dozortsev A, 2018, INT J CIRC THEOR APP, V46, P122, DOI 10.1002/cta.2399
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Eleftheriou E, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947008
   Eryilmaz SB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00205
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fang Su, 2017, 2017 Symposium on VLSI Technology, pT260, DOI 10.23919/VLSIT.2017.7998149
   Fantini A, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P30, DOI 10.1109/IMW.2013.6582090
   Fantini A., 2015, 2015 IEEE INT EL DEV
   Gao LG, 2016, IEEE T ELECTRON DEV, V63, P3109, DOI 10.1109/TED.2016.2578720
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gong YP, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3290405
   Google, 2019, EDG TPU GOOGL PURP B
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Gupta I, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12805
   Haj-Ali A, 2018, IEEE T CIRCUITS-I, V65, P4258, DOI 10.1109/TCSI.2018.2846699
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harpe P, 2016, IEEE J SOLID-ST CIRC, V51, P240, DOI 10.1109/JSSC.2015.2487270
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Hastings A., 2001, ART ANALOG LAYOUT
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hruska J, 2017, NEW MOVIDIUS MYRIAD
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu SG, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8522
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jiang H, 2018, NAT ELECTRON, V1, P548, DOI 10.1038/s41928-018-0146-5
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KARABUTSA A, 1962, DOKL AKAD NAUK SSSR+, V145, P293
   Kavehei O, 2013, NANOSCALE, V5, P5119, DOI 10.1039/c3nr00535f
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Lim KY, 2010, INT EL DEVICES MEET
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   LIU D, 2015, ACM SIGARCH COMPUT A, V43, P369, DOI DOI 10.1145/2786763.2694358
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Liu SJ, 2018, IEEE CIRC SYST MAG, V18, P29, DOI 10.1109/MCAS.2017.2785421
   Mahmood M, 2019, INT BHURBAN C APPL S, P30, DOI [10.1109/IBCAST.2019.8667140, 10.1109/iedm19573.2019.8993618]
   Mahmoodi MR, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13103-7
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Merritt R., 2019, STARTUP ACCELERATES
   Midya R, 2019, ADV INTELL SYST-GER, V1, DOI 10.1002/aisy.201900084
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Moon J, 2019, NAT ELECTRON, V2, P480, DOI 10.1038/s41928-019-0313-3
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moore GE, 1998, P IEEE, V86, P82, DOI 10.1109/JPROC.1998.658762
   Murmann B., 2020, ADC PERFORMANCE SURV
   Mutlu O, 2019, MICROPROCESS MICROSY, V67, P28, DOI 10.1016/j.micpro.2019.01.009
   Nag A, 2018, IEEE MICRO, V38, P41, DOI 10.1109/MM.2018.053631140
   Nili H, 2018, NAT ELECTRON, V1, P197, DOI 10.1038/s41928-018-0039-7
   Ohnh┬u├▒user, 2015, ANALOG DIGITAL CONVE
   Pan WQ, 2020, IEEE T ELECTRON DEV, V67, P895, DOI 10.1109/TED.2019.2963323
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Prezioso M, 2016, SCI REP-UK, V6, DOI 10.1038/srep21331
   RABUSKE T, 2017, CHARGE SHARING SAR A
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Rockchip, 2018, ROCKCH REL ITS 1 AL
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sassine G, 2016, J VAC SCI TECHNOL B, V34, DOI 10.1116/1.4940129
   Schreier R., 2005, UNDERSTANDING DELTA, V74
   Sebastian A., 2019, 2019 Symposium on VLSI Technology, pT168, DOI 10.23919/VLSIT.2019.8776518
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Serb A, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12611
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/nnano.2017.83, 10.1038/NNANO.2017.83]
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Strukov, 2019, ARXIV PREPRINT ARXIV
   Strukov D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12521-x
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sung C, 2018, J APPL PHYS, V124, DOI 10.1063/1.5037835
   Sze V., 2018, 2017 IEEE CUSTOM INT, P1, DOI 10.1109/CICC.2018.8357072
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   VONNEUMANN J, 1993, IEEE ANN HIST COMPUT, V15, P28
   Walden RH, 1999, IEEE J SEL AREA COMM, V17, P539, DOI 10.1109/49.761034
   Wu TF, 2019, ISSCC DIG TECH PAP I, V62, P226, DOI 10.1109/ISSCC.2019.8662402
   Wu TF, 2018, ISSCC DIG TECH PAP I, P492, DOI 10.1109/ISSCC.2018.8310399
   Xia LX, 2019, IEEE T COMPUT AID D, V38, P1611, DOI 10.1109/TCAD.2018.2855145
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 126
TC 64
Z9 64
U1 7
U2 36
PD NOV
PY 2020
VL 2
IS 11
AR 2000115
DI 10.1002/aisy.202000115
UT WOS:000669793800011
DA 2023-11-16
ER

PT J
AU Bardhan, A
   Alzo'ubi, AK
   Palanivelu, S
   Hamidian, P
   GuhaRay, A
   Kumar, G
   Tsoukalas, MZ
   Asteris, PG
AF Bardhan, Abidhan
   Alzo'ubi, Abdel Kareem
   Palanivelu, Sangeetha
   Hamidian, Pouria
   GuhaRay, Anasua
   Kumar, Gaurav
   Tsoukalas, Markos Z.
   Asteris, Panagiotis G.
TI A hybrid approach of ANN and improved PSO for estimating soaked CBR of
   subgrade soils of heavy-haul railway corridor
SO INTERNATIONAL JOURNAL OF PAVEMENT ENGINEERING
DT Article
DE Subgrade design; transportation infrastructure; Indian railways;
   artificial neural network; particle swarm optimisation
ID ARTIFICIAL NEURAL-NETWORK; FINE-GRAINED SOILS; BEARING RATIO CBR;
   PREDICTION; PERFORMANCE; REGRESSION; MODELS
AB The determination of subgrade/subsoil strength is one of the most important pavement design factors in transportation engineering, particularly for railways, roadways, and airport runways. The California bearing ratio (CBR) is often used to measure the strength and stiffness modulus of subgrade materials. This study presents a novel machine learning solution as an alternate approach for estimating soil CBR in soaked conditions. The present approach is an integration of an artificial neural network (ANN) and improved particle swarm optimisation (IPSO). According to experimental results during the testing phase, the proposed hybrid model, ANN-IPSO has achieved the highest predictive precision with root mean square error, RMSE = 0.0711 and mean absolute error, MAE = 0.0546. The findings of the proposed model are far superior to those of employed models including the conventional ANN, support vector machine, and group method of data handling. Six additional hybrid models of ANN and standard PSO (SPSO), PSO with time-varying accelerator coefficients, modified PSO, Harris hawks optimisation, slime mould algorithm, and colony predation algorithm were also constructed for a detailed comparison. Based on the outcomes, the newly created ANN-IPSO has the potential to be a new tool to estimate soaked CBR of fine-grained soils in civil engineering projects.
C1 [Bardhan, Abidhan] Natl Inst Technol Patna, Dept Civil Engn, Patna, Bihar, India.
   [Alzo'ubi, Abdel Kareem] Abu Dhabi Univ, Dept Civil Engn, Al Ain, U Arab Emirates.
   [Palanivelu, Sangeetha] Sri Sivasubramaniya Nadar Coll Engn, Dept Civil Engn, Chennai, India.
   [Hamidian, Pouria] Univ Tehran, Coll Engn, Sch Civil Engn, Tehran, Iran.
   [GuhaRay, Anasua] BITS Pilani Hyderabad Campus, Hyderabad, India.
   [Kumar, Gaurav] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
   [Tsoukalas, Markos Z.; Asteris, Panagiotis G.] Computat Mech Lab, Sch Pedag & Technol Educ, Athens, Heraklion, Greece.
RP Asteris, PG (corresponding author), Computat Mech Lab, Sch Pedag & Technol Educ, Athens, Heraklion, Greece.
EM asteris@aspete.gr
CR Agarwal K., 1970, PROCEEDING 2 S E ASI
   Al-Busultan Shakir, 2020, IOP Conference Series: Materials Science and Engineering, V671, DOI 10.1088/1757-899X/671/1/012106
   Al-Refeai T., 1997, J KING SAUD U ENG SC, V9, P191
   Alam SK, 2020, J GEOL SOC INDIA, V95, P190, DOI 10.1007/s12594-020-1409-0
   Alel MNA, 2018, J PHYS CONF SER, V995, DOI 10.1088/1742-6596/995/1/012046
   Alemdag S, 2016, ENG GEOL, V203, P70, DOI 10.1016/j.enggeo.2015.12.002
   Alzabeebee S, 2022, ROAD MATER PAVEMENT, V23, P2733, DOI 10.1080/14680629.2021.1995471
   Alzo'Ubi AK, 2021, INT J GEOTECH ENG, V15, P810, DOI 10.1080/19386362.2018.1519975
   Alzo'ubi AK, 2019, GEOTECH GEOL ENG, V37, P1311, DOI 10.1007/s10706-018-0687-4
   Alzo'ubi A. K., 2018, MATEC Web of Conferences, V149, DOI 10.1051/matecconf/201814902031
   Alzoubi A.K., 2018, INT C EXHIBITION SUS, P49, DOI [10.1007/978-3-030-01902-0_5, DOI 10.1007/978-3-030-01902-0_5]
   [Anonymous], 1987, 2720 IS
   Armaghani DJ, 2014, ARAB J GEOSCI, V7, P5383, DOI 10.1007/s12517-013-1174-0
   Asteris PG, 2020, NEURAL COMPUT APPL, V32, P11807, DOI 10.1007/s00521-019-04663-2
   Bao GQ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2134, DOI 10.1109/ROBIO.2009.5420504
   Bardhan A, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107595
   Bhatt S., 2014, AM INT J RES SCI TEC, V8, P156
   Black WPM., 1962, GEOTECHNIQUE, V12, P271, DOI [10.1680/geot.1962.12.4.271, DOI 10.1680/GEOT.1962.12.4.271]
   Bui XN, 2020, NAT RESOUR RES, V29, P571, DOI 10.1007/s11053-019-09461-0
   Cabalar AF, 2019, ROAD MATER PAVEMENT, V20, P702, DOI 10.1080/14680629.2017.1407817
   Cabalar AF, 2015, J TEST EVAL, V43, DOI 10.1520/JTE20130070
   Cevik A, 2011, APPL SOFT COMPUT, V11, P2587, DOI 10.1016/j.asoc.2010.10.008
   Chandra S, 2018, ENERGY REP, V4, P252, DOI 10.1016/j.egyr.2017.11.001
   Cui ZH, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS, P638, DOI 10.1109/ISDA.2008.86
   De Graft-Johnson JWS., 1969, P 7 INT C SOIL MECH, V2, P13
   Dharma Silalahi Divo, 2016, Information Processing in Agriculture, V3, P252, DOI 10.1016/j.inpa.2016.10.001
   Bui DT, 2018, ADV ENG INFORM, V38, P593, DOI 10.1016/j.aei.2018.09.005
   Dorn M, 2012, EXPERT SYST APPL, V39, P12268, DOI 10.1016/j.eswa.2012.04.046
   Trong DK, 2021, MATERIALS, V14, DOI 10.3390/ma14216516
   Ebtehaj I, 2015, ENG SCI TECHNOL, V18, P746, DOI 10.1016/j.jestch.2015.04.012
   Edincliler A, 2013, EUR J ENVIRON CIV EN, V17, P720, DOI 10.1080/19648189.2013.814552
   Erzin Y, 2016, NEURAL COMPUT APPL, V27, P1415, DOI 10.1007/s00521-015-1943-7
   Faridmehr I, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11060229
   Fukuyama Y, 2001, IEEE C EVOL COMPUTAT, P87, DOI 10.1109/CEC.2001.934375
   Ghorbani A, 2018, SOILS FOUND, V58, P34, DOI 10.1016/j.sandf.2017.11.002
   Golafshani EM, 2020, CONSTR BUILD MATER, V232, DOI 10.1016/j.conbuildmat.2019.117266
   Farias IG, 2018, GEOTECH GEOL ENG, V36, P3485, DOI 10.1007/s10706-018-0548-1
   Ly HB, 2021, NEURAL COMPUT APPL, V33, P3437, DOI 10.1007/s00521-020-05214-w
   Hajihassani M, 2014, APPL ACOUST, V80, P57, DOI 10.1016/j.apacoust.2014.01.005
   Hasanipanah M, 2017, NEURAL COMPUT APPL, V28, pS1043, DOI 10.1007/s00521-016-2434-1
   Hassan J, 2022, TRANSP INFRASTRUCT G, V9, P764, DOI 10.1007/s40515-021-00197-0
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Ibrahim F, 2023, ARAB J SCI ENG, V48, P4403, DOI 10.1007/s13369-022-06969-1
   IVAKHNENKO AG, 1971, IEEE T SYST MAN CYB, VSMC1, P364, DOI 10.1109/TSMC.1971.4308320
   Katte VY, 2019, GEOTECH GEOL ENG, V37, P217, DOI 10.1007/s10706-018-0604-x
   Kennedy J, 1995, SWARM INTELLIGENCE, DOI DOI 10.1016/B978-155860595-4/50007-3
   Khan MUA, 2022, SOFT COMPUT, V26, P6839, DOI 10.1007/s00500-021-06628-x
   Khan MUA, 2021, NEURAL COMPUT APPL, V33, P14861, DOI 10.1007/s00521-021-06125-0
   Kin MW., 2006, CALIFORNIA BEARING R
   Koopialipoor M, 2019, ENG COMPUT-GERMANY, V35, P243, DOI 10.1007/s00366-018-0596-4
   Kumar S.A., 2013, CBR REMOLDED SOILS, V2, P3019
   Kurnaz TF, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12692-0
   Le LT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132630
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Lili Chen, 2020, IOP Conference Series: Earth and Environmental Science, V428, DOI 10.1088/1755-1315/428/1/012089
   Liou SW, 2009, J UNIVERS COMPUT SCI, V15, P742
   Mandal A, 2021, ENERGIES, V14, DOI 10.3390/en14102910
   Min SH, 2006, EXPERT SYST APPL, V31, P652, DOI 10.1016/j.eswa.2005.09.070
   Moayedi H, 2020, ENG COMPUT-GERMANY, V36, P671, DOI 10.1007/s00366-019-00723-2
   Monjezi M, 2012, ARAB J GEOSCI, V5, P441, DOI 10.1007/s12517-010-0185-3
   Murlidhar BR, 2020, NAT RESOUR RES, V29, P4103, DOI 10.1007/s11053-020-09676-6
   NCHRP (National Cooperative Highway Research Program), 2004, 137A NCHRP
   Nefeslioglu HA, 2008, ENG GEOL, V97, P171, DOI 10.1016/j.enggeo.2008.01.004
   Nordin NFC, 2021, GROUNDWATER SUST DEV, V14, DOI 10.1016/j.gsd.2021.100643
   Otchere DA, 2021, J PETROL SCI ENG, V200, DOI 10.1016/j.petrol.2020.108182
   Pandey SK, 2020, ADV INTELL SYST COMP, V1079, P409, DOI 10.1007/978-981-15-1097-7_34
   Patel R. S., 2010, P IND GEOT C MUMB NE, P79
   Pradeep Kumar KJ., 2016, INT J INNOVATIVE RES, V5, P13852
   Quan V., 2022, J SCI TRANSPORT TECH, V1, DOI [10.58845/jstt.utt.2021.en3, DOI 10.58845/JSTT.UTT.2021.EN3]
   Rad HN, 2020, NAT RESOUR RES, V29, P609, DOI 10.1007/s11053-019-09464-x
   Raghurama G., 2018, DEDICATED FREIGHT CO
   Raja MNA, 2021, GEOSYNTH INT, V28, P368, DOI 10.1680/jgein.20.00049
   Raja MNA, 2021, GEOTEXT GEOMEMBRANES, V49, P1280, DOI 10.1016/j.geotexmem.2021.04.007
   Raja MNA, 2022, INT J PAVEMENT ENG, V23, P3505, DOI 10.1080/10298436.2021.1904237
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Roy P, 2019, IEEE-CAA J AUTOMATIC, V6, P1365, DOI 10.1109/JAS.2019.1911753
   Roy T.K., 2013, P INT S ENG UNCERTAI, DOI [10.1007/978-81-322-0757-3, DOI 10.1007/978-81-322-0757-3]
   Sabat KA., 2015, ELECTRON J GEOTECH E, V20, P981
   Srivastava P, 2021, MULTIMED TOOLS APPL, V80, P14887, DOI 10.1007/s11042-021-10544-5
   Stephens D.J., 1990, CIV ENG SIVIELE INGE, V1990, P523
   Suthar M, 2018, INT J GEOSYNTH GROUN, V4, DOI 10.1007/s40891-017-0125-3
   Taha S, 2019, ARAB J SCI ENG, V44, P8691, DOI 10.1007/s13369-019-03803-z
   Tang ZY, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P330, DOI 10.1109/APCIP.2009.217
   Taskiran T, 2010, ADV ENG SOFTW, V41, P886, DOI 10.1016/j.advengsoft.2010.01.003
   TAYLOR CE, 1994, JH HOLLAND Q REV BIO, V69, P88, DOI DOI 10.1086/418447
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Tenpe AR, 2020, ARAB J SCI ENG, V45, P4301, DOI 10.1007/s13369-020-04441-6
   Tu J, 2021, J BIONIC ENG, V18, P674, DOI 10.1007/s42235-021-0050-y
   van den Bergh F, 2006, INFORM SCIENCES, V176, P937, DOI 10.1016/j.ins.2005.02.003
   Varghese VK, 2013, GEOTECH GEOL ENG, V31, P1187, DOI 10.1007/s10706-013-9643-5
   Wang HL, 2020, ENG GEOL, V276, DOI 10.1016/j.enggeo.2020.105758
   Yildirim B, 2011, EXPERT SYST APPL, V38, P6381, DOI 10.1016/j.eswa.2010.12.054
NR 92
TC 3
Z9 3
U1 19
U2 29
PD DEC 6
PY 2023
VL 24
IS 1
AR 2176494
DI 10.1080/10298436.2023.2176494
UT WOS:000943826800001
DA 2023-11-16
ER

PT C
AU Sharma, A
   Bhasi, VM
   Singh, S
   Jain, R
   Gunasekaran, JR
   Mitra, S
   Kandemir, MT
   Kesidis, G
   Das, CR
AF Sharma, Aakash
   Bhasi, Vivek M.
   Singh, Sonali
   Jain, Rishabh
   Gunasekaran, Jashwant Raj
   Mitra, Subrata
   Kandemir, Mahmut Taylan
   Kesidis, George
   Das, Chita R.
GP IEEE
TI Stash: A comprehensive stall-centric characterization of public cloud
   VMs for distributed deep learning
SO 2023 IEEE 43RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING
   SYSTEMS, ICDCS
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 43rd IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY JUL 18-21, 2023
CL Hong Kong, HONG KONG
ID PYTORCH
AB Deep neural networks (DNNs) are increasingly popular owing to their ability to solve complex problems such as image recognition, autonomous driving, and natural language processing. Their growing complexity coupled with the use of larger volumes of training data (to achieve acceptable accuracy) has warranted the use of GPUs and other accelerators. Such accelerators are typically expensive, with users having to pay a high upfront cost to acquire them. For infrequent use, users can, instead, leverage the public cloud to mitigate the high acquisition cost. However, with the wide diversity of hardware instances (particularly GPU instances) available in public cloud, it becomes challenging for a user to make an appropriate choice from a cost/performance standpoint.
   In this work, we try to address this problem by (i) introducing a comprehensive distributed deep learning (DDL) profiler Stash, which determines the various execution stalls that DDL suffers from, and (ii) using Stash to extensively characterize various public cloud GPU instances by running popular DNN models on them. Specifically, it estimates two types of communication stalls, namely, interconnect and network stalls, that play a dominant role in DDL execution time. Stash is implemented on top of prior work, DS-analyzer, that computes only the CPU and disk stalls. Using our detailed stall characterization, we list the advantages and shortcomings of public cloud GPU instances for users to help them make an informed decision(s). Our characterization results indicate that the more expensive GPU instances may not be the most performant for all DNN models and that AWS can sometimes sub-optimally allocate hardware interconnect resources. Specifically, the intra-machine interconnect can introduce communication overheads of up to 90% of DNN training time and the network-connected instances can suffer from up to 5x slowdown compared to training on a single instance. Furthermore, (iii) we also model the impact of DNN macroscopic features such as the number of layers and the number of gradients on communication stalls, and finally, (iv) we briefly discuss a cost comparison with existing work.
C1 [Sharma, Aakash; Bhasi, Vivek M.; Singh, Sonali; Jain, Rishabh; Kandemir, Mahmut Taylan; Kesidis, George; Das, Chita R.] Penn State Univ, Comp Sci & Engn, University Pk, PA 16802 USA.
   [Gunasekaran, Jashwant Raj; Mitra, Subrata] Adobe Res, San Francisco, CA USA.
RP Sharma, A (corresponding author), Penn State Univ, Comp Sci & Engn, University Pk, PA 16802 USA.
EM abs5688@psu.edu; vmbhasi@psu.edu; sms821@psu.edu; rishabh@psu.edu;
   jgunasekaran@adobe.com; subrata.mitra@adobe.com; mtk2@psu.edu;
   gik2@psu.edu; cxd12@psu.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], AL PAI
   [Anonymous], NVIDIA DEEP LEARN EX
   [Anonymous], NVPROF
   [Anonymous], DAWNBENCH
   [Anonymous], IMAGENET LARGE SCALE
   [Anonymous], 2020, MLSYS
   [Anonymous], AWS NVIDIA GPU INST
   Awan AA, 2019, IEEE ACM INT SYMP, P498, DOI [10.1109/CCGRID.2019.00064, 10.1109/ccgrid.2019.00064]
   Bhasi Vivek M., 2021, P SOCC 21
   Bhasi Vivek M., 2022, P SOCC 22
   Dean Jeffrey, 2012, P ADV NEUR INF PROC, V25
   Devlin Jacob, 2019, P NAACL HLT 19
   Fukuda K., TECHNOLOGIES DISTRIB
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Ho Qirong, 2013, P NIPS
   Jain A, 2019, IEEE INT C CL COMP, P58, DOI 10.1109/cluster.2019.8891042
   Kheria Rashika, OPTIMIZING DEEP LEAR
   Ko Y, 2021, INT PARALL DISTRIB P, P994, DOI 10.1109/IPDPS49936.2021.00108
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leong MC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020557
   Li A, 2020, IEEE T PARALL DISTR, V31, P94, DOI 10.1109/TPDS.2019.2928289
   Li M., 2014, P 11 USENIX S OP SYS, V14, P583, DOI DOI 10.1145/2640087.2644155
   Li S, 2020, PROC VLDB ENDOW, V13, P3005, DOI 10.14778/3415478.3415530
   Lian XR, 2018, PR MACH LEARN RES, V80
   Liu J, 2019, INT C PAR DISTRIB SY, P506, DOI 10.1109/ICPADS47876.2019.00077
   Luo Liang, 2022, MLSYS, V4, P833
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mohan J, 2021, Arxiv, DOI arXiv:2007.06775
   Mojumder SA, 2018, I S WORKL CHAR PROC, P122, DOI 10.1109/IISWC.2018.8573521
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646
   Nsight, US
   Parmar N, 2018, PR MACH LEARN RES, V80
   Rabenseifner R, 2004, LECT NOTES COMPUT SC, V3036, P1
   Rajpurkar P., 2016, SQUAD 100000 QUESTIO, P2383, DOI DOI 10.18653/V1/D16-1264
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma A, 2022, Arxiv, DOI arXiv:2208.14344
   Sharma Aakash, 2021, P IEEEACM CCGRID
   Keskar NS, 2017, Arxiv, DOI arXiv:1609.04836
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2020, ANN I S COM, P363, DOI 10.1109/ISCA45697.2020.00039
   Singh Sonali, 2022, P 55 IEEEACM MICRO
   Stash, US
   Wang C., 2017, P ACM SIGMETRICS URB
   Wang MD, 2019, I S WORKL CHAR PROC, P189, DOI 10.1109/IISWC47752.2019.9042047
   Weng QZ, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P945
   Xia CW, 2018, I S WORKL CHAR PROC, P82, DOI 10.1109/IISWC.2018.8573514
   Yi J, 2020, INT PARALL DISTRIB P, P419, DOI 10.1109/IPDPS47924.2020.00051
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang Hao, 2017, P USENIX ATC
   Zhang SX, 2015, ADV NEUR IN, V28
   Zhang Tianwei, P SC 21
   Zhu HY, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P337
NR 55
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 875
EP 886
DI 10.1109/ICDCS57875.2023.00023
UT WOS:001081242600077
DA 2023-11-16
ER

PT C
AU Sharma, T
   Wang, C
   Agrawal, A
   Roy, K
AF Sharma, Tanvi
   Wang, Cheng
   Agrawal, Amogh
   Roy, Kaushik
GP IEEE
TI Enabling Robust SOT-MTJ Crossbars for Machine Learning using
   Sparsity-Aware Device-Circuit Co-design
SO 2021 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN (ISLPED)
SE International Symposium on Low Power Electronics and Design
DT Proceedings Paper
CT IEEE/ACM International Symposium on Low Power Electronics and Design
   (ISLPED)
CY JUL 26-28, 2021
CL ELECTR NETWORK
AB Embedded non-volatile memory (eNVM) based crossbars have emerged as energy-efficient building blocks for machine learning accelerators. However, the analog computations in crossbars introduce errors due to several non-idealities. Moreover, since communications between crossbars are usually done in the digital domain, the energy and area costs are dominated by the Analog-to-Digital Converters (ADC). Among the eNVM technologies, Resistive Random-Access-Memory (RRAM) and Phase-Change Memory (PCM) devices suffer from poor endurance, write variability and conductance drift. Whereas magneto-resistive technologies provide superior endurance, write stability and reliability. To that effect, we propose sparsity-aware device/circuit co-design of robust crossbars using Spin-Orbit-Torque Magnetic Tunnel Junctions (SOT-MTJs). Note, standard MTJs have low R-OFF/R-ON and low R-ON, making them unsuitable for crossbars. In this work, we first demonstrate SOT-MTJs as crossbar elements with high R-ON and high R-OFF/R-ON by allowing the read-path to have thicker tunneling-barrier, leaving the write path undisturbed. Second, through extensive simulations, we quantitatively assess the impact of various device-circuit parameters such as R-ON, R-OFF/R-ON ratio, crossbar size, along with input and weight sparsity, on both circuit and application level accuracy and energy consumption. We evaluate system accuracy for Resnet-20 inference on CIFAR-10 dataset and show that leveraging sparsity allows reduced ADC precision, without degrading accuracy. Our results show that an SOT-MTJ (R-ON=200k Omega and E-OFF/R-ON=7) crossbar array of size 32x32 could achieve near-software accuracy. The 64x64 and 128x128 crossbars show an accuracy degradation of 2% and 9.8%, respectively, from the software accuracy and an energy improvement of upto 3.8 x and 6.3x compared to a 32x32array with 4bit-ADC.
C1 [Sharma, Tanvi; Wang, Cheng; Agrawal, Amogh; Roy, Kaushik] Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Sharma, T (corresponding author), Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM sharm418@purdue.edu
CR Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Boniardi M, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3599559
   Chakraborty I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218688
   Chakraborty J, 2020, PROCEEDINGS OF THE 2020 IEEE 10TH INTERNATIONAL CONFERENCE ON NANOMATERIALS: APPLICATIONS & PROPERTIES (NAP-2020)
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choquette J., 2020, IEEE HOT CHIPS S
   Doevenspeck J., 2020, S VLSI TECH
   Edelstein D, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371922
   Fleischer B., 2020, IBM RES BLOG
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   He Kaiming, 2016, PROC CVPR IEEE
   Ikeda S, 2010, NAT MATER, V9, P721, DOI [10.1038/nmat2804, 10.1038/NMAT2804]
   Ikeda S, 2008, APPL PHYS LETT, V93, DOI 10.1063/1.2976435
   Ikegawa S, 2020, IEEE T ELECTRON DEV, V67, P1407, DOI 10.1109/TED.2020.2965403
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Lin C. J., 2009, IEDM, P1
   Murmann B., 2018, ADC PERFORMANCE SURV
   Park C, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P185, DOI 10.1109/VLSIT.2018.8510653
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shi YH, 2020, IEEE ELECTR DEVICE L, V41, P1126, DOI 10.1109/LED.2020.2995819
   Xuanyao Fong, 2011, 2011 International Conference on Simulation of Semiconductor Processes and Devices (SISPAD 2011), P51, DOI 10.1109/SISPAD.2011.6035047
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yuasa S, 2004, NAT MATER, V3, P868, DOI 10.1038/nmat1257
NR 24
TC 9
Z9 9
U1 1
U2 3
PY 2021
DI 10.1109/ISLPED52811.2021.9502492
UT WOS:000701418600023
DA 2023-11-16
ER

PT J
AU Gupta, S
   Ullah, S
   Ahuja, K
   Tiwari, A
   Kumar, A
AF Gupta, Siddharth
   Ullah, Salim
   Ahuja, Kapil
   Tiwari, Aruna
   Kumar, Akash
TI ALigN: A Highly Accurate Adaptive Layerwise Log&x005F;2&x005F;Lead
   Quantization of Pre-Trained Neural Networks
SO IEEE ACCESS
DT Article
DE Machine learning; deep neural networks; quantization; multipliers
AB Deep Neural Networks are one of the machine learning techniques which are increasingly used in a variety of applications. However, the significantly high memory and computation demands of deep neural networks often limit their deployment on embedded systems. Many recent works have considered this problem by proposing different types of data quantization schemes. However, most of these techniques either require post-quantization retraining of deep neural networks or bear a significant loss in output accuracy. In this paper, we propose a novel and scalable technique with two different modes for the quantization of the parameters of pre-trained neural networks. In the first mode, referred to as <italic>log & x005F;2 & x005F;lead</italic>, we use a single template for the quantization of all parameters. In the second mode, denoted as <italic>ALigN</italic>, we analyze the trained parameters of each layer and adaptively adjust the quantization template to achieve even higher accuracy. Our technique significantly maintains the accuracy of the parameters and does not require retraining of the networks. Moreover, it supports quantization to an arbitrary bit-size. For example, compared to the single-precision floating-point numbers-based implementation, our proposed 8-bit quantization technique generates only and , loss in the Top-1 and Top-5 accuracies respectively for VGG-16 network using ImageNet dataset. We have observed similar minimal losses in the Top-1 and Top-5 accuracies for AlexNet and Resnet-18 using the proposed quantization scheme for the 8-bit range. Our proposed quantization technique also provides a higher mean intersection over union for semantic segmentation when compared with state-of-the-art quantization techniques. The proposed technique represents parameters in powers of 2, thereby eliminating the need for resource-computationally intensive multiplier units for the hardware accelerators of the neural networks. We also present a design for implementing the multiplication operation using bit-shifts and addition for the proposed quantization technique.
C1 [Gupta, Siddharth; Ahuja, Kapil; Tiwari, Aruna] Indian Inst Technol Indore, Dept Comp Sci & Engn, Indore 453552, India.
   [Ullah, Salim; Kumar, Akash] Tech Univ Dresden, Dept Comp Sci, D-01062 Dresden, Germany.
RP Ullah, S; Kumar, A (corresponding author), Tech Univ Dresden, Dept Comp Sci, D-01062 Dresden, Germany.
EM salim.ullah@tu-dresden.de; akash.kumar@tu-dresden.de
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   de Prado M, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P36, DOI 10.1145/3203217.3203282
   Deng L, 2013, IEEE INT NEW CIRC
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kalamkar D., 2019, ARXIV190512322
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V3, P6
   LeCun Y., 1998, MNIST DATABASE HANDW
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lin Zhouhan, 2015, NEURAL NETWORKS FEW
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miyashita Daisuke, 2016, ARXIV160301025
   Mordido G., 2019, ARXIV190512253
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tann H, 2017, DES AUT CON, DOI 10.1145/3061639.3062259
   Ullah S, 2020, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE48585.2020.9116373
   Vogel S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240803
   Vogel S, 2019, DES AUT TEST EUROPE, P1094, DOI [10.23919/date.2019.8714901, 10.23919/DATE.2019.8714901]
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhou Shuchang, 2016, ARXIV160606160
   Zhu C., 2016, ARXIV161201064
NR 31
TC 7
Z9 7
U1 0
U2 4
PY 2020
VL 8
BP 118899
EP 118911
DI 10.1109/ACCESS.2020.3005286
UT WOS:000551824900001
DA 2023-11-16
ER

PT C
AU Tumeo, A
AF Tumeo, Antonino
GP Assoc Comp Machinery
TI Data and Model Convergence: a Case for Software Defined Architectures
SO CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON
   COMPUTING FRONTIERS
DT Proceedings Paper
CT 16th ACM International Conference on Computing Frontiers (CF)
CY APR 30-MAY 02, 2019
CL Alghero, ITALY
DE Data-Model Convergence; reconfigurable architectures
AB High Performance Computing, data analytics, and machine learning are often considered three separate and different approaches. Applications, software and now hardware stacks are typically designed to only address one of the areas at a time. This creates a false distinction across the three different areas. In reality, domain scientists need to exercise all the three approaches in an integrated way. For example, large scale simulations generate enormous amount of data, to which Big Data Analytics techniques can be applied. Or, as scientist seek to use data analytics as well as simulation for discovery, machine learning can play an important role in making sense of the disparate source's information. Pacific Northwest National Laboratory is launching a new Laboratory Directed Research and Development (LDRD) Initiative to investigate the integration of the three techniques at all level of the high-performance computing stack, the Data-Model Convergence (DMC) Initiative. The DMC Initiative aims to increase scientist productivity by enabling purpose-built software and hardware and domain-aware ML techniques.
   In this talk, I will present the objectives of PNNL's DMC Initiative, highlighting the research that will be performed to enable the integration of vastly different programming paradigms and mental models. I will then make the case for how reconfigurable architectures could represent a great opportunity to address the challenges of DMC. In principle, the possibility to dynamically modify the architecture during runtime could provide a way to address the requirement of workloads that have significantly diverse behaviors across phases, without losing too much flexibility or programmer productivity, with respect to highly heterogeneous architectures composed by sea of fixed application specific accelerators. Reconfigurable architectures have been explored since long time ago, and arguably new software breakthroughs are required to make them successful. I will thus present the efforts that the DMC initiative is launching to design a productive toolchain for upcoming novel reconfigurable systems.
C1 [Tumeo, Antonino] Pacific Northwest Natl Lab, High Performance Comp, Richland, WA 99352 USA.
RP Tumeo, A (corresponding author), Pacific Northwest Natl Lab, High Performance Comp, Richland, WA 99352 USA.
EM antonino.tumeo@pnnl.gov
NR 0
TC 0
Z9 0
U1 0
U2 4
PY 2019
BP 343
EP 343
DI 10.1145/3310273.3323438
UT WOS:000474686400062
DA 2023-11-16
ER

PT J
AU Krithivasan, S
   Sen, S
   Raghunathan, A
AF Krithivasan, Sarada
   Sen, Sanchari
   Raghunathan, Anand
TI Sparsity Turns Adversarial: Energy and Latency Attacks on Deep Neural
   Networks
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Adversarial machine learning; deep neural networks; sparsity in DNNs
AB Adversarial attacks have exposed serious vulnerabilities in deep neural networks (DNNs), causing misclassifications through human-imperceptible perturbations to DNN inputs. We explore a new direction in the field of adversarial attacks by suggesting attacks that aim to degrade the energy or latency of DNNs rather than their classification accuracy. As a specific embodiment of this new threat vector, we propose and demonstrate adversarial sparsity attacks, which modify a DNN's inputs so as to reduce sparsity (or the incidence of zeros) in its internal activation values. Exploiting sparsity in hardware and software has emerged as a popular approach to improve DNN efficiency in resource-constrained systems. The proposed attack, therefore, increases the execution time and energy consumption of sparsity-optimized DNN implementations, raising concern over their deployment in latency and energy-critical applications. We propose a systematic methodology to generate adversarial inputs for sparsity attacks by formulating an objective function that quantifies the network's activation sparsity and minimizing this function using iterative gradient-descent techniques. To prevent easy detection of the attack, we further ensure that the perturbation magnitude is within a specified constraint and that the perturbation does not affect classification accuracy. We launch both white-box and black-box versions of adversarial sparsity attacks on image recognition DNNs and demonstrate that they decrease activation sparsity by 1.16x-1.82x. On a sparsity-optimized DNN accelerator, the attack results in degradations of 1.12x-1.59x in latency and 1.18x-1.99x in energy-delay product (EDP). Additionally, we analyze the impact of various hyperparameters and constraints on the attack's efficacy. Finally, we evaluate defense techniques, such as activation thresholding and input quantization and demonstrate that the proposed attack is able to withstand them, highlighting the need for further efforts in this new direction within the field of adversarial machine learning.
C1 [Krithivasan, Sarada; Sen, Sanchari; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Krithivasan, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM skrithiv@purdue.edu; sen9@purdue.edu; raghunathan@purdue.edu
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2014, ABS1412556
   [Anonymous], 2016, ADVERSARIAL EXAMPLES
   [Anonymous], 2017, DISCOVERING ADVERSAR
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen P.-Y., 2017, ZOO ZEROTH ORDER OPT, P15, DOI DOI 10.1145/3128572.3140448
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duddu V., 2018, STEALING NEURAL NETW
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Goodfellow R, 2015, OIL AND GAS PIPELINES: INTEGRITY AND SAFETY HANDBOOK, P3
   Guo C., 2017, COUNTERING ADVERSARI
   Guo Chuan, 2019, SIMPLE BLACK BOX ADV
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hwang U, 2019, IEEE ACCESS, V7, P126582, DOI 10.1109/ACCESS.2019.2939352
   Isakov M., 2019, P 2019 IEEE HIGH PER, P1, DOI 10.1109/HPEC.2019.8916519
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA, V3, P6
   LeCun Y., 1998, MNIST DATABASE HANDW
   Liu Y., 2016, DELVING TRANSFERABLE
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Madry A., 2018, P 6 INT C LEARN REPR
   Palossi D., 2018, ULTRALOW POWER DEEP
   Pang T., 2019, IMPROVING ADVERSARIA
   Papernot N., 2016, PRACTICAL BLACK BOX
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rakin Adnan Siraj, 2019, BIT FLIP ATTACK CRUS
   Samangouei P., 2018, DEFENSE GAN PROTECTI
   Sen S, 2020, HERBAL MEDICINE IN INDIA: INDIGENOUS KNOWLEDGE, PRACTICE, INNOVATION AND ITS VALUE, P1, DOI 10.1007/978-981-13-7248-3
   Sen S, 2019, IEEE T COMPUT, V68, P912, DOI 10.1109/TC.2018.2879434
   Shokri Reza, 2016, MEMBERSHIP INFERENCE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg Jost Tobias, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1109/TGRS.2018.2833293
   Sutskever Ilya, 2013, INT C MACH LEARN, P1139
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269
NR 40
TC 4
Z9 4
U1 1
U2 2
PD NOV
PY 2020
VL 39
IS 11
BP 4129
EP 4141
DI 10.1109/TCAD.2020.3013077
UT WOS:000587712700081
DA 2023-11-16
ER

PT J
AU Nambi, S
   Ullah, S
   Sahoo, SS
   Lohana, A
   Merchant, F
   Kumar, A
AF Nambi, Suresh
   Ullah, Salim
   Sahoo, Siva Satyendra
   Lohana, Aditya
   Merchant, Farhad
   Kumar, Akash
TI <i>ExPAN(N)D</i>: Exploring Posits for Efficient Artificial Neural
   Network Design in FPGA-Based Systems
SO IEEE ACCESS
DT Article
DE Quantization (signal); Hardware; Dynamic range; Field programmable gate
   arrays; Neural networks; Machine learning algorithms; Delays; Computer
   arithmetic; deep neural networks; energy efficient computing; posits;
   FPGA; high-level synthesis
ID ACCURATE
AB The high computational complexity, memory footprints, and energy requirements of machine learning models, such as Artificial Neural Networks (ANNs), hinder their deployment on resource-constrained embedded systems. Most state-of-the-art works have considered this problem by proposing various low bit-width data representation schemes and optimized arithmetic operators' implementations. To further elevate the implementation gains offered by these individual techniques, there is a need to cross-examine and combine these techniques' unique features. This paper presents ExPAN(N)D, a framework to analyze and ingather the efficacy of the Posit number representation scheme and the efficiency of fixed-point arithmetic implementations for ANNs. The Posit scheme offers a better dynamic range and higher precision for various applications than IEEE 754 single-precision floating-point format. However, due to the dynamic nature of the various fields of the Posit scheme, the corresponding arithmetic circuits have higher critical path delay and resource requirements than the single-precision-based arithmetic units. Towards this end, we propose a novel Posit to fixed-point converter for enabling high-performance and energy-efficient hardware implementations for ANNs with minimal drop in the output accuracy. We also propose a modified Posit-based representation to store the trained parameters of a network. With the proposed Posit to fixed-point converter-based designs, we provide multiple design points with varying accuracy-performance trade-offs for an ANN. For instance, compared to the lowest power dissipating Posit-only accelerator design, one of our proposed designs results in 80% and 48% reduction in power dissipation and LUT utilization respectively, with marginal increase in classification error for Imagenet dataset classification using VGG-16.
C1 [Nambi, Suresh; Ullah, Salim; Sahoo, Siva Satyendra; Lohana, Aditya; Kumar, Akash] Tech Univ Dresden, Ctr Adv Elect Dresden Cfaed, Chair Processor Design, D-01062 Dresden, Germany.
   [Merchant, Farhad] Rhein Westfal TH Aachen, Inst Commun Technol & Embedded Syst, D-52056 Aachen, Germany.
RP Ullah, S; Sahoo, SS (corresponding author), Tech Univ Dresden, Ctr Adv Elect Dresden Cfaed, Chair Processor Design, D-01062 Dresden, Germany.
EM salim.ullah@tu-dresden.de; siva_satyendra.sahoo@tu-dresden.de
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2017, XILINX AXI INTERCONN
   [Anonymous], 2018, 2018 1 WORKSH EN, DOI DOI 10.1109/EMC2.2018.00012
   Ansari MS, 2020, IEEE T VLSI SYST, V28, P317, DOI 10.1109/TVLSI.2019.2940943
   Avnet, 2019, ULTRA96 V2
   Burgess N, 2019, P S COMP ARITHM, P88, DOI 10.1109/ARITH.2019.00022
   Carmichael Z, 2019, DES AUT TEST EUROPE, P1421, DOI [10.23919/DATE.2019.8715262, 10.23919/date.2019.8715262]
   Chaurasiya R, 2018, PR IEEE COMP DESIGN, P334, DOI 10.1109/ICCD.2018.00057
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cococcioni M, 2020, J REAL-TIME IMAGE PR, V17, P759, DOI 10.1007/s11554-020-00984-x
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   De la Parra C, 2020, DES AUT TEST EUROPE, P1193, DOI 10.23919/DATE48585.2020.9116476
   de Prado M., 2018, QUENN QUANTIZATION E, P1
   Deng L, 2013, IEEE INT NEW CIRC
   Ebrahimi Zahra, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P605, DOI 10.1109/ASP-DAC47756.2020.9045171
   Gupta S, 2020, IEEE ACCESS, V8, P118899, DOI 10.1109/ACCESS.2020.3005286
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Jain R., 2020, ARXIV200600364
   Jaiswal MK, 2019, IEEE ACCESS, V7, P74586, DOI 10.1109/ACCESS.2019.2920936
   Jaiswal MK, 2018, DES AUT TEST EUROPE, P1159, DOI 10.23919/DATE.2018.8342187
   Langroudi H. F., ARXIV190802386
   Langroudi HF, 2020, IEEE COMPUT SOC CONF, P3123, DOI 10.1109/CVPRW50498.2020.00371
   Langroudi HF, 2019, 2019 IEEE SPACE COMPUTING CONFERENCE (SCC), P53, DOI 10.1109/SpaceComp.2019.00011
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Murillo R, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102762
   Podobas A, 2018, IEEE SYM PARA DISTR, P138, DOI 10.1109/IPDPSW.2018.00029
   Prabakaran BS, 2018, DES AUT TEST EUROPE, P917, DOI 10.23919/DATE.2018.8342140
   Rajagopalan Vidya, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477495
   Rastegari M., 2016, XNOR NET IMAGENET CL, P1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2015, ARXIV
   Ullah S, 2021, IEEE T COMPUT, V70, P384, DOI 10.1109/TC.2020.2988404
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Vogel S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240803
   Wu, 2020, SMALLPOSITHDL
   Xiao FB, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101622
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang HQ, 2020, IEEE T KNOWL DATA EN, V32, P659, DOI [10.1109/IRMMW-THz.2019.8874163, 10.1109/TKDE.2019.2893266]
   Zhou Shuchang, 2016, ARXIV160606160
NR 44
TC 5
Z9 5
U1 0
U2 3
PY 2021
VL 9
BP 103691
EP 103708
DI 10.1109/ACCESS.2021.3098730
UT WOS:000678313700001
DA 2023-11-16
ER

PT J
AU Camsari, KY
   Sutton, BM
   Datta, S
AF Camsari, Kerem Y.
   Sutton, Brian M.
   Datta, Supriyo
TI p-bits for probabilistic spin logic
SO APPLIED PHYSICS REVIEWS
DT Review
ID MEMORY; DEVICES
AB We introduce the concept of a probabilistic or p-bit, intermediate between the standard bits of digital electronics and the emerging q-bits of quantum computing. We show that low barrier magnets or LBMs provide a natural physical representation for p-bits and can be built either from perpendicular magnets designed to be close to the in-plane transition or from circular in-plane magnets. Magnetic tunnel junctions (MTJs) built using LBMs as free layers can be combined with standard NMOS transistors to provide three-terminal building blocks for large scale probabilistic circuits that can be designed to perform useful functions. Interestingly, this three-terminal unit looks just like the 1T/MTJ device used in embedded magnetic random access memory technology, with only one difference: the use of an LBM for the MTJ free layer. We hope that the concept of p-bits and p-circuits will help open up new application spaces for this emerging technology. However, a p-bit need not involve an MTJ; any fluctuating resistor could be combined with a transistor to implement it, while completely digital implementations using conventional CMOS technology are also possible. The p-bit also provides a conceptual bridge between two active but disjoint fields of research, namely, stochastic machine learning and quantum computing. First, there are the applications that are based on the similarity of a p-bit to the binary stochastic neuron (BSN), a well-known concept in machine learning. Three-terminal p-bits could provide an efficient hardware accelerator for the BSN. Second, there are the applications that are based on the p-bit being like a poor man's q-bit. Initial demonstrations based on full SPICE simulations show that several optimization problems, including quantum annealing are amenable to p-bit implementations which can be scaled up at room temperature using existing technology. Published under license by AIP Publishing.
C1 [Camsari, Kerem Y.; Sutton, Brian M.; Datta, Supriyo] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Camsari, KY (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Albash T, 2018, REV MOD PHYS, V90, DOI 10.1103/RevModPhys.90.015002
   Amit D. J., 1992, MODELING BRAIN FUNCT
   [Anonymous], 2014, 2014 IEEE INT EL DEV
   [Anonymous], P 75 ANN DEV RES C D, DOI DOI 10.1109/DRC.2017.7999423
   [Anonymous], 2018, SCI REP-UK, DOI DOI 10.1038/s41598-017-17765-5
   [Anonymous], 2018, ARXIV181007144
   [Anonymous], 2017, ARXIV170908102
   [Anonymous], 2002, PREDICTIVE TECHNOLOG
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Atxitia U., 2018, ARXIV180807665
   Bapna M, 2017, APPL PHYS LETT, V111, DOI 10.1063/1.5012091
   Behin-Aein Behtash, 2012, ESSDERC 2012 - 42nd European Solid State Device Research Conference, P36, DOI 10.1109/ESSDERC.2012.6343328
   Behin-Aein B., 2014, U.S. Patent, Patent No. [8 698 517, 8698517]
   Behin-Aein B, 2016, SCI REP-UK, V6, DOI 10.1038/srep29893
   Bhatti S, 2017, MATER TODAY, V20, P530, DOI 10.1016/j.mattod.2017.07.007
   Biswas AK, 2017, NANO LETT, V17, P3478, DOI 10.1021/acs.nanolett.7b00439
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Bucci M, 2003, IEEE T COMPUT, V52, P403, DOI 10.1109/TC.2003.1190581
   Camsari KY, 2018, PHYS REV APPL, V9, DOI 10.1103/PhysRevApplied.9.044020
   Camsari KY, 2017, IEEE ELECTR DEVICE L, V38, P1767, DOI 10.1109/LED.2017.2768321
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Camsari KY, 2016, IEEE MAGN LETT, V7, DOI 10.1109/LMAG.2016.2610942
   Camsari KY, 2015, SCI REP-UK, V5, DOI 10.1038/srep10571
   Chakrapani LN, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255466
   Cheemalavagu Suresh, 2005, P IFIP INT
   Chen E, 2010, IEEE T MAGN, V46, P1873, DOI 10.1109/TMAG.2010.2042041
   Cowburn RP, 1999, PHYS REV LETT, V83, P1042, DOI 10.1103/PhysRevLett.83.1042
   Debashis P., 2016, P 2016 IEEE INT EL D
   Debashis P, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2860547
   Di Ventra M, 2018, J APPL PHYS, V123, DOI 10.1063/1.5026506
   Faria R., ACCELERATING M UNPUB
   Faria R, 2017, IEEE MAGN LETT, V8, DOI 10.1109/LMAG.2017.2685358
   FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   Fukushima A, 2014, APPL PHYS EXPRESS, V7, DOI 10.7567/APEX.7.083001
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Grollier J, 2016, P IEEE, V104, P2024, DOI 10.1109/JPROC.2016.2597152
   Hassan O., 2018, ARXIV180109026CS
   Henelius P., ARXIV11021296CONDMAT
   Hinton G. E., 2012, NEURAL NETWORKS TRIC, P599, DOI 10.1007/978-3-642-35289-8_32
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Johnson MW, 2011, NATURE, V473, P194, DOI 10.1038/nature10012
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lemieux G, 2004, DESIGN INTERCONNECTI
   LEWIS TG, 1973, J ACM, V20, P456, DOI 10.1145/321765.321777
   Liyanagedera CM, 2017, PHYS REV APPL, V8, DOI 10.1103/PhysRevApplied.8.064017
   Locatelli N, 2014, PHYS REV APPL, V2, DOI 10.1103/PhysRevApplied.2.034009
   Locatelli N, 2014, NAT MATER, V13, P11, DOI [10.1038/NMAT3823, 10.1038/nmat3823]
   Lopez-Diaz L, 2002, PHYS REV B, V65, DOI 10.1103/PhysRevB.65.224406
   Lucas A, 2014, FRONT PHYS-LAUSANNE, V2, DOI 10.3389/fphy.2014.00005
   Lv Y., 2017, EL DEV M IEDM 2017 I, P36
   Lyle A, 2011, IEEE T MAGN, V47, P2970, DOI 10.1109/TMAG.2011.2158527
   Manipatruni S, 2018, NAT PHYS, V14, P338, DOI 10.1038/s41567-018-0101-4
   Matsunaga S, 2008, APPL PHYS EXPRESS, V1, DOI 10.1143/APEX.1.091301
   McMahon PL, 2016, SCIENCE, V354, P614, DOI 10.1126/science.aah5178
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mizrahi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03963-w
   Mooij JE, 1999, SCIENCE, V285, P1036, DOI 10.1126/science.285.5430.1036
   MURTY KG, 1987, MATH PROGRAM, V39, P117, DOI 10.1007/BF02592948
   NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6
   Nikonov DE, 2015, IEEE J EXPLOR SOLID-, V1, P3, DOI 10.1109/JXCDC.2015.2418033
   Ohno H., 2010, P 2010 IEEE INT EL D, P9
   Parks B, 2018, AIP ADV, V8, DOI 10.1063/1.5006422
   Peng XH, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.220405
   Pervaiz A. Z., IEEE T NEURAL NETWOR
   Pervaiz AZ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11011-8
   Querlioz D, 2015, P IEEE, V103, P1398, DOI 10.1109/JPROC.2015.2437616
   Salakhutdinov R., 2007, P 24 INT C MACHINE L, V227, P791
   Sengupta A, 2016, IEEE T ELECTRON DEV, V63, P2963, DOI 10.1109/TED.2016.2568762
   Sharmin S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11732-w
   SHIBATA T, 1992, IEEE T ELECTRON DEV, V39, P1444, DOI 10.1109/16.137325
   Shim Y, 2017, J APPL PHYS, V121, DOI 10.1063/1.4983636
   Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011
   Sutton B, 2017, SCI REP-UK, V7, DOI 10.1038/srep44370
   Traversa FL, 2017, CHAOS, V27, DOI 10.1063/1.4975761
   Tylman W, 2016, COMPUT BIOL MED, V69, P245, DOI 10.1016/j.compbiomed.2015.08.015
   Van Vaerenbergh T., 2018, P SOC PHOTO-OPT INS, V10537
   Vincent AF, 2015, IEEE T BIOMED CIRC S, V9, P166, DOI 10.1109/TBCAS.2015.2414423
   Vodenicarevic D, 2017, PHYS REV APPL, V8, DOI 10.1103/PhysRevApplied.8.054045
   Vodenicarevic D, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351771
   Wang JG, 2005, J APPL PHYS, V97, DOI 10.1063/1.1857655
   Yamaoka M, 2016, IEEE J SOLID-ST CIRC, V51, P303, DOI 10.1109/JSSC.2015.2498601
   Yao XF, 2012, IEEE T NANOTECHNOL, V11, P120, DOI 10.1109/TNANO.2011.2158848
   Zand R, 2018, PR GR LAK SYMP VLSI, P15, DOI 10.1145/3194554.3194558
NR 86
TC 92
Z9 93
U1 6
U2 46
PD MAR
PY 2019
VL 6
IS 1
AR 011305
DI 10.1063/1.5055860
UT WOS:000462883500005
DA 2023-11-16
ER

PT J
AU Ahmed, H
   Ismail, MA
AF Ahmed, Hameeza
   Ismail, Muhammad Ali
TI Towards a Novel Framework for Automatic Big Data Detection
SO IEEE ACCESS
DT Article
DE Big Data; Feature extraction; Tools; Hardware; Software; Measurement;
   Optimization; Big data (3Vs); detection; LLVM; machine learning
ID BENCHMARK SUITE; INTERNET; COMPILER; CHALLENGES; MAPREDUCE; RUNTIME;
   THINGS; IOT
AB Big data is a relative concept. It is the combination of data, application, and platform properties. Recently, big data specific technologies have emerged, including software frameworks, databases, hardware accelerators, storage technologies, etc. However, the automatic selection of these solutions for big data computations remains a non-trivial task. Presently, the big data tools are selected by analyzing the problem manually, or by using several performance prediction techniques. The manual identification is based on the data properties only, whereas the performance predictors only estimate basic execution metrics without linking them with big data (3Vs) thresholds. Hence, both ways of identification are mostly incorrect, which can lead to inefficient use of 3Vs optimizations, resulting into global inefficiency, reduced system performance, increasing power consumption, requiring greater effort on the part of the programming team, and misallocation of the hardware resources required for the task. In this regard, a novel framework has been proposed for automatic detection of 3Vs (Volume, Velocity, Variety) of big data, using machine learning. The detection is done through static code features, data, and platform properties, leading to relevant tool selection, and code generation, with minimal overheads, lesser programmer interventions, higher usability, and portability. Instead of handling each application with big data specialized solutions, or manually identifying the 3Vs, the framework can automatically detect and link the 3Vs to the relevant optimizations. Several standard applications have been tested using the proposed framework. In the case of volume, the average detection accuracy is up to 97.8% for seen and 95.9% for unseen applications. In the case of velocity, the average detection accuracy is up to 97.3% for seen and 92.6%; for unseen applications. There is no margin of error in variety detection, as it has straightforward computations without any predictions. Furthermore, an airline recommendation system case study strengthens the effectiveness of the proposed approach.
C1 [Ahmed, Hameeza; Ismail, Muhammad Ali] NED Univ Engn & Technol, Dept Comp & Informat Syst Engn, Karachi 75270, Pakistan.
RP Ahmed, H (corresponding author), NED Univ Engn & Technol, Dept Comp & Informat Syst Engn, Karachi 75270, Pakistan.
EM hameeza@neduet.edu.pk
CR Anghel A, 2016, INT J PARALLEL PROG, V44, P924, DOI 10.1007/s10766-016-0410-0
   [Anonymous], 2019, GREP BENCH
   [Anonymous], 2019, C NEURAL NETWORK LIB
   [Anonymous], 2012, LINEAR REGRESSION AN
   Ashouri AH, 2018, SPRINGERBR APPL SCI, P1, DOI 10.1007/978-3-319-71489-9
   Awad M, 2015, EFFICIENT LEARNING M, P67, DOI [DOI 10.1007/978-1-4302-5990-9_4, 10.1007/978-1-4302-5990-9_4]
   Basanta-Val Pablo, 2016, IEEE Transactions on Big Data, V2, P310, DOI 10.1109/TBDATA.2016.2622719
   Belcastro L, 2019, INT J PARALLEL EMERG, V34, P632, DOI 10.1080/17445760.2017.1422501
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Chan Y, 2017, IEEE T BIG DATA, V3, P262, DOI 10.1109/TBDATA.2017.2666201
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen C, 2018, IEEE T PARALL DISTR, V29, P1275, DOI 10.1109/TPDS.2018.2794343
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Cherkassky V, 2002, LECT NOTES COMPUT SC, V2415, P687
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Dautov R, 2017, IEEE INT CONF BIG DA, P2843, DOI 10.1109/BigData.2017.8258252
   Dittrich J, 2012, PROC VLDB ENDOW, V5, P2014, DOI 10.14778/2367502.2367562
   Emani CK, 2015, COMPUT SCI REV, V17, P70, DOI 10.1016/j.cosrev.2015.05.002
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Gao WL, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243190
   Ge M, 2018, FUTURE GENER COMP SY, V87, P601, DOI 10.1016/j.future.2018.04.053
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Hirzel M, 2013, IBM J RES DEV, V57, DOI 10.1147/JRD.2013.2243535
   Huang W., 2017, BAYESIAN INFERENCE
   Inoubli W, 2018, FUTURE GENER COMP SY, V86, P546, DOI 10.1016/j.future.2018.04.032
   Jagadish HV, 2015, BIG DATA RES, V2, P49, DOI 10.1016/j.bdr.2015.01.005
   Jin XL, 2015, BIG DATA RES, V2, P59, DOI 10.1016/j.bdr.2015.01.006
   Jirkovsky V, 2017, IEEE T IND INFORM, V13, P660, DOI 10.1109/TII.2016.2596101
   Kiriansky V, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P299, DOI 10.1145/2967938.2967948
   Kruse M., 2014, ARXIV14092089
   Kuo S. M., 2006, INTRO REAL TIME DIGI, P1
   Li YY, 2020, NEUROCOMPUTING, V418, P36, DOI 10.1016/j.neucom.2020.07.059
   Mariani G, 2018, FUTURE GENER COMP SY, V87, P618, DOI 10.1016/j.future.2017.10.048
   Mariani G, 2016, INT J PARALLEL PROG, V44, P975, DOI 10.1007/s10766-016-0412-y
   Mayer G, 2018, SLEEP DISORDERS IN NEUROLOGY: A PRACTICAL APPROACH, 2ND EDITION, P47
   Mustafa S, 2018, ALEX ENG J, V57, P3767, DOI 10.1016/j.aej.2018.03.006
   Myung R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091340
   Nai LF, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807626
   Nguyen K, 2015, ACM SIGPLAN NOTICES, V50, P675, DOI [10.1145/2694344.2694345, 10.1145/2775054.2694345]
   Rao TR, 2019, KNOWL INF SYST, V60, P1165, DOI 10.1007/s10115-018-1248-0
   Rodríguez-Mazahua L, 2016, J SUPERCOMPUT, V72, P3073, DOI 10.1007/s11227-015-1501-1
   Rubiano T., 2017, THESIS
   Sakr S, 2017, IT PROF, V19, P34, DOI 10.1109/MITP.2017.6
   Schiller Benjamin, 2016, Appl Netw Sci, V1, P9, DOI 10.1007/s41109-016-0011-2
   Sidhanta S, 2021, IEEE T BIG DATA, V7, P115, DOI 10.1109/TBDATA.2019.2908188
   Stevens W. Richard, 2008, ADV PROGRAMMING UNIX
   Strohbach M, 2015, MODEL OPTIM SCI TECH, V4, P257, DOI 10.1007/978-3-319-09177-8_11
   Tetzlaff Dirk, 2013, 2013 Second International Conference on Informatics & Applications (ICIA), P234, DOI 10.1109/ICoIA.2013.6650262
   Thoman P, 2019, J SIGNAL PROCESS SYS, V91, P303, DOI 10.1007/s11265-018-1356-9
   Thomas S, 2014, I S WORKL CHAR PROC, P76, DOI 10.1109/IISWC.2014.6983043
   Triantafyllis S, 2003, INT SYM CODE GENER, P204, DOI 10.1109/CGO.2003.1191546
   Tsai LJ, 2018, IEEE T PARALL DISTR, V29, P1332, DOI 10.1109/TPDS.2018.2800011
   Tumeo A, 2015, COMPUTER, V48, P14, DOI 10.1109/MC.2015.233
   Venkataraman S, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P363
   Wang KW, 2015, IEEE I C EMBED SOFTW, P166, DOI 10.1109/HPCC-CSS-ICESS.2015.246
   Wang L, 2014, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA.2014.6835958
   Wang Z, 2018, P IEEE, V106, P1879, DOI 10.1109/JPROC.2018.2817118
   Wongthongtham P, 2017, COMPUT COMMUN NETW S, P41, DOI 10.1007/978-3-319-70102-8_3
   Yoo RM, 2009, I S WORKL CHAR PROC, P198, DOI 10.1109/IISWC.2009.5306783
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   Zhang H, 2015, IEEE T KNOWL DATA EN, V27, P1920, DOI 10.1109/TKDE.2015.2427795
   Zhang YQ, 2016, P IEEE, V104, P2114, DOI 10.1109/JPROC.2016.2591592
NR 63
TC 2
Z9 2
U1 0
U2 7
PY 2020
VL 8
BP 186304
EP 186322
DI 10.1109/ACCESS.2020.3030562
UT WOS:000583566900001
DA 2023-11-16
ER

PT C
AU Pal, S
   Feng, SY
   Park, DH
   Kim, S
   Amarnath, A
   Yang, CS
   He, X
   Beaumont, J
   May, K
   Xiong, Y
   Kaszyk, K
   Morton, JM
   Sun, JW
   O'Boyle, M
   Cole, M
   Chakrabarti, C
   Blaauw, D
   Kim, HS
   Mudge, T
   Dreslinski, R
AF Pal, Subhankar
   Feng, Siying
   Park, Dong-hyeon
   Kim, Sung
   Amarnath, Aporva
   Yang, Chi-Sheng
   He, Xin
   Beaumont, Jonathan
   May, Kyle
   Xiong, Yan
   Kaszyk, Kuba
   Morton, John Magnus
   Sun, Jiawen
   O'Boyle, Michael
   Cole, Murray
   Chakrabarti, Chaitali
   Blaauw, David
   Kim, Hun-Seok
   Mudge, Trevor
   Dreslinski, Ronald
GP ASSOC COMP MACHINERY
TI Transmuter: Bridging the Efficiency Gap using Memory and Dataflow
   Reconfiguration
SO PACT '20: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON PARALLEL
   ARCHITECTURES AND COMPILATION TECHNIQUES
SE International Conference on Parallel Architectures and Compilation
   Techniques
DT Proceedings Paper
CT ACM International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY OCT 03-07, 2020
CL ELECTR NETWORK
DE Reconfigurable architectures; memory reconfiguration; dataflow
   reconfiguration; hardware acceleration; general-purpose acceleration
ID ARCHITECTURE; STANDARD; PROCESSORS; CIRCUITS
AB With the end of Dennard scaling and Moore's law, it is becoming increasingly difficult to build hardware for emerging applications that meet power and performance targets, while remaining flexible and programmable for end users. This is particularly true for domains that have frequently changing algorithms and applications involving mixed sparse/dense data structures, such as those in machine learning and graph analytics. To overcome this, we present a flexible accelerator called Transmuter, in a novel effort to bridge the gap between General-Purpose Processors (GPPs) and Application-Specific Integrated Circuits (ASICs). Transmuter adapts to changing kernel characteristics, such as data reuse and control divergence, through the ability to reconfigure the on-chip memory type, resource sharing and dataflow at run-time within a short latency. This is facilitated by a fabric of light-weight cores connected to a network of reconfigurable caches and crossbars. Transmuter addresses a rapidly growing set of algorithms exhibiting dynamic data movement patterns, irregularity, and sparsity, while delivering GPU-like efficiencies for traditional dense applications. Finally, in order to support programmability and ease-of-adoption, we prototype a software stack composed of low-level runtime routines, and a high-level language library called TransPy, that cater to expert programmers and end-users, respectively.
   Our evaluations with Transmut er demonstrate average throughput (energy-efficiency) improvements of 5.0x (18.4x) and 4.2x (4.0x) over a high-end CPU and GPU, respectively, across a diverse set of kernels predominant in graph analytics, scientific computing and machine learning. Transmut er achieves energy-efficiency gains averaging 3.4x and 2.0x over prior FPGA and CGRA implementations of the same kernels, while remaining on average within 9.3x of state-of-the-art ASICs.
C1 [Pal, Subhankar; Feng, Siying; Park, Dong-hyeon; Kim, Sung; Amarnath, Aporva; Yang, Chi-Sheng; He, Xin; Beaumont, Jonathan; May, Kyle; Blaauw, David; Kim, Hun-Seok; Mudge, Trevor; Dreslinski, Ronald] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Xiong, Yan; Chakrabarti, Chaitali] Arizona State Univ, Tempe, AZ 85287 USA.
   [Kaszyk, Kuba; Morton, John Magnus; Sun, Jiawen; O'Boyle, Michael; Cole, Murray] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
RP Pal, S (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM subh@umich.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abeyratne N, 2013, INT S HIGH PERF COMP, P496
   Adelson E., 1983, RCA ENG, V29, P33
   Akbari Omid, 2019, IEEE T COMPUTER AIDE
   Anandkumar Anima, 2012, ABS12107559
   [Anonymous], 2013, 2013 IEEE HIGH PERFO
   [Anonymous], 2012, P 26 ACM INT C SUPER
   [Anonymous], 2013, P 27 INT ACM C INT C
   Ayhan T, 2014, EUR SIGNAL PR CONF, P266
   Bacon DF, 2013, COMMUN ACM, V56, P56, DOI 10.1145/2436256.2436271
   Balasubramonian R., 2009, HP LAB
   Banakar R, 2002, CODES 2002: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON HARDWARE/SOFTWARE CODESIGN, P73, DOI 10.1109/CODES.2002.1003604
   Bell N, 2012, SIAM J SCI COMPUT, V34, pC123, DOI 10.1137/110838844
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Binkert NL, 2006, IEEE MICRO, V26, P52, DOI 10.1109/MM.2006.82
   Buck Ian, 2010, P GPU TECHN C 2010, P11
   Burtscher M., 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P141, DOI 10.1109/IISWC.2012.6402918
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Calhoun BH, 2010, P IEEE, V98, P267, DOI 10.1109/JPROC.2009.2037211
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cuturi Marco, 2013, ADV NEURAL INFORM PR, V26
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   Davidson S, 2018, IEEE MICRO, V38, P30, DOI 10.1109/MM.2018.022071133
   Ding CHQ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P107, DOI 10.1109/ICDM.2001.989507
   Dongwook Lee, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P376, DOI 10.1109/FPT.2009.5377609
   Donnat C, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1320, DOI 10.1145/3219819.3220025
   Dorrance Richard, 2014, PROC ISFPGA, P161
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Farahini N, 2013, IEEE INT SYMP CIRC S, P1448, DOI 10.1109/ISCAS.2013.6572129
   Fatahalian Kayvon, 2004, P ACM SIGGRAPH EUROG, P133
   Feng SY, 2019, INT SYM PERFORM ANAL, P202, DOI 10.1109/ISPASS.2019.00033
   Filipovic J, 2015, J SUPERCOMPUT, V71, P3934, DOI 10.1007/s11227-015-1483-z
   Fricke Florian, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P661, DOI 10.1007/978-3-319-78890-6_53
   Fujii Y, 2013, INT C PAR DISTRIB SY, P275, DOI 10.1109/ICPADS.2013.47
   Fujimoto N, 2008, PARALLEL PROCESS LET, V18, P511, DOI 10.1142/S0129626408003545
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Giefers H, 2016, J SIGNAL PROCESS SYS, V85, P307, DOI 10.1007/s11265-015-1057-6
   Giefers H, 2016, INT SYM PERFORM ANAL, P46, DOI 10.1109/ISPASS.2016.7482073
   Goldstein SC, 2000, COMPUTER, V33, P70, DOI 10.1109/2.839324
   Govindaraju V, 2011, INT S HIGH PERF COMP, P503, DOI 10.1109/HPCA.2011.5749755
   Halfhill Tom R, 2006, MICROPROCESSOR REPOR, V20, P19
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   HUGHES RA, 1986, P IEEE, V74, P1775, DOI 10.1109/PROC.1986.13691
   Ipek E, 2007, CONF PROC INT SYMP C, P186, DOI 10.1145/1273440.1250686
   ITOH S, 1995, COMPUT PHYS COMMUN, V88, P173, DOI 10.1016/0010-4655(95)00031-A
   Jackson Preston A., 2004, HIGH PERFORMANCE EMB
   Jakob W., 2017, PYBIND11 SEAMLESS OP
   Jeloka S, 2014, INT SYMP MICROARCH, P471, DOI 10.1109/MICRO.2014.45
   JOHNSON KT, 1993, COMPUTER, V26, P20, DOI 10.1109/2.241423
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karunaratne M, 2017, DES AUT CON, DOI 10.1145/3061639.3062262
   Kelm JH, 2009, CONF PROC INT SYMP C, P140, DOI 10.1145/1555815.1555774
   Kepner Jeremy, 2016, 2016 IEEE HIGH PERF, P1, DOI [10.1109/HPEC.2016.7761646, DOI 10.1109/HPEC.2016.7761646]
   Khubaib, 2012, INT SYMP MICROARCH, P305, DOI 10.1109/MICRO.2012.36
   Kim MM, 2008, CONF PROC INT SYMP C, P101, DOI 10.1109/ISCA.2008.25
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Kuon Ian, 2008, FPGA ARCHITECTURE SU
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Kuzmanov Georgi, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P483, DOI 10.1109/FPT.2009.5377625
   Lee BC, 2004, PROC INT CONF PARAL, P169
   Lee CC, 2016, ELEC COMP C, P1439, DOI 10.1109/ECTC.2016.348
   Lee CH, 2015, KNOWL-BASED SYST, V85, P71, DOI 10.1016/j.knosys.2015.04.020
   Liang C, 2008, IEEE WRK SIG PRO SYS, P257, DOI 10.1109/SIPS.2008.4671772
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Liu LB, 2015, IEEE T MULTIMEDIA, V17, P1706, DOI 10.1109/TMM.2015.2463735
   Logan Beth, 2000, ISMIR, V270, P1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Magaki I, 2016, CONF PROC INT SYMP C, P178, DOI 10.1109/ISCA.2016.25
   Mai K, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P161, DOI [10.1109/ISCA.2000.854387, 10.1145/342001.339673]
   Marcin J., 2018, P ACL 2018 SYST DEM, P116, DOI DOI 10.18653/V1/P18-4020
   Mattson T, 2013, IEEE HIGH PERF EXTR
   Merity Stephen, 2018, ANAL NEURAL LANGUAGE
   Mohapatra BN, 2017, INT CONF WIREL OPT
   Mueller Frank, 1993, PTHREADS LIB INTERFA
   Nicol Chris, 2017, CISC VIS NETW IND GL
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   O'Neil MA, 2014, I S WORKL CHAR PROC, P130, DOI 10.1109/IISWC.2014.6983052
   Ovtcharov K., 2015, MICROSOFT RES WHITEP, V2, P1
   Pal S, 2019, SYMP VLSI CIRCUITS, pC150
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Park DH, 2020, IEEE J SOLID-ST CIRC, V55, P933, DOI 10.1109/JSSC.2019.2960480
   Pedram A, 2014, J SIGNAL PROCESS SYS, V77, P169, DOI 10.1007/s11265-014-0896-x
   Pedram A, 2011, IEEE INT CONF ASAP, P35, DOI 10.1109/ASAP.2011.6043234
   Penn G, 2006, THEOR COMPUT SCI, V354, P72, DOI 10.1016/j.tcs.2005.11.008
   Poon KKW, 2005, ACM T DES AUTOMAT EL, V10, P279, DOI 10.1145/1059876.1059881
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Salimans Tim, 2018, ARXIV180305573
   Schuiki F, 2019, DES AUT TEST EUROPE, P662, DOI [10.23919/date.2019.8715007, 10.23919/DATE.2019.8715007]
   Sewell K, 2012, IEEE J EM SEL TOP C, V2, P278, DOI 10.1109/JETCAS.2012.2193936
   Shafique M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2633408
   Soorishetty A, 2020, INT CONF ACOUST SPEE, P1558, DOI [10.1109/ICASSP40776.2020.9054126, 10.1109/icassp40776.2020.9054126]
   Steffl S, 2017, PR IEEE COMP DESIGN, P137, DOI 10.1109/ICCD.2017.29
   Steuwer M, 2017, INT SYM CODE GENER, P74, DOI 10.1109/CGO.2017.7863730
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Swartzlander EE, 2006, IEEE INT CONF ASAP, P153
   Tan C, 2018, CONF PROC INT SYMP C, P575, DOI 10.1109/ISCA.2018.00054
   Tanomoto M, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P73, DOI 10.1109/MCSoC.2015.41
   Taylor MB, 2002, IEEE MICRO, V22, P25, DOI 10.1109/MM.2002.997877
   Tehre Vaishali, IMPLEMENTATION FAST
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Verma M, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P1264, DOI 10.1109/DATE.2004.1269069
   Vipin K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3193827
   Wang DL, 2016, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2016.7446086
   Web Chang, 2001, US Patent., Patent No. [6,260,087, 6260087]
   Weerasinghe J, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P1078, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.199
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Xilinx, PART REC US GUID UG7
   Xin He, 2020, ICS '20: Proceedings of the 34th ACM International Conference on Supercomputing, DOI 10.1145/3392717.3392751
   Yamazaki I, 2011, LECT NOTES COMPUT SC, V6449, P421, DOI 10.1007/978-3-642-19328-6_38
   Ye FH, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1393, DOI 10.1145/3269206.3271697
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 119
TC 10
Z9 10
U1 2
U2 2
PY 2020
BP 175
EP 190
DI 10.1145/3410463.3414627
UT WOS:000723645400018
DA 2023-11-16
ER

PT C
AU Jia, DL
   Yuan, G
   Lin, X
   Mi, NF
AF Jia, Danlin
   Yuan, Geng
   Lin, Xue
   Mi, Ningfang
BE Ardagna, CA
   Atukorala, N
   Buyya, R
   Chang, CK
   Chang, RN
   Damiani, E
   Dasgupta, GB
   Gagliardi, F
   Hagleitner, C
   Milojicic, D
   Trong, TMH
   Ward, R
   Xhafa, F
   Zhang, J
TI A Data-Loader Tunable Knob to Shorten GPU Idleness for Distributed Deep
   Learning
SO 2022 IEEE 15TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (IEEE CLOUD
   2022)
SE IEEE International Conference on Cloud Computing
DT Proceedings Paper
CT 15th IEEE International Conference on Cloud Computing (IEEE CLOUD) /
   IEEE World Congress on Services (IEEE SERVICES)
CY JUL 11-15, 2022
CL Barcelona, SPAIN
AB Deep Neural Network (DNN) has been applied as an effective machine learning algorithm to tackle problems in different domains. However, training a sophisticated DNN model takes days to weeks and becomes a challenge in constructing research on large-scale DNN models. Distributed Deep Learning (DDL) contributes to accelerating DNN training by distributing training workloads across multiple computation accelerators (e.g., GPUs). Although a surge of research works has been devoted to optimizing DDL training, the impact of data-loading on GPU usage and training performance has been relatively under-explored. It is non-trivial to optimize data-loading in DDL applications that need intensive CPU and I/O resources to process enormous training data. When multiple DDL applications are deployed on a system (e.g., Cloud and HPC), the lack of a practical and efficient technique for data-loader allocation incurs GPU idleness and degrades the training throughput. Therefore, our work first focuses on investigating the impact of data-loading on the global training throughput. We then propose a throughput prediction model to predict the maximum throughput for an individual DDL training application. By leveraging the predicted results, A-Dloader is designed to dynamically allocate CPU and I/O resources to concurrently running DDL applications and use the data-loader allocation as a knob to reduce GPU idle intervals and thus improve the overall training throughput. We implement and evaluate A-Dloader in a DDL framework for a series of DDL applications arriving and completing across the runtime. Our experimental results show that A-Dloader can achieve a 23.5% throughput improvement and a 10% makespan improvement, compared to allocating resources evenly across applications.
C1 [Jia, Danlin; Yuan, Geng; Lin, Xue; Mi, Ningfang] Northeastern Univ, Boston, MA 02115 USA.
RP Jia, DL (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM jia.da@northeastern.edu; yuan.geng@northeastern.edu;
   xue.lin@northeastern.edu; ningfang@ece.neu.edu
CR Ben-Nun T, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3320060
   Evci Utku, 2020, INT C MACHINE LEARNI
   Hashemi S. H., 2019, PROC MLSYS, P418
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hindman B, 2011, 8 USENIX S NETWORKED, P295
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li S, 2020, Arxiv, DOI arXiv:2006.15704
   Mohan J, 2021, Arxiv, DOI arXiv:2007.06775
   pypi, THOP PYTORCH OPCOUNT
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vavilapalli V.K., P 4 ANN S
   Yang C.-C., 2019, 2019 IEEE 26 INT C H
   Yang CC, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P235, DOI 10.1109/HiPC.2019.00037
   Zhu HY, 2018, I S WORKL CHAR PROC, P88, DOI 10.1109/IISWC.2018.8573476
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
   Zolnouri M, 2020, Arxiv, DOI arXiv:2005.02130
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 449
EP 458
DI 10.1109/CLOUD55607.2022.00068
UT WOS:000861121600053
DA 2023-11-16
ER

PT J
AU Kontaxis, C
   Bol, GH
   Lagendijk, JJW
   Raaymakers, BW
AF Kontaxis, C.
   Bol, G. H.
   Lagendijk, J. J. W.
   Raaymakers, B. W.
TI DeepDose: Towards a fast dose calculation engine for radiation therapy
   using deep learning
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE dose engine; IMRT; deep learning; AI; treatment planning; plan
   adaptation; MR-linac
ID PLATFORM; IMPACT
AB We present DeepDose, a deep learning framework for fast dose calculations in radiation therapy. Given a patient anatomy and linear-accelerator IMRT multi-leaf-collimator shape or segment, a novel set of physics-based inputs is calculated that encode the linac machine parameters into the underlying anatomy. These inputs are then used to train a deep convolutional network to derive the dose distribution of individual MLC shapes on a given patient anatomy.
   In this work we demonstrate the proof-of-concept application of DeepDose on 101 prostate patients treated in our clinic with fixed-beam IMRT. The ground-truth data used for training, validation and testing of the prediction were calculated with a state-of-the-art Monte Carlo dose engine at 1% statistical uncertainty per segment. A deep convolution network was trained using the data of 80 patients at the clinically used 3 mm(3) grid spacing while 10 patients were used for validation.
   For another 11 independent test patients, the network was able to accurately estimate the segment doses from the clinical plans of each patient passing the clinical QA when compared with the Monte Carlo calculations, yielding on average 99.9%+/- 0.3% for the forward calculated patient plans at 3%/3 mm gamma tests. Dose prediction using the trained network was very fast at approximately 0.9 seconds for the input generation and 0.6 seconds for single GPU inference per segment and 1 minute per patient in total.
   The overall performance of this dose calculation framework in terms of both accuracy and inference speed, makes it compelling for online adaptive workflows where fast segment dose calculations are needed.
C1 [Kontaxis, C.; Bol, G. H.; Lagendijk, J. J. W.; Raaymakers, B. W.] Univ Med Ctr Utrecht, Dept Radiotherapy, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
RP Kontaxis, C (corresponding author), Univ Med Ctr Utrecht, Dept Radiotherapy, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
EM c.kontaxis@umcutrecht.nl
CR AHNESJO A, 1989, MED PHYS, V16, P577, DOI 10.1118/1.596360
   Arnfield MR, 2000, MED PHYS, V27, P1266, DOI 10.1118/1.599004
   Barragan-Montero AM, 2019, MED PHYS, V46, P3679, DOI 10.1002/mp.13597
   BORTFELD TR, 1994, INT J RADIAT ONCOL, V28, P723, DOI 10.1016/0360-3016(94)90200-3
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Nguyen D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37741-x
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Henke LE, 2018, CLIN ONCOL-UK, V30, P720, DOI 10.1016/j.clon.2018.08.010
   Hissoiny S, 2011, PHYS MED BIOL, V56, P5119, DOI 10.1088/0031-9155/56/16/003
   Kontaxis C, 2017, PHYS MED BIOL, V62, P7233, DOI 10.1088/1361-6560/aa82ae
   Kontaxis C, 2015, PHYS MED BIOL, V60, P2493, DOI 10.1088/0031-9155/60/6/2493
   Krieger T, 2005, PHYS MED BIOL, V50, P859, DOI 10.1088/0031-9155/50/5/010
   Mahmood R., 2018, MACH LEARN HEALTHC C, P484
   MOHAN R, 1986, MED PHYS, V13, P64, DOI 10.1118/1.595924
   Raaijmakers AJE, 2007, PHYS MED BIOL, V52, P929, DOI 10.1088/0031-9155/52/4/005
   Rogers DWO, 2006, PHYS MED BIOL, V51, pR287, DOI 10.1088/0031-9155/51/13/R17
   Shepard DM, 2002, MED PHYS, V29, P1007, DOI 10.1118/1.1477415
   Tian Z, 2015, PHYS MED BIOL, V60, P7419, DOI 10.1088/0031-9155/60/19/7419
   Werensteijn-Honingh AM, 2019, RADIOTHER ONCOL, V134, P50, DOI 10.1016/j.radonc.2019.01.024
NR 19
TC 56
Z9 57
U1 2
U2 18
PD APR 7
PY 2020
VL 65
IS 7
AR 075013
DI 10.1088/1361-6560/ab7630
UT WOS:000525618700001
DA 2023-11-16
ER

PT C
AU Zhang, XY
   Song, SL
   Xie, CH
   Wang, J
   Zhang, WG
   Fu, X
AF Zhang, Xingyao
   Song, Shuaiwen Leon
   Xie, Chenhao
   Wang, Jing
   Zhang, Weigong
   Fu, Xin
GP IEEE
TI Enabling Highly Efficient Capsule Networks Processing Through A
   PIM-Based Architecture Design
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2020)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 26th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 22-26, 2020
CL San Diego, CA
DE Accelerators; domain-specific architectures Architecture applications of
   Machine Learning; Emerging technologies
AB In recent years, the CNNs have achieved great successes in the image processing tasks, e.g., image recognition and object detection. Unfortunately, traditional CNN's classification is found to be easily misled by increasingly complex image features due to the usage of pooling operations, hence unable to preserve accurate position and pose information of the objects. To address this challenge, a novel neural network structure called Capsule Network has been proposed, which introduces equivariance through capsules to significantly enhance the learning ability for image segmentation and object detection. Due to its requirement of performing a high volume of matrix operations, CapsNets have been generally accelerated on modern GPU platforms that provide highly optimized software library for common deep learning tasks. However, based on our performance characterization on modern GPUs, CapsNets exhibit low efficiency due to the special program and execution features of their routing procedure, including massive unshareable intermediate variables and intensive synchronizations, which are very difficult to optimize at software level. To address these challenges, we propose a hybrid computing architecture design named PIM-CapsNet. It preserves GPU's on-chip computing capability for accelerating CNN types of layers in CapsNet, while pipelining with an off-chip in-memory acceleration solution that effectively tackles routing procedure's inefficiency by leveraging the processingin -memory capability of today's 31) stacked memory. Using routing procedure's inherent parallellization feature, our design enables hierarchical improvements on CapsNet inference efficiency through minimizing data movement and maximizing parallel processing in memory. Evaluation results demonstrate that our proposed design can achieve substantial improvement on both performance and energy savings for CapsNet inference, with almost zero accuracy loss. The results also suggest good performance scalability in optimizing the routing procedure with increasing network size.
C1 [Zhang, Xingyao; Fu, Xin] Univ Houston, ECE Dept, ECOMS Lab, Houston, TX 77004 USA.
   [Song, Shuaiwen Leon] Univ Sydney, Future Syst Architecture FSA Lab, Sydney, NSW, Australia.
   [Xie, Chenhao] Pacific Northwest Natl Lab PNNL, Richland, WA USA.
   [Wang, Jing] Capital Normal Univ, Coll Informat Engn, Beijing, Peoples R China.
   [Zhang, Weigong] Beijing Adv Innovanon Ctr Imaging Theory & Techno, Beijing, Peoples R China.
RP Zhang, XY (corresponding author), Univ Houston, ECE Dept, ECOMS Lab, Houston, TX 77004 USA.
EM xzhang55@uh.edu; shuaiwen.song@sydney.edu.au; chenhao.xie@pnnl.gov;
   jwang@cnu.edu.cn; 5591@cnu.edu.cn; xfu8@central.uh.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], 2017, 22 INT C ARCHITECTUR, DOI DOI 10.1145/3037697.3037702
   [Anonymous], SCCAPSNET DEEP LEARN
   [Anonymous], P HIPEAC WAPCO AMST
   [Anonymous], CANADIAN J REMOTE SE
   [Anonymous], THESIS
   [Anonymous], ARXIV190209839
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen ZY, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P578, DOI 10.1109/HPCC/SmartCity/DSS.2018.00107
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   De Caro D, 2009, IEEE T CIRCUITS-I, V56, P1968, DOI 10.1109/TCSI.2008.2010150
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Falahati H., 2018, ARXIV181211473
   Grimmer J, 2015, PS-POLIT SCI POLIT, V48, P80, DOI 10.1017/S1049096514001784
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2014, COGNITIVE SCI, V38, P1078, DOI 10.1111/cogs.12049
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hinton Geoffrey E, 2018, INT C LEARN REPR
   Iandola Forrest N., 2016, P IEEE C COMPUTER VI
   Jeddeloh J., 2012, 2012 S VLSI TECHN VL, P87
   Jeon DI, 2018, IEEE COMPUT ARCHIT L, V17, P5, DOI 10.1109/LCA.2017.2700298
   Jiménez-Sánchez A, 2018, LECT NOTES COMPUT SC, V11043, P150, DOI 10.1007/978-3-030-01364-6_17
   Joardar BK, 2019, DES AUT TEST EUROPE, P522, DOI [10.23919/date.2019.8714802, 10.23919/DATE.2019.8714802]
   Kahan W., 1996, LECT NOTES STATUS IE, V754, P11
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   KOISTINEN P, 1992, ADV NEUR IN, V4, P1033
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Kumar A. D., 2018, ARXIV180504424, V118, P4543
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leidel JD, 2014, PARALLEL PROCESS LET, V24, DOI 10.1142/S012962641442002X
   Li C, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P633, DOI 10.1109/SC.2016.53
   Li YJ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P175, DOI 10.1109/MICRO.2018.00023
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Lomont C, 2003, FAST INVERSE SQUARE, V32
   Mao HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P669, DOI [10.1109/MICR0.2018.00060, 10.1109/MICRO.2018.00060]
   Middendorf L, 2013, COMPUT GRAPH FORUM, V32, P325, DOI 10.1111/cgf.12240
   Mobiny A, 2018, LECT NOTES COMPUT SC, V11071, P741, DOI 10.1007/978-3-030-00934-2_82
   Mukhometzianov R, 2018, ARXIV PREPRINT ARXIV
   Netzer Y., 2011, READING DIGITS NATUR, V2, P5
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Perini F, 2018, COMBUST FLAME, V194, P37, DOI 10.1016/j.combustflame.2018.04.013
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Robertson Matthew, 2012, BRIEF HIST INVSQRT
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song MC, 2017, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2017.52
   Stoutchinin Arthur, 2019, ARXIV190201492
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Xi Edgar, 2017, ARXIV171203480
   Yitbarek SF, 2016, DES AUT TEST EUROPE, P1449
   Zhang D., 2014, P 23 INT S HIGH PERF, P85
   Zhang XQ, 2019, J MED IMAG HEALTH IN, V9, P159, DOI 10.1166/jmihi.2019.2555
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zoglauer A, 2011, NUCL INSTRUM METH A, V652, P568, DOI 10.1016/j.nima.2010.08.043
NR 61
TC 12
Z9 12
U1 1
U2 5
PY 2020
BP 542
EP 555
DI 10.1109/HPCA47549.2020.00051
UT WOS:000531494100041
DA 2023-11-16
ER

PT J
AU Zhang, XY
   Fu, X
   Zhuang, DL
   Xie, CH
   Song, SL
AF Zhang, Xingyao
   Fu, Xin
   Zhuang, Donglin
   Xie, Chenhao
   Song, Shuaiwen Leon
TI Enabling Highly Efficient Capsule Networks Processing Through
   Software-Hardware Co-Design
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Accelerators; domain-specific architectures; machine learning; emerging
   technologies
ID IMAGE CLASSIFICATION
AB As the demand for the image processing increases, the image features become increasingly complicated. Although the Convolutional Neural Network (CNN) have been widely adopted for the imaging processing tasks, it has been found easily misled due to the massive usage of pooling operations. A novel neural network structure called Capsule Networks (CapsNet) is proposed to address the CNN challenge and essentially enhance the learning ability for the image segmentation and object detection. Since the CapsNet contains the high volume of the matrix execution, it has been generally accelerated on modern GPU platforms with the highly optimized deep-learning library. However, the routing procedure of CapsNet introduces the special program and execution features,including massive unshareable intermediate variables and intensive synchronizations, causing inefficient CapsNet execution on modern GPU. To address these challenges, we propose the software-hardware co-designed optimizations, SH-CapsNet, which includes the software-level optimizations named S-CapsNet and a hybrid computing architecture design named PIM-CapsNet. In software-level, S-CapsNet reduces the computation and memory accesses by exploiting the computational redundancy and data similarity of the routing procedure. In hardware-level, the PIM-CapsNet leverages the processing-in-memory capability of today's 3D stacked memory to conduct the off-chip in-memory acceleration solution for the routing procedure, while pipelining with the GPU's on-chip computing capability for accelerating CNN types of layers in CapsNet. Evaluation results demonstrate that either our software or hardware optimizations can significantly improve the CapsNet execution efficiency. Together, our co-design can achieve greatly improvement on both performance ($3.41\times$3.41x) and energy savings (68.72 percent) for CapsNet inference, with negligible accuracy loss.
C1 [Zhang, Xingyao; Fu, Xin] Univ Houston, Dept Elect & Comp Engn, Houston, TX 77004 USA.
   [Zhuang, Donglin; Song, Shuaiwen Leon] Univ Sydney, Future Syst Architecture FSA Lab, Sydney, NSW 2006, Australia.
   [Xie, Chenhao] Pacific Northwest Natl Lab PNNL, Richland, WA 99354 USA.
RP Zhang, XY (corresponding author), Univ Houston, Dept Elect & Comp Engn, Houston, TX 77004 USA.
EM zhangxyleo2013@gmail.com; xfu8@central.uh.edu; dzhu9887@sydney.edu.au;
   chenhao.xie@pnnl.gov; shuaiwen.song@sydney.edu.au
CR [Anonymous], 2017, P 31 INT C NEUR INF
   [Anonymous], NVIDIA TESLA P100 WH
   [Anonymous], OPTIMIZATIONS ACCELE
   [Anonymous], 2018, DENSE DIVERSE CAPSUL
   [Anonymous], GATE LEVEL SIMULATIO
   [Anonymous], HBM3 CHEAPER 64GB ON
   [Anonymous], 2018, P INT C LEARN REPR
   [Anonymous], HMC SPECIFICATION 21
   [Anonymous], NVIDIA PROFILER
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chacón MI, 2005, NAFIPS 2005 - 2005 Annual Meeting of the North American Fuzzy Information Processing Society, P241, DOI 10.1109/NAFIPS.2005.1548541
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Coates A., P ADV C NEUR INF PRO, V2011, P5
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Falahati H., 2018, ARXIV181211473
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   Hinton G, 2014, COGNITIVE SCI, V38, P1078, DOI 10.1111/cogs.12049
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hu X, 2018, IEEE MICRO, V38, P22, DOI 10.1109/MM.2018.011441561
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Kahan W., 1996, LECT NOTES STATUS IE, V754, P11
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kronenberger J, 2018, LECT NOTES COMPUT SC, V11141, P33, DOI 10.1007/978-3-030-01424-7_4
   Kumar A. D., 2018, ARXIV180504424, V118, P4543
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leidel JD, 2014, PARALLEL PROCESS LET, V24, DOI 10.1142/S012962641442002X
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Lomont C, 2003, FAST INVERSE SQUARE, V32
   Lopez D. A, 2018, THESIS U NEVADA RENO
   Marchisio A, 2019, DES AUT TEST EUROPE, P964, DOI [10.23919/DATE.2019.8714922, 10.23919/date.2019.8714922]
   Middendorf L, 2013, COMPUT GRAPH FORUM, V32, P325, DOI 10.1111/cgf.12240
   Mobiny A, 2018, LECT NOTES COMPUT SC, V11071, P741, DOI 10.1007/978-3-030-00934-2_82
   Robertson M, 2012, THESIS U NEW BRUNSWI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Xie CH, 2019, INT S HIGH PERF COMP, P609, DOI 10.1109/HPCA.2019.00013
   Xie CH, 2017, INT S HIGH PERF COMP, P637, DOI 10.1109/HPCA.2017.37
   Yusuf A, 2018, CAN J REMOTE SENS, V44, P532, DOI 10.1080/07038992.2018.1559725
   Zhang D., 2014, P 23 INT S HIGH PERF, P85
   Zhang XQ, 2019, J MED IMAG HEALTH IN, V9, P159, DOI 10.1166/jmihi.2019.2555
   Zhang XY, 2020, INT S HIGH PERF COMP, P542, DOI 10.1109/HPCA47549.2020.00051
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 44
TC 4
Z9 4
U1 4
U2 28
PD APR 1
PY 2021
VL 70
IS 4
BP 495
EP 510
DI 10.1109/TC.2021.3056929
UT WOS:000631200400001
DA 2023-11-16
ER

PT J
AU Tsuji, S
   Yamada, F
   Kawaguchi, H
   Inoue, A
   Sakai, Y
AF Tsuji, Satoki
   Yamada, Fuyuka
   Kawaguchi, Hiroshi
   Inoue, Atsuki
   Sakai, Yasufumi
TI Greedy search algorithm for partial quantization of convolutional neural
   networks inspired by submodular optimization
SO NEURAL COMPUTING & APPLICATIONS
DT Article; Early Access
DE Machine learning; Deep neural networks; Quantization; Neural
   architecture search; Submodular optimization
AB Recent results of studies have indicated that neural network quantization effects on inference accuracy vary among layers. Therefore, partial quantization and mixed precision quantization have been studied for neural network accelerators with multi-precision designs. However, these quantization methods typically require network training, which entails a high computational cost because of the exponentially increasing search space with respect to the number of layers N. However, an insufficient search leads to a significant degradation of inference accuracy. For partial quantization, this paper presents a greedy search algorithm that can derive practical combinations of quantization layers without re-training; notably, the proposed method exhibits particularly low computational complexity O(N-2). The proposed greedy search algorithm achieved 4.2x model size compression with only 0.03% accuracy degradation in ResNet50 and 2.5x compression with +0.015% accuracy gain in Xception. The computational cost of the greedy search algorithm was only 2.6 hours for a single V100 GPU in the case of MobileNetV2 quantization for ImageNet classification. Furthermore, we accelerated the proposed algorithm to computational complexity O(N) and achieved 4.15x model size compression with only 0.072% accuracy degradation in ResNet50.
C1 [Tsuji, Satoki; Yamada, Fuyuka] Kobe Univ, Grad Sch Syst Informat, 1-1 Rokkoudai, Kobe, Hyogo 6578501, Japan.
   [Kawaguchi, Hiroshi; Inoue, Atsuki] Kobe Univ, Grad Sch Sci Technol & Innovat, 1-1 Rokkoudai, Kobe, Hyogo 6578501, Japan.
   [Tsuji, Satoki; Yamada, Fuyuka; Sakai, Yasufumi] Fujitsu Ltd, Fujitsu Res, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
RP Tsuji, S (corresponding author), Kobe Univ, Grad Sch Syst Informat, 1-1 Rokkoudai, Kobe, Hyogo 6578501, Japan.; Tsuji, S (corresponding author), Fujitsu Ltd, Fujitsu Res, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
EM tsuji.satoki@fujitsu.com; yamada.fuyuka@fujitsu.com;
   kawapy@godzilla.kobe-u.ac.jp; ainoue@godzilla.kobe-u.ac.jp;
   sakaiyasufumi@fujitsu.com
CR Banner Ron, 2018, ARXIV181005723
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Choukroun Y, 2019, IEEE INT CONF COMP V, P3009, DOI 10.1109/ICCVW.2019.00363
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S., 2015, ADV NEURAL INFORM PR, P1135
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton Geoffrey, 2015, ARXIV150302531
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krishnamoorthi Raghuraman, 2018, ARXIV180608342
   Lin H., 2010, HUMAN LANGUAGE TECHN, P912
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Molchanov Pavlo, 2016, ARXIV161106440
   Nagel M, 2019, IEEE I CONF COMP VIS, P1325, DOI 10.1109/ICCV.2019.00141
   Nagel Markus, 2020, INT C MACH LEARN, P7197
   Nahshan Y., 2019, ARXIV PREPRINT ARXIV
   Nemhauser G. L., 1981, Studies on graphs and discrete programming, P279
   Paszke A, 2019, ADV NEUR IN, V32
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Uhlich Stefan, 2019, ARXIV190511452
   Vanhoucke V., 2011, IMPROVING SPEED NEUR
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.00881, 10.1109/CVPR.2019.01218]
   Wang TZ, 2020, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR42600.2020.00215
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu Hao, 2020, ARXIV200409602
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xie Q., 2020, P IEEE CVF C COMP VI
   Zhang Peizhao, 2018, ARXIV181200090
   Zhou Shuchang, 2016, ARXIV160606160
   Zhou YR, 2018, AAAI CONF ARTIF INTE, P4596
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zoph B, 2016, ARXIV161101578
NR 38
TC 0
Z9 0
U1 0
U2 1
PD 2022 JAN 13
PY 2022
DI 10.1007/s00521-021-06752-7
EA JAN 2022
UT WOS:000741951500007
DA 2023-11-16
ER

PT C
AU Juste, B
   Barrachina, T
   Miró, R
   Verdú, G
AF Juste, Belen
   Barrachina, Teresa
   Miro, Rafael
   Verdu, Gumersindo
BE GomezChova, L
   LopezMartinez, A
   CandelTorres, I
TI USE OF SIMULATION CODES IN NUCLEAR ENGINEERING TO INCREASE THE KNOWLEDGE
   OF RADIATION TRANSPORT THROUGH MATTER
SO EDULEARN15: 7TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES
SE EDULEARN Proceedings
DT Proceedings Paper
CT 7th International Conference on Education and New Learning Technologies
   (EDULEARN)
CY JUL 06-08, 2015
CL Barcelona, SPAIN
DE simulation; radiation transport; radiological protection; medical
   physics
AB Radiation transport through matter is a complex phenomenon whose physics can be described by the Boltzmann equation, involving the interactions of different subatomic particles, like photons, electrons and/or neutrons.
   The use of simulation become complex for undergraduate students since fields as Radiation Protection need good knowledge of several subjects as computing, a high level of mathematical skills in modeling and numerical methods or a good knowledge of the physical problem to be simulated.
   We have introduced the use of Monte Carlo radiation transport codes in the master programs taught at the Chemical and Nuclear Engineering Department at the UPV. Radiological Protection and Radiation Technology computer-aided learning courses are designed to be supported with the use of simulation techniques to analyze, design and understand the behavior of industrial of medical devices making use of ionizing radiation. These devices include radiotherapy linear accelerators, mammographic and diagnostic X-ray machines, industrial X-ray equipment, radiation detectors, etc. Then, the goal of the courses is that students develop the capabilities necessaries to face complex problems, using computer codes as a tool.
C1 [Juste, Belen; Barrachina, Teresa; Miro, Rafael; Verdu, Gumersindo] Univ Politecn Valencia, DIQN, E-46022 Valencia, Spain.
   [Barrachina, Teresa] Univ Politecn Valencia, DEIOAC, E-46022 Valencia, Spain.
RP Juste, B (corresponding author), Univ Politecn Valencia, DIQN, E-46022 Valencia, Spain.
CR Barrows H.S., 1980, PROBLEM BASED LEARNI
   James M. R., 2014, LACP1400745 LOS AL N
   Martz Roger L., LAUR1105668 TN GEN D
NR 3
TC 0
Z9 0
U1 0
U2 3
PY 2015
BP 6655
EP 6659
UT WOS:000376685706104
DA 2023-11-16
ER

PT C
AU Romero, P
   Idler, C
AF Romero, Phil
   Idler, Craig
GP IEEE
TI Methodologies and Application of Machine Learning Algorithms to Classify
   the Performance of High Performance Cluster Components
SO 2014 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)
SE IEEE International Conference on Cluster Computing
DT Proceedings Paper
CT 16th IEEE International Conference on Cluster Computing (CLUSTER)
CY SEP 22-26, 2014
CL Madrid, SPAIN
AB High Performance Computing Clusters are designed to host highly parallelized applications, often in excess of thousands of nodes allocated to a job. These jobs, especially those that require a high level of synchronous communication, can be greatly affected by a single poor, or even sub-standard performing component. These components, often referred to as a node, are typically comprised of CPUs, accelerator processors, memory, a communication bus, and so on. Consequently it is important to identify and eliminate these sub-standard performing nodes before a job is scheduled onto them.
   In this paper we will describe the process used to measure and the methodology used to quantify poor performing nodes or classify suspect performing nodes into groups, or clusters, that can be later used to identify future performance issues. This process is more involved than simply running a scientific calculation across all the nodes, finding one that was "slow", and labeling it as a bad node. At Los Alamos, this methodology has been used successfully to find problem nodes and has helped characterize the components of other clusters to aid in the proactive elimination of potential problems.
C1 [Romero, Phil] Los Alamos Natl Lab, High Performance Comp 1, Los Alamos, NM 87545 USA.
   [Idler, Craig] Los Alamos Natl Lab, High Performance Comp 5, Los Alamos, NM USA.
RP Romero, P (corresponding author), Los Alamos Natl Lab, High Performance Comp 1, Los Alamos, NM 87545 USA.
EM prr@lanl.gov; cwi@lanl.gov
CR Abdi Herve, 2010, WILEY INTERDISCIPLIN
   Antoine, 2001, LINPACK BENCHMARK PR
   Coates A., 2012, NEURAL NETWORKS TRIC
   Danalis A, 2010, SCALABLE HETEROGENEO
   Ketchen Jr David J., 1996, STRATEGIC MANAGEMENT, V17
   Madhulatha T. Soni, 2011, INT J ADV COMPUT APR
   Tibshirani R., 2001, J ROYAL STAT SOC B
   van der Maaten L., 2013, P INT C LEARN REPR
NR 8
TC 0
Z9 0
U1 0
U2 0
PY 2014
BP 400
EP 407
UT WOS:000411853200058
DA 2023-11-16
ER

PT J
AU Selmi, R
   Hammoudeh, S
   Errami, Y
   Wohar, ME
AF Selmi, Refk
   Hammoudeh, Shawkat
   Errami, Youssef
   Wohar, Mark E.
TI Is COVID-19 Related Anxiety an Accelerator for Responsible and
   Sustainable Investing ? A Sentiment Analysis
SO APPLIED ECONOMICS
DT Article
DE COVID-19; anxiety; environmental and social responsibilities; Sentiment
   analysis
ID LONG-RUN CAUSALITY; TIME-SERIES
AB The excessive volatility generated by the COVID-19 pandemic highlights that environmental and social issues are potential elements that businesses and governments must manage effectively and swiftly. This study seeks to test whether the rising anxiety over this pandemic has affected the attitudes and choices towards environmentally and socially responsible investing. To this end, we first use machine learning tools to examine tweets related to this unprecedented and wild shock. Second, we compare the impact of these sentiments on the stock performance of companies from the S&P500 that meet environmental and social sustainability criteria for three COVID-19 phases with varying levels of anxiety, which we label incubation, fever and the increasing risk of second wave pandemic (in the absence of vaccine). Our findings reveal that the increasing uncertainty and worries over COVID-19 and its consequences has not distracted investors' attention away from environmental and social issues, but companies with responsible strategies on environmental issues that specifically address climate responsibility are likely to be more responsive to sentiments at the current situation of emergency.
C1 [Selmi, Refk; Errami, Youssef] ESC Pau Business Sch, Pau, France.
   [Hammoudeh, Shawkat] Drexel Univ, Lebow Coll Business, Philadelphia, PA USA.
   [Wohar, Mark E.] Univ Econ, Inst Business Res, Ho Chi Minh, Vietnam.
   Univ Nebraska, Coll Business Adm, Sch Business & Econ, Omaha, NE 68182 USA.
RP Wohar, ME (corresponding author), Univ Nebraska, Coll Business Adm, Omaha, NE 68182 USA.
EM mwohar@mail.unomaha.edu
CR Breitung J, 2006, J ECONOMETRICS, V132, P363, DOI 10.1016/j.jeconom.2005.02.004
   Brock WA, 1996, ECONOMET REV, V15, P197, DOI [DOI 10.1080/07474939608800353, DOI 10.1080/2F07474939608800353.NUME]
   Dufour JM, 2006, J ECONOMETRICS, V132, P337, DOI 10.1016/j.jeconom.2005.02.003
   Dufour JM, 1998, ECONOMETRICA, V66, P1099, DOI 10.2307/2999631
   Fernandez M, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P85, DOI 10.1145/2908131.2908167
   Garel A, 2020, INVESTOR REWARDS ENV
   Hodson J., 2018, INTERDISCIPLINARY EN, V12, P17
   Jost F., ENV SCI POLICY
   O'Brien K, 2015, SCIENCE, V350, P1170, DOI 10.1126/science.aad0267
   Porshnev A., SSRN ELECT J
   Scharl A, 2017, IEEE SYST J, V11, P762, DOI 10.1109/JSYST.2015.2466439
   Sluban B., 2015, COMPUTATIONAL SOCIAL, V2, P1, DOI [DOI 10.1186/S40649-015-0016-5, 10.1186/s40649-015-0016-5]
   Sluban B, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P376, DOI 10.1109/SITIS.2014.27
   Stulz, 2020, W27106 NAT BUR EC RE
   Weichselbraun A, 2016, P ANN HICSS, P1040, DOI 10.1109/HICSS.2016.133
NR 15
TC 8
Z9 8
U1 2
U2 33
PD MAR 16
PY 2021
VL 53
IS 13
BP 1528
EP 1539
DI 10.1080/00036846.2020.1834501
EA OCT 2020
UT WOS:000584078100001
DA 2023-11-16
ER

PT J
AU Mazumdar, S
   Scionti, A
AF Mazumdar, Somnath
   Scionti, Alberto
TI Ring-mesh: a scalable and high-performance approach for manycore
   accelerators
SO JOURNAL OF SUPERCOMPUTING
DT Article
DE Interconnect; Network-on-chip; Manycores; Performance; Energy; Latency;
   Throughput
ID NETWORK; TOPOLOGY; INTERCONNECT; GENERATION; DESIGN; TOOL; NOC
AB There is increasing number of works addressing the design challenges of fast, scalable solutions for the growing number of new type of applications. Recently, many of the solutions aimed at improving processing element capabilities to speed up the execution of machine learning application domain. However, only a few works focused on the interconnection subsystem as a potential source of performance improvement. Wrapping many cores together offer excellent parallelism, but it brings other challenges (e.g. adequate interconnections). Scalable, power-aware interconnects are required to support such a growing number of processing elements, as well as modern applications. In this paper, we propose a scalable and energy-efficient network-on-chip architecture fusing the advantages of rings as well as the 2D mesh without using any bridge router to provide high performance. A dynamic adaptation mechanism allows to better adapt to the application requirements. Simulation results show efficient power consumption (up to141.3%saving for connecting 1024 cores),2x (on average) throughput growth with better scalability (up to 1024 processing elements) compared to popular 2D mesh while tested in multiple statistical traffic pattern scenarios.
C1 [Mazumdar, Somnath] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Scionti, Alberto] LINKS Fdn, Turin, Italy.
RP Mazumdar, S (corresponding author), Univ Siena, Dept Informat Engn & Math, Siena, Italy.
EM mazumdar@dii.unisi.it; alberto.scionti@linksfoundation.com
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   [Anonymous], 2016, VLSI CIRCUITS 2016 I
   [Anonymous], 2011, P 5 ACMIEEE INT S
   Ausavarungnirun R, 2016, PARALLEL COMPUT, V54, P29, DOI 10.1016/j.parco.2016.01.009
   Balfour J., 2006, P 20 ANN INT C SUP I, P187, DOI DOI 10.1145/1183401.1183430
   BARAN P, 1964, IEEE T COMMUN SYST, VCS12, P1, DOI 10.1109/TCOM.1964.1088883
   Barrow-Williams N, 2009, I S WORKL CHAR PROC, P86, DOI 10.1109/IISWC.2009.5306792
   Benson T., 2010, ACM IMC, P267, DOI DOI 10.1145/1879141.1879175
   Besta M, 2018, ACM SIGPLAN NOTICES, V53, P43, DOI [10.1145/3296957.3177158, 10.1145/3173162.3177158]
   Bolotin E, 2004, INTEGRATION, V38, P19, DOI 10.1016/j.vlsi.2004.03.006
   Bourduas S, 2007, NOCS 2007: FIRST INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, PROCEEDINGS, P195
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XN, 2003, ISLPED'03: PROCEEDINGS OF THE 2003 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P90
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Dally W.J., 2004, PRINCIPLES PRACTICES
   Das R, 2009, INT S HIGH PERF COMP, P175, DOI 10.1109/HPCA.2009.4798252
   Ding L, 2012, PROCEEDINGS OF ISCRAM ASIA 2012 CONFERENCE ON INFORMATION SYSTEMS FOR CRISIS RESPONSE AND MANAGEMENT, P201
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Grot B, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P401, DOI 10.1145/2024723.2000112
   Hamacher VC, 2001, IEEE T COMPUT, V50, P1, DOI 10.1109/12.902749
   Harting RC, 2012, TECHNICAL REPORT, V131
   Horro M, 2019, IEEE ACCESS, V7, P81195, DOI 10.1109/ACCESS.2019.2923855
   Hoskote Y, 2007, IEEE MICRO, V27, P51, DOI 10.1109/MM.2007.4378783
   Jeffers J, 2016, INTEL XEON PHI PROCE
   Junghee Lee, 2013, 2013 IEEE Computer Society Annual Symposium on VLSI. Emerging VLSI Technologies and Architectures (ISVLSI), P2, DOI 10.1109/ISVLSI.2013.6654614
   Kandula S, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P202
   Kim H, 2014, INT S HIGH PERF COMP, P332, DOI 10.1109/HPCA.2014.6835943
   Kim J, 2007, INT SYMP MICROARCH, P172, DOI 10.1109/MICRO.2007.29
   Kim J, 2008, CONF PROC INT SYMP C, P77, DOI 10.1109/ISCA.2008.19
   Kumar A, 2007, CONF PROC INT SYMP C, P150, DOI 10.1145/1273440.1250681
   Kurth T, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126916
   Kwon H, 2017, NEW J PHYS, V19, DOI 10.1088/1367-2630/aa68f5
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HG, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255460
   Liu SL, 2016, IEEE T PARALL DISTR, V27, P1700, DOI 10.1109/TPDS.2015.2465905
   Liu XX, 2018, ASIA S PACIF DES AUT, P141, DOI 10.1109/ASPDAC.2018.8297296
   Liu Y, 2016, APPL DEEP CONVOLUTIO, P81
   Ma S, 2012, INT S HIGH PERF COMP, P467
   Moraes F, 2004, INTEGRATION, V38, P69, DOI 10.1016/j.vlsi.2004.03.003
   Murali S, 2004, DES AUT CON, P914, DOI 10.1145/996566.996809
   Papamichael MK, 2012, FPGA 12: PROCEEDINGS OF THE 2012 ACM-SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P37
   Parikh R, 2014, DES AUT CON
   Puttmann C, 2007, DSD 2007: 10TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN ARCHITECTURES, METHODS AND TOOLS, PROCEEDINGS, P495, DOI 10.1109/DSD.2007.4341514
   Ravindran G, 1997, THIRD INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE - PROCEEDINGS, P58, DOI 10.1109/HPCA.1997.569606
   Scionti A, 2018, IEEE COMPUT ARCHIT L, V17, P1, DOI 10.1109/LCA.2017.2697863
   Scionti A, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P112, DOI 10.1109/HPCSim.2016.7568323
   Suettlerlein J, 2013, LECT NOTES COMPUT SC, V8097, P633, DOI 10.1007/978-3-642-40047-6_63
   Tam SM, 2018, ISSCC DIG TECH PAP I, P34, DOI 10.1109/ISSCC.2018.8310170
   Vangal SR, 2008, IEEE J SOLID-ST CIRC, V43, P29, DOI 10.1109/JSSC.2007.910957
   Vranesic ZG, 1995, NUMACHINE MULTIPROCE
   Wang H, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P105
   Wentzlaff D, 2007, IEEE MICRO, V27, P15, DOI 10.1109/MM.2007.4378780
   Xianglun Leng, 2005, International Symposium on Communications and Information Technologies 2005 (IEEE Cat. No.05EX1224), P1203
   Zheng NJ, 2015, MICROPROCESS MICROSY, V39, P313, DOI 10.1016/j.micpro.2015.03.008
NR 55
TC 2
Z9 2
U1 0
U2 1
PD SEP
PY 2020
VL 76
IS 9
BP 6720
EP 6752
DI 10.1007/s11227-019-03072-5
UT WOS:000552755500010
DA 2023-11-16
ER

PT C
AU Hassan, O
   Paul, T
   Thakker, R
   Parvin, D
   Shuvo, MMH
   Mosa, AM
   Islam, SK
AF Hassan, Omiya
   Paul, Tanmoy
   Thakker, Rushil
   Parvin, Dilruba
   Shuvo, Md Maruf Hossain
   Mosa, Abu Saleh Mohammad
   Islam, Syed Kamrul
GP IEEE
TI A Multi-Sensor Based Automatic Sleep Apnea Detection System for Adults
   Using Neural Network Inference on FPGA
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON MEDICAL MEASUREMENTS AND
   APPLICATIONS (MEMEA 2022)
SE IEEE International Symposium on Medical Measurements and Applications
   Proceedings-MeMeA
DT Proceedings Paper
CT 17th IEEE International Symposium on Medical Measurements and
   Applications (IEEE MeMeA)
CY JUN 22-24, 2022
CL Messina, ITALY
DE Sleep Apnea; ECG Sensor; Biomedical; Feedforward Neural Network;
   Shifter; FPGA; Digital Hardware; Deep Learning
ID ELECTROCARDIOGRAM; VARIABILITY; OXIMETRY
AB This paper proposes an automatic sleep apnea monitoring device for adults employing of single ECG patch and a pulse oximeter. The device is designed to automatically detect sleep apneic (SA) events with the inference of feedforward neural network (FNN) model embedded in digital hardware. The three-layer (8-6-4) FNN model was trained over several epochs with a 5-fold cross validation technique where the training set had a mini-batch size of 10. Open-source Apnea ECG dataset collected from the PhysioNET bank was used in training, validating, and testing the model. Rectified Linear Unit (ReLU) activation function was used in the input and hidden layers of the network and sigmoid function was used as the output classifier. ADAM optimizer was used for optimization of the model while mean-squared-error (MSE) was used for calculating model loss. The final trained and validated model was implemented onto re-programmable digital hardware called Field Programmable Gate Array (FPGA). The hardware implementation of the model yielded an accuracy of over 87 percent with a power consumption rate of around 52 W, which is 5x times lower than that of commercially available machine learning hardware accelerators. The proposed system design will be realized in integrated circuits on CMOS platform for developing energy-efficient, smart, wearable, and automated sleep apnea detection and screening device for adults.
C1 [Hassan, Omiya; Paul, Tanmoy; Thakker, Rushil; Parvin, Dilruba; Shuvo, Md Maruf Hossain; Islam, Syed Kamrul] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
   [Mosa, Abu Saleh Mohammad] Univ Missouri, Dept Hlth Management & Informat, Columbia, MO 65211 USA.
RP Hassan, O (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
EM omiya.hassan@mail.missouri.edu
CR Alvarez D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62223-4
   Amaral L., 2020, CIRCULATION, V101, P215
   Azimi H, 2020, IEEE INT SYM MED MEA, DOI 10.1109/memea49120.2020.9137203
   de Chazal P, 2009, PHILOS T R SOC A, V367, P369, DOI 10.1098/rsta.2008.0156
   Han S, 2015, ADV NEUR IN, V28
   Hassan O, 2020, MIDWEST SYMP CIRCUIT, P607, DOI [10.1109/mwscas48704.2020.9184554, 10.1109/MWSCAS48704.2020.9184554]
   Hassan T., 2022, J SIGNAL PROCESS SYS
   Hillman DR, 2006, SLEEP, V29, P299, DOI 10.1093/sleep/29.3.299
   Hossain M. M., 2021, IEEE INT INSTRUMENTA
   Jin JY, 2015, IEEE T BIOMED CIRC S, V9, P96, DOI 10.1109/TBCAS.2014.2314301
   Khincha Rishab, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P377, DOI 10.1007/978-3-030-51935-3_40
   Kwon S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093122
   Leung RST, 2001, AM J RESP CRIT CARE, V164, P2147, DOI 10.1164/ajrccm.164.12.2107045
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Li KY, 2018, NEUROCOMPUTING, V294, P94, DOI 10.1016/j.neucom.2018.03.011
   Mostafa SS, 2017, 2017 XXVI INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATION AND AUTOMATION TECHNOLOGIES (ICAT)
   Narkiewicz K, 1998, CIRCULATION, V98, P1071, DOI 10.1161/01.CIR.98.11.1071
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   PhysioNet, US
   Ravelo-García AG, 2015, ENTROPY-SWITZ, V17, P914, DOI 10.3390/e17030914
   Schmittendorf E, 2011, BIOMED TECH, V56, P215, DOI 10.1515/BMT.2011.101
   Song CY, 2016, IEEE T BIO-MED ENG, V63, P1532, DOI 10.1109/TBME.2015.2498199
   Tsmots I, 2019, EXP DES APPL CAD SYS, DOI 10.1109/cadsm.2019.8779253
   Varon C, 2015, IEEE T BIO-MED ENG, V62, P2269, DOI 10.1109/TBME.2015.2422378
   Wang T, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9768072
NR 25
TC 2
Z9 2
U1 0
U2 2
PY 2022
DI 10.1109/MEMEA54994.2022.9856509
UT WOS:000861225100103
DA 2023-11-16
ER

PT C
AU Belabed, T
   Coutinho, MGF
   Fernandes, MAC
   Carlos, V
   Souani, C
AF Belabed, Tarek
   Coutinho, Maria Gracielly F.
   Fernandes, Marcelo A. C.
   Carlos, Valderrama
   Souani, Chokri
GP IEEE
TI Low Cost and Low Power Stacked Sparse Autoencoder Hardware Acceleration
   for Deep Learning Edge Computing Applications
SO 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL
   AND IMAGE PROCESSING (ATSIP'2020)
DT Proceedings Paper
CT 5th International Conference on Advanced Technologies for Signal and
   Image Processing (ATSIP)
CY SEP 02-05, 2020
CL Sfax, TUNISIA
DE Autoencoder; FPGA; Low energy consumption; low cost
AB Nowadays, Deep Learning DL becoming more and more interesting in many areas, such as genomics, security, data analysis, image, and video processing. However, DL requires more and more powerful and parallel computing. The calculation performed by super-machines equipped with powerful processors, such as the latest GPUs. Despite their power, these computing units consume a lot of energy, which makes their use very difficult in small embedded systems and edge computing. To overcome the problem for which we must keep the maximum performance and satisfy the power constraint, it is necessary to use a heterogeneous strategy. Some solutions are promising when using less energy-consuming electronic circuits, such as FPGAs associated with less expensive topologies such as Stacked Sparse Autoencoders. Our target architecture is the Xilinx ZYNQ 7020 SoC, which combines a dual-core ARM processor and an FPGA in the same chip. In the interest of flexibility, we decided to leverage the performance of Xilinx's high-level synthesis tools, evaluate and choose the best solution in terms of size and performance of the data exchange, synchronization and pipeline processing. The results show that our implementation gives high performance at very low energy consumption. Indeed, the evaluation of our accelerator shows that it can classify 1160 MNIST images per second, consuming only 0.443 W; 2.4 W for the entire system. More than the low energy consumption and the high performance, the platform used only costs $ 125.
C1 [Belabed, Tarek; Carlos, Valderrama] iUniv Mons, Fac Polytech, SEMi, 31 Bd Dolez, B-7000 Mons, Belgium.
   [Belabed, Tarek] Univ Sousse, Ecole Natl Ingn Sousse, Sousse 4000, Tunisia.
   [Belabed, Tarek; Souani, Chokri] Univ Monastir, Fac Sci Monastir, Lab Microelect & Instrumentat, Monastir 5019, Tunisia.
   [Souani, Chokri] Univ Sousse, Inst Super Sci Appl & Technol Sousse, Sousse 4003, Tunisia.
   [Coutinho, Maria Gracielly F.; Fernandes, Marcelo A. C.] Univ Fed Rio Grande do Norte, Dept Comp & Automat Engn, BR-59078970 Natal, RN, Brazil.
RP Belabed, T (corresponding author), iUniv Mons, Fac Polytech, SEMi, 31 Bd Dolez, B-7000 Mons, Belgium.; Belabed, T (corresponding author), Univ Sousse, Ecole Natl Ingn Sousse, Sousse 4000, Tunisia.; Belabed, T (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Microelect & Instrumentat, Monastir 5019, Tunisia.
EM belabed.tarek@gmail.com; gracielly@dca.ufrn.br; mfernandes@dca.ufrn.br;
   sakuyama@umons.ac.be; chokri.souani@gmail.com
CR Coutinho MGF, 2019, IEEE ACCESS, V7, P40674, DOI 10.1109/ACCESS.2019.2907261
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   LeCun Y., MNIST DATABASE HANDW
   Maria J, 2016, NEURAL PROCESS LETT, V43, P445, DOI 10.1007/s11063-015-9430-9
   Moss DJM, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350890
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou YM, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P829, DOI 10.1109/ICCSNT.2015.7490869
NR 8
TC 3
Z9 3
U1 0
U2 0
PY 2020
DI 10.1109/atsip49331.2020.9231748
UT WOS:000789375600050
DA 2023-11-16
ER

PT C
AU Akin, B
   Chishti, ZA
   Alameldeen, AR
AF Akin, Berkin
   Chishti, Zeshan A.
   Alameldeen, Alaa R.
GP Assoc Comp Machinery
TI ZCOMP: Reducing DNN Cross-Layer Memory Footprint Using Vector Extensions
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE Deep learning; memory system; sparsity; compression; ISA; CPU
ID CACHE COMPRESSION
AB Deep Neural Networks (DNNs) are becoming the prevalent approach in computer vision, machine learning, natural language processing, and speech recognition applications. Although DNNs are perceived as compute-intensive tasks, they also apply intense pressure on the capacity and bandwidth of the memory hierarchy, primarily due to the large intermediate data communicated across network layers. Prior work on hardware DNN accelerators leverages the cross-layer data sparsity via fully-customized datapaths. However, dynamically compressing/expanding such data is a challenging task for general-purpose multi-processors with virtual memory and hardware-managed coherent cache hierarchies.
   In this paper, we observe that the DNN intermediate data is either sequentially streamed or reshaped with a regular transformation between layers. Hence, accesses to this data can tolerate a sequential or block sequential compression/expansion without requiring random element retrieval. Based on this insight, we propose ZCOMP, a CPU vector ISA extension tailored for DNN cross-layer communication. ZCOMP compactly represents zero value compression/expansion and fully automates the metadata generation, storage and retrieval which eliminates the need for several extra instruction executions and register usage. ZCOMP can be targeted both for inference and training to dynamically compress/expand cross-layer data before being written to memory. Our evaluations for individual layers and end-to-end DNN networks demonstrate that ZCOMP offers substantial data traffic reduction, both on-chip across cache-hierarchy and off-chip to DRAM, and performance improvements over no compression and existing AVX512 compression approaches.
C1 [Akin, Berkin; Chishti, Zeshan A.; Alameldeen, Alaa R.] Intel Labs, Hillsboro, OR 97124 USA.
RP Akin, B (corresponding author), Intel Labs, Hillsboro, OR 97124 USA.
EM berkin.akin@intel.com; zeshan.a.chishti@intel.com;
   alaa.r.alameldeen@intel.com
CR Abadi M, TENSORFLOW SYSTEM LA
   Aklaghi Vahideh, 2018, ACM IEEE INT S COMP
   Alameldeen AR, 2018, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS (MEMSYS 2018), P129, DOI 10.1145/3240302.3240429
   Alameldeen Alaa R, 2004, 1500 U WISC DEP COMP
   Alameldeen AR, 2004, CONF PROC INT SYMP C, P212
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2016, ACM SIGARCH COMPUTER, DOI DOI 10.1109/ISCA.2016.32
   [Anonymous], 2016, IEEEACM INT S MICROA
   [Anonymous], 2016, MICROARCHITECTURE MI
   Arelakis A, 2014, CONF PROC INT SYMP C, P145, DOI 10.1109/ISCA.2014.6853231
   Carlson TE, 2014, ACM T ARCHIT CODE OP, V11, P127, DOI 10.1145/2629677
   Chen T., 2016, ARXIV160406174
   Chen X, 2010, IEEE T VLSI SYST, V18, P1196, DOI 10.1109/TVLSI.2009.2020989
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dusser J, 2009, ICS'09: PROCEEDINGS OF THE 2009 ACM SIGARCH INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P46, DOI 10.1145/1542275.1542288
   Fog Agner, 2018, LISTS INSTRUCTION LA
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   Gaur J, 2016, CONF PROC INT SYMP C, P317, DOI 10.1109/ISCA.2016.36
   Georganas Evangelos, 2018, ARXIV180805567
   Hallnor EG, 2005, INT S HIGH PERF COMP, P201, DOI 10.1109/HPCA.2005.4
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Hill P, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P786, DOI 10.1145/3123939.3123970
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon Y, 2018, IEEE COMPUT ARCHIT L, V17, P134, DOI 10.1109/LCA.2018.2823302
   Liu Y., 2018, ARXIV180902697
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park J., 2018, ARXIV PREPRINT ARXIV
   Pekhimenko Gennady, 2012, P INT C PAR ARCH COM, P51
   Rhu M., 2016, 2016 49 ANN IEEEACM, P1, DOI DOI 10.1109/MICRO.2016.7783721
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Sardashti S, 2014, INT SYMP MICROARCH, P331, DOI 10.1109/MICRO.2014.41
   Sardashti Somayeh, 2013, P 46 ANN INT S MICR
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang L., 2018, SCHEDULING COMPUTATI
   Vanhoucke Vincent, 2011, DEEP LEARNING UNSUPE
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
NR 48
TC 13
Z9 13
U1 0
U2 2
PY 2019
BP 126
EP 138
DI 10.1145/3352460.3358305
UT WOS:000519057400010
DA 2023-11-16
ER

PT C
AU Selg, H
   Jenihhin, M
   Ellervee, P
   Raik, J
AF Selg, Hardi
   Jenihhin, Maksim
   Ellervee, Peeter
   Raik, Jaan
BE Savino, A
   Maniatakos, M
   DiCarlo, S
   Gizopoulos, D
TI ML-Based Online Design Error Localization for RISC-V Implementations
SO 2023 IEEE 29TH INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN, IOLTS
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 29th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 03-05, 2023
CL Platanias, GREECE
DE Online design error debug; microprocessor architecture; machine
   learning; neural architecture search
ID TRACE; BUGS
AB The accelerated growth of computing systems' complexity makes comprehensive design verification challenging and time-consuming. In practice, hard-to-model complex environments are unfeasible to be simulated exhaustively within a reasonable time frame. Therefore, some corner-case conditions can be overlooked and design errors might escape to the final product. This means that it is imperative for the system to be able to detect and locate bugs to enable self-repair. This is particularly crucial during long-term remote missions in order to apply graceful degradation. This paper proposes a novel online design error localization methodology for microprocessors by immediate analysis of traced and buffered signals upon a failure detection event, using a pre-trained Neural Network (NN) and existing processor components, i.e. trace buffers and AI accelerators. An in-house Neural Architecture Search (NAS) framework is used to train a tailored Multi-Layer Perceptron (MLP) NN for error localization at the microprocessor module-level resolution. The proposed approach is validated by simulating a RISC-V implementation with different workload programs. It is demonstrated to be capable of localizing the microprocessor module of bug origin with 92.81% accuracy, on average.
C1 [Selg, Hardi; Jenihhin, Maksim; Ellervee, Peeter; Raik, Jaan] Tallinn Univ Technol, Comp Syst, Tallinn, Estonia.
RP Selg, H (corresponding author), Tallinn Univ Technol, Comp Syst, Tallinn, Estonia.
EM hardi.selg@taltech.ee
CR Abramovici M, 2006, DES AUT CON, P7, DOI 10.1109/DAC.2006.238683
   Azambuja JR, 2013, IEEE T NUCL SCI, V60, P2805, DOI 10.1109/TNS.2013.2246798
   Azambuja JR, 2012, IEEE T NUCL SCI, V59, P1117, DOI 10.1109/TNS.2012.2201750
   Bailey B., WHAT MAKES RISC V VE
   Benso A, 2001, IEEE MICRO, V21, P16, DOI 10.1109/40.958696
   Dutta A, 2021, J COMPUT LANG, V66, DOI 10.1016/j.cola.2021.101064
   Dutto S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1456, DOI 10.23919/DATE51398.2021.9474120
   Goh M., 2006, MSP430 COMPETITIVE B
   Grosso M., 2010, 2010 IEEE 16th International On-Line Testing Symposium (IOLTS 2010), P167, DOI 10.1109/IOLTS.2010.5560215
   Jenihhin M, 2014, IEEE DES TEST, V31, P83, DOI 10.1109/MDAT.2013.2271420
   Jin HF, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1946, DOI 10.1145/3292500.3330648
   Jones James A, 2005, P 20 IEEE ACM INT C, P273
   Jutman A, 2017, DES AUT TEST EUROPE, P115, DOI 10.23919/DATE.2017.7926968
   Kumar B, 2020, IEEE T COMPUT AID D, V39, P248, DOI 10.1109/TCAD.2018.2883899
   Li M, 2013, DES AUT TEST EUROPE, P485
   Li X, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P169, DOI 10.1145/3293882.3330574
   McCann E., SYSTEM VALIDATION AR
   Nakamura Y, 2002, 2002 PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING, PROCEEDINGS, P75, DOI 10.1109/PRDC.2002.1185621
   Rahmani K, 2016, IEEE T VLSI SYST, V24, P313, DOI 10.1109/TVLSI.2015.2396083
   Schiavone PD, 2018, IEEE SOI3DSUB MICRO
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Selg H, 2021, INT SYM DEFEC FAU TO, DOI 10.1109/DFT52944.2021.9568321
   Veira N, 2020, IEEE T COMPUT AID D, V39, P5267, DOI 10.1109/TCAD.2020.2966448
   VESSEY I, 1986, IEEE T SYST MAN CYB, V16, P621, DOI 10.1109/TSMC.1986.289308
   WEICKER RP, 1984, COMMUN ACM, V27, P1013, DOI 10.1145/358274.358283
   Xiao Y, 2018, ASIA PAC SOFWR ENG, P703, DOI 10.1109/APSEC.2018.00097
   Xiao Y, 2017, ASIA PAC SOFWR ENG, P338, DOI 10.1109/APSEC.2017.40
   Zhou J, 2012, PROC INT CONF SOFTW, P14, DOI 10.1109/ICSE.2012.6227210
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/IOLTS59296.2023.10224864
UT WOS:001062141900005
DA 2023-11-16
ER

PT J
AU Xu, XY
   Ren, GH
   Feleppa, T
   Liu, XM
   Boes, A
   Mitchell, A
   Lowery, AJ
AF Xu, Xingyuan
   Ren, Guanghui
   Feleppa, Tim
   Liu, Xumeng
   Boes, Andreas
   Mitchell, Arnan
   Lowery, Arthur J.
TI Self-calibrating programmable photonic integrated circuits
SO NATURE PHOTONICS
DT Article
ID PHASE; TRIPLEX; CHIP
AB Researchers demonstrate a self-calibrating programmable photonic integrated circuit. The findings may be useful for the accurate control of large-scale photonic integrated circuits in applications such as light-based machine learning.
   Programmable photonic integrated circuits (PICs) are dense assemblies of tunable elements that provide flexible reconfigurability to enable different functions to be selected; however, due to manufacturing variations and thermal gradients that affect the optical phases of the elements, it is difficult to guarantee a stable correspondence between the electrical commands to the chip, and the function that it provides. Here we demonstrate a self-calibrating programmable PIC with full control over its complex impulse response, in the presence of thermal cross-talk between phase-tuning elements. Self-calibration is achieved by: (1) incorporating an optical reference path into the PIC; (2) using the Kramers-Kronig relationship to recover the phase response from amplitude measurements; and (3) applying a fast-converging self-calibration algorithm. We demonstrate dial-up signal processing functions with complex impulse responses using only 25 training iterations. This approach offers stable and accurate control of large-scale PICs, for demanding applications such as communications network reconfiguration, neuromorphic hardware accelerators and quantum computers.
C1 [Xu, Xingyuan; Feleppa, Tim; Liu, Xumeng; Lowery, Arthur J.] Monash Univ, Dept Elect & Comp Syst Engn, Electrophoton Lab, Clayton, Vic, Australia.
   [Xu, Xingyuan] Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing, Peoples R China.
   [Ren, Guanghui; Boes, Andreas; Mitchell, Arnan] RMIT Univ, Sch Engn, Integrated Photon & Applicat Ctr, Melbourne, Vic, Australia.
   [Boes, Andreas] Univ Adelaide, Inst Photon & Adv Sensing IPAS, Adelaide, SA, Australia.
   [Boes, Andreas] Univ Adelaide, Sch Elect & Elect Engn, Adelaide, SA, Australia.
RP Xu, XY (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Electrophoton Lab, Clayton, Vic, Australia.; Xu, XY (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing, Peoples R China.
EM xingyuanxu@bupt.edu.cn
CR Annoni A, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2017.110
   Bogaerts W., 2013, P SPIE, V8781
   Bogaerts W, 2020, NATURE, V586, P207, DOI 10.1038/s41586-020-2764-0
   Capmany J., 2019, PROGRAMMABLE INTEGRA
   Capmany J, 2016, NAT PHOTONICS, V10, P6, DOI 10.1038/nphoton.2015.254
   Carolan J, 2019, OPTICA, V6, P335, DOI 10.1364/OPTICA.6.000335
   Carolan J, 2015, SCIENCE, V349, P711, DOI 10.1126/science.aab3642
   Carroll L, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6120426
   Cheng Q, 2015, J OPT COMMUN NETW, V7, pA388, DOI 10.1364/JOCN.7.00A388
   Choo G, 2018, J LIGHTWAVE TECHNOL, V36, P5263, DOI 10.1109/JLT.2018.2873199
   Choo G, 2018, J LIGHTWAVE TECHNOL, V36, P1899, DOI 10.1109/JLT.2018.2795582
   Chrostowski L, 2015, SILICON PHOTONICS DESIGN, P1
   Gazman A, 2018, OPT EXPRESS, V26, P32662, DOI 10.1364/OE.26.032662
   Guan BV, 2014, IEEE J SEL TOP QUANT, V20, DOI 10.1109/JSTQE.2013.2296233
   Guo YH, 2016, OPT LETT, V41, P4939, DOI 10.1364/OL.41.004939
   Halir R, 2009, OPT EXPRESS, V17, P8349, DOI 10.1364/OE.17.008349
   HAYES MH, 1980, IEEE T ACOUST SPEECH, V28, P672, DOI 10.1109/TASSP.1980.1163463
   Inniss D., 2016, SILICON PHOTONICS FU
   Jayatilleka H, 2018, J LIGHTWAVE TECHNOL, V36, P210, DOI 10.1109/JLT.2017.2769962
   Jiang HY, 2018, OPT LETT, V43, P415, DOI 10.1364/OL.43.000415
   Li Z, 2017, J LIGHTWAVE TECHNOL, V35, P1887, DOI 10.1109/JLT.2017.2684298
   Lin Y, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2842026
   Lyke JC, 2015, P IEEE, V103, P291, DOI 10.1109/JPROC.2015.2397832
   Mauthe S, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18374-z
   Mecozzi A, 2016, OPTICA, V3, P1220, DOI 10.1364/OPTICA.3.001220
   Milanizadeh M, 2019, J LIGHTWAVE TECHNOL, V37, P1325, DOI 10.1109/JLT.2019.2892512
   Miller DAB, 2015, OPTICA, V2, P747, DOI 10.1364/OPTICA.2.000747
   Ozcan A, 2006, J LIGHTWAVE TECHNOL, V24, P1739, DOI 10.1109/JLT.2006.871111
   Ozcan A, 2006, J OPT SOC AM A, V23, P1669, DOI 10.1364/JOSAA.23.001669
   Pérez D, 2019, OPTICA, V6, P19, DOI 10.1364/OPTICA.6.000019
   Pérez D, 2018, OPT EXPRESS, V26, P27265, DOI 10.1364/OE.26.027265
   Pérez D, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00714-1
   Pérez-López D, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19608-w
   Qiao PF, 2017, IEEE J SEL TOP QUANT, V23, DOI 10.1109/JSTQE.2017.2707181
   Ribeiro A, 2016, OPTICA, V3, P1348, DOI 10.1364/OPTICA.3.001348
   Roeloffzen CGH, 2013, OPT EXPRESS, V21, P22937, DOI 10.1364/OE.21.022937
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Streshinsky M, 2013, OPT PHOTONICS NEWS, V24, P32, DOI 10.1364/OPN.24.9.000032
   Tait AN, 2016, OPT EXPRESS, V24, P8895, DOI 10.1364/OE.24.008895
   Tait AN, 2016, IEEE PHOTONIC TECH L, V28, P887, DOI 10.1109/LPT.2016.2516440
   Wörhoff K, 2015, ADV OPT TECHNOL, V4, P189, DOI 10.1515/aot-2015-0016
   Xie YW, 2018, NANOPHOTONICS-BERLIN, V7, P837, DOI 10.1515/nanoph-2017-0113
   Yegnanarayanan S., 2018, C LASERS ELECTRO OPT
   Zhang H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20719-7
   Zhang WF, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-14249-0
   Zheng D, 2019, OPT LETT, V44, P2629, DOI 10.1364/OL.44.002629
   Zhuang LM, 2015, OPTICA, V2, P854, DOI 10.1364/OPTICA.2.000854
   Zhuang LM, 2012, OPT EXPRESS, V20, P26499, DOI 10.1364/OE.20.026499
NR 48
TC 28
Z9 29
U1 20
U2 81
PD AUG
PY 2022
VL 16
IS 8
BP 595
EP +
DI 10.1038/s41566-022-01020-z
EA JUL 2022
UT WOS:000824862900002
DA 2023-11-16
ER

PT J
AU Kim, MS
   Del Barrio, AA
   Kim, H
   Bagherzadeh, N
AF Kim, Min Soo
   Del Barrio, Alberto A.
   Kim, Hyunjin
   Bagherzadeh, Nader
TI The Effects of Approximate Multiplication on Convolutional Neural
   Networks
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Machine learning; computer vision; object recognition; arithmetic and
   logic units; low-power design
AB This article analyzes the effects of approximate multiplication when performing inferences on deep convolutional neural networks (CNNs). The approximate multiplication can reduce the cost of the underlying circuits so that CNN inferences can be performed more efficiently in hardware accelerators. The study identifies the critical factors in the convolution, fully-connected, and batch normalization layers that allow more accurate CNN predictions despite the errors from approximate multiplication. The same factors also provide an arithmetic explanation of why bfloat16 multiplication performs well on CNNs. The experiments are performed with recognized network architectures to show that the approximate multipliers can produce predictions that are nearly as accurate as the FP32 references, without additional training. For example, the ResNet and Inception-v4 models with Mitch-w6 multiplication produces Top-5 errors that are within 0.2 percent compared to the FP32 references. A brief cost comparison of Mitch-w6 against bfloat16 is presented where a MAC operation saves up to 80 percent of energy compared to the bfloat16 arithmetic. The most far-reaching contribution of this article is the analytical justification that multiplications can be approximated while additions need to be exact in CNN MAC operations.
C1 [Kim, Min Soo] NGD Syst, Irvine, CA 92618 USA.
   [Del Barrio, Alberto A.] Univ Complutense Madrid, Dept Comp Architecture & Automat, Madrid 28040, Spain.
   [Kim, Hyunjin] Dankook Univ, Sch Elect & Elect Engn, Yongin 16890, Gyeonggi Do, South Korea.
   [Bagherzadeh, Nader] Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA.
RP Kim, MS (corresponding author), NGD Syst, Irvine, CA 92618 USA.
EM minsk1@uci.edu
CR Ansari MS, 2021, IEEE T COMPUT, V70, P614, DOI 10.1109/TC.2020.2992113
   Ansari MS, 2020, IEEE T VLSI SYST, V28, P317, DOI 10.1109/TVLSI.2019.2940943
   Chippa VK, 2010, DES AUT CON, P555
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   De S, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P288, DOI 10.1109/DSD.2018.00059
   Del Barrio A, 2019, LOGARITHMETIC
   Del Barrio AA, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2567932
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Guadarrama S., 2016, TENSORFLOW SLIM LIGH
   Hammad I, 2018, IEEE ACCESS, V6, P60438, DOI 10.1109/ACCESS.2018.2875376
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry G, 2019, P S COMP ARITHM, P69, DOI 10.1109/ARITH.2019.00019
   Imani M, 2018, ASIA S PACIF DES AUT, P682, DOI 10.1109/ASPDAC.2018.8297401
   Ioffe S., 2015, INT C MACH LEARN PML, V1, P448
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Judd P, 2016, INT SYMP MICROARCH
   Kim D, 2017, IEEE T EMERG TOP COM, V5, P164, DOI 10.1109/TETC.2017.2673548
   Kim H, 2019, P S COMP ARITHM, P108, DOI 10.1109/ARITH.2019.00029
   Kim MS, 2019, IEEE T COMPUT, V68, P660, DOI 10.1109/TC.2018.2880742
   Kim MS, 2018, ASIA S PACIF DES AUT, P617, DOI 10.1109/ASPDAC.2018.8297391
   Kung J, 2015, I SYMPOS LOW POWER E, P85, DOI 10.1109/ISLPED.2015.7273495
   Lai L, 2017, ARXIV 170303073
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lin DD, 2016, PR MACH LEARN RES, V48
   Liu WQ, 2018, IEEE T CIRCUITS-I, V65, P2856, DOI 10.1109/TCSI.2018.2792902
   Liu Y, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1320, DOI 10.1145/3368089.3417051
   Lotric U, 2012, NEUROCOMPUTING, V96, P57, DOI 10.1016/j.neucom.2011.09.039
   Mitchell J. N., 1962, IRE T ELECT COMPUTER, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Miyashita Daisuke, 2016, ARXIV160301025
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Oliveira L.T., 2019, EUROPEAN S ARTIFICIA, P203
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Salamat S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P219
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Shim Y., 2016, PATAIS CHEM FUNCTION, P1
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang S., 2019, GOOGLE CLOUD BLO AUG
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
NR 45
TC 20
Z9 20
U1 1
U2 17
PD APR-JUN
PY 2022
VL 10
IS 2
BP 904
EP 916
DI 10.1109/TETC.2021.3050989
UT WOS:000808083300031
DA 2023-11-16
ER

PT C
AU Bhattacharjee, D
   Devadoss, R
   Chattopadhyay, A
AF Bhattacharjee, Debjyoti
   Devadoss, Rajeswari
   Chattopadhyay, Anupam
GP IEEE
TI ReVAMP : ReRAM based VLIW Architecture for in-Memory comPuting
SO PROCEEDINGS OF THE 2017 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 20th Conference and Exhibition on Design, Automation and Test in Europe
   (DATE)
CY MAR 27-31, 2017
CL EPFL Campus, Lausanne, SWITZERLAND
HO EPFL Campus
AB With diverse types of emerging devices offering simultaneous capability of storage and logic operations, researchers have proposed novel platforms that promise gains in energy-efficiency. Such platforms can be classified into two domainsapplication- specific and general-purpose. The application-specific in-memory computing platforms include machine learning accelerators, arithmetic units, and Content Addressable Memory (CAM)-based structures. On the other hand, the general-purpose computing platforms stem from the idea that several in-memory computing logic devices do support a universal set of Boolean logic operation and therefore, can be used for mapping arbitrary Boolean functions efficiently. In this direction, so far, researchers have concentrated on challenges in logic synthesis (e.g. depth optimization), and technology mapping (e.g. device count reduction). The important problem of efficient technology mapping of arbitrary logic network onto a crossbar array structure has been overlooked so far. In this paper, we propose, ReVAMP, a generalpurpose computing platform based on Resistive RAM crossbar array, which exploits the parallelism in computing multiple logic operations in the same word. Further, we study the problem of instruction generation and scheduling for such a platform. We benchmark the performance of ReVAMP with respect to the state of the art architecture.
C1 [Bhattacharjee, Debjyoti; Devadoss, Rajeswari; Chattopadhyay, Anupam] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
RP Bhattacharjee, D (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
EM debjyoti001@ntu.edu.sg; rajeswari@ntu.edu.sg; anupam@ntu.edu.sg
CR Amaru L. G., 2014, P 51 ANN DES AUT C, P1
   Bhattacharjee D., 2016, VER LARG SCAL INT VL, P1, DOI DOI 10.1109/VLSISOC.2016.7753568
   Bhattacharjee D., 2016, P 35 INT C COMP AID, P119
   Easwaran Arvind, 2017, 22 AS S PAC DES AUT
   Gaillardon PE, 2016, DES AUT TEST EUROPE, P427
   Hamdioui S, 2015, DES AUT TEST EUROPE, P1718
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Lehtonen E, 2009, 2009 IEEE/ACM INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURES, P33, DOI 10.1109/NANOARCH.2009.5226356
   Linn E, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/30/305205
   Poikonen JH, 2012, IEEE T COMPUT AID D, V31, P1129, DOI 10.1109/TCAD.2012.2187524
   Raghuvanshi A, 2014, ICCAD-IEEE ACM INT, P470, DOI 10.1109/ICCAD.2014.7001393
   Shirinzadeh S., 2016, DATE
   Shulaker MM, 2013, NATURE, V501, P526, DOI 10.1038/nature12502
   Siemon A, 2014, IEEE INT SYMP CIRC S, P1420, DOI 10.1109/ISCAS.2014.6865411
   Siemon A, 2015, IEEE J EM SEL TOP C, V5, P64, DOI 10.1109/JETCAS.2015.2398217
   Soeken M., 2016, DAC
   Strukov DB, 2010, IEEE INT SYMP CIRC S, P1967, DOI 10.1109/ISCAS.2010.5537020
NR 17
TC 38
Z9 38
U1 0
U2 1
PY 2017
BP 782
EP 787
UT WOS:000404171500147
DA 2023-11-16
ER

PT C
AU Ansari, S
   Du, HP
   Naghdy, F
AF Ansari, Shahzeb
   Du, Haiping
   Naghdy, Fazel
GP IEEE
TI Driver's Foot Trajectory Tracking for Safe Maneuverability Using New
   Modified reLU-BiLSTM Deep Neural Network
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
DT Proceedings Paper
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
DE Driver foot behaviour; foot trajectory; foot posture; classification;
   deep learning model; reLU-BiLSTM
ID PEDAL APPLICATIONS; RISK
AB Driver's foot behaviour is unpredictable and can suddenly change the nature of driving and dynamics under the influence of different factors that stimulates the driving style. Such effects result in sudden variations in foot dynamics and trajectory between accelerator and brake pedals inducing vagueness in smart active control system. This paper is an extension to the intrusive approach where driver's foot trajectory and shifting between pedals are monitored using XSENS motion capture system. The main objective is to predict the foot patterns associated with acceleration and braking. The experiments were conducted on 10 young subjects on MATHWORKS driver-in-loop (DIL) simulator, interfaced with Unreal Engine 4 studio. A new modified bidirectional long short-term memory (Bi-LSTM) deep neural network based on a rectified linear unit layer was designed, trained, tested and compared with traditional machine learning algorithms on 3D time-series foot orientation data for the sequence-to-sequence classification. The results show that the proposed classifier performs well and successfully recognizes the driver's foot behaviour with overall accuracy of 99.8%. Such identified patterns will help in determining the foot posture and the degree of intention in pressing the particular pedal. Moreover, the patterns will be useful for early intervention by smart systems to cope with the longitudinal mistakes made during driving. The limitations of the current work and directions for future work are explored.
C1 [Ansari, Shahzeb; Du, Haiping; Naghdy, Fazel] Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2500, Australia.
RP Ansari, S (corresponding author), Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2500, Australia.
EM sa345@uowmail.edu.au
CR Ameli S, 2017, PATTERN RECOGN, V63, P246, DOI 10.1016/j.patcog.2016.08.002
   Atwood J, 2018, ACCIDENT ANAL PREV, V119, P149, DOI 10.1016/j.aap.2018.07.007
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Blanco JL., 2010, U MALAGA TECH REP, V3, P6
   Cui ZY, 2020, TRANSPORT RES C-EMER, V118, DOI 10.1016/j.trc.2020.102674
   Tran C, 2012, COMPUT VIS IMAGE UND, V116, P435, DOI 10.1016/j.cviu.2011.09.008
   Frank S, 2019, J AMB INTEL SMART EN, V11, P221, DOI 10.3233/AIS-190522
   Hatfield J, 2014, ACCIDENT ANAL PREV, V62, P223, DOI 10.1016/j.aap.2013.09.028
   Jagvaral B, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112960
   Kim J, 2020, J NUCL CARDIOL, V27, P2154, DOI 10.1007/s12350-019-01617-y
   Kuipers J. B., 1999, QUATERNIONS ROTATION
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Mathworks, 2019, VEH DYN BLOCKS
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   Ohn-Bar E, 2014, IEEE INT VEH SYM, P719, DOI 10.1109/IVS.2014.6856612
   Panhwar YN, 2018, IEEE INT C BIOINF BI, P269, DOI 10.1109/BIBE.2018.00059
   Podusenko A, 2017, 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1622, DOI 10.23919/SICE.2017.8105641
   Suzuki K., 2018, 01487191 SAE
   Tran C, 2012, IEEE INT C INTELL TR, P1137, DOI 10.1109/ITSC.2012.6338908
   Tran C, 2011, IEEE INT VEH SYM, P577, DOI 10.1109/IVS.2011.5940548
   Wu YQ, 2018, ACCIDENT ANAL PREV, V118, P146, DOI 10.1016/j.aap.2018.02.011
   Wu YQ, 2017, ACCIDENT ANAL PREV, V99, P102, DOI 10.1016/j.aap.2016.10.019
   Wu YQ, 2015, HUM FACTORS, V57, P1276, DOI 10.1177/0018720815589665
   Xi Y., 2018, SAE TECHNICAL PAPER, P01
   Zeng H, 2018, COGN NEURODYNAMICS, V12, P597, DOI 10.1007/s11571-018-9496-y
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
NR 26
TC 5
Z9 5
U1 0
U2 2
PY 2020
BP 4392
EP 4397
UT WOS:000687430604068
DA 2023-11-16
ER

PT J
AU Arnaudov, P
   Ogunfunmi, T
AF Arnaudov, Pavel
   Ogunfunmi, Tokunbo
TI Artificially Intelligent Adaptive Search Fast Motion Estimation
   Algorithm for HD Video
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Motion estimation; H; 264; HEVC; AI; ML; ASIC; VLSI; HMDS; Adaptive;
   Video coding; Video compression; Video; multidimensional signal
   processing
ID DIAMOND SEARCH
AB This paper presents a new Machine Learning based approach to video Fast Motion Estimation, which improves quality, minimizes power consumption and provides control over the performance vs power balance, rendering it very suitable for hardware implementation into a motion co-processor. Many mobile and hand-held devices today deploy such hardware accelerators. The main goal of the presented algorithm is to achieve maximum quality Motion Estimation per unit of consumed power by minimizing the number of search points and also providing an optional mechanism for finding an optimal early termination point. The paper presents the creation of a dictionary of adaptively pre-learned fixed search patterns along with a pre-trained neural network to adaptively help select the most adequate search pattern from a dictionary according to the dynamics of the motion within a specific region of the video frame, not the frame or scene as a whole. There are often motions in various directions within the same scene or frame and the ability to focus on a local region within the frame improves quality significantly. Full Search represents the quality goal and upper boundary for any integer Fast Motion Estimation. The presented algorithm adds about 1 dB of PSNR to state-of-the-art fixed search patterns. There is only about 0.5 dB of PSNR remaining between our algorithm and Full Search.
C1 [Arnaudov, Pavel; Ogunfunmi, Tokunbo] Santa Clara Univ, Santa Clara, CA 95053 USA.
RP Ogunfunmi, T (corresponding author), Santa Clara Univ, Santa Clara, CA 95053 USA.
EM togunfunmi@scu.edu
CR Al-Najdawi N, 2014, INFORM SCIENCES, V268, P425, DOI 10.1016/j.ins.2013.08.009
   Arnaudov P., ICCE 17, P221
   Arnaudov P., 2017, 10 INT C UB MED COMP, P1
   Arnaudov P., 2017, ISCAS C, P1
   Arnaudov P, 2017, CONF REC ASILOMAR C, P173, DOI 10.1109/ACSSC.2017.8335161
   Arnaudov P, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P11, DOI 10.1109/SiPS.2016.10
   Cheng YS, 2009, IEEE INT SYMP CIRC S, P880, DOI 10.1109/ISCAS.2009.5117897
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Hosur P.I., 2 INT C INF COMM SIG
   Jeong JH, 2015, INT SOC DESIGN CONF, P275, DOI 10.1109/ISOCC.2015.7401754
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087
   Ndili O, 2011, IEEE T CIRC SYST VID, V21, P1214, DOI 10.1109/TCSVT.2011.2133990
   Ndili O, 2010, IEEE IMAGE PROC, P749, DOI 10.1109/ICIP.2010.5652065
   Parmar N, 2014, INT SOC DESIGN CONF, P260, DOI 10.1109/ISOCC.2014.7087637
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Song X., 1998, ISCAS 98 P 1998 IEEE, V4, P126
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   Tourapis HYC, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P517
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 24
TC 3
Z9 3
U1 0
U2 4
PD APR
PY 2020
VL 92
IS 4
BP 389
EP 408
DI 10.1007/s11265-019-01466-5
UT WOS:000519348800004
DA 2023-11-16
ER

PT C
AU León, EA
   D'Hooge, T
   Hanford, N
   Karlin, I
   Pankajakshan, R
   Foraker, J
   Chambreau, C
   Leininger, ML
AF Leon, Edgar A.
   D'Hooge, Trent
   Hanford, Nathan
   Karlin, Ian
   Pankajakshan, Ramesh
   Foraker, Jim
   Chambreau, Chris
   Leininger, Matthew L.
GP IEEE
TI TOSS-2020: A Commodity Software Stack for HPC
SO PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE
   COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20)
DT Proceedings Paper
CT International Conference on High Performance Computing, Networking,
   Storage and Analysis (SC)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE Scientific computing; Accelerator architectures; Parallel architectures;
   Multicore processing; Multiprocessor interconnection networks; Parallel
   machines; Supercomputers; Processor scheduling; Cluster computing; High
   performance computing; Software performance; Software reusability;
   System software; Operating systems; Utility programs; Programming
   environments; Runtime; Runtime environment; Software libraries
AB The simulation environment of any HPC platform is key to the performance, portability, and productivity of scientific applications. This environment has traditionally been provided by platform vendors, presenting challenges for HPC centers and users including platform-specific software that tend to stagnate over the lifetime of the system. In this paper, we present the Tri-Laboratory Operating System Stack (TOSS), a production simulation environment based on Linux and open source software, with proprietary software components integrated as needed. TOSS, focused on mid-to-large scale commodity HPC systems, provides a common simulation environment across system architectures, reduces the learning curve on new systems, and benefits from a lineage of past experience and bug fixes. To further the scope and applicability of TOSS, we demonstrate its feasibility and effectiveness on a leadership-class supercomputer architecture. Our evaluation, relative to the vendor stack, includes an analysis of resource manager complexity, system noise, networking, and application performance.
C1 [Leon, Edgar A.; D'Hooge, Trent; Hanford, Nathan; Karlin, Ian; Pankajakshan, Ramesh; Foraker, Jim; Chambreau, Chris; Leininger, Matthew L.] Lawrence Livermore Natl Lab, Livermore Comp, Livermore, CA 94550 USA.
RP León, EA (corresponding author), Lawrence Livermore Natl Lab, Livermore Comp, Livermore, CA 94550 USA.
EM leon@llnl.gov; dhooge1@llnl.gov; nhanford@llnl.gov; karlin1@llnl.gov;
   pankajakshan1@llnl.gov; foraker1@llnl.gov; chambreau1@llnl.gov;
   leininger4@llnl.gov
CR Agelastos A., 2014, SC 14
   Ahn Dong H., 2014, 2014 43rd International Conference on Parallel Processing Workshops (ICCPW). Proceedings, P9, DOI 10.1109/ICPPW.2014.15
   [Anonymous], 2018, ALGEBRAIC MULTIGRID
   [Anonymous], 2013, CORAL BENCHMARK CODE
   Balaji P, 2009, LECT NOTES COMPUT SC, V5759, P20, DOI 10.1007/978-3-642-03770-2_9
   Beckman P., 2006, CLUSTER 06
   Capit N, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, VOLS 1 AND 2, P776
   CORAL: Collaboration of Oak Ridge Argonne and Livermore National Laboratories, 2013, B604142 CORAL RFP AS
   Cray, CRAY LIN ENV
   De P., 2009, IPDPS 09
   De P, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING, P331, DOI 10.1109/CLUSTR.2007.4629247
   De Sensi D, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356196
   Doerfler D., 2010, INT J DISTRIBUTED SY, V1
   Exascale Computing Project, ECP PROX APPS SUIT R
   Fermilab, SCI LIN
   Ferreira K. B., 2008, SC 08
   Ferreira K. B., 2010, CLUSTER 10
   Gamblin T, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807623
   Giampapa M., 2010, INT C HIGH PERF COMP
   Groves T, 2017, IEEE INT C CL COMP, P809, DOI 10.1109/CLUSTER.2017.76
   Haring RA, 2012, IEEE MICRO, V32, P48, DOI 10.1109/MM.2011.108
   Hoefler T., 2010, SC 10
   IBM Corporation, 2018, IBM CSM CLUST SYST M
   Jones T., 2003, SC 03
   Jones T, 2011, ROSS 11
   Kato Takeharu, 2019, K COMPUTER, P183, DOI [10.1007/978-981-13-6624-6_11, DOI 10.1007/978-981-13-6624-6_11]
   Kumar S, 2012, INT PARALL DISTRIB P, P763, DOI 10.1109/IPDPS.2012.73
   Lawrence Livermore National Laboratory, TOSS SPEED COMM CLUS
   Lawrence Livermore National Laboratory, PDSH
   Lawrence Livermore National Laboratory, ZFS LIN
   Lawrence Livermore National Laboratory, CONMAN CONS MAN
   Lawrence Livermore National Laboratory, MUNGE MUNGE UID N GI
   Lawrence Livermore National Laboratory, POW
   Leon E. A., 2016, IPDPS 16
   Leon E.A., 2018, GTC 18
   Leon E. A., 2018, MEMSYS 18
   Leon E. A., 2017, MEMSYS 17
   León EA, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P909, DOI 10.1109/SC.2016.77
   Linux Foundation, 2018, OPENHPC COMM BUILD H
   Mellanox Technologies, LIN INF DRIV
   Morari A., 2011, IPDPS 11
   Panda D., 2019, OSU MICROBENCHMARKS
   Pankajakshan R., 2019, IBM J RES DEV
   Papadopoulou N, 2017, IEEE ACM INT SYMP, P345, DOI 10.1109/CCGRID.2017.149
   Petersson NA, 2015, J COMPUT PHYS, V299, P820, DOI 10.1016/j.jcp.2015.07.023
   Petersson NA, 2014, COMMUN COMPUT PHYS, V16, P913, DOI 10.4208/cicp.290113.220514a
   PETRINI F, 2003, SC 03
   Priedhorsky R, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126925
   Pritchard H., 2012, CUG 12
   Red Hat, RED HAT ENT LIN
   Riesen R, 2009, CONCURR COMP-PRACT E, V21, P793, DOI 10.1002/cpe.1361
   Rosenthal E., 2013, SC 13
   Seagate Technology LLC, LUSTR
   Seelam S., 2010, IPDPS 10
   Sjögreen B, 2012, J SCI COMPUT, V52, P17, DOI 10.1007/s10915-011-9531-1
   SUSE Group, SUSE LIN ENT SERV
   SyLabs.io, SINGULARITY
   Tabe T. B., 1995, Computing Science and Statistics. Vol.27. Proceedings of the 27th Symposium on the Interface. Statistics and Manufacturing with Subthemes in Environmental Statistics, Graphics and Imaging, P347
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
   Zimmer C., 2019, SC 19
   TORQUE RESOURCE MANA
NR 61
TC 0
Z9 0
U1 0
U2 1
PY 2020
DI 10.1109/SC41405.2020.00044
UT WOS:000668022000061
DA 2023-11-16
ER

PT J
AU Schade, R
   Kenter, T
   Elgabarty, H
   Lass, M
   Schütt, O
   Lazzaro, A
   Pabst, H
   Mohr, S
   Hutter, J
   Kühne, TD
   Plessl, C
AF Schade, Robert
   Kenter, Tobias
   Elgabarty, Hossam
   Lass, Michael
   Schuett, Ole
   Lazzaro, Alfio
   Pabst, Hans
   Mohr, Stephan
   Hutter, Juerg
   Kuehne, Thomas D.
   Plessl, Christian
TI Towards electronic structure-based <i>ab-initio</i> molecular dynamics
   simulations with hundreds of millions of atoms
SO PARALLEL COMPUTING
DT Article
DE Supercomputing; High-performance computing; Massively-parallel
   algorithms; Large-scale linear algebra; Ab-initio molecular dynamics;
   Approximate computing
ID LINEAR-SCALING DFT; 1ST PRINCIPLES; DENSITY; CODE; PARALLELISM;
   PERFORMANCE; FIELD
AB We push the boundaries of electronic structure-based ab-initio molecular dynamics (AIMD) beyond 100 million atoms. This scale is otherwise barely reachable with classical force-field methods or novel neural network and machine learning potentials. We achieve this breakthrough by combining innovations in linear-scaling AIMD, efficient and approximate sparse linear algebra, low and mixed-precision floating-point computation on GPUs, and a compensation scheme for the errors introduced by numerical approximations.
   The core of our work is the non-orthogonalized local submatrix method (NOLSM), which scales very favorably to massively parallel computing systems and translates large sparse matrix operations into highly parallel, dense matrix operations that are ideally suited to hardware accelerators. We demonstrate that the NOLSM method, which is at the center point of each AIMD step, is able to achieve a sustained performance of 324 PFLOP/s in mixed FP16/FP32 precision corresponding to an efficiency of 67.7% when running on 1536 NVIDIA A100 GPUs.
C1 [Schade, Robert; Kenter, Tobias; Lass, Michael; Kuehne, Thomas D.; Plessl, Christian] Paderborn Univ, Paderborn Ctr Parallel Comp, Warburger Str 100, D-33098 Paderborn, Germany.
   [Kenter, Tobias; Lass, Michael; Plessl, Christian] Paderborn Univ, Dept Comp Sci, Warburger Str 100, D-33098 Paderborn, Germany.
   [Elgabarty, Hossam; Kuehne, Thomas D.] Paderborn Univ, Dept Chem, Warburger Str 100, D-33098 Paderborn, Germany.
   [Schuett, Ole] Swiss Fed Inst Technol, Dept Mat, CH-8092 Zurich, Switzerland.
   [Lazzaro, Alfio] HPE Switzerland GmbH, Basel, Switzerland.
   [Pabst, Hans] Intel Extreme Comp Software & Syst, Zurich, Switzerland.
   [Mohr, Stephan] Nextmol Bytelab Solut SL, Barcelona, Spain.
   [Mohr, Stephan] Barcelona Supercomp Ctr BSC, Barcelona, Spain.
   [Hutter, Juerg] Univ Zurich, Dept Chem, Zurich, Switzerland.
RP Kühne, TD (corresponding author), Paderborn Univ, Paderborn Ctr Parallel Comp, Warburger Str 100, D-33098 Paderborn, Germany.; Kühne, TD (corresponding author), Paderborn Univ, Dept Chem, Warburger Str 100, D-33098 Paderborn, Germany.
EM thomas.kuehne@uni-paderborn.de
CR Andermatt S, 2016, J CHEM THEORY COMPUT, V12, P3214, DOI 10.1021/acs.jctc.6b00398
   [Anonymous], HARDWARE CONFIGURATI
   [Anonymous], JUWELS BOOSTER TOP 5
   Arita M, 2014, J ADV SIMUL SCI ENG, V1, P87, DOI 10.15748/jasse.1.87
   Bartók AP, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1701816
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   Bowler DR, 2010, J PHYS-CONDENS MAT, V22, DOI 10.1088/0953-8984/22/7/074207
   CAR R, 1985, PHYS REV LETT, V55, P2471, DOI 10.1103/PhysRevLett.55.2471
   Das S, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3357157
   ESSMANN U, 1995, J CHEM PHYS, V103, P8577, DOI 10.1063/1.470117
   Fattebert JL, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P12, DOI 10.1109/SC.2016.88
   GALLI G, 1992, PHYS REV LETT, V69, P3547, DOI 10.1103/PhysRevLett.69.3547
   github, US
   Goedecker S, 1999, REV MOD PHYS, V71, P1085, DOI 10.1103/RevModPhys.71.1085
   Grimme S, 2017, J CHEM THEORY COMPUT, V13, P1989, DOI 10.1021/acs.jctc.7b00118
   Grimme S, 2011, J COMPUT CHEM, V32, P1456, DOI 10.1002/jcc.21759
   Gygi, 2006, P 2006 ACM IEEE C SU, P45
   Gygi F, 2008, IBM J RES DEV, V52, P137, DOI 10.1147/rd.521.0137
   Hasegawa Y, 2014, INT J HIGH PERFORM C, V28, P335, DOI 10.1177/1094342013508163
   Higham NJ, 1997, NUMER ALGORITHMS, V15, P227, DOI 10.1023/A:1019150005407
   Hutter J, 2005, CHEMPHYSCHEM, V6, P1788, DOI 10.1002/cphc.200500059
   Hutter J, 2005, PARALLEL COMPUT, V31, P1, DOI 10.1016/j.parco.2004.12.004
   Jain N, 2016, LECT NOTES COMPUT SC, V9697, P139, DOI 10.1007/978-3-319-41321-1_8
   Johnson SG, 2001, OPT EXPRESS, V8, P173, DOI 10.1364/OE.8.000173
   Karhan K, 2014, J CHEM PHYS, V141, DOI 10.1063/1.4902537
   Keith J.A, ARXIV
   KENNEY C, 1991, SIAM J MATRIX ANAL A, V12, P273, DOI 10.1137/0612020
   Klavík P, 2014, PHILOS T R SOC A, V372, DOI 10.1098/rsta.2013.0278
   Kühne TD, 2020, ANN PHYS-NEW YORK, V421, DOI 10.1016/j.aop.2020.168290
   Kühne TD, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0007045
   Kühne TD, 2018, ANN PHYS-NEW YORK, V391, P120, DOI 10.1016/j.aop.2018.01.016
   Kühne TD, 2014, WIRES COMPUT MOL SCI, V4, P391, DOI 10.1002/wcms.1176
   Kühne TD, 2009, J CHEM THEORY COMPUT, V5, P235, DOI 10.1021/ct800417q
   Kühne TD, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.066401
   Lass, 2020, PROC INT C HIGH PERF, P1127
   Lass M, 2017, PROCEEDINGS OF THE PLATFORM FOR ADVANCED SCIENTIFIC COMPUTING CONFERENCE (PASC '18), DOI 10.1145/3218176.3218231
   MacKerell AD, 1998, J PHYS CHEM B, V102, P3586, DOI 10.1021/jp973084f
   MCWEENY R, 1960, REV MOD PHYS, V32, P335, DOI 10.1103/RevModPhys.32.335
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Motamarri P, 2020, COMPUT PHYS COMMUN, V246, DOI 10.1016/j.cpc.2019.07.016
   Nakata A, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0005074
   Németh K, 2000, J CHEM PHYS, V113, P6035, DOI 10.1063/1.1308546
   Nomura K, 2014, INT CONF HIGH PERFOR, P661, DOI 10.1109/SC.2014.59
   nvidia, US
   NVIDIA Corp, 2021, CUDA C PROGRAMMING G
   PAYNE MC, 1992, REV MOD PHYS, V64, P1045, DOI 10.1103/RevModPhys.64.1045
   Plessl C., 2015, INFORM SPEKTRUM, V38, P396, DOI DOI 10.1007/S00287-015-0911-Z
   Prentice JCA, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0004445
   Prodan E, 2005, P NATL ACAD SCI USA, V102, P11635, DOI 10.1073/pnas.0505436102
   PULAY P, 1969, MOL PHYS, V17, P197, DOI 10.1080/00268976900100941
   RAHMAN A, 1964, PHYS REV, V136, pA405, DOI 10.1103/PhysRev.136.A405
   RAPPE AK, 1992, J AM CHEM SOC, V114, P10024, DOI 10.1021/ja00051a040
   Rengaraj V, 2020, COMPUTATION, V8, DOI 10.3390/computation8020039
   Ricci A, 2003, MOL PHYS, V101, P1927, DOI 10.1080/0026897031000108113
   Richters D, 2019, COMMUN COMPUT PHYS, V25, P564, DOI 10.4208/cicp.OA-2018-0053
   Richters D, 2014, J CHEM PHYS, V140, DOI 10.1063/1.4869865
   Schade Robert, 2021, Zenodo, DOI 10.5281/ZENODO.4692508
   Schulz G., 1933, Z ANGEW MATH MECH, V13, P57, DOI [10.1002/zamm.19330130111, DOI 10.1002/ZAMM.19330130111]
   VandeVondele J, 2012, J CHEM THEORY COMPUT, V8, P3565, DOI 10.1021/ct200897x
   Wilkinson KA, 2014, J CHEM THEORY COMPUT, V10, P4782, DOI 10.1021/ct500686r
   YANG WT, 1991, PHYS REV LETT, V66, P1438, DOI 10.1103/PhysRevLett.66.1438
   Zhao GP, 2013, NATURE, V497, P643, DOI 10.1038/nature12162
   Zhao ZJ, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012079
NR 63
TC 8
Z9 8
U1 1
U2 3
PD JUL
PY 2022
VL 111
AR 102920
DI 10.1016/j.parco.2022.102920
UT WOS:000919045000003
DA 2023-11-16
ER

PT J
AU Vandebon, J
   Coutinho, JGF
   Luk, W
AF Vandebon, Jessica
   Coutinho, Jose G. F.
   Luk, Wayne
TI Scheduling Hardware-Accelerated Cloud Functions
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Cloud computing; Heterogeneous computing; FaaS; FPGA
AB This paper presents a Function-as-a-Service (FaaS) approach for deploying managed cloud functions onto heterogeneous cloud infrastructures. Current FaaS systems, such as AWS Lambda, allow domain-specific functionality, such as AI, HPC and image processing, to be deployed in the cloud while abstracting users from infrastructure and platform concerns. Existing approaches, however, use a single type of resource configuration to execute all function requests. In this paper, we present a novel FaaS approach that allows cloud functions to be effectively executed across heterogeneous compute resources, including hardware accelerators such as GPUs and FPGAs. We implement heterogeneous scheduling to tailor resource selection to each request, taking into account performance and cost concerns. In this way, our approach makes use of different processor types and quantities (e.g. 2 CPU cores), uniquely suited to handle different types of workload, potentially providing improved performance at a reduced cost. We validate our approach in three application domains: machine learning, bio-informatics, and physics, and target a hardware platform with a combined computational capacity of 24 FPGAs and 12 CPU cores. Compared to traditional FaaS, our approach achieves a cost improvement for non-uniform traffic of up to 8.9 times, while maintaining performance objectives.
C1 [Vandebon, Jessica; Coutinho, Jose G. F.; Luk, Wayne] Imperial Coll London, London, England.
RP Vandebon, J (corresponding author), Imperial Coll London, London, England.
EM jessica.vandebon17@imperial.ac.uk; gabriel.figueiredo@imperial.ac.uk;
   w.luk@imperial.ac.uk
CR Amazon Web Services, AM EC2
   Amazon Web Services, AWS LAMBD SERV COMP
   Apache Software Foundation, OP SOURC SERV CLOUD
   Arram J, 2017, IEEE ACM T COMPUT BI, V14, P668, DOI 10.1109/TCBB.2016.2535385
   Bleuse R, 2017, IEEE T PARALL DISTR, V28, P2689, DOI 10.1109/TPDS.2017.2675891
   Google Cloud Platform, CLOUD FUNCT
   Graepel T., 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Kubeless, KUB NAT SERV FRAM
   Maxeler, 2015, N BOD PART SIM
   Microsoft Azure, AZ FUNCT SERV COMP
   Peilun Du, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P534, DOI 10.1109/HPCC/SmartCity/DSS.2019.00084
   SciPy.org, SCIPY OPT
   Vandebon J, 2020, IEEE INT CONF ASAP, P141, DOI 10.1109/ASAP49362.2020.00032
   Vandebon J, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P162, DOI 10.1109/ICFPT47387.2019.00027
   Wen Y, 2014, INT C HIGH PERFORM
   Yasudo R, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P317, DOI 10.1109/FPT.2018.00062
NR 16
TC 1
Z9 1
U1 1
U2 1
PD DEC
PY 2021
VL 93
IS 12
BP 1419
EP 1431
DI 10.1007/s11265-021-01695-7
EA OCT 2021
UT WOS:000712487900001
DA 2023-11-16
ER

PT J
AU Elbtity, ME
   Chandarana, PS
   Reidy, B
   Eshraghian, JK
   Zand, R
AF Elbtity, Mohammed E.
   Chandarana, Peyton S.
   Reidy, Brendan
   Eshraghian, Jason K.
   Zand, Ramtin
TI APTPU: Approximate Computing Based Tensor Processing Unit
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Approximate computing; tensor processing units; machine learning
   hardware accelerator; systolic array
ID POWER
AB We propose an approximate tensor processing unit (APTPU), which includes two main components: (1) approximate processing elements (APEs) consisting of a low-precision multiplier and an approximate adder, and (2) pre-approximate units (PAUs) which are shared among the APEs in the APTPU's systolic array, functioning as the steering logic to pre-process the operands and feed them to the APEs. We conduct extensive experiments to evaluate the performance of the APTPU across various configurations and various workloads. The results show that the APTPU's systolic array achieves up to 5.2 x TOPSmm(2) and 4.4 x TOPS/W improvements compared to that of a conventional systolic array design. The comparison between the proposed APTPU and in-house TPU designs shows that we can achieve approximately 2.5 x and 1.2 x area and power reduction, respectively, while realizing comparable accuracy. Finally, a comparison with the state-of-the-art approximate systolic arrays shows that the APTPU can realize up to 1.58x , 2x , and 1.78x , reduction in delay, power, and area, respectively, while using similar design specifications and synthesis constraints.
C1 [Elbtity, Mohammed E.; Chandarana, Peyton S.; Reidy, Brendan; Zand, Ramtin] Univ South Carolina, Dept Comp Sci & Comp Engn, Columbia, SC 29201 USA.
   [Eshraghian, Jason K.] Univ Calif Santa Cruz, Dept Elect & Comp Engn, Santa Cruz, CA 95064 USA.
RP Elbtity, ME (corresponding author), Univ South Carolina, Dept Comp Sci & Comp Engn, Columbia, SC 29201 USA.
EM elbtity@ieee.org
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/ICACCS48705.2020.9074315, 10.1109/icaccs48705.2020.9074315]
   Amudha M., 2012, INT J ELECT COMPUT S, V1, P522
   [Anonymous], 2017, ARXIV, Patent No. 171009829Cs
   [Anonymous], 2020, ARXIV
   Ansari MS, 2021, IEEE T COMPUT, V70, P614, DOI 10.1109/TC.2020.2992113
   Balasubramanian P, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111212
   Bhardwaj K, 2015, INT SYM QUAL ELECT, P263
   Boro B, 2020, MICROELECTRON J, V101, DOI 10.1016/j.mejo.2020.104816
   Chen K, 2015, IEEE INT SYMP NANO, P151, DOI 10.1109/NANOARCH.2015.7180604
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Dalloo A, 2018, IEEE T VLSI SYST, V26, P1595, DOI 10.1109/TVLSI.2018.2822278
   Elbtity ME, 2020, INT SOC DESIGN CONF, P71, DOI 10.1109/ISOCC50952.2020.9333013
   Guo SS, 2019, PR GR LAK SYMP VLSI, P63, DOI 10.1145/3299874.3317966
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Jiang HL, 2020, P IEEE, V108, P2108, DOI 10.1109/JPROC.2020.3006451
   Jing Shen, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1200, DOI 10.1109/ICCT46805.2019.8947127
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kumar Vinay, 2019, Proceedings of 2nd International Conference on Communication, Computing and Networking. ICCCN 2018. Lecture Notes in Networks and Systems (LNNS 46), P607, DOI 10.1007/978-981-13-1217-5_59
   Lahari P. L., 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1039, DOI 10.1109/ICOEI48184.2020.9142930
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee Jaeheum, 2021, J Nanosci Nanotechnol, V21, P1854, DOI 10.1166/jnn.2021.18925
   Liang TL, 2021, NEUROCOMPUTING, V461, P370, DOI 10.1016/j.neucom.2021.07.045
   Lim H, 2000, IEEE T COMPUT, V49, P1297, DOI 10.1109/12.895848
   Lin IC, 2015, IEEE T VLSI SYST, V23, P1591, DOI 10.1109/TVLSI.2014.2355217
   Liu WQ, 2018, IEEE T CIRCUITS-I, V65, P2856, DOI 10.1109/TCSI.2018.2792902
   Liu WQ, 2017, IEEE T COMPUT, V66, P1435, DOI 10.1109/TC.2017.2672976
   Mitchell J. N., 1962, IRE T ELECT COMPUTER, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mo H., 2019, PROC 56 ACMIEEE DESI, P1
   Nam BG, 2008, IEEE T COMPUT, V57, P490, DOI 10.1109/TC.2008.12
   Nayar R, 2020, IEEE COMP SOC ANN, P84, DOI 10.1109/ISVLSI49217.2020.00025
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Samajdar Ananda, 2018, ARXIV
   Sullivan MB, 2012, CONF REC ASILOMAR C, P355, DOI 10.1109/ACSSC.2012.6489023
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Wang JP, 2011, IEEE T VLSI SYST, V19, P52, DOI 10.1109/TVLSI.2009.2032289
   Waris H, 2021, J SIGNAL PROCESS SYS, V93, P605, DOI 10.1007/s11265-020-01582-7
   Waris H, 2019, IEEE WRK SIG PRO SYS, P13, DOI [10.1109/sips47522.2019.9020404, 10.1109/SiPS47522.2019.9020404]
   Xiao H., 2017, ARXIV170807747
   Xu XW, 2018, PROC CVPR IEEE, P8300, DOI 10.1109/CVPR.2018.00866
   Yin PP, 2021, IEEE T SUST COMPUT, V6, P612, DOI 10.1109/TSUSC.2020.3004980
   Younes H, 2019, IEEE I C ELECT CIRC, P113, DOI [10.1109/icecs46596.2019.8964974, 10.1109/ICECS46596.2019.8964974]
   Zhou Aojun, 2017, INT C LEARN REPR ICL
NR 46
TC 3
Z9 3
U1 1
U2 5
PD DEC
PY 2022
VL 69
IS 12
BP 5135
EP 5146
DI 10.1109/TCSI.2022.3206262
EA SEP 2022
UT WOS:000862437300001
DA 2023-11-16
ER

PT C
AU Sunkavilli, S
   Zhang, ZM
   Yu, QY
AF Sunkavilli, Sandeep
   Zhang, Zhiming
   Yu, Qiaoyan
GP IEEE Comp Soc
TI New Security Threats on FPGAs: From FPGA Design Tools Perspective
SO 2021 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2021)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 20th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 07-09, 2017-2021
CL ELECTR NETWORK
DE FPGA security; hardware security; covert channel; hardware Trojan;
   multi-tenant FPGA; cloud computing
AB The growing market share of FPGAs motivates the increasing number of attackers to tamper with FPGA systems. The majority of existing research efforts on FPGA security focus on counterfeiting devices, hardware Trojans, reverse engineering hardware designs via decomposing or decrypting bitstream files, and side-channel analysis attacks. Those attacks are typically limited to the FPGA systems implemented in standalone FPGA devices. As more cloud-based FPGA providers, third-party accelerator suppliers, and open-source FPGA design tools are available for prototyping, hardware acceleration, and high-performance computing, new FPGA utilization models are gradually formed. The increasing number of entities involved in the new FPGA use model leads to the emergence of new security threats and attack surfaces. Although the security issues on FPGA systems design and piracy have been widely investigated, there is limited investigation available disclosing the security threats from the FPGA design tools perspective. This work conducts a comprehensive survey on the FPGA tool security and proposes a thorough security threat landscape for the new FPGA utilization model in the era of machine learning and cloud computing.
C1 [Sunkavilli, Sandeep; Zhang, Zhiming; Yu, Qiaoyan] Univ New Hampshire, Dept Elect & Comp Engn, Durham, NH 03824 USA.
RP Sunkavilli, S (corresponding author), Univ New Hampshire, Dept Elect & Comp Engn, Durham, NH 03824 USA.
CR Alam Md Mahbub, 2019, 2019 Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC). Proceedings, P48, DOI 10.1109/FDTC.2019.00015
   [Anonymous], 2015, ISO IEC, P1, DOI [DOI 10.1109/IEEESTD.2015.7118618, DOI 10.1016/B978-0-7020-2920-2.50020-0, DOI 10.1109/IEEESTD.2015.7106435]
   Benhani EM, 2019, IEEE T COMPUT, V68, P1238, DOI 10.1109/TC.2019.2900235
   Chakraborty RS, 2013, IEEE DES TEST, V30, P45, DOI 10.1109/MDT.2013.2247460
   Chhotaray A., 2017, P CCS 17, P1533
   Dogan H, 2014, INT SYM DEFEC FAU TO, P171, DOI 10.1109/DFT.2014.6962099
   Giechaskil I, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3322483
   Gundabolu S, 2018, IEEE COMP SOC ANN, P644, DOI 10.1109/ISVLSI.2018.00122
   Hoque T, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3361147
   Intel, 2019, AN 556 US DES SEC F, V11
   Jin C., 2020, ARXIV PREPRINT ARXIV
   Krautter J., 2018, IACR TCHES, P44, DOI 10.13154/tches.v2018.i3.44-68
   Krautter J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3328222
   Krieg C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967054
   Luo YK, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P331, DOI 10.1109/ICFPT47387.2019.00060
   Mal-Sarkar S, 2014, PR GR LAK SYMP VLSI, P287, DOI 10.1145/2591513.2591520
   Moradi A, 2016, LECT NOTES COMPUT SC, V9689, P71, DOI 10.1007/978-3-319-43283-0_5
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Murray KE, 2020, IEEE MICRO, V40, P49, DOI 10.1109/MM.2020.2998435
   Narula S, 2015, INT C ADV COMPUT COM, P501, DOI 10.1109/ACCT.2015.20
   Olney B, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3373638
   Pham KD, 2018, 2018 IEEE 12TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2018), P36, DOI 10.1109/MCSoC2018.2018.00018
   Pitaka S., 2020, XILINX XAPP1222
   Provelengios G, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P292, DOI 10.1145/3289602.3293923
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Seifoori Z, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P197, DOI 10.1145/3373087.3375319
   Sunkavilli S, 2021, INT SYM QUAL ELECT, P504, DOI 10.1109/ISQED51717.2021.9424291
   Thoonen M., 2019, THESIS U TWENTE
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Trimberger SM, 2014, P IEEE, V102, P1248, DOI 10.1109/JPROC.2014.2331672
   Turan F., 2020, CSUR, V53, P1
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xilinx, US ENCR SEC 7 SER FP, V2, P2021
   Zhang JL, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3340557
   Zhang T, 2019, IEEE ACCESS, V7, P38379, DOI 10.1109/ACCESS.2019.2901949
   Zhang ZM, 2019, IEEE T VLSI SYST, V27, P665, DOI 10.1109/TVLSI.2018.2879878
NR 36
TC 5
Z9 5
U1 6
U2 32
PY 2021
BP 278
EP 283
DI 10.1109/ISVLSI51109.2021.00058
UT WOS:000708182400047
DA 2023-11-16
ER

PT C
AU Sankaralingam, K
   Nowatzki, T
   Gangadhar, V
   Shah, P
   Davies, M
   Galliher, W
   Guo, ZL
   Khare, J
   Vijay, D
   Palamuttam, P
   Punde, M
   Tan, A
   Thiruvengadam, V
   Wang, RY
   Xu, SM
AF Sankaralingam, Karthikeyan
   Nowatzki, Tony
   Gangadhar, Vinay
   Shah, Preyas
   Davies, Michael
   Galliher, William
   Guo, Ziliang
   Khare, Jitu
   Vijay, Deepak
   Palamuttam, Poly
   Punde, Maghawan
   Tan, Alex
   Thiruvengadam, Vijay
   Wang, Rongyi
   Xu, Shunmiao
GP ACM
TI The Mozart Reuse Exposed Dataflow Processor for AI and Beyond
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
DE dataflow; reuse; accelerator; multicasting; chips; machine learning
ID FLEXIBILITY; COMPILER
AB In this paper we introduce the Mozart Processor, which implements a new processing paradigm called Reuse Exposed Dataflow (RED). RED is a counterpart to existing execution models of Von-Neumann, SIMT, Dataflow, and FPGA. Dataflow and data reuse are the fundamental architecture primitives in RED, implemented with mechanisms for inter-worker communication and synchronization. The paper defines the processor architecture, the details of the microarchitecture, chip implementation, software stack development, and performance results. The architecture's goal is to achieve near-CPU like flexibility while having ASIC-like efficiency for a large-class of data-intensive workloads. An additional goal was software maturity - have large coverage of applications immediately, avoiding the need for a long-drawn hand-tuning software development phase. The architecture was defined with this software-maturity/compiler friendliness in mind. In short, the goal was to do to GPUs, what GPUs did to CPUs - i.e. be a better solution for a large range of workloads, while preserving flexibility and programmability. The chip was implemented with HBM and PCIe interfaces and taken to production on a 16nm TSMC FFC process. For ML inference tasks with batch-size=4, Mozart is integer factors better than state-of-the-art GPUs even while being nearly 2 technology nodes behind. We conclude with a set of lessons learned, the unique challenges of a clean-slate architecture in a commercial setting, and pointers for uncovered research problems.
C1 [Sankaralingam, Karthikeyan; Nowatzki, Tony; Gangadhar, Vinay; Shah, Preyas; Davies, Michael; Galliher, William; Guo, Ziliang; Khare, Jitu; Vijay, Deepak; Palamuttam, Poly; Punde, Maghawan; Tan, Alex; Thiruvengadam, Vijay; Wang, Rongyi; Xu, Shunmiao] SimpleMachines Inc, San Jose, CA 95134 USA.
   [Nowatzki, Tony] UCLA, Los Angeles, CA USA.
RP Sankaralingam, K (corresponding author), SimpleMachines Inc, San Jose, CA 95134 USA.
CR Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Asanovic K., 2016, ROCKET CHIP GENERATO
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Bhaskaracharya S.G., 2020, ARXIV
   Cao Y, 2022, J COMPUT ASSIST LEAR, V38, P845, DOI 10.1111/jcal.12652
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Cho Sung-Gun, 2021, 2021 S VLSI CIRCUITS, P1, DOI [10.23919/VLSICircuits52068.2021.9492517, DOI 10.23919/VLSICIRCUITS52068.2021.9492517]
   Clark Don, 2017, NEW YORK TIMES
   Cook H, 2017, 1 WORKSHOP COMPUTER
   CYTRON R, 1991, ACM T PROGR LANG SYS, V13, P451, DOI 10.1145/115372.115320
   Dadu V, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P1, DOI 10.1145/3503222.3507706
   Dadu V, 2021, CONF PROC INT SYMP C, P595, DOI 10.1109/ISCA52012.2021.00053
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   Darvish Rouhani B., 2020, ADV NEURAL INFORM PR, V33, P10271
   Dave S, 2021, P IEEE, V109, P1706, DOI 10.1109/JPROC.2021.3098483
   DFI Group, 2021, DFI SPEC
   Domke Jens, 2021, IEEE INT PARALLEL DI
   Dong Junfeng, 2019, ACCELERATING COMPUTE
   Ehsan Ardestani K., 2021, ARXIV
   Georganas Evangelos, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P830, DOI 10.1109/SC.2018.00069
   Han RC, 2019, INT SYM PERFORM ANAL, P22, DOI 10.1109/ISPASS.2019.00011
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He YZ, 2019, INT CONF ACOUST SPEE, P6381, DOI 10.1109/ICASSP.2019.8682336
   Hooker S, 2021, COMMUN ACM, V64, P58
   Hower DR, 2014, ACM SIGPLAN NOTICES, V49, P427, DOI 10.1145/2541940.2541981
   Huang QJ, 2021, CONF PROC INT SYMP C, P554, DOI 10.1109/ISCA52012.2021.00050
   Intel, 2022, INT 64 IA 32 ARCH OP
   Johnson J, 2018, Arxiv, DOI arXiv:1811.01721
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Kal H, 2021, CONF PROC INT SYMP C, P679, DOI 10.1109/ISCA52012.2021.00059
   Lee Y, 2016, IEEE MICRO, V36, P8, DOI 10.1109/MM.2016.11
   Li MZ, 2021, IEEE T PARALL DISTR, V32, P708, DOI 10.1109/TPDS.2020.3030548
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Mittal S, 2022, IEEE T NEUR NET LEAR, V33, P5095, DOI 10.1109/TNNLS.2021.3071762
   Nowatzki T, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243212
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Nowatzki T, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P298, DOI 10.1145/2749469.2750380
   Nowatzki Tony, 2013, P 34 INT C PROGRAMMI
   NVIDIA, 2021, CUTLASS 2 8
   Pradeep Vijay, 2017, ETHEREUM MEMORY HARD
   Qadeer W, 2015, COMMUN ACM, V58, P85, DOI 10.1145/2735841
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Ries E., 2011, LEAN STARTUP TODAYS, DOI DOI 10.1111/J.1540-5885.2012.00920_2.X
   Sankaralingam Karthikeyan, 2021, SYSTEMS METHODS STRE
   Sankaralingam Karthikeyan, 2021, METHOD COMPUTER PROG
   Sankaralingam Karthikeyan, 2020, ACCELERATING PARALLE
   Shallue CJ, 2019, J MACH LEARN RES, V20
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   TESLA, 2021, TESL DOJ TECHN GUID
   Vaswani A, 2017, ADV NEUR IN, V30
   Vijayaraghavan T, 2018, IEEE COMPUT ARCHIT L, V17, P179, DOI 10.1109/LCA.2018.2849064
   Wang ZR, 2021, INT S HIGH PERF COMP, P640, DOI 10.1109/HPCA51647.2021.00060
   Wang ZR, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P736, DOI 10.1145/3307650.3322229
   Weng J, 2020, INT S HIGH PERF COMP, P703, DOI 10.1109/HPCA47549.2020.00063
   Wheeler Bob, 2021, SAMBANOVA TAKES NVID
   Zhaoying Li, 2022, 2022 IEEE INT S HIGH
NR 61
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 978
EP 992
DI 10.1145/3470496.3533040
UT WOS:000852702500068
DA 2023-11-16
ER

PT J
AU Chen, YR
   Wang, TF
   Chen, SH
   Kao, YC
AF Chen, Yean Ru
   Wang, Tzu Fan
   Chen, Si-Han
   Kao, Yi-Chun
TI Empirical study on security verification and assessment of neural
   network accelerator
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Neural network; Formal verification; Hardware Trojan; Risk assessment;
   Trojan detection
AB With the significant success of machine learning, there are plenty of innovative neural network designs nowadays. The related applications become more and more pervasive in our daily life, even in life-critical domains such as autopilot and medical diagnosis, etc. In these domains, whether the AI-based system is "secure"or not is a critical issue. In this work, we first present six Hardware Trojan attacks with demonstrations of their impacts on the hardware design of neural networks. When data leakage occurs, we encode the leakage data to the output and make it more difficult to be detected. Most of our attacks can either achieve more than 98% attack success rate or leak out confidential data without causing any functional violation, with less than 1.5% overhead. We also discuss how to effectively and efficiently detect these Hardware Trojans with formal verification methods and further propose a risk assessment process to constitute a priority guidance to suggest security verification tasks of neuron network hardware. Based on our results, we strongly suggest that security specification and total verification are essential to neuron network designs.
C1 [Chen, Yean Ru; Wang, Tzu Fan; Chen, Si-Han; Kao, Yi-Chun] Natl Cheng Kung Univ, 1 Univ Rd, Tainan 70101, Taiwan.
RP Chen, YR (corresponding author), Natl Cheng Kung Univ, 1 Univ Rd, Tainan 70101, Taiwan.
EM chenyr@mail.ncku.edu.tw
CR Abbink David A., 2022, Road Vehicle Automation 8. Lecture Notes in Mobility, P60, DOI 10.1007/978-3-030-80063-5_6
   [Anonymous], 2006, 2006 IEEE INT TEST C, DOI DOI 10.1109/TEST.2006.297720
   Baier C, 2008, PRINCIPLES OF MODEL CHECKING, P1
   Berezin S, 1998, LECT NOTES COMPUT SC, V1536, P81, DOI 10.1007/3-540-49213-5_4
   Cadence Design Systems Inc., JASPERGOLD FORM VER
   Chakraborty RS, 2009, INT HIGH LEVEL DESIG, P166, DOI 10.1109/HLDVT.2009.5340158
   Clements J, 2018, Arxiv, DOI arXiv:1806.05768
   Clements J, 2019, IEEE INT SYMP CIRC S
   Corin Ricardo, 2012, Information and Communication Security. 14th International Conference (ICICS 2012). Proceedings, P264, DOI 10.1007/978-3-642-34129-8_23
   Cruz J, 2018, I CONF VLSI DESIGN, P91, DOI 10.1109/VLSID.2018.43
   DeepMind I., ALPHAGO PROJ
   Fagot C., 1999, European Test Workshop 1999 (Cat. No.PR00390), P7, DOI 10.1109/ETW.1999.803819
   Gehr T, 2018, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2018.00058
   Hetherington G., 1999, International Test Conference 1999. Proceedings (IEEE Cat. No.99CH37034), P358, DOI 10.1109/TEST.1999.805650
   Hoque T, 2018, INT TEST CONF P
   Hu X, 2021, IEEE T COMPUT AID D, V40, P1230, DOI 10.1109/TCAD.2020.2995347
   Jacob N, 2014, IET COMPUT DIGIT TEC, V8, P264, DOI 10.1049/iet-cdt.2014.0039
   Jin Y, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HARDWARE-ORIENTED SECURITY AND TRUST, P50, DOI 10.1109/HST.2009.5224971
   Kuo MH, 2019, 2019 IEEE INTERNATIONAL TEST CONFERENCE IN ASIA (ITC-ASIA 2019), P43, DOI 10.1109/ITC-Asia.2019.00021
   LeCun Y., MNIST DATABASE HANDW
   Li H., 2017, PROC INT C LEARN REP
   Li WS, 2018, IEEE COMP SOC ANN, P482, DOI 10.1109/ISVLSI.2018.00093
   Liu ZZ, 2020, IEEE VLSI TEST SYMP, DOI 10.1109/vts48691.2020.9107582
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Nahiyan A, 2017, INT TEST CONF P
   Pierce J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300275
   Piscitelli R., 2015, P INT C DES TECHN IN, P1, DOI DOI 10.1109/DTIS.2015.7127352
   Rajendran J, 2016, I CONF VLSI DESIGN, P547, DOI 10.1109/VLSID.2016.143
   Rajendran J, 2015, DES AUT CON, DOI 10.1145/2744769.2744823
   Salmani H, 2017, IEEE T INF FOREN SEC, V12, P338, DOI 10.1109/TIFS.2016.2613842
   Tehranipoor M, 2010, IEEE DES TEST COMPUT, V27, P10, DOI 10.1109/MDT.2010.7
   Yasaei R., 2022, HARDWARE TROJAN DETE
   Yasaei R, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1504, DOI 10.23919/DATE51398.2021.9474174
   Ye J, 2018, ASIAN TEST SYMPOSIUM, P68, DOI 10.1109/ATS.2018.00024
   Yean-Ru Chen, 2014, 2014 International Conference on Trustworthy Systems and their Applications, P22, DOI 10.1109/TSA.2014.13
   Yin J, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8919127
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zhang BY, 2019, IEEE T CIRCUITS-II, V66, P2052, DOI 10.1109/TCSII.2019.2899829
   Zhang JL, 2020, IEEE T NEUR NET LEAR, V31, P2578, DOI 10.1109/TNNLS.2019.2933524
   Zhao Y, 2019, DES AUT TEST EUROPE, P1415, DOI [10.23919/DATE.2019.8715027, 10.23919/date.2019.8715027]
NR 40
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2023
VL 99
AR 104845
DI 10.1016/j.micpro.2023.104845
EA MAY 2023
UT WOS:001010849600001
DA 2023-11-16
ER

PT C
AU Zaruba, F
   Schuiki, F
   Mach, S
   Benini, L
AF Zaruba, Florian
   Schuiki, Fabian
   Mach, Stefan
   Benini, Luca
GP IEEE
TI The Floating Point Trinity: A Multi-modal Approach to Extreme
   Energy-Efficiency and Performance
SO 2019 26TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND
   SYSTEMS (ICECS)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 26th IEEE International Conference on Electronics, Circuits and Systems
   (ICECS)
CY NOV 27-29, 2019
CL Genoa, ITALY
AB The demand for floating-point compute power is ever growing. The domains of big-data, machine learning, and scientific computing require a wide precision range and high operational intensity. The sheer number of operations paired with increased power density implied by technology scaling makes it more important than ever to achieve maximum energy-efficiency for floating point operations. In this work, we present Kosmodrom, our novel silicon solution in Globalfoundries 22 nm Fully-Depleted Silicon on Insulator (FD-SOI) which offers a multi-dimensional approach to trade-off performance, energy-efficiency and power consumption. A variable-precision, dual-core RISC-V system together with a specialized floating point accelerator form the architectural basis. Different implementation strategies and standard cell flavors provide optimal solutions for different operating conditions while supply voltage and forward body bias (FBB) enable for a dynamic trade-off during operation. In this work, we provide a unique insight into the impact of a multitude of tuning parameters to achieve the optimal operating point on the power-performance surface. Kosmodrom achieves a peak energy-efficiency of 260Gflop/s/W and up to 28Gflop/s peak performance within a 6.2-400mW power envelope.
C1 [Zaruba, Florian; Schuiki, Fabian; Mach, Stefan; Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab IIS, Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn DEI, Bologna, Italy.
RP Zaruba, F (corresponding author), Swiss Fed Inst Technol, Integrated Syst Lab IIS, Zurich, Switzerland.
EM zarubaf@iis.ee.ethz.ch; fschuiki@iis.ee.ethz.ch; smach@iis.ee.ethz.ch;
   lbenini@iis.ee.ethz.ch
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Dongarra JJ, 1997, SUPERCOMPUTER, V13, P89
   Feng WC, 2007, COMPUTER, V40, P50, DOI 10.1109/MC.2007.445
   Hall C., 2018, KEEPING COOL CUTTING
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kogge P., 2008, TECH REP, P15
   Mach S., 2019, 080 PJ FLOP 1 24 TFL
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Reed DA, 2015, COMMUN ACM, V58, P56, DOI 10.1145/2699414
   Schuiki F, 2019, IEEE T COMPUT, V68, P484, DOI 10.1109/TC.2018.2876312
   Shibahara S, 2017, IEEE J SOLID-ST CIRC, V52, P77, DOI 10.1109/JSSC.2016.2623682
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Youn Kyu Lee, 2014, 2014 21st Asia-Pacific Software Engineering Conference (APSEC), P199, DOI 10.1109/APSEC.2014.39
   Zaruba F., 2019, IEEE T VERY LARGE SC, P1
NR 15
TC 4
Z9 4
U1 0
U2 5
PY 2019
BP 767
EP 770
DI 10.1109/icecs46596.2019.8964820
UT WOS:000534573400201
DA 2023-11-16
ER

PT J
AU Ali, MS
   Bin Iqbal, MT
   Lee, KH
   Muqeet, A
   Lee, SH
   Kim, L
   Bae, SH
AF Ali, Muhammad Salman
   Iqbal, Md Tauhid Bin
   Lee, Kang-Ho
   Muqeet, Abdul
   Lee, Seunghyun
   Kim, Lokwon
   Bae, Sung-Ho
TI ERDNN: Error-Resilient Deep Neural Networks With a New Error Correction
   Layer and Piece-Wise Rectified Linear Unit
SO IEEE ACCESS
DT Article
DE Hardware; Error correction; Convolution; Machine learning; Computational
   complexity; Neural networks; Standards; Deep learning; soft error;
   reliability; error correction layer; piece-wise ReLU; PwReLU; bit error
   rate
AB Deep Learning techniques have been successfully used to solve a wide range of computer vision problems. Due to their high computation complexity, specialized hardware accelerators are being proposed to achieve high performance and efficiency for deep learning-based algorithms. However, soft errors, i.e., bit flipping errors in the layer output, are often caused due to process variation and high energy particles in these hardware systems. These can significantly reduce model accuracy. To remedy this problem, we propose new algorithms that effectively reduce the impact of errors, thus keeping high accuracy. We firstly propose to incorporate an Error Correction Layer (ECL) into neural networks where convolution is performed multiple times in each layer and majority reporting is conducted for the outputs at bit level. We found that ECL can eliminate most errors while bypassing the bit-error when the bits at the same position are corrupted multiple times under the simulated condition. In order to solve this problem, we analyze the impact of errors depending on the position of bits, thus observing that errors in most significant bit (MSB) positions tend to severely corrupt the output of the network compared to the errors in the least significant bit (LSB) positions. According to this observation, we propose a new specialized activation function, called Piece-wise Rectified Linear Unit (PwReLU), which selectively suppresses errors depending on the bit positions, resulting in an increased model resistance against the errors. Compared to existing activation functions, the proposed PwReLU outperforms with large accuracy margins of up-to 20% even with very high bit error rates (BERs). Our extensive experiments show that the proposed ECL and PwReLU work in a complementary manner, achieving comparable accuracy to the error-free networks even at a severe BER of 0.1% on CIFAR10, CIFAR100, and ImageNet.
C1 [Ali, Muhammad Salman; Iqbal, Md Tauhid Bin; Lee, Kang-Ho; Muqeet, Abdul; Kim, Lokwon; Bae, Sung-Ho] Kyung Hee Univ, Dept Comp Sci & Engn, Yongin 17104, South Korea.
   [Lee, Seunghyun] Kyung Hee Univ, Dept Elect Engn, Yongin 17104, South Korea.
RP Bae, SH (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Yongin 17104, South Korea.
EM shbae@khu.ac.kr
CR [Anonymous], 2010, TECH REP
   [Anonymous], 2018, IEEE T NEUR NET LEAR, DOI DOI 10.1109/TNNLS.2018.2815085
   Barron J.T., 2017, ARXIV170407483
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen ZY, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317800
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Clevert D-A, 2015, ARXIV151107289, DOI DOI 10.48550/ARXIV.1511.07289
   Czerny B. J., 2002, ORIGINS, V9, P2003
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   Guan H., 2019, ADV NEURAL INFORM PR, P5735
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hareland S, 2001, 2001 SYMPOSIUM ON VLSI TECHNOLOGY, DIGEST OF TECHNICAL PAPERS, P73, DOI 10.1109/VLSIT.2001.934953
   Hasan R, 2017, IEEE IJCNN, P3527, DOI 10.1109/IJCNN.2017.7966300
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Howard A. G., 2017, ABS170404861 CORR
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Hubara I, 2018, J MACH LEARN RES, V18
   Ishizaka M, 2018, ASIAN TEST SYMPOSIUM, P167, DOI 10.1109/ATS.2018.00040
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Kim JS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317805
   Kim LW, 2018, IEEE T NEUR NET LEAR, V29, P1441, DOI 10.1109/TNNLS.2017.2665555
   Kong SM, 2017, IEEE IJCNN, P2562, DOI 10.1109/IJCNN.2017.7966168
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2014, THE CIFAR 10 DATASET
   Krizhevsky A., 2010, CONVOLUTIONAL DEEP B, V40, P1, DOI DOI 10.1145/3065386
   Krizhevsky A, 2009, HDB SYST AUTOIMMUNE, V1, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Ng, 2013, PROC ICML WORKSHOP D, V30, P3
   Nicolae A., 2018, ARXIV180909534
   Park J, 1991, NEURAL COMPUT, V3, P246, DOI 10.1162/neco.1991.3.2.246
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schorn C, 2019, DES AUT TEST EUROPE, P1507, DOI [10.23919/DATE.2019.8714885, 10.23919/date.2019.8714885]
   Schorn C, 2018, LECT NOTES COMPUT SC, V11093, P205, DOI 10.1007/978-3-319-99130-6_14
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun XH, 2019, IEEE ELECTR DEVICE L, V40, P1080, DOI 10.1109/LED.2019.2917944
   Tithi JJ, 2014, INT SYM PERFORM ANAL, P23, DOI 10.1109/ISPASS.2014.6844458
   Wang JF, 2016, WATER-SUI, V8, DOI 10.3390/w8010011
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Xu B., 2015, ARXIV PREPRINT ARXIV, V1505, P853
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Z, 2019, IEEE INT C CL COMP, P125, DOI 10.1109/cluster.2019.8890989
NR 52
TC 1
Z9 1
U1 0
U2 4
PY 2020
VL 8
BP 158702
EP 158711
DI 10.1109/ACCESS.2020.3017211
UT WOS:000568255300001
DA 2023-11-16
ER

PT C
AU Crafton, B
   Spetalnick, S
   Murali, G
   Krishna, T
   Lim, SK
   Raychowdhury, A
AF Crafton, Brian
   Spetalnick, Samuel
   Murali, Gauthaman
   Krishna, Tushar
   Lim, Sung-Kyu
   Raychowdhury, Arijit
BE Calimera, A
   Gaillardon, PE
   Korgaonkar, K
   Kvatinsky, S
   Reis, R
TI Statistical Array Allocation and Partitioning for Compute In-Memory
   Fabrics
SO VLSI-SOC: DESIGN TRENDS, VLSI-SOC 2020
SE IFIP Advances in Information and Communication Technology
DT Proceedings Paper
CT 28th IFIP WG 10.5/IEEE International Conference on Very Large Scale
   Integration (VLSI-SoC)
CY OCT 06-09, 2020
CL ELECTR NETWORK
DE Compute In-Memory; RRAM; PCRAM
AB Compute in-memory (CIM) is a promising technique that minimizes data transport, the primary performance bottleneck and energy cost of most data intensive applications. This has found widespread adoption in accelerating neural networks for machine learning applications. Utilizing a crossbar architecture with emerging nonvolatile memories (eNVM) such as dense resistive random access memory (RRAM) or phase change random access memory (PCRAM), various forms of neural networks can be implemented to greatly reduce power and increase on chip memory capacity. However, compute in-memory faces its own limitations at both the circuit and the device levels. Although compute in-memory using the crossbar architecture can greatly reduce data transport, the rigid nature of these large fixed weight matrices forfeits the flexibility of traditional CMOS and SRAM based designs. In this work, we explore the different synchronization barriers that occur from the CIM constraints. Furthermore, we propose a new allocation algorithm and data flow based on input data distributions to maximize utilization and performance for compute-in memory based designs. We demonstrate a 7.47x performance improvement over a naive allocation method for CIM accelerators on ResNet18.
C1 [Crafton, Brian; Spetalnick, Samuel; Murali, Gauthaman; Krishna, Tushar; Lim, Sung-Kyu; Raychowdhury, Arijit] Georgia Inst Technol, Atlanta, GA 30332 USA.
RP Crafton, B (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM brian.crafton@gatech.edu; arijit.raychowdhury@ece.gatech.edu
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Crafton B., 2020, ARXIV PREPRINT ARXIV
   Crafton B, 2020, IEEE INT CONF VLSI, P123, DOI 10.1109/VLSI-SOC46417.2020.9344086
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Peng X., 2019, IEEE T CIRCUITS SYST
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wilton SJE, 1996, IEEE J SOLID-ST CIRC, V31, P677, DOI 10.1109/4.509850
   Wu JY, 2018, INT EL DEVICES MEET
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Yoon J.-H., 2021 IEEE INT SOLID, V64
   Yoon JH, 2021, IEEE CUST INTEGR CIR, DOI 10.1109/CICC51472.2021.9431412
NR 19
TC 0
Z9 0
U1 0
U2 7
PY 2021
VL 621
BP 323
EP 341
DI 10.1007/978-3-030-81641-4_15
UT WOS:000794306600015
DA 2023-11-16
ER

PT C
AU Xu, LN
   Butt, AR
   Lim, SH
   Kannan, R
AF Xu, Luna
   Butt, Ali R.
   Lim, Seung-Hwan
   Kannan, Ramakrishnan
GP IEEE
TI A Heterogeneity-Aware Task Scheduler for Spark
SO 2018 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)
SE IEEE International Conference on Cluster Computing
DT Proceedings Paper
CT IEEE International Conference on Cluster Computing (CLUSTER)
CY SEP 10-13, 2018
CL Belfast, NORTH IRELAND
AB Big data processing systems such as Spark are employed in an increasing number of diverse applications- such as machine learning, graph computation, and scientific computing-each with dynamic and different resource needs. These applications increasingly run on heterogeneous hardware, e.g., with out-of-core accelerators. However, big data platforms do not factor in the multi-dimensional heterogeneity of applications and hardware. This leads to a fundamental mismatch between the application and hardware characteristics, and the resource scheduling adopted in big data platforms. For example, Hadoop and Spark consider only data locality when assigning tasks to nodes, and typically disregard the hardware capabilities and suitability to specific application requirements.
   In this paper, we present RUPAM, a heterogeneity-aware task scheduling system for big data platforms, which considers both task-level resource characteristics and underlying hardware characteristics, as well as preserves data locality. RUPAM adopts a simple yet effective heuristic to decide the dominant scheduling factor (e.g., CPU, memory, or DO), given a task in a particular stage. Our experiments show that RUPAM is able to improve the performance of representative applications by up to 62.3% compared to the standard Spark scheduler.
C1 [Xu, Luna; Butt, Ali R.] Virginia Tech, Blacksburg, VA 24061 USA.
   [Lim, Seung-Hwan; Kannan, Ramakrishnan] Oak Ridge Natl Lab, Oak Ridge, TN USA.
RP Xu, LN (corresponding author), Virginia Tech, Blacksburg, VA 24061 USA.
EM xuluna@cs.vt.edu; butta@cs.vt.edu; lims1@ornl.gov; kannanr@ornl.gov
CR Ahmad F., 2012, ACM SIGARCH COMPUTER
   Ahsan M. K., 2003, Journal of Systems Science and Systems Engineering, V12, P190, DOI 10.1007/s11518-006-0129-3
   [Anonymous], 2013, P 8 ACM EUROPEAN C C
   [Anonymous], 2017, ARXIV171107440
   [Anonymous], 2011, P 8 ACM INT C AUTONO, DOI DOI 10.1145/1998582.1998637
   [Anonymous], 2011, P 2 ACM S CLOUD COMP
   Bo Wang, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1328, DOI 10.1109/INFOCOM.2015.7218509
   Bobroff N, 2007, 2007 10TH IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2009), VOLS 1 AND 2, P119, DOI 10.1109/inm.2007.374776
   Cheng DZ, 2017, IEEE T PARALL DISTR, V28, P774, DOI 10.1109/TPDS.2016.2594765
   Chowdhury Mosharaf, 2016, NSDI
   Das T., 2012, PROC 9 USENIX S NETW, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Fadika Z., 2012, Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid 2012), P49, DOI 10.1109/CCGrid.2012.135
   Ferguson Andrew D., 2012, ACM EUROSYS 12, P99
   Gandhi Rohan, 2013, PRESENTED PART 2013, P61
   Ghodsi An, 2011, Computer Communication Review, V41, P507, DOI 10.1145/2018584.2018586
   Graham R. L., 1979, Discrete Optimisation, P287
   Grandl R, 2014, ACM SIGCOMM COMP COM, V44, P455, DOI 10.1145/2740070.2626334
   Hindman B., 2011, NSDI, P22, DOI DOI 10.1016/0375-6505(85)90011-2
   Jyothi SA, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P117
   Konwinski A. D, 2008, USENIX OSDI, P7
   Kopytov A., SYSBENCH
   Lee G., 2012, RESOURCE ALLOCATION
   Li MH, 2017, ASIA PAC J MANAG, V34, P19, DOI 10.1007/s10490-015-9436-x
   Ousterhout K., 2017, P SOSP
   Ousterhout K, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P69, DOI 10.1145/2517349.2522716
   Polo J., 2011, RESOURCE AWARE ADAPT, P187
   Seung-Hwan Lim, 2012, Performance Evaluation Review, V40, P271, DOI 10.1145/2318857.2254790
   Sharma B, 2013, INT CON DISTR COMP S, P102, DOI 10.1109/ICDCS.2013.31
   SHMOYS DB, 1995, SIAM J COMPUT, V24, P1313, DOI 10.1137/S0097539793248317
   Tan ZL, 2016, PROC VLDB ENDOW, V9, P720, DOI 10.14778/2977797.2977799
   Thinakaran Prashanth, 2017, 37 IEEE INT C DISTR
   Thusoo A., 2010, P 2010 ACM SIGMOD IN, P1013, DOI 10.1145/1807167.1807278
   Tian C, 2009, 2009 EIGHTH INTERNATIONAL CONFERENCE ON GRID AND COOPERATIVE COMPUTING, PROCEEDINGS, P218, DOI 10.1109/GCC.2009.19
   Vavilapalli V.K., 2013, P 4 ANN S CLOUD COMP, P1
   Verma A, 2014, PERFORM EVALUATION, V79, P328, DOI 10.1016/j.peva.2014.07.020
   Xu L., 2017, P 2017 IEEE INT C BI
   Yang H., 2013, ACM SIGARCH COMPUTER
   Yang HB, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P28, DOI 10.1109/ICALIP.2016.7846627
   Zhang XC, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P507, DOI 10.1145/3132847.3132996
   Zhang XC, 2017, IEEE INT CONF BIG DA, P1688, DOI 10.1109/BigData.2017.8258107
   Zhang XC, 2017, IEEE INT CONF BIG DA, P1590, DOI 10.1109/BigData.2017.8258093
NR 42
TC 9
Z9 9
U1 1
U2 2
PY 2018
BP 245
EP 256
DI 10.1109/CLUSTER.2018.00042
UT WOS:000454692400031
DA 2023-11-16
ER

PT J
AU Markidis, S
AF Markidis, Stefano
TI On physics-informed neural networks for quantum computers
SO FRONTIERS IN APPLIED MATHEMATICS AND STATISTICS
DT Article
DE quantum physics-informed neural network; Poisson equation; quantum
   neural networks; continuous variable quantum computing; heterogeneous
   QPU CPU computing
ID COMPUTATION; INFORMATION
AB Physics-Informed Neural Networks (PINN) emerged as a powerful tool for solving scientific computing problems, ranging from the solution of Partial Differential Equations to data assimilation tasks. One of the advantages of using PINN is to leverage the usage of Machine Learning computational frameworks relying on the combined usage of CPUs and co-processors, such as accelerators, to achieve maximum performance. This work investigates the design, implementation, and performance of PINNs, using the Quantum Processing Unit (QPU) co-processor. We design a simple Quantum PINN to solve the one-dimensional Poisson problem using a Continuous Variable (CV) quantum computing framework. We discuss the impact of different optimizers, PINN residual formulation, and quantum neural network depth on the quantum PINN accuracy. We show that the optimizer exploration of the training landscape in the case of quantum PINN is not as effective as in classical PINN, and basic Stochastic Gradient Descent (SGD) optimizers outperform adaptive and high-order optimizers. Finally, we highlight the difference in methods and algorithms between quantum and classical PINNs and outline future research challenges for quantum PINN development.
C1 [Markidis, Stefano] KTH Royal Inst Technol, Dept Comp Sci, Stockholm, Sweden.
RP Markidis, S (corresponding author), KTH Royal Inst Technol, Dept Comp Sci, Stockholm, Sweden.
EM markidis@kth.se
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
   Arrasmith A, 2021, QUANTUM-AUSTRIA, V5, DOI 10.22331/q-2021-10-05-558
   Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5
   Baydin AG, 2018, J MACH LEARN RES, V18
   Bengio Y., 2007, GREEDY LAYER WISE TR
   Braunstein SL, 2005, REV MOD PHYS, V77, P513, DOI 10.1103/RevModPhys.77.513
   Bromley TR, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab8504
   Broughton M., 2020, PREPRINT
   Cai SZ, 2021, ACTA MECH SINICA-PRC, V37, P1727, DOI 10.1007/s10409-021-01148-1
   Cerezo M, 2021, NAT REV PHYS, V3, P625, DOI 10.1038/s42254-021-00348-9
   Chen CG, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37354-4
   Chen YY, 2020, OPT EXPRESS, V28, P11618, DOI 10.1364/OE.384875
   Chien Steven W. D., 2019, 2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P509, DOI 10.1109/IPDPSW.2019.00092
   Chow J., 2021, IBM RES BLOG
   Fukui K, 2022, J PHYS B-AT MOL OPT, V55, DOI 10.1088/1361-6455/ac489c
   Gidney C, 2021, QUANTUM-AUSTRIA, V5, DOI 10.22331/q-2021-04-15-433
   Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P212, DOI 10.1145/237814.237866
   Haghighat E, 2021, COMPUT METHOD APPL M, V373, DOI 10.1016/j.cma.2020.113552
   Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502
   Heim N., 2021, PREPRINT
   Horowitz M, 2005, INT EL DEVICES MEET, P11
   Killoran N, 2019, PHYS REV RES, V1, DOI 10.1103/PhysRevResearch.1.033063
   Killoran N, 2019, QUANTUM-AUSTRIA, V3, DOI 10.22331/q-2019-03-11-129
   Kingma DP., 2017, ARXIV
   Knudsen M., 2020, PREPRINT
   Kumar N., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2206.14184
   Kyriienko O., 2022, PREPRINT
   Kyriienko O, 2021, PHYS REV A, V103, DOI 10.1103/PhysRevA.103.052416
   LaRose Ryan, 2019, PREPRINT
   Lattner C., 2020, PREPRINT
   Li H, 2018, ADV NEUR IN, V31
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Lloyd S., 1999, Physical Review Letters, V82, P1784, DOI 10.1103/PhysRevLett.82.1784
   Lu L, 2021, SIAM REV, V63, P208, DOI 10.1137/19M1274067
   Madsen LS, 2022, NATURE, V606, P75, DOI 10.1038/s41586-022-04725-x
   Markidis S, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.669097
   McClean JR, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07090-4
   McClean JR, 2016, NEW J PHYS, V18, DOI 10.1088/1367-2630/18/2/023023
   McKay DC., 2018, PREPRINT
   Mishra S, 2022, IMA J NUMER ANAL, V42, P981, DOI 10.1093/imanum/drab032
   Moore GE, 1998, P IEEE, V86, P82, DOI 10.1109/JPROC.1998.658762
   O'Malley PJJ, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.031007
   Ortiz-Gutiérrez L, 2017, OPT COMMUN, V397, P166, DOI 10.1016/j.optcom.2017.04.011
   Paine AE., 2022, PREPRINT
   Paine AE., 2021, PREPRINT
   Pang GF, 2019, SIAM J SCI COMPUT, V41, pA2603, DOI 10.1137/18M1229845
   Paszke A, 2019, ADV NEUR IN, V32
   Peruzzo A, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5213
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Ruder S., OVERVIEW GRADIENT DE, DOI DOI 10.48550/ARXIV.1609.04747
   Shin Y., 2020, PREPRINT
   Slussarenko S, 2019, APPL PHYS REV, V6, DOI 10.1063/1.5115814
   Spall JC, 1998, J HOPKINS APL TECH D, V19, P482
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Watabe M, 2021, QUANTUM REPORTS, V3, P333
   Weedbrook C, 2012, REV MOD PHYS, V84, P621, DOI 10.1103/RevModPhys.84.621
   Zeiler M.D., 2012, PREPRINT
NR 60
TC 0
Z9 0
U1 5
U2 7
PD OCT 28
PY 2022
VL 8
AR 1036711
DI 10.3389/fams.2022.1036711
UT WOS:000885109200001
DA 2023-11-16
ER

PT J
AU Dong, BW
   Aggarwal, S
   Zhou, W
   Ali, UE
   Farmakidis, N
   Lee, JS
   He, YH
   Li, X
   Kwong, DL
   Wright, CD
   Pernice, WHP
   Bhaskaran, H
AF Dong, Bowei
   Aggarwal, Samarth
   Zhou, Wen
   Ali, Utku Emre
   Farmakidis, Nikolaos
   Lee, June Sang
   He, Yuhan
   Li, Xuan
   Kwong, Dim-Lee
   Wright, C. D.
   Pernice, Wolfram H. P.
   Bhaskaran, H.
TI Higher-dimensional processing using a photonic tensor core with
   continuous-time data
SO NATURE PHOTONICS
DT Article; Early Access
ID ARTIFICIAL-INTELLIGENCE
AB New developments in hardware-based 'accelerators' range from electronic tensor cores and memristor-based arrays to photonic implementations. The goal of these approaches is to handle the exponentially growing computational load of machine learning, which currently requires the doubling of hardware capability approximately every 3.5 months. One solution is increasing the data dimensionality that is processable by such hardware. Although two-dimensional data processing by multiplexing space and wavelength has been previously reported, the use of three-dimensional processing has not yet been implemented in hardware. In this paper, we introduce the radio-frequency modulation of photonic signals to increase parallelization, adding an additional dimension to the data alongside spatially distributed non-volatile memories and wavelength multiplexing. We leverage higher-dimensional processing to configure such a system to an architecture compatible with edge computing frameworks. Our system achieves a parallelism of 100, two orders higher than implementations using only the spatial and wavelength degrees of freedom. We demonstrate this by performing a synchronous convolution of 100 clinical electrocardiogram signals from patients with cardiovascular diseases, and constructing a convolutional neural network capable of identifying patients at sudden death risk with 93.5% accuracy.
C1 [Dong, Bowei; Aggarwal, Samarth; Zhou, Wen; Ali, Utku Emre; Farmakidis, Nikolaos; Lee, June Sang; He, Yuhan; Li, Xuan; Bhaskaran, H.] Univ Oxford, Dept Mat, Oxford, England.
   [Dong, Bowei; Kwong, Dim-Lee] ASTAR, Inst Microelect, Singapore, Singapore.
   [Wright, C. D.] Univ Exeter, Dept Engn, Exeter, England.
   [Pernice, Wolfram H. P.] Univ Munster, Inst Phys, Munster, Germany.
   [Pernice, Wolfram H. P.] Heidelberg Univ, Kirchhoff Inst Phys, Heidelberg, Germany.
RP Bhaskaran, H (corresponding author), Univ Oxford, Dept Mat, Oxford, England.
EM harish.bhaskaran@materials.ox.ac.uk
CR Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Assael Y, 2022, NATURE, V603, P280, DOI 10.1038/s41586-022-04448-z
   Baig MT, 2013, REV SCI INSTRUM, V84, DOI 10.1063/1.4832042
   Dauparas J, 2022, SCIENCE, V378, P49, DOI 10.1126/science.add2187
   Dong BW, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abl9874
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Fawzi A, 2022, NATURE, V610, P47, DOI 10.1038/s41586-022-05172-4
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Greenwald S. D., 1986, DEV ANAL VENTRICULAR
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Han C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav6134
   Iigaya K, 2021, NAT HUM BEHAV, V5, P743, DOI 10.1038/s41562-021-01124-6
   Ji H, 2010, IEEE PHOTONIC TECH L, V22, P1762, DOI 10.1109/LPT.2010.2084566
   Jung S, 2022, NATURE, V601, P211, DOI 10.1038/s41586-021-04196-6
   Kim MK, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm8537
   Lanza M, 2022, SCIENCE, V376, P1066, DOI 10.1126/science.abj9979
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JS, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn9459
   Li XQ, 2016, PROC INT CONF PARAL, P67, DOI 10.1109/ICPP.2016.15
   Liu WL, 2016, NAT PHOTONICS, V10, P190, DOI [10.1038/nphoton.2015.281, 10.1038/NPHOTON.2015.281]
   Liu Y, 2022, SCIENCE, V376, P1309, DOI 10.1126/science.abo2631
   Magaki I, 2016, CONF PROC INT SYMP C, P178, DOI 10.1109/ISCA.2016.25
   Markov IL, 2014, NATURE, V512, P147, DOI 10.1038/nature13570
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rao ZY, 2022, SCIENCE, V378, P78, DOI 10.1126/science.abo4940
   Reuther A, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622867
   Ríos C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau5759
   Ríos C, 2015, NAT PHOTONICS, V9, P725, DOI [10.1038/NPHOTON.2015.182, 10.1038/nphoton.2015.182]
   Sanz M., 2022, CREATETFW INPUTSIGNA
   Sarwat SG, 2022, NAT NANOTECHNOL, V17, P507, DOI 10.1038/s41565-022-01095-3
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shu HW, 2022, NATURE, V605, P457, DOI 10.1038/s41586-022-04579-3
   Sludds Alexander, 2022, Science, V378, P270, DOI 10.1126/science.abq8271
   Statista Research Department, 2022, AM DAT CREAT CONS ST
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Trail MA, 2022, NATURE, V610, P54, DOI 10.1038/s41586-022-05119-9
   Wan WE, 2022, NATURE, V608, P504, DOI 10.1038/s41586-022-04992-8
   Wang C, 2021, NAT NANOTECHNOL, V16, P1079, DOI 10.1038/s41565-021-00943-y
   Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491
   Wang N., 2020, NIPS 20
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   White AD, 2023, NAT PHOTONICS, V17, P143, DOI 10.1038/s41566-022-01110-y
   World Health Organization, CARDIOVASC DIS
   Wu CM, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm2956
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yan T, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn7630
   Yang KY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-35446-4
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yuan LQ, 2018, OPTICA, V5, P1396, DOI 10.1364/OPTICA.5.001396
   Zhao H, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33132-z
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou LN, 2017, NEUROCOMPUTING, V237, P350, DOI 10.1016/j.neucom.2017.01.026
NR 57
TC 0
Z9 0
U1 3
U2 3
PD 2023 OCT 19
PY 2023
DI 10.1038/s41566-023-01313-x
EA OCT 2023
UT WOS:001085931100001
DA 2023-11-16
ER

PT C
AU Kahng, AB
   Varadarajan, R
   Wang, ZA
AF Kahng, Andrew B.
   Varadarajan, Ravi
   Wang, Zhiang
GP ACM
TI RTL-MP: Toward Practical, Human-Quality Chip Planning and Macro
   Placement
SO ISPD'22: PROCEEDINGS OF THE 2022 INTERNATIONAL SYMPOSIUM ON PHYSICAL
   DESIGN
DT Proceedings Paper
CT 31st edition of the ACM International Symposium on Physical Design
   (ISPD)
CY MAR 27-30, 2022
CL ELECTR NETWORK
DE Macro placement; RTL-driven; dataflow
ID ALGORITHM; PACKING; TREES
AB In a typical RTL-to-GDSII flow, floorplanning plays an essential role in achieving decent quality of results (QoR). A good floorplan typically requires interaction between the frontend designer, who is responsible for the functionality of the RTL, and the backend physical design engineer. The increasing complexity of macro-dominated designs (especially machine learning accelerators with autogenerated RTL) has made the floorplanning task even more challenging and time-consuming. In this paper, we propose RTL-MP, a novel macro placer which utilizes RTL information and tries to "mimic" the interaction between the frontend RTL designer and the backend physical design engineer to produce human-quality floorplans. By exploiting the logical hierarchy and processing logical modules based on connection signatures, RTL-MP can capture the dataflow inherent in the RTL and use the dataflow information to guide macro placement. We also apply autotuning [37] to optimize hyperparameter settings based on input designs. We have built RTL-MP based on OpenROAD infrastructure [25, 49] and applied RTL-MP to a set of industrial designs. RTL-MP outperforms state-of-the-art commercial macro placers and achieves QoR similar to that of handcrafted floorplans.
C1 [Kahng, Andrew B.; Varadarajan, Ravi; Wang, Zhiang] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Kahng, AB (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM abk@ucsd.edu; rvaradarajan@ucsd.edu; zhwO33@ucsd.edu
CR Adya SN, 2003, IEEE T VLSI SYST, V11, P1120, DOI 10.1109/TVLSI.2003.817546
   ALDOUS D, 1994, AN S FDN CO, P492, DOI 10.1109/SFCS.1994.365742
   [Anonymous], COYOTE RISC V ROCKET
   [Anonymous], TUNE
   [Anonymous], OPENROAD PROJECT
   [Anonymous], SWERV CORETM VERSION
   [Anonymous], CVA6 RISC V CPU
   [Anonymous], BLACKPARROT
   Bruck R., 1988, Proceedings of the International Workshop on Artificial Intelligence for Industrial Applications: IEEE AI '88 (Cat. No.88CH2529-6), P194, DOI 10.1109/AIIA.1988.13292
   Caldwell A., 2006, MLPART HIGH PERFORMA
   Chan TB, 2020, INT WORKS SYST LEVEL, DOI 10.1145/3414622.3431907
   Chang CH, 2017, ICCAD-IEEE ACM INT, P504, DOI 10.1109/ICCAD.2017.8203819
   Chang YC, 2000, DES AUT CON, P458
   Chen GL, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1020, DOI 10.1109/ISKE.2008.4731079
   Chen TC, 2006, IEEE T COMPUT AID D, V25, P637, DOI 10.1109/TCAD.2006.870076
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P1621, DOI 10.1109/TCAD.2008.927760
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P286, DOI 10.1109/TCAD.2007.907065
   Chen YF, 2014, DES AUT CON, DOI 10.1145/2593069.2593206
   Chiou CH, 2016, ASIA S PACIF DES AUT, P172, DOI 10.1109/ASPDAC.2016.7428007
   Choi WJ, 2003, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, PROCEEDINGS, P1104
   Chuang YL, 2010, ICCAD-IEEE ACM INT, P663, DOI 10.1109/ICCAD.2010.5654234
   Cong J, 2006, IEEE T COMPUT AID D, V25, P1719, DOI 10.1109/TCAD.2005.859519
   Cortadella J., 2020, IEEE T CAD, V40, P2542
   Dae Hyun Kim, 2008, 13th Asia and South Pacific Design Automation Conference ASP-DAC 2008, P204
   Ekpanyapong M, 2006, IEEE T COMPUT AID D, V25, P1289, DOI 10.1109/TCAD.2005.855971
   Fogaça M, 2020, INTEGRATION, V74, P32, DOI 10.1016/j.vlsi.2020.03.007
   Gwee BH, 1999, INTEGRATION, V28, P157, DOI 10.1016/S0167-9260(99)00015-2
   He ZL, 2020, PR IEEE COMP DESIGN, P324, DOI 10.1109/ICCD50377.2020.00061
   Hsu MK, 2013, DES AUT CON
   Hsu MK, 2014, IEEE T COMPUT AID D, V33, P1914, DOI 10.1109/TCAD.2014.2360453
   Hu CC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P205
   Kahng A. B., 2000, Proceedings International Symposium on Physical Design, 2000. ISPD-2000, P207, DOI 10.1145/332357.332401
   Kahng A. B., 2021, PROC GOMACTECH
   Kim MC, 2012, ISPD 12: PROCEEDINGS OF THE 2012 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P193
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Liaw R, 2018, Arxiv, DOI [arXiv:1807.05118, DOI 10.48550/ARXIV.1807.05118]
   Lin JM, 2021, IEEE T VLSI SYST, V29, P973, DOI 10.1109/TVLSI.2021.3057921
   Lin JM, 2019, ICCAD-IEEE ACM INT, DOI [10.1109/iccad45719.2019.8942168, 10.1145/3316781.3317901]
   Lin JM, 2019, IEEE T VLSI SYST, V27, P57, DOI 10.1109/TVLSI.2018.2867833
   Liu Y.-C., 2019, PROC ASP DAC
   Lu JW, 2015, IEEE T COMPUT AID D, V34, P685, DOI 10.1109/TCAD.2015.2391263
   Mirhoseini A, 2020, Arxiv, DOI arXiv:2004.10746
   Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w
   Murata H, 1996, IEEE T COMPUT AID D, V15, P1518, DOI 10.1109/43.552084
   Nookala V, 2005, DES AUT CON, P579
   OUSTERHOUT JK, 1984, IEEE T COMPUT AID D, V3, P87, DOI 10.1109/TCAD.1984.1270061
   Tang XP, 2001, PROCEEDINGS OF THE ASP-DAC 2001: ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE 2001, P521, DOI 10.1109/ASPDAC.2001.913361
   Team VLSI, 2014, FLOORPL STRAT MACR D
   Temme K. -H., 1998, PROC INT WORKSHOP AR, P188
   Vidal-Obiols A, 2019, DES AUT TEST EUROPE, P186, DOI [10.23919/date.2019.8714812, 10.23919/DATE.2019.8714812]
   Yan JZ, 2008, DES AUT CON, P161
   Yan JZ, 2014, ACM T DES AUTOMAT EL, V19, DOI 10.1145/2611761
   Zhan Y, 2006, ASIA S PACIF DES AUT, P771
NR 53
TC 2
Z9 2
U1 2
U2 3
PY 2022
BP 3
EP 11
DI 10.1145/3505170.3506731
UT WOS:000944052800026
DA 2023-11-16
ER

PT C
AU Li, Y
   Li, JY
   Jiang, XL
   Gao, CL
   Zhang, T
AF Li, Ya
   Li, Jiying
   Jiang, Xinlong
   Gao, Chenlong
   Zhang, Teng
GP IEEE Comp Soc
TI A Driving Attention Detection Method Based on Head Pose
SO 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED &
   TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA
   COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION
   (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019)
DT Proceedings Paper
CT IEEE Conference on SmartWorld, Ubiquitous Intelligence and Computing,
   Advanced and Trusted Computing, Scalable Computing and Communications,
   Cloud and Big Data Computing, Internet of People and Smart City
   Innovation
CY AUG 19-23, 2019
CL Leicester, ENGLAND
DE Driving Attention Detection; Wearable Sensor; Machine Learning; Head
   Pose
ID SYSTEM; DISTRACTION; INATTENTION; BEHAVIOR
AB Head pose is an important indicator of driving attention detection. During driving, head pose, including head position and head movement, can infer the driver's attention. This paper presents a novel method for collecting driver's head pose information using a built-in accelerometer and gyroscope head-mounted inertial sensor. In our experimental study, we designed 10 scenes that are easy to distract from driving. And five subjects were asked to wear a head-mounted inertial sensor to drive the driving simulator. This driving simulator is equipped with real driving conditions such as brakes, steering wheels, accelerators and so on. While driving, subjects need to complete the designed driving scene in order. Subsequently,We perform pre-processing such as Savitzky-Golay filtering and windowing on data collected by inertial sensors with built-in accelerometers and gyroscopes. The time domain and frequency domain features of the data are then extracted in the corresponding window. Finally, we designed a random forest model to detect driving attention. Our simulation experiments show that our proposed method of collecting data using the built-in accelerometer and gyroscope's head-mounted sensor can achieve higher precision, recall and F1(score).
C1 [Li, Ya; Li, Jiying] Lanzhou Jiaotong Univ, Lanzhou, Peoples R China.
   [Li, Ya; Jiang, Xinlong; Gao, Chenlong; Zhang, Teng] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Jiang, Xinlong; Gao, Chenlong; Zhang, Teng] Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
   [Jiang, Xinlong; Gao, Chenlong] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Li, Y (corresponding author), Lanzhou Jiaotong Univ, Lanzhou, Peoples R China.; Li, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM liyash66@163.com; ljy7609@mail.lzjtu.cn; jiangxinlong@ict.ac.cn;
   gaochenlong@ict.ac.cn; ztech@outlook.com
CR ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547
   Angell L.S., 2006, DRIVER WORKLOAD METR
   [Anonymous], 2010, P CHI, DOI DOI 10.1145/1753846.1754138
   Arun S, 2012, IEEE CONF SUSTAIN UT, P1, DOI 10.1109/STUDENT.2012.6408351
   Banos O, 2014, SENSORS-BASEL, V14, P6474, DOI 10.3390/s140406474
   Batista JP, 2005, LECT NOTES COMPUT SC, V3522, P200
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Ersal T, 2010, IEEE T INTELL TRANSP, V11, P692, DOI 10.1109/TITS.2010.2049741
   Harbluk JL, 2007, ACCIDENT ANAL PREV, V39, P372, DOI 10.1016/j.aap.2006.08.013
   Itoh M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P7, DOI 10.1109/ICMA.2009.5246188
   Jiménez F, 2015, IET INTELL TRANSP SY, V9, P105, DOI 10.1049/iet-its.2013.0118
   Kawakita E., 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P765, DOI 10.1109/ITSC.2010.5625079
   Li XP, 2018, T I MEAS CONTROL, V40, P885, DOI 10.1177/0142331216670451
   Mead R, 2013, INT J SOC ROBOT, V5, P367, DOI 10.1007/s12369-013-0189-8
   Rumar K., 1999, NORDIC ROAD TRANSPOR, V11
   Sahayadhas A, 2015, BIOCYBERN BIOMED ENG, V35, P198, DOI 10.1016/j.bbe.2014.12.002
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   Spasova V., 2014, INT J ADV COMPUT RES, V4, P94
   Tango F, 2013, IEEE T INTELL TRANSP, V14, P894, DOI 10.1109/TITS.2013.2247760
   W. H. Organization, 2018, GLOBAL STATUS REPORT
   Wu BF, 2014, IET INTELL TRANSP SY, V8, P361, DOI 10.1049/iet-its.2013.0009
   Xing Y, 2018, IEEE T COMPUT SOC SY, V5, P95, DOI 10.1109/TCSS.2017.2766884
   Yan C, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P680, DOI 10.1109/CISP.2015.7407964
NR 23
TC 0
Z9 0
U1 2
U2 2
PY 2019
BP 483
EP 490
DI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00124
UT WOS:000936421900078
DA 2023-11-16
ER

PT J
AU Min, D
   Ko, Y
   Walker, R
   Lee, J
   Kim, Y
AF Min, Donghyun
   Ko, Yungwoo
   Walker, Ryan
   Lee, Junghee
   Kim, Youngjae
TI A Content-Based Ransomware Detection and Backup Solid-State Drive for
   Ransomware Defense
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Ransomware; Performance evaluation; Entropy; Encryption; Machine
   learning; Libraries; Engines; Ransomware attack; solid-state drive
   (SSD); storage security; storage system
AB Ransomware is a growing concern in business and government because it causes immediate financial damages or loss of important data. There is a way to detect and block ransomware in advance, but evolved ransomware can still attack while avoiding detection. Another alternative is to back up the original data. However, existing backup solutions can be under the control of ransomware and backup copies can be destroyed by ransomware. Moreover, backup methods incur storage and performance overhead. In this article, we propose AMOEBA, a device-level backup solution that does not require additional storage for backup. AMOEBA is armed with: 1) a hardware accelerator to run content-based detection algorithms for ransomware detection at high speed and 2) a fine-grained backup control mechanism to minimize space overhead for data backup. For evaluations, we not only implemented AMOEBA using the Microsoft solid-state drive (SSD) simulator but also prototyped it on the OpenSSD-platform. Our extensive evaluations with real ransomware workloads show that AMOEBA has high ransomware detection accuracy with negligible performance overhead.
C1 [Min, Donghyun; Kim, Youngjae] Sogang Univ, Dept Comp Sci & Engn, Seoul 04107, South Korea.
   [Ko, Yungwoo] TmaxSoft, Seoul, South Korea.
   [Walker, Ryan] Booz Allen Hamilton, Global Def Grp, Mclean, VA 22102 USA.
   [Lee, Junghee] Korea Univ, Sch Cybersecur, Seoul 02841, South Korea.
RP Kim, Y (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul 04107, South Korea.; Lee, J (corresponding author), Korea Univ, Sch Cybersecur, Seoul 02841, South Korea.
EM mdh38112@sogang.ac.kr; ryan.walker@my.utsa.edu; j_lee@korea.ac.kr;
   youkim@sogang.ac.kr
CR Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, V10, P978, DOI [10.1007/978-3-319-94463-0, DOI 10.1007/978-3-319-94463-0]
   Agrawal N., 2008, P USENIX ANN TECH C, V8, P57, DOI DOI 10.1109/ISSCC.2012.6177101
   Ahmadian MM, 2016, 2016 13TH INTERNATIONAL IRANIAN SOCIETY OF CRYPTOLOGY CONFERENCE ON INFORMATION SECURITY AND CRYPTOLOGY (ISCISC), P79, DOI 10.1109/ISCISC.2016.7736455
   [Anonymous], 2019, CYEMPTIVE LAUNCHES P
   [Anonymous], VIRTUAL GANGSTER
   [Anonymous], 2019, MCAFEE LABS THREATS
   [Anonymous], COSMOS OPENSSD PLATF
   [Anonymous], 2012, P 10 USENIX C FIL ST
   [Anonymous], 2020, WILL I RECOVER RANSO
   [Anonymous], 2018, DATA SHEET DS188 V1
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Back S, 2018, INT CON DISTR COMP S, P875, DOI 10.1109/ICDCS.2018.00089
   Biggio B, 2018, PATTERN RECOGN, V84, P317, DOI 10.1016/j.patcog.2018.07.023
   Bucy John S., 2008, CMUPDL08101
   Cabaj K, 2016, IEEE NETWORK, V30, P14, DOI 10.1109/MNET.2016.1600110NM
   Chen X, 2008, I C DEPEND SYS NETWO, P177, DOI 10.1109/DSN.2008.4630086
   Continella A, 2016, ANN COMPUT SECURITY, P336, DOI 10.1145/2991079.2991110
   Maimo LF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051114
   Huang J, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2231, DOI 10.1145/3133956.3134035
   Kangara M. G. M., 2016, Proceedings - International Fertiliser Society, P1
   Kim S., 2011, PROC INT WORKSHOP AC, P1
   Kim S, 2018, DES AUT CON, DOI 10.1145/3195970.3196085
   Kleinbaum DavidG., 2002, LOGISTIC REGRESSION
   Knudsen Jesper, 2008, NANGATE 45NM OPEN CE
   Kolodenker E, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P599, DOI 10.1145/3052973.3053035
   Lv H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Lyda R, 2007, IEEE SECUR PRIV, V5, P40, DOI 10.1109/MSP.2007.48
   Maiorca D., 2017, P S APPL COMPUTING, P1718, DOI 10.1145/3019612.3019793
   Miladinovic N., 2012, FLASH MEM SUMM
   Min D, 2018, IEEE COMPUT ARCHIT L, V17, P243, DOI 10.1109/LCA.2018.2883431
   Moore C, 2016, 2016 CYBERSECURITY AND CYBERFORENSICS CONFERENCE (CCC), P77, DOI 10.1109/CCC.2016.14
   OCZ Technology, 2012, PCI EXPR OCZ TECHN
   Park D., 2018, PROC USENIX C FILE S
   Park J, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317889
   Rho E, 2018, PROCEEDINGS OF THE 16TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P257
   ROSENBLUM M, 1992, ACM T COMPUT SYST, V10, P26, DOI 10.1145/146941.146943
   Scaife N, 2016, INT CON DISTR COMP S, P303, DOI 10.1109/ICDCS.2016.46
   Trend Micro, 2017, ER LIN RANS IMP SERV
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wilson V., 2019, 24 RECENT RANSOMWARE
   Xilinx, 2019, ZCU102 EV BOARD US M
   Xilinx, ISE SIM ISIM
NR 42
TC 3
Z9 3
U1 6
U2 11
PD JUL
PY 2022
VL 41
IS 7
BP 2038
EP 2051
DI 10.1109/TCAD.2021.3099084
UT WOS:000812532700009
DA 2023-11-16
ER

PT C
AU Nguyen, S
   Salcic, Z
   Trivedi, U
   Zhang, XY
AF Nguyen, Sang
   Salcic, Zoran
   Trivedi, Utsav
   Zhang, Xuyun
GP IEEE
TI Predicting Parking Occupancy by FPGA-Accelerated DNN Models at Fog Layer
SO 2021 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2021)
DT Proceedings Paper
CT 7th IEEE International Conference on Smart Computing (SMARTCOMP)
CY AUG 23-27, 2021
CL ELECTR NETWORK
DE Fog computing; Deep Neural Network; FPGA accelerator; parking inferences
ID SYSTEM
AB Model inference is the final stage in machine/deep learning application deployments in practical applications. Hardware-implemented or accelerated model inferences find significant attractions as they offer faster inference than those implemented as programs. This is especially attractive for real-time applications. In this paper, we address models that serve for parking occupancy prediction based on historical time-series parking records. We use the Keras library to build and train software DNN and LSTM models, then compare their prediction performances in terms of accuracy. While the software-implemented inference models indicate advantages of LSTM, we still opted to select only DNN-based models for additional hardware acceleration as the current advanced tool-chains leveraged for automatic software-to-hardware model converting do not allow the creation of LSTM hardware-implemented models. We create, explore and compare the inference performances of hardware (FPGA)-implemented models on relatively low-cost FPGAs. For this, we create an FPGA-accelerated Fog-layer cluster by adding two additional Xilinx FPGA boards of different performances into our existing cluster of four Raspberry Pi (RPi) computers.
C1 [Nguyen, Sang; Salcic, Zoran; Trivedi, Utsav] Univ Auckland, Dept Elect Comp & Software Engn, Auckland, New Zealand.
   [Zhang, Xuyun] Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
RP Nguyen, S (corresponding author), Univ Auckland, Dept Elect Comp & Software Engn, Auckland, New Zealand.
EM sugn565@aucklanduni.ac.nz; z.salcic@auckland.ac.nz;
   utri092@aucklanduni.ac.nz; xuyun.zhang@mq.edu.au
CR A Camero, 2018, INT C LEARN INT OPT
   Abe M, 2018, LECT NOTES ARTIF INT, V10937, P273, DOI 10.1007/978-3-319-93034-3_22
   Ali G, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101696
   [Anonymous], 2021, HLS4ML STATUS FEATUR
   Awan FM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010322
   DH Stolfi, 2017, INT C SMART CIT
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Gómez-Carmona O, 2020, FUTURE GENER COMP SY, V112, P670, DOI 10.1016/j.future.2020.06.013
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   J Du, 2020, IEEE T PARALLEL DIST
   Mohammed T, 2020, IEEE INFOCOM SER, P854, DOI [10.1109/infocom41043.2020.9155237, 10.1109/INFOCOM41043.2020.9155237]
   Ngadiuba J, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/aba042
   Nguyen S., 2020, IEEE INTERNET THINGS
   S Jiang, 2019, IEEE ACCESS
   Saharan S, 2020, FUTURE GENER COMP SY, V106, P622, DOI 10.1016/j.future.2020.01.031
   T Aarrestad, 2021, ARXIV210105108
   Vlahogianni EI, 2016, J INTELL TRANSPORT S, V20, P192, DOI 10.1080/15472450.2015.1037955
   XU ZCA, 2020, P 28 ACM INT C MULT, P3265, DOI DOI 10.1145/3394171.3414048
   Yi SH, 2015, 2015 THIRD IEEE WORKSHOP ON HOT TOPICS IN WEB SYSTEMS AND TECHNOLOGIES (HOTWEB), P73, DOI 10.1109/HotWeb.2015.22
   Zhang W, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108052
NR 20
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 83
EP 88
DI 10.1109/SMARTCOMP52413.2021.00032
UT WOS:000853326000012
DA 2023-11-16
ER

PT J
AU Crilly, AJ
   Garin-Fernandez, I
   Appelbe, BD
   Chittenden, JP
AF Crilly, A. J.
   Garin-Fernandez, I.
   Appelbe, B. D.
   Chittenden, J. P.
TI Efficacy of inertial confinement fusion experiments in light ion fusion
   cross section measurement at nucleosynthesis relevant energies
SO FRONTIERS IN PHYSICS
DT Article
DE inertial confinement fusion (ICF); nuclear astrophysics; Bayesian
   inference; S factor; bare nuclear cross section; thermal reactivity; ion
   kinetic effects
ID DATA LIBRARY; CHAIN
AB Inertial confinement fusion (ICF) experiments create a unique laboratory environment in which thermonuclear fusion reactions occur within a plasma, with conditions comparable to stellar cores and the early universe. In contrast, accelerator-based measurements must compete with bound electron screening effects and beam stopping when measuring fusion cross sections at nucleosynthesis-relevant energies. Therefore, ICF experiments are a natural place to study nuclear reactions relevant to nuclear astrophysics. However, analysis of ICF-based measurements must address its own set of complicating factors. These include: the inherent range of reaction energies, spatial and temporal thermal temperature variation, and kinetic effects such as species separation. In this work we examine these phenomena and develop an analysis to quantify and, when possible, compensate for their effects on our inference. Error propagation in the analyses are studied using synthetic data combined with Markov Chain Monte Carlo (MCMC) machine learning. The novel inference techniques will aid in the extraction of valuable and accurate data from ICF-based nuclear astrophysics experiments.
C1 [Crilly, A. J.; Garin-Fernandez, I.; Appelbe, B. D.; Chittenden, J. P.] Imperial Coll, Ctr Inertial Fus Studies, Blackett Lab, London, England.
RP Crilly, AJ (corresponding author), Imperial Coll, Ctr Inertial Fus Studies, Blackett Lab, London, England.
EM ac116@ic.ac.uk
CR Adelberger EG, 2011, REV MOD PHYS, V83, P195, DOI 10.1103/RevModPhys.83.195
   Appelbe B, 2011, PLASMA PHYS CONTR F, V53, DOI 10.1088/0741-3335/53/4/045002
   Appelbe BD., 2022, PRIMARY NEUTRO UNPUB
   Bahcall J. N., 1989, NEUTRINO ASTROPHYSIC
   BAHCALL JN, 1966, ASTROPHYS J, V143, P259, DOI 10.1086/148497
   Ballabio L, 1998, NUCL FUSION, V38, P1723, DOI 10.1088/0029-5515/38/11/310
   Bellei C, 2014, PHYS PLASMAS, V21, DOI 10.1063/1.4876614
   BOSCH HS, 1992, NUCL FUSION, V32, P611, DOI 10.1088/0029-5515/32/4/I07
   BRYSK H, 1973, PLASMA PHYS CONTR F, V15, P611, DOI 10.1088/0032-1028/15/7/001
   Casella C, 2002, NUCL PHYS A, V706, P203, DOI 10.1016/S0375-9474(02)00749-2
   Casey DT, 2017, NAT PHYS, V13, P1227, DOI [10.1038/NPHYS4220, 10.1038/nphys4220]
   Chadwick MB, 2006, NUCL DATA SHEETS, V107, P2931, DOI 10.1016/j.nds.2006.11.001
   Clayton D. D., 1983, PRINCIPLES STELLAR E
   Foreman-Mackey D, 2013, PUBL ASTRON SOC PAC, V125, P306, DOI 10.1086/670067
   Goodman J, 2010, COMM APP MATH COM SC, V5, P65, DOI 10.2140/camcos.2010.5.65
   Hatarik R, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5039372
   Higginson DP, 2019, PHYS PLASMAS, V26, DOI 10.1063/1.5048386
   Inglebert A, 2014, EPL-EUROPHYS LETT, V107, DOI 10.1209/0295-5075/107/65003
   Kabadi NV, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0032139
   Kagan G, 2014, PHYS LETT A, V378, P1531, DOI 10.1016/j.physleta.2014.04.005
   Leonard DS, 2006, PHYS REV C, V73, DOI 10.1103/PhysRevC.73.045801
   Mannion OM, 2020, NUCL INSTRUM METH A, V964, DOI 10.1016/j.nima.2020.163774
   Mannion OM., 2022, EVIDENCE NONMA UNPUB
   Mossa V, 2020, NATURE, V587, P210, DOI 10.1038/s41586-020-2878-4
   Munro DH, 2016, NUCL FUSION, V56, DOI 10.1088/0029-5515/56/3/036001
   Murphy TJ, 2014, PHYS PLASMAS, V21, DOI 10.1063/1.4885342
   Otuka N, 2014, NUCL DATA SHEETS, V120, P272, DOI 10.1016/j.nds.2014.07.065
   Rinderknecht HG, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.025001
   Spitaleri C, 2019, EUR PHYS J A, V55, DOI 10.1140/epja/i2019-12833-0
   Turkat S, 2021, PHYS REV C, V103, DOI 10.1103/PhysRevC.103.045805
   Kabadi NV, 2021, PHYS REV E, V104, DOI 10.1103/PhysRevE.104.L013201
   van Ravenzwaaij D, 2018, PSYCHON B REV, V25, P143, DOI 10.3758/s13423-016-1015-8
   WILLIAMS MM, 1971, J NUCL ENERGY, V25, P489, DOI 10.1016/0022-3107(71)90029-3
   Zylstra AB, 2020, PHYS REV C, V101, DOI 10.1103/PhysRevC.101.042802
   Zylstra AB, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.035002
NR 35
TC 0
Z9 0
U1 2
U2 3
PD SEP 20
PY 2022
VL 10
AR 937972
DI 10.3389/fphy.2022.937972
UT WOS:000867695700001
DA 2023-11-16
ER

PT J
AU Lu, AN
   Luo, YD
   Yu, SM
AF Lu, Anni
   Luo, Yandong
   Yu, Shimeng
TI An Algorithm-Hardware Co-Design for Bayesian Neural Network Utilizing
   SOT-MRAM's Inherent Stochasticity
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE Bayesian neural network (BayesNN); magnetic tunnel junction (MTJ);
   neural network hardware accelerator; probabilistic computing; random
   number generation
AB Probabilistic machine learning plays a central role in the domains such as decision-making and autonomous control benefitting from its ability of representing and manipulating uncertainty about models and predictions. Until now, there are few hardware considerations to address the intensive computation and true random number generation for Bayesian neural network (BayesNN), whose weights are represented by probability distributions. In this article, we propose to apply the local reparameterization trick to alleviate the burden of random number generators (RNGs), which could be implemented by utilizing the inherent random noise of spin-orbit torque magnetic random access memory (SOT-MRAM). Sampling strategies are discussed to significantly reduce the number of operations and parameters of BayesNN. A device-circuit-system benchmark framework is then developed to evaluate the effects of device nonidealities such as the bias and variation of switching probability. The evaluation on the CIFAR-10 dataset suggests that BayesNN could achieve comparable accuracy as conventional deep neural network (DNN) with acceptable hardware overhead but provide much better uncertainty calibration with respect to out-of-distribution (OOD) inputs (rotated images as the example).
C1 [Lu, Anni; Luo, Yandong; Yu, Shimeng] Georgia Inst Technol, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3296957.3173212, 10.1145/3173162.3173212]
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Debashis P, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2860547
   Doevenspeck J., 2021, 2021 Symposium on VLSI Technology
   Doevenspeck J, 2020, S VLSI TECH, DOI 10.1109/vlsitechnology18217.2020.9265099
   Fan HX, 2021, DES AUT CON, P1063, DOI 10.1109/DAC18074.2021.9586137
   Garello K, 2019, S VLSI TECH, pT194
   Garello K, 2018, SYMP VLSI CIRCUITS, P81, DOI 10.1109/VLSIC.2018.8502269
   Jia XT, 2021, IEEE T NEUR NET LEAR, V32, P1703, DOI 10.1109/TNNLS.2020.2987760
   Kingma Durk P, 2015, NEURIPS
   Lin Y., 2019, IEDM, P14
   Lu AN, 2020, IEEE T VLSI SYST, V28, P1945, DOI 10.1109/TVLSI.2020.3001526
   Malhotra A, 2020, IEEE T NANOTECHNOL, V19, P328, DOI 10.1109/TNANO.2020.2982819
   Mulaosmanovic H, 2018, IEEE ELECTR DEVICE L, V39, P135, DOI 10.1109/LED.2017.2771818
   Ostwal V, 2019, IEEE MAGN LETT, V10, DOI 10.1109/LMAG.2019.2912971
   Peng XC, 2019, INT EL DEVICES MEET
   Wang H, 2016, IEEE T KNOWL DATA EN, V28, P3395, DOI 10.1109/TKDE.2016.2606428
   Yamaoka M, 2016, IEEE J SOLID-ST CIRC, V51, P303, DOI 10.1109/JSSC.2015.2498601
   Yang KZ, 2020, IEEE T ELECTRON DEV, V67, P1340, DOI 10.1109/TED.2020.2968223
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
NR 21
TC 4
Z9 4
U1 4
U2 10
PD JUN
PY 2022
VL 8
IS 1
BP 27
EP 34
DI 10.1109/JXCDC.2022.3177588
UT WOS:000809711000001
DA 2023-11-16
ER

PT C
AU Chiu, PF
   Choi, WH
   Ma, W
   Qin, MH
   Lueker-Boden, M
AF Chiu, Pi-Feng
   Choi, Won Ho
   Ma, Wen
   Qin, Minghai
   Lueker-Boden, Martin
GP IEEE
TI A Binarized Neural Network Accelerator with Differential Crosspoint
   Memristor Array for Energy-Efficient MAC Operations
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
DE Crosspoint memristor array; Binarized Neural Network (BNN); In-Memory
   Computing; Machine Learning
AB Binarized Neural Networks (BNN) significantly reduce computational complexity and relax memory requirements with binarized weights and activations. We propose a differential crosspoint (DX) memristor array for enabling parallel multiply-and-accumulate (MAC) operations in BNN to further improve the efficiency. Two differential memristors compose one synapse. The synapses on the same column form a voltage divider in which the output voltage corresponds linearly to the digital summation. The analog output voltage is then quantized to 4-bit output by a voltage sense amplifier. A small 64x64 DX array in every DX unit (DXU) minimizes parasitic resistance and capacitance for quicker MAC operations. A system architecture using DXUs for BNN acceleration is introduced. A wide range of BNN models can be mapped to an array of DXUs. To further reduce the energy spent on data movement, a neighbor shifting scheme increases the input data reusability. The effects of quantization and bit errors are investigated by running MNIST and CFAR-10 datasets. A DXU is able to achieve an estimated energy efficiency of 160 TMAC/s/W.
C1 [Chiu, Pi-Feng; Choi, Won Ho; Ma, Wen; Qin, Minghai; Lueker-Boden, Martin] Western Digital, San Jose, CA 95119 USA.
RP Chiu, PF (corresponding author), Western Digital, San Jose, CA 95119 USA.
EM pi-feng.chiu@wdc.com
CR Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Bengio, 2016, ABS160202830 CORR
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chiu PF, 2016, IEEE ASIAN SOLID STA, P181, DOI 10.1109/ASSCC.2016.7844165
   Chiu PF, 2015, IEEE T CIRCUITS-II, V62, P461, DOI 10.1109/TCSII.2014.2385431
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Liu R, 2014, 2014 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP), P1, DOI 10.1109/ISANP.2014.7026480
   Pogue BW, 2004, TECHNOL CANCER RES T, V3, P15, DOI 10.1177/153303460400300102
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K., 2015, ARXIV
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
NR 12
TC 6
Z9 6
U1 1
U2 3
PY 2019
UT WOS:000483076400058
DA 2023-11-16
ER

PT J
AU Chen, XH
   Zhao, Y
   Wang, Y
   Xu, PF
   You, HR
   Li, CJ
   Fu, YG
   Lin, YY
   Wang, ZY
AF Chen, Xiaohan
   Zhao, Yang
   Wang, Yue
   Xu, Pengfei
   You, Haoran
   Li, Chaojian
   Fu, Yonggan
   Lin, Yingyan
   Wang, Zhangyang
TI SmartDeal: Remodeling Deep Network Weights for Efficient Inference and
   Training
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Training; Matrix decomposition; Costs; Quantization (signal); Inference
   algorithms; Random access memory; Hardware acceleration; Data movement;
   deep network training; efficient machine learning; hardware accelerator
ID NEURAL-NETWORKS; ACCELERATOR
AB The record-breaking performance of deep neural networks (DNNs) comes with heavy parameter budgets, which leads to external dynamic random access memory (DRAM) for storage. The prohibitive energy of DRAM accesses makes it nontrivial for DNN deployment on resource-constrained devices, calling for minimizing the movements of weights and data in order to improve the energy efficiency. Driven by this critical bottleneck, we present SmartDeal, a hardware-friendly algorithm framework to trade higher-cost memory storage/access for lower-cost computation, in order to aggressively boost the storage and energy efficiency, for both DNN inference and training. The core technique of SmartDeal is a novel DNN weight matrix decomposition framework with respective structural constraints on each matrix factor, carefully crafted to unleash the hardware-aware efficiency potential. Specifically, we decompose each weight tensor as the product of a small basis matrix and a large structurally sparse coefficient matrix whose nonzero elements are readily quantized to the power-of-2. The resulting sparse and readily quantized DNNs enjoy greatly reduced energy consumption in data movement as well as weight storage, while incurring minimal overhead to recover the original weights thanks to the required sparse bit-operations and cost-favorable computations. Beyond inference, we take another leap to embrace energy-efficient training, by introducing several customized techniques to address the unique roadblocks arising in training while preserving the SmartDeal structures. We also design a dedicated hardware accelerator to fully utilize the new weight structure to improve the real energy efficiency and latency performance. We conduct experiments on both vision and language tasks, with nine models, four datasets, and three settings (inference-only, adaptation, and fine-tuning). Our extensive results show that 1) being applied to inference, SmartDeal achieves up to 2.44x improvement in energy efficiency as evaluated using real hardware implementations and 2) being applied to training, SmartDeal can lead to 10.56x and 4.48x reduction in the storage and the training energy cost, respectively, with usually negligible accuracy loss, compared to state-of-the-art training baselines. Our source codes are available at: https://github.com/VITA-Group/SmartDeal.
C1 [Chen, Xiaohan; Wang, Zhangyang] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
   [Zhao, Yang; Wang, Yue; Xu, Pengfei; You, Haoran; Li, Chaojian; Fu, Yonggan; Lin, Yingyan] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
RP Chen, XH (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM xiaohan.chen@utexas.edu; zy34@rice.edu; atlaswang@utexas.edu;
   px5@rice.edu; hy34@rice.edu; cl114@rice.edu; yf22@rice.edu;
   yingyan.lin@rice.edu
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Ba L. J., 2014, ADV NEURAL INFORM PR, V2, P2654
   Banner R, 2018, ADV NEURAL INFORM PR, P5151
   Bernstein J., 2018, ARXIV180204434, V80, P560
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brown Tom, 2020, NEURIPS, V1, P3
   Chaojian Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P500, DOI 10.1007/978-3-030-58545-7_29
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Tianlong, 2020, ARXIV PREPRINT ARXIV
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Ting, 2020, NEURIPS
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esser Steven K, 2019, ARXIV190208153
   Fu Y.`, 2020, ADV NEURAL INFORM PR, P12127
   Gong RH, 2019, IEEE I CONF COMP VIS, P4851, DOI 10.1109/ICCV.2019.00495
   Gong Y., 2014, INT C LEARN REPR ICL, P1
   Gui S., 2019, ADVERSARIALLY TRAINE
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Helwegen K., 2019, ADV NEURAL INFORM PR, P7531
   Hinton Geoffrey, 2015, ARXIV150302531
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Hu T.-K., 2020, ARXIV200210025
   Huang HT, 2018, IEEE T NANOTECHNOL, V17, P645, DOI 10.1109/TNANO.2017.2732698
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim C, 2019, ISSCC DIG TECH PAP I, V62, P136, DOI [10.1109/isscc.2019.8662447, 10.1109/ISSCC.2019.8662447]
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Marcus M. P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Micikevicius Paulius, 2018, 6 INT C LEARNING REP, DOI DOI 10.1109/CAMAD.2018.8514963
   Mishra A., 2018, P INT C LEARN REPR I
   Novikov A., 2015, TENSORIZING NEURAL N, P442
   NVIDIA, NVIDIA JETSON TX2 DE
   NVIDIA, NVIDIA TESL V100 TEN
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Polino Antonio, 2018, ARXIV180205668
   Qin ZD, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010078
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen JH, 2020, AAAI CONF ARTIF INTE, V34, P5700
   Synopsys, PRIMETIME PX SIGN PO
   Tailor S. A., 2021, P INT C LEARN REPR
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tung F, 2018, PROC CVPR IEEE, P7873, DOI 10.1109/CVPR.2018.00821
   Wang, 2019, ADV NEURAL INFORM PR, P5139
   Wang Hanqing, 2020, ECCV, V2, P7
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.00881, 10.1109/CVPR.2019.01218]
   Wang M., 2018, ARXIV181108589
   Wang N., 2018, INT C NEURAL INFORM, P7686
   Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25
   Wang Y, 2020, IEEE J-STSP, V14, P623, DOI 10.1109/JSTSP.2020.2979669
   Wen W, 2016, ADV NEUR IN, V29
   Wu JR, 2018, PR MACH LEARN RES, V80
   Xilinx Inc, AVNET ULTRA96
   Yang G., 2019, PR MACH LEARN RES
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yang YK, 2020, NEURAL NETWORKS, V125, P70, DOI 10.1016/j.neunet.2019.12.027
   You, 2020, ARXIV201012785
   You Haoran, 2019, ARXIV190911957
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang Peizhao, 2018, ARXIV181200090
   Zhao Y, 2020, ANN I S COM, P954, DOI 10.1109/ISCA45697.2020.00082
   Zhou Shuchang, 2016, ARXIV160606160
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 75
TC 0
Z9 0
U1 0
U2 3
PD OCT
PY 2023
VL 34
IS 10
BP 7099
EP 7113
DI 10.1109/TNNLS.2021.3138056
EA MAR 2022
UT WOS:000764847100001
DA 2023-11-16
ER

PT J
AU Puyati, W
   Khawne, A
   Barnes, M
   Zwan, B
   Greer, P
   Fuangrod, T
AF Puyati, Wayo
   Khawne, Amnach
   Barnes, Michael
   Zwan, Benjamin
   Greer, Peter
   Fuangrod, Todsaporn
TI Predictive quality assurance of a linear accelerator based on the
   machine performance check application using statistical process control
   and ARIMA forecast modeling
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE autoregressive integrated moving average forecast modeling; machine
   performance check; predictive quality assurance; statistical process
   control
ID VERIFICATION; STABILITY; SYMMETRY
AB Purpose A predictive linac quality assurance system based on the output of the Machine Performance Check (MPC) application was developed using statistical process control and autoregressive integrated moving average forecast modeling. The aim of this study is to demonstrate the feasibility of predictive quality assurance based on MPC tests that allow proactive preventative maintenance procedures to be carried out to better ensure optimal linac performance and minimize downtime. Method and Materials Daily MPC data were acquired for a total of 490 measurements. The initial 85% of data were used in prediction model learning with the autoregressive integrated moving average technique and in calculating upper and lower control limits for statistical process control analysis. The remaining 15% of data were used in testing the accuracy of the predictions of the proposed system. Two types of prediction were studied, namely, one-step-ahead values for predicting the next day's quality assurance results and six-step-ahead values for predicting up to a week ahead. Results that fall within the upper and lower control limits indicate a normal stage of machine performance, while the tolerance, determined from AAPM TG-142, is the clinically required performance. The gap between the control limits and the clinical tolerances (as the warning stage) provides a window of opportunity for rectifying linac performance issues before they become clinically significant. The accuracy of the predictive model was tested using the root-mean-square error, absolute error, and average accuracy rate for all MPC test parameters. Results The accuracy of the predictive model is considered high (average root-mean-square error and absolute error for all parameters of less than 0.05). The average accuracy rate for indicating the normal/warning stages was higher than 85.00%. Conclusion Predictive quality assurance with the MPC will allow preventative maintenance, which could lead to improved linac performance and a reduction in unscheduled linac downtime.
C1 [Puyati, Wayo; Khawne, Amnach] King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok 10520, Thailand.
   [Puyati, Wayo] Ubon Ratchathani Univ, Fac Sci, Dept Math Stat & Comp, Ubon Ratchathani 34190, Thailand.
   [Barnes, Michael; Greer, Peter] Calvary Mater Hosp Newcastle, Dept Radiat Oncol, Newcastle, NSW 2298, Australia.
   [Barnes, Michael; Zwan, Benjamin; Greer, Peter] Univ Newcastle, Sch Math & Phys Sci, Newcastle, NSW 2308, Australia.
   [Zwan, Benjamin] Gosford Hosp, Cent Coast Canc Ctr, Gosford, NSW 2250, Australia.
   [Fuangrod, Todsaporn] Chulabhorn Royal Acad, HRH Princess Chulabhorn Coll Med Sci, Fac Med & Publ Hlth, Bangkok 10210, Thailand.
RP Fuangrod, T (corresponding author), Chulabhorn Royal Acad, HRH Princess Chulabhorn Coll Med Sci, Fac Med & Publ Hlth, Bangkok 10210, Thailand.
EM Todsaporn.fua@pccms.ac.th
CR Able C, 2012, MED PHYS, V39, P3750, DOI 10.1118/1.4735265
   Able C, 2012, MED PHYS, V39, P3751, DOI 10.1118/1.4735268
   Able CM, 2011, RADIAT ONCOL, V6, DOI 10.1186/1748-717X-6-180
   Barnes MP, 2018, J APPL CLIN MED PHYS, V19, P68, DOI 10.1002/acm2.12445
   Barnes MP, 2017, J APPL CLIN MED PHYS, V18, P56, DOI 10.1002/acm2.12072
   Barnes MP, 2017, J APPL CLIN MED PHYS, V18, P200, DOI 10.1002/acm2.12064
   Barnes MP, 2017, J APPL CLIN MED PHYS, V18, P139, DOI 10.1002/acm2.12016
   Binny D, 2019, J APPL CLIN MED PHYS, V20, P71, DOI 10.1002/acm2.12547
   Binny D, 2017, PHYS MEDICA, V38, P105, DOI 10.1016/j.ejmp.2017.05.052
   Bissonnette JP, 2012, MED PHYS, V39, P1946, DOI 10.1118/1.3690466
   Burnham KP., 2002, MODEL SELECTION MULT, DOI 10.1007/978-0-387-22456-5_2
   Clivio A, 2015, RADIAT ONCOL, V10, DOI 10.1186/s13014-015-0381-0
   Fuangrod T, 2016, RADIAT ONCOL, V11, DOI 10.1186/s13014-016-0682-y
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Greer PB, 2003, MED PHYS, V30, P1618, DOI 10.1118/1.1582469
   Hampton CJ, 2010, INT J RADIAT ONCOL, V78, pS71, DOI 10.1016/j.ijrobp.2010.07.198
   King BW, 2011, AUSTRALAS PHYS ENG S, V34, P459, DOI 10.1007/s13246-011-0106-0
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Li QG, 2017, ANN NY ACAD SCI, V1387, P84, DOI 10.1111/nyas.13215
   Li YT, 2018, J APPL CLIN MED PHYS, V19, P375, DOI 10.1002/acm2.12391
   López-Tarjuelo J, 2015, PHYS MEDICA, V31, P493, DOI 10.1016/j.ejmp.2015.05.006
   Louwe RJW, 2004, MED PHYS, V31, P2989, DOI 10.1118/1.1803751
   Nijsten SMJJG, 2007, MED PHYS, V34, P3872, DOI 10.1118/1.2776244
   Qin Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2627
   Shewhart W.A, 1939, STAT METHOD VIEWPOIN
   Smith K, 2017, J APPL CLIN MED PHYS, V18, P23, DOI 10.1002/acm2.12080
   Van Esch A, 2004, RADIOTHER ONCOL, V71, P223, DOI 10.1016/j.radonc.2004.02.018
   Wheeler DJ, 1995, ADV TOPICS STAT PROC, V470
   Winkler P, 2005, MED PHYS, V32, P3095, DOI 10.1118/1.2040711
NR 29
TC 6
Z9 8
U1 0
U2 6
PD AUG
PY 2020
VL 21
IS 8
BP 73
EP 82
DI 10.1002/acm2.12917
EA JUN 2020
UT WOS:000540205500001
DA 2023-11-16
ER

PT J
AU Lu, XY
   Jordan, KE
   Wheeler, MF
   Pyzer-Knapp, EO
   Benatan, M
AF Lu, Xueying
   Jordan, Kirk E.
   Wheeler, Mary F.
   Pyzer-Knapp, Edward O.
   Benatan, Matthew
TI Bayesian Optimization for Field-Scale Geological Carbon Storage
SO ENGINEERING
DT Article
DE Compositional flow; Bayesian optimization; Geological carbon storage;
   CCUS; Machine learning; AI for science
ID CO2 STORAGE; FLOW; PERMEABILITY; HYSTERESIS; ALGORITHMS
AB We present a framework that couples a high-fidelity compositional reservoir simulator with Bayesian optimization (BO) for injection well scheduling optimization in geological carbon sequestration. This work represents one of the first at tempts to apply BO and high-fidelity physics models to geological carbon storage. The implicit parallel accurate reservoir simulator (IPARS) is utilized to accurately capture the underlying physical processes during CO2 sequestration. IPARS provides a framework for several flow and mechanics models and thus supports both stand-alone and coupled simulations. In this work, we use the compositional flow module to simulate the geological carbon storage process. The compositional flow model, which includes a hysteretic three-phase relative permeability model, accounts for three major CO2 trapping mechanisms: structural trapping, residual gas trapping, and solubility trapping. Furthermore, IPARS is coupled to the International Business Machines (IBM) Corporation Bayesian Optimization Accelerator (BOA) for parallel optimizations of CO2 injection strategies during field-scale CO2 sequestration. BO builds a probabilistic surrogate for the objective function using a Bayesian machine learning algorithm-the Gaussian process regression, and then uses an acquisition function that leverages the uncertainty in the surrogate to decide where to sample. The IBM BOA addresses the three weaknesses of standard BO that limits its scalability in that IBM BOA supports parallel (batch) executions, scales better for high-dimensional problems, and is more robust to initializations. We demonstrate these merits by applying the algorithm in the optimization of the CO2 injection schedule in the Cranfield site in Mississippi, USA, using field data. The optimized injec-tion schedule achieves 16% more gas storage volume and 56% less water/surfactant usage compared with the baseline. The performance of BO is compared with that of a genetic algorithm (GA) and a covariance matrix adaptation (CMA)-evolution strategy (ES). The results demonstrate the superior performance of BO, in that it achieves a competitive objective function value with over 60% fewer forward model evaluations.(c) 2022 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Lu, Xueying; Wheeler, Mary F.] Univ Texas Austin, Oden Inst Computat Engn & Sci, Ctr Subsurface Modeling, Austin, TX 78712 USA.
   [Jordan, Kirk E.; Pyzer-Knapp, Edward O.; Benatan, Matthew] IBM Res United Kingdom, Warrington WA4 4AD, England.
RP Lu, XY (corresponding author), Univ Texas Austin, Oden Inst Computat Engn & Sci, Ctr Subsurface Modeling, Austin, TX 78712 USA.
EM xylu@utexas.edu
CR Abdollahzadeh A, 2012, SPE J, V17, P865, DOI 10.2118/143290-PA
   Bangerth W, 2006, COMPUTAT GEOSCI, V10, P303, DOI 10.1007/s10596-006-9025-7
   Beygi MR, 2015, SPE J, V20, P21, DOI 10.2118/165324-PA
   Brochu E, 2010, Arxiv, DOI [arXiv:1012.2599, DOI 10.48550/ARXIV.1012.2599]
   Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Calandra R, 2016, ANN MATH ARTIF INTEL, V76, P5, DOI 10.1007/s10472-015-9463-9
   Cappa F, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL048487
   [陈至立 CHEN Zhili], 2006, [中国软科学, China Soft Science], P1
   Class H, 2009, COMPUTAT GEOSCI, V13, P409, DOI 10.1007/s10596-009-9146-x
   Delshad M, 2011, P SPE RES SIM S 2011
   Delshad M, 2013, INT J GREENH GAS CON, V18, P463, DOI 10.1016/j.ijggc.2013.03.019
   Fonseca RRM, 2017, INT J NUMER METH ENG, V109, P1756, DOI 10.1002/nme.5342
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Ganis B, 2017, COMPUTAT GEOSCI, V21, P1189, DOI 10.1007/s10596-017-9683-7
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   IEA, 2021, US
   Jasrasaria D, 2019, ADV INTELL SYST COMP, V858, P1, DOI 10.1007/978-3-030-01174-1_1
   Kulkarni MM, 2005, J PETROL SCI ENG, V48, P1, DOI 10.1016/j.petrol.2005.05.001
   Kumar A, 2005, SPE J, V10, P336, DOI 10.2118/89343-PA
   Kumar A, 2004, DISSERTATION
   Li HY, 2020, J COMPUT PHYS, V403, DOI [10.1016/j.jcp.2019.10.9074, 10.1016/j.jcp.2019.109074]
   Liu Y, ENGINEERING
   Lizotte DJ, 2008, DISSERTATION
   Lotfollahi M, 2017, TRANSPORT POROUS MED, V116, P687, DOI 10.1007/s11242-016-0796-6
   Lu X, 2019, P SPE RESERVOIR SIMU
   Lu X, 2018, P SPE IMPR OIL REC C
   Lu XY, 2020, J COMPUT PHYS, V401, DOI 10.1016/j.jcp.2019.109053
   Ma K, 2015, SPE J, V20, P453, DOI 10.2118/169104-PA
   Marchant R, 2012, IEEE INT C INT ROBOT, P2242, DOI 10.1109/IROS.2012.6385653
   Matern B, 1986, SPATIAL VARIATION, DOI 10.1007/978-1-4615-7892-5
   Hernández-Lobato JM, 2017, PR MACH LEARN RES, V70
   Mikelic A, 2014, COMPUTAT GEOSCI, V18, P325, DOI 10.1007/s10596-013-9393-8
   Min B, 2018, J PETROL SCI ENG, V170, P244, DOI 10.1016/j.petrol.2018.06.035
   Mockus J., 1978, Towards global optimisation. II, P117
   Navarre-Sitchler AK, 2013, ADV WATER RESOUR, V53, P45, DOI 10.1016/j.advwatres.2012.10.005
   Nwachukwu A., 2018, SPE IMPR OIL REC C
   Onwunalu JE, 2010, COMPUTAT GEOSCI, V14, P183, DOI 10.1007/s10596-009-9142-1
   PENG D, 1976, IND ENG CHEM FUND, V15, P59, DOI 10.1021/i160057a011
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Singh G, 2016, COMPUTAT GEOSCI, V20, P421, DOI 10.1007/s10596-015-9535-2
   Snoek J., 2012, ADV NEURAL INF PROCE, V25, P2951, DOI DOI 10.5555/2999325.2999464
   Stein M. L, 1999, INTERPOLATION SPATIA
   Tang M, 2020, J COMPUT PHYS, V413, DOI 10.1016/j.jcp.2020.109456
   Thomas SG, 2009, DISSERTATION
   Wheeler MF, 2010, PROCEEDINGS OF THE INTERNATIONAL CONGRESS OF MATHEMATICIANS, VOL IV: INVITED LECTURES, P2864
   White D, 2017, SPE RESERVOIR SIMULA, P1
   Zandvliet MJ, 2008, SPE J, V13, P392, DOI 10.2118/105797-PA
   Zhang K, 2010, J PETROL SCI ENG, V73, P220, DOI 10.1016/j.petrol.2010.07.002
   Zhao XL, 2016, J NAT GAS SCI ENG, V29, P275, DOI 10.1016/j.jngse.2015.12.044
   Zhao XL, 2014, J ENERGY INST, V87, P297, DOI 10.1016/j.joei.2014.03.032
   Zhu YH, 2018, J COMPUT PHYS, V366, P415, DOI 10.1016/j.jcp.2018.04.018
   Zoback MD, 2012, P NATL ACAD SCI USA, V109, P10164, DOI 10.1073/pnas.1202473109
NR 52
TC 1
Z9 1
U1 4
U2 14
PD NOV
PY 2022
VL 18
BP 96
EP 104
DI 10.1016/j.eng.2022.06.011
UT WOS:000925142400001
DA 2023-11-16
ER

PT C
AU Zhou, K
   Anderson, J
   Meng, XZ
   Mellor-Crummey, J
AF Zhou, Keren
   Anderson, Jonathon
   Meng, Xiaozhu
   Mellor-Crummey, John
GP ACM
TI Low Overhead and Context Sensitive Profiling of GPU-accelerated
   Applications
SO PROCEEDINGS OF THE 36TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING,
   ICS 2022
DT Proceedings Paper
CT 36th ACM International Conference on Supercomputing (ICS)
CY JUN 27-30, 2022
CL ELECTR NETWORK
DE Calling Context; GPUs; GPU-accelerated Applications; GPU Performance
   Tools; Instruction Sampling; Profiling
AB As we near the end of Moore's law scaling, the next-generation computing platforms are increasingly exploring heterogeneous processors for acceleration. Graphics Processing Units (GPUs) are the most widely used accelerators. Meanwhile, applications are evolving by adopting new programming models and algorithms for emerging platforms. To harness the full power of GPUs, performance tools serve a critical role in understanding and tuning application performance, especially for those that involve complex executions spanning both CPU and GPU. To help developers analyze and tune applications, performance tools need to associate performance metrics with calling contexts. However, existing performance tools incur high overhead collecting and attributing performance metrics to full calling contexts. To address the problem, we developed a tool that constructs both CPU and GPU calling contexts with low overhead and high accuracy. With an innovative call path memoization mechanism, our tool can obtain call paths for GPU operations with negligible cost. For GPU calling contexts, our tool uses an adaptive epoch profiling method to collect GPU instruction samples to reduce the synchronization cost and reconstruct the calling contexts using postmortem analysis. We have evaluated our tool on nine HPC and machine learning applications on a machine equipped with an NVIDIA GPU. Compared with the state-of-the-art GPU profilers, our tool reduces the overhead for coarse-grained profiling of GPU operations from 2.07x to 1.42x and the overhead for fine-grained profiling of GPU instructions from 27.51x to 4.61x with an accuracy of 99.93% and 96.16% in each mode.
C1 [Zhou, Keren; Anderson, Jonathon; Meng, Xiaozhu; Mellor-Crummey, John] Rice Univ, Houston, TX 77251 USA.
RP Zhou, K (corresponding author), Rice Univ, Houston, TX 77251 USA.
EM keren.zhou@rice.edu; janderson@rice.edu; mxz297@gmail.com;
   johnmc@rice.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adhianto L, 2010, CONCURR COMP-PRACT E, V22, P685, DOI 10.1002/cpe.1553
   Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   AMD Corporation, 2017, ROC TRAC
   AMD Corporation, 2017, ROC PROF
   Ammons G, 1997, ACM SIGPLAN NOTICES, V32, P85, DOI 10.1145/258916.258924
   Ball T, 1996, PROCEEDINGS OF THE 29TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE - MICRO-29, P46, DOI 10.1109/MICRO.1996.566449
   Bastian T, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360572
   Bond MD, 2007, ACM SIGPLAN NOTICES, V42, P97, DOI 10.1145/1297105.1297035
   Chabbi M, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503299
   Deslippe J, 2012, COMPUT PHYS COMMUN, V183, P1269, DOI 10.1016/j.cpc.2011.12.006
   Dimakopoulou M, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P396, DOI 10.1109/SC.2016.33
   Dobrev VA, 2012, SIAM J SCI COMPUT, V34, pB606, DOI 10.1137/120864672
   Dongarra Jack, 2001, C LIN CLUST HPC REV, V5
   Edwards HC, 2014, J PARALLEL DISTR COM, V74, P3202, DOI 10.1016/j.jpdc.2014.07.003
   Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, DOI 10.48550/ARXIV.1903.02428]
   Froyd Nathan, 2005, P 19 ANN INT C SUP, P81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hornung Richard D., 2014, RAJA PORTABILITY LAY, DOI DOI 10.2172/1169830
   Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2704, DOI 10.1145/3366423.3380027
   Intel Corporation, 2022, ONEAPI LEV ZER
   Kambadur M, 2015, I S WORKL CHAR PROC, P76, DOI 10.1109/IISWC.2015.14
   Lawrence Berkeley National Laboratory National Renewable Energy Laboratory and Sandia National Laboratories, 2019, AMR WIND
   Myers A, 2021, Arxiv, DOI arXiv:2101.12149
   Mytkowicz T, 2009, ACM SIGPLAN NOTICES, V44, P175, DOI 10.1145/1639949.1640102
   National Renewable Energy Laboratory, 2019, PELEC
   NVIDIA Corporation, 2022, NVIDIA NSIGHT COMP
   NVIDIA Corporation, 2022, CUDA TOOLK DOC
   NVIDIA Corporation, 2022, US MAN NVIDIA PROF T
   NVIDIA Corporation, 2022, PC SAMPL
   NVIDIA Corporation, 2022, NVIDIA NSIGHT SYST
   NVIDIA Corporation, 2022, CUPTI US GUID DA 056
   Paszke A, 2019, ADV NEUR IN, V32
   Phillips JC, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0014475
   PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039
   Reinders James, 2005, VTUNE PERFORMANCE AN
   Servat H, 2016, EUROMICRO WORKSHOP P, P82, DOI 10.1109/PDP.2016.62
   Sumner WN, 2012, IEEE T SOFTWARE ENG, V38, P1160, DOI 10.1109/TSE.2011.70
   Treibig J., 2010, 2010 39th International Conference on Parallel Processing Workshops (ICPPW), P207, DOI 10.1109/ICPPW.2010.38
   Villa O, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P372, DOI 10.1145/3352460.3358307
   Welton B, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356213
   Zhang H, 2019, PROCEEDINGS OF PROTOOLS 2019: 2019 IEEE/ACM INTERNATIONAL WORKSHOP ON PROGRAMMING AND PERFORMANCE VISUALIZATION TOOLS (PROTOOLS), P1, DOI 10.1109/ProTools49597.2019.00006
   Zhang W., 2019, J OPEN SOURCE SOFTW, V4, P1370, DOI [DOI 10.21105/JOSS.01370, 10.21105/joss.01370]
   Zhou Keren, 2020, ICS '20: Proceedings of the 34th ACM International Conference on Supercomputing, DOI 10.1145/3392717.3392752
   Zhou KR, 2021, PARALLEL COMPUT, V108, DOI 10.1016/j.parco.2021.102837
   Zhou KR, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00093
   Zhou KR, 2021, INT SYM CODE GENER, P115, DOI 10.1109/CGO51591.2021.9370339
   Zhuang X, 2006, ACM SIGPLAN NOTICES, V41, P263, DOI 10.1145/1133981.1134012
NR 48
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3524059.3532388
UT WOS:001086201800030
DA 2023-11-16
ER

PT C
AU Rybalkin, V
   Bukhari, SS
   Ghaffar, MM
   Ghafoor, A
   Wehn, N
   Dengel, A
AF Rybalkin, Vladimir
   Bukhari, Syed Saqib
   Ghaffar, Muhammad Mohsin
   Ghafoor, Aqib
   Wehn, Norbert
   Dengel, Andreas
GP ACM
TI <i>i</i>DocChip - A Configurable Hardware Architecture for Historical
   Document Image Processing: Percentile Based Binarization
SO PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG 2018)
DT Proceedings Paper
CT 18th ACM Symposium on Document Engineering (DocEng)
CY AUG 28-31, 2018
CL Halifax, CANADA
DE Optical Character Recognition; FPGA; Binarization; Hardware-Software
   Co-Design; Zynq; Hardware Architecture; Machine Learning
AB End-to-end Optical Character Recognition (OCR) systems are heavily used to convert document images into machine-readable text. Commercial and open-source OCR systems (like Abbyy, OCRopus, Tesseract etc.) have traditionally been optimized for contemporary documents like books, letters, memos, and other end-user documents. However, these systems are difficult to use equally well for digitizing historical document images, which contain degradations like non-uniform shading, bleed-through, and irregular layout; such degradations usually do not exist in contemporary document images.
   The open-source anyOCR is an end-to-end OCR pipeline, which contains state-of-the-art techniques that are required for digitizing degraded historical archives with high accuracy. However, high accuracy comes at a cost of high computational complexity that results in 1) long runtime that limits digitization of big collection of historical archives and 2) high energy consumption that is the most critical limiting factor for portable devices with constrained energy budget. Therefore, we are targeting energy efficient and high throughput acceleration of the anyOCR pipeline. General-purpose computing platforms fail to meet these requirements that makes custom hardware design mandatory. In this paper, we are presenting a new concept named iDocChip. It is a portable hybrid hardware-software FPGA-based accelerator that is characterized by low footprint meaning small size, high power efficiency that will allow using it in portable devices, and high throughput that will make it possible to process big collection of historical archives in real time without effecting the accuracy.
   In this paper, we focus on binarization, which is the second most critical step in the anyOCR pipeline after text-line recognizer that we have already presented in our previous publication [21]. The anyOCR system makes use of a Percentile Based Binarization method that is suitable for overcoming degradations like non-uniform shading and bleed-through. To the best of our knowledge, we propose the first hardware architecture of the PBB technique. Based on the new architecture, we present a hybrid hardware-software FPGA-based accelerator that outperforms the existing anyOCR software implementation running on i7-4790T in terms of runtime by factor of 21, while achieving energy efficiency of 10 Images/J that is higher than that achieved by low power embedded processors with negligible loss of recognition accuracy.
C1 [Rybalkin, Vladimir; Ghaffar, Muhammad Mohsin; Wehn, Norbert] Univ Kaiserslautern, Microelect Syst Design Res Grp, Kaiserslautern, Germany.
   [Bukhari, Syed Saqib; Dengel, Andreas] Univ Kaiserslautern, German Res Ctr Artificial Intelligence DFKI, Kaiserslautern, Germany.
   [Ghafoor, Aqib] Univ Kaiserslautern, Kaiserslautern, Germany.
RP Rybalkin, V (corresponding author), Univ Kaiserslautern, Microelect Syst Design Res Grp, Kaiserslautern, Germany.
EM rybalkin@eit.uni-kl.de; saqib.bukhari@dfki.de; ghaffar@eit.uni-kl.de;
   aaqibghafoor@gmail.com; wehn@eit.uni-kl.de; andreas.dengel@dfki.de
CR Afzal MZ, 2014, LECT NOTES COMPUT SC, V8357, P139, DOI 10.1007/978-3-319-05167-3_11
   ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], 2011, INT J COMPUT APPL
   [Anonymous], 2011, INT J COMPUT APPL
   Breuel TM, 2013, PROC INT CONF DOC, P683, DOI 10.1109/ICDAR.2013.140
   Bukhari Syed Saqib, 2017, 14 IAPR INT C DOC AN
   Faure Claudie, 2009, COMP NIBLACK INSPIRE, DOI [10.1117/12.805827, DOI 10.1117/12.805827]
   Graves Alex, 2006, P ICML, P369
   He J, 2005, PROC INT CONF DOC, P538, DOI 10.1109/ICDAR.2005.3
   Kavallieratou E, 2006, INT C PATT RECOG, P742
   Kawakami K., 2008, SUPERVISED SEQUENCE
   Kheiri F., 2017, ARXIVCSCV171005749
   Najafi MH, 2016, IEEE T VLSI SYST, V24, P808, DOI 10.1109/TVLSI.2015.2415932
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Puneet P., 2013, INT J COMPUTER APPL, V71, P8, DOI 10.5120/12320-8533
   Rybalkin V, 2017, DES AUT TEST EUROPE, P1390, DOI 10.23919/DATE.2017.7927210
   Sauvola J, 1997, PROC INT CONF DOC, P147, DOI 10.1109/ICDAR.1997.619831
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   YANG JD, 1994, PATTERN RECOGN LETT, V15, P141, DOI 10.1016/0167-8655(94)90043-4
   Yousefi MR, 2015, PROC INT CONF DOC, P1121, DOI 10.1109/ICDAR.2015.7333935
   Yousefi MR, 2015, PROC SPIE, V9402, DOI 10.1117/12.2075930
NR 21
TC 0
Z9 0
U1 0
U2 1
PY 2018
DI 10.1145/3209280.3209538
UT WOS:000455832100024
DA 2023-11-16
ER

PT J
AU Shao, RL
   He, HY
   Chen, ZW
   Liu, H
   Liu, DB
AF Shao, Rulin
   He, Hongyu
   Chen, Ziwei
   Liu, Hui
   Liu, Dianbo
TI Stochastic Channel-Based Federated Learning With Neural Network Pruning
   for Medical Data Privacy Preservation: Model Development and
   Experimental Validation
SO JMIR FORMATIVE RESEARCH
DT Article
DE federated learning; differential privacy preserving; neural network
   pruning; health care; privacy; medical data; machine learning; neural
   network
AB Background: Artificial neural networks have achieved unprecedented success in the medical domain. This success depends on the availability of massive and representative datasets. However, data collection is often prevented by privacy concerns, and people want to take control over their sensitive information during both the training and using processes.
   Objective: To address security and privacy issues, we propose a privacy-preserving method for the analysis of distributed medical data. The proposed method, termed stochastic channel-based federated learning (SCBFL), enables participants to train a high-performance model cooperatively and in a distributed manner without sharing their inputs.
   Methods: We designed, implemented, and evaluated a channel-based update algorithm for a central server in a distributed system. The update algorithm will select the channels with regard to the most active features in a training loop, and then upload them as learned information from local datasets. A pruning process, which serves as a model accelerator, was further applied to the algorithm based on the validation set.
   Results: We constructed a distributed system consisting of 5 clients and 1 server. Our trials showed that the SCBFL method can achieve an area under the receiver operating characteristic curve (AUC-ROC) of 0.9776 and an area under the precision-recall curve (AUC-PR) of 0.9695 with only 10% of channels shared with the server. Compared with the federated averaging algorithm, the proposed SCBFL method achieved a 0.05388 higher AUC-ROC and 0.09695 higher AUC-PR. In addition, our experiment showed that 57% of the time is saved by the pruning process with only a reduction of 0.0047 in AUC-ROC performance and a reduction of 0.0068 in AUC-PR performance.
   Conclusions: In this experiment, our model demonstrated better performance and a higher saturating speed than the federated averaging method, which reveals all of the parameters of local models to the server. The saturation rate of performance could be promoted by introducing a pruning process and further improvement could be achieved by tuning the pruning rate.
C1 [Shao, Rulin] Xi An Jiao Tong Univ, Dept Math & Stat, Xian, Peoples R China.
   [He, Hongyu] Xi An Jiao Tong Univ, Dept Elect Engn, Xian, Peoples R China.
   [Chen, Ziwei] Beijing Jiaotong Univ, Beijing, Peoples R China.
   [Liu, Hui] Mianyang Vocat Coll, Dept Math, Mianyang, Sichuan, Peoples R China.
   [Liu, Dianbo] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Liu, DB (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM dianbo@mit.edu
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Abouelmehdi K, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0110-7
   Adam Nabil, 2007, AMIA Annu Symp Proc, P1
   [Anonymous], 2006, L DIVERSITY PRIVACY, DOI DOI 10.1109/ICDE.2006.1
   Bagdasaryan E, 2020, PR MACH LEARN RES, V108, P2938
   Bassily R, 2014, ANN IEEE SYMP FOUND, P464, DOI 10.1109/FOCS.2014.56
   Bertino E, 2005, PROC INT CONF DATA, P521
   Bonawitz K., 2019, MLSYS
   Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982
   Chilimbi T., 2014, P 11 USENIX S OP SYS, P571, DOI DOI 10.1108/01439911111122716
   Craig Terence, 2011, PRIVACY BIG DATA PLA
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Dwork C, 2010, ACM S THEORY COMPUT, P715
   Dwork C, 2010, ANN IEEE SYMP FOUND, P51, DOI 10.1109/FOCS.2010.12
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Geyer R.C., 2017, ARXIV
   Han HG, 2010, IEEE T FUZZY SYST, V18, P1129, DOI 10.1109/TFUZZ.2010.2070841
   Hard A, 2019, Arxiv, DOI arXiv:1811.03604
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hu HY, 2016, Arxiv, DOI [arXiv:1607.03250, 10.48550/arXiv.1607.03250]
   Hundepool A, 1997, RECORD LINKAGE TECHN
   Jain Priyank, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0059-y
   Jensen M, 2013, IEEE INT CONGR BIG, P235, DOI 10.1109/BigData.Congress.2013.39
   Konečny J, 2015, Arxiv, DOI arXiv:1511.03575
   Konečny J, 2016, Arxiv, DOI arXiv:1610.02527
   Konečny J, 2017, Arxiv, DOI arXiv:1610.05492
   Li N., 2007, 2007 IEEE 23 INT C D, P106, DOI DOI 10.1109/ICDE.2007.367856
   Ma C, 2017, OPTIM METHOD SOFTW, V32, P813, DOI 10.1080/10556788.2016.1278445
   McMahan H B, 2016, FEDERATED LEARNING D, DOI DOI 10.48550/ARXIV.1602.05629
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Peterson ED, 2019, JAMA-J AM MED ASSOC, V322, P2283, DOI 10.1001/jama.2019.17831
   Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193
   Sarwate AD, 2013, IEEE SIGNAL PROC MAG, V30, P86, DOI 10.1109/MSP.2013.2259911
   Sedayao Jeff, 2014, 2014 IEEE International Congress on Big Data (BigData Congress), P601, DOI 10.1109/BigData.Congress.2014.92
   Shamir O, 2014, PR MACH LEARN RES, V32, P1000
   Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687
   Song S, 2013, IEEE GLOB CONF SIG, P245, DOI 10.1109/GlobalSIP.2013.6736861
   Srinivas S, 2015, Arxiv, DOI arXiv:1507.06149
   Sweeney L., 1998, Database Security XI. Status and Prospects. IFIP TC11 WG11.3 Eleventh International Conference on Database Security, P356
   Wang YC, 2018, TECHNOL FORECAST SOC, V126, P3, DOI 10.1016/j.techfore.2015.12.019
   Watson HJ, 2014, COMMUN ASSOC INF SYS, V34, P1247
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang TMY, 2018, Arxiv, DOI [arXiv:1812.02903, DOI 10.48550/ARXIV.1812.02903]
   Zhang YL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P19, DOI [10.1109/SP.2017.12, 10.1145/3132747.3132768]
   Zhang YC, 2015, PR MACH LEARN RES, V37, P362
NR 49
TC 2
Z9 2
U1 0
U2 8
PD DEC
PY 2020
VL 4
IS 12
AR e17265
DI 10.2196/17265
UT WOS:000853427500009
DA 2023-11-16
ER

PT C
AU Sailer, J
   Frey, C
   Kühnert, C
AF Sailer, Johannes
   Frey, Christian
   Kuehnert, Christian
BE Beyerer, J
   Kuhnert, C
   Niggemann, O
TI GPU GEMM-Kernel Autotuning for scalable machine learners
SO MACHINE LEARNING FOR CYBER PHYSICAL SYSTEMS, ML4CPS 2018
SE Technologien fur die intelligente Automation
DT Proceedings Paper
CT 4th Conference on Machine Learning for Cyber-Physical-Systems and
   Industry 4.0 (ML4CPS)
CY OCT 23-24, 2018
CL Fraunhofer IOSB, Karlsruhe, GERMANY
HO Fraunhofer IOSB
DE GPU; Matrix Multiplication; Autotuning; automatic gerneration;
   acceleration; CUDA; BLAS
AB Deep learning (DL) is one of the key technologies in the artificial intelligence (AI) domain Deep learning neural networks (DLNN) profit a lot from the overall exponential data growth while on the other hand the computational effort for training and inference strongly increase. Most of the computational time in DLNN is consumed by the convolution step, which is based on a general matrix multiplication (GEMM). In order to accelerate the computational time for DLNN different highly optimized GEMM implementations for Graphic Processing Units (GPUs) have been presented in the last years [1] most of these approaches are GPU hardware specific implementations of the GEMM software kernel and do not incorporate the performance dependency of the training data layout. In order to achieve a maximum performance the parameters of the GEMM algorithm have to be tuned for the different GPU hardware and specific data layout of the training task. In this paper we present a two step autotuning approach for GPU based GEMM algorithms. In the first step the kernel parameter search space is pruned by several performance criteria and afterwards further processed by a modified Simulated Annealing in order to find the best kernel parameter combinations with respect to the GPU hardware and the task specific data layout. Our results were carried out on 160 different input problems with the proposed approach an average speedup against the state of the art implementation from NVIDIA (cuBLAS) from around 12 on a NVIDIA GTX 1080 Ti accelerator card can be achieved.
C1 [Sailer, Johannes; Frey, Christian; Kuehnert, Christian] Fraunhofer Inst Optron Syst Technol & Image Explo, Karlsruhe, Germany.
RP Sailer, J (corresponding author), Fraunhofer Inst Optron Syst Technol & Image Explo, Karlsruhe, Germany.
CR Aarts E., 1988, SIMULATED ANNEALING
   [Anonymous], 2017, PERFORMANCE PREDICTI
   [Anonymous], 2015, BRUTE FORCE K NEARES
   [Anonymous], 2013, SCRIPT BASED AUTOTUN
   [Anonymous], 2015, EXPERIENCES AUTOTUNI
   [Anonymous], 2016, PERFORMANCE DESIGN A
   [Anonymous], 2013, APPL INDEPENDENT AUT
   [Anonymous], 2009, NOTE AUTOTUNING GEMM
   [Anonymous], 2009, AUTOTUNING 3 D FFT L
   [Anonymous], 2017, NOVEL HPC TECHNIQUES
   [Anonymous], FAST K NEAREST NEIGH
   [Anonymous], 2011, AUTOTUNING GEMMS FER
   [Anonymous], 2001, AUTOMATED EMPIRICAL
   [Anonymous], 2008, BENCHMARKING GPUS TU
   [Anonymous], 2010, MODEL DRIVEN AUTOTUN
   Baskaran M. M., 2010, AUTOMATIC C TO CUDA
   Nath R., 2010, IMPROVED MAGMA GEMM
   python Bergstra James, NIPS 2011 BIGLEARNIN
   Volkov Vasily, 2016, UNDERSTANDING LATENC
   Vuduc R., 2005, OSKI LIB AUTOMATICAL
NR 20
TC 1
Z9 1
U1 1
U2 2
PY 2019
VL 9
BP 66
EP 76
DI 10.1007/978-3-662-58485-9_8
UT WOS:000493989300008
DA 2023-11-16
ER

PT J
AU Lopez, JM
   Hirtz, T
   Dampfhoffer, M
   Grenouillee, L
   Reganaz, L
   Navarro, G
   Carabasse, C
   Vianello, E
   Magis, T
   Deleruyelle, D
   Bocquet, M
   Portal, JM
   Andrieu, F
   Molas, G
AF Lopez, J. Minguet
   Hirtz, T.
   Dampfhoffer, M.
   Grenouillee, L.
   Reganaz, L.
   Navarro, G.
   Carabasse, C.
   Vianello, E.
   Magis, T.
   Deleruyelle, D.
   Bocquet, M.
   Portal, J. M.
   Andrieu, F.
   Molas, G.
TI OxRAM plus OTS optimization for binarized neural network hardware
   implementation
SO SEMICONDUCTOR SCIENCE AND TECHNOLOGY
DT Article
DE BNN; resistive RAM; OTS; chalcogenide; crossbar
AB Low-power memristive devices embedded on graphics or central processing units logic core are a very promising non-von-Neumann approach to improve significantly the speed and power consumption of deep learning accelerators, enhancing their deployment on embedded systems. Among various non-ideal emerging neuromorphic memory devices, synaptic weight hardware implementation using resistive random-access memories (RRAMs) within 1T1R architectures promises high performance on low precision binarized neural networks (BNN). Taking advantage of the RRAM capabilities and allowing to substantially improve the density thanks to the ovonic threshold selector (OTS) selector, this work proposes to replace the standard 1T1R architecture with a denser 1S1R crossbar system, where an HfO2-based resistive oxide memory (OxRAM) is co-integrated with a Ge-Se-Sb-N-based OTS. In this context, an extensive experimental study is performed to optimize the 1S1R stack and programming conditions for extended read window margin and endurance characteristics. Focusing on the standard machine learning MNIST image recognition task, we perform offline training simulations in order to define the constraints on the devices during the training process. A very promising bit error rate of similar to 10(-3) is demonstrated together with 1S1R 10(4) error-free programming endurance characteristics, fulfilling the requirements for the application of interest. Based on this simulation and experimental study, BNN figures of merit (system footprint, number of weight updates, accuracy, inference speed, electrical consumption per image classification and tolerance to errors) are optimized by engineering the number of learnable parameters of the system. Altogether, an inherent BNN resilience to 1S1R parasitic bit errors is demonstrated.
C1 [Lopez, J. Minguet; Hirtz, T.; Grenouillee, L.; Reganaz, L.; Navarro, G.; Carabasse, C.; Vianello, E.; Magis, T.; Andrieu, F.; Molas, G.] Univ Grenoble Alpes, LETI, CEA, F-38000 Grenoble, France.
   [Dampfhoffer, M.] Univ Grenoble Alpes, CEA, CNRS, Grenoble INP,INAC Spintec, F-38000 Grenoble, France.
   [Bocquet, M.; Portal, J. M.] Aix Marseille Univ, Univ Toulon, CNRS, IM2NP, F-13009 Marseille, France.
   [Deleruyelle, D.] INL CNRS, INSA Lyon, F-69621 Villeurbanne, France.
RP Lopez, JM; Molas, G (corresponding author), Univ Grenoble Alpes, LETI, CEA, F-38000 Grenoble, France.
EM joel.minguetlopez@cea.fr; gabriel.molas@cea.fr
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Bocquet M, 2018, INT EL DEVICES MEET
   Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Chou, 2020, IEEE S VLSI CIRCUITS, V1, P1
   Garbin D, 2015, IEEE T ELECTRON DEV, V62, P2494, DOI 10.1109/TED.2015.2440102
   Grenouillet L., 2021, P IMW
   Helwegen K., 2019, ADV NEURAL INFORM PR, P7531
   Hirtzlin T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01383
   Hubara Itay, 2016, P 30 INT C NEUR INF
   Ielmini D, 2020, NANOTECHNOLOGY, V31, DOI 10.1088/1361-6528/ab554b
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lopez JM, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405195
   Villanueva JAL, 2020, CON DES CIRC INTEGR, DOI 10.1109/dcis51330.2020.9268676
   Martí D, 2016, NEURAL COMPUT, V28, P2011, DOI 10.1162/NECO_a_00882
   Molas, P IMW2020, V1, P1
   Nail C, 2016, INT EL DEVICES MEET
   Pedram A, 2017, IEEE DES TEST, V34, P39, DOI 10.1109/MDAT.2016.2573586
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Regev A, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P145, DOI [10.1109/AICAS48895.2020.9073840, 10.1109/aicas48895.2020.9073840]
   ROBAYO DA, 2019, IEDM2019 TECH DIG 35
   Sassine G, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800658
   Sheng X, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800876
   Truong SN, 2020, IEEE ACCESS, V8, P69327, DOI 10.1109/ACCESS.2020.2986513
   Strukov D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12521-x
   Sze V., 2019, NEURIPS
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Valentian A, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993431
   Verdy A, 2018, INT EL DEVICES MEET
   Yu S., 2015, IEDM2015 TECH DIG
NR 32
TC 4
Z9 4
U1 2
U2 15
PD JAN
PY 2022
VL 37
IS 1
AR 014001
DI 10.1088/1361-6641/ac31e2
UT WOS:000728366900001
DA 2023-11-16
ER

PT C
AU Abdelfattah, A
   Tomov, S
   Dongarra, J
AF Abdelfattah, Ahmad
   Tomov, Stanimire
   Dongarra, Jack
GP IEEE
TI Towards Half-Precision Computation for Complex Matrices: A Case Study
   for Mixed-Precision Solvers on GPUs
SO PROCEEDINGS OF SCALA 2019: 2019 IEEE/ACM 10TH WORKSHOP ON LATEST
   ADVANCES IN SCALABLE ALGORITHMS FOR LARGE-SCALE SYSTEMS (SCALA)
DT Proceedings Paper
CT 10th IEEE/ACM Workshop on Latest Advances in Scalable Algorithms for
   Large-Scale Systems (ScalA)
CY NOV 18, 2019
CL Denver, CO
DE Half precision; Tensor cores FP16 arithmetic; mixed-precision solvers
ID GMRES
AB The use of low-precision computations is popular in accelerating machine learning and artificial intelligence (AI) applications. Hardware architectures, such as high-end graphics processing units (GPUs), now support native 16-bit floating-point arithmetic (i.e., half-precision). While half precision provides a natural 2x/4x speedup against the performance of single/double precisions, respectively, modern GPUs are equipped with hardware accelerators that further boost the FP16 performance. These accelerators, known as tensor cores (TCs), have a theoretical peak performance that is 8x/16x faster than FP32/FP64 performance, respectively. Such a high level of performance has encouraged researchers to harness the compute power of TCs outside AI applications.
   This paper presents a mixed-precision dense linear solver (Ax = b) for complex matrices using the GPU's TC units. Unlike similar efforts that have discussed accelerating Ax = b in real FP16 arithmetic, this paper focuses on complex FP16 precisions. The developed solution uses a "half-complex" precision to accelerate the solution of Ax = b while maintaining complex FP32 precision accuracy. The proposed solver requires the development of a high-performance mixed-precision matrix multiplication (CGEMM-FP16) that accepts half-complex inputs, and uses the TCs' full-precision products and FP32 accumulations for the computation. We discuss two designs and their performance. Similar to the way fast GEMMs power the performance of LAPACK, the mixed-precision CGEMM-FP16 can enable the development of mixed-precision LAPACK algorithms. We illustrate this by integrating both CGEMM-FP16s into the development of mixed-precision LU factorizations of complex matrices. Finally, an iterative refinement solver is used to deliver complex FP32 accuracy using a preconditioned GMRES solver. Our experiments, conducted on V100 GPUs, show that the mixed-precision solver can be up to 2.5x faster than a full single-complex precision solver.
C1 [Abdelfattah, Ahmad; Tomov, Stanimire; Dongarra, Jack] Univ Tennessee, Innovat Comp Lab, Knoxville, TN 37996 USA.
RP Abdelfattah, A (corresponding author), Univ Tennessee, Innovat Comp Lab, Knoxville, TN 37996 USA.
EM ahmad@icl.utk.edu; tomov@icl.utk.edu; dongarra@icl.utk.edu
CR Abdelfattah A, 2019, INT PARALL DISTRIB P, P111, DOI 10.1109/IPDPS.2019.00022
   Abdelfattah A, 2018, IEEE T PARALL DISTR, V29, P2700, DOI 10.1109/TPDS.2018.2842785
   Agullo E, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012037
   [Anonymous], 2006, SC 06 P 2006 ACM IEE
   [Anonymous], 2015, FULL WALK SGEMM IMPL
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-41321-1_2
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2018, P INT C HIGH PERF CO, DOI DOI 10.1109/SC.2018.00050
   Baboulin M, 2009, COMPUT PHYS COMMUN, V180, P2526, DOI 10.1016/j.cpc.2008.11.005
   Carson E, 2018, SIAM J SCI COMPUT, V40, pA817, DOI 10.1137/17M1140819
   Carson E, 2017, SIAM J SCI COMPUT, V39, pA2834, DOI 10.1137/17M1122918
   Higham NJ, 2019, SIAM J SCI COMPUT, V41, pA2536, DOI 10.1137/18M1229511
   IEEE standard for floating-point arithmetic, 2019, IEEE STANDARD FLOATI, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2019.8766229]
   Lai JJ, 2013, INT SYM CODE GENER, P89
   Nath R, 2010, INT J HIGH PERFORM C, V24, P511, DOI 10.1177/1094342010385729
   SAAD Y, 1986, SIAM J SCI STAT COMP, V7, P856, DOI 10.1137/0907058
   SAAD Y, 1993, SIAM J SCI COMPUT, V14, P461, DOI 10.1137/0914028
   Simoncini V, 2003, SIAM J NUMER ANAL, V40, P2219
NR 18
TC 8
Z9 8
U1 1
U2 2
PY 2019
BP 17
EP 24
DI 10.1109/ScalA49573.2019.00008
UT WOS:000527739200003
DA 2023-11-16
ER

PT J
AU Chen, ZJ
   Sludds, A
   Davis, R
   Christen, I
   Bernstein, L
   Ateshian, L
   Heuser, T
   Heermeier, N
   Lott, JA
   Reitzenstein, S
   Hamerly, R
   Englund, D
AF Chen, Zaijun
   Sludds, Alexander
   Davis III, Ronald
   Christen, Ian
   Bernstein, Liane
   Ateshian, Lamia
   Heuser, Tobias
   Heermeier, Niels
   Lott, James A.
   Reitzenstein, Stephan
   Hamerly, Ryan
   Englund, Dirk
TI Deep learning with coherent VCSEL neural networks
SO NATURE PHOTONICS
DT Article
ID ACCELERATOR; PHOTONICS; INFERENCE
AB Energy consumption and compute density are challenges for computing systems. Here researchers show an optical computing architecture using micrometre-scale VCSEL transmitter arrays enabling 7 fJ energy per operation and a potential compute density of 6 tera-operations mm(-2) s(-1).
   Deep neural networks (DNNs) are reshaping the field of information processing. With the exponential growth of these DNNs challenging existing computing hardware, optical neural networks (ONNs) have recently emerged to process DNN tasks with high clock rates, parallelism and low-loss data transmission. However, existing challenges for ONNs are high energy consumption due to their low electro-optic conversion efficiency, low compute density due to large device footprints and channel crosstalk, and long latency due to the lack of inline nonlinearity. Here we experimentally demonstrate a spatial-temporal-multiplexed ONN system that simultaneously overcomes all these challenges. We exploit neuron encoding with volume-manufactured micrometre-scale vertical-cavity surface-emitting laser (VCSEL) arrays that exhibit efficient electro-optic conversion (V-& pi; = 4 mV) and compact footprint (<0.01 mm(2) per device). Homodyne photoelectric multiplication allows matrix operations at the quantum-noise limit and detection-based optical nonlinearity with instantaneous response. With three-dimensional neural connectivity, our system can reach an energy efficiency of 7 femtojoules per operation (OP) with a compute density of 6 teraOP mm(-)(2) s(-1), representing 100-fold and 20-fold improvements, respectively, over state-of-the-art digital processors. Near-term development could improve these metrics by two more orders of magnitude. Our optoelectronic processor opens new avenues to accelerate machine learning tasks from data centres to decentralized devices.
C1 [Chen, Zaijun; Sludds, Alexander; Davis III, Ronald; Christen, Ian; Bernstein, Liane; Ateshian, Lamia; Hamerly, Ryan; Englund, Dirk] MIT, Res Lab Elect, Cambridge, MA 02139 USA.
   [Chen, Zaijun] Univ Southern Calif, Ming Hsieh Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Heuser, Tobias; Heermeier, Niels; Lott, James A.; Reitzenstein, Stephan] Tech Univ Berlin, Fak Inst Festkorperphys 2, Berlin, Germany.
   [Hamerly, Ryan] NTT Res Inc, PHI Labs, Sunnyvale, CA 94085 USA.
RP Chen, ZJ; Hamerly, R; Englund, D (corresponding author), MIT, Res Lab Elect, Cambridge, MA 02139 USA.; Chen, ZJ (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.; Hamerly, R (corresponding author), NTT Res Inc, PHI Labs, Sunnyvale, CA 94085 USA.
EM zaijunch@usc.edu; rhamerly@mit.edu; englund@mit.edu
CR [Anonymous], 2022, US VCSELS 3D SENS AP
   Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Atabaki AH, 2018, NATURE, V556, P349, DOI 10.1038/s41586-018-0028-z
   Bhooplapur S, 2011, OPT LETT, V36, P1887, DOI 10.1364/OL.36.001887
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Hadibrata W, 2021, NANO LETT, V21, P2422, DOI 10.1021/acs.nanolett.0c04463
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Heidari E, 2020, NANOPHOTONICS-BERLIN, V9, P4743, DOI 10.1515/nanoph-2020-0437
   Heuser T, 2020, J PHYS-PHOTONICS, V2, DOI 10.1088/2515-7647/aba671
   Hoghooghi N, 2010, OPT LETT, V35, P1218, DOI 10.1364/OL.35.001218
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I, 2018, J MACH LEARN RES, V18
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Jager R, 1997, ELECTRON LETT, V33, P330, DOI 10.1049/el:19970193
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim I, 2021, NAT NANOTECHNOL, V16, P508, DOI 10.1038/s41565-021-00895-3
   Koyama F, 2006, J LIGHTWAVE TECHNOL, V24, P4502, DOI 10.1109/JLT.2006.886064
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumari S, 2018, LASER PHOTONICS REV, V12, DOI 10.1002/lpor.201700206
   Li GHY, 2023, NANOPHOTONICS-BERLIN, V12, P847, DOI 10.1515/nanoph-2022-0137
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Liu AJ, 2019, PHOTONICS RES, V7, P121, DOI 10.1364/PRJ.7.000121
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Mishkin D., 2016, INT C LEARNING REPRE
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Noé F, 2020, ANNU REV PHYS CHEM, V71, P361, DOI 10.1146/annurev-physchem-042018-052331
   Ossiander M, 2018, NATURE, V561, P374, DOI 10.1038/s41586-018-0503-6
   Paszke A, 2019, ADV NEUR IN, V32
   Rowland J, 2021, OPT LETT, V46, P412, DOI 10.1364/OL.416166
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sludds Alexander, 2022, Science, V378, P270, DOI 10.1126/science.abq8271
   Sun C, 2015, NATURE, V528, P534, DOI 10.1038/nature16454
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   Wang C, 2018, NATURE, V562, P101, DOI 10.1038/s41586-018-0551-y
   Wang TY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-021-27774-8
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yang YS, 2017, OPT EXPRESS, V25, P5758, DOI 10.1364/OE.25.005758
   Yeap G, 2019, INT EL DEVICES MEET, DOI 10.1109/IEDM19573.2019.8993577
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou TK, 2021, NAT PHOTONICS, V15, P367, DOI 10.1038/s41566-021-00796-w
   Zuo Y, 2019, OPTICA, V6, P1132, DOI 10.1364/OPTICA.6.001132
NR 55
TC 0
Z9 0
U1 25
U2 25
PD AUG
PY 2023
VL 17
IS 8
BP 723
EP +
DI 10.1038/s41566-023-01233-w
EA JUL 2023
UT WOS:001031418200002
DA 2023-11-16
ER

PT C
AU Ahn, J
   Hong, S
   Yoo, S
   Mutlu, O
   Choi, K
AF Ahn, Junwhan
   Hong, Sungpack
   Yoo, Sungjoo
   Mutlu, Onur
   Choi, Kiyoung
GP IEEE
TI A Scalable Processing-in-Memory Accelerator for Parallel Graph
   Processing
SO 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
DT Proceedings Paper
CT ACM/IEEE 42nd Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 13-17, 2015
CL Portland, OR
AB The explosion of digital data and the ever-growing need for fast data analysis have made in-memory big-data processing in computer systems increasingly important. In particular, large-scale graph processing is gaining attention due to its broad applicability from social science to machine learning. However, scalable hardware design that can efficiently process large graphs in main memory is still an open problem. Ideally, cost-effective and scalable graph processing systems can be realized by building a system whose performance increases proportionally with the sizes of graphs that can be stored in the system, which is extremely challenging in conventional systems due to severe memory bandwidth limitations.
   In this work, we argue that the conventional concept of processing-in-memory (PIM) can be a viable solution to achieve such an objective. The key modern enabler for PIM is the recent advancement of the 3D integration technology that facilitates stacking logic and memory dies in a single package, which was not available when the PIM concept was originally examined. In order to take advantage of such a new technology to enable memory-capacity-proportional performance, we design a programmable PIM accelerator for large-scale graph processing called Tesseract. Tesseract is composed of (1) a new hardware architecture that fully utilizes the available memory bandwidth, (2) an efficient method of communication between different memory partitions, and (3) a programming interface that reflects and exploits the unique hardware design. It also includes two hardware prefetchers specialized for memory access patterns of graph processing, which operate based on the hints provided by our programming model. Our comprehensive evaluations using five state-of-the-art graph processing workloads with large real-world graphs show that the proposed architecture improves average system performance by a factor of ten and achieves 87% average energy reduction over conventional systems.
C1 [Ahn, Junwhan; Yoo, Sungjoo; Choi, Kiyoung] Seoul Natl Univ, Seoul 151, South Korea.
   [Hong, Sungpack] Oracle Labs, Palo Alto, CA USA.
   [Mutlu, Onur] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
RP Ahn, J (corresponding author), Seoul Natl Univ, Seoul 151, South Korea.
EM junwhan@snu.ac.kr; sungpack.hong@oracle.com; sungjoo.yoo@gmail.com;
   onur@cmu.edu; kchoi@snu.ac.kr
CR [Anonymous], 2013, TECH REP
   [Anonymous], P WWW
   [Anonymous], P ASPLOS
   [Anonymous], 2006, P ASPLOS
   [Anonymous], P ISCA
   [Anonymous], 2014, P HPDC
   [Anonymous], 2013, P ISCA
   [Anonymous], 2013, P SSDBM
   [Anonymous], 2006, 2GB X4 X8 X16 DDR3 S
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Basu A., 2013, P ISCA
   Basu A., 2014, IEEE MICRO, V34, P36
   BIRRELL AD, 1984, ACM T COMPUT SYST, V2, P39, DOI 10.1145/2080.357392
   CHEN TF, 1995, IEEE T COMPUT, V44, P609, DOI 10.1109/12.381947
   Chung E. S., 2013, P ISCA
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Eckert Y., 2014, WONDP
   GOKHALE M, 1995, IEEE COMPUT, V28, P23
   Gonzalez JE, 2012, 10 USENIX S OP SYST
   Gutierrez A., 2014, P ASPLOS
   Hall M., 1999, P SC
   Harish P., 2007, P HIPC
   Harshvardhan, 2014, P PACT
   Hong S., 2011, P PPOPP
   Hong S., 2012, P ASPLOS
   Hong S., 2011, P PACT
   Hong S., 2014, P CGO
   Hughes CJ, 2005, J PARALLEL DISTR COM, V65, P448, DOI 10.1016/j.jpdc.2004.11.004
   Hybrid Memory Cube Consortium, 2014, TECH REP
   Jeddeloh J., 2012, P VLSIT
   JOUPPI N, 1990, P ISCA
   Kang Y., 1999, P ICCD
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kim G., 2013, P PACT
   Kocberber O., 2013, P ICPP
   Kocberber Onur, 2013, P MICRO
   Lim K., 2013, P ISCA
   Loh G., 2008, P ISCA
   Loh G. H., 2013, WONDP
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Luk Chi-Keung, 2005, P PLDI
   Malewicz G., 2010, P SIGMOD
   Merrill D. G., 2012, P PPOPP
   MISLOVE A, 2007, P IMC
   Mutlu O., 2003, P HPCA
   Oskin M., 1998, P ISCA
   Ousterhout J., 2010, ACM SIGOPS OPERAT SY, V43, P92, DOI DOI 10.1145/1713254.1713276
   Patterson D., 1997, ISSCC
   Pugsley Seth H., 2014, P ISPASS
   Qadeer W., 2013, P ISCA
   Ranganathan P, 2011, COMPUTER, V44, P39, DOI 10.1109/MC.2011.18
   Seshadri V., 2013, P MICRO
   Shevgoor M., 2013, P MICRO
   Solihin Y., 2002, P ISCA
   Srinath S., 2007, P HPCA
   Suleman M. A., 2009, P ASPLOS
   Tian Y, 2013, PROC VLDB ENDOW, V7, P193, DOI 10.14778/2732232.2732238
   Wu L., 2013, P ICS
   Zhang D. P., 2014, P 3DIC
   Zhu Q., 2013, P HPEC
NR 60
TC 260
Z9 269
U1 2
U2 15
PY 2015
BP 105
EP 117
DI 10.1145/2749469.2750386
UT WOS:000380455700009
DA 2023-11-16
ER

PT C
AU Huang, Y
   Chen, ZY
   Li, D
   Yang, KY
AF Huang, Yi
   Chen, Zhiyu
   Li, Dai
   Yang, Kaiyuan
GP IEEE Comp Soc
TI CAMA: Energy and Memory Efficient Automata Processing in
   Content-Addressable Memories
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
AB Accelerating finite automata processing is critical for advancing real-time analytic in pattern matching, data mining, bioinformatics, intrusion detection, and machine learning. Recent in-memory automata accelerators leveraging SRAMs and DRAMs have shown exciting improvements over conventional digital designs. However, the bit-vector representation of state transitions used by all state-of-the-art (SOTA) designs is only optimal in processing worst-case completely random patterns, while a significant amount of memory and energy is wasted in running most real-world benchmarks.
   We present CAMA, a Content-Addressable Memory (CAM) enabled Automata accelerator for processing homogeneous non-deterministic finite automata (NFA). A radically different state representation scheme, along with co-designed novel circuits and data encoding schemes, greatly reduces energy, memory, and chip area for most realistic NFAs. CAMA is holistically optimized with the following major contributions: (1) a 16x256 8-transistor (8T) CAM array for state matching, replacing the 256x256 6T SRAM array or two 16x256 6T SRAM banks in state-of-the-art (SOTA) designs; (2) a novel encoding scheme that enables content searching within 8T SRAMs and adapts to different applications; (3) a reconfigurable and scalable architecture that improves efficiency on all tested benchmarks, without losing support for any NFA that's compatible with SOTA designs; (4) an optimization framework that automates the choice of encoding schemes and maps a given NFA to the proposed hardware. Two versions of CAMA, one optimized for energy (CAMA-E) and the other for throughput (CAMA-T), are comprehensively evaluated in a 28nm CMOS process, and across 21 real-world and synthetic benchmarks. CAMA-E achieves 2.1x, 2.8x, and 2.04x lower energy than CA, 2-stride Impala, and eAP. CAMA-T shows 2.68x, 3.87x and 2.62x higher average compute density than 2-stride Impala, CA, and eAP. Both versions reduce the chip area required for the largest tested benchmark by 2.48x over CA, 1.91x over 2-stride Impala, and 1.78x over eAP.
C1 [Huang, Yi; Chen, Zhiyu; Li, Dai; Yang, Kaiyuan] Rice Univ, Dept Elect & Comp Engn, POB 1892, Houston, TX 77251 USA.
RP Huang, Y (corresponding author), Rice Univ, Dept Elect & Comp Engn, POB 1892, Houston, TX 77251 USA.
EM yihuang@ustc.edu; zc37@rice.edu; d137@rice.edu; kyang@rice.edu
CR AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855
   Alicherry M, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P183
   Alur R, 2001, ACM T PROGR LANG SYS, V23, P273, DOI 10.1145/503502.503503
   Becchi M, 2007, P 3 ACM IEEE S ARCH
   Becchi M., 2008, PROC 4 ACMIEEE S ARC, P50, DOI 10.1145/1477942.1477950
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Bo C, 2018, INT S HIGH PERF COMP, P737, DOI 10.1109/HPCA.2018.00068
   Bo CK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P311, DOI 10.1109/BigData.2016.7840617
   Bremler-Barr A, 2014, IEEE ACM T NETWORK, V22, P415, DOI 10.1109/TNET.2013.2253119
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang Yu, 2006, ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS 2006), P93, DOI 10.1109/ANCS.2006.4579527
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Glushkov V. M, ABSTRACT THEORY AUTO, V16, P1, DOI [10.1070/rm1961v016n05abeh004112, DOI 10.1070/RM1961V016N05ABEH004112]
   Gogte V, 2016, INT SYMP MICROARCH
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Kunyang Peng, 2011, 2011 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS), P24, DOI 10.1109/ANCS.2011.13
   Lenjani M, 2014, IET COMPUT DIGIT TEC, V8, P30, DOI 10.1049/iet-cdt.2011.0066
   Li D, 2020, IEEE SOLID-ST CIRC L, V3, P358, DOI 10.1109/LSSC.2020.3022006
   Liu TW, 2011, IEEE INFOCOM SER, P2129, DOI 10.1109/INFCOM.2011.5935024
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Pao D, 2011, IEEE T COMPUT, V60, P1596, DOI 10.1109/TC.2010.250
   Rahimi R, 2020, ANN IEEE SYM FIELD P, P138, DOI 10.1109/FCCM48280.2020.00027
   Roy I, 2016, IEEE ACM T COMPUT BI, V13, P99, DOI 10.1109/TCBB.2015.2430313
   Sadredini E., 2017, P INT C SUPERCOMPUTI, DOI [10.1145/3079079.3079084, DOI 10.1145/3079079.3079084]
   Sadredini E, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P219, DOI 10.1145/3373376.3378459
   Sadredini E, 2020, INT S HIGH PERF COMP, P86, DOI 10.1109/HPCA47549.2020.00017
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Tandon P, 2016, PROC INT CONF DATA, P469, DOI 10.1109/ICDE.2016.7498263
   Hieu TT, 2013, INT CONF UBIQ FUTUR, P252, DOI 10.1109/ICUFN.2013.6614821
   van Lunteren J, 2012, INT SYMP MICROARCH, P461, DOI 10.1109/MICRO.2012.49
   Wadden J, 2018, I S WORKL CHAR PROC, P13, DOI 10.1109/IISWC.2018.8573482
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wadden J, 2016, I S WORKL CHAR PROC, P105, DOI 10.1109/IISWC.2016.7581271
   Wang K, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P135, DOI 10.1145/2903150.2903172
   Wang K, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2976763
   Xie T, 2017, I C FIELD PROG LOGIC
   Yabuuchi M, 2018, SYMP VLSI CIRCUITS, P19, DOI 10.1109/VLSIC.2018.8502345
   Yun S, 2012, IEEE T COMPUT, V61, P213, DOI 10.1109/TC.2010.273
NR 40
TC 3
Z9 3
U1 0
U2 1
PY 2022
BP 25
EP 37
DI 10.1109/HPCA53966.2022.00011
UT WOS:000838704300003
DA 2023-11-16
ER

PT C
AU Rotaru, MD
   Tang, W
   Rahul, D
   Zhang, ZY
AF Rotaru, Mihai D.
   Tang, Wei
   Rahul, Dutta
   Zhang, Zhengya
GP IEEE Comp Soc
TI Design and Development of High Density Fan-Out Wafer Level Package
   (HD-FOWLP) for Deep Neural Network (DNN) Chiplet Accelerators using
   Advanced Interface Bus (AIB)
SO IEEE 71ST ELECTRONIC COMPONENTS AND TECHNOLOGY CONFERENCE (ECTC 2021)
SE Electronic Components and Technology Conference
DT Proceedings Paper
CT IEEE 71st Electronic Components and Technology Conference (ECTC)
CY JUN 01-JUL 04, 2021
CL ELECTR NETWORK
DE High Density Fan-out Wafer Level Package; chiplet; heterogeneous
   integration; signal and power integrity
AB Emerging applications such as machine learning (ML) and artificial intelligence (AI) require more computing capabilities that ought to be distributed and have access to large memory and storage, while the systems need to be energy efficient and low-cost. The increase in cost of advanced nodes and the difficulties of shrinking analog circuits such as input and output (I/O) to address the computation and communication needs of ML/AI applications have created the opportunity to bring into the mainstream chiplet-based systems. The chiplet based systems enable modularity, scalability and technology partitioning providing a cost and energy efficient solution. The chiplet integration has been enabled by the development of a raft of advanced packaging technologies such as silicon interposer, EMIB, COWoS, high density fan-out wafer level packaging (HDFOWLP) to name a few. In this work the design, development and electrical characterization of a four-chiplet system integrated using in 2.5D HD-FOWLP platform is discussed. The chiplet accelerators are fabricated in 22 nm CMOS technology, while the package uses a five metal layer HD-FOWLP with dielectric polymer and 2 um width and space as minimum design rules. The Advanced Bus Interface (AIB) die-to-die PHY-level standard is used to interconnect the four chiplets in a ring topology. The AIB bus requires 192 lines between each two chiplets, and a total of 768 2umx2um lines are routed on the top three layers of the HDFOLWP. The bottom two metal layers of the package are used to distribute the ground and power necessary for all four chiplets. Each chiplet requires seven distinct voltage islands that are separately routed on the bottom metal layer.
C1 [Rotaru, Mihai D.; Rahul, Dutta] ASTAR, Inst Microelect, Singapore, Singapore.
   [Tang, Wei; Zhang, Zhengya] Univ Michigan, EECS Dept, Ann Arbor, MI USA.
RP Rotaru, MD (corresponding author), ASTAR, Inst Microelect, Singapore, Singapore.
EM mihaidr@ime.a-star.edu.sg; weitang@umich.edu; duttar@ime.a-star.edu.sg;
   zhengya@umich.edu
CR [Anonymous], ADS USER MANUAL
   Beck N, 2018, ISSCC DIG TECH PAP I, P40, DOI 10.1109/ISSCC.2018.8310173
   Chen M.-F., 2019, P IEEE 69 EL COMP TE, P1
   Coughlin T., 2020, IEEE CONSUM ELECTR M, V9
   Coughlin T, 2019, IEEE CONSUM ELECTR M, V8, P97, DOI 10.1109/MCE.2018.2880855
   DARPA Microsystems Technology Office, 2016, BROAD AG ANN COMM HE
   Hancock T. M., 2019, 2019 INT 3D SYST INT
   Lin M.-S., 2019, P S VLSI CIRC JUN, P28
   Pantano N, 2016, 2016 6TH ELECTRONIC SYSTEM-INTEGRATION TECHNOLOGY CONFERENCE (ESTC)
   Rotaru MD, 2020, EL PACKAG TECH CONF, P430, DOI 10.1109/EPTC50525.2020.9315178
   Vivet P, 2021, IEEE J SOLID-ST CIRC, V56, P79, DOI 10.1109/JSSC.2020.3036341
   Wade M, 2020, IEEE MICRO, V40, P63, DOI 10.1109/MM.2020.2976067
NR 12
TC 7
Z9 6
U1 2
U2 13
PY 2021
BP 1258
EP 1263
DI 10.1109/ECTC32696.2021.00204
UT WOS:000702282700192
DA 2023-11-16
ER

PT C
AU Walter, I
   Ney, J
   Hotfilter, T
   Rybalkin, V
   Hoefer, J
   Wehn, N
   Becker, J
AF Walter, Iris
   Ney, Jonas
   Hotfilter, Tim
   Rybalkin, Vladimir
   Hoefer, Julian
   Wehn, Norbert
   Becker, Juergen
BE Kamp, M
   Koprinska, I
   Bibal, A
   Bouadi, T
   Frenay, B
   Galarraga, L
   Oramas, J
   Adilova, L
TI Embedded Face Recognition for Personalized Services in the Assistive
   Robotics
SO MACHINE LEARNING AND PRINCIPLES AND PRACTICE OF KNOWLEDGE DISCOVERY IN
   DATABASES, ECML PKDD 2021, PT I
SE Communications in Computer and Information Science
DT Proceedings Paper
CT 21st Joint European Conference on Machine Learning and Principles and
   Practice of Knowledge Discovery in Databases (ECML PKDD)
CY SEP 13-17, 2021
CL ELECTR NETWORK
DE Ambient assisted living; Assistive robotics; Convolutional neural
   networks; Face recognition; Field programmable gate array; Quantization
AB Recently, the field of assistive robotics has drawn much attention in the health care sector. In combination with modern machine learning-supported person recognition systems, they can deliver highly personalized services. However, common algorithms for person recognition such as convolutional neural networks (CNNs) consume high amounts of power and show low energy efficiency when executed on general-purpose computing platforms.
   In this paper, we present our hardware architecture and field programmable gate array (FPGA) accelerator to enable on-device person recognition in the context of assistive robotics. Therefore, we optimize a neural network based on the SqueezeNet topology and implement it on an FPGA for a high degree of flexibility and reconfigurability. By pruning redundant filters and quantization of weights and activations, we are able to find a well-fitting neural network that achieves a high identification accuracy of 84%. On a Xilinx Zynq Ultra96v2, we achieve a power consumption of 4.8 W, a latency of 31 ms and an efficiency of 6.738 FPS/W. Our results outperform the latency by 1.6x compared to recent person recognition systems in assistive robots and energy efficiency by 1.7x for embedded face recognition, respectively.
C1 [Walter, Iris; Hotfilter, Tim; Hoefer, Julian; Becker, Juergen] Karlsruhe Inst Technol, Karlsruhe, Germany.
   [Ney, Jonas; Rybalkin, Vladimir; Wehn, Norbert] Tech Univ Kaiserslautern, Kaiserslautern, Germany.
RP Walter, I (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM iris.walter@kit.edu; ney@eit.uni-kl.de; hotfilter@kit.edu;
   rybalkin@eit.uni-kl.de; julian.hoefer@kit.edu; wehn@eit.uni-kl.de;
   becker@kit.edu
CR [Anonymous], 2014, ARXIV14117923
   Asfour T, 2019, IEEE ROBOT AUTOM MAG, V26, P108, DOI 10.1109/MRA.2019.2941246
   Baehr S., 2019, LOW LATENCY NEURAL N
   Brinker TJ, 2019, EUR J CANCER, V113, P47, DOI 10.1016/j.ejca.2019.04.001
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duque-Domingo J, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00034
   Esler T., FACE RECOGNITION USI
   Ghita Stefania Alexandra, 2018, Towards Autonomous Robotic Systems. 19th Annual Conference, TAROS 2018 Proceedings: Lecture Notes in Artificial Intelligence (LNAI 10965), P271, DOI 10.1007/978-3-319-96728-8_23
   Han S., 2015, ADV NEURAL INFORM PR, P1135
   Hotfilter T., 2020, 2020 IEEE 6 WORLD FO, P1, DOI [10.1109/WF-IoT48130.2020.9221396, DOI 10.1109/WF-IOT48130.2020.9221396]
   Howard A. G., 2017, ABS170404861 CORR
   Hubara I, 2018, J MACH LEARN RES, V18
   Iandola F.N., 2016, GITHUB FORRESTI SQUE
   Iandola Forrest N., 2016, P IEEE C COMPUTER VI
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Labs X.R, FINN HLS LIB
   Liu X, 2022, IEEE T COMPUT SOC SY, V9, P252, DOI 10.1109/TCSS.2021.3059318
   Liu Y., 2017, ABS171000870 CORR
   Liu Zhuang, 2018, ARXIV181005270
   Ranjan R., 2017, ABS170309507 CORR
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Siciliano B, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1, DOI 10.1007/978-3-319-32552-1
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang M., 2018, ABS180406655 CORR
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhou HL, 2014, IEEE T HUM-MACH SYST, V44, P701, DOI 10.1109/THMS.2014.2340578
   Zhuge C., 2018, ABS180309004 CORR
NR 32
TC 6
Z9 6
U1 1
U2 2
PY 2021
VL 1524
BP 339
EP 350
DI 10.1007/978-3-030-93736-2_26
UT WOS:000773469200026
DA 2023-11-16
ER

PT J
AU Sun, Z
   Pedretti, G
   Mannocci, P
   Ambrosi, E
   Bricalli, A
   Ielmini, D
AF Sun, Zhong
   Pedretti, Giacomo
   Mannocci, Piergiulio
   Ambrosi, Elia
   Bricalli, Alessandro
   Ielmini, Daniele
TI Time Complexity of In-Memory Solution of Linear Systems
SO IEEE TRANSACTIONS ON ELECTRON DEVICES
DT Article
DE In-memory computing (IMC); linear system; resistive memory; time
   complexity
ID NEURAL NETWORKS
AB In-memory computing (IMC) with cross-point resistive memory arrays has been shown to accelerate data-centric computations, such as the training and inference of deep neural networks, due to the high parallelism endowed by physical rules in the electrical circuits. By connecting cross-point arrays with negative feedback amplifiers, it is possible to solve linear algebraic problems, such as linear systems and matrix eigenvectors in just one step. Based on the theory of feedback circuits, we study the dynamics of the solution of linear systems within a memory array, showing that the time complexity of the solution is free of any direct dependence on the problem size N, rather it is governed by theminimal eigenvalue of an associatedmatrix of the coefficient matrix. We show that when the linear system is modeled by a covariancematrix, the time complexity is O(logN) or O(1). In the case of sparse positive-definite linear systems, the time complexity is solely determined by the minimal eigenvalue of the coefficient matrix. These results demonstrate the high speed of the circuit for solving linear systems in a wide range of applications, thus supporting IMC as a strong candidate for future big data and machine learning accelerators.
C1 [Sun, Zhong; Pedretti, Giacomo; Mannocci, Piergiulio; Ambrosi, Elia; Bricalli, Alessandro; Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
RP Sun, Z; Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
EM zhong.sun@polimi.it; daniele.ielmini@polimi.it
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   [Anonymous], 2013, MATRIX COMPUTATIONS
   [Anonymous], 2015, RESISTIVE SWITCHING
   [Anonymous], 1989, DENSITY FUNCTIONAL T
   [Anonymous], 2018, IEEE INT EL DEV M IE
   [Anonymous], 2000, MATRIX ANAL APPL LIN
   Bekas C., 2009, P 2 WORKSH HIGH PERF, P1
   Bhatia R, 2007, PRINC SER APPL MATH, P1
   Bhatia R., 1997, MATRIX ANAL, V169
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Bourzac K, 2017, NATURE, V551, P554, DOI 10.1038/d41586-017-07523-y
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chang TC, 2016, MATER TODAY, V19, P254, DOI 10.1016/j.mattod.2015.11.009
   CICHOCKI A, 1992, IEEE T CIRCUITS-I, V39, P124, DOI 10.1109/81.167018
   Csanky L., 1976, SIAM Journal on Computing, V5, P618, DOI 10.1137/0205040
   Elango V, 2015, ACM SIGPLAN NOTICES, V50, P567, DOI [10.1145/2676726.2677010, 10.1145/2775051.2677010]
   Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502
   HELLER D, 1978, SIAM REV, V20, P740, DOI 10.1137/1020096
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Ielmini D, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/6/063002
   Kent AD, 2015, NAT NANOTECHNOL, V10, P187, DOI 10.1038/nnano.2015.24
   Ladd TD, 2010, NATURE, V464, P45, DOI 10.1038/nature08812
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Mehonic A, 2018, ADV MATER, V30, DOI 10.1002/adma.201801187
   Moler C, 2003, SIAM REV, V45, P3, DOI 10.1137/S00361445024180
   Park J, 2016, IEEE ELECTR DEVICE L, V37, P1559, DOI 10.1109/LED.2016.2622716
   Raoux S, 2010, CHEM REV, V110, P240, DOI 10.1021/cr900040x
   Razavi B., 2005, DESIGN ANALOG CMOS I
   Robertson J, 2004, EUR PHYS J-APPL PHYS, V28, P265, DOI 10.1051/epjap:2004206
   Rojas R, 1996, NEURAL NETWORKS, P149, DOI 10.1007/978-3-642-61068-4{\_}7
   Saad Y., 2003, ITERATIVE METHODS SP
   Seo K, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/25/254023
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/nnano.2017.83, 10.1038/NNANO.2017.83]
   Shewchuk J.R., 1994, CMUCS94125
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Tang JM, 2012, NUMER LINEAR ALGEBR, V19, P485, DOI 10.1002/nla.779
   Waldrop MM, 2016, NATURE, V530, P144, DOI 10.1038/530144a
   Waser R, 2009, ADV MATER, V21, P2632, DOI 10.1002/adma.200900375
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yu S, 2015, 2015 IEEE 5TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), P170, DOI 10.1109/ICCE-Berlin.2015.7391225
   Zheng YR, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.210504
NR 44
TC 17
Z9 19
U1 2
U2 4
PD JUL
PY 2020
VL 67
IS 7
BP 2945
EP 2951
DI 10.1109/TED.2020.2992435
UT WOS:000542842800044
DA 2023-11-16
ER

PT C
AU Kim, Y
   Venkataramani, S
   Roy, K
   Raghunathan, A
AF Kim, Younghoon
   Venkataramani, Swagath
   Roy, Kaushik
   Raghunathan, Anand
GP ACM
TI Designing Approximate Circuits using Clock Overgating
SO 2016 ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 53rd ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 05-09, 2016
CL Austin, TX
DE Approximate Computing; Clock Gating; Energy Efficiency
AB Approximate computing is an emerging paradigm to improve the efficiency of computing systems by leveraging the intrinsic resilience of applications to their computations being executed in an approximate manner. Prior efforts on approximate hardware design have largely focused on circuit-level techniques. We propose a new approach, clock overgating, for the design of approximate circuits at the Register Transfer Level (RTL). The key idea is to gate the clock signal to selected Flip-Flops (FFs) in the circuit, even during execution cycles in which the circuit functionality is sensitive to their state. This saves power in the clock tree, the FF itself and in its downstream logic, while a quality loss ensues if the erroneous FF state propagates to the circuit output. We develop a systematic methodology to identify an energy-efficient overgating configuration for any given circuit and quality constraint. Towards this end, we develop 3 key strategies - significance-based overgating, grouping FFs into overgating islands, and utilizing internal signals of the circuit as triggers for overgating - that efficiently prune the large space of possible overgating configurations. We evaluate clock overgating by designing approximate versions of 6 machine learning accelerators, and demonstrate energy benefits of 1.36x on average (and upto 1.80x) for negligible (< 0.5%) loss in application quality (classification accuracy).
C1 [Kim, Younghoon; Venkataramani, Swagath; Roy, Kaushik; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Kim, Y (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM kim1606@purdue.edu; venkata0@purdue.edu; kaushik@purdue.edu;
   raghunathan@purdue.edu
CR [Anonymous], 2014, PROC DESIGN AUTOM TE
   [Anonymous], 2011, DESIGN AUTOMATION TE
   Breuer MA, 2005, DSD 2005: 8TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN, PROCEEDINGS, P2
   Chakradhar ST, 2010, DES AUT CON, P865
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Hegde R., 1999, Proceedings. 1999 International Symposium on Low Power Electronics and Design (Cat. No.99TH8477), P30, DOI 10.1109/LPE.1999.799405
   Huang JW, 2012, DES AUT CON, P504
   Kahng AB, 2012, DES AUT CON, P820
   Krause P. K., 2011, P DATE, P1
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Li CR, 2015, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083498
   Miao J, 2012, ICCAD-IEEE ACM INT, P728
   Misailovic S, 2014, ACM SIGPLAN NOTICES, V49, P309, DOI [10.1145/2714064.2660231, 10.1145/10.1145/2660193.2660231]
   Ranjan A., 2014, P DATE, P1, DOI DOI 10.7873/DATE.2014.377
   Shin D., 2011, P DATE, P1
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Thwaites B, 2014, INT CONFER PARA, P493, DOI 10.1145/2628071.2628110
   Venkataramani S, 2012, DES AUT CON, P796
   Yazdanbakhsh A, 2015, DES AUT TEST EUROPE, P812
   Zhai B, 2009, IEEE T VLSI SYST, V17, P1127, DOI 10.1109/TVLSI.2008.2007564
   Zhu N, 2009, PROCEEDINGS OF THE 2009 12TH INTERNATIONAL SYMPOSIUM ON INTEGRATED CIRCUITS (ISIC 2009), P400
NR 21
TC 5
Z9 5
U1 0
U2 1
PY 2016
DI 10.1145/2897937.2898005
UT WOS:000390302500015
DA 2023-11-16
ER

PT J
AU Chaikittisilp, W
   Yamauchi, Y
   Ariga, K
AF Chaikittisilp, Watcharop
   Yamauchi, Yusuke
   Ariga, Katsuhiko
TI Material Evolution with Nanotechnology, Nanoarchitectonics, and
   Materials Informatics: What will be the Next Paradigm Shift in
   Nanoporous Materials?
SO ADVANCED MATERIALS
DT Review
DE data science; machine learning; mesoporous materials; metal-organic
   frameworks; self-assembly; zeolites
ID METAL-ORGANIC FRAMEWORKS; TRANSMISSION ELECTRON-MICROSCOPY;
   DENSITY-FUNCTIONAL THEORY; CRYSTALLINE SPONGE METHOD; X-RAY
   SPECTROSCOPY; ZEOLITE SYNTHESIS; OXYGEN REDUCTION; CARBON-DIOXIDE;
   COMBINING EXPERIMENTS; COMPUTATION-READY
AB Materials science and chemistry have played a central and significant role in advancing society. With the shift toward sustainable living, it is anticipated that the development of functional materials will continue to be vital for sustaining life on our planet. In the recent decades, rapid progress has been made in materials science and chemistry owing to the advances in experimental, analytical, and computational methods, thereby producing several novel and useful materials. However, most problems in material development are highly complex. Here, the best strategy for the development of functional materials via the implementation of three key concepts is discussed: nanotechnology as a game changer, nanoarchitectonics as an integrator, and materials informatics as a super-accelerator. Discussions from conceptual viewpoints and example recent developments, chiefly focused on nanoporous materials, are presented. It is anticipated that coupling these three strategies together will open advanced routes for the swift design and exploratory search of functional materials truly useful for solving real-world problems. These novel strategies will result in the evolution of nanoporous functional materials.
C1 [Chaikittisilp, Watcharop; Yamauchi, Yusuke; Ariga, Katsuhiko] Natl Inst Mat Sci NIMS, JST ERATO Yamauchi Mat Space Tecton Project, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.
   [Chaikittisilp, Watcharop] Natl Inst Mat Sci NIMS, Res & Serv Div Mat Data & Integrated Syst Ma DIS, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.
   [Yamauchi, Yusuke; Ariga, Katsuhiko] Natl Inst Mat Sci NIMS, Int Ctr Mat Nanoarchitecton WPI MANA, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.
   [Yamauchi, Yusuke] Univ Queensland, Australian Inst Bioengn & Nanotechnol AIBN, Brisbane, Qld 4072, Australia.
   [Yamauchi, Yusuke] Univ Queensland, Sch Chem Engn, Brisbane, Qld 4072, Australia.
   [Ariga, Katsuhiko] Univ Tokyo, Grad Sch Frontier Sci, 5-1-5 Kashiwanoha, Kashiwa, Chiba 2778561, Japan.
RP Chaikittisilp, W; Yamauchi, Y; Ariga, K (corresponding author), Natl Inst Mat Sci NIMS, JST ERATO Yamauchi Mat Space Tecton Project, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.; Chaikittisilp, W (corresponding author), Natl Inst Mat Sci NIMS, Res & Serv Div Mat Data & Integrated Syst Ma DIS, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.; Yamauchi, Y; Ariga, K (corresponding author), Natl Inst Mat Sci NIMS, Int Ctr Mat Nanoarchitecton WPI MANA, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.; Yamauchi, Y (corresponding author), Univ Queensland, Australian Inst Bioengn & Nanotechnol AIBN, Brisbane, Qld 4072, Australia.; Yamauchi, Y (corresponding author), Univ Queensland, Sch Chem Engn, Brisbane, Qld 4072, Australia.; Ariga, K (corresponding author), Univ Tokyo, Grad Sch Frontier Sci, 5-1-5 Kashiwanoha, Kashiwa, Chiba 2778561, Japan.
EM CHAIKITTISILP.Watcharop@nims.go.jp; y.yamauchi@uq.edu.au;
   ARIGA.Katsuhiko@nims.go.jp
CR Aarva A, 2019, CHEM MATER, V31, P9256, DOI 10.1021/acs.chemmater.9b02050
   Aarva A, 2019, CHEM MATER, V31, P9243, DOI 10.1021/acs.chemmater.9b02049
   Allen FH, 2002, ACTA CRYSTALLOGR B, V58, P380, DOI 10.1107/S0108768102003890
   Altintas C, 2019, J MATER CHEM A, V7, P9593, DOI 10.1039/c9ta01378d
   Amrute AP, 2021, CHEM-EUR J, V27, P6819, DOI 10.1002/chem.202004583
   Anantharaj S, 2021, NANO ENERGY, V80, DOI 10.1016/j.nanoen.2020.105514
   [Anonymous], 2017, RES FRONTS
   Aono M, 2016, ADV MATER, V28, P989, DOI 10.1002/adma.201502868
   Ariga K., 2021, CHEM WORLD-UK, V18, P5
   Ariga K, 2008, SCI TECHNOL ADV MAT, V9, DOI 10.1088/1468-6996/9/1/014109
   Ariga K, 2021, SMALL STRUCT, V2, DOI 10.1002/sstr.202100006
   Ariga K, 2021, NANOSCALE HORIZ, V6, P364, DOI 10.1039/d0nh00680g
   Ariga K, 2021, B CHEM SOC JPN, V94, P839, DOI 10.1246/bcsj.20200362
   Ariga K, 2019, SCI TECHNOL ADV MAT, V20, P51, DOI 10.1080/14686996.2018.1553108
   Ariga K, 2020, ANGEW CHEM INT EDIT, V59, P15424, DOI 10.1002/anie.202000802
   Ariga K, 2020, ADV MATER, V32, DOI 10.1002/adma.201905657
   Ariga K, 2020, CHEM-ASIAN J, V15, P718, DOI 10.1002/asia.202000106
   Ariga K, 2019, BEILSTEIN J NANOTECH, V10, P1559, DOI 10.3762/bjnano.10.153
   Ariga K, 2018, CHEM-ASIAN J, V13, P1266, DOI 10.1002/asia.201800225
   Ariga K, 2017, MATER CHEM FRONT, V1, P208, DOI 10.1039/c6qm00240d
   Ariga K, 2016, COORDIN CHEM REV, V320, P139, DOI 10.1016/j.ccr.2016.01.015
   Ariga K, 2016, POLYM J, V48, P371, DOI 10.1038/pj.2016.8
   Ariga K, 2016, ADV MATER, V28, P1251, DOI 10.1002/adma.201502545
   Ariga K, 2015, MATER HORIZ, V2, P406, DOI 10.1039/c5mh00012b
   Ariga K, 2012, NPG ASIA MATER, V4, DOI 10.1038/am.2012.30
   Ariga K, 2012, B CHEM SOC JPN, V85, P1, DOI 10.1246/bcsj.20110162
   Avizienis AV, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042772
   Aykol M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10030-5
   Aykol M, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aaq0148
   Azhar A, 2019, B CHEM SOC JPN, V92, P875, DOI 10.1246/bcsj.20180368
   Bacilla ACC, 2021, B CHEM SOC JPN, V94, P34, DOI 10.1246/bcsj.20200188
   Bairi P, 2016, ACS NANO, V10, P6631, DOI 10.1021/acsnano.6b01544
   Baskar AV, 2021, B CHEM SOC JPN, V94, P133, DOI 10.1246/bcsj.20200265
   Bastakoti BP, 2021, J HAZARD MATER, V401, DOI 10.1016/j.jhazmat.2020.123348
   Belgibayeva A, 2021, J POWER SOURCES, V484, DOI 10.1016/j.jpowsour.2020.229308
   Biener J, 2008, ADV MATER, V20, P1211, DOI 10.1002/adma.200701899
   BINNING G, 1982, PHYS REV LETT, V49, P57, DOI 10.1103/PhysRevLett.49.57
   Briggs K, 2018, NANO LETT, V18, P660, DOI 10.1021/acs.nanolett.7b03987
   Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Burner J, 2020, J PHYS CHEM C, V124, P27996, DOI 10.1021/acs.jpcc.0c06334
   Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2
   Cai XQ, 2021, IND ENG CHEM RES, V60, P639, DOI 10.1021/acs.iecr.0c05398
   Cai ZY, 2018, CHEM REV, V118, P6091, DOI 10.1021/acs.chemrev.7b00536
   Carné-Sánchez A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04834-0
   Castro Neto AH, 2009, REV MOD PHYS, V81, P109, DOI 10.1103/RevModPhys.81.109
   Chaikittisilp W., 2017, HDB SOLID STATE CHEM, P97, DOI DOI 10.1002/9783527691036.HSSCVOL4013
   Chen KK, 2021, ACS NANO, V15, P2679, DOI 10.1021/acsnano.0c07947
   Chen PC, 2020, MATTER-US, V2, P1651, DOI 10.1016/j.matt.2020.04.021
   Chiorescu I, 2003, SCIENCE, V299, P1869, DOI 10.1126/science.1081045
   Chiu YH, 2019, CATALYSTS, V9, DOI 10.3390/catal9050430
   Cho EH, 2020, J PHYS CHEM C, V124, P27580, DOI 10.1021/acs.jpcc.0c09073
   Cho HS, 2021, ANGEW CHEM INT EDIT, V60, P20504, DOI 10.1002/anie.202107897
   Cho HS, 2019, NAT CHEM, V11, P562, DOI 10.1038/s41557-019-0257-2
   Choi M, 2009, NATURE, V461, P246, DOI 10.1038/nature08288
   Chung YG, 2019, J CHEM ENG DATA, V64, P5985, DOI 10.1021/acs.jced.9b00835
   Chung YG, 2014, CHEM MATER, V26, P6185, DOI 10.1021/cm502594j
   Clayson IG, 2020, ADV MATER, V32, DOI 10.1002/adma.202002780
   Correa-Baena JP, 2018, JOULE, V2, P1410, DOI 10.1016/j.joule.2018.05.009
   Daglar H, 2021, ANGEW CHEM INT EDIT, V60, P7828, DOI 10.1002/anie.202015250
   Datta S, 2020, NATURE, V583, P400, DOI 10.1038/s41586-020-2445-z
   DAVIS ME, 1992, CHEM MATER, V4, P756, DOI 10.1021/cm00022a005
   Davis ME, 2002, NATURE, V417, P813, DOI 10.1038/nature00785
   de Pablo JJ, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0173-4
   de Pablo JJ, 2014, CURR OPIN SOLID ST M, V18, P99, DOI 10.1016/j.cossms.2014.02.003
   Dekker C, 2007, NAT NANOTECHNOL, V2, P209, DOI 10.1038/nnano.2007.27
   Deng HX, 2012, SCIENCE, V336, P1018, DOI 10.1126/science.1220131
   Du QZ, 2018, TRAC-TREND ANAL CHEM, V102, P290, DOI 10.1016/j.trac.2018.02.014
   Durá G, 2016, ANGEW CHEM INT EDIT, V55, P9173, DOI 10.1002/anie.201602226
   Dureckova H, 2019, J PHYS CHEM C, V123, P4133, DOI 10.1021/acs.jpcc.8b10644
   Epps RW, 2020, ADV MATER, V32, DOI 10.1002/adma.202001626
   Evans JD, 2017, CHEM MATER, V29, P7833, DOI 10.1021/acs.chemmater.7b02532
   Falyouna O, 2020, J COLLOID INTERF SCI, V571, P66, DOI 10.1016/j.jcis.2020.03.028
   Fan YX, 2021, ADV MATER, V33, DOI [10.1002/adma.202004243, 10.1002/adma.202003956]
   Feng XY, 2016, ACS NANO, V10, P556, DOI 10.1021/acsnano.5b05579
   Fernandez M, 2013, J PHYS CHEM C, V117, P14095, DOI 10.1021/jp404287t
   Ferreira KN, 2004, SCIENCE, V303, P1831, DOI 10.1126/science.1093087
   Feynman RP, 1960, ENG SCI, V23, P22, DOI [10.1201/9781420040623-8, DOI 10.1108/IJCST-06-2013-0067]
   Freeze JG, 2019, CHEM REV, V119, P6595, DOI 10.1021/acs.chemrev.8b00759
   Gao P, 2020, J PHYS CHEM LETT, V11, P9812, DOI 10.1021/acs.jpclett.0c02654
   Garcia R, 2014, NAT NANOTECHNOL, V9, P577, DOI [10.1038/NNANO.2014.157, 10.1038/nnano.2014.157]
   Gawande MB, 2021, SMALL, V17, DOI 10.1002/smll.202101584
   Glotov A, 2019, B CHEM SOC JPN, V92, P61, DOI 10.1246/bcsj.20180207
   Greenaway RL, 2021, ADV MATER, V33, DOI 10.1002/adma.202004831
   Gu YM, 2020, J PHYS CHEM C, V124, P9314, DOI 10.1021/acs.jpcc.0c00130
   Guo DH, 2016, SCIENCE, V351, P361, DOI 10.1126/science.aad0832
   Guo YN, 2019, ADV MATER, V31, DOI 10.1002/adma.201807134
   Harada M, 2020, J MATER CHEM A, V8, P15103, DOI 10.1039/d0ta04441e
   Harano K, 2021, B CHEM SOC JPN, V94, P463, DOI 10.1246/bcsj.20200333
   Hasegawa T, 2012, ADV MATER, V24, P252, DOI 10.1002/adma.201102597
   He TJ, 2020, CHEM MATER, V32, P7861, DOI 10.1021/acs.chemmater.0c02553
   Hecht S, 2003, ANGEW CHEM INT EDIT, V42, P24, DOI 10.1002/anie.200390045
   Hetz C, 2020, NAT REV MOL CELL BIO, V21, P421, DOI 10.1038/s41580-020-0250-z
   Hoshino M, 2016, IUCRJ, V3, P139, DOI 10.1107/S2052252515024379
   Hosono N, 2021, B CHEM SOC JPN, V94, P60, DOI 10.1246/bcsj.20200242
   Huang HH, 2019, J MEMBRANE SCI, V572, P12, DOI 10.1016/j.memsci.2018.10.085
   Huff T, 2018, NAT ELECTRON, V1, P636, DOI 10.1038/s41928-018-0180-3
   Huo HY, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0204-1
   Iacomi P, 2020, CHEM MATER, V32, P982, DOI 10.1021/acs.chemmater.9b03376
   Imaoka T, 2019, B CHEM SOC JPN, V92, P941, DOI 10.1246/bcsj.20190008
   Inokuma Y, 2014, B CHEM SOC JPN, V87, P1161, DOI 10.1246/bcsj.20140217
   Inokuma Y, 2013, NATURE, V495, P461, DOI 10.1038/nature11990
   Inokuma Y, 2010, NAT CHEM, V2, P780, DOI [10.1038/NCHEM.742, 10.1038/nchem.742]
   Ishida T, 2020, CHEM REV, V120, P464, DOI 10.1021/acs.chemrev.9b00551
   Jablonka KM, 2020, CHEM REV, V120, P8066, DOI 10.1021/acs.chemrev.0c00004
   Jang J, 2020, J AM CHEM SOC, V142, P18836, DOI 10.1021/jacs.0c07384
   Jena AK, 2019, CHEM REV, V119, P3036, DOI 10.1021/acs.chemrev.8b00539
   Jensen Z, 2021, ACS CENTRAL SCI, V7, P858, DOI 10.1021/acscentsci.1c00024
   Jensen Z, 2019, ACS CENTRAL SCI, V5, P892, DOI 10.1021/acscentsci.9b00193
   Jeong B, 2020, ADV MATER, V32, DOI 10.1002/adma.202000597
   Ji DX, 2019, ADV MATER, V31, DOI 10.1002/adma.201808267
   Ji Q, 2008, J AM CHEM SOC, V130, P2376, DOI 10.1021/ja076139s
   Ji QM, 2009, ADV FUNCT MATER, V19, P1792, DOI 10.1002/adfm.200801762
   Jia Y, 2019, NAT REV CHEM, V3, P361, DOI 10.1038/s41570-019-0100-8
   Jia Y, 2019, ACCOUNTS CHEM RES, V52, P1623, DOI 10.1021/acs.accounts.9b00015
   Jiang JZ, 2019, CHEM SOC REV, V48, P4639, DOI 10.1039/c9cs00348g
   Jordá JL, 2013, ANGEW CHEM INT EDIT, V52, P10458, DOI 10.1002/anie.201305230
   Jung EH, 2019, NATURE, V567, P511, DOI 10.1038/s41586-019-1036-3
   Jung WB, 2020, ADV MATER, V32, DOI 10.1002/adma.201907101
   Kamei K, 2020, B CHEM SOC JPN, V93, P1603, DOI 10.1246/bcsj.20200232
   Kankala RK, 2020, ADV MATER, V32, DOI 10.1002/adma.201907035
   Kato T, 2021, B CHEM SOC JPN, V94, P357, DOI 10.1246/bcsj.20200304
   Kawai S, 2020, ANGEW CHEM INT EDIT, V59, P10842, DOI 10.1002/anie.202001268
   Kawai S, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay8913
   Kazuma E, 2020, B CHEM SOC JPN, V93, P1552, DOI 10.1246/bcsj.20200204
   Kim C, 2018, J PHYS CHEM C, V122, P17575, DOI 10.1021/acs.jpcc.8b02913
   Kimmig J, 2021, ADV MATER, V33, DOI 10.1002/adma.202004940
   Kimura K, 2019, NATURE, V570, P210, DOI 10.1038/s41586-019-1284-2
   Kitagawa S, 2004, ANGEW CHEM INT EDIT, V43, P2334, DOI 10.1002/anie.200300610
   Kobayashi J, 2019, B CHEM SOC JPN, V92, P817, DOI 10.1246/bcsj.20180378
   Konnerth H, 2020, COORDIN CHEM REV, V416, DOI 10.1016/j.ccr.2020.213319
   Kramer D, 2004, NANO LETT, V4, P793, DOI 10.1021/nl049927d
   KRESGE CT, 1992, NATURE, V359, P710, DOI 10.1038/359710a0
   Krishnapriyan AS, 2020, J PHYS CHEM C, V124, P9360, DOI 10.1021/acs.jpcc.0c01167
   Kudo A, 2009, CHEM SOC REV, V38, P253, DOI 10.1039/b800489g
   Lan YS, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07720-x
   Lee JW, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13749-3
   Lee Y, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15396
   Li BL, 2017, ACS APPL MATER INTER, V9, P15286, DOI 10.1021/acsami.7b02529
   Li CL, 2018, ACCOUNTS CHEM RES, V51, P1764, DOI 10.1021/acs.accounts.8b00119
   Li JG, 2020, ADV SCI, V7, DOI 10.1002/advs.201901957
   Li Y, 2020, B CHEM SOC JPN, V93, P176, DOI 10.1246/bcsj.20190298
   Li Y, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9328
   Li Y, 2018, ACS NANO, V12, P1455, DOI 10.1021/acsnano.7b07841
   Liang XG, 2020, B CHEM SOC JPN, V93, P581, DOI 10.1246/bcsj.20200012
   Liao W, 2019, ACTA BIOMATER, V86, P1, DOI 10.1016/j.actbio.2018.12.045
   Lim HR, 2020, ADV MATER, V32, DOI 10.1002/adma.201901924
   Liu GQ, 2020, CHEM REV, V120, P6009, DOI 10.1021/acs.chemrev.9b00725
   Liu XM, 2021, J ENERGY CHEM, V53, P290, DOI 10.1016/j.jechem.2020.04.012
   Liu XH, 2020, ADV MATER, V32, DOI 10.1002/adma.202000866
   Liu YZ, 2016, SCIENCE, V351, P365, DOI 10.1126/science.aad4011
   Liu Z, 2013, MICROSCOPY-JPN, V62, P109, DOI 10.1093/jmicro/dfs098
   Cortez ML, 2018, SOFT MATTER, V14, P1939, DOI 10.1039/c8sm00052b
   Lu XF, 2019, ADV MATER, V31, DOI 10.1002/adma.201902339
   Ma RM, 2020, ACS APPL MATER INTER, V12, P34041, DOI 10.1021/acsami.0c06858
   MacLeod BP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz8867
   Maeda K, 2019, B CHEM SOC JPN, V92, P38, DOI 10.1246/bcsj.20180258
   Mahyuddin MH, 2020, B CHEM SOC JPN, V93, P345, DOI 10.1246/bcsj.20190282
   Maji S, 2021, B CHEM SOC JPN, V94, P1502, DOI 10.1246/bcsj.20210059
   Markovich G, 1999, ACCOUNTS CHEM RES, V32, P415, DOI 10.1021/ar980039x
   Martin RL, 2014, J AM CHEM SOC, V136, P5006, DOI 10.1021/ja4123939
   Mi P, 2020, ADV MATER, V32, DOI 10.1002/adma.201902604
   Mishima K, 2020, B CHEM SOC JPN, V93, P1509, DOI 10.1246/bcsj.20200187
   Moghadam PZ, 2019, MATTER-US, V1, P219, DOI 10.1016/j.matt.2019.03.002
   Moghadam PZ, 2017, CHEM MATER, V29, P2618, DOI 10.1021/acs.chemmater.7b00441
   Moliner M, 2013, ANGEW CHEM INT EDIT, V52, P13880, DOI 10.1002/anie.201304713
   Moosavi SM, 2020, J AM CHEM SOC, V142, P20273, DOI 10.1021/jacs.0c09105
   Moosavi SM, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08483-9
   Muraoka K, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12394-0
   Nakamura E, 2018, P JPN ACAD B-PHYS, V94, P428, DOI 10.2183/pjab.94.028
   Nishijima H, 1999, APPL PHYS LETT, V74, P4061, DOI 10.1063/1.123261
   NISHIZUKA Y, 1984, NATURE, V308, P693, DOI 10.1038/308693a0
   Noh J, 2020, CHEM SCI, V11, P4871, DOI 10.1039/d0sc00594k
   Nugraha AS, 2020, J MATER CHEM A, V8, P13532, DOI 10.1039/d0ta04096g
   Ohata Y, 2019, B CHEM SOC JPN, V92, P655, DOI 10.1246/bcsj.20180376
   Ohno T, 2011, NAT MATER, V10, P591, DOI [10.1038/NMAT3054, 10.1038/nmat3054]
   Ongari D, 2019, ACS CENTRAL SCI, V5, P1663, DOI 10.1021/acscentsci.9b00619
   Otake K, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14627-z
   Oviedo F, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0196-x
   Pang PF, 2020, B CHEM SOC JPN, V93, P637, DOI 10.1246/bcsj.20190365
   Pardakhti M, 2020, J PHYS CHEM C, V124, P4534, DOI 10.1021/acs.jpcc.9b09319
   Park J, 2017, CHEM MATER, V29, P10487, DOI 10.1021/acs.chemmater.7b04287
   Paruzzo FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06972-x
   Pavlicek N, 2017, NAT NANOTECHNOL, V12, P308, DOI [10.1038/NNANO.2016.305, 10.1038/nnano.2016.305]
   Pavlicek N, 2015, NAT CHEM, V7, P623, DOI [10.1038/NCHEM.2300, 10.1038/nchem.2300]
   Percec V, 2021, B CHEM SOC JPN, V94, P900, DOI 10.1246/bcsj.20210015
   Pophale R, 2011, PHYS CHEM CHEM PHYS, V13, P12407, DOI 10.1039/c0cp02255a
   Qiao JL, 2014, CHEM SOC REV, V43, P631, DOI 10.1039/c3cs60323g
   Qu XB, 2020, ANGEW CHEM INT EDIT, V59, P10297, DOI 10.1002/anie.201908162
   Quo ZW, 2021, J PHYS CHEM C, V125, P7839, DOI 10.1021/acs.jpcc.0c10773
   Raccuglia P, 2016, NATURE, V533, P73, DOI 10.1038/nature17439
   Rainer DN, 2021, DALTON T, V50, P8995, DOI 10.1039/d1dt01440d
   Rajan AC, 2018, CHEM MATER, V30, P4031, DOI 10.1021/acs.chemmater.8b00686
   Rajan K, 2015, ANNU REV MATER RES, V45, P153, DOI 10.1146/annurev-matsci-070214-021132
   Rao CNR, 2019, B CHEM SOC JPN, V92, P441, DOI 10.1246/bcsj.20180335
   Rapenne G, 2017, NAT REV MATER, V2, DOI 10.1038/natrevmats.2017.40
   Rosen AS, 2021, MATTER-US, V4, P1578, DOI 10.1016/j.matt.2021.02.015
   Roukes M, 2001, SCI AM, V285, P48, DOI 10.1038/scientificamerican0901-48
   Roy N, 2019, B CHEM SOC JPN, V92, P178, DOI 10.1246/bcsj.20180250
   Saito Y, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0262-4
   Salinas-Torres D, 2020, B CHEM SOC JPN, V93, P438, DOI 10.1246/bcsj.20190371
   Sang YT, 2019, MOL SYST DES ENG, V4, P11, DOI 10.1039/c8me00068a
   Sasaki Y, 2021, COORDIN CHEM REV, V429, DOI 10.1016/j.ccr.2020.213607
   Schmidt J, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0221-0
   Shi Y, 2021, ACCOUNTS CHEM RES, V54, P546, DOI 10.1021/acs.accounts.0c00736
   Shi YF, 2021, CHEM REV, V121, P649, DOI 10.1021/acs.chemrev.0c00454
   Shimizu T, 2020, B CHEM SOC JPN, V93, P1079, DOI 10.1246/bcsj.20200134
   Sillin HO, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/384004
   Simpson GJ, 2017, NAT NANOTECHNOL, V12, P604, DOI 10.1038/nnano.2017.137
   Singh B, 2020, B CHEM SOC JPN, V93, P1459, DOI 10.1246/bcsj.20200136
   Singh G, 2021, B CHEM SOC JPN, V94, P1232, DOI 10.1246/bcsj.20200379
   Suga M, 2015, NATURE, V517, P99, DOI 10.1038/nature13991
   Sugimoto Y, 2007, NATURE, V446, P64, DOI 10.1038/nature05530
   Sun HM, 2020, ADV MATER, V32, DOI 10.1002/adma.201806326
   Sun QM, 2020, ADV MATER, V32, DOI 10.1002/adma.202001818
   Sun WB, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aay4275
   Tamura T, 2006, JPN J APPL PHYS 2, V45, pL364, DOI 10.1143/JJAP.45.L364
   Tan C, 2020, CHEM COMMUN, V56, P2811, DOI 10.1039/c9cc09966b
   Tang J, 2015, J AM CHEM SOC, V137, P1572, DOI 10.1021/ja511539a
   Tao QL, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00495-8
   Tayfuroglu O, 2020, LANGMUIR, V36, P119, DOI 10.1021/acs.langmuir.9b03618
   Wada N, 2018, ANGEW CHEM INT EDIT, V57, P3671, DOI 10.1002/anie.201713219
   Wan HR, 2021, B CHEM SOC JPN, V94, P961, DOI 10.1246/bcsj.20200380
   Wang CH, 2020, CHEM-US, V6, P19, DOI 10.1016/j.chempr.2019.09.005
   Wang HF, 2020, CHEM SOC REV, V49, P1414, DOI 10.1039/c9cs00906j
   Wang HJ, 2012, J AM CHEM SOC, V134, P10819, DOI 10.1021/ja303773z
   Wang J, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15717
   Wang Q, 2020, CHEM REV, V120, P919, DOI 10.1021/acs.chemrev.9b00201
   Wang S, 2020, ANGEW CHEM INT EDIT, V59, P19645, DOI 10.1002/anie.202005931
   Wang S, 2019, ACS MATER LETT, V1, P558, DOI 10.1021/acsmaterialslett.9b00374
   Wang Y, 2020, MATER TODAY, V32, P178, DOI 10.1016/j.mattod.2019.06.005
   Wang Z, 2019, CHEM SOC REV, V48, P2109, DOI 10.1039/c8cs00542g
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Wei LF, 2019, CHEM MATER, V31, P7340, DOI 10.1021/acs.chemmater.9b01953
   Wei YS, 2020, CHEM REV, V120, P12089, DOI 10.1021/acs.chemrev.9b00757
   Wiktor C, 2017, J MATER CHEM A, V5, P14969, DOI 10.1039/c7ta00194k
   Willhammar T, 2014, ADV FUNCT MATER, V24, P182, DOI 10.1002/adfm.201301949
   Wilmer CE, 2012, NAT CHEM, V4, P83, DOI [10.1038/nchem.1192, 10.1038/NCHEM.1192]
   Wu YJ, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0193-0
   Wu Y, 2020, CHEM MATER, V32, P2986, DOI 10.1021/acs.chemmater.9b05322
   Xiao X, 2020, CHEM SOC REV, V49, P301, DOI 10.1039/c7cs00614d
   Xie YC, 2020, J AM CHEM SOC, V142, P1475, DOI 10.1021/jacs.9b11569
   Xing JF, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11564-4
   Xiong MY, 2020, ACS NANO, V14, P16131, DOI 10.1021/acsnano.0c08382
   Xu GR, 2021, COORDIN CHEM REV, V427, DOI 10.1016/j.ccr.2020.213554
   Yabuuchi N, 2014, CHEM REV, V114, P11636, DOI 10.1021/cr500192f
   Yamada H, 2019, ACS CENTRAL SCI, V5, P1717, DOI 10.1021/acscentsci.9b00804
   Yamada Y, 2020, B CHEM SOC JPN, V93, P109, DOI 10.1246/bcsj.20190314
   Yamashita M, 2021, B CHEM SOC JPN, V94, P209, DOI 10.1246/bcsj.20200257
   YANAGISAWA T, 1990, B CHEM SOC JPN, V63, P988, DOI 10.1246/bcsj.63.988
   Yang JC, 2019, ADV MATER, V31, DOI 10.1002/adma.201904765
   Yang LJ, 2019, ADV MATER, V31, DOI 10.1002/adma.201804799
   Ye WK, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06322-x
   Yonamine Y, 2016, PHYS CHEM CHEM PHYS, V18, P12576, DOI 10.1039/c6cp01586g
   Yonamine Y, 2015, PHYS CHEM CHEM PHYS, V17, P32122, DOI 10.1039/c5cp05765e
   Zeng YX, 2019, ADV MATER, V31, DOI 10.1002/adma.201903675
   Zhang DL, 2018, SCIENCE, V359, P675, DOI 10.1126/science.aao0865
   Zhang NN, 2021, ANGEW CHEM INT EDIT, V60, P2861, DOI 10.1002/anie.202012322
   Zhang Q, 2020, ANGEW CHEM INT EDIT, V59, P19403, DOI 10.1002/anie.202007490
   Zhang XY, 2020, CHEM SCI, V11, P10844, DOI 10.1039/d0sc02048f
   Zhang ZH, 2019, ANGEW CHEM INT EDIT, V58, P259, DOI 10.1002/anie.201812363
   Zhao YC, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22472-x
   Zhao YX, 2019, ADV MATER, V31, DOI 10.1002/adma.201806482
   Zheng C, 2018, NPJ COMPUT MATER, V4, DOI 10.1038/s41524-018-0067-x
   Zhu QL, 2016, CHEM-US, V1, P220, DOI 10.1016/j.chempr.2016.07.005
   Zhu YH, 2017, NAT MATER, V16, P532, DOI [10.1038/NMAT4852, 10.1038/nmat4852]
NR 265
TC 58
Z9 58
U1 53
U2 329
PD FEB
PY 2022
VL 34
IS 7
AR 2107212
DI 10.1002/adma.202107212
EA JAN 2022
UT WOS:000738654400001
HC Y
HP N
DA 2023-11-16
ER

PT C
AU Arora, A
   Wei, ZG
   John, LK
AF Arora, Aman
   Wei, Zhigang
   John, Lizy K.
BE Hannig, F
   Navaridas, J
   Koch, D
   Abdelhadi, A
TI Hamamu: Specializing FPGAs for ML Applications by Adding Hard Matrix
   Multiplier Blocks
SO 2020 IEEE 31ST INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2020)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 31st IEEE International Conference on Application-Specific Systems,
   Architectures and Processors (ASAP)
CY JUL 06-08, 2020
CL Univ Manchester, Dept Comp Sci, Manchester, ENGLAND
HO Univ Manchester, Dept Comp Sci
ID ARCHITECTURE
AB Designing efficient hardware for accelerating artificial intelligence (AI) and machine learning (ML) applications is a major challenge. Rapidly changing algorithms and neural network architectures make FPGA based designs an attractive solution. But the generic building blocks available in current FPGAs (Logic Blocks (LBs), multipliers, DSP blocks) limit the acceleration that can be achieved. We propose Hamamu, a modification to the current FPGA architecture that makes FPGAs specialized for ML applications. Specifically, we propose adding hard matrix multiplier blocks (matmuls) into the FPGA fabric. These matmuls are implemented using systolic arrays of MACs (Multiply-And-Accumulate) and can be connected using programmable direct interconnect between neighboring matmuls to make larger systolic matrix multipliers. We explore various matmul sizes (2x2x2, 4x4x4, 8x8x8, 16x16x16) and various strategies to place these blocks on the FPGA (Columnar, Surround, Hybrid). We find that providing 4x4x4 hard matrix multiplier blocks in an FPGA speeds up neural networks from MLPerf benchmarks by up to (similar to)3.9x, compared to a Stratix-10 like FPGA with equal number of MACs, same MAC architecture and high DSP:LB ratio. Although the flexibility of the FPGA will reduce for non-ML applications, an FPGA with hard matrix multipliers is a faster, and more area efficient hardware accelerator for ML applications, compared to current FPGAs.
C1 [Arora, Aman; Wei, Zhigang; John, Lizy K.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Arora, A (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM aman.kbm@utexas.edu; zw5259@utexas.edu; ljohn@ece.utexas.edu
CR Abdelfattah M. S., 2018, CORR
   Achronix, 2019, SPEEDSTER7T FPGAS
   [Anonymous], 2017, NVID TESL V100 GPU A, P1
   Boutros A, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P94, DOI 10.1145/3289602.3293912
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Flex-Logix, 2019, FLEX LOG EFLX EFPGA
   Flex-Logix, 2019, FLEX LOG NNMAX INF A
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Ho CH, 2007, I C FIELD PROG LOGIC, P196, DOI 10.1109/FPL.2007.4380647
   Jamieson PA, 2010, IEEE T VLSI SYST, V18, P1696, DOI 10.1109/TVLSI.2009.2026651
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keller R. M., 2011, SYSTOLIC ARRAYS ALGO
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kuon I, 2007, FOUND TRENDS ELECTRO, V2, P135, DOI 10.1561/1000000005
   Lacey G., 2016, CORR
   Luu J, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2617593
   Nurvitadhi E., 2018, IN PACKAGE DOMAIN SP, P287
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Synopsys, 2018, SYN DES COMP
   Synopsys, 2018, SYNOPS VCS
   Xilinx, 2018, XIL AI ENG THEIR APP
   Xilinx, 2018, ACC DNNS XIL ALV ACC
   Yu C., 2010, ROUTING OPTIMIZATION, P419
   Yu CW, 2008, 2008 4TH SOUTHERN CONFERENCE ON PROGRAMMABLE LOGIC, PROCEEDINGS, P63, DOI 10.1109/SPL.2008.4547733
NR 27
TC 6
Z9 6
U1 0
U2 0
PY 2020
BP 53
EP 60
DI 10.1109/ASAP49362.2020.00018
UT WOS:000618062800009
DA 2023-11-16
ER

PT C
AU Kim, J
   Kang, M
   Han, Y
   Kim, YG
   Kim, LS
AF Kim, Junkyum
   Kang, Myeonggu
   Han, Yunki
   Kim, Yang-gon
   Kim, Lee-sup
GP IEEE
TI OptimStore: In-Storage Optimization of Large Scale DNNs with On-Die
   Processing
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
AB Training deep neural network (DNN) models is a resource-intensive, iterative process. For this reason, nowadays, complex optimizers like Adam are widely adopted as it increases the speed and efficiency of training. These optimizers, however, employ additional variables and raise the memory demand 2x to 3x of model parameters, worsening the memory capacity bottleneck. Moreover, as the size of DNN models is projected to grow even further, it is not practical to assume that the future models will fit in accelerator memory. This has triggered various efforts to offload models to flash-based storage. However, when the model, especially the optimizer, is offloaded to flash, the limited I/O bandwidth severely slows down the overall training process. To this end, we present OptimStore, a solid-state drive (SSD) system with on-die processing (ODP) architectures for gradient descent-based machine learning models. OptimStore accelerates the training process of such large-scale models by processing model optimization in the storage device, specifically inside the flash dies. ODP capability of OptimStore eliminates the heavy data movement over external interconnect and internal flash channels. Overall, OptimStore achieves, on average, a 2.8x speedup and a 3.6x improved energy efficiency in the weight update stage over baseline SSD offloading.
C1 [Kim, Junkyum] Samsung Elect, SAIT, Seoul, South Korea.
   [Kim, Junkyum; Kang, Myeonggu; Han, Yunki; Kim, Yang-gon; Kim, Lee-sup] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
   [Kim, Yang-gon] Samsung Elect, Syst LSI, Seoul, South Korea.
RP Kim, J (corresponding author), Samsung Elect, SAIT, Seoul, South Korea.; Kim, J (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
CR Agrawal A, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126918
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, 10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Bae J, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P387
   Cai Y, 2012, DES AUT TEST EUROPE, P521
   Chandrasekar K., DRAMPOWER OPEN SOURC
   Choe H, 2017, Arxiv, DOI arXiv:1610.02273
   Choi C., 2016, FLASH MEM SUMM
   Das D, 2018, Arxiv, DOI arXiv:1802.00930
   Do Jaeyoung, 2013, P 2013 ACM SIGMOD IN, P1221
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Ghiasi NM, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P635, DOI 10.1145/3503222.3507702
   Gouk D, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P469, DOI 10.1109/MICRO.2018.00045
   Gupta S, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415723
   Hildebrand M, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P875, DOI 10.1145/3373376.3378465
   Huang CC, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1341, DOI 10.1145/3373376.3378530
   Jeong WS, 2020, IEEE T PARALL DISTR, V31, P1137, DOI 10.1109/TPDS.2019.2953646
   Jia XY, 2018, Arxiv, DOI arXiv:1807.11205
   Jun SW, 2016, IEEE HIGH PERF EXTR
   K. Corporation, KIOX TECHN BRIEF
   Kang D, 2019, ISSCC DIG TECH PAP I, V62, P216, DOI 10.1109/ISSCC.2019.8662493
   Kim H, 2021, INT S HIGH PERF COMP, P249, DOI 10.1109/HPCA51647.2021.00030
   Kim S, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P371
   Kingma DP., 2017, ARXIV
   Koo G, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P219, DOI 10.1145/3123939.3124553
   Kuchaiev O, 2018, Arxiv, DOI arXiv:1805.10387
   Kwon M, 2022, Arxiv, DOI arXiv:2201.09189
   Kwon Y, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P148, DOI 10.1109/MICRO.2018.00021
   Li CY, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P225
   Liang SW, 2019, I C FIELD PROG LOGIC, P173, DOI 10.1109/FPL.2019.00035
   Liang SW, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P395
   Liu Re., 2012, TARGET-NETH
   Luo YX, 2015, IEEE S MASS STOR SYS
   Luo YX, 2018, P ACM MEAS ANAL COMP, V2, DOI [10.1145/3224432, 10.1145/3292040.3219659]
   Mailthody VS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P224, DOI 10.1145/3352460.3358320
   Michael O., 2016, U.S. Patent, Patent No. 9367392
   Micikevicius P., 2017, ARXIV171003740
   Microsoft, DEEPSPEED
   Minsub Kim, 2020, APSys 20. Proceedings of the 2020 SIGOPS Asia-Pacific Workshop on Systems, P90, DOI 10.1145/3409963.3410501
   Dauphin YN, 2015, Arxiv, DOI arXiv:1502.04390
   O. N. F. Interface, ONF 50 SPEC
   Park J, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P702, DOI 10.1145/3445814.3446719
   Pati S, 2021, Arxiv, DOI arXiv:2104.08335
   Peng X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P891, DOI 10.1145/3373376.3378505
   Radford A., 2018, IMPROVING LANGUAGE U
   Radford A., 2019, OPENAI BLOG, V1, P9
   Raffel C, 2020, Arxiv, DOI [arXiv:1910.10683, DOI 10.48550/ARXIV.1910.10683]
   Rajbhandari S, 2021, Arxiv, DOI [arXiv:2104.07857, 10.48550/ARXIV.2104.07857]
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024
   Ren J, 2021, INT S HIGH PERF COMP, P598, DOI 10.1109/HPCA51647.2021.00057
   Seagate, FIRECUDA530 PCIE 40
   Seshadri S., 2014, 11 USENIX S OPERATIN
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stoica R, 2019, I S MOD ANAL SIM COM, P152, DOI 10.1109/MASCOTS.2019.00025
   Synopsys I, DESIGN COMPILER
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tiwari D., 2012, 2012 WORKSH POW AW C
   Tiwari Devesh, 2013, P 11 USENIX C FILE S, P119
   Vaswani A, 2017, ADV NEUR IN, V30
   Walczyk C. J., 2018, IMPROVING ACCURACY F
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Yoon J, 2020, ANN I S COM, P693, DOI 10.1109/ISCA45697.2020.00063
NR 63
TC 1
Z9 1
U1 0
U2 0
PY 2023
BP 611
EP 623
DI 10.1109/HPCA56546.2023.10071024
UT WOS:000982303200045
DA 2023-11-16
ER

PT J
AU Aweisi, A
   Arora, D
   Emby, R
   Rehman, M
   Tanev, G
   Tanev, S
AF Aweisi, Abdulla
   Arora, Daman
   Emby, Renee
   Rehman, Madiha
   Tanev, George
   Tanev, Stoyan
TI Using Web Text Analytics to Categorize the Business Focus of Innovative
   Digital Health Companies
SO TECHNOLOGY INNOVATION MANAGEMENT REVIEW
DT Article
DE Digital health sector; topic modeling algorithm; market offer; value
   proposition; machine learning; web analytics
AB Categorizing the market focus of larger samples of companies can be a tedious and time-consuming process for both researchers and business analysts interested in developing insights about emerging business sectors. The objective of this article is to suggest a text analytics approach to categorizing the application areas of companies operating in the digital health sector based on the information provided on their websites. More specifically, we apply topic modeling on a collection of text documents, including information collected from the websites of a sample of 100 innovative digital health companies. The topic model helps in grouping the companies offering similar types of market offers. It enables identifying the companies that are most highly associated with each of the topics. In addition, it allows identifying some of the emerging themes that are discussed online by the companies, as well as their specific market offers. The results will be of interest to aspiring technology entrepreneurs, organizations supporting new ventures, and business accelerators interested to enhance their services to new venture clients. The development, operationalization, and automation of the company categorization process based on publicly available information is a methodological contribution that opens the opportunity for future applications in research and business practice.
C1 [Aweisi, Abdulla] TechBrew Robot, Salmon Arm, BC, Canada.
   [Arora, Daman] Carleton Univ, TIM Program, Appl Business Analyt Degree, Ottawa, ON, Canada.
   [Emby, Renee] Shared Serv Canada, Ottawa, ON, Canada.
   [Tanev, George] Export Dev Canada, Ottawa, ON, Canada.
   [Tanev, Stoyan] Carleton Univ, Sprott Sch Business, Technol Innovat Management TIM Program, Ottawa, ON, Canada.
   [Tanev, Stoyan] Univ Southern Denmark SDU, Fac Engn, Innovat & Design Engn Sect, Odense, Denmark.
RP Aweisi, A (corresponding author), TechBrew Robot, Salmon Arm, BC, Canada.
CR Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Hannigan TR, 2019, ACAD MANAG ANN, V13, P586, DOI 10.5465/annals.2017.0099
   Hecking T., 2018, TOPIC MODELLING EMPI
   Johnson MW, 2008, HARVARD BUS REV, V86, P50
   Mamosian H., 2018, P ISPIM CONN FUK C
   Taney S, 2015, EXPERT SYST APPL, V42, P7582, DOI 10.1016/j.eswa.2015.06.006
   Tang JT, 2012, J BUS VENTURING, V27, P77, DOI 10.1016/j.jbusvent.2010.07.001
   Wulfovich S., 2020, DIGITAL HLTH ENTREPR
NR 8
TC 2
Z9 2
U1 0
U2 5
PY 2021
VL 11
IS 7-8
BP 65
EP 78
DI 10.22215/timreview/1457
UT WOS:000714099900006
DA 2023-11-16
ER

PT J
AU Tang, YQ
   Zhang, JT
   Verma, N
AF Tang, Yinqi
   Zhang, Jintao
   Verma, Naveen
TI Scaling Up In-Memory-Computing Classifiers via Boosted Feature Subsets
   in Banked Architectures
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Boosting; feature segmentation; in-memory computing; machine learning;
   multi-armed bandits
AB In-memory computing is an emerging approach for overcoming memory-accessing bottlenecks, by eliminating the costs of explicitly moving data from point of storage to point of computation outside the array. However, computation increases the dynamic range of signals, such that performing it via the existing structure of dense memory substantially squeezes the signal-to-noise ratio (SNR). In this brief, we explore how computations can be scaled up, to jointly optimize energy/latency/bandwidth gains with SNR requirements. We employ algorithmic techniques to decompose computations so that they can be mapped to multiple parallel memory banks operating at chosen optimal points. Specifically focusing on in-memory classification, we consider a custom IC in 130-nm CMOS IC and demonstrate an algorithm combining error-adaptive classifier boosting and multi-armed bandits, to enable segmentation of a feature vector into multiple subsets. The measured performance of 10-way MNIST digit classification, using images downsampled to 16x16 pixels (mapped across four separate banks), is 91%, close to that simulated using full unsegmented feature vectors. The energy per classification is 879.7 pJ, 14.3x lower than that of a system based on separated memory and digital accelerator.
C1 [Tang, Yinqi; Zhang, Jintao; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Tang, YQ (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM yinqit@princeton.edu; jintao@princeton.edu; nverma@princeton.edu
CR Aly M. A., 2006, INT J ARTIF INTELL M, V6, P1
   [Anonymous], 2009, JMLR WORKSHOP C P KD
   [Anonymous], 2016, MICRO
   Auer P, 2003, SIAM J COMPUT, V32, P48, DOI 10.1137/S0097539701398375
   Busa-Fekete R., 2010, INT C MACH LEARN, V27, P143
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Wang Z, 2015, IEEE T CIRCUITS-I, V62, P1136, DOI 10.1109/TCSI.2015.2395591
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 14
TC 7
Z9 9
U1 1
U2 7
PD MAR
PY 2019
VL 66
IS 3
BP 477
EP 481
DI 10.1109/TCSII.2018.2854759
UT WOS:000460427700033
DA 2023-11-16
ER

PT J
AU Luo, AW
   An, FW
   Zhang, XY
   Mattausch, HJ
AF Luo, Aiwen
   An, Fengwei
   Zhang, Xiangyu
   Mattausch, Hans Juergen
TI A Hardware-Efficient Recognition Accelerator Using Haar-Like Feature and
   SVM Classifier
SO IEEE ACCESS
DT Article
DE Hardware architecture; Haar-like feature extraction; support vector
   machine (SVM); object recognition; high-speed processing; flexible
   memory allocation; high resolution image
ID ORIENTED GRADIENTS; COMPUTER VISION; ALGORITHM; MODELS; SPARSE
AB Significantly improved performance of the various learning algorithms has revived the interest in computer vision for recognition applications during the current decade. This paper reports a vision-based hardware recognition architecture combining the Haar-like feature extraction with the support vector machine (SVM) classification. To support an optimal tradeoff between resource requirements, processing speed, and recognition accuracy, a 12-bit fixed-point computation for block-based feature normalization and a recycling allocation of minimalized memory resources are proposed in this paper. Furthermore, an efficient scale generation of target objects for recognition is enabled by configurable windows with high size flexibility. Additionally, a parallel-partial SVM-classification architecture is developed for improving the recognition speed, by accumulating the partially completed SVM results for multiple windows in parallel. The proposed hardware architecture is verified with an Altera DE4 platform to achieve a high throughput rate of 216 and 70 f/s for XGA (1024 x 768) and HD (1920 x 1080) video resolutions, respectively. A recycled memory space of only 193 KB is sufficient for processing high-resolution images up to 2048 x 2048 pixels during online testing. Using the INRIA person dataset, 89.81% average precision and maximum accuracy of 96.93% for pedestrian recognition are realized. Furthermore, about 99.08% accuracy is achieved for two car recognition tasks using the UIUC dataset (side view of cars) and a frontal car dataset collected by ourselves at Hiroshima University with the proposed hardware-architecture framework.
C1 [Luo, Aiwen; Mattausch, Hans Juergen] Hiroshima Univ, HiSIM Res Ctr, Higashihiroshima 7398530, Japan.
   [Luo, Aiwen] Hiroshima Univ, Global Career Design Ctr, Higashihiroshima 7398514, Japan.
   [An, Fengwei; Zhang, Xiangyu] Hiroshima Univ, Grad Sch Engn, Higashihiroshima 7398527, Japan.
RP Luo, AW (corresponding author), Hiroshima Univ, HiSIM Res Ctr, Higashihiroshima 7398530, Japan.; Luo, AW (corresponding author), Hiroshima Univ, Global Career Design Ctr, Higashihiroshima 7398514, Japan.
EM luoaiwen@hiroshima-u.ac.jp
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], 2005, INRIA PERSON DATASET
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengler K, 2014, IEEE INTEL TRANSP SY, V6, P6, DOI 10.1109/MITS.2014.2336271
   Bhatia N., 2010, INT J COMPUT SCI INF, V8, P302, DOI DOI 10.1016/J.PMCJ.2015.02.001
   CISCO, 2018, CISCO GLOBAL CLOUD I
   Cristianini, 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   David  P., PYTHON RESOURCES
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dürre J, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P163, DOI 10.1145/3174243.3174249
   Nguyen-Tuong D, 2011, COGN PROCESS, V12, P319, DOI 10.1007/s10339-011-0404-1
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   Hahnle M, 2013, IEEE COMPUT SOC CONF, P629, DOI 10.1109/CVPRW.2013.95
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Hu WM, 2008, IEEE T SYST MAN CY B, V38, P577, DOI 10.1109/TSMCB.2007.914695
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Li ZS, 2017, IEEE INT SYMP PARAL, P143, DOI 10.1109/ISPA/IUCC.2017.00030
   Liu ZY, 2018, IEEE ACCESS, V6, P57006, DOI 10.1109/ACCESS.2018.2872939
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo AW, 2018, IEEE T VLSI SYST, V26, P431, DOI 10.1109/TVLSI.2017.2774813
   Luo AW, 2017, JPN J APPL PHYS, V56, DOI 10.7567/JJAP.56.04CF06
   Mizuno K, 2012, IEEE WORKSHOP SIG, P197, DOI 10.1109/SiPS.2012.57
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rister B, 2013, INT CONF ACOUST SPEE, P2674, DOI 10.1109/ICASSP.2013.6638141
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Su YC, 2012, IEEE J SOLID-ST CIRC, V47, P797, DOI 10.1109/JSSC.2012.2185349
   Szegedy C., 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tang YX, 2018, IEEE T PATTERN ANAL, V40, P3045, DOI 10.1109/TPAMI.2017.2771779
   Tang YX, 2014, IEEE IMAGE PROC, P4072, DOI 10.1109/ICIP.2014.7025827
   Vapnik Vladimir N, 1998, STAT LEARNING THEORY
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xu Y, 2015, IEEE IMAGE PROC, P3452, DOI 10.1109/ICIP.2015.7351445
   Yin SY, 2017, IEEE SYST J, V11, P260, DOI 10.1109/JSYST.2015.2418680
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang XY, 2017, JPN J APPL PHYS, V56, DOI 10.7567/JJAP.56.04CF01
NR 49
TC 15
Z9 15
U1 1
U2 13
PY 2019
VL 7
BP 14472
EP 14487
DI 10.1109/ACCESS.2019.2894169
UT WOS:000458797900021
DA 2023-11-16
ER

PT J
AU Li, J
   Wang, Y
   Zi, YY
   Sun, XJ
   Yang, Y
AF Li, Jie
   Wang, Yu
   Zi, Yanyang
   Sun, Xiaojie
   Yang, Ying
TI A Current Signal-Based Adaptive Semisupervised Framework for Bearing
   Faults Diagnosis in Drivetrains
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
DT Article
DE Bearing faults; current signals; generative adversarial network;
   semisupervised learning; signal processing
ID INDUCTION MACHINES; FEATURE-EXTRACTION; NETWORK
AB In most practical applications of fault diagnosis methods, two problems will inevitably arise. First, limited by the monitored object itself and its environment, accelerators are difficult to install. Second, industrial applications lack data with fault labels, which limits the use of data-driven-based methods. To solve these problems, a current signal-based adaptive semisupervised framework (C-ASSF) is proposed. In C-ASSF, the Wasserstein generative adversarial network with gradient penalty (WGAN-CP) is adopted to extract recognizable features from only normal current signals. Subsequently, since WGAN-GP pays too much attention to body signals and ignores the changes caused by faults, the line spectrum feature extraction (LSFE) technique is utilized to remove the main frequency component of the current signal specifically. Finally, an index indicating the degree of deviation from the normal distribution is introduced to identify external bearing faults in drivetrains. Two groups of different experimental data sets are applied to verify the performance of C-ASSF. The results show that C-ASSF is superior to existing methods, such as self-organizing map (SOM) and stack autoencoder (SAE), and can not only identify faults in drivetrains but also identify different fault classes.
C1 [Li, Jie; Wang, Yu; Zi, Yanyang; Sun, Xiaojie] Xi An Jiao Tong Univ, State Key Lab Mfg Syst Engn, Xian 710049, Peoples R China.
   [Yang, Ying] Peking Univ, Dept Mech & Engn Sci, Coll Engn, Beijing 100871, Peoples R China.
RP Wang, Y (corresponding author), Xi An Jiao Tong Univ, State Key Lab Mfg Syst Engn, Xian 710049, Peoples R China.
EM lijie1@stu.xjtu.edu.cn; ywang95@xjtu.edu.cn; ziyy@xjtu.edu.cn;
   banjamin555@stu.xjtu.edu.cn; yy@mech.pku.edu.cn
CR Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   [Anonymous], 2017, BEGAN BOUNDARY EQUIL
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Beggel L., 2019, P JOINT EUR C MACH L, P206
   Ben Abid F, 2018, IEEE T ENERGY CONVER, V33, P1692, DOI 10.1109/TEC.2018.2839083
   Bloedt M, 2008, IEEE T IND ELECTRON, V55, P1813, DOI 10.1109/TIE.2008.917108
   Hoang DT, 2020, IEEE T INSTRUM MEAS, V69, P3325, DOI 10.1109/TIM.2019.2933119
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I., 2017, ADV NEURAL INFORM PR, V30, P5767
   Han T, 2019, MECH SYST SIGNAL PR, V117, P170, DOI 10.1016/j.ymssp.2018.07.048
   Immovilli F, 2010, IEEE T IND APPL, V46, P1350, DOI 10.1109/TIA.2010.2049623
   Ince T, 2016, IEEE T IND ELECTRON, V63, P7067, DOI 10.1109/TIE.2016.2582729
   Jung JH, 2006, IEEE T IND ELECTRON, V53, P1842, DOI 10.1109/TIE.2006.885131
   Kuncan M, 2020, ISA T, V100, P346, DOI 10.1016/j.isatra.2019.11.006
   Leite VCMN, 2015, IEEE T IND ELECTRON, V62, P1855, DOI 10.1109/TIE.2014.2345330
   Lessmeier C., 2016, P EUR C PROGN HLTH M, P5
   Li HF, 2019, PROCEDIA COMPUT SCI, V162, P438, DOI 10.1016/j.procs.2019.12.008
   Li JX, 2018, I C CONT AUTOMAT ROB, P1327, DOI 10.1109/ICARCV.2018.8581331
   Li J, 2020, IEEE T INSTRUM MEAS, V69, P8580, DOI 10.1109/TIM.2020.2986853
   Mao WT, 2020, IEEE T INSTRUM MEAS, V69, P443, DOI 10.1109/TIM.2019.2903699
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Paderborn University Paderborn Germany, KAT DATACENTER WEBSI
   Pan TY, 2019, IEEE T IND INFORM, V15, P5119, DOI 10.1109/TII.2019.2896665
   Plakias S, 2019, NEUROCOMPUTING, V332, P396, DOI 10.1016/j.neucom.2018.12.041
   Ramanathan S, 2020, INT C TRANS OPT NETW, DOI 10.1109/icton51198.2020.9328898
   Salimans T, 2016, P 30 C NEUR INF PROC, P2234
   SCHOEN RR, 1995, IEEE T IND APPL, V31, P900, DOI 10.1109/28.395302
   Shahriar MR, 2018, IEEE T IND ELECTRON, V65, P5941, DOI 10.1109/TIE.2017.2782240
   Singh S, 2017, IEEE T IND INFORM, V13, P1341, DOI 10.1109/TII.2016.2641470
   Wagner T., 2020, P INT C INNOVATIONS, P1
   Wang XX, 2020, IEEE T INSTRUM MEAS, V69, P5556, DOI 10.1109/TIM.2019.2963582
   Xiao YC, 2016, CHEMOMETR INTELL LAB, V151, P15, DOI 10.1016/j.chemolab.2015.11.010
   Yan K, 2017, NEUROCOMPUTING, V228, P205, DOI 10.1016/j.neucom.2016.09.076
   Zhang DC, 2020, IEEE T INSTRUM MEAS, V69, P2996, DOI 10.1109/TIM.2019.2929669
   Zhang KY, 2020, J MANUF SYST, V55, P273, DOI 10.1016/j.jmsy.2020.04.016
NR 35
TC 5
Z9 6
U1 5
U2 60
PY 2021
VL 70
AR 3508012
DI 10.1109/TIM.2020.3046051
UT WOS:000636274000020
DA 2023-11-16
ER

PT C
AU Kulkarni, A
   Jafari, A
   Sagedy, C
   Mohsenin, T
AF Kulkarni, Amey
   Jafari, Ali
   Sagedy, Chris
   Mohsenin, Tinoosh
GP IEEE
TI Sketching-based High-Performance Biomedical Big Data Processing
   Accelerator
SO 2016 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 22-25, 2016
CL Montreal, CANADA
DE Big Data Processing; Sketching Technique; Many-Core; Seizure Detection
ID ARCHITECTURE
AB Multi-Sensor health monitoring systems are used to predict near future events of our health system. Each sensor generates humongous amount of data per second and needs to be processed in real-time. At the same time health monitoring systems are battery operated, thus they have rigid constraints on power and area of processing platform. Additionally, health monitoring systems should be accurate, thus we adapt machine learning techniques to improve detection accuracy. We propose a programmable Big Data Processing framework to reduce on-chip communications and computations, thus reducing energy of the processing. We integrate a low-overhead sketching framework with a low-power programmable PENC many-core platform. The sketching technique reduces the data communications and computations, additionally processing time is scaled down by parallel processing on the many-core platform. For demonstration we show seizure detection application with 22-channel of electroencephalograph (EEG), each channel generates 256 samples per second requiring total of 88 Kbps data rate. The computations are reduced by 16x while energy consumption of processing is reduced up to 68%. For compression rates of 2-16x, the seizure detection performance for sensitivity and specificity is degraded by 2.07% and 2.97%, respectively for Logistic Regression classifier.
C1 [Kulkarni, Amey; Jafari, Ali; Sagedy, Chris; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
RP Kulkarni, A (corresponding author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
CR [Anonymous], IEEE BIOM CIRC SYST
   [Anonymous], IEEE BIOM CIRC SYST
   [Anonymous], MATHWORKS NEWS NOTES
   Chen F, 2012, IEEE J SOLID-ST CIRC, V47, P744, DOI 10.1109/JSSC.2011.2179451
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Kulkarni A., 2016, P 26 ED GREAT LAK S
   Kulkarni A., 2016, J EMERGING TECHNOLOG
   Kulkarni A, 2014, PR GR LAK SYMP VLSI, P299, DOI 10.1145/2591513.2591598
   Kulkarni A, 2015, IEEE INT SYMP CIRC S, P970, DOI 10.1109/ISCAS.2015.7168797
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Septimus A., 2010, CIRC SYST ISCAS P 20, P3316
   Shoaib M, 2012, CUSTOM INTEGRATED CI, P1
   Shoeb A. H., 2010, P 27 INT C MACHINE L, P975, DOI DOI 10.5555/3104322.3104446
   Tavana MK, 2014, I SYMPOS LOW POWER E, P275, DOI 10.1145/2627369.2627654
   Wulsin DF, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036015
NR 16
TC 7
Z9 7
U1 0
U2 0
PY 2016
BP 1138
EP 1141
UT WOS:000390094701068
DA 2023-11-16
ER

PT J
AU Tang, LX
   Ning, CF
   Adaimi, G
   Ijspeert, A
   Alahi, A
   Bolotnikova, A
AF Tang, Lixuan
   Ning, Chuanfang
   Adaimi, George
   Ijspeert, Auke
   Alahi, Alexandre
   Bolotnikova, Anastasia
TI Real-Time Localization for Closed-Loop Control of Assistive Furniture
SO IEEE ROBOTICS AND AUTOMATION LETTERS
DT Article
DE Vision-based navigation; localization; object detection; segmentation
   and categorization
AB For people with limited mobility, navigating in cluttered indoor environment is challenging. In this work, we propose a mobile assistive furniture suite that is designed to ease the life of people with special needs in indoor movement. To enable intelligent coordination of this system, a key component is the localization of each mobile furniture. The challenge is to assess the state of an arbitrary living scenario so that the estimation can be used as a real-time feedback signal for autonomous closed-loop control of mobile furniture. We propose a perception pipeline that addresses these challenges. A machine learning model is designed and trained to jointly achieve multi-object semantic keypoint detection and classification in camera images. The synthetic data generation is employed to augment the training set and boost the model performance. A robust point cloud registration uses the detected semantic keypoints and depth information to estimate poses of the furniture. Tracking is applied to achieve smooth estimation. A high-performance accelerator that optimizes the efficiency of using heterogeneous devices is applied to achieve real-time performance. This visual perception pipeline is used in closed-loop control to steer the mobile furniture from initial to a desired location demonstrated in experiments on real hardware.
C1 [Tang, Lixuan; Ning, Chuanfang; Ijspeert, Auke; Bolotnikova, Anastasia] Swiss Fed Inst Technol Lausanne EPFL, Biorobot Lab, CH-1015 Lausanne, Switzerland.
   [Adaimi, George; Alahi, Alexandre] Swiss Fed Inst Technol Lausanne EPFL, Visual Intelligence Transportat Lab, CH-1015 Lausanne, Switzerland.
RP Tang, LX (corresponding author), Swiss Fed Inst Technol Lausanne EPFL, Biorobot Lab, CH-1015 Lausanne, Switzerland.
EM lixuan.tang@epfl.ch; chuanfang.ning@epfl.ch; george.adaimi@epfl.ch;
   auke.ijspeert@epfl.ch; alexandre.alahi@epfl.ch;
   anastasia.bolotnikova@epfl.ch
CR Amodei D., 2016, P INT C MACH LEARN, P173
   Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Conzelmann FM, 2022, IEEE INT C INT ROBOT, P7259, DOI 10.1109/IROS47612.2022.9981583
   Fallatah A., 2021, P IEEE INT C ROB HUM, P1066
   Günther M, 2017, ARTIF INTELL, V247, P336, DOI 10.1016/j.artint.2014.12.007
   Hauser S, 2020, ROBOT AUTON SYST, V127, DOI 10.1016/j.robot.2020.103467
   Knight H, 2017, IEEE ROMAN, P443, DOI 10.1109/ROMAN.2017.8172340
   Kreiss S, 2022, IEEE T INTELL TRANSP, V23, P13498, DOI 10.1109/TITS.2021.3124981
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Lugaresi Camillo, 2019, 3 WORKSHOP COMPUTER
   Moon I, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3453
   RUS D, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 1, P235, DOI 10.1109/IROS.1995.525802
   Weng XS, 2020, IEEE INT C INT ROBOT, P10359, DOI 10.1109/IROS45743.2020.9341164
   Wu JJ, 2018, INT J COMPUT VISION, V126, P1009, DOI 10.1007/s11263-018-1074-6
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yixiao Guo, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P3763, DOI 10.1145/3474085.3478325
   Zhou XY, 2018, LECT NOTES COMPUT SC, V11205, P328, DOI 10.1007/978-3-030-01246-5_20
NR 20
TC 0
Z9 0
U1 5
U2 5
PD AUG
PY 2023
VL 8
IS 8
BP 4799
EP 4806
DI 10.1109/LRA.2023.3287365
UT WOS:001024186200005
DA 2023-11-16
ER

PT J
AU Yadav, N
   Kim, Y
   Li, S
   Choi, KK
AF Yadav, Nandakishor
   Kim, Youngbae
   Li, Shuai
   Choi, Kyuwon Ken
TI Stable, Low Power and Bit-Interleaving Aware SRAM Memory for Multi-Core
   Processing Elements
SO ELECTRONICS
DT Article
DE SRAM; stability; reliability; CNN; read time; write time
ID SUBTHRESHOLD SRAM; SENSE-AMPLIFIER; VOLTAGE; CELL
AB The machine learning and convolutional neural network (CNN)-based intelligent artificial accelerator needs significant parallel data processing from the cache memory. The separate read port is mostly used to design built-in computational memory (CRAM) to reduce the data processing bottleneck. This memory uses multi-port reading and writing operations, which reduces stability and reliability. In this paper, we proposed a self-adaptive 12T SRAM cell to increase the read stability for multi-port operation. The self-adaptive technique increases stability and reliability. We increased the read stability by refreshing the storing node in the read mode of operation. The proposed technique also prevents the bit-interleaving problem. Further, we offered a butterfly-inspired SRAM bank to increase the performance and reduce the power dissipation. The proposed SRAM saves 12% more total power than the state-of-the-art 12T SRAM cell-based SRAM. We improve the write performance by 28.15% compared with the state-of-the-art 12T SRAM design. The total area overhead of the proposed architecture compared to the conventional 6T SRAM cell-based SRAM is only 1.9 times larger than the 6T SRAM cell.
C1 [Yadav, Nandakishor] Fraunhofer Inst Photon Microsyst IPMS, D-01109 Dresden, Germany.
   [Kim, Youngbae; Li, Shuai; Choi, Kyuwon Ken] IIT, Chicago, IL 60616 USA.
RP Yadav, N (corresponding author), Fraunhofer Inst Photon Microsyst IPMS, D-01109 Dresden, Germany.
EM nkyadav.vlsi@gmail.com; ykim102@hawk.iit.edu; sli97@hawk.iit.edu;
   kchoi12@iit.edu
CR Ahmad S, 2016, IEEE T VLSI SYST, V24, P2634, DOI 10.1109/TVLSI.2016.2520490
   Almeida RB, 2018, MICROELECTRON RELIAB, V88-90, P196, DOI 10.1016/j.microrel.2018.07.134
   [Anonymous], 2012, COMPUTER BRAIN
   Ataei S, 2016, PR IEEE COMP DESIGN, P499, DOI 10.1109/ICCD.2016.7753333
   Chhabra A, 2016, IEEE INT SYMP CIRC S, P1018, DOI 10.1109/ISCAS.2016.7527416
   Chiu YW, 2014, IEEE T CIRCUITS-I, V61, P2578, DOI 10.1109/TCSI.2014.2332267
   Dong Q, 2018, IEEE J SOLID-ST CIRC, V53, P1006, DOI 10.1109/JSSC.2017.2776309
   Gupta P, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE), P11
   Hodges D., 2005, DEEP SUBMICRON TECHN
   Jaiswal A, 2019, IEEE T VLSI SYST, V27, P2556, DOI 10.1109/TVLSI.2019.2929245
   Jia HY, 2020, IEEE J SOLID-ST CIRC, V55, P2609, DOI 10.1109/JSSC.2020.2987714
   Jiang JW, 2019, IEEE T CIRCUITS-I, V66, P967, DOI 10.1109/TCSI.2018.2872507
   Jiang WX, 2020, J SEMICOND, V41, DOI 10.1088/1674-4926/41/2/022406
   Kang M, 2011, IEEE T ELECTRON DEV, V58, P2959, DOI 10.1109/TED.2011.2160180
   Kim TH, 2008, IEEE J SOLID-ST CIRC, V43, P518, DOI 10.1109/JSSC.2007.914328
   Moon S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050704
   Moradi F, 2008, IEEE INT SOC CONF, P113, DOI 10.1109/SOCC.2008.4641491
   Pal S, 2016, IEEE T COMPUT AID D, V35, P549, DOI 10.1109/TCAD.2015.2474408
   Patel PK, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2019.102956
   Pedretti G, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091063
   Ranganathan K, 2002, 11TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, PROCEEDINGS, P352, DOI 10.1109/HPDC.2002.1029935
   Reniwal BS, 2019, CIRC SYST SIGNAL PR, V38, P1482, DOI 10.1007/s00034-018-0934-1
   Sheu YM, 2006, IEEE T ELECTRON DEV, V53, P2792, DOI 10.1109/TED.2006.884070
   Verma N, 2008, IEEE J SOLID-ST CIRC, V43, P141, DOI 10.1109/JSSC.2007.908005
   Yadav N, 2017, IEEE T SEMICONDUCT M, V30, P276, DOI 10.1109/TSM.2017.2718029
   Yang Y, 2015, IEEE T VLSI SYST, V23, P2748, DOI 10.1109/TVLSI.2014.2367234
   Zhao Q, 2020, IEEE T VLSI SYST, V28, P848, DOI 10.1109/TVLSI.2019.2955865
NR 27
TC 1
Z9 1
U1 0
U2 6
PD NOV
PY 2021
VL 10
IS 21
AR 2724
DI 10.3390/electronics10212724
UT WOS:000720531800001
DA 2023-11-16
ER

PT C
AU Liu, SY
   Bavikadi, S
   Sen, T
   Shen, HY
   Sutradhar, PR
   Ganguly, A
   Dinakarrao, SMP
   Smith, BL
AF Liu, Shiyi
   Bavikadi, Sathwika
   Sen, Tanmoy
   Shen, Haiying
   Sutradhar, Purab Ranjan
   Ganguly, Amlan
   Dinakarrao, Sai Manoj Pudukotai
   Smith, Brian L.
GP IEEE
TI Accelerating Adversarial Attack using Process-in-Memory Architecture
SO 2022 18TH INTERNATIONAL CONFERENCE ON MOBILITY, SENSING AND NETWORKING,
   MSN
DT Proceedings Paper
CT 18th IEEE International Conference on Mobility, Sensing and Networking
   (MSN)
CY DEC 14-16, 2022
CL ELECTR NETWORK
DE Black-box adversarial attack; Deep neural network; Processing in memory
   (PIM)
AB Recent research has demonstrated that machine learning algorithms are vulnerable to adversarial attacks, in which small but carefully crafted input perturbations can lead to algorithm failure. It has been demonstrated that certain adversarial attack algorithms are capable of producing these types of perturbations. These attack methods are inapplicable when the attack must be generated in near real time. The use of a hardware accelerator, such as a Process-in-Memory (PIM) architecture, is a potential method for addressing this issue. The PIM architecture is regarded as a superior option for data-intensive applications such as solving optimization problems and Deep Neural Networks (DNN) due to its capacity for ultra-low-latency parallel processing. However, implementing an adversarial attack algorithm directly on the PIM platform is inefficient due to the PIM architecture's complexity and overhead costs. To address this issue, we utilize a novel adversarial attack scheme based on the PIM that leverages Look-up-Table (LUT)-based processing. The proposed LUT-based PIM architecture is capable of being dynamically programmed to execute the operations necessary for an adversarial attack algorithm. Our simulations reveal that the proposed method is capable of achieving an ultra-low operating delay and energy-efficiency performance.
C1 [Liu, Shiyi; Smith, Brian L.] Univ Virginia, Dept Engn Syst & Environm, Charlottesville, VA 22903 USA.
   [Bavikadi, Sathwika; Dinakarrao, Sai Manoj Pudukotai] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA USA.
   [Sen, Tanmoy; Shen, Haiying] Univ Virginia, Dept Comp Sci, Charlottesville, VA USA.
   [Sutradhar, Purab Ranjan; Ganguly, Amlan] Rochester Inst Technol, Rochester, NY USA.
RP Liu, SY (corresponding author), Univ Virginia, Dept Engn Syst & Environm, Charlottesville, VA 22903 USA.
EM sl9hm@virginia.edu; sbavikad@gmu.edu; ts5xm@virginia.edu;
   hs6ms@virginia.edu; ps9525@rit.edu; axgeec@rit.edu; spudukot@gmu.edu;
   bls2z@virginia.edu
CR Ajmi H., 2022, ARXIV
   [Anonymous], 2020, IEEE J SOLID-ST CIRC
   [Anonymous], 2019, IEEE INT S CIRCUITS
   [Anonymous], 2019, ACMIEEE DESIGN AUTOM
   Bavikadi S., 2021, 2021 IEEE 3 INT C AR, P1, DOI DOI 10.1109/AICAS51828.2021.9458575
   Bavikadi S., 2020, GLSVLSI 20
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Cai F., 2019, ARXIV
   Carboni R, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900198
   Chakraborty A, 2021, CAAI T INTELL TECHNO, V6, P25, DOI 10.1049/cit2.12028
   Chen P.-Y., 2017, PROC AISW
   Chen X, 2019, ARXIV
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chollet F., 2015, KERAS
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Fridman L., 2017, ARXIV
   Gong Y., 2019, ARXIV
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Goodfellow Ian J., 2015, EXPLAINING HARNESSIN
   Guesmi A., 2022, ARXIV
   Hu G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P384, DOI 10.1109/ICCVW.2015.58
   Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014
   Kim Y, 2017, ICCAD-IEEE ACM INT, P25, DOI 10.1109/ICCAD.2017.8203756
   Kingma DP., 2017, ARXIV
   Kong Z., 2021, WIRELESS COMPUTING C, V2021
   Kuutti S, 2021, IEEE T INTELL TRANSP, V22, P712, DOI 10.1109/TITS.2019.2962338
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li S, 2018, ARXIV
   Madry Aleksander, 2017, ARXIV170606083
   McAllister R, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4745
   Mladenovic A., 2021, ARXIV
   Modas A, 2020, IEEE SIGNAL PROC MAG, V37, P14, DOI 10.1109/MSP.2020.2985363
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N., 2018, ARXIV
   Sarker A., 2021, PROC MASS
   Sarker A., 2021, PROC SECON
   Sarker A, 2020, IEEE INT CONF MOB, P184, DOI 10.1109/MASS50613.2020.00032
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Serrano CR, 2020, 2020 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2020), P27, DOI 10.1109/SPW50608.2020.00022
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen H., 2022, 2022 IFIP NETWORKING, P1
   Sutradhar PR, 2021, PR IEEE COMP DESIGN, P252, DOI 10.1109/ICCD53106.2021.00049
   Sutradhar PR, 2022, IEEE T PARALL DISTR, V33, P263, DOI 10.1109/TPDS.2021.3066909
   Sutradhar PR, 2020, IEEE COMPUT ARCHIT L, V19, P118, DOI 10.1109/LCA.2020.3011643
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tandel NH, 2020, INT CONF ADVAN COMPU, P459, DOI [10.1109/icaccs48705.2020.9074184, 10.1109/ICACCS48705.2020.9074184]
   Tramer F., 2017, ARXIV
   Tu CC, 2019, AAAI CONF ARTIF INTE, P742
   Wang F, 2021, PROC INT CONF DATA, P1859, DOI 10.1109/ICDE51399.2021.00167
   Wang J, 2018, INT CON DISTR COMP S, P1385, DOI 10.1109/ICDCS.2018.00139
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003
   Wang Y, 2019, TRANSPORT RES C-EMER, V99, P144, DOI 10.1016/j.trc.2018.12.004
   Zhang C., 2021, ARXIV
NR 57
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 325
EP 330
DI 10.1109/MSN57253.2022.00061
UT WOS:000982822400044
DA 2023-11-16
ER

PT C
AU Akyildiz, TA
   Aljundi, AA
   Kaya, K
AF Akyildiz, Taha Atahan
   Aljundi, Amro Alabsi
   Kaya, Kamer
BE Wu, XT
   Jermaine, C
   Xiong, L
   Hu, XH
   Kotevska, O
   Lu, SY
   Xu, WJ
   Aluru, S
   Zhai, CX
   Al-Masri, E
   Chen, ZY
   Saltz, J
TI Understanding Coarsening for Embedding Large-Scale Graphs
SO 2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
DT Proceedings Paper
CT 8th IEEE International Conference on Big Data (Big Data)
CY DEC 10-13, 2020
CL ELECTR NETWORK
DE Graph coarsening; graph embedding; multi-level approach
ID SCHEME
AB A significant portion of the data today, e.g, social networks, web connections, etc., can be modeled by graphs. A proper analysis of graphs with Machine Learning (ML) algorithms has the potential to yield far-reaching insights into many areas of research and industry. However, the irregular structure of graph data constitutes an obstacle for running ML tasks on graphs such as link prediction, node classification, and anomaly detection. Graph embedding is a compute-intensive process of representing graphs as a set of vectors in a d-dimensional space, which in turn makes it amenable to ML tasks. Many approaches have been proposed in the literature to improve the performance of graph embedding, e.g., using distributed algorithms, accelerators, and pre-processing techniques. Graph coarsening, which can be considered a pre-processing step, is a structural approximation of a given, large graph with a smaller one. As the literature suggests, the cost of embedding significantly decreases when coarsening is employed. In this work, we thoroughly analyze the impact of the coarsening quality on the embedding performance both in terms of speed and accuracy. Our experiments with a state-of-the-art, fast graph embedding tool show that there is an interplay between the coarsening decisions taken and the embedding quality.
C1 [Akyildiz, Taha Atahan; Aljundi, Amro Alabsi; Kaya, Kamer] Sabanci Univ, Fac Engn & Nat Sci, Istanbul, Turkey.
RP Akyildiz, TA (corresponding author), Sabanci Univ, Fac Engn & Nat Sci, Istanbul, Turkey.
EM aakyildiz@sabanciuniv.edu; amroa@sabanciuniv.edu; kaya@sabanciuniv.edu
CR Akyildiz T., 2020, ICPP 20
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Çatalyürek ÜV, 2012, INT PARALL DISTRIB P, P848, DOI 10.1109/IPDPS.2012.81
   Chen HC, 2018, AAAI CONF ARTIF INTE, P2127
   Deveci M, 2015, J PARALLEL DISTR COM, V77, P69, DOI 10.1016/j.jpdc.2014.12.002
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Halappanavar M., 2017, IEEE HIGH PERF EXTR, P1
   Hendrickson B, 1995, SUPERCOMP PROC, P626
   Hu RJ, 2016, PROC INT CONF DATA, P385, DOI 10.1109/ICDE.2016.7498256
   Hu Y., 2005, MATH J, V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Karypis G, 1998, J PARALLEL DISTR COM, V48, P96, DOI 10.1006/jpdc.1997.1404
   Kipf Thomas N., 2017, ICLR 2017 A BROWN IN
   Lerer A., 2019, P MACH LEARN SYST 20
   Leskovec J., 2014, SNAP DATASETS STANFO
   Liang J., 2018, CORR
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Meusel Robert, 2015, J WEB SCI, V1, P33, DOI DOI 10.1561/106.00000003
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Newman M.E.J., 2004, PHYS REV E, V69, P1, DOI 10.1103/PhysRevE.69.026113
   Pellegrini F., 1996, High-Performance Computing and Networking. International Conference and Exhibition HPCN EUROPE 1996. Proceedings, P493, DOI 10.1007/3-540-61142-8_588
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tithi JJ, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404455
   Tsitsulin A, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P539, DOI 10.1145/3178876.3186120
   Zhu ZC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2494, DOI 10.1145/3308558.3313508
NR 28
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 2937
EP 2946
DI 10.1109/BigData50022.2020.9377898
UT WOS:000662554703009
DA 2023-11-16
ER

PT J
AU Wang, WJ
   Lin, B
AF Wang, Weijia
   Lin, Bill
TI Trained Biased Number Representation for ReRAM-Based Neural Network
   Accelerators
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article; Proceedings Paper
CT 3rd Workshop on Hardware Algorithms for Learning On-a-Chip (HALO)
CY NOV 16, 2017
CL Irvine, CA
DE Resistive Memory; convolutional neural networks; quantization; machine
   learning; processing-in-memory
AB Recent works have demonstrated the promise of using resistive random access memory (ReRAM) to perform neural network computations in memory. In particular, ReRAM-based crossbar structures can perform matrix-vector multiplication directly in the analog domain, but the resolutions of ReRAM cells and digital/analog converters limit the precisions of inputs and weights that can be directly supported. Although convolutional neural networks (CNNs) can be trained with low-precision weights and activations, previous quantization approaches are either not amenable to ReRAM-based crossbar implementations or have poor accuracies when applied to deep CNNs on complex datasets. In this article, we propose a new CNN training and implementation approach that implements weights using a trained biased number representation, which can achieve near full-precision model accuracy with as little as 2-bit weights and 2-bit activations on the CIFAR datasets. The proposed approach is compatible with a ReRAM-based crossbar implementation. We also propose an activation-side coalescing technique that combines the steps of batch normalization, nonlinear activation, and quantization into a single stage that simply performs a clipped-rounding operation. Experiments demonstrate that our approach outperforms previous low-precision number representations for VGG-11, VGG-13, and VGG-19 models on both the CIFAR-10 and CIFAR-100 datasets.
C1 [Wang, Weijia; Lin, Bill] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
RP Wang, WJ (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM wweijia@eng.ucsd.edu; billlin@eng.ucsd.edu
CR Burr GW, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM), DOI 10.1109/iedm.2015.7409625
   Cai Z, 2017, WOODH PUBL SER BIOM, P171, DOI 10.1016/B978-0-08-100383-1.00010-2
   Chen ZJ, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/919805
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Courbariaux Matthieu, 2014, ARXIV14127024
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim Y, 2015, ACM J EMERG TECH COM, V11, DOI 10.1145/2700234
   Li BX, 2013, I SYMPOS LOW POWER E, P242, DOI 10.1109/ISLPED.2013.6629302
   Liu XD, 2015, 4TH INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTER AND INFORMATION TECHNOLOGY NGCIT 2015, P15, DOI 10.1109/NGCIT.2015.8
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Miyashita Daisuke, 2016, ARXIV160301025
   Paszke Adam, 2017, P 2017 NIPS WORKSH
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Taha T., 2013, P 2013 INT JOINT C N
   Wang P, 2018, PROC CVPR IEEE, P5860, DOI 10.1109/CVPR.2018.00614
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yakopcic C., 2013, P 2013 INT JOINT C N
   Yu Ji, 2018, ACM SIGPLAN Notices, V53, P448, DOI 10.1145/3296957.3173205
   Zhou Shuchang, 2016, ARXIV160606160
   Zhuang B., 2017, ARXIV171100205
NR 28
TC 4
Z9 4
U1 1
U2 4
PD JUN
PY 2019
VL 15
IS 2
SI SI
AR 15
DI 10.1145/3304107
UT WOS:000495422200002
DA 2023-11-16
ER

PT C
AU Huang, NS
   Braun, JM
   Larsen, JC
   Manoonpong, P
AF Huang, Nan-Sheng
   Braun, Jan-Matthias
   Larsen, Jorgen Christian
   Manoonpong, Poramate
BE Jozwiak, L
   Stojanovic, R
   Lutovac, B
   Jurisic, D
TI A scalable Echo State Networks hardware generator for embedded systems
   using high-level synthesis
SO 2019 8TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO)
SE Mediterranean Conference on Embedded Computing
DT Proceedings Paper
CT 8th Mediterranean Conference on Embedded Computing (MECO)
CY JUN 10-14, 2019
CL Budva, MONTENEGRO
DE Neural Networks; Reservoir Computing; Echo State Networks; Hardware
   Accelerator; Embedded Systems; High-Level Synthesis
ID RESERVOIR
AB Reservoir computing (RC) features with the rich computational dynamics is a kind of powerful machine learning paradigm that is well suited for non-linear time-series prediction and classification problems. However, this impressive performance comes with a cost of complex arithmetic operations and high memory usage that make it significantly challenging to deploy on embedded systems. Solutions based on CPU and/or GPU-based designs, provides flexibility but suffers from a lack of efficiency in terms of power, performance, and area (PPA). Although hardware-accelerated solutions can improve efficiency, it takes longer design cycles and is time-consuming. Furthermore, it may happen that design spec requires run change due to the fact that the network is retrained with the new data set to improve the performance. It leads to extra effort in the redesign of the hardware-accelerated solution. This preliminary work presents the design and implementation of a hardware generator for RC-ESNs (echo state networks) to tackle the problem. The proposed methodology is demonstrated by various offline-trained network parameters and topologies. Compared to existing solutions, the proposed framework provides scalability with the support of DSE in agile hardware design.
C1 [Huang, Nan-Sheng; Braun, Jan-Matthias; Larsen, Jorgen Christian; Manoonpong, Poramate] Univ Southern Denmark, Maersk Mckinney Moller Inst, Embodied AI & Neurorobot Lab, Odense M, Denmark.
RP Huang, NS (corresponding author), Univ Southern Denmark, Maersk Mckinney Moller Inst, Embodied AI & Neurorobot Lab, Odense M, Denmark.
EM nan@mmmi.sdu.dk; j-mb@mmmi.sdu.dk; jcla@mmmi.sdu.dk; poma@mmmi.sdu.dk
CR Alomar M, 2017, NEURAL COMPUT APPL, V32, P1
   Alomar ML, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3917892
   Buchanan S., 2016, DESIGN FPGA IMPLEMEN
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dasgupta S, 2013, EVOL SYST-GER, V4, P235, DOI 10.1007/s12530-013-9080-y
   DeHon A, 2004, ANN IEEE SYM FIELD P, P13
   Gamma Erich, 1994, DESIGN PATTERNS ELEM, V1st
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Schuman C.D., 2017, SURVEY NEUROMORPHIC, Vabs/1705.06963
   Soures N, 2017, IEEE CONSUM ELECTR M, V6, P67, DOI 10.1109/MCE.2017.2685159
   Xilinx, 2017, VIVADO DESIGN SUITE
   Yi Y, 2016, MICROPROCESS MICROSY, V46, P175, DOI 10.1016/j.micpro.2016.03.009
NR 14
TC 3
Z9 3
U1 0
U2 1
PY 2019
BP 128
EP 133
UT WOS:000492146100039
DA 2023-11-16
ER

PT J
AU Inoue, A
   Miyoshi, T
   Ishihara, T
   Honda, Y
AF Inoue, Atsuki
   Miyoshi, Takashi
   Ishihara, Teruo
   Honda, Yasufumi
TI Innovative Computing for Solving Social Issues
SO FUJITSU SCIENTIFIC & TECHNICAL JOURNAL
DT Article
ID ACCELERATOR
AB Since the development of practical stored-program computers in the late 1940s, performance has risen amazingly by about 10(12) times over a period of 70 years. However, it is generally recognized that semiconductor transistor scaling is reaching its limits and that Moore's law is coming to an end. Regardless of these technical issues, the explosive increase in the amount of data generated in today's loT era is expected to continue, and it is highly anticipated that this data will be used to create new value and novel services. Meeting these expectations will therefore require improvements in performance independent of Moore's law. To address these issues, Fujitsu Laboratories proposes domain-specific computing as a new computing paradigm. The aim of domain-specific computing is to break through Moore's law by adopting 'architecture specific to the type of processing needed in fields such as knowledge processing whose objective is not to obtain rigorous numerical results. For example, in application to deep learning engines, high-speed image search engines, and machines dedicated to combinatorial optimization problems, domain-specific computing has demonstrated that it showed 50-12,000 times higher performance than that of conventional approaches. In this paper, we describe the direction of domain-specific computing as a new computing paradigm and present specific application examples.
C1 [Inoue, Atsuki; Miyoshi, Takashi; Ishihara, Teruo] Fujitsu Labs Ltd, Tokyo, Japan.
   [Honda, Yasufumi] Fujitsu Ltd, Tokyo, Japan.
RP Inoue, A (corresponding author), Fujitsu Labs Ltd, Tokyo, Japan.
CR Ike A, 2017, FUJITSU SCI TECH J, V53, P14
   Koomey JG, 2011, IEEE ANN HIST COMPUT, V33, P46, DOI 10.1109/MAHC.2010.28
   Koster U., 2017, ADV NEURAL INFORM PR, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Maruyama T., ISC 2017
   Micikevicius P., 2017, ARXIV171003740
   MOORE GE, 1965, ELECTRONICS, V38, DOI DOI 10.1109/N-SSC.2006.4785860
   Nihei M., 2016, IEICE TECHNICAL REPO, V116, P9
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Tsukamoto S, 2017, FUJITSU SCI TECH J, V53, P8
   Watanabe Y, 2017, FUJITSU SCI TECH J, V53, P20
NR 10
TC 0
Z9 0
U1 0
U2 2
PD OCT
PY 2018
VL 54
IS 5
BP 15
EP 21
UT WOS:000450542900004
DA 2023-11-16
ER

PT C
AU O'Neal, K
   Brisk, P
AF O'Neal, Kenneth
   Brisk, Philip
GP IEEE
TI Predictive Modeling for CPU, GPU, and FPGA Performance and Power
   Consumption: A Survey
SO 2018 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 17th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 09-11, 2018
CL Hong Kong Polytechn Univ, Hong Kong, HONG KONG
HO Hong Kong Polytechn Univ
DE CPU; GPU; FPGA; Predictive Model; Machine Learning; Accuracy; Error;
   Survey
AB CPUs and dedicated accelerators (namely GPUs and FPGAs) continue to grow increasingly large and complex to support todays demanding performance and power requirements. Designers are tasked with evaluating the performance and power of similarly increasingly large design spaces during pre-silicon design for CPUs and GPUs to reduce time-to-market and limit manufacturing costs, or to figure out how to best map applications onto FPGAs using high-level synthesis tools. Typically, cycle accurate simulators are used to evaluate workloads for pre-silicon CPUs and GPUs and to avoid the overhead of synthesis and place and-route when targeting FPGAs; however, simulators exhibit prohibitively long run times that limit the number of design points and workloads that can be evaluated in a reasonable timeframe.
   This survey focuses on predictive modeling as an alternative to cycle-accurate simulation, which enables rapid evaluation of workloads and design points. When applied properly, predictive modeling can improve time to market, and can facilitate more comprehensive design space explorations with far less overhead than simulation. The survey focuses on predictive models applied to CPUs, GPUs, and FPGAs, noting that the general approach has been applied to many other computing platforms as well.
C1 [O'Neal, Kenneth; Brisk, Philip] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
RP O'Neal, K (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
EM konea001@ucr.edu; philip@cs.ucr.edu
CR [Anonymous], 2010, HPCA 16 2010 16 INT, DOI DOI 10.1109/HPCA.2010.5416635
   [Anonymous], 2014, TUTORIAL PRINCIPAL C
   Ardalani N, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P725, DOI 10.1145/2830772.2830780
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Carlson T. E., 2011, SC 11 P 2011 INT C H, DOI DOI 10.1145/2063384.2063454
   Choi YK, 2017, ICCAD-IEEE ACM INT, P691
   Guo Q, 2016, IEEE T COMPUT AID D, V35, P433, DOI 10.1109/TCAD.2015.2481796
   Hoste K, 2006, I S WORKL CHAR PROC, P83
   Ipek E, 2006, ACM SIGPLAN NOTICES, V41, P195, DOI 10.1145/1168918.1168882
   Koeplinger D, 2016, CONF PROC INT SYMP C, P115, DOI 10.1109/ISCA.2016.20
   Lee BC, 2006, ACM SIGPLAN NOTICES, V41, P185, DOI [10.1145/1168917.1168881, 10.1145/1168919.1168881]
   Liu HY, 2013, 2013 15TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1, DOI 10.1109/ICCT.2013.6820340
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Nath R, 2013, IEEE SYMP COMP COMMU
   O'Neal K, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126557
   ONeal K., 2017, P 54 ANN DES AUT C 2, P1
   Palermo G, 2009, IEEE T COMPUT AID D, V28, P1816, DOI 10.1109/TCAD.2009.2028681
   Pellauer M, 2011, INT S HIGH PERF COMP, P406, DOI 10.1109/HPCA.2011.5749747
   Perelman E., 2003, Performance Evaluation Review, V31, P318, DOI 10.1145/885651.781076
   Sanchez Daniel, 2013, P 40 ANN INT S COMP, P475, DOI DOI 10.1145/2485922.2485963
   Skadron K., 2004, ACM T ARCHIT CODE OP, V1, P94, DOI DOI 10.1145/980152.980157
   Sujeeth A.K., 2011, ICML 11
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang S., 2017, MOLECULES, V22, P1, DOI DOI 10.1007/s00784-017-2197-9
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
   Wunderlich RE, 2003, CONF PROC INT SYMP C, P84, DOI 10.1109/ISCA.2003.1206991
   Yu K., 2006, P 23 INT C MACH LEAR, P1081
   Zheng XN, 2015, PROCEEDINGS INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS - ARCHITECTURES, MODELING AND SIMULATION (SAMOS XV), P52, DOI 10.1109/SAMOS.2015.7363659
   Zheng XF, 2016, ACSR ADV COMPUT, V66, P1
   Zhong GW, 2017, DES AUT TEST EUROPE, P1141, DOI 10.23919/DATE.2017.7927161
   Zhong Guanwen, 2016, DAC, P1
NR 32
TC 23
Z9 23
U1 0
U2 5
PY 2018
BP 763
EP 768
DI 10.1109/ISVLSI.2018.00143
UT WOS:000443443500133
DA 2023-11-16
ER

PT J
AU Dix, J
   Holleman, J
   Blalock, BJ
AF Dix, Jeff
   Holleman, Jeremy
   Blalock, Benjamin J.
TI Programmable Energy-Efficient Analog Multilayer Perceptron Architecture
   Suitable for Future Expansion to Hardware Accelerators
SO JOURNAL OF LOW POWER ELECTRONICS AND APPLICATIONS
DT Article
DE neural network; multilayer perceptron; energy efficient; analog; weak
   inversion; programmable
ID TRANSLINEAR CIRCUITS
AB A programmable, energy-efficient analog hardware implementation of a multilayer perceptron (MLP) is presented featuring a highly programmable system that offers the user the capability to create an MLP neural network hardware design within the available framework. In addition to programmability, this implementation provides energy-efficient operation via analog/mixed-signal design. The configurable system is made up of 12 neurons and is fabricated in a standard 130 nm CMOS process occupying approximately 1 mm2 of on-chip area. The system architecture is analyzed in several different configurations with each achieving a power efficiency of greater than 1 tera-operations per watt. This work offers an energy-efficient and scalable alternative to digital configurable neural networks that can be built upon to create larger networks capable of standard machine learning applications, such as image and text classification. This research details a programmable hardware implementation of an MLP that achieves a peak power efficiency of 5.23 tera-operations per watt while consuming considerably less power than comparable digital and analog designs. This paper describes circuit elements that can readily be scaled up at the system level to create a larger neural network architecture capable of improved energy efficiency.
C1 [Dix, Jeff] Univ Arkansas, Elect Engn Dept, Fayetteville, AR 72701 USA.
   [Holleman, Jeremy] Univ North Carolina Charlotte, Elect & Comp Engn Dept, Charlotte, NC 28262 USA.
   [Blalock, Benjamin J.] Univ Tennessee Knoxville, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.
RP Blalock, BJ (corresponding author), Univ Tennessee Knoxville, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.
EM dix@uark.edu; jhollem3@uncc.edu; bblalock@utk.edu
CR Al-Absi M. A., 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P13, DOI 10.1109/ICCCE.2012.6271143
   Binas J, 2020, Arxiv, DOI arXiv:1606.07786
   Duc-Thinh Nguyen-hoang, 2022, 2022 IEEE Ninth International Conference on Communications and Electronics (ICCE), P219, DOI 10.1109/ICCE55644.2022.9852060
   Gales M., 2015, MODULE 4F10 STAT PAT
   Gilbert B, 1996, ANALOG INTEGR CIRC S, V9, P95, DOI 10.1007/BF00166408
   GILBERT B, 1975, ELECTRON LETT, V11, P14, DOI 10.1049/el:19750011
   Gravati M, 2005, PROC EUR SOLID-STATE, P495, DOI 10.1109/ESSCIR.2005.1541668
   Harrison R., 2010, MOSFET OPERATION WEA
   Hasler P, 2005, FIFTH INTERNATIONAL WORKSHOP ON SYSTEM-ON-CHIP FOR REAL-TIME APPLICATIONS, PROCEEDINGS, P413, DOI 10.1109/IWSOC.2005.83
   LONT JB, 1992, IEEE T NEURAL NETWOR, V3, P457, DOI 10.1109/72.129418
   Lopez-Martin AJ, 2000, VLSI DES, V11, P321, DOI 10.1155/2000/21852
   Mackay D.J.C., 2003, INFORM THEORY INFERE
   MEAD CA, 1989, ADVANCED RESEARCH IN VLSI : PROCEEDINGS OF THE DECENNIAL CALTECH CONFERENCE ON VLSI, P1
   Minch BA, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, CONFERENCE PROCEEDINGS, P53
   Park SW, 2015, IEEE T BIOMED CIRC S, V9, P838, DOI 10.1109/TBCAS.2015.2504563
   Riedmiller M., 2009, MACHINE LEARNING MUL
   Sedra A.S., 1998, MICROELECTRONIC CIRC, VVolume 1
   Talaska T, 2016, IEEE T NEUR NET LEAR, V27, P661, DOI 10.1109/TNNLS.2015.2434847
   Tsai CH, 2017, IEEE J SOLID-ST CIRC, V52, P2601, DOI 10.1109/JSSC.2017.2715171
   Venkataramanaiah SK, 2020, INT SOC DESIGN CONF, P21, DOI 10.1109/ISOCC50952.2020.9333063
   Wunderlich RB, 2013, IEEE T VLSI SYST, V21, P1496, DOI 10.1109/TVLSI.2012.2211049
   Yüzügüler AC, 2019, IEEE MICRO, V39, P55, DOI 10.1109/MM.2019.2931182
   Zhang H., 2021, P 2021 IEEE 14 INT C, P1, DOI DOI 10.1109/ASICON52560.2021.9620305
NR 23
TC 1
Z9 1
U1 0
U2 0
PD SEP
PY 2023
VL 13
IS 3
AR 47
DI 10.3390/jlpea13030047
UT WOS:001075653000001
DA 2023-11-16
ER

PT C
AU Feng, HY
   Chen, PY
   Hou, JP
AF Feng, Hsin-Yu
   Chen, Po-Ying
   Hou, Janpu
GP IEEE
TI SR-ScatNet Algorithm for On-device ECG Time Series Anomaly Detection
SO SOUTHEASTCON 2021
SE IEEE SoutheastCon-Proceedings
DT Proceedings Paper
CT IEEEE Southeast Conference (SoutheastCon)
CY MAR 10-13, 2021
CL Atlanta, GA
DE Spectral Residual; Arrhythmia ECG; Smart Cloth
AB Anomaly detection of real-time ECG time series is of particular interest for early detection of cardiovascular disease for aging population. To use convolutional neural networks (CNN) for any on-device training or inference, you need GPU-accelerated hardware which will not only increase the hardware cost but also consume higher battery power. We proposed a SR-ScatNet algorithm for on-device application such as smart cloth with ECG monitoring sensors. Two improvements were made. First on spectral residual, we use Fourier Transform of autocorrelation of ECG signals instead of original time series to increase the sensitivity. Second on feature extraction, we use shallow wavelet scattering network (ScatNet) instead of deep CNN network so the on-device training can be performed on a simple Arm Cortex-A53 processor without any GPU-accelerator. These improvements are made to create a compact machine learning model according to the nature of different waves constituting the ECG signals. To verify the proposed method, we use the MIT-BIH Arrhythmia Database. The spectral residual of autocorrelation ECG signals can detect the abnormal ECG signals with over 98% accuracy. The wavelet scattering network can further classify the type of abnormality with over 90% accuracy. We believe the design of ECG monitoring smart cloth can benefit from such SR-ScatNet algorithm.
C1 [Feng, Hsin-Yu; Chen, Po-Ying] Natl Tsing Hua Univ, Dept Math, Hsinchu, Taiwan.
   [Hou, Janpu] Inst Data Learning, Appl Data Res, Las Vegas, NV USA.
RP Feng, HY (corresponding author), Natl Tsing Hua Univ, Dept Math, Hsinchu, Taiwan.
EM sabrina900118@gmail.com; bchenturkey@gmail.com; janpu@ieee.org
CR Feng Hsin-Yu, 2020, THESIS NATL TSING HU
   Hou D., 2020, 2020 IEEE INT C CONS, P1
   Kumar A, 2019, BIOMED ENG LETT, V9, P145, DOI [10.1007/s13534-018-0087-y, 10.1007/s13534-018-0087-y(0123456789().,-volV)(0123456789().,-volV)]
   Lu ZY, 2020, IEEE J-STARS, V13, P4311, DOI 10.1109/JSTARS.2020.3011992
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Prerau MJ, 2017, PHYSIOLOGY, V32, P60, DOI 10.1152/physiol.00062.2015
   Quiroz-Juárez MA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55448-5
   Xing Tony, 2019, STRAT DAT C NEW YORK STRAT DAT C NEW YORK
   Zhou HJ, 2019, IEEE ACCESS, V7, P175889, DOI 10.1109/ACCESS.2019.2957519
NR 9
TC 4
Z9 4
U1 0
U2 4
PY 2021
BP 736
EP 740
DI 10.1109/SOUTHEASTCON45413.2021.9401872
UT WOS:000685167800120
DA 2023-11-16
ER

PT J
AU Ahmadi, F
   Semati, MR
   Daryanavard, H
AF Ahmadi, Farshid
   Semati, Mohammad R.
   Daryanavard, Hassan
TI A Low-Power Improved-Accuracy Approximate Error-Report-Propagate Adder
   for DSP Applications
SO CIRCUITS SYSTEMS AND SIGNAL PROCESSING
DT Article; Early Access
DE Approximate computing; Approximate adder; High-speed integrated
   circuits; Low-power design; Digital signal processing (DSP);
   Error-report-propagate adder (ERPA)
ID DESIGN; VIDEO
AB Approximate computing is widely used as an efficient method in areas such as digital signal processing (DSP) and machine learning which are inherently error tolerant. This technique can increase the speed and reduce the energy consumption of the hardware at the expense of lower accuracy. As the performance of the adder used in a digital signal processor has a significant impact on its speed and power dissipation, this paper presents an approximate error-report-propagate adder (ERPA) in which error compensation occurs from the higher-value to the lower-value bits without any delay overhead. Furthermore, in microarchitectural level, a novel design methodology for implementing and synthesizing hardware accelerators is proposed. In this design, the approximate adders compensate for each other's error without any additional cost. Simulation results show that the proposed adders offer 17% reduction in the mean error distance compared to the other state-of-the-art approximate adders. Furthermore, a dense computational DSP task using the proposed approximate adders is presented. Compared to other conventional approximate adders, our approximation methodologies achieve 9.47%, 42%, and 26% improvements in quality, energy and area, respectively.
C1 [Ahmadi, Farshid; Semati, Mohammad R.; Daryanavard, Hassan] Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Iran.
RP Semati, MR (corresponding author), Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Iran.
EM farshidahmadi.stu@hormozgan.ac.ir; semati@hormozgan.ac.ir;
   h_daryanavard@hormozgan.ac.ir
CR Asadi MA, 2021, J AMB INTEL HUM COMP, V12, P7745, DOI 10.1007/s12652-020-02499-6
   Banerjee N, 2007, DES AUT TEST EUROPE, P630
   Bhaskaran V., 1997, IMAGE VIDEO COMPRESS
   Buck J. R, 1999, DISCRETE TIME SIGNAL, V2nd, P594
   Celia D, 2018, DES AUT TEST EUROPE, P1488, DOI 10.23919/DATE.2018.8342248
   Chen JJ, 2015, IEEE T CIRCUITS-I, V62, P224, DOI 10.1109/TCSI.2014.2348072
   Eshraghian K., 1993, PRINCIPLES CMOS VLSI
   Garg B, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2019), P296, DOI 10.1109/iSES47678.2019.00073
   Goel S, 2006, IEEE T VLSI SYST, V14, P1309, DOI 10.1109/TVLSI.2006.887807
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Jiang H., 2017, ACM J EMERG TECH COM, V13, P1, DOI DOI 10.1145/3094124
   Jothin R, 2020, MICROPROCESS MICROSY, V78, DOI 10.1016/j.micpro.2020.103237
   Kahng AB, 2012, DES AUT CON, P820
   Kheirandish D, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03292-w
   Kumm M, 2018, IEEE T CIRCUITS-II, V65, P567, DOI 10.1109/TCSII.2018.2823780
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Madanayake A, 2015, IEEE CIRC SYST MAG, V15, P25, DOI 10.1109/MCAS.2014.2385553
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Ning Zhu, 2010, Proceedings 2010 International SoC Design Conference (ISOCC 2010), P323, DOI 10.1109/SOCDC.2010.5682905
   Ning Zhu, 2009, 2009 12th International Symposium on Integrated Circuits (ISIC 2009), P69
   Pan Y, 2014, IEEE T CIRCUITS-I, V61, P455, DOI 10.1109/TCSI.2013.2278331
   Pashaeifar M, 2018, IEEE T VLSI SYST, V26, P2530, DOI 10.1109/TVLSI.2018.2859939
   Predictive Technology Model (PTM), AS ED
   Roy AS, 2020, IEEE T VLSI SYST, V28, P876, DOI 10.1109/TVLSI.2020.2967149
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Weste N.H., 2015, CMOS VLSI DESIGN CIR
   Xu WB, 2018, IEEE T VLSI SYST, V26, P1112, DOI 10.1109/TVLSI.2018.2803081
   Yang ZX, 2015, IEEE INT SYMP NANO, P145, DOI 10.1109/NANOARCH.2015.7180603
   Ye R, 2013, ICCAD-IEEE ACM INT, P48, DOI 10.1109/ICCAD.2013.6691096
   Zhang MY, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL V, P317
   Zhu N, 2010, IEEE T VLSI SYST, V18, P1225, DOI 10.1109/TVLSI.2009.2020591
NR 32
TC 3
Z9 3
U1 2
U2 3
PD 2023 JAN 24
PY 2023
DI 10.1007/s00034-023-02291-9
EA JAN 2023
UT WOS:000919813700001
DA 2023-11-16
ER

PT J
AU Inggs, G
   Thomas, DB
   Luk, W
AF Inggs, Gordon
   Thomas, David B.
   Luk, Wayne
TI A Domain Specific Approach to High Performance Heterogeneous Computing
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Distributed computing; programming environments; accelerator
   architectures; high performance computing; application software
ID INDEPENDENT TASKS; ALLOCATION
AB Users of heterogeneous computing systems face two problems: first, in understanding the trade-off relationships between the observable characteristics of their applications, such as latency and quality of the result, and second, how to exploit knowledge of these characteristics to allocate work to distributed computing platforms efficiently. A domain specific approach addresses both of these problems. By considering a subset of operations or functions, models of the observable characteristics or domain metrics may be formulated in advance, and populated at run-time for task instances. These metric models can then be used to express the allocation of work as a constrained integer program. These claims are illustrated using the domain of derivatives pricing in computational finance, with the domain metrics of workload latency and pricing accuracy. For a large, varied workload of 128 Black-Scholes and Heston model-based option pricing tasks, running upon a diverse array of 16 Multicore CPUs, GPUs and FPGAs platforms, predictions made by models of both the makespan and accuracy are generally within 10 percent of the run-time performance. When these models are used as inputs to machine learning and MILP-based workload allocation approaches, a latency improvement of up to 24 and 270 times over the heuristic approach is seen.
C1 [Inggs, Gordon; Thomas, David B.] Imperial Coll London, Dept Elect & Elect Engn, Circuits & Syst Grp, London SW7 2AZ, England.
   [Luk, Wayne] Imperial Coll London, Dept Comp, Custom Comp Grp, London SW7 2AZ, England.
RP Inggs, G (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, Circuits & Syst Grp, London SW7 2AZ, England.
EM gordon.e.inggs@ieee.org; d.thomas1@imperial.ac.uk; w.luk@imperial.ac.uk
CR Achterberg T, 2009, MATH PROGRAM COMPUT, V1, P1, DOI 10.1007/s12532-008-0001-1
   [Anonymous], 2006, TECH REP
   Berman F., 1996, SUPERCOMPUTING, P39
   Bixby R, 2007, ANN OPER RES, V149, P37, DOI 10.1007/s10479-006-0091-y
   Braun T. D., 2001, High Performance Computing - HiPC 2001. 8th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2238), P307
   Braun TD, 2001, J PARALLEL DISTR COM, V61, P810, DOI 10.1006/jpdc.2000.1714
   Chafi H, 2011, ACM SIGPLAN NOTICES, V46, P35, DOI 10.1145/2038037.1941561
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   CHU WW, 1980, COMPUTER, V13, P57, DOI 10.1109/MC.1980.1653419
   de Schryver Christian, 2011, Knowledge-Based and Intelligent Information and Engineering Systems. Proceedings 15th International Conference, KES 2011, P177, DOI 10.1007/978-3-642-23866-6_19
   Fisher N, 2005, 11TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P416, DOI 10.1109/RTCSA.2005.97
   Fowler M., 2010, DOMAIN SPECIFIC LANG
   Grewe D, 2011, LECT NOTES COMPUT SC, V6601, P286, DOI 10.1007/978-3-642-19861-8_16
   Hull JC, 2011, OPTIONS FUTURES OTHE
   IBARRA OH, 1977, J ACM, V24, P280, DOI 10.1145/322003.322011
   Inggs G., 2015, P INT WORKSH FPGAS S, Vabs/1506.06684
   Inggs G, 2013, PROC INT CONF PARAL, P688, DOI 10.1109/ICPP.2013.82
   Jones E., 2001, SCIPY OPEN SOURCE SC
   Kang QM, 2011, J SYST SOFTWARE, V84, P985, DOI 10.1016/j.jss.2011.01.051
   Karp R.M., 2010, REDUCIBILITY COMBINA
   KHOKHAR AA, 1993, COMPUTER, V26, P18, DOI 10.1109/2.214439
   Kidd T, 1996, SECOND INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS, AND NETWORKS (I-SPAN '96), PROCEEDINGS, P514, DOI 10.1109/ISPAN.1996.509034
   Kirlik G, 2014, EUR J OPER RES, V232, P479, DOI 10.1016/j.ejor.2013.08.001
   Koch T., 2004, THESIS
   Kuang SR, 2005, 11TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS WORKSHOPS, VOL II, PROCEEDINGS,, P37
   Nardi B.A., 1993, SMALL MATTER PROGRAM
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Tarplee KM, 2015, J PARALLEL DISTR COM, V84, P76, DOI 10.1016/j.jpdc.2015.07.002
   Thomas DB, 2007, ICFPT 2007: INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, PROCEEDINGS, P97
   van Deursen A, 2000, ACM SIGPLAN NOTICES, V35, P26, DOI 10.1145/352029.352035
NR 31
TC 6
Z9 6
U1 0
U2 12
PD JAN 1
PY 2017
VL 28
IS 1
BP 2
EP 15
DI 10.1109/TPDS.2016.2563427
UT WOS:000390676100002
DA 2023-11-16
ER

PT J
AU Amin, R
   George, JK
   Wang, H
   Maiti, R
   Ma, ZZ
   Dalir, H
   Khurgin, JB
   Sorger, VJ
AF Amin, Rubab
   George, Jonathan K.
   Wang, Hao
   Maiti, Rishi
   Ma, Zhizhen
   Dalir, Hamed
   Khurgin, Jacob B.
   Sorger, Volker J.
TI An ITO-graphene heterojunction integrated absorption modulator on
   Si-photonics for neuromorphic nonlinear activation
SO APL PHOTONICS
DT Article
ID MACH-ZEHNDER MODULATOR; ELECTROABSORPTION MODULATOR; DIRAC FERMIONS
AB The high demand for machine intelligence of doubling every three months is driving novel hardware solutions beyond charging of electrical wires, given a resurrection to application specific integrated circuit (ASIC)-based accelerators. These innovations include photonic-based ASICs (P-ASICs) due to prospects of performing optical linear (and also nonlinear) operations, such as multiply-accumulate for vector matrix multiplications or convolutions, without iterative architectures. Such photonic linear algebra enables picosecond delay when photonic integrated circuits are utilized via "on-the-fly" mathematics. However, the neuron's full function includes providing a nonlinear activation function, known as thresholding, to enable decision making on inferred data. Many P-ASIC solutions perform this nonlinearity in the electronic domain, which brings challenges in terms of data throughput and delay, thus breaking the optical link and introducing increased system complexity via domain crossings. This work follows the notion of utilizing enhanced light-matter interactions to provide efficient, compact, and engineerable electro-optic neuron nonlinearity. Here, we introduce and demonstrate a novel electro-optic device to engineer the shape of this optical nonlinearity to resemble a leaky rectifying linear unit-the most commonly used nonlinear activation function in neural networks. We combine the counter-directional transfer functions from heterostructures made out of two electro-optic materials to design a diode-like nonlinear response of the device. Integrating this nonlinearity into a photonic neural network, we show how the electrostatics of this thresholder's gating junction improves machine learning inference accuracy and the energy efficiency of the neural network. (c) 2021 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).
C1 [Amin, Rubab; George, Jonathan K.; Wang, Hao; Maiti, Rishi; Ma, Zhizhen; Dalir, Hamed; Sorger, Volker J.] George Washington Univ, Dept Elect & Comp Engn, 800 22nd St NW, Washington, DC 20052 USA.
   [Khurgin, Jacob B.] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.
RP Sorger, VJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, 800 22nd St NW, Washington, DC 20052 USA.
EM sorger@gwu.edu
CR Amin R, 2019, APL MATER, V7, DOI 10.1063/1.5109039
   Amin R, 2021, IEEE J SEL TOP QUANT, V27, DOI 10.1109/JSTQE.2020.3041835
   Amin R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80381-3
   Amin R, 2020, OPTICA, V7, P333, DOI 10.1364/OPTICA.389437
   Amin R, 2020, J LIGHTWAVE TECHNOL, V38, P282, DOI 10.1109/JLT.2019.2956719
   Amin R, 2018, APL PHOTONICS, V3, DOI 10.1063/1.5052635
   Amin R, 2018, OPT EXPRESS, V26, P15445, DOI 10.1364/OE.26.015445
   Amin R, 2018, NANOPHOTONICS-BERLIN, V7, P455, DOI 10.1515/nanoph-2017-0072
   Blumenthal DJ, 2018, NAT PHOTONICS, V12, P447, DOI 10.1038/s41566-018-0222-4
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Cheng Z, 2020, NANOPHOTONICS-BERLIN, V9, P2377, DOI 10.1515/nanoph-2019-0381
   Chiu Y., 2015, 2015 14 INT C OPT CO, P1
   de Lima TF, 2017, NANOPHOTONICS-BERLIN, V6, P577, DOI 10.1515/nanoph-2016-0139
   Dejonckheere A, 2014, OPT EXPRESS, V22, P10868, DOI 10.1364/OE.22.010868
   Dionne JA, 2009, NANO LETT, V9, P897, DOI 10.1021/nl803868k
   Esmaeilzadeh H, 2012, IEEE MICRO, V32, P122, DOI 10.1109/MM.2012.17
   George J., 2018, ADV PHOT 2018 BGPP I
   George S., 2021, ARXIV210210398
   Giambra MA, 2019, OPT EXPRESS, V27, P20145, DOI 10.1364/OE.27.020145
   Koh SK, 2006, THIN SOLID FILMS, V496, P81, DOI 10.1016/j.tsf.2005.08.251
   LeCun Y., 1998, MNIST DATABASE HANDW
   Lee KB, 2017, POWER SYST, P179, DOI 10.1007/978-981-10-4992-7_5
   Lee SH, 2012, MOL CRYST LIQ CRYST, V564, P185, DOI 10.1080/15421406.2012.691772
   Li W, 2014, NANO LETT, V14, P955, DOI 10.1021/nl404356t
   Liu JH, 2016, NANOSCALE RES LETT, V11, DOI 10.1186/s11671-016-1323-y
   Liu M, 2011, NATURE, V474, P64, DOI 10.1038/nature10067
   Liu XG, 2018, ACS PHOTONICS, V5, P4484, DOI 10.1021/acsphotonics.8b00945
   Ma PY, 2017, OPT EXPRESS, V25, P33504, DOI 10.1364/OE.25.033504
   Ma ZZ, 2020, ACS PHOTONICS, V7, P932, DOI 10.1021/acsphotonics.9b01452
   Ma ZZ, 2017, IEEE J SEL TOP QUANT, V23, DOI 10.1109/JSTQE.2016.2574306
   Mesaritakis C, 2016, SCI REP-UK, V6, DOI 10.1038/srep39317
   Miscuglio M, 2018, OPT MATER EXPRESS, V8, P3851, DOI 10.1364/OME.8.003851
   Moscoso-Mártir A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12023-0
   Nagamine T, 2016, INTERSPEECH, P803, DOI 10.21437/Interspeech.2016-1406
   Novoselov KS, 2005, NATURE, V438, P197, DOI 10.1038/nature04233
   Nozaki K, 2017, APL PHOTONICS, V2, DOI 10.1063/1.4980036
   Peng HT, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2840448
   Rajput S, 2020, J LIGHTWAVE TECHNOL, V38, P1365, DOI 10.1109/JLT.2019.2953690
   Reed GT, 2014, NANOPHOTONICS-BERLIN, V3, P229, DOI 10.1515/nanoph-2013-0016
   Shastri BJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep19126
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Shu HW, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19171-x
   Sorger VJ, 2012, NANOPHOTONICS-BERLIN, V1, P17, DOI 10.1515/nanoph-2012-0009
   Tahersima MH, 2019, NANOPHOTONICS-BERLIN, V8, P1559, DOI 10.1515/nanoph-2019-0153
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Tu XG, 2011, OPT EXPRESS, V19, P18029, DOI 10.1364/OE.19.018029
   Yoo S, 2016, ACS NANO, V10, P4274, DOI 10.1021/acsnano.5b07747
   Zhou SY, 2006, NAT PHYS, V2, P595, DOI 10.1038/nphys393
   Zhu SY, 2013, OPT EXPRESS, V21, P8320, DOI 10.1364/OE.21.008320
NR 50
TC 18
Z9 18
U1 3
U2 17
PD DEC 1
PY 2021
VL 6
IS 12
AR 120801
DI 10.1063/5.0062830
UT WOS:000729400900002
DA 2023-11-16
ER

PT J
AU Ngo, DM
   Lightbody, D
   Temko, A
   Pham-Quoc, C
   Tran, NT
   Murphy, CC
   Popovici, E
AF Ngo, Duc-Minh
   Lightbody, Dominic
   Temko, Andriy
   Pham-Quoc, Cuong
   Tran, Ngoc-Thinh
   Murphy, Colin C. C.
   Popovici, Emanuel
TI HH-NIDS: Heterogeneous Hardware-Based Network Intrusion Detection
   Framework for IoT Security
SO FUTURE INTERNET
DT Article
DE network security; artificial neural Networks; hardware accelerators; low
   power; high-performance; microcontrollers; CPU; GPU; FPGA
AB This study proposes a heterogeneous hardware-based framework for network intrusion detection using lightweight artificial neural network models. With the increase in the volume of exchanged data, IoT networks' security has become a crucial issue. Anomaly-based intrusion detection systems (IDS) using machine learning have recently gained increased popularity due to their generation's ability to detect unseen attacks. However, the deployment of anomaly-based AI-assisted IDS for IoT devices is computationally expensive. A high-performance and ultra-low power consumption anomaly-based IDS framework is proposed and evaluated in this paper. The framework has achieved the highest accuracy of 98.57% and 99.66% on the UNSW-NB15 and IoT-23 datasets, respectively. The inference engine on the MAX78000EVKIT AI-microcontroller is 11.3 times faster than the Intel Core i7-9750H 2.6 GHz and 21.3 times faster than NVIDIA GeForce GTX 1650 graphics cards, when the power drawn was 18mW. In addition, the pipelined design on the PYNQ-Z2 SoC FPGA board with the Xilinx Zynq xc7z020-1clg400c device is optimised to run at the on-chip frequency (100 MHz), which shows a speedup of 53.5 times compared to the MAX78000EVKIT.
C1 [Ngo, Duc-Minh; Lightbody, Dominic; Temko, Andriy; Murphy, Colin C. C.; Popovici, Emanuel] Univ Coll Cork, Elect & Elect Engn, Cork T12 K8AF, Ireland.
   [Pham-Quoc, Cuong; Tran, Ngoc-Thinh] Ho Chi Minh City Univ Technol HCMUT, Comp Sci & Engn, VNU HCM, 268 Ly Thuong Kiet St,Dist 10, Ho Chi Minh City 740050, Vietnam.
RP Ngo, DM; Murphy, CC (corresponding author), Univ Coll Cork, Elect & Elect Engn, Cork T12 K8AF, Ireland.; Pham-Quoc, C (corresponding author), Ho Chi Minh City Univ Technol HCMUT, Comp Sci & Engn, VNU HCM, 268 Ly Thuong Kiet St,Dist 10, Ho Chi Minh City 740050, Vietnam.
EM 120220051@umail.ucc.ie; cuongpham@hcmut.edu.vn; colinmurphy@ucc.ie
CR Ahmed M, 2016, J NETW COMPUT APPL, V60, P19, DOI 10.1016/j.jnca.2015.11.016
   Alani MM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155690
   Alsoufi MA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188383
   [Anonymous], XUP PYNQ Z2
   Antonopoulos CP, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6030054
   Bovenzi G, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348167
   Cheour R., 2020, P IEEE 6 WORLD FORUM, P1
   d'Orazio L., 2018, OPEN J INTERNET THIN, V4, P150
   Douiba M, 2023, J SUPERCOMPUT, V79, P3392, DOI 10.1007/s11227-022-04783-y
   Ngo DM, 2021, I C FIELD PROG LOGIC, P69, DOI 10.1109/FPL53798.2021.00020
   Dutta V, 2020, J UNIVERS COMPUT SCI, V26, P1422
   Dutta V, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164583
   Expertsystem, WHAT IS MACH LEARN D
   Gao CY, 2019, PALG STUD GLOB HIGHE, P1, DOI 10.1007/978-3-030-21465-4_1
   García-Teodoro P, 2009, COMPUT SECUR, V28, P18, DOI 10.1016/j.cose.2008.08.003
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Hegde Mandira, 2020, 2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA), P21, DOI 10.1109/IDSTA50958.2020.9264143
   Heidari A, 2023, CLUSTER COMPUT, V26, P3753, DOI 10.1007/s10586-022-03776-z
   Hossin M., 2015, INT J DATA MINING KN, V5, P1, DOI [10.5121/ijdkp.2015.5201, DOI 10.5121/IJDKP.2015.5201]
   Hubballi N, 2014, COMPUT COMMUN, V49, P1, DOI 10.1016/j.comcom.2014.04.012
   Hussain FB, 2020, ARXIV
   Idhammad M, 2017, INT J ADV COMPUT SC, V8, P465
   Integrated M., MAX78000 ART INT MIC
   Integrated M., MAX78000EVKIT EV KIT
   Ioannou L, 2019, I C FIELD PROG LOGIC, P232, DOI 10.1109/FPL.2019.00043
   Kalantar A, 2021, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM51124.2021.00013
   Kumar P, 2021, AUTOM CONTROL COMPUT, V55, P137, DOI 10.3103/S0146411621020085
   Kumar KS, 2017, 2017 3RD IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P151, DOI 10.1109/iNIS.2017.39
   Maitra S, 2019, 2019 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)
   Manimurugan S, 2020, IEEE ACCESS, V8, P77396, DOI 10.1109/ACCESS.2020.2986013
   Mishra A., 2020, P 2 INT C DAT ENG AP, P1, DOI 10.1109/IDEA49133.2020.9170674
   Mothukuri V, 2022, IEEE INTERNET THINGS, V9, P2545, DOI 10.1109/JIOT.2021.3077803
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Nobakht M, 2022, EVOL SYST-GER, DOI 10.1007/s12530-022-09471-z
   Parmisano A., 2020, IOT 23 LABELED DATAS
   Protogerou A, 2021, EVOL SYST-GER, V12, P19, DOI 10.1007/s12530-020-09347-0
   Sidana M., TYPES CLASSIFICATION
   Stoian N.-A., 2020, THESIS U TWENTE ENSC
   Storcheus D., 2015, JMLR WORKSHOP C P, P1
   Thamaraiselvi D., 2020, INT J COMPUT SCI MOB, V9, P95, DOI [10.47760/ijcsmc.2020.v09i10.012, DOI 10.47760/IJCSMC.2020.V09I10.012]
   Nguyen TD, 2019, INT CON DISTR COMP S, P756, DOI 10.1109/ICDCS.2019.00080
   Ullah I, 2022, IEEE ACCESS, V10, P62722, DOI 10.1109/ACCESS.2022.3176317
   Vaccari I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226578
   Vailshery L., NUMBER INTERNET THIN
   van Long N.H., 2020, P INT WORKSHOP VERY
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Wielgosz M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132981
   Xu CY, 2018, IEEE ACCESS, V6, P48697, DOI 10.1109/ACCESS.2018.2867564
   Yang Z, 2022, COMPUT SECUR, V116, DOI 10.1016/j.cose.2022.102675
   Yin CY, 2022, IEEE T SYST MAN CY-S, V52, P112, DOI 10.1109/TSMC.2020.2968516
NR 50
TC 3
Z9 3
U1 0
U2 3
PD JAN
PY 2023
VL 15
IS 1
AR 9
DI 10.3390/fi15010009
UT WOS:000917572800001
DA 2023-11-16
ER

PT C
AU Dupuis, E
   Novo, D
   O'Connor, I
   Bosio, A
AF Dupuis, Etienne
   Novo, David
   O'Connor, Ian
   Bosio, Alberto
GP IEEE
TI Sensitivity Analysis and Compression Opportunities in DNNs Using Weight
   Sharing
SO 2020 23RD INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS & SYSTEMS (DDECS 2020)
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 23rd IEEE International Symposium on Design and Diagnostics of
   Electronic Circuits and Systems (DDECS)
CY APR 22-24, 2020
CL Univ Novi Sad, Novi Sad, SERBIA
HO Univ Novi Sad
DE Deep Neural Networks; Approximate Computing; Model Compression; Weight
   Sharing; Design Space Exploration; Embedded System; Hardware Accelerator
AB Deep artificial Neural Networks (DNNs) are currently one of the most intensively and widely used predictive models in the field of machine learning. However, the computational workload involved in DNNs is typically out of reach for lowpower embedded devices. The approximate computing paradigm can be exploited to reduce the DNN complexity. It improves performance and energy-efficiency by relaxing the need for fully accurate operations. There are a large number of implementation options leveraging many approximation techniques (e.g., pruning, quantization, weight-sharing, low-rank factorization, knowledge distillation, etc.). However, to the best of our knowledge, a few or no automated approach exists to explore, select and generate the best approximate version of a given DNN according to design objectives. The goal of this paper is to demonstrate that the design space exploration phase can enable significant network compression without noticeable accuracy loss. We demonstrate this via an example based on weight sharing and show that our direct conversion method can obtain a 4.85x compression rate with 0.14% accuracy loss in ResNetl8 and 4.91x compression rate with 0.44% accuracy loss in SqueezeNet without involving retraining steps.
C1 [Dupuis, Etienne; O'Connor, Ian; Bosio, Alberto] Ecole Cent Lyon, Inst Nanotechnol Lyon, Lyon, France.
   [Novo, David] Univ Montpellier, CNRS, LIRMM, Montpellier, France.
RP Dupuis, E (corresponding author), Ecole Cent Lyon, Inst Nanotechnol Lyon, Lyon, France.
EM etienne.dupuis@ec-lyon.fr; david.novo@lirmm.fr; ian.oconnor@ec-lyon.fr;
   alberto.bosio@ec-lyon.fr
CR Acharya A., 2018, ONLINE EMBEDDING COM
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   [Anonymous], 2015, CORR
   [Anonymous], 2014, COMPRESSING DEEP CON
   Arvin AM, 2009, LIVE VARIOLA VIRUS: CONSIDERATIONS FOR CONTINUING RESEARCH, P9
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Baskin C., 2018, UNIQ UNIFORM NOISE I
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Dupuis E., 2020, P DATE2020
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hinton G., 2014, P ADV NEUR INF PROC
   Iandola F.N., 2016, CORR ABS160207360
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Razlighi MS, 2017, DES AUT TEST EUROPE, P1775, DOI 10.23919/DATE.2017.7927280
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Ullrich K., 2017, ABS170204008 ARXIV
   Wu J., 2018, DEEP K MEANS RETRAIN
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
NR 20
TC 7
Z9 7
U1 0
U2 0
PY 2020
DI 10.1109/ddecs50862.2020.9095658
UT WOS:000587761500014
DA 2023-11-16
ER

PT C
AU Mills, AP
AF Mills, Allen P., Jr.
GP AIP
TI Proposal for a slow positron facility at Jefferson National Laboratory
SO INTERNATIONAL WORKSHOP ON PHYSICS WITH POSITRONS AT JEFFERSON LAB
SE AIP Conference Proceedings
DT Proceedings Paper
CT International Workshop on Positron Physics at Jefferson Lab (JPos)
CY SEP 12-17, 2017
CL Newport News, VA
ID BRIGHTNESS ENHANCEMENT; ANNIHILATION; DIFFRACTION; CRYSTAL; REEMISSION
AB One goal of the JPos-17 International Workshop on Physics with Positrons was to ascertain whether it would be a good idea to expand the mission of the Thomas Jefferson National Accelerator Facility (JLab) to include science with low energy (i.e. "slow") spin polarized positrons. It is probably true that experimentation with slow positrons would potentially have wide-ranging benefits comparable to those obtained with neutron and x-ray scattering, but it is certain that the full range of these benefits will never be fully available without an infrastructure comparable to that of existing neutron and x-ray facilities. The role for Jefferson Laboratory would therefore be to provide and maintain (1) a dedicated set of machines for making and manipulating high intensity, high brightness beams of polarized slow positrons; (2) a suite of unique and easily used instruments of wide utility that will make efficient use of the positrons; and (3) a group of on-site positron scientists to provide scientific leadership, instrument development, and user support. In this note some examples will be given of the science that might make a serious investment in a positron facility worthwhile. At the same time, the lessons learned from various proposed and successful positron facilities will be presented for consideration.
C1 [Mills, Allen P., Jr.] Univ Calif Riverside, Riverside, CA 92521 USA.
RP Mills, AP (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM allen.mills@ucr.edu
CR Abbott D, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.214801
   Barbiellini B, 2006, NEW J PHYS, V8, DOI 10.1088/1367-2630/8/2/020
   BERKO S, 1980, SCRIPTA METALL MATER, V14, P23, DOI 10.1016/0036-9748(80)90118-0
   Berko S., 1981, POSITRON SOLID STATE, P64
   Biasini M, 2006, J PHYS-CONDENS MAT, V18, pL289, DOI 10.1088/0953-8984/18/22/L03
   BRANDES GR, 1988, REV SCI INSTRUM, V59, P228, DOI 10.1063/1.1140231
   BRANDES GR, 1988, PHYS REV LETT, V61, P492, DOI 10.1103/PhysRevLett.61.492
   CANTER KF, 1982, CAN J PHYS, V60, P551, DOI 10.1139/p82-071
   CANTER KF, 1972, J PHYS PT B ATOM M P, V5, pL167, DOI 10.1088/0022-3700/5/8/007
   Cassidy DB, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.173401
   Cassidy DB, 2001, PHYS REV C, V64, DOI 10.1103/PhysRevC.64.054603
   Chen Y., 1993, CONF9209221 DOE
   Cherry W. H., 1958, THESIS
   Davisson C, 1927, PHYS REV, V30, P705, DOI 10.1103/PhysRev.30.705
   Dil JH, 2009, J PHYS-CONDENS MAT, V21, DOI 10.1088/0953-8984/21/40/403001
   Eberle C., 1994, CONF9405170
   FRIEZE WE, 1985, PHYS REV B, V31, P5628, DOI 10.1103/PhysRevB.31.5628
   Fukaya Y, 2014, APPL PHYS EXPRESS, V7, DOI 10.7567/APEX.7.056601
   Gidley DW, 1999, PHYS REV B, V60, pR5157, DOI 10.1103/PhysRevB.60.R5157
   Golge S, 2014, J APPL PHYS, V115, DOI 10.1063/1.4884781
   HORSKY TN, 1989, PHYS REV LETT, V62, P1876, DOI 10.1103/PhysRevLett.62.1876
   Howell R. H., 1997, AIP C P, V392, P451, DOI [10.1063/1.52486, DOI 10.1063/1.52486]
   Hugenschmidt C, 2016, SURF SCI REP, V71, P547, DOI 10.1016/j.surfrep.2016.09.002
   Hulett LD, 1997, ACCELERATOR-BASED ATOMIC PHYSICS TECHNIQUES AND APPLICATIONS, P637
   JACKSON JD, 1957, PHYS REV, V106, P517, DOI 10.1103/PhysRev.106.517
   Jones ACL, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.216402
   Jones ACL, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.153201
   KOSSLER WJ, 1994, AIP CONF PROC, P296, DOI 10.1063/1.45513
   LEE KH, 1994, PHYS REV LETT, V72, P1866, DOI 10.1103/PhysRevLett.72.1866
   LEE TD, 1956, PHYS REV, V104, P254, DOI 10.1103/PhysRev.104.254
   LOCK DG, 1973, J PHYS F MET PHYS, V3, P561, DOI 10.1088/0305-4608/3/3/014
   LYNN KG, 1994, HYPERFINE INTERACT, V89, P19, DOI 10.1007/BF02064493
   MACKENZIE IK, 1967, PHYS REV LETT, V19, P946, DOI 10.1103/PhysRevLett.19.946
   MADANSKY L, 1950, PHYS REV, V79, P397, DOI 10.1103/PhysRev.79.397
   Mills AP, 2011, RIV NUOVO CIMENTO, V34, P151, DOI 10.1393/ncr/i2011-10064-5
   Mills AP, 2001, NEW DIRECTIONS IN ANTIMATTER CHEMISTRY AND PHYSICS, P115
   MILLS AP, 1980, APPL PHYS, V23, P189, DOI 10.1007/BF00899716
   MILLS AP, 1986, APPL PHYS LETT, V49, P1121, DOI 10.1063/1.97441
   Mills Jr A. P., 1994, AIP C P, V303, P335
   Mukherjee S, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4943858
   Peng P. J., 1996, PHYS REV LETT, V76, P2157
   ROSENBERG IJ, 1980, PHYS REV LETT, V44, P1139, DOI 10.1103/PhysRevLett.44.1139
   SCHULTZ PJ, 1986, PHYS REV B, V34, P442, DOI 10.1103/PhysRevB.34.442
   Stoeffl W, 1999, APPL SURF SCI, V149, P1, DOI 10.1016/S0169-4332(99)00162-2
   VEHANEN A, 1983, APPL PHYS A-MATER, V32, P163, DOI 10.1007/BF00616613
   Wagner A, 2017, J PHYS CONF SER, V791, DOI 10.1088/1742-6596/791/1/012004
   Xu J, 1997, APPL SURF SCI, V116, P34, DOI 10.1016/S0169-4332(96)00970-1
   ZITZEWITZ PW, 1979, PHYS REV LETT, V43, P1281, DOI 10.1103/PhysRevLett.43.1281
NR 48
TC 2
Z9 2
U1 0
U2 5
PY 2018
VL 1970
AR 040002
DI 10.1063/1.5040214
UT WOS:000445098200020
DA 2023-11-16
ER

PT C
AU Peng, XC
   Liu, R
   Yu, SM
AF Peng, Xiaochen
   Liu, Rui
   Yu, Shimeng
GP IEEE
TI Optimizing Weight Mapping and Data Flow for Convolutional Neural
   Networks on RRAM based Processing-In-Memory Architecture
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
DE non-volatile memory; processing-in-memory; machine learning; deep neural
   network; hardware accelerator
AB Resistive random access memory (RRAM) based array architecture has been proposed for on-chip acceleration of convolutional neural networks (CNNs), where the array could be configured for dot-product computation in a parallel fashion by summing up the column currents. Prior processing-in-memory (PIM) designs unroll each 3D kernel of the convolutional layers into a vertical column of a large weight matrix, where the input data will be accessed multiple times. As a result, significant latency and energy are consumed in interconnect and buffer. In this paper, in order to maximize both weight and input data reuse for RRAM based PIM architecture, we propose a novel weight mapping method and the corresponding data flow which divides the kernels and assign the input data into different processing-elements (PEs) according to their spatial locations. The proposed design achieves similar to 65% save in latency and energy for interconnect and buffer, and yields overall 2.1x speed up and similar to 17% improvement in the energy efficiency in terms of TOPS/W for VGG-16 CNN, compared with the prior design based on the conventional mapping method.
C1 [Peng, Xiaochen; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Liu, Rui] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR [Anonymous], 2018, IEEE T COMPUTER AIDE
   Chen PY, 2016, IEEE INT SYMP CIRC S, P2310, DOI 10.1109/ISCAS.2016.7539046
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K., 2015, 3 INT C LEARNING REP, P1
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
NR 11
TC 39
Z9 39
U1 0
U2 3
PY 2019
UT WOS:000483076402181
DA 2023-11-16
ER

PT J
AU Truong, MSQ
   Shen, LT
   Glass, A
   Hoffmann, A
   Carley, LR
   Bain, JA
   Ghose, S
AF Truong, Minh S. Q.
   Shen, Liting
   Glass, Alexander
   Hoffmann, Alison
   Carley, L. Richard
   Bain, James A.
   Ghose, Saugata
TI Adapting the RACER Architecture to Integrate Improved In-ReRAM Logic
   Primitives
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Computer architecture; Microprocessors; Resistance; Logic arrays; Random
   access memory; Topology; Voltage; Accelerator architectures; memory
   architecture; resistive RAM
ID MEMORY; OPERATIONS; MEMRISTOR; CHALLENGES
AB Modern computing applications based upon machine learning can incur significant data movement overheads in state-of-the-art computers. Resistive-memory-based processing-using-memory (PUM) can mitigate this data movement by instead performing computation in situ (i.e., directly within memory cells), but device-level limitations restrict the practicality and/or performance of many PUM architecture proposals. The RACER architecture overcomes these limitations, by proposing efficient peripheral circuitry and the concept of bit-pipelining to enable high-performance, high-efficiency computation using small memory tiles. In this work, we extend RACER to adapt easily to different PUM logic families, by (1) modifying the device access circuitry to support a wide range of logic families, (2) evaluating three logic families proposed by prior work, and (3) proposing and evaluating a new logic family called OSCAR that significantly relaxes the switching voltage constraints required to perform logic with resistive memory devices. We show that the modified RACER architecture, using the OSCAR logic family, can enable practical PUM on real ReRAM devices while improving performance and energy savings by 30% and 37%, respectively, over the original RACER work.
C1 [Truong, Minh S. Q.; Shen, Liting; Glass, Alexander; Hoffmann, Alison; Carley, L. Richard; Bain, James A.] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
   [Ghose, Saugata] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
RP Ghose, S (corresponding author), Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
EM minhsyqt@andrew.cmu.edu; ghose@illinois.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Angizi S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317764
   Angizi S, 2018, DES AUT CON, DOI 10.1145/3195970.3196009
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2018, PROC 55 ACMESDAIEEE
   ARCANA Research Group, 2021, RACER Artifacts-Zenodo Repository, DOI 10.5281/zenodo.5495803
   BATCHER KE, 1982, IEEE T COMPUT, V31, P377, DOI 10.1109/TC.1982.1676015
   Bhanushali K., 2015, P 2015 S INT S PHYS, P165
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3296957.3173177, 10.1145/3173162.3173177]
   Chen A, 2016, SOLID STATE ELECTRON, V125, P25, DOI 10.1016/j.sse.2016.07.006
   Chen YY, 2012, 2012 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   Chung-Wei Hsu, 2013, 2013 Symposium on VLSI Technology, pT166
   Dally W. J., 2015, HIPEAC KEYN, P1
   Dong XY, 2008, DES AUT CON, P554
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   El-Kady M. A., 1983, IEEE POWER ENG REV, P46
   Fantini A, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P30, DOI 10.1109/IMW.2013.6582090
   Fujiki D, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P397, DOI 10.1145/3307650.3322257
   Gaillardon PE, 2016, DES AUT TEST EUROPE, P427
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Gupta S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240811
   Hajinazar N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P329, DOI 10.1145/3445814.3446749
   Hamdioui S, 2017, DES AUT TEST EUROPE, P722, DOI 10.23919/DATE.2017.7927083
   Hamdioui S, 2015, DES AUT TEST EUROPE, P1718
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Intel Corp, INT XEON PLAT 8253
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Kang U, 2014, PROC MEMORY FORUM
   Kestor G, 2013, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2013.6704670
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Kvatinsky S, 2014, IEEE T VLSI SYST, V22, P2054, DOI 10.1109/TVLSI.2013.2282132
   Kvatinsky S, 2011, 2011 IEEE 29TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P142, DOI 10.1109/ICCD.2011.6081389
   Levy Y, 2014, MICROELECTRON J, V45, P1429, DOI 10.1016/j.mejo.2014.06.006
   Li BX, 2015, DES AUT CON, DOI 10.1145/2744769.2744870
   Li SC, 2016, DES AUT CON, DOI [10.1109/ICAUMS.2016.8479697, 10.1145/2897937.2898064]
   Liu R, 2015, IEEE ELECTR DEVICE L, V36, P1380, DOI 10.1109/LED.2015.2496257
   Louis J, 2019, IEEE I C ELECT CIRC, P787, DOI [10.1109/icecs46596.2019.8965179, 10.1109/ICECS46596.2019.8965179]
   Maiti DK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13754-w
   Makarov A, 2012, MICROELECTRON RELIAB, V52, P628, DOI 10.1016/j.microrel.2011.10.020
   Mandelman JA, 2002, IBM J RES DEV, V46, P187, DOI 10.1147/rd.462.0187
   Minh SQ, 2021, ANN INT S MICROARCHI, P100
   Mutlu O, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P21, DOI 10.1109/IMW.2013.6582088
   NVIDIA Corp, GEF RTX 2070
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Seshadri V, 2017, ADV COMPUT, V106, P107, DOI 10.1016/bs.adcom.2017.04.004
   Seung Ryul Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P71, DOI 10.1109/VLSIT.2012.6242466
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Wang J, 2014, I SYMPOS LOW POWER E, P339, DOI 10.1145/2627369.2627610
   Weste N., 2011, CIRCUITS SYSTEMS PER, V4th
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Woo J, 2016, IEEE ELECTR DEVICE L, V37, P994, DOI 10.1109/LED.2016.2582859
   Xie L, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P335, DOI 10.1109/ICCD.2015.7357122
   Ye C, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/10/105005
   Yu JT, 2018, DES AUT TEST EUROPE, P1646, DOI 10.23919/DATE.2018.8342278
   Yu SM, 2016, INT EL DEVICES MEET
   Zha Y, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P51, DOI 10.1145/31742433174244
NR 62
TC 0
Z9 0
U1 2
U2 5
PD JUN
PY 2022
VL 12
IS 2
BP 393
EP 407
DI 10.1109/JETCAS.2022.3171765
UT WOS:000811585100009
DA 2023-11-16
ER

PT C
AU Chang, YN
   Chen, GJ
AF Chang, Yun-Nan
   Chen, Guan-Jhen
GP IEEE
TI Design of A Bit-Serial Artificial Neuron VLSI Architecture with Early
   Termination
SO 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND
   COMMUNICATION (ICEIC)
DT Proceedings Paper
CT 18th Annual International Conference on Electronics, Information, and
   Communication (ICEIC)
CY JAN 22-25, 2019
CL Inst Elect & Informat Engineers, Auckland, NEW ZEALAND
HO Inst Elect & Informat Engineers
DE Neuron; nerual network; CNN; most significant bit; bit-serial
AB In this paper, a VLSI design of a bit-serial artificial neuron circuit is proposed. Different from the ordinary bit-serial architectures which usually start from the least significant bit (LSB), the proposed design will start from processing the most significant bit (MSB). For the MSB-first approach, the more significant part of results will be generated earlier, and the intermediate results will be progressively refined by processing the less significant bits. An artificial neuron is equipped with an activation function at the output, and many common used activation functions such as sigmoid, a rectified linear unit (ReLU) etc will saturate to 0 for large negative inputs. Some will saturate to 1 for large positive inputs. Therefore, when the intermediate results are positive or negative enough, the remaining processing of less significant bits can be neglected. Our preliminary results shows that the approximation results due to the proposed early termination can still lead to the same classification accuracy as the full precision, but the processing cycles can be reduced by more than 25%. The proposed methodology can be applied to the design of hardware accelerators for those machine learning networks based on neurons such as neural network (NN) and convolution NN (CNN).
C1 [Chang, Yun-Nan; Chen, Guan-Jhen] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung, Taiwan.
RP Chang, YN (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung, Taiwan.
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Choi Y, 2017, IEEE T CIRCUITS-II, V64, P1332, DOI 10.1109/TCSII.2017.2691771
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Judd P, 2017, IEEE COMPUT ARCHIT L, V16, P80, DOI 10.1109/LCA.2016.2597140
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
NR 11
TC 0
Z9 0
U1 1
U2 1
PY 2019
BP 503
EP 505
DI 10.23919/elinfocom.2019.8706444
UT WOS:000470015800128
DA 2023-11-16
ER

PT C
AU Yik, J
   Kuppannagari, SR
   Zeng, HQ
   Prasanna, VK
AF Yik, Jason
   Kuppannagari, Sanmukh R.
   Zeng, Hanqing
   Prasanna, Viktor K.
GP IEEE
TI Input Feature Pruning for Accelerating GNN Inference on Heterogeneous
   Platforms
SO 2022 IEEE 29TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS, HIPC
SE International Conference on High Performance Computing
DT Proceedings Paper
CT 29th Annual IEEE International Conference on High Performance Computing,
   Data, and Analytics (HiPC)
CY DEC 18-21, 2022
CL Bangalore, INDIA
DE data science algorithms; graph neural network; accuracy/performance
   trade-off; input feature pruning
AB Graph Neural Networks (GNNs) are an emerging class of machine learning models which utilize structured graph information and node features to reduce high-dimensional input data to low-dimensional embeddings, from which predictions can be made. Due to the compounding effect of aggregating neighbor information, GNN inferences require raw data from many times more nodes than are targeted for prediction. Thus, on heterogeneous compute platforms, inference latency can be largely subject to the inter-device communication cost of transferring input feature data to the GPU/accelerator before computation has even begun. In this paper, we analyze the trade-off effect of pruning input features from GNN models, reducing the volume of raw data that the model works with to lower communication latency at the expense of an expected decrease in the overall model accuracy. We develop greedy and regression-based algorithms to determine which features to retain for optimal prediction accuracy. We evaluate pruned model variants and find that they can reduce inference latency by up to 80% with an accuracy loss of less than 5% compared to non-pruned models. Furthermore, we show that the latency reductions from input feature pruning can be extended under different system variables such as batch size and floating point precision.
C1 [Yik, Jason] Harvard Univ, Cambridge, MA 02138 USA.
   [Kuppannagari, Sanmukh R.] Case Western Reserve Univ, Cleveland, OH 44106 USA.
   [Zeng, Hanqing] Meta AI, New York, NY USA.
   [Prasanna, Viktor K.] Univ Southern Calif, Los Angeles, CA 90007 USA.
RP Yik, J (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM jyik@g.harvard.edu; sanmukh.kuppannagari@case.edu; zengh@meta.com;
   prasanna@usc.edu
CR Bahri M., 2021, BINARY GRAPH NEURAL
   Brennan J., 2020, NOT HALF BAD EXPLORI, P2725
   Derrow-pinion Austin, 2021, CIKM '21: Proceedings of the 30th ACM International Conference on Information & Knowledge Management, P3767, DOI 10.1145/3459637.3481916
   Fey Matthias, 2019, ICLR WORKSHOP REPRES
   Halpern M, 2019, INT SYM PERFORM ANAL, P34, DOI 10.1109/ISPASS.2019.00012
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hennessy J.L., 2011, COMPUTER ARCHITECTUR
   Hu WH, 2021, Arxiv, DOI arXiv:2005.00687
   Liu X., 2022, ARXIV
   Liu Z., 2020, HETEROGENEOUS GRAPH
   Nagel M, 2019, Arxiv, DOI arXiv:1906.04721
   Pal A, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2311, DOI 10.1145/3394486.3403280
   Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397
   Sze V., 2020, ARXIV200303033, V2, P129, DOI [DOI 10.1109/CVPR.2019.01152, DOI 10.48550/ARXIV.2003.03033]
   Tailor S. A., 2021, DEGREE QUANT QUANTIZ
   Velickovi P., 2018, GRAPH ATTENTION NETW
   Welling M., 2016, P INT C LEARN REPR
   Wu F, 2019, PR MACH LEARN RES, V97
   Xu K., 2018, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1810.00826
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Zeng H., 2021, 35 C NEURAL INFORM P
   Zeng HQ, 2020, Arxiv, DOI arXiv:1907.04931
   Zhang BY, 2020, ANN IEEE SYM FIELD P, P241, DOI 10.1109/FCCM48280.2020.00074
   Zhang Jeff, 2020, 12 USENIX WORKSH HOT
   Zhou HK, 2021, PROC VLDB ENDOW, V14, P1597, DOI 10.14778/3461535.3461547
   Zhu R, 2019, PROC VLDB ENDOW, V12, P2094, DOI 10.14778/3352063.3352127
NR 26
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 282
EP 291
DI 10.1109/HiPC56025.2022.00045
UT WOS:000990551500032
DA 2023-11-16
ER

PT J
AU Agrawal, A
   Jaiswal, A
   Roy, D
   Han, B
   Srinivasan, G
   Ankit, A
   Roy, K
AF Agrawal, Amogh
   Jaiswal, Akhilesh
   Roy, Deboleena
   Han, Bing
   Srinivasan, Gopalakrishnan
   Ankit, Aayush
   Roy, Kaushik
TI Xcel-RAM: Accelerating Binary Neural Networks in High-Throughput SRAM
   Compute Arrays
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE In-memory computing; SRAM; binary convolution; binary neural networks;
   deep-CNNs
ID MEMORY
AB Deep neural networks are biologically inspired class of algorithms that have recently demonstrated the state-of-the-art accuracy in large-scale classification and recognition tasks. Hardware acceleration of deep networks is of paramount importance to ensure their ubiquitous presence in future computing platforms. Indeed, a major landmark that enables efficient hardware accelerators for deep networks is the recent advances from the machine learning community that have demonstrated the viability of aggressively scaled deep binary networks. In this paper, we demonstrate how deep binary networks can be accelerated in modified von Neumann machines by enabling binary convolutions within the static random access memory (SRAM) arrays. In general, binary convolutions consist of bit-wise exclusive-NOR (XNOR) operations followed by a population count (popcount). We present two proposals: one based on charge sharing approach to perform vector XNOR and approximate popcount and another based on bit-wise XNOR followed by a digital bit-tree adder for accurate popcount. We highlight the various tradeoffs in terms of circuit complexity, speed-up, and classification accuracy for both the approaches. Few key techniques presented as a part of the manuscript are the use of low-precision, low-overhead analog-todigital converter (ADC), to achieve a fairly accurate popcount for the charge-sharing scheme and proposal for sectioning of the SRAM array by adding switches onto the read-bitlines, thereby achieving improved parallelism. Our results on benchmark image classification datasets for CIFAR-10 and SVHN on a binarized neural network architecture show energy improvements of up to 6.1x and 2.3x for the two proposals, compared to conventional SRAM banks. In terms of latency, improvements of up to 15.8x and 8.1x were achieved for the two respective proposals.
C1 [Agrawal, Amogh; Jaiswal, Akhilesh; Roy, Deboleena; Han, Bing; Srinivasan, Gopalakrishnan; Ankit, Aayush; Roy, Kaushik] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Agrawal, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM agrawa64@purdue.edu
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ankit A., 2017, PROC 54 ACMEDACIEEE, P1
   [Anonymous], 2016, BINARIZED NEURAL NET
   [Anonymous], IEEE T COMPUT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, PREDICTIVE TECHNOLOG
   [Anonymous], 2017, 2017 S VLSI CIRC
   [Anonymous], BINARYNET PYTORCH
   [Anonymous], NEURAL CACHE BIT SER
   [Anonymous], IEEE T CIRCUITS SY 1
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], P NIPS AUT WORKSH OC
   [Anonymous], ANALOGTODIGITAL CONV
   BACKUS J, 1978, COMMUN ACM, V21, P613, DOI 10.1145/359576.359579
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Chen A., 2011, 2011 INT RELIABILITY, DOI [10.1109/IRPS.2011.5784590, DOI 10.1109/IRPS.2011.5784590]
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chu P. P., 2011, EMBEDDED SOPC DESIGN, P179
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jaiswal A., 2018, 8T SRAM CELL MULTIBI
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Jones N, 2014, NATURE, V505, P146, DOI 10.1038/505146a
   Krizhevsky Alex, 2022, LEARNING MULTIPLE LA
   Netzer Y., 2011, ADV NEURAL INFORM PR, P1
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Schneider ML, 2018, SCI ADV, V4, DOI 10.1126/sciadv.1701329
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Srinivasan G, 2017, DES AUT TEST EUROPE, P530, DOI 10.23919/DATE.2017.7927045
   Srinivasan G, 2016, SCI REP-UK, V6, DOI 10.1038/srep29545
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
NR 37
TC 61
Z9 62
U1 1
U2 14
PD AUG
PY 2019
VL 66
IS 8
BP 3064
EP 3076
DI 10.1109/TCSI.2019.2907488
UT WOS:000474599000021
DA 2023-11-16
ER

PT C
AU de Oliveira, LA
   Barros, E
AF de Oliveira Junior, Luiz Antonio
   Barros, Edna
GP IEEE
TI An FPGA-based Hardware Accelerator for Scene Text Character Recognition
SO PROCEEDINGS OF THE 2018 26TH IFIP/IEEE INTERNATIONAL CONFERENCE ON VERY
   LARGE SCALE INTEGRATION (VLSI-SOC)
SE IEEE-IFIP International Conference on VLSI and System-on-Chip
DT Proceedings Paper
CT 26th IFIP/IEEE International Conference on Very Large Scale Integration
   (VLSI-SoC)
CY OCT 08-10, 2018
CL Verona, ITALY
DE Character Recognition; FPGA; HOG; ELM; Computer Vision
AB Scene text character recognition is a challenging task in Computer Vision since natural scene images usually have cluttered background and the character's size, font, orientation, texture, brightness, and alignment in the picture are variable and non-predictable. Furthermore, most systems including scene text character recognition are usually embedded in a system on a chip (SoC), which has critical requirements, such as low latency, low area, mobility, and flexibility, at the same time that they require high accuracy. In this context, in this work we propose a heterogeneous system for embedded applications with time, area and power constraints, that combines hardware and software to accelerate a technique for scene text character recognition, based on Histogram of Oriented Gradients (HOG) for feature extraction and a neural network Extreme Learning Machine (ELM) as a classifier. The system was prototyped and experimented in the Terasic embedded platform DE2i-150 and the results showed that the system has accuracy of 65.5% in the Chars74k-15 dataset and is able to process up to 11 frames per second, having a good trade-off between processing time and accuracy in embedded environments. Moreover, it occupies only 11% logic elements of the Altera Cyclone IV FPGA, enabling its use in embedded systems.
C1 [de Oliveira Junior, Luiz Antonio; Barros, Edna] Univ Fed Pernambuco, Ctr Informat, Recife, PE, Brazil.
RP de Oliveira, LA (corresponding author), Univ Fed Pernambuco, Ctr Informat, Recife, PE, Brazil.
EM laoj2@cin.ufpe.br; ensb@cin.ufpe.br
CR Aggravi M, 2015, AMBIENT ASSISTED LIVING: ITALIAN FORUM 2014, P487, DOI 10.1007/978-3-319-18374-9_45
   Ali Muhammad, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P368
   [Anonymous], 2005, [No title captured]
   Chongmu Chen, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9219, P310, DOI 10.1007/978-3-319-21969-1_27
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jacobsen M, 2015, ACM T RECONFIG TECHN, V8, DOI 10.1145/2815631
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rong X., 2016, EUR C COMP VIS, P1
   Sanni Kayode, 2015, 2015 49 ANN C INF SC, P1, DOI [DOI 10.1109/CISS.2015.7086904, 10.1109/CISS.2015.7086904]
   Shi CZ, 2017, PATTERN RECOGN, V72, P1, DOI 10.1016/j.patcog.2017.06.022
   Shi CZ, 2014, PATTERN RECOGN, V47, P2853, DOI 10.1016/j.patcog.2014.03.023
   Yi CC, 2014, IEEE T IMAGE PROCESS, V23, P2972, DOI 10.1109/TIP.2014.2317980
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang Z, 2018, IEEE ACCESS, V6, P16454, DOI 10.1109/ACCESS.2018.2817342
   Zho H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P539, DOI 10.1109/SIPROCESS.2016.7888320
NR 19
TC 0
Z9 0
U1 0
U2 2
PY 2018
BP 125
EP 130
UT WOS:000462970000027
DA 2023-11-16
ER

PT C
AU Largent, A
   Nunes, JC
   Saint-Jalmes, H
   Simon, A
   Perichon, N
   Barateau, A
   Hervé, C
   Lafond, C
   Greer, PB
   Dowling, JA
   de Crevoisier, R
   Acosta, O
AF Largent, Axel
   Nunes, Jean-Claude
   Saint-Jalmes, Herve
   Simon, Antoine
   Perichon, Nicolas
   Barateau, Anais
   Herve, Chloe
   Lafond, Caroline
   Greer, Peter B.
   Dowling, Jason A.
   de Crevoisier, Renaud
   Acosta, Oscar
GP IEEE
TI Pseudo-CT Generation by Conditional Inference Random Forest for
   MRI-based Radiotherapy Treatment Planning
SO 2017 25TH EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO)
SE European Signal Processing Conference
DT Proceedings Paper
CT 25th European Signal Processing Conference (EUSIPCO)
CY AUG 28-SEP 02, 2017
CL GREECE
DE Pseudo-CT; Radiotherapy; Magnetic Resonance Imaging; Treatment planning;
   Random Forest
ID PROSTATE RADIATION-THERAPY; REGISTRATION; TOMOGRAPHY; SEQUENCES
AB Dose calculation from MRI is a topical issue. New treatment systems combining a linear accelerator with a MRI have been recently being developed. MRI has good soft tissue contrast without ionizing radiation exposure. However, unlike CT, MRI does not provide electron density information necessary for dose calculation. We propose in this paper a machine learning method to simulate a CT from a target MRI and co-registered CT-MRI training set. Ten prostate MR and CT images have been considered. Firstly, a reference image was randomly selected in the training set. A common space has been built thanks to affine registrations between the training set and the reference image. Multiscale image descriptors such as spatial information, gradients and texture features were extracted from MRI patches at different levels of a Gaussian pyramid and used as voxel-wise characteristics in the learning scheme. A Conditional Inference Random Forest (CIRF) modelled the relation between MRI descriptors and CT patches. For validation, test images were spatially normalized and the same descriptors were computed to generate a new pCT. Leave-one out experiments were performed. We obtained a MAE = 45.79 (pCT vs CT). Dose volume histograms inside PTV and organs at risk are in close agreement. The D98% was 0.45 % (inside PTV) and the 3D gamma pass rate (1mm, 1%) was 99,2%. Our method has better results than direct bulk assignment. And the results suggest that the method may be used for dose calculations in an MR based planning system.
C1 [Largent, Axel; Nunes, Jean-Claude; Saint-Jalmes, Herve; Simon, Antoine; Barateau, Anais; Lafond, Caroline; de Crevoisier, Renaud; Acosta, Oscar] Lab Signal & Image Proc LTSI, Rennes, France.
   [Largent, Axel; Nunes, Jean-Claude; Saint-Jalmes, Herve; Simon, Antoine; Barateau, Anais; Lafond, Caroline; de Crevoisier, Renaud; Acosta, Oscar] INSERM, UMR 1099, Rennes, France.
   [Perichon, Nicolas; Herve, Chloe; Lafond, Caroline; de Crevoisier, Renaud] Ctr Eugene Marquis, Dept Radiotherapy, Rennes, France.
   [Saint-Jalmes, Herve] Ctr Eugene Marquis, Imagery Dept, Rennes, France.
   [Greer, Peter B.] Univ Newcastle, Sch Math & Phys Sci, Newcastle, NSW, Australia.
   [Dowling, Jason A.] CSIRO Australian E Hlth Res Ctr, Herston, Qld, Australia.
RP Nunes, JC (corresponding author), Lab Signal & Image Proc LTSI, Rennes, France.; Nunes, JC (corresponding author), INSERM, UMR 1099, Rennes, France.
EM jean-claude.nunes@univ-rennes1.fr
CR Burgos N, 2015, LECT NOTES COMPUT SC, V9350, P476, DOI 10.1007/978-3-319-24571-3_57
   Demol B, 2016, MED PHYS, V43, P6557, DOI 10.1118/1.4967480
   Demol B, 2015, J APPL CLIN MED PHYS, V16, P117, DOI 10.1120/jacmp.v16i5.5586
   Dowling JA, 2015, INT J RADIAT ONCOL, V93, P1144, DOI 10.1016/j.ijrobp.2015.08.045
   Dowling JA, 2012, INT J RADIAT ONCOL, V83, pE5, DOI 10.1016/j.ijrobp.2011.11.056
   Hoogcarspel SJ, 2014, PHYS MED BIOL, V59, P7383, DOI 10.1088/0031-9155/59/23/7383
   Johanson A, 2013, ACTA ONCOL, V52, P1369, DOI 10.3109/0284186X.2013.819119
   Johansson A, 2011, MED PHYS, V38, P2708, DOI 10.1118/1.3578928
   Kapanen M, 2013, ACTA ONCOL, V52, P612, DOI 10.3109/0284186X.2012.692883
   Korhonen J, 2014, MED PHYS, V41, DOI 10.1118/1.4842575
   Lagendijk JJW, 2008, RADIOTHER ONCOL, V86, P25, DOI 10.1016/j.radonc.2007.10.034
   Lambert J, 2011, RADIOTHER ONCOL, V98, P330, DOI 10.1016/j.radonc.2011.01.012
   Lee YK, 2003, RADIOTHER ONCOL, V66, P203, DOI 10.1016/S0167-8140(02)00440-1
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Rivest-Henault D., 2013, CLIN IMAGE BASED PRO, P65
   Rivest-Henault D, 2015, MED IMAGE ANAL, V23, P56, DOI 10.1016/j.media.2015.04.014
   Huynh T, 2016, IEEE T MED IMAGING, V35, P174, DOI 10.1109/TMI.2015.2461533
   Wang ZH, 2013, LECT NOTES COMPUT SC, V8184, P98, DOI 10.1007/978-3-319-02267-3_13
   Wendling M, 2007, MED PHYS, V34, P1647, DOI 10.1118/1.2721657
NR 19
TC 9
Z9 10
U1 0
U2 1
PY 2017
BP 46
EP 50
UT WOS:000426986000010
DA 2023-11-16
ER

PT J
AU Sze, V
   Chen, YH
   Yang, TJ
   Emer, JS
AF Sze, Vivienne
   Chen, Yu-Hsin
   Yang, Tien-Ju
   Emer, Joel S.
TI Efficient Processing of Deep Neural Networks: A Tutorial and Survey
SO PROCEEDINGS OF THE IEEE
DT Article
DE ASIC; computer architecture; convolutional neural networks; dataflow
   processing; deep learning; deep neural networks; energy-efficient
   accelerators; low power; machine learning; spatial architectures; VLSI
ID COPROCESSOR; OBJECT
AB Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.
C1 [Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel S.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
   [Emer, Joel S.] Nvidia Corp, Westford, MA 01886 USA.
RP Sze, V (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
EM sze@mit.edu; yhchen@mit.edu; tjy@mit.edu; jsemer@mit.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2016, COMPLETE VISUAL NETW
   [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   [Anonymous], 2016, P ICLR
   [Anonymous], 2016, MICROARCHITECTURE MI
   [Anonymous], 2017, P 22 INT C ARCHITECT
   [Anonymous], 2012, P 2012 7 INT FOR STR, DOI [10.1109/IFOST.2012.6357669, DOI 10.1109/IFOST.2012.6357669]
   [Anonymous], 2017, INTEL ARCHITECTURE I
   [Anonymous], 2016, TUTORIAL EMERGING ME
   [Anonymous], 2017, P CVPR
   [Anonymous], 2015, P ICLR
   [Anonymous], 2017, P ICLR
   [Anonymous], 2017, MOBILENETS EFFICIENT
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Ba L. J., 2014, ADV NEURAL INFORM PR, V2, P2654
   BAILEY DH, 1991, J SUPERCOMPUT, V4, P357, DOI 10.1007/BF00129836
   Bengio, 2016, ABS160202830 CORR
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Cai ZW, 2017, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR.2017.574
   Cavigelli L., 2015, P 25 EDITION GREAT L, P199, DOI [10.1145/2742060.2743766, DOI 10.1145/2742060.2743766]
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen HG, 2016, PROC CVPR IEEE, P903, DOI 10.1109/CVPR.2016.104
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen YH, 2017, IEEE MICRO, V37, P12, DOI 10.1109/MM.2017.54
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Clevert Djork-Arne, 2016, ICLR 2016
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Condon S., 2017, P ZDNET MAR
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Courbariaux M., 2015, ADV NEURAL INF PROCE, V2, P3123, DOI [DOI 10.1109/TWC.2016.2633262, DOI 10.5555/2969442.2969588]
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Denton E.L., 2014, ADV NEURAL INFORM PR, V27, P1269, DOI DOI 10.5555/2968826.2968968
   Dorrance Richard, 2014, PROC ISFPGA, P161
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   Eryilmaz SB, 2016, INT SYM QUAL ELECT, P118
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Girshick R. B., 2014, CORR, P580, DOI DOI 10.1109/CVPR.2014.81
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Graham B., 2014, CORR
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel P., 2016, P ICLR
   Han S., 2015, ADV NEURAL INFORM PR, P1135
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2016, ICLR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hemsoth N., 2016, TECH REP
   Higginbotham S., 2016, GOOGLE TAKES UNCONVE
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton Geoffrey, 2014, NEURIPS
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Jeddeloh J., 2012, 2012 S VLSI TECHN VL, P87
   Jermyn M, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.094002
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Keitel-Schulz D, 2001, IEEE DES TEST COMPUT, V18, P7, DOI 10.1109/54.922799
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2010, CONVOLUTIONAL DEEP B, V40, P1, DOI DOI 10.1145/3065386
   Krizhevsky A., THE CIFAR 10 DATASET
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LECUN Y, 1989, IEEE COMMUN MAG, V27, P41, DOI 10.1109/35.41400
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1989, ADV IN NEURAL INFORM, P598
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lee EH, 2016, ISSCC DIG TECH PAP I, V59, P418, DOI 10.1109/ISSCC.2016.7418085
   Levine S, 2016, J MACH LEARN RES, V17
   Li F.-F., STANFORD CS CLASS CS
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Lim J.S., 1990, 2 DIMENSIONAL SIGNAL, P710
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   LiWan Matthew Zeiler, 2013, P 30 INT C MACH LEAR, P1058
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Maas AL, 2013, P 30 INT C MACH LEAR, V30, P3, DOI DOI 10.1016/0010-0277(84)90022-2
   Mao Huizi, 2017, IEEE C COMP VIS PATT
   Mathieu M., 2014, P ICLR
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Miyashita Daisuke, 2016, ARXIV160301025
   Mnih Volodymyr, 2013, PLAYING ATARI DEEP R
   Moons B, 2016, SYMP VLSI CIRCUITS
   Morgan T.P, 2016, NVIDIA PUSHES DEEP L
   Nair V., 2010, ICML, P807
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pfeiffer Mark, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1527, DOI 10.1109/ICRA.2017.7989182
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Romero Adriana, 2015, ICLR
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sermanet P., 2014, P 2 INT C LEARN REPR
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shalev-Shwartz S., 2016, P NIPS WORKSH LEARN
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simonyan Karen, 2014, ADV NEURAL INFORM PR, DOI DOI 10.1002/14651858.CD001941.PUB3
   Sriram V., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P273, DOI 10.1109/FPT.2010.5681487
   Standard J., 2013, P JESD
   Suleiman A, 2014, IEEE WRK SIG PRO SYS, P256
   Sze V., 2014, INTEGRATED CIRCUIT S, V39, P49, DOI DOI 10.1007/978-3-319-06895-4
   Szegedy C., 2017, P 31 AAAI C ARTIFICI, V31, DOI 10.1609/aaai.v31i1.11231
   Szegedy C., 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Urban G., 2017, ICLR
   van den Oord Aaron, 2016, ARXIV160903499
   Wang D, 2016, ARXIV160605718
   Wen Wei, 2016, ADV NEURAL INFORM PR, P2074
   Widrow B, 2005, IEEE SIGNAL PROC MAG, V22, P100, DOI 10.1109/MSP.2005.1407720
   Widrow B., 1960, P IRE WESCON CONV RE
   Wilson L., 2013, P SEM IND ASS
   Woodhouse J., 2016, BIG BIG BIG DATA HIG
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Xiong HY, 2015, SCIENCE, V347, DOI 10.1126/science.1254806
   Yang T.-J., 2017, P CVPR
   Yann C.J.B., MNIST DATABASE HANDW
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zeng HY, 2016, BIOINFORMATICS, V32, P121, DOI 10.1093/bioinformatics/btw255
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang J., 2015, IEEE ISSCC, P27
   Zhang JX, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/4350965
   Zhang TH, 2016, IEEE INT CONF ROBOT, P528, DOI 10.1109/ICRA.2016.7487175
   Zhang Y, 2016, INTERSPEECH, P410, DOI 10.21437/Interspeech.2016-1446
   Zhou A., 2017, P ICLR
   Zhou J, 2015, NAT METHODS, V12, P931, DOI [10.1038/NMETH.3547, 10.1038/nmeth.3547]
   Zhou Shuchang, 2016, ARXIV160606160
   Zhu Chenzhuo, 2017, INT C LEARN REPR ICL
   Zhuo Wang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3884, DOI 10.1109/ICASSP.2014.6854329
NR 150
TC 1776
Z9 1886
U1 61
U2 551
PD DEC
PY 2017
VL 105
IS 12
BP 2295
EP 2329
DI 10.1109/JPROC.2017.2761740
UT WOS:000416244800002
HC Y
HP N
DA 2023-11-16
ER

PT C
AU James, M
   Tom, M
   Groeneveld, P
   Kibardin, V
AF James, Michael
   Tom, Marvin
   Groeneveld, Patrick
   Kibardin, Vladimir
GP ACM
TI ISPD 2020 Physical Mapping of Neural Networks on a Wafer-Scale Deep
   Learning Accelerator
SO PROCEEDINGS OF THE 2020 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN
   (ISPD'20)
DT Proceedings Paper
CT ACM International Symposium on Physical Design (ISPD)
CY MAR 29-APR 01, 2020
CL Taipei, TAIWAN
DE Machine Learning; Physical Design; Floorplanning; Training of Neural
   Networks; Wafer-Scale Circuits
AB This paper introduces a special case of the floorplanning problem for optimizing neural networks to run on a wafer-scale computing engine. From a compute perspective, neural networks can be represented by a deeply layered structure of compute kernels. During the training of a neural network, gradient descent is used to determine the weight factors. Each layer then uses a local weight tensor to transform "activations" and "gradients" that are shared among connected kernels according to the topology of the network. This process is computationally intensive and requires high memory and communication bandwidth. Cerebras has developed a novel computer system designed for this work that is powered by a 21.5cm by 21.5cm wafer-scale processor with 400,000 programmable compute cores. It is structured as a regular array of 633 by 633 processing elements, each with its own local high bandwidth SRAM memory and direct high bandwidth connection to its neighboring cores. In addition to supporting traditional execution models for neural network training and inference, this engine has a unique capability to compile and compute every layer of a complete neural network simultaneously. Mapping a neural network in this fashion onto Cerebras' Wafer-Scale Engine (WSE) is reminiscent of the traditional floorplanning problem in physical design. A kernel ends up as a rectangle of x by y compute elements. These are the flexible blocks that need to be placed to optimize performance. This paper describes an ISPD 2020 challenge to develop algorithms and heuristics that produce compiled neural networks that achieve the highest possible performance on the Cerebras WSE.
C1 [James, Michael; Tom, Marvin; Groeneveld, Patrick; Kibardin, Vladimir] Cerebras Syst, Los Altos, CA 94022 USA.
RP James, M (corresponding author), Cerebras Syst, Los Altos, CA 94022 USA.
EM michael@cerebras.net; marvin@cerebras.net; patrick@cerebras.net;
   vladimir@cerebras.net
CR Amodei D, 2018, OPENAI BLOG
   [Anonymous], 1988, SIMULATED ANNEALING
   [Anonymous], 2017, MASTERING CHESS SHOG
   Fricker J. P., 2019, BUILDING WAFER SCALE
   He J K., 2015, DEEP RESIDUAL LEARNI
   James M., 2020, ISPD 20202 CONTEST W
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Otten R. H. J. M., 1982, ACM IEEE Nineteenth Design Automation Conference Proceedings, P261
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
NR 9
TC 13
Z9 14
U1 0
U2 0
PY 2020
BP 145
EP 149
DI 10.1145/3372780.3380846
UT WOS:000719342700022
DA 2023-11-16
ER

PT J
AU Shah, N
   Chaudhari, P
   Varghese, K
AF Shah, Nimish
   Chaudhari, Paragkumar
   Varghese, Kuruvilla
TI Runtime Programmable and Memory Bandwidth Optimized FPGA-Based
   Coprocessor for Deep Convolutional Neural Network
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Accelerator; coprocessor; deep convolutional neural network (DCNN); deep
   learning; field-programmable gate array (FPGA); runtime programmable
AB The deep convolutional neural network (DCNN) is a class of machine learning algorithms based on feed-forward artificial neural network and is widely used for image processing applications. Implementation of DCNN in real-world problems needs high computational power and high memory bandwidth, in a power-constrained environment. A general purpose CPU cannot exploit different parallelisms offered by these algorithms and hence is slow and energy inefficient for practical use. We propose a field-programmable gate array (FPGA)-based runtime programmable coprocessor to accelerate feed-forward computation of DCNNs. The coprocessor can be programmed for a new network architecture at runtime without resynthesizing the FPGA hardware. Hence, it acts as a plug-and-use peripheral for the host computer. Caching is implemented for input features and filter weights using on-chip memory to reduce the external memory bandwidth requirement. Data are prefetched at several stages to avoid stalling of computational units and different optimization techniques are used to efficiently reuse the fetched data. Dataflow is dynamically adjusted in runtime for each DCNN layer to achieve consistent computational throughput across a wide range of input feature sizes and filter sizes. The coprocessor is prototyped using Xilinx Virtex-7 XC7VX485T FPGA-based VC707 board and operates at 150 MHz. Experimental results show that our implementation is 15x energy efficient than highly optimized CPU implementation and achieves consistent computational throughput of more than 140 G operations/s for a wide range of input feature sizes and filter sizes. Off-chip memory transactions decrease by 111x due to the use of the on-chip cache.
C1 [Shah, Nimish; Chaudhari, Paragkumar; Varghese, Kuruvilla] Indian Inst Sci, Dept Elect Syst Engn, Bangalore, Karnataka, India.
RP Varghese, K (corresponding author), Indian Inst Sci, Dept Elect Syst Engn, Bangalore, Karnataka, India.
EM snimish@dese.iisc.ernet.in; parag@dese.iisc.ernet.in; kuru@iisc.ac.in
CR Alain G., 2016, THEANO PYTHON FRAMEW
   Ayer J., 2009, XAPP1022 XIL
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Jia Y., 2014, PROC 22 ACM INT C MU, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Jin JH, 2014, MIDWEST SYMP CIRCUIT, P133, DOI 10.1109/MWSCAS.2014.6908370
   Kim L.-W., IEEE T NEUR IN PRESS
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lavin A., 2015, MAXDNN EFFICIENT CON
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Park J, 2017, IEEE T NEUR NET LEAR, V28, P2408, DOI 10.1109/TNNLS.2016.2572164
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P82, DOI 10.1007/978-3-642-15825-4_9
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Vasilache Nicolas, 2014, ARXIV14127580
   Xilinx Inc, 2016, 7 SER DSP48E1 SLIC U
   Yadan O., 2013, MULTI GPU TRAINING C
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou X., IEEE T NEUR IN PRESS
NR 35
TC 98
Z9 99
U1 3
U2 5
PD DEC
PY 2018
VL 29
IS 12
BP 5922
EP 5934
DI 10.1109/TNNLS.2018.2815085
UT WOS:000451230100011
DA 2023-11-16
ER

PT J
AU Loni, M
   Zoljodi, A
   Majd, A
   Ahn, BH
   Daneshtalab, M
   Sjödin, M
   Esmaeilzadeh, H
AF Loni, Mohammad
   Zoljodi, Ali
   Majd, Amin
   Ahn, Byung Hoon
   Daneshtalab, Masoud
   Sjodin, Mikael
   Esmaeilzadeh, Hadi
TI FastStereoNet: A Fast Neural Architecture Search for Improving the
   Inference of Disparity Estimation on Resource-Limited Platforms
SO IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS
DT Article
DE Disparity estimation; machine vision; neural architecture search;
   optimization; transfer learning
ID STEREO; VISION
AB Convolutional neural networks (CNNs) provide the best accuracy for disparity estimation. However, CNNs are computationally expensive, making them unfavorable for resource-limited devices with real-time constraints. Recent advances in neural architectures search (NAS) promise opportunities in automated optimization for disparity estimation. However, the main challenge of the NAS methods is the significant amount of computing time to explore a vast search space [e.g., 1.6x10(29)] and costly training candidates. To reduce the NAS computational demand, many proxy-based NAS methods have been proposed. Despite their success, most of them are designed for comparatively small-scale learning tasks. In this article, we propose a fast NAS method, called FastStereoNet, to enable resource-aware NAS within an intractably large search space. FastStereoNet automatically searches for hardware-friendly CNN architectures based on late acceptance hill climbing (LAHC), followed by simulated annealing (SA). FastStereoNet also employs a fine-tuning with a transferred weights mechanism to improve the convergence of the search process. The collection of these ideas provides competitive results in terms of search time and strikes a balance between accuracy and efficiency. Compared to the state of the art, FastStereoNet provides 5.25x reduction in search time and 44.4x reduction in model size. These benefits are attained while yielding a comparable accuracy that enables seamless deployment of disparity estimation on resource-limited devices. Finally, FastStereoNet significantly improves the perception quality of disparity estimation deployed on field-programmable gate array and Intel Neural Compute Stick 2 accelerator in a significantly less onerous manner.
C1 [Loni, Mohammad; Zoljodi, Ali; Daneshtalab, Masoud; Sjodin, Mikael] Malardalen Univ, Sch Innovat Design & Engn, S-72218 Vasteras, Sweden.
   [Majd, Amin] Arcada Univ Appl Sci, Dept Econ & Business Anal, Helsinki 00560, Finland.
   [Ahn, Byung Hoon; Esmaeilzadeh, Hadi] Univ Calif San Diego, Dept Comp Sci & Engn, Alternat Comp Technol Lab, La Jolla, CA 92093 USA.
   [Daneshtalab, Masoud] TalTech Univ, Dept Comp Syst, EE-19086 Tallinn, Estonia.
RP Loni, M (corresponding author), Malardalen Univ, Sch Innovat Design & Engn, S-72218 Vasteras, Sweden.
EM mohammad.loni@mdh.se; ali.zoljodi@mdh.se; amin.majd@arcada.fi;
   bhahn@eng.ucsd.edu; masoud.daneshtalab@mdh.se; mikael.sjodin@mdh.se;
   hadi@eng.ucsd.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahlberg C, 2019, IEEE WINT CONF APPL, P1616, DOI 10.1109/WACV.2019.00177
   Ahn B. H., 2020, P MACHINE LEARNING S, V2, P44
   [Anonymous], 2010, ARTIF INTELL
   [Anonymous], 2018, IEEE ROBOT AUTOM LET
   Atienza R, 2018, IEEE INT CONF ROBOT, P3207
   Brock Andrew, 2018, ICLR
   Burke EK, 2017, EUR J OPER RES, V258, P70, DOI 10.1016/j.ejor.2016.07.012
   Cai H., 2019, ONCE FOR ALL TRAIN N, P1
   Cai H., 2018, INT C MACH LEARN, P678
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Cai Han, 2019, ICLR
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen Tianqi, 2016, P ICLR
   Collobert R, 2002, TECHNICAL REPORT
   Dong XY, 2022, IEEE T PATTERN ANAL, V44, P3634, DOI 10.1109/TPAMI.2021.3054824
   Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186
   Elsken T., 2017, ARXIV171104528
   Elsken T, 2019, J MACH LEARN RES, V20
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   GRANVILLE V, 1994, IEEE T PATTERN ANAL, V16, P652, DOI 10.1109/34.295910
   Hsu C.-H., 2018, CORR
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Jin S, 2010, IEEE T CIRC SYST VID, V20, P15, DOI 10.1109/TCSVT.2009.2026831
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Li J, 2015, IEEE T CYBERNETICS, V45, P2390, DOI 10.1109/TCYB.2014.2371918
   Li X, 2019, PROC CVPR IEEE, P9137, DOI 10.1109/CVPR.2019.00936
   Libutti L. A., 2020, PROC 2NDWORKSHOP ACC
   Liu C, 2019, IEEE T CYBERNETICS, V49, P3665, DOI 10.1109/TCYB.2018.2846361
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3
   Liu Ying, 2012, Optics and Precision Engineering, V20, P213, DOI 10.3788/OPE.20122002.0213
   Logothetis F, 2019, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2019.00114
   Loni M, 2020, IEEE C EVOL COMPUTAT
   Loni M, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102989
   Loni M, 2019, LECT NOTES COMPUT SC, V11727, P208, DOI 10.1007/978-3-030-30487-4_17
   Loni M, 2018, 2018 IEEE 12TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2018), P244, DOI 10.1109/MCSoC2018.2018.00049
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Niu LC, 2018, IOP CONF SER-MAT SCI, V320, DOI 10.1088/1757-899X/320/1/012007
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Pham H, 2018, PR MACH LEARN RES, V80
   Poggi M., 2020, ARXIV200408566
   Rahnama O, 2019, IEEE T CIRCUITS-II, V66, P773, DOI 10.1109/TCSII.2019.2909169
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Saikia T, 2019, IEEE I CONF COMP VIS, P1812, DOI 10.1109/ICCV.2019.00190
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Smith N, 2019, TRANSITIONING INTEL
   Suganuma M, 2020, EVOL COMPUT, V28, P141, DOI 10.1162/evco_a_00253
   Sun YN, 2020, IEEE T CYBERNETICS, V50, P3840, DOI 10.1109/TCYB.2020.2983860
   SZU H, 1987, PHYS LETT A, V122, P157, DOI 10.1016/0375-9601(87)90796-1
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tonioni A., 2019, CODE REAL TIME SELF
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Vinyals O., 2018, PROC 6 INT C LEARN R
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zha D., 2016, PROC ACMSIGDA INT S, P274
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang HY, 2021, IEEE T EVOLUT COMPUT, V25, P371, DOI 10.1109/TEVC.2020.3040272
   Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174
   Zoph B., 2017, INT C LEARNING REPRE, P1
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 66
TC 8
Z9 8
U1 0
U2 8
PD AUG
PY 2022
VL 52
IS 8
BP 5222
EP 5234
DI 10.1109/TSMC.2021.3123136
EA NOV 2021
UT WOS:000732342800001
DA 2023-11-16
ER

PT J
AU Morningstar, A
   Hauru, M
   Beall, J
   Ganahl, M
   Lewis, AGM
   Khemani, V
   Vidal, G
AF Morningstar, Alan
   Hauru, Markus
   Beall, Jackson
   Ganahl, Martin
   Lewis, Adam G. M.
   Khemani, Vedika
   Vidal, Guifre
TI Simulation of Quantum Many-Body Dynamics with Tensor Processing Units:
   Floquet Prethermalization
SO PRX QUANTUM
DT Article
ID PERIODICALLY DRIVEN; THERMALIZATION
AB Tensor processing units (TPUs) are specialized hardware accelerators developed by Google to support large-scale machine-learning tasks but they can also be leveraged to accelerate and scale other linear-algebra-intensive computations. In this paper, we demonstrate the usage of TPUs for massively parallel classical simulations of quantum many-body dynamics on long time scales. We apply our methods to study the phenomenon of Floquet prethermalization, i.e., exponentially slow heating in quantum spin chains subject to high-frequency periodic driving. We simulate the dynamics of L = 34 qubits for over 10(5) Floquet periods, corresponding to circuits with 4 x 10(6) nearest-neighbor two-qubit gates. The circuits simulated have no additional symmetries and represent a pure-state evolution in the full 2(L)-dimensional Hilbert space. This is achieved by distributing the computation over 128 TPU cores. On that size TPU cluster, we find speed-ups in wall-clock run time of 230 times and 15 times when compared to reference CPU and single-graphics-processing-unit (GPU) simulations, respectively, for shorter-time 30-qubit simulations that can be handled by all three platforms. We study the computational cost of the simulations, as a function of both the number of qubits and the number of TPU cores used, up to our maximum capacity of L = 40 qubits, which requires a "full pod" of 2048 TPU cores with tens of terabytes of memory in total. For these simulations, an eight-TPU-core machine is comparable to a single A100 GPU and thus the full TPU pod is comparable to a machine with hundreds of top-of-the-line GPUs. However, the TPU pod is more energy and cost efficient and readily accessible (via Google Cloud), unlike such large many-GPU configurations. We also study the accumulation of numerical error as a function of circuit depth in very deep circuits. Our work demonstrates that TPUs can offer significant advantages for state-of-the-art simulations of quantum many-body dynamics.
C1 [Morningstar, Alan] Princeton Univ, Dept Phys, Princeton, NJ 08544 USA.
   [Morningstar, Alan; Hauru, Markus; Beall, Jackson; Ganahl, Martin; Lewis, Adam G. M.; Vidal, Guifre] Sandbox Alphabet, Mountain View, CA 94043 USA.
   [Khemani, Vedika] Stanford Univ, Dept Phys, Stanford, CA 94305 USA.
RP Morningstar, A (corresponding author), Princeton Univ, Dept Phys, Princeton, NJ 08544 USA.; Morningstar, A (corresponding author), Sandbox Alphabet, Mountain View, CA 94043 USA.
EM alanmorningstar@princeton.edu
CR Abadi Martin, 2016, arXiv
   Abanin DA, 2021, ANN PHYS-NEW YORK, V427, DOI 10.1016/j.aop.2021.168415
   Abanin D, 2017, COMMUN MATH PHYS, V354, P809, DOI 10.1007/s00220-017-2930-x
   Abanin DA, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.021001
   Abanin DA, 2017, PHYS REV B, V95, DOI 10.1103/PhysRevB.95.014112
   Abanin DA, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.256803
   Alet F, 2018, CR PHYS, V19, P498, DOI 10.1016/j.crhy.2018.03.003
   Alexeev Y, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.017001
   Altman E, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.017003
   [Anonymous], JAX DOCUMENTATION
   Aspuru-Guzik A, 2012, NAT PHYS, V8, P285, DOI [10.1038/NPHYS2253, 10.1038/nphys2253]
   Awschalom D, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.017002
   Belletti F., 2020, ARXIV190602818
   Blatt R, 2012, NAT PHYS, V8, P277, DOI [10.1038/nphys2252, 10.1038/NPHYS2252]
   Bloch I, 2012, NAT PHYS, V8, P267, DOI [10.1038/nphys2259, 10.1038/NPHYS2259]
   Bradbury James, 2018, JAX COMPOSABLE TRANS
   Bukov M, 2015, ADV PHYS, V64, P139, DOI 10.1080/00018732.2015.1055918
   Chan A, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.041019
   Cirq developers, 2021, CIRQ
   D'Alessio L, 2016, ADV PHYS, V65, P239, DOI 10.1080/00018732.2016.1198134
   D'Alessio L, 2014, PHYS REV X, V4, DOI 10.1103/PhysRevX.4.041048
   Efthymiou S, 2022, QUANTUM SCI TECHNOL, V7, DOI 10.1088/2058-9565/ac39f5
   Else DV, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.011026
   Else DV, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.090402
   FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   Fleckenstein C, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.144307
   Frostig R., 2018, SYSTEMS MACHINE LEAR, P23
   Ganahl M., IN PRESS
   Georgescu IM, 2014, REV MOD PHYS, V86, P153, DOI 10.1103/RevModPhys.86.153
   Gray J, 2018, J OPEN SOURCE SOFTW, V3, P819, DOI DOI 10.21105/JOSS.00819
   Gustafson E., ARXIV211007482 2021
   Harper F, 2020, ANNU REV CONDEN MA P, V11, P345, DOI 10.1146/annurev-conmatphys-031218-013721
   Hauru M., 2021, ARXIV211110466
   Heyl M, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau8342
   Houck AA, 2012, NAT PHYS, V8, P292, DOI [10.1038/NPHYS2251, 10.1038/nphys2251]
   Huang C., 2020, ARXIV200506787
   Huot F., 2019, ARXIV191208063
   Ippoliti M, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.030346
   Isakov S. V., ARXIV211102396 2021
   Jones T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47174-9
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kelly A., 2018, ARXIV180500988
   Khemani V, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.250401
   Kiefer-Emmanouilidis M, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.024203
   Kuwahara T, 2016, ANN PHYS-NEW YORK, V367, P96, DOI 10.1016/j.aop.2016.01.012
   Ladd TD, 2010, NATURE, V464, P45, DOI 10.1038/nature08812
   Lazarides A, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.030402
   Lazarides A, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.012110
   Lewis A. G. M., 2021, ARXIV211209017
   Lezama TLM, 2019, PHYS REV B, V99, DOI 10.1103/PhysRevB.99.161106
   Li A., 2020, STRATEG ORGAN, P1
   Lloyd S, 1996, SCIENCE, V273, P1073, DOI 10.1126/science.273.5278.1073
   Lu T., 2020, ARXIV
   Lu TJ, 2021, I S BIOMED IMAGING, P783, DOI 10.1109/ISBI48211.2021.9434068
   Luitz DJ, 2020, PHYS REV B, V102, DOI 10.1103/PhysRevB.102.100202
   Luitz DJ, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.021046
   Luo XZ, 2020, QUANTUM-AUSTRIA, V4, DOI 10.22331/q-2020-10-11-341
   Ma C., 2021, NONUNIFORM FAST FOUR
   Machado F, 2019, PHYS REV RES, V1, DOI 10.1103/PhysRevResearch.1.033202
   Mandra S, 2021, PROCEEDINGS OF SECOND INTERNATIONAL WORKSHOP ON QUANTUM COMPUTING SOFTWARE (QCS 2021), P99, DOI 10.1109/QCS54837.2021.00015
   Mi X., 2021, ARXIV210713571
   Monroe C, 2021, REV MOD PHYS, V93, DOI 10.1103/RevModPhys.93.025001
   Mori T, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.120401
   Morningstar A., 2021, ARXIV210705642
   Moudgalya S., 2022, ARXIV210900548, V85
   Nandkishore R, 2015, ANNU REV CONDEN MA P, V6, P15, DOI 10.1146/annurev-conmatphys-031214-014726
   Oka T, 2019, ANNU REV CONDEN MA P, V10, P387, DOI 10.1146/annurev-conmatphys-031218-013423
   Oka T, 2009, PHYS REV B, V79, DOI 10.1103/PhysRevB.79.081406
   Pan F., 2021, ARXIV210303074
   Pan Z., 2021, ARXIV210311927
   Panda RK, 2019, EPL-EUROPHYS LETT, V128, DOI 10.1209/0295-5075/128/67003
   Pederson R., IN PRESS
   Peng P, 2021, NAT PHYS, V17, P444, DOI 10.1038/s41567-020-01120-z
   Po HC, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.041070
   Polkovnikov A, 2011, REV MOD PHYS, V83, P863, DOI 10.1103/RevModPhys.83.863
   Ponte P, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.140401
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Quantum AI team and collaborators, 2020, QSIM
   Rubio-Abadal A, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.021044
   Rudner MS, 2013, PHYS REV X, V3, DOI 10.1103/PhysRevX.3.031005
   Sels D., 2020, ARXIV200904501
   Serbyn M, 2021, NAT PHYS, V17, P675, DOI 10.1038/s41567-021-01230-2
   Shillito R, IN PRESS
   Sierant P., 2021, ARXIV210913608
   Sierant P, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.186601
   Song R., IN PRESS
   Sünderhauf C, 2018, PHYS REV B, V98, DOI 10.1103/PhysRevB.98.134204
   Suntajs J, 2020, PHYS REV E, V102, DOI 10.1103/PhysRevE.102.062144
   SUZUKI M, 1991, J MATH PHYS, V32, P400, DOI 10.1063/1.529425
   Suzuki Y, 2021, QUANTUM-AUSTRIA, V5, P1, DOI 10.22331/q-2021-10-06-559
   Titum P, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.021013
   Vidal G, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.040502
   Villalonga B, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab7eeb
   Vincent T., 2021, ARXIV210709793
   Wang Q., 2022, COMPUT PHYS COMMUN, V274, DOI [10.1016/j.cpc.2022.108292, DOI 10.1016/J.CPC.2022.108292]
   Weinberg P, 2017, SCIPOST PHYS, V2, DOI 10.21468/SciPostPhys.2.1.003
NR 97
TC 10
Z9 10
U1 0
U2 1
PD MAY 11
PY 2022
VL 3
IS 2
AR 020331
DI 10.1103/PRXQuantum.3.020331
UT WOS:000802835000001
DA 2023-11-16
ER

PT C
AU Khandelwal, S
   Shreejith, S
AF Khandelwal, Shashwat
   Shreejith, Shanker
GP IEEE
TI A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN
SO 2022 21ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY
   (ICFPT 2022)
DT Proceedings Paper
CT 21st International Conference on Field-Programmable Technology (ICFPT)
CY DEC 05-09, 2022
CL Hong Kong Univ Sci & Technol, Hong Kong, HONG KONG
HO Hong Kong Univ Sci & Technol
DE Controller Area Network; Intrusion Detection System; Machine Learning;
   Field Programmable Gate Arrays
ID INTRUSION DETECTION
AB Recent years have seen an exponential rise in complex software-driven functionality in vehicles, leading to a rising number of electronic control units (ECUs), network capabilities, and interfaces. These expanded capabilities also bring-in new planes of vulnerabilities making intrusion detection and management a critical capability; however, this can often result in more ECUs and network elements due to the high computational overheads. In this paper, we present a consolidated ECU architecture incorporating an Intrusion Detection System (IDS) for Automotive Controller Area Network (CAN) along with traditional ECU functionality on an off-the-shelf hybrid FPGA device, with near-zero overhead for the ECU functionality. We propose two quantised multi-layer perceptrons (QMLP's) as isolated IDSs for detecting a range of attack vectors including Denial-of-Service, Fuzzing and Spoofing, which are accelerated using off-the-shelf deep-learning processing unit (DPU) IP block from Xilinx, operating fully transparently to the software on the ECU. The proposed models achieve the state-of-the-art classification accuracy for all the attacks, while we observed a 15x reduction in power consumption when compared against the GPU-based implementation of the same models quantised using Nvidia libraries. We also achieved a 2.3x speed up in permessage processing latency (at 0.24 ms from the arrival of a CAN message) to meet the strict end-to-end latency on critical CAN nodes and a 2.6x reduction in power consumption for inference when compared to the state-of-the-art IDS models on embedded IDS and loosely coupled IDS accelerators (GPUs) discussed in the literature.
C1 [Khandelwal, Shashwat; Shreejith, Shanker] Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
RP Khandelwal, S (corresponding author), Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
EM khandels@tcd.ie; shankers@tcd.ie
CR Agrawal K, 2022, IEEE T INTELL TRANSP, V23, P22596, DOI 10.1109/TITS.2022.3146024
   Al-Jarrah OY, 2019, IEEE ACCESS, V7, P21266, DOI 10.1109/ACCESS.2019.2894183
   Alshammari A., 2018, WIRELESS ENG TECHNOL, V9, P79, DOI 10.4236/wet.2018.94007
   [Anonymous], 2018, ZYNQ ULTRASCALE PLUS
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Bozdal M, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE), P201, DOI 10.1109/iCCECOME.2018.8658720
   Cai Z., 2019, BLACK HAT US, V2019, P39
   CAR Hacking Dataset, 2020, CAR HACKING DATASET
   Casino M, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS 2019), P136, DOI [10.1109/icsrs48664.2019.8987605, 10.1109/ICSRS48664.2019.8987605]
   Cheng PZ, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020310
   Cho KN, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12111309
   Cho KT, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1109, DOI 10.1145/3133956.3134001
   Cho KT, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P911
   De Araujo PF, 2021, IEEE ACCESS, V9, P166855, DOI 10.1109/ACCESS.2021.3136147
   Desta Araya Kibrom, 2020, 2020 30 INT TELECOMM, P1
   Enev Miro, 2016, P PRIVACY ENHANCING, V1, P34, DOI DOI 10.1515/POPETS-2015-0029
   Fons F., 2012, XCELL J, p[20, 31]
   GmbH R.B., 2015, ENGINE CONTROL UNIT
   GmbH R.B., 1991, CAN SPEC VERS 2 0
   Greenberg A, 2015, WIRED, V7, P21
   Hartwich F., 2012, P ICC
   Iehira K, 2018, CONSUM COMM NETWORK
   Khandelwal S, 2022, I C FIELD PROG LOGIC, P425, DOI 10.1109/FPL57034.2022.00070
   Khandelwal S, 2022, IEEE INT CONF ASAP, P88, DOI 10.1109/ASAP54787.2022.00023
   Koscher K, 2010, P IEEE S SECUR PRIV, P447, DOI 10.1109/SP.2010.34
   Larson Ulf E., 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P220, DOI 10.1109/IVS.2008.4621263
   Lee H, 2017, ANN CONF PRIV SECUR, P57, DOI 10.1109/PST.2017.00017
   Ma H., 2022, SECUR COMMUN NETW, V2022
   Miller C., 2013, DEF CON, V21, P15
   Mukherjee S, 2016, LECT NOTES COMPUT SC, V10063, P23, DOI 10.1007/978-3-319-49806-5_2
   Narayanan SN, 2015, Arxiv, DOI arXiv:1512.08048
   Nie S, 2017, BRIEFING BLACK HAT U, V25, P1
   Ohira S, 2022, VEH COMMUN, V35, DOI 10.1016/j.vehcom.2022.100470
   Palanca Andrea, 2017, Detection of Intrusions and Malware, and Vulnerability Assessment. 14th International Conference, DIMVA 2017. Proceedings: LNCS 10327, P185, DOI 10.1007/978-3-319-60876-1_9
   Seo E, 2018, ANN CONF PRIV SECUR, P286
   Sharma H, 2016, WORKSH COGN ARCH
   Shreejith S, 2018, IEEE MICRO, V38, P72, DOI 10.1109/MM.2018.022071137
   Shreejith S, 2013, IEEE EMBED SYST LETT, V5, P12, DOI 10.1109/LES.2013.2243698
   Song HM, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100198
   Studnia I, 2018, INT J EMBED SYST, V10, P1
   Tuan Phan Vuong, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P2106, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.313
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vasistha D. K., 2017, THESIS
   Vipin Kizheppatt, 2014, 2014 IEEE International Conference on Cyber-Physical Systems, Networks, and Applications, P31, DOI 10.1109/CPSNA.2014.14
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang EW, 2019, ANN IEEE SYM FIELD P, P26, DOI 10.1109/FCCM.2019.00014
   Weber Marc, 2018, PROC EUROPEAN C EMBE
   Wu S, 2018, Arxiv, DOI arXiv:1802.04680
   Wu WF, 2018, IEEE ACCESS, V6, P45233, DOI 10.1109/ACCESS.2018.2865169
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xilinx, 2020, ZYNQ DPU V3 2
   Xilinx, 2021, VIT US GUID
   Yang L, 2022, IEEE INTERNET THINGS, V9, P616, DOI 10.1109/JIOT.2021.3084796
   Yang L, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013892
   Yang Y, 2020, SMART CITIES-BASEL, V3, P17, DOI 10.3390/smartcities3010002
   Zhou J, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362034
NR 56
TC 1
Z9 1
U1 1
U2 1
PY 2022
BP 113
EP 121
UT WOS:000922377900014
DA 2023-11-16
ER

PT J
AU Qu, Z
   Deng, L
   Wang, BY
   Chen, HN
   Lin, JL
   Liang, L
   Li, GQ
   Zhang, Z
   Xie, Y
AF Qu, Zheng
   Deng, Lei
   Wang, Bangyan
   Chen, Hengnu
   Lin, Jilan
   Liang, Ling
   Li, Guoqi
   Zhang, Zheng
   Xie, Yuan
TI Hardware-Enabled Efficient Data Processing With Tensor-Train
   Decomposition
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Algorithm hardware co-design; tensor-train decomposition (TTD);
   TT-format data processing
ID SINGULAR VALUE DECOMPOSITION; ALGORITHM
AB In recent years, tensor computation has become a promising tool for solving big data analysis, machine learning, medical image, and EDA problems. To ease the memory and computation intensity of tensor processing, decomposition techniques, especially tensor-train decomposition (TTD), are widely adopted to compress the extremely high-dimensional tensor data. Despite TTD's potential to break the curse of dimensionality, researchers have not yet leveraged its full computational potential, mainly because of two reasons: 1) executing TTD itself is time- and energy-consuming due to the singular value decomposition (SVD) operation inside each of TTD's iteration and 2) additional software/hardware optimizations are often required to process the obtained TT-format data in certain applications such as deep learning inference. In this article, we address these challenges with two approaches. First, we propose an algorithm-hardware co-design with customized architecture, namely, TTD Engine to accelerate TTD. We use MRI image compression as a demo application to illustrate the efficacy of the proposed accelerator. Second, we present a case study demonstrating the benefit of TT-format data processing and the efficacy of using TTD Engine. In the case study, we use the TT approach to realize convolution operation, which is difficult and nontrivial for TT-format data. Experimental results show that, TTD Engine achieves, on average, 14.9 x-36.9 x speedup over CPU implementations and 4.1 x-9.9 x speedup compared to the GPU baseline. The energy efficiency is also improved by at least 14.4 x and 5.4 x over CPU and GPU, respectively. Moreover, our hardware-enabled TT-format data processing further leads to more efficient implementations of complicated operations and applications.
C1 [Qu, Zheng; Deng, Lei; Wang, Bangyan; Lin, Jilan; Liang, Ling; Zhang, Zheng; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Chen, Hengnu; Li, Guoqi] Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
RP Deng, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM zhengqu@ucsb.edu; leideng@ucsb.edu; bangyan@ucsb.edu;
   chn18@mails.tsinghua.edu.cn; jilan@ucsb.edu; linglinag@ucsb.edu;
   liguoqi@mail.tsinghua.edu.cn; zhengzhang@ucsb.edu; yuanxie@ucsb.edu
CR [Anonymous], 2019, ARXIV190701522
   [Anonymous], 2014, ARXIV14073124
   ARNOLDI WE, 1951, Q APPL MATH, V9, P17, DOI 10.1090/qam/42792
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   Balasubramonian R., 2009, HP LAB
   Ballester R., TNTORCH TENSOR NETWO
   BRENT RP, 1985, J VLSI COMPUT SYST, V1, P242
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI DOI 10.1002/9780470747278
   Cichocki A., 2013, P INT WORKSH SMART I, P1
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1
   De Lathauwer L, 2008, SIAM J MATRIX ANAL A, V30, pVII, DOI 10.1137/SJMAEL000030000003000vii000001
   DERIJK PPM, 1989, SIAM J SCI STAT COMP, V10, P359, DOI 10.1137/0910023
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Garipov Timur, 2016, ABS161103214 CORR
   Gupta U., 2019, ARXIV190808976
   Harshman R. A., 1970, WORKING PAPERS PHONE
   Hwang R., 2020, ARXIV200505968
   Klus S, 2018, NONLINEARITY, V31, P3359, DOI 10.1088/1361-6544/aabc8f
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Ledesma-Carrillo Luis M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P345, DOI 10.1109/ReConFig.2011.77
   Novikov A., 2015, TENSORIZING NEURAL N, P442
   Novikov A., 2015, P NIPS, P442
   Oseledets I., 2021, OSELEDETS TT TOOLBOX
   Oseledets IV, 2012, SIAM J SCI COMPUT, V34, pA2718, DOI 10.1137/110833142
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Oseledets I, 2010, LINEAR ALGEBRA APPL, V432, P70, DOI 10.1016/j.laa.2009.07.024
   Sorber L, 2013, SIAM J OPTIMIZ, V23, P695, DOI 10.1137/120868323
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Tucker L. R., 1963, PROBLEMS MEASURING C, V15, P122
   Tucker L.R., 1964, CONTRIBUTIONS MATH P, P109
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wang XY, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P220, DOI 10.1109/IPDPSW.2014.29
   Zhang Y., 2019, ARXIV190913654
   Zhang Z, 2017, IEEE T COMPUT AID D, V36, P521, DOI 10.1109/TCAD.2016.2618879
   Zhang Z, 2015, IEEE T COMPUT AID D, V34, P63, DOI 10.1109/TCAD.2014.2369505
NR 41
TC 3
Z9 3
U1 2
U2 10
PD FEB
PY 2022
VL 41
IS 2
BP 372
EP 385
DI 10.1109/TCAD.2021.3058317
UT WOS:000744531400017
DA 2023-11-16
ER

PT J
AU Hosseini, M
   Mohsenin, T
AF Hosseini, Morteza
   Mohsenin, Tinoosh
TI Binary Precision Neural Network Manycore Accelerator
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE BiNMAC; low-power manycore accelerator; binarized neural network;
   CPU-GPU; deep learning; ASIC
ID DESIGN; MEMORY
AB This article presents a low-power, programmable, domain-specific manycore accelerator, Binarized neural Network Manycore Accelerator (BiNMAC), which adopts and efficiently executes binary precision weight/activation neural network models. Such networks have compact models in which weights are constrained to only 1 bit and can be packed several in one memory entry that minimizes memory footprint to its finest. Packing weights also facilitates executing single instruction, multiple data with simple circuitry that allows maximizing performance and efficiency. The proposed BiNMAC has light-weight cores that support domain-specific instructions, and a router-based memory access architecture that helps with efficient implementation of layers in binary precision weight/activation neural networks of proper size. With only 3.73% and 1.98% area and average power overhead, respectively, novel instructions such as Combined Population-Count-XNOR, Patch-Select, and Bit-based Accumulation are added to the instruction set architecture of the BiNMAC, each of which replaces execution cycles of frequently used functions with 1 clock cycle that otherwise would have taken 54, 4, and 3 clock cycles, respectively. Additionally, customized logic is added to every core to transpose 16x16-bit blocks of memory on a bit-level basis, that expedites reshaping intermediate data to be well-aligned for bitwise operations. A 64-cluster architecture of the BiNMAC is fully placed and routed in 65-nm TSMC CMOS technology, where a single cluster occupies an area of 0.53 mm(2) with an average power of 232 mW at 1-GHz clock frequency and 1.1 V. The 64-cluster architecture takes 36.5 mm(2) area and, if fully exploited, consumes a total power of 16.4 W and can perform 1,360 Giga Operations Per Second (GOPS) while providing full programmability. To demonstrate its scalability, four binarized case studies including ResNet-20 and LeNet-5 for high-performance image classification, as well as a ConvNet and a multilayer perceptron for low-power physiological applications were implemented on BiNMAC. The implementation results indicate that the population-count instruction alone can expedite the performance by approximately 5x. When other new instructions are added to a RISC machine with existing population-count instruction, the performance is increased by 58% on average. To compare the performance of the BiNMAC with other commercial-off-the-shelf platforms, the case studies with their double-precision floating-point models are also implemented on the NVIDIA Jetson TX2 SoC (CPU+GPU). The results indicate that, within a margin of similar to 2.1%-9.5% accuracy loss, BiNMAC on average outperforms the TX2 GPU by approximately 1.9x (or 7.5x with fabrication technology scaled) in energy consumption for image classification applications. On low power settings and within a margin of similar to 3.7%-5.5% accuracy loss compared to ARM Cortex-A57 CPU implementation, BiNMAC is roughly similar to 9.7x-17.2x (or 38.8x-68.8x with fabrication technology scaled) more energy efficient for physiological applications while meeting the application deadline.
C1 [Hosseini, Morteza; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, 1000 Hilltop Cir, Catonsville, MD 21250 USA.
RP Hosseini, M (corresponding author), Univ Maryland Baltimore Cty, 1000 Hilltop Cir, Catonsville, MD 21250 USA.
EM hs10@umbc.edu; tinoosh@umbc.edu
CR Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   Amdahl Gene M., 1967, PROC SPRING JOINT CO, P483, DOI [DOI 10.1145/1465482.1465560, 10.1145/1465482.1465560]
   Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Birjandtalab J, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P110, DOI 10.1109/SiPS.2016.27
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Colangelo P, 2017, ANN IEEE SYM FIELD P, P135, DOI 10.1109/FCCM.2017.46
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dauphin Yann N., 2013, P ICLR WORKSH
   Deng L, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00841
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Franklin D., 2017, NVIDIA ACCELERATED C
   Gong Y., 2014, INT C LEARN REPR ICL, P1
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, PROC CVPR IEEE
   Hossain MJ, 2020, PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P1, DOI 10.1109/ICECE51571.2020.9393122
   Howard A. G., 2017, ABS170404861 CORR
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hubara I, 2018, J MACH LEARN RES, V18
   Ioffe S, 2015, Arxiv, DOI arXiv:1502.03167
   Javaheripi M, 2020, IEEE J-STSP, V14, P750, DOI 10.1109/JSTSP.2020.2992384
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mirzaeian Ali, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P530, DOI 10.1109/ASP-DAC47756.2020.9045135
   Mirzaeian A, 2019, 2019 INT C RECONFIGU, P1
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Peng XC, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P471, DOI 10.1145/3357526.3357566
   Prakash B., 2020, SAFEAI WORKSH 34 AAA
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Ren H., 2020, P 2020 IEEE 33 INT S
   Samragh M, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3391901
   Shea C, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3358699
   Shiri Aidin, 2020, GLSVLSI '20. Proceedings of the 2020 Great Lakes Symposium on VLSI, P131, DOI 10.1145/3386263.3407652
   Song LH, 2019, CCF T HIGH PERFORM C, V1, P196, DOI 10.1007/s42514-019-00014-8
   Sumbul Huseyin Ekin, 2020, US Patent App, Patent No. [16/697,616, 16697616]
   Thulasiraman K., 1992, GRAPHS THEORY ALGORI
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yonekawa H, 2017, IEEE SYM PARA DISTR, P98, DOI 10.1109/IPDPSW.2017.95
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Y., 2017, ARXIV171107128
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu ZH, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317739
NR 52
TC 2
Z9 2
U1 1
U2 1
PD FEB
PY 2021
VL 17
IS 2
AR 19
DI 10.1145/3423136
UT WOS:000648512700001
DA 2023-11-16
ER

PT J
AU Almagro, CV
   Orrego, RAM
   González, AG
   Matheson, E
   Prades, RM
   Di Castro, M
   PéTrez, MF
AF Veiga Almagro, Carlos
   Munoz Orrego, Renato Andres
   Gonzalez, Alvaro Garcia
   Matheson, Eloise
   Marin Prades, Raul
   Di Castro, Mario
   Ferre Perez, Manuel
TI (MARGOT) Monocular Camera-Based Robot Grasping Strategy for Metallic
   Objects
SO SENSORS
DT Article
DE computer vision; telerobotics; grasping determination
ID VISION
AB Robotic handling of objects is not always a trivial assignment, even in teleoperation where, in most cases, this might lead to stressful labor for operators. To reduce the task difficulty, supervised motions could be performed in safe scenarios to reduce the workload in these non-critical steps by using machine learning and computer vision techniques. This paper describes a novel grasping strategy based on a groundbreaking geometrical analysis which extracts diametrically opposite points taking into account surface smoothing (even those target objects that might conform highly complex shapes) to guarantee the uniformity of the grasping. It uses a monocular camera, as we are often facing space restrictions that generate the need to use laparoscopic cameras integrated in the tools, to recognize and isolate targets from the background, estimating their spatial coordinates and providing the best possible stable grasping points for both feature and featureless objects. It copes with reflections and shadows produced by light sources (which require extra effort to extract their geometrical properties) in unstructured facilities such as nuclear power plants or particle accelerators on scientific equipment. Based on the experimental results, utilizing a specialized dataset improved the detection of metallic objects in low-contrast environments, resulting in the successful application of the algorithm with error rates in the scale of millimeters in the majority of repeatability and accuracy tests.
C1 [Veiga Almagro, Carlos; Munoz Orrego, Renato Andres; Gonzalez, Alvaro Garcia; Matheson, Eloise; Di Castro, Mario] European Org Nucl Res CERN, BE CEM Beams Dept, Elect & Mechatron Grp, CH-1217 Geneva, Switzerland.
   [Veiga Almagro, Carlos; Marin Prades, Raul] Jaume I Univ Castellon, Interact Robot Syst Lab, Castellon De La Plana 12006, Spain.
   [Munoz Orrego, Renato Andres; Ferre Perez, Manuel] Univ Politecn Madrid, Ctr Automat & Robot CAR UPM CSIC, Madrid 28006, Spain.
RP Almagro, CV; Orrego, RAM (corresponding author), European Org Nucl Res CERN, BE CEM Beams Dept, Elect & Mechatron Grp, CH-1217 Geneva, Switzerland.; Almagro, CV (corresponding author), Jaume I Univ Castellon, Interact Robot Syst Lab, Castellon De La Plana 12006, Spain.; Orrego, RAM (corresponding author), Univ Politecn Madrid, Ctr Automat & Robot CAR UPM CSIC, Madrid 28006, Spain.
EM carlos.veiga.almagro@cern.ch; rena.munozo@gmail.com
CR [Anonymous], 2014, SCIPY V1 9 3 MAN
   Balasubramanian R, 2012, IEEE T ROBOT, V28, P899, DOI 10.1109/TRO.2012.2189498
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Calandra R, 2018, IEEE ROBOT AUTOM LET, V3, P3300, DOI 10.1109/LRA.2018.2852779
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Chiou M, 2022, Arxiv, DOI arXiv:2207.00648
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Di Castro M, 2018, IEEE ACCESS, V6, P37506, DOI 10.1109/ACCESS.2018.2849572
   Duan SL, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1000, DOI 10.1109/WCICA.2010.5554595
   Elaraby AF, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P247, DOI 10.1109/IEMCON.2018.8615020
   Fan Q, 2020, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR42600.2020.00407
   Graeter J, 2018, IEEE INT C INT ROBOT, P7872, DOI 10.1109/IROS.2018.8594394
   Grech L, 2018, IEEE INT CON AUTO SC, P817, DOI 10.1109/COASE.2018.8560485
   Hambarde P, 2019, IEEE IMAGE PROC, P989, DOI [10.1109/icip.2019.8803027, 10.1109/ICIP.2019.8803027]
   Hartley Richard, 2003, MULTIPLE VIEW GEOMET, DOI [10.1016/S0143-8166(01)00145-2, 10.1017/CBO9780511811685, DOI 10.1017/CBO9780511811685]
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]
   Hsu GS, 2012, INT C PATT RECOG, P3500
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Kao I, 1997, IEEE T ROBOTIC AUTOM, V13, P557, DOI 10.1109/70.611319
   Kok-Meng Lee, 1999, 1999 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (Cat. No.99TH8399), P354, DOI 10.1109/AIM.1999.803192
   Kumra S, 2017, IEEE INT C INT ROBOT, P769, DOI 10.1109/IROS.2017.8202237
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Lars W.L., 2000, EXTENDED ARM MAN HIS
   Lee MA, 2020, IEEE T ROBOT, V36, P582, DOI 10.1109/TRO.2019.2959445
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lin TY, 2018, Arxiv, DOI arXiv:1708.02002
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, Arxiv, DOI [arXiv:1512.02325, DOI 10.48550/ARXIV.1512.02325]
   Lowe D., 1999, P INT C COMPUTER VIS, V2, P1150
   Lunchi G, 2019, IEEE ACCESS, V7, P127290, DOI 10.1109/ACCESS.2019.2939493
   May S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1673, DOI 10.1109/IROS.2009.5354684
   Moghari M D., 2019, 2019 IEEE NUCL SCI S
   Mohammed MQ, 2020, IEEE ACCESS, V8, P178450, DOI 10.1109/ACCESS.2020.3027923
   Nakajima C, 2000, INT C PATT RECOG, P787, DOI 10.1109/ICPR.2000.903035
   Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680
   Noraky J, 2020, IEEE T CIRC SYST VID, V30, P1524, DOI 10.1109/TCSVT.2019.2907904
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park H.J., 2020, INDONES J ELECT ENG, V19, P1021, DOI [10.11591/ijeecs.v19.i2.pp1021-1027, DOI 10.11591/IJEECS.V19.I2.PP1021-1027]
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Ronneberger O, 2015, Arxiv, DOI arXiv:1505.04597
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sanz P., 2008, THESIS U JAUME I CAS
   Saravanakumar S., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P79, DOI 10.1109/ICSIP.2010.5697446
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Schneider & Company, COEFF FRICT REF CHAR
   Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI DOI 10.1109/CVPR.2006.19
   Shi CQ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114283
   Shin YS, 2018, IEEE INT CONF ROBOT, P5144, DOI 10.1109/ICRA.2018.8461102
   Tongphu S., 2012, P 2012 9 INT C ELECT, P1, DOI [10.1109/ECTICon.2012.6254268, DOI 10.1109/ECTICON.2012.6254268]
   Almagro CV, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143220
   Velasco E, 2020, REV IBEROAM AUTOM IN, V17, P44, DOI 10.4995/riai.2019.10923
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P275, DOI 10.1109/ICCV.2001.937529
   Yamaguchi T., 2007, P 2007 14 INT WORKSH, P426, DOI [10.1109/IWSSIP.2007.4381132, DOI 10.1109/IWSSIP.2007.4381132]
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang Y, 2012, COMPUT MATH APPL, V64, P1235, DOI 10.1016/j.camwa.2012.03.067
   Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912
   Yoshida T, 2014, FIELD SERVICE ROBOTI, P19
   Zeng A, 2018, IEEE INT C INT ROBOT, P4238, DOI 10.1109/IROS.2018.8593986
   Zhang ZB, 2013, IEEE T CIRC SYST VID, V23, P1795, DOI 10.1109/TCSVT.2013.2269023
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou MH, 2020, PROC CVPR IEEE, P11771, DOI 10.1109/CVPR42600.2020.01179
NR 72
TC 0
Z9 0
U1 3
U2 3
PD JUN 5
PY 2023
VL 23
IS 11
AR 5344
DI 10.3390/s23115344
UT WOS:001005309100001
DA 2023-11-16
ER

PT J
AU Ielmini, D
   Pedretti, G
AF Ielmini, Daniele
   Pedretti, Giacomo
TI Device and Circuit Architectures for In-Memory Computing
SO ADVANCED INTELLIGENT SYSTEMS
DT Review
DE artificial intelligence; in-memory computing; machine learning;
   memories; neural networks
ID PHASE-CHANGE MATERIALS; RANDOM-ACCESS MEMORY; CONTENT-ADDRESSABLE
   MEMORY; RESISTIVE SWITCHES; LOGIC OPERATIONS; NEURAL-NETWORKS; CROSSBAR
   ARRAY; PART I; OXIDE; RESISTANCE
AB With the rise in artificial intelligence (AI), computing systems are facing new challenges related to the large amount of data and the increasing burden of communication between the memory and the processing unit. In-memory computing (IMC) appears as a promising approach to suppress the memory bottleneck and enable higher parallelism of data processing, thanks to the memory array architecture. As a result, IMC shows a better throughput and lower energy consumption with respect to the conventional digital approach, not only for typical AI tasks, but also for general-purpose problems such as constraint satisfaction problems (CSPs) and linear algebra. Herein, an overview of IMC is provided in terms of memory devices and circuit architectures. First, the memory device technologies adopted for IMC are summarized, focusing on both charge-based memories and emerging devices relying on electrically induced material modification at the chemical or physical level. Then, the computational memory programming and the corresponding device nonidealities are described with reference to offline and online training of IMC circuits. Finally, array architectures for computing are reviewed, including typical architectures for neural network accelerators, content addressable memory (CAM), and novel circuit topologies for general-purpose computing with low complexity.
C1 [Ielmini, Daniele; Pedretti, Giacomo] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Piazza L da Vinci 32, I-20133 Milan, Italy.
   [Ielmini, Daniele; Pedretti, Giacomo] Italian Univ Nanoelect Team IUNET, Piazza L da Vinci 32, I-20133 Milan, Italy.
RP Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Piazza L da Vinci 32, I-20133 Milan, Italy.; Ielmini, D (corresponding author), Italian Univ Nanoelect Team IUNET, Piazza L da Vinci 32, I-20133 Milan, Italy.
EM daniele.ielmini@polimi.it
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ambrogio S, 2016, IEEE T ELECTRON DEV, V63, P1508, DOI 10.1109/TED.2016.2526647
   Ambrogio S, 2015, IEEE T ELECTRON DEV, V62, P3812, DOI 10.1109/TED.2015.2477135
   Ambrogio S, 2014, IEEE T ELECTRON DEV, V61, P2912, DOI 10.1109/TED.2014.2330200
   [Anonymous], 2015, DEEP LEARNING, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2019, ARXIV190907514
   [Anonymous], 2019, ARXIV190311194CS
   Athmanathan A, 2016, IEEE J EM SEL TOP C, V6, P87, DOI 10.1109/JETCAS.2016.2528598
   Baek IG, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Baek IG, 2005, INT EL DEVICES MEET, P769
   Balatti S, 2015, IEEE T ELECTRON DEV, V62, P3365, DOI 10.1109/TED.2015.2463104
   Balatti S, 2015, IEEE J EM SEL TOP C, V5, P214, DOI 10.1109/JETCAS.2015.2426492
   Balatti S, 2015, IEEE T ELECTRON DEV, V62, P1831, DOI 10.1109/TED.2015.2422999
   Balatti S, 2013, IEEE ELECTR DEVICE L, V34, P861, DOI 10.1109/LED.2013.2261451
   Bez R, 2003, P IEEE, V91, P489, DOI 10.1109/JPROC.2003.811702
   Bi GQ, 1998, J NEUROSCI, V18, P10464, DOI 10.1523/jneurosci.18-24-10464.1998
   BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32, DOI 10.1523/jneurosci.02-01-00032.1982
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boscke T. S., 2011, IEDM, P24, DOI [10.1109/IEDM.2011.6131606, DOI 10.1109/IEDM.2011.6131606]
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Bricalli A, 2018, IEEE T ELECTRON DEV, V65, P122, DOI 10.1109/TED.2017.2776085
   Bryan K, 2006, SIAM REV, V48, P569, DOI 10.1137/050623280
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Carboni R, 2019, IEEE T ELECTRON DEV, V66, P4176, DOI 10.1109/TED.2019.2933315
   Carboni R, 2018, IEEE T ELECTRON DEV, V65, P2470, DOI 10.1109/TED.2018.2822343
   Cassinerio M, 2013, ADV MATER, V25, P5975, DOI 10.1002/adma.201301940
   Chang CC, 2018, IEEE J EM SEL TOP C, V8, P116, DOI 10.1109/JETCAS.2017.2771529
   Chanthbouala A, 2012, NAT NANOTECHNOL, V7, P101, DOI [10.1038/NNANO.2011.213, 10.1038/nnano.2011.213]
   Chappert C, 2007, NAT MATER, V6, P813, DOI 10.1038/nmat2024
   Chen B, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Chen WH, 2019, NAT ELECTRON, V2, P420, DOI 10.1038/s41928-019-0288-0
   Chen YC, 2003, 2003 IEEE INTERNATIONAL ELECTRON DEVICES MEETING, TECHNICAL DIGEST, P905
   Cheng HY, 2018, INT EL DEVICES MEET
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chicca E, 2014, P IEEE, V102, P1367, DOI 10.1109/JPROC.2014.2313954
   Ciocchini N, 2012, IEEE T ELECTRON DEV, V59, P3084, DOI 10.1109/TED.2012.2214784
   Cosemans S, 2019, INT EL DEVICES MEET
   Cubukcu M, 2014, APPL PHYS LETT, V104, DOI 10.1063/1.4863407
   Engel BN, 2005, IEEE T MAGN, V41, P132, DOI 10.1109/TMAG.2004.840847
   Fantini P, 2012, APPL PHYS LETT, V100, DOI 10.1063/1.3674311
   Florent K., 2018, 2018 IEEE INT EL DEV
   Fuller EJ, 2019, SCIENCE, V364, P570, DOI 10.1126/science.aaw5581
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Gabardi S, 2015, PHYS REV B, V92, DOI 10.1103/PhysRevB.92.054201
   Gao LG, 2016, IEEE T ELECTRON DEV, V63, P3109, DOI 10.1109/TED.2016.2578720
   Garbin D, 2015, IEEE T ELECTRON DEV, V62, P2494, DOI 10.1109/TED.2015.2440102
   Garello K, 2014, APPL PHYS LETT, V105, DOI 10.1063/1.4902443
   Garey M., 1979, COMPUTERS INTRACTABI
   Giannopoulos I, 2018, INT EL DEVICES MEET
   Gokmen T, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993573
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gopalakrishnan K, 2010, S VLSI TECH, P205, DOI 10.1109/VLSIT.2010.5556229
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Graves CE, 2019, IEEE T NANOTECHNOL, V18, P963, DOI 10.1109/TNANO.2019.2936239
   Grollier J, 2016, P IEEE, V104, P2024, DOI 10.1109/JPROC.2016.2597152
   Gu Y, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P1, DOI 10.1109/DASC.2014.10
   Guo Q., 2013, 2013 ACM IEEE 43 ANN, P189
   Guo Q, 2011, INT SYMP MICROARCH, P339
   Hai K., 2019, MIT TECHNOL REV
   Hasegawa T, 2012, ADV MATER, V24, P252, DOI 10.1002/adma.201102597
   HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141
   HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hosomi M, 2005, INT EL DEVICES MEET, P473
   Hsieh M.-C., 2013, 2013 IEEE INT EL DEV, p10.3.1
   Hsu CW, 2014, NANOTECHNOLOGY, V25, DOI 10.1088/0957-4484/25/16/165202
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hua QL, 2019, GLOB CHALL, V3, DOI 10.1002/gch2.201900015
   Huang P, 2016, ADV MATER, V28, P9758, DOI 10.1002/adma.201602418
   Hui F, 2017, ADV ELECTRON MATER, V3, DOI 10.1002/aelm.201600195
   Ielmini D, 2007, IEEE T ELECTRON DEV, V54, P308, DOI 10.1109/TED.2006.888752
   Ielmini D, 2020, NANOTECHNOLOGY, V31, DOI 10.1088/1361-6528/ab554b
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Ielmini D, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/6/063002
   Ielmini D, 2011, MATER TODAY, V14, P600, DOI 10.1016/S1369-7021(11)70301-7
   Ielmini D, 2011, PHASE TRANSIT, V84, P570, DOI 10.1080/01411594.2011.561478
   Ielmini D, 2011, IEEE T ELECTRON DEV, V58, P4309, DOI 10.1109/TED.2011.2167513
   Ielmini D, 2009, IEEE T ELECTRON DEV, V56, P1070, DOI 10.1109/TED.2009.2016397
   Ikeda S, 2010, NAT MATER, V9, P721, DOI [10.1038/nmat2804, 10.1038/NMAT2804]
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jang JW, 2015, IEEE ELECTR DEVICE L, V36, P457, DOI 10.1109/LED.2015.2418342
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kau D, 2009, INT EL DEVICES MEET, P571
   Kim H., 2019, ARXIV190710228
   Kim S., 2013, 2013 IEEE INT EL DEV
   Kim S., 2019, 2019 IEEE INT EL DEV
   Kim T, 2018, INT EL DEVICES MEET
   Kumar S, 2017, NATURE, V548, P318, DOI 10.1038/nature23307
   Kuzum D, 2012, NANO LETT, V12, P2179, DOI 10.1021/nl201040y
   Le Gallo M, 2018, IEEE T ELECTRON DEV, V65, P4304, DOI 10.1109/TED.2018.2865352
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Lee MJ, 2007, INT EL DEVICES MEET, P771, DOI 10.1109/IEDM.2007.4419061
   Lee MJ, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3629
   Li C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15254-4
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Li F, 2004, IEEE T DEVICE MAT RE, V4, P416, DOI 10.1109/TDMR.2004.837118
   Li TK, 2002, JPN J APPL PHYS 1, V41, P6890, DOI 10.1143/JJAP.41.6890
   Liang JL, 2012, IEEE T ELECTRON DEV, V59, P1155, DOI 10.1109/TED.2012.2184542
   Lin YH, 2019, IEEE T ELECTRON DEV, V66, P1289, DOI 10.1109/TED.2019.2894273
   Linn E, 2010, NAT MATER, V9, P403, DOI [10.1038/NMAT2748, 10.1038/nmat2748]
   Liu TY, 2013, ISSCC DIG TECH PAP I, V56, P210, DOI 10.1109/ISSCC.2013.6487703
   Mahmoodi MR, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13103-7
   Mahmoodi M.R., 2019, 2019 IEEE INT ELECT
   Malavena G, 2019, IEEE T ELECTRON DEV, V66, P4733, DOI 10.1109/TED.2019.2940599
   Malavena G, 2019, IEEE T ELECTRON DEV, V66, P4727, DOI 10.1109/TED.2019.2940602
   Mantegazza D, 2006, INT EL DEVICES MEET, P519
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Merrikh-Bayat F, 2018, IEEE T NEUR NET LEAR, V29, P4782, DOI 10.1109/TNNLS.2017.2778940
   Midya R, 2017, ADV MATER, V29, DOI 10.1002/adma.201604457
   Mikolajick T, 2001, MICROELECTRON RELIAB, V41, P947, DOI 10.1016/S0026-2714(01)00049-X
   Milo V, 2019, PROC EUR S-STATE DEV, P174, DOI 10.1109/essderc.2019.8901818
   Milo V, 2019, APL MATER, V7, DOI 10.1063/1.5108650
   Milo V., 2017, 2017 IEEE International Electron Devices Meeting (IEDM), p11.2.1, DOI 10.1109/IEDM.2017.8268369
   MOORE GE, 1965, ELECTRONICS, V38, DOI DOI 10.1109/N-SSC.2006.4785860
   Mulaosmanovic H, 2017, ACS APPL MATER INTER, V9, P3792, DOI 10.1021/acsami.6b13866
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Nirschl T, 2007, INT EL DEVICES MEET, P461, DOI 10.1109/IEDM.2007.4418973
   Oh S, 2018, IEEE ELECTR DEVICE L, V39, P1768, DOI 10.1109/LED.2018.2872434
   Ohno T, 2011, NAT MATER, V10, P591, DOI [10.1038/NMAT3054, 10.1038/nmat3054]
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Pedretti G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05480-0
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Pickett MD, 2013, NAT MATER, V12, P114, DOI [10.1038/nmat3510, 10.1038/NMAT3510]
   Rao MY, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993465
   Raoux S, 2008, IBM J RES DEV, V52, P465, DOI 10.1147/rd.524.0465
   Raoux S, 2010, CHEM REV, V110, P240, DOI 10.1021/cr900040x
   Richter I, 2015, GOV MICR APPL CRIT T
   Romero LP, 2019, FARADAY DISCUSS, V213, P371, DOI 10.1039/c8fd00107c
   Russo U., 2009, IEEE T ELECTRON DEV, V56, P5
   Sakai S, 2008, 2008 JOINT NON-VOLATILE SEMICONDUCTOR MEMORY WORKSHOP AND INTERNATIONAL CONFERENCE ON MEMORY TECHNOLOGY AND DESIGN, PROCEEDINGS, P103, DOI 10.1109/NVSMW.2008.36
   Sakamoto T, 2003, APPL PHYS LETT, V82, P3032, DOI 10.1063/1.1572964
   Sakhare S, 2018, INT EL DEVICES MEET
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Sangwan VK, 2018, NATURE, V554, P500, DOI 10.1038/nature25747
   Sangwan VK, 2015, NAT NANOTECHNOL, V10, P403, DOI [10.1038/nnano.2015.56, 10.1038/NNANO.2015.56]
   Sawa A, 2008, MATER TODAY, V11, P28, DOI 10.1016/S1369-7021(08)70119-6
   Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653
   Servalli G, 2009, INT EL DEVICES MEET, P103
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/nnano.2017.83, 10.1038/NNANO.2017.83]
   Shin JH, 2018, INT EL DEVICES MEET
   Son M, 2011, IEEE ELECTR DEVICE L, V32, P1579, DOI 10.1109/LED.2011.2163697
   Truong SN, 2014, J SEMICOND TECH SCI, V14, P356, DOI 10.5573/JSTS.2014.14.3.356
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Tang JS, 2018, INT EL DEVICES MEET
   Tang MH, 2011, IEEE T ELECTRON DEV, V58, P370, DOI 10.1109/TED.2010.2090883
   Tracy T, 2016, LECT NOTES COMPUT SC, V9697, P200, DOI 10.1007/978-3-319-41321-1_11
   Tsai CL, 2013, ACS NANO, V7, P5360, DOI 10.1021/nn401212p
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/NMAT4856, 10.1038/nmat4856]
   Wang Q., 2019, 2019 IEEE INT EL DEV, p14.4.1
   Wang ZQ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15158-3
   Wang ZQ, 2015, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00438
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wang ZR, 2018, NAT ELECTRON, V1, P137, DOI 10.1038/s41928-018-0023-2
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Woo J., 2013, 2013 S VLSI TECHN VL, P168
   Wootae Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P37, DOI 10.1109/VLSIT.2012.6242449
   Wu T, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT GREEN BUILDING AND SMART GRID (IGBSG 2019), P631, DOI 10.1109/IGBSG.2019.8886333
   Xiong F, 2011, SCIENCE, V332, P568, DOI 10.1126/science.1201938
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang TJ, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993662
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yu M, 2016, SCI REP-UK, V6, DOI 10.1038/srep21020
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Yu SM, 2013, ACS NANO, V7, P2320, DOI 10.1021/nn305510u
   Zamarreño-Ramos C, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00026
   Zhang ZP, 2015, IEEE ELECTR DEVICE L, V36, P29, DOI 10.1109/LED.2014.2367542
   Zhao M., 2018, 2018 IEEE INT EL DEV, p20.2.1
   Zhou Y, 2019, ADV FUNCT MATER, V29, DOI 10.1002/adfm.201900155
   Zhou Z, 2018, INT EL DEVICES MEET
   Zhu XJ, 2019, NAT MATER, V18, P141, DOI 10.1038/s41563-018-0248-5
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 187
TC 74
Z9 74
U1 7
U2 74
PD JUL
PY 2020
VL 2
IS 7
AR 2000040
DI 10.1002/aisy.202000040
UT WOS:000669780200011
DA 2023-11-16
ER

PT J
AU Rahmani, AM
   Mirmahaleh, SYH
AF Rahmani, Amir Masoud
   Mirmahaleh, Seyedeh Yasaman Hosseini
TI A predictor circuit and a delay-aware algorithm for identifying data
   transfer pattern on NoC-based communication networks
SO MICROELECTRONICS JOURNAL
DT Article
DE Prediction; Processing-in-memory (PIM); Address assignment; Pattern
   recognition; Network-on-Chip (NoC)
ID HIGH-THROUGHPUT; ACCELERATOR; CNN
AB Deploying the Internet of Things and machine learning (ML)-based applications increased processing rate and data transfer between main memory and processing elements (PEs) in NoC-based communication networks, leading to memory access problems. Predicting and identifying reusable data for different tasks can reduce memory accesses and support various applications with high flexibility. Therefore, we propose a method to minimize memory access. It provides a predictor circuit to assign the address for PEs based on data buffering into task cores due to their reusability. We also present a delay-aware algorithm to investigate the initial relationship between tasks and identify a similar pattern for the mapped task graph on the various topologies. Our algorithm and predictor circuit decrease latency for determining related data to tasks and transfers data from global buffer onto PEs and buffers them according to its reusability for tasks with similar patterns. We utilized real data of the reported COVID-19 statistics and particulate matter 2.5 (PM2.5) condensation for evaluating our method. Simulation results demonstrate reducing energy consumption, delay, memory access, and increasing area consumption by approximately 61.83%, 39.96%, 66.66%, and 0.13%, respectively, for the mapped task graphs on a mesh network before employing the circuit and algorithm.
C1 [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
   [Mirmahaleh, Seyedeh Yasaman Hosseini] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
RP Mirmahaleh, SYH (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
EM yasamanhosseini1986@gmail.com
CR Ahmed H., 2019 DES AUT TEST EU
   Do AT, 2019, IEEE T VLSI SYST, V27, P126, DOI 10.1109/TVLSI.2018.2875934
   [Anonymous], 2017 IEEE CUSTOM INT, DOI DOI 10.1109/CICC.2017.7993628
   Catania V, 2016, ACM T MODEL COMPUT S, V27, DOI 10.1145/2953878
   Chen CH, 2019, IEEE T PARALL DISTR, V30, P1738, DOI 10.1109/TPDS.2019.2892957
   Chen KC, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352376
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cho K., 2019, 2019 IEEE 28 C EL PE, P1
   Deb D, 2019, IET COMPUT DIGIT TEC, V13, P417, DOI 10.1049/iet-cdt.2019.0035
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Guo X., 2017, IEDM, P6, DOI [10.1109/iedm.2017.8268341, DOI 10.1109/IEDM.2017.8268341, 10.1109/CISP-BMEI.2017.8301926]
   Hadidi R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3155287
   Hayashikoshi M, 2020, IEEE INT MEM WORKSH, P95, DOI 10.1109/imw48823.2020.9108132
   Jeong W.S., 2019, IEEE T PARALLEL DIST, V31
   Jerger Natalie Enright, 2017, ON CHIP NETWORKS, Vsecond, p2ND
   Kang G, 2019, IEEE T VLSI SYST, V27, P1343, DOI 10.1109/TVLSI.2019.2901291
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3173162.3173176, 10.1145/3296957.3173176]
   Kwon H, 2017, INT SYM PERFORM ANAL, P195, DOI 10.1109/ISPASS.2017.7975291
   Lee DY, 2019, IEEE T VLSI SYST, V27, P1450, DOI 10.1109/TVLSI.2019.2891507
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Mirmahaleh SYH, 2020, J PARALLEL DISTR COM, V144, P80, DOI 10.1016/j.jpdc.2020.04.011
   Mirmahaleh SYH, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352378
   Mirmahaleh SYH, 2019, MICROELECTRON J, V94, DOI 10.1016/j.mejo.2019.104655
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Nabavinejad SM, 2020, IEEE J EM SEL TOP C, V10, P268, DOI 10.1109/JETCAS.2020.3022920
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Sun RD, 2020, IEEE T VLSI SYST, V28, P565, DOI 10.1109/TVLSI.2019.2945982
   Wang Y, 2019, IEEE T PARALL DISTR, V30, P589, DOI 10.1109/TPDS.2018.2868062
   Zhou SJ, 2020, IEEE T PARALL DISTR, V31, P1897, DOI 10.1109/TPDS.2020.2974744
   Zhou SJ, 2019, IEEE T PARALL DISTR, V30, P2249, DOI 10.1109/TPDS.2019.2910068
NR 36
TC 2
Z9 2
U1 1
U2 1
PD OCT
PY 2021
VL 116
AR 105250
DI 10.1016/j.mejo.2021.105250
EA SEP 2021
UT WOS:000709485800001
DA 2023-11-16
ER

PT J
AU Higham, NJ
   Pranesh, S
AF Higham, Nicholas J.
   Pranesh, Srikara
TI SIMULATING LOW PRECISION FLOATING-POINT ARITHMETIC
SO SIAM JOURNAL ON SCIENTIFIC COMPUTING
DT Article
DE floating-point arithmetic; half precision; low precision; IEEE
   arithmetic; fp16; bfloat 16; subnormal numbers; mixed precision;
   simulation; rounding error analysis; round to nearest; directed
   rounding; stochastic rounding; bit flips; MATLAB
ID ITERATIVE REFINEMENT; ACCURACY
AB The half-precision (fp16) floating-point format, defined in the 2008 revision of the IEEE standard for floating-point arithmetic, and a more recently proposed half-precision format bfloatl6, are increasingly available in GPUs and other accelerators. While the support for low precision arithmetic is mainly motivated by machine learning applications, general purpose numerical algorithms can benefit from it, too, gaining in speed, energy usage, and reduced communication costs. Since the appropriate hardware is not always available, and one may wish to experiment with new arithmetics not yet implemented in hardware, software simulations of low precision arithmetic are needed. We discuss how to simulate low precision arithmetic using arithmetic of higher precision. We examine the correctness of such simulations and explain via rounding error analysis why a natural method of simulation can provide results that are more accurate than actual computations at low precision. We provide a MATLAB function, chop, that can be used to efficiently simulate fp16, bfloatl6, and other low precision arithmetics, with or without the representation of subnormal numbers and with the options of round to nearest, directed rounding, stochastic rounding, and random bit flips in the significand. We demonstrate the advantages of this approach over defining a new MATLAB class and overloading operators.
C1 [Higham, Nicholas J.; Pranesh, Srikara] Univ Manchester, Sch Math, Manchester M13 9PL, Lancs, England.
RP Higham, NJ (corresponding author), Univ Manchester, Sch Math, Manchester M13 9PL, Lancs, England.
EM nick.higham@manchester.ac.uk; srikara.pranesh@manchester.ac.uk
CR [Anonymous], 2018, ARM ARCH REF MAN ARM
   [Anonymous], 2010, IEEE INT S PARALLEL
   [Anonymous], 1985, 7541985 IEEE ANSI
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2018, P INT C HIGH PERF CO, DOI DOI 10.1109/SC.2018.00050
   Carson E, 2018, SIAM J SCI COMPUT, V40, pA817, DOI 10.1137/17M1140819
   Carson E, 2017, SIAM J SCI COMPUT, V39, pA2834, DOI 10.1137/17M1122918
   Chantry M, 2019, MON WEATHER REV, V147, P645, DOI 10.1175/MWR-D-18-0308.1
   Cox AJ, 1999, BIT, V39, P34, DOI 10.1023/A:1022365107361
   Dawson A, 2018, CLIM DYNAM, V51, P2657, DOI 10.1007/s00382-017-4034-x
   Dawson A, 2017, GEOSCI MODEL DEV, V10, P2221, DOI 10.5194/gmd-10-2221-2017
   Dongarra J., 2014, NUMERICAL COMPUTATIO, P1
   Dutta S., 2019, CODENET TRAINING LAR
   Feldman M., 2018, IBM TAKES AIM REDUCE
   Feldman M., 2018, FUJITSU REVEALS DETA
   Feldman M., RECORD BREAKING EXAS
   Feldman M., INTEL LAYS OUT ROADM
   Figueroa S. A., 1995, SIGNUM Newsletter, V30, P21, DOI 10.1145/221332.221334
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   Haidar A., 2017, P 8 WORKSHOP LATEST, P1
   Haidar A, 2018, LECT NOTES COMPUT SC, V10860, P586, DOI 10.1007/978-3-319-93698-7_45
   Hatfield S, 2018, J ADV MODEL EARTH SY, V10, P2177, DOI 10.1029/2018MS001341
   Higham N. J., MATRIX COMPUTATION T
   Higham N. J., 2002, ACCURACY STABILITY N, DOI [10.1137/1.9780898718027, DOI 10.1137/1.9780898718027]
   Higham NJ, 2019, SIAM J SCI COMPUT, V41, pA2536, DOI 10.1137/18M1229511
   Higham NJ, 2019, SIAM J SCI COMPUT, V41, pA59, DOI 10.1137/18M1182802
   HIGHAM NJ, 1989, SIAM J NUMER ANAL, V26, P1252, DOI 10.1137/0726070
   HIGHAM NJ, 1993, SIAM J SCI COMPUT, V14, P783, DOI 10.1137/0914050
   IEEE standard for floating-point arithmetic, 2019, IEEE STANDARD FLOATI, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2019.8766229]
   Intel Corporation, 2018, CISC VIS NETW IND GL
   Isaacson E., 2012, ANAL NUMERICAL METHO
   Lefèvre V, 2017, P S COMP ARITHM, P18, DOI 10.1109/ARITH.2017.28
   MALONE D, 2013, IRISH MATH SOC B, V71, P59
   Moler C. B., HALF PRECISION 16 BI
   Moler C. B., 1982, CS811 U NEW MEX
   Moler C. B., VARIABLE FORMAT HALF
   Moler C. B., HIST MATLAB USERS GU
   O'uchi S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350953
   Palem K, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465789
   Palmer TN, 2014, PHILOS T R SOC A, V372, DOI 10.1098/rsta.2013.0391
   Rao N., CPU GPU WHY ENTERPRI
   Rau C., 2017, IEEE 1 12 IEEE 754 B
   Roux P, 2014, J FORMALIZ REASON, V7, P131
   Rump S.M., 1999, DEV RELIABLE COMPUTI, P77, DOI DOI 10.1007/978-94-017-1247-7
   Rump SM, 2017, ACM T MATH SOFTWARE, V43, DOI 10.1145/2785965
   Rump SM, 2010, ACTA NUMER, V19, P287, DOI 10.1017/S096249291000005X
   Shah V., COMMENT NJ HIGHAM HA
   Svyatkovskiy A., 2017, MLHPC 17, DOI 10.1145/3146347.3146358
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Thornes T, 2017, Q J ROY METEOR SOC, V143, P897, DOI 10.1002/qj.2974
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
   Wang Naigang, 2018, NEURIPS, P7675
   Young M, 2016, CURRICULUM AND THE SPECIALIZATION OF KNOWLEDGE: STUDIES IN THE SOCIOLOGY OF EDUCATION, P3
NR 53
TC 32
Z9 33
U1 0
U2 8
PY 2019
VL 41
IS 5
BP C585
EP C602
DI 10.1137/19M1251308
UT WOS:000493897100046
DA 2023-11-16
ER

PT C
AU Fargo, F
   Franza, O
AF Fargo, Farah
   Franza, Olivier
GP IEEE
TI Autonomic Secure HPC Architecture Against Power Attacks
SO 2018 IEEE/ACS 15TH INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS (AICCSA)
SE International Conference on Computer Systems and Applications
DT Proceedings Paper
CT 15th IEEE/ACS International Conference on Computer Systems and
   Applications (AICCSA)
CY OCT 28-NOV 01, 2018
CL Aqaba, JORDAN
DE High Performance Computing; Autonomic Computing; Security; Data
   Analytics; Power Attacks; Intrusion Detection System; Anomaly Behavior
   Analysis
AB High Performance Computing (HPC) systems are enabling broad computing capabilities across scientific simulations, data analytics, and machine learning. Such HPC systems are composed of high-end compute elements (CPUs, accelerators, co-processors...) to handle high throughput and high parallelism, which results in significant power consumption. However, the power infrastructures built for such systems are proportionately older and may not be built to sustain system's peak power for extensive periods of time. Therefore, innovative power management schemes are used to allocate power across all system's components within a given power limit. HPC power management systems regulate resources' power within budget constraints and the overall system's power limit. Failing not to limit system's power consumption can result in operational failures that can bring down the whole system. Additionally, system reliability would be compromised under extensive computational system power and temperature. In addition to power consumption, possible attack scenarios can cause reliability issues where the attackers can manipulate the reported data of the measured power that is used for power management, which in turn can misguide the schedulers or can assign tasks that will result in exceeding the power limits, leading to system failures. Hence, intrusion detection systems (IDS) for power attacks are extremely important. This paper presents a framework for power attack IDS and describe each steps to be taken.
C1 [Fargo, Farah; Franza, Olivier] Intel Corp, Hudson, MA 01749 USA.
RP Fargo, F (corresponding author), Intel Corp, Hudson, MA 01749 USA.
EM farah.e.fargo@intel.com; olivier.franza@intel.com
CR [Anonymous], 4 ANN INT C MOB UB S
   Can O, 2015, INT CONF MODEL SIM
   Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P115
   Fargo F., 2014, INT C CLOUD AUT COMP
   Fargo F., 2014, IEEE INT C CLOUD AUT
   Greengard S, 2016, COMMUN ACM, V59, P29, DOI 10.1145/2898969
   Padmavathi G., 2013, INT J NETWORK SECURI, V15, P391
   Pan Z., 2014, IEEE ACS 11 INT C CO
   Pan ZW, 2016, I C COMP SYST APPLIC
   Qu Guangzhi, 2005, IEEE T KNOWLEDGE DAT, V17
   RISTENPART T., P ACM CCS 09, P199
   Rowland C. H., 2002, U.S. Patent, Patent No. [6 405 318, 6405318, 6, 405, 318]
NR 12
TC 0
Z9 0
U1 0
U2 0
PY 2018
UT WOS:000457628800030
DA 2023-11-16
ER

PT C
AU Sun, XY
   Peng, XC
   Chen, PY
   Liu, R
   Seo, JS
   Yu, SM
AF Sun, Xiaoyu
   Peng, Xiaochen
   Chen, Pai-Yu
   Liu, Rui
   Seo, Jae-sun
   Yu, Shimeng
GP IEEE
TI Fully Parallel RRAM Synaptic Array for Implementing Binary Neural
   Network with (+1,-1) Weights and (+1,0) Neurons
SO 2018 23RD ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 22-25, 2018
CL Jeju, SOUTH KOREA
AB Binary Neural Networks (BNNs) have been recently proposed to improve the area-/energy-efficiency of the machine/deep learning hardware accelerators, which opens an opportunity to use the technologically more mature binary RRAM devices to effectively implement the binary synaptic weights. In addition, the binary neuron activation enables using the sense amplifier instead of the analog-to-digital converter to allow bitwise communication between layers of the neural networks. However, the sense amplifier has intrinsic offset that affects the threshold of binary neuron, thus it may degrade the classification accuracy. In this work, we analyze a fully parallel RRAM synaptic array architecture that implements the fully connected layers in a convolutional neural network with (+1, -1) weights and (+1, 0) neurons. The simulation results with TSMC 65 nm PDK show that the offset of current mode sense amplifier introduces a slight accuracy loss from similar to 98.5% to similar to 97.6% for MNIST dataset. Nevertheless, the proposed fully parallel BNN architecture (P-BNN) can achieve 137.35 TOPS/W energy efficiency for the inference, improved by similar to 20X compared to the sequential BNN architecture (S-BNN) with row-by-row read-out scheme. Moreover, the proposed P-BNN architecture can save the chip area by similar to 16% as it eliminates the area overhead of MAC peripheral units in the S-BNN architecture.
C1 [Sun, Xiaoyu; Peng, Xiaochen; Chen, Pai-Yu; Liu, Rui; Seo, Jae-sun; Yu, Shimeng] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
RP Yu, SM (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
EM shimengy@asu.edu
CR [Anonymous], 2016, ARXIV160305279
   Burr G. W, 2014, IEEE IEDM
   Chang M.-F., 2012, IEEE ICSICT
   Chang MF, 2013, IEEE J SOLID-ST CIRC, V48, P864, DOI 10.1109/JSSC.2012.2235013
   Chen P.-Y., 2015, ACM IEEE ICCAD
   Chen  Y.-H., 2016, IEEE ISSCC
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Fackenthal R., 2014, IEEE ISSCC
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Krizhevsky A, 2012, NIPS 2012, V1, P1097, DOI 10.1061/(ASCE)GT.1943-5606.0001284
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B., 2015, ACM IEEE DAC
   Park S., 2013, IEEE IEDM
   Tang  T., 2017, ACM IEEE ASP DAC
   Yu  S., 2016, IEEE IEDM
NR 16
TC 57
Z9 60
U1 1
U2 15
PY 2018
BP 574
EP 579
UT WOS:000426987100110
DA 2023-11-16
ER

PT C
AU Colangelo, P
   Segal, O
   Speicher, A
   Margala, M
AF Colangelo, Philip
   Segal, Oren
   Speicher, Alex
   Margala, Martin
GP IEEE
TI Automated Hardware and Neural Network Architecture co-design of FPGA
   accelerators using multi-objective Neural Architecture Search
SO 2020 IEEE 10TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS
   (ICCE-BERLIN)
SE International Conference on Consumer Electronics
DT Proceedings Paper
CT 10th IEEE International Conference on Consumer Electronics (ICCE-Berlin)
CY NOV 09-11, 2020
CL Berlin, GERMANY
DE Evolutionary Algorithms; Machine Learning; FPGA; Automated Design
AB State-of-the-art Neural Network Architectures (NNAs) are challenging to design and implement efficiently in hardware. In the past couple of years, this has led to an explosion in research and development of automatic Neural Architecture Search (NAS) tools. AutoML tools are now used to achieve state of the art NNA designs and attempt to optimize for hardware usage and design. Much of the recent research in the auto-design of NNAs has focused on convolution networks and image recognition, ignoring the fact that a significant part of the workload in data centers is general-purpose deep neural networks. In this work, we develop and test a general multilayer perceptron (MLP) flow that can take arbitrary datasets as input and automatically produce optimized NNAs and hardware designs. We test the flow on six benchmarks. Our results show we exceed the performance of currently published MLP accuracy results and are competitive with non-MLP based results. We compare general and common GPU architectures with our scalable FPGA design and show we can achieve higher efficiency and higher throughput (outputs per second) for the majority of datasets. Further insights into the design space for both accurate networks and high performing hardware shows the power of co-design by correlating accuracy versus throughput, network size versus accuracy, and scaling to high-performance devices.
C1 [Colangelo, Philip] Intel PSG, San Jose, CA 95134 USA.
   [Segal, Oren; Speicher, Alex] Hofstra Univ, Hempstead, NY 11550 USA.
   [Margala, Martin] Univ Massachusetts Lowell, Lowell, MA USA.
RP Colangelo, P (corresponding author), Intel PSG, San Jose, CA 95134 USA.
EM philip.colangelo@intel.com; oren.segal@hofstra.edu;
   aspeicher1@pride.hofstra.edu; Martin_Margala@uml.edu
CR [Anonymous], 2017, CORR ABS170807747
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Colangelo P, 2019, IEEE HIGH PERF EXTR
   Culurciello E., 2016, ARXIV PREPRINT ARXIV
   Fernando C., 2017, ARXIV PREPRINT ARXIV
   GOLD D, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P69, DOI 10.1109/ACSSC.1991.186416
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   LeCun Y., 1998, MNIST DATABASE HANDW
   MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379
   Park J., 2018, ARXIV PREPRINT ARXIV
   Real E., 2017, ICML, P2902
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Vanschoren J., 2013, SIGKDD EXPLOR NEWSL, V15, P49, DOI DOI 10.1145/2641190.2641198
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Vishwanath A., 2016, CISC VIS NETW IND GL
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/ICCE-Berlin50680.2020.9352153
UT WOS:000657309100002
DA 2023-11-16
ER

PT C
AU Fawzi, H
   Goulbourne, H
AF Fawzi, Hamza
   Goulbourne, Harry
BE Ranzato, M
   Beygelzimer, A
   Dauphin, Y
   Liang, PS
   Vaughan, JW
TI Faster proximal algorithms for matrix optimization using Jacobi-based
   eigenvalue methods
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 34 (NEURIPS 2021)
SE Advances in Neural Information Processing Systems
DT Proceedings Paper
CT 35th Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 06-14, 2021
CL ELECTR NETWORK
ID THRESHOLDING ALGORITHM; SEMIDEFINITE; CONVERGENCE
AB We consider proximal splitting algorithms for convex optimization problems over matrices. A significant computational bottleneck in many of these algorithms is the need to compute a full eigenvalue or singular value decomposition at each iteration for the evaluation of a proximal operator.
   In this paper we propose to use an old and surprisingly simple method due to Jacobi to compute these eigenvalue and singular value decompositions, and we demonstrate that it can lead to substantial gains in terms of computation time compared to standard approaches. We rely on three essential properties of this method: (a) its ability to exploit an approximate decomposition as an initial point, which in the case of iterative optimization algorithms can be obtained from the previous iterate; (b) its parallel nature which makes it a great fit for hardware accelerators such as GPUs, now common in machine learning, and (c) its simple termination criterion which allows us to trade-off accuracy with computation time. We demonstrate the efficacy of this approach on a variety of algorithms and problems, and show that, on a GPU, we can obtain 5 to 10x speed-ups in the evaluation of proximal operators compared to standard CPU or GPU linear algebra routines. Our findings are supported by new theoretical results providing guarantees on the approximation quality of proximal operators obtained using approximate eigenvalue or singular value decompositions.
C1 [Fawzi, Hamza; Goulbourne, Harry] Univ Cambridge, Dept Appl Math & Theoret Phys, Cambridge, England.
RP Fawzi, H (corresponding author), Univ Cambridge, Dept Appl Math & Theoret Phys, Cambridge, England.
EM hf323@cam.ac.uk; hmg42@cam.ac.uk
CR [Anonymous], J REINE ANGEW MATH, DOI DOI 10.1515/CR11.1846.30.51
   Bandeira A. S., 2016, P 29 C LEARNING THEO, V49, P361
   Barre Mathieu, 2020, ARXIV200606041
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Ben-Tal A., 2001, LECT MODERN CONVEX O
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Burer S, 2003, MATH PROGRAM, V95, P329, DOI 10.1007/s10107-002-0352-8
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chao HH, 2018, IEEE T SIGNAL PROCES, V66, P4826, DOI 10.1109/TSP.2018.2862399
   Davis C., 1957, ARCH MATH, V8, P276, DOI [10.1007/BF01898787, DOI 10.1007/BF01898787]
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Forsythe G. E., 1960, T AM MATH SOC, V94, P1, DOI DOI 10.1090/S0002-9947-1960-0109825-2
   Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045
   Fukuda M., 2000, SIAM Journal on Optimization, V11, P647, DOI 10.1137/S1052623400366218
   Golub Gene H, 2013, MATRIX COMPUTATIONS, P4, DOI DOI 10.56021/9781421407944
   Goulart PJ, 2020, LINEAR ALGEBRA APPL, V594, P177, DOI 10.1016/j.laa.2020.02.014
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Helmberg C, 2000, SIAM J OPTIMIZ, V10, P673, DOI 10.1137/S1052623497328987
   Jiang Xin, 2021, BREGMAN PRIMAL DUAL
   Knyazev AV, 2001, SIAM J SCI COMPUT, V23, P517, DOI 10.1137/S1064827500366124
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   LEWIS A. S., 1995, J CONVEX ANAL, V2, P173
   Madani R, 2015, IEEE DECIS CONTR P, P5932, DOI 10.1109/CDC.2015.7403152
   Marshall Albert W, 1979, INEQUALITIES THEORY, V143
   Nesterov Y, 2004, INTRO LECT CONVEX OP, DOI [10.1007/978-1-4419-8853-9, DOI 10.1007/978-1-4419-8853-9]
   NVIDIA, 2020, CUS LIB
   O'Donoghue B, 2016, J OPTIMIZ THEORY APP, V169, P1042, DOI 10.1007/s10957-016-0892-3
   ODonoghue B., 2019, SCS SPLITTING CONIC
   Okuta R., 2017, P WORKSHOP MACHINE L
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Renegar James, 2014, ARXIV14095832
   Rontsis Nikitas, 2019, ARXIV191202767
   Scheinberg Katya, 2010, ARXIV10110097
   Schmidt M., 2011, NEURAL INFORM PROCES, P415
   Schonhage A, 1964, NUMERISCHE MATH
   Trefethen L. N., 1997, NUMERICAL LINEAR ALG, V50
   VANKEMPEN HP, 1966, NUMER MATH, V9, P19, DOI 10.1007/BF02165225
   VANKEMPEN HP, 1966, NUMER MATH, V9, P11, DOI 10.1007/BF02165224
   Wilkinson J. H., 1962, NUMER MATH, V4, P296, DOI [10.1007/BF01386321, DOI 10.1007/BF01386321]
   Yao W., 2016, THESIS TU MUNCHEN
   Yurtsever A, 2021, SIAM J MATH DATA SCI, V3, P171, DOI 10.1137/19M1305045
   ZHENG C, 2006, P 23 INT C MACH LEAR, P89
   Zheng Y, 2020, MATH PROGRAM, V180, P489, DOI 10.1007/s10107-019-01366-3
NR 46
TC 0
Z9 0
U1 0
U2 0
PY 2021
VL 34
UT WOS:000922928201021
DA 2023-11-16
ER

PT C
AU Khandelwal, A
   Kejariwal, A
   Ramasamy, K
AF Khandelwal, Anurag
   Kejariwal, Arun
   Ramasamy, Karthikeyan
GP Assoc Comp Machinery
TI <i>Le Taureau</i>: Deconstructing the Serverless Landscape & A Look
   Forward
SO SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE
   ON MANAGEMENT OF DATA
DT Proceedings Paper
CT ACM SIGMOD International Conference on Management of Data (SIGMOD)
CY JUN 14-19, 2020
CL ELECTR NETWORK
AB Akin to the natural evolution of programming in assembly language to high-level languages, serverless computing represents the next frontier in the evolution of cloud computing: bare metal. virtual machines. containers. serverless. The genesis of serverless computing can be traced back to the fundamental need of enabling a programmer to singularly focus on writing application code in a high-level language and isolating all facets of system management (for example, but not limited to, instance selection, scaling, deployment, logging, monitoring, fault tolerance and so on). This is particularly critical in light of today's, increasingly tightening, time-to-market constraints. Currently, serverless computing is supported by leading public cloud vendors, such as AWS Lambda, Google Cloud Functions, Azure Cloud Functions and others. While this is an important step in the right direction, there are many challenges going forward. For instance, but not limited to, how to enable support for dynamic optimization, how to extend support for stateful computation, how to efficiently bin-pack applications, how to support hardware heterogeneity (this will be key especially in light of the emergence of hardware accelerators for deep learning workloads).
   Inspired by Picasso's Le Taureau(1), in the tutorial proposed herein, we shall deconstruct evolution of serverless the overarching intent being to facilitate better understanding of the serverless landscape. This, we hope, would help push the innovation frontier on both fronts, the paradigm itself and the applications built atop of it.
C1 [Khandelwal, Anurag] Yale Univ, New Haven, CT 06520 USA.
   [Kejariwal, Arun] Facebook Inc, Menlo Pk, CA USA.
   [Ramasamy, Karthikeyan] Splunk Inc, San Francisco, CA USA.
RP Khandelwal, A (corresponding author), Yale Univ, New Haven, CT 06520 USA.
CR Akkus IE, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P923
   Anil R., 2018, COMPUTING RES REPOSI
   [Anonymous], DATA STREAMS MODELS
   [Anonymous], 2019, IEEE T MED IMAGING, DOI [DOI 10.1109/TMI.2018.2867261, 10.1016/j.isci.2022.105043]
   [Anonymous], 2016, 8 USENIX WORKSH HOT
   [Anonymous], 2018, SERVERLESS ARCHITECT
   [Anonymous], 2018, SERVERLESS COMMUNITY
   Ao LX, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P263, DOI 10.1145/3267809.3267815
   Arik S. O., 2017, P INT C MACH LEARN
   Aytekin A, 2019, IEEE INT CONF CLOUD, P499, DOI 10.1109/CLOUD.2019.00090
   Banerjee S., 2019, COMPUTING RES REPOSI
   Bugnion E, 1997, ACM T COMPUT SYST, V15, P412, DOI [10.1145/265924.265930, 10.1145/269005.266672]
   Cai H, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P661, DOI 10.1145/3018661.3018702
   Carreira J, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P13, DOI 10.1145/3357223.3362711
   Carter J. B., 1995, Proceedings Fifth Workshop on Hot Topics in Operating Systems (HotOS-V) (Cat. No.95TH8059), P119, DOI 10.1109/HOTOS.1995.513466
   Castro M., P S NETW SYST DES IM
   Castro P, 2019, COMMUN ACM, V62, P44, DOI 10.1145/3368454
   Chard R., 2019, ABS190804907 CORR
   Chen X., 2017, COMPUTING RES REPOSI
   Choi S., 2019, COMPUTING RES REPOSI
   Cormode G, 2005, J ALGORITHMS, V55, P58, DOI 10.1016/j.jalgor.2003.12.001
   Cormode G., 2007, REFERENCES DATA STRE
   CREASY RJ, 1981, IBM J RES DEV, V25, P483, DOI 10.1147/rd.255.0483
   DASGUPTA P, 1991, COMPUTER, V24, P34, DOI 10.1109/2.116849
   Dean J., 2012, P C NEUR INF PROC SY
   Falkner S., 2018, COMPUTING RES REPOSI
   Feng L, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P334, DOI 10.1109/CLOUD.2018.00049
   Figiela K., 2017, FUTURE GENER COMP SY
   Fingler H, 2019, APSYS'19: PROCEEDINGS OF THE 10TH ACM SIGOPS ASIA-PACIFIC WORKSHOP ON SYSTEMS, P23, DOI 10.1145/3343737.3343750
   Fouladi S, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P363
   Gabbrielli M., 2019, COMPUTING RES REPOSI
   Gafni O., 2019, COMPUTING RES REPOSI
   López PG, 2018, INT CONF UTIL CLOUD, P148, DOI 10.1109/UCC-Companion.2018.00049
   Garcia-Lopez P, 2019, SERVERMIX TRADEOFFS
   Goldreich O, 1996, J ACM, V43, P431, DOI 10.1145/233551.233553
   Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925
   Gray Cary, 1989, LEASES EFFICIENT FAU, V23
   Hall A, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS DESIGN AND IMPLEMENTATION (IOTDI '19), P225, DOI 10.1145/3302505.3310084
   Hellerstein J.M., 2018, 9 BIENNIAL C INNOVAT
   Hung L.H., 2018, COMPUTING RES REPOSI
   Hung L.-H., 2019, BIORXIV
   Hunt Patrick, 2010, USENIX TECHN C ATC
   Isard M., 2007, Operating Systems Review, V41, P59, DOI 10.1145/1272998.1273005
   Ivanov V., 2019, COMPUTING RES REPOSI
   Jangda A, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360575
   Jonas E, 2017, PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC '17), P445, DOI 10.1145/3127479.3128601
   Joy T. T., 2019, COMPUTING RES REPOSI
   Joyner S., 2020, COMPUTING RES REPOSI
   JUL E, 1988, ACM T COMPUT SYST, V6, P109, DOI 10.1145/35037.42182
   Karsai G., 2019, COMPUTING RES REPOSI
   Kavukcuoglu K., 2015, COMPUTING RES REPOSI
   Kawaguchi K, 2019, NEURAL COMPUT, V31, P1462, DOI 10.1162/neco_a_01195
   Kejariwal A., 2017, COMPUTING RES REPOSI
   Khalid J, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P313
   Kim Y, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P451, DOI 10.1109/CLOUD.2018.00063
   Kjerrumgaard D., 2018, REAL TIME ANAL PULSA
   Klimovic A, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P789
   Klimovic A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P427
   Koller R, 2017, PROCEEDINGS OF THE 16TH WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS 2017), P169, DOI 10.1145/3102980.3103008
   Konecny J., 2016, COMPUTING RES REPOSI
   Król M, 2017, PROCEEDINGS OF THE 4TH ACM CONFERENCE ON INFORMATION-CENTRIC NETWORKING (ICN 2017), P134, DOI 10.1145/3125719.3125727
   Lazar D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P211, DOI 10.1145/3341301.3359648
   Lee BD, 2019, NUCLEIC ACIDS RES, V47, pW20, DOI 10.1093/nar/gkz404
   Lee K, 2018, IEEE T INFORM THEORY, V64, P1514, DOI 10.1109/TIT.2017.2736066
   Li K., 1988, Proceedings of the 1988 International Conference on Parallel Processing, P94
   Li L., 2018, COMPUTING RES REPOSI
   Lim H., 2014, P USENIX C NETW SYST, P429
   Lin W, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P439
   Madhavapeddy A, 2013, ACM SIGPLAN NOTICES, V48, P461, DOI 10.1145/2499368.2451167
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184, 10.1145/1807167.1807184]
   Manco F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P218, DOI 10.1145/3132747.3132763
   McGregor A, 2014, SIGMOD REC, V43, P9, DOI 10.1145/2627692.2627694
   mei Hwu W., 2018, COMPUTING RES REPOSI
   Mirzasoleiman B., 2019, COMPUTING RES REPOSI
   Moritz P, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P561
   Muthukrishnan S, 2005, FOUND TRENDS THEOR C, V1, P1, DOI 10.1561/0400000002
   Niu XZ, 2019, ACM-BCB'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY AND HEALTH INFORMATICS, P683, DOI 10.1145/3307339.3343465
   Ousterhout J., 2010, ACM SIGOPS OPERAT SY, V43, P92, DOI DOI 10.1145/1713254.1713276
   Passwater Andrea, 2018, 2018 SERVERLESS COMM
   PHILLIPS JM, 2016, COMPUTING RES REPOSI
   Picasso P., 1946, TAUREAU
   Ping W., 2017, COMPUTING RES REPOSI
   Pinto D., 2018, COMPUTING RES REPOSI
   Popek Gerald, 1989, MIRAGE COHERENT DIST, V23
   Pu QF, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P193
   Quick L, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P457, DOI 10.1109/ASONAM.2012.254
   Ramage D., 2017, GOOGLE
   Ramchandran K., 2019, P 36 INT C MACH LEAR
   Rhodes L., 2019, COMPUTING RES REPOSI
   Sampé J, 2018, MIDDLEWARE INDUSTRY'18: PROCEEDINGS OF THE 2018 ACM/IFIP/USENIX MIDDLEWARE CONFERENCE (INDUSTRIAL TRACK), P1, DOI 10.1145/3284028.3284029
   Sanada T., 2019, COMPUTING RES REPOSI
   Seaborn M., EXPLOITING DRAM ROWH
   Shankar V., 2019, TECHNICAL REPORT UCB
   Shen ZM, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P121, DOI 10.1145/3297858.3304016
   Sievert S., 2019, BETTER FASTER HYPERP
   Silva JA, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522981
   Sivasubramanian Swaminathan, 2012, P ACM SIGMOD INT C M, P729, DOI [10.1145/2213836.2213945, DOI 10.1145/2213836.2213945]
   Slominski A., 2017, COMPUTING RES REPOSI
   Soltesz S., 2007, Operating Systems Review, V41, P275, DOI 10.1145/1272998.1273025
   Sreekanti V., 2020, COMPUTING RES REPOSI
   Stefanov E., 2013, CCS
   STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411
   Sun S., 2015, COMPUTING RES REPOSI
   Sun X., 2018, COMPUTING RES REPOSI
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Toader L, 2019, INT SYMP PARA DISTR, P66, DOI 10.1109/ISPDC.2019.00012
   Uta A, 2018, IEEE INT C CL COMP, P381, DOI 10.1109/CLUSTER.2018.00056
   van den Hooff J, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P137, DOI 10.1145/2815400.2815417
   van Eyk E, 2018, IEEE INTERNET COMPUT, V22, P8, DOI 10.1109/MIC.2018.053681358
   Verma Abhishek, 2015, PARKINSONS DIS-US
   Vershynin R., 2018, P C NEUR INF PROC SY
   Wagner T., 2019, SERVERLESS NETWORKIN
   Wang L, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P133
   Werner S, 2018, IEEE INT CONF BIG DA, P358, DOI 10.1109/BigData.2018.8622362
   Wolski R, 2019, SEC'19: PROCEEDINGS OF THE 4TH ACM/IEEE SYMPOSIUM ON EDGE COMPUTING, P236, DOI 10.1145/3318216.3363314
   Xiong Z., 2018, COMPUTING RES REPOSI
   Yan MT, 2016, FIRST INTERNATIONAL WORKSHOP ON MASHUPS OF THINGS AND APIS (MOTA), DOI 10.1145/3007203.3007217
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zhang M, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P61, DOI 10.1145/3304112.3325608
   Zhang M, 2019, IEEE INT CONF CLOUD, P404, DOI 10.1109/CLOUD.2019.00071
   Zhao J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1021, DOI 10.1145/3219819.3219918
   Zhong C., 2019, COMPUTING RES REPOSI
NR 122
TC 8
Z9 8
U1 0
U2 2
PY 2020
BP 2641
EP 2650
DI 10.1145/3318464.3383130
UT WOS:000644433700176
DA 2023-11-16
ER

PT J
AU Zhang, Y
   Zhang, F
   Jin, ZM
   Bakos, JD
AF Zhang, Yan
   Zhang, Fan
   Jin, Zheming
   Bakos, Jason D.
TI An FPGA-Based Accelerator for Frequent Itemset Mining
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Performance; Frequent itemset mining; data mining; Eclat; data
   intensive; co-processor; high performance computing; reconfigurable
   applications; reconfigurable
ID PATTERNS
AB In this article we describe a Field Programmable Gate Array (FPGA)-based coprocessor architecture for Frequent Itemset Mining (FIM). FIM is a common data mining task used to find frequently occurring subsets amongst a database of sets. FIM is a nonnumerical, data intensive computation and is used in machine learning and computational biology. FIM is particularly expensive-in terms of execution time and memory-when performed on large and/or sparse databases or when applied using a low appearance frequency threshold. Because of this, the development of increasingly efficient FIM algorithms and their mapping to parallel architectures is an active field. Previous attempts to accelerate FIM using FPGAs have relied on performance-limiting strategies such as iterative database loading and runtime logic unit reconfiguration. In this article, we present a novel architecture to implement Eclat, a well-known FIM algorithm. Unlike previous efforts, our technique does not impose limits on the maximum set size as a function of available FPGA logic resources and our design scales well to multiple FPGAs. In addition to a novel hardware design, we also present a corresponding compression scheme for intermediate results that are stored in on-chip memory. On a four-FPGA board, experimental results show up to 68X speedup compared to a highly optimized software implementation.
C1 [Zhang, Yan; Zhang, Fan; Jin, Zheming; Bakos, Jason D.] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
RP Zhang, Y (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
EM jbakos@cse.sc.edu
CR Agrawal R., 1994, VLDB, P487, DOI DOI 10.1007/BF02948845
   Alachiotis N., 2011, P IEEE S FIELD PROGR
   [Anonymous], 2003, FIMI
   [Anonymous], 1993, PROC 1993 ACM SIGMOD
   BAKER Z, 2006, P IEEE S FIELD PROGR
   Baker ZK, 2005, ANN IEEE SYM FIELD P, P3
   Bodon F, 2003, MATH COMPUT MODEL, V38, P739, DOI [10.1016/0895-7177(03)90058-6, 10.1016/S0895-7177(03)00275-9]
   Bodon F., 2006, SURVEY FREQUENT ITEM
   BORGELT C., 2003, P IEEE ICDM WORKSH F
   FIMI Repository, 2003, FREQ IT MIN DAT REP
   Fukuzaki M, 2010, LECT NOTES ARTIF INT, V6119, P147
   Gidel Ltd, 2009, PROSTAR3 DAT BOOK VE
   GOETHALS B, 2003, P IEEE ICDM WORKSH F
   GOETHALS B, 2002, SURVEY FREQUENT PATT
   Han JW, 2000, SIGMOD RECORD, V29, P1
   Heighton J., 2006, P C EXH DES AUT TEST
   IBM, 2012, IBM SYNTH DAT GEN
   Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813, DOI 10.1109/69.634757
   Sun S., 2008, P INT C REC COMP FPG
   Sun S, 2011, IEEE T PARALL DISTR, V22, P1497, DOI 10.1109/TPDS.2011.34
   Thoni D. W., 2009, P INT C FIELD PROGR
   Wen YH, 2008, IEEE T KNOWL DATA EN, V20, P784, DOI 10.1109/TKDE.2008.39
   Witten I.H., 2005, DATA MINING PRACTICA, P27
   Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291
   Zhang Y, 2011, IEEE INT C CL COMP, P585, DOI 10.1109/CLUSTER.2011.69
   Zhou L., 2008, IEEE T COMPUT, V57, P12
NR 26
TC 20
Z9 20
U1 0
U2 15
PD MAY
PY 2013
VL 6
IS 1
AR 2
DI 10.1145/2457443.2457445
UT WOS:000318629100002
DA 2023-11-16
ER

PT C
AU Wang, ZY
   Nalla, PS
   Krishnan, G
   Joshi, RV
   Cady, NC
   Fan, DL
   Seo, JS
   Cao, Y
AF Wang, Zhenyu
   Nalla, Pragnya Sudershan
   Krishnan, Gokul
   Joshi, Rajiv V.
   Cady, Nathaniel C.
   Fan, Deliang
   Seo, Jae-sun
   Cao, Yu
GP IEEE
TI Digital-Assisted Analog In-Memory Computing with RRAM Devices
SO 2023 INTERNATIONAL VLSI SYMPOSIUM ON TECHNOLOGY, SYSTEMS AND
   APPLICATIONS, VLSI-TSA/VLSI-DAT
DT Proceedings Paper
CT International VLSI Symposium on Technology, Systems and Applications
   (VLSI-TSA/VLSI-DAT)
CY APR 17-20, 2023
CL Hsinchu, TAIWAN
DE In-memory computing; ADC; RRAM; SRAM; Deep neural networks (DNNs)
   acceleration
AB In-memory computing (IMC) has been proposed as a solution to accelerate deep neural networks (DNNs) and other machine learning algorithms. RRAM-based IMC accelerators combine memory access and computation into the same array structure, saving a significant amount of chip area. However, the output from RRAM crossbar array requires an analog-to-digital converter (ADC) for further processing which causes the accuracy drop, extra power dissipation, and area overhead. In addition, the RRAM device also suffers from several nonidealities that degrade the accuracy. In this work, we propose a digital-assisted analog IMC architecture that combines analog RRAM-based IMC with the digital SRAM macro, using a programmable shifter, to compensate for the accuracy loss from ADC and the RRAM variations. By adding the precise output from the digital SRAM macro, the non-ideal output from the RRAM macro will be compensated. In this way, we achieve digital-assisted analog in-memory computing. We also designed a silicon prototype of the proposed hybrid IMC architecture in the 65nm CMOS process to demonstrate its efficacy. Our hybrid IMC architecture, evaluated through simulation on ResNet-20 with CIFAR-10, achieves a post-mapping testing accuracy to 91.15%, higher to that of the RRAM macro with 3-bit ADC, while requiring 1.19x smaller area and 1.90x less average power.
C1 [Wang, Zhenyu; Nalla, Pragnya Sudershan; Krishnan, Gokul; Fan, Deliang; Seo, Jae-sun; Cao, Yu] Arizona State Univ, Sch ECEE, Tempe, AZ 85287 USA.
   [Joshi, Rajiv V.] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
   [Cady, Nathaniel C.] SUNY Polytech, Dept Nanobiosci, Albany, NY USA.
RP Wang, ZY (corresponding author), Arizona State Univ, Sch ECEE, Tempe, AZ 85287 USA.
CR Azamat A, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643502
   Chakraborty I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218688
   Charan G, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218605
   Choi J, 2018, Arxiv, DOI arXiv:1805.06085
   Krishnan G, 2022, IEEE T COMPUT AID D, V41, P4241, DOI 10.1109/TCAD.2022.3197516
   Li BX, 2015, DES AUT CON, DOI 10.1145/2744769.2744870
   Liehr M, 2020, INT INTEG REL WRKSP, P82, DOI 10.1109/IIRW49815.2020.9312855
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shim W, 2020, SEMICOND SCI TECH, V35, DOI 10.1088/1361-6641/abb842
   Yang L, 2020, AAAI CONF ARTIF INTE, V34, P6623
   Zhou S., 2016, DOREFAR NET TRAINING
NR 11
TC 0
Z9 0
U1 4
U2 4
PY 2023
DI 10.1109/VLSI-TSA/VLSI-DAT57221.2023.10134272
UT WOS:001012107600076
DA 2023-11-16
ER

PT C
AU Khalil, K
   Eldash, O
   Kumar, A
   Bayoumi, M
AF Khalil, Kasem
   Eldash, Omar
   Kumar, Ashok
   Bayoumi, Magdy
BE Zhao, D
   Basu, A
   Bayoumi, M
   Hwee, GB
   Tong, G
   Sridhar, R
TI <i>N</i><SUP>2</SUP>OC: Neural-Network-on-Chip Architecture
SO 32ND IEEE INTERNATIONAL SYSTEM ON CHIP CONFERENCE (IEEE SOCC 2019)
SE IEEE International SOC Conference
DT Proceedings Paper
CT 32nd IEEE International System-on-Chip Conference (IEEE SOCC)
CY SEP 03-06, 2019
CL Singapore, SINGAPORE
DE Machine learning; Neural network; Hardware neural network; Hardware
   accelerator; FPGA architecture; Network-on-chip
AB Neural networks are increasingly being used in many applications because of their ability to solve complex problems. In order to increase the processing speed of neural networks, hardware-based techniques are being actively researched in the literature. However, implementing a neural network using conventional hardware design methods is a complex and challenging task for hardware designers as there are many hyperparameters and trade-offs that need to be examined in depth. This paper presents a novel Neural-Network-on-Chip (N2OC) to provide a hardware implementation of a neural network based on network-on-chip. The proposed approach provides reconfigurability when the number of nodes per layer varies depending on the desired performance and application. The proposed method provides a flexible hardware implementation of a neural network where the number and order of nodes can he controlled. Two datasets have been used for testing the proposed method, and the proposed method has a comparable result with the state-of-the-art. The hardware design is implemented using VHDL and Altera Arria 10 GX FPGA 10AX115N2F45E1SG. Throughput and average delay of the network are studied, and the simulation result shows the design has stable performance. On a problem studied (in handwritten digits classification), the proposed method has an accuracy of 99.24% while the state-of-the-art has an accuracy of 98.17%.
C1 [Khalil, Kasem; Eldash, Omar; Kumar, Ashok; Bayoumi, Magdy] Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
   [Bayoumi, Magdy] Univ Louisiana Lafayette, Dept Elect & Comp Engn, Lafayette, LA 70504 USA.
RP Khalil, K (corresponding author), Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
EM kmk8148@louisiana.edu; oke1206@louisiana.edu; axk1769@louisiana.edu;
   mab0778@louisiana.edu
CR Bohrn M, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P727, DOI 10.1109/TSP.2013.6614033
   Carleo G, 2017, SCIENCE, V355, P602, DOI 10.1126/science.aag2302
   Chae YT, 2016, ENERG BUILDINGS, V111, P184, DOI 10.1016/j.enbuild.2015.11.045
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang CW, 2017, IEEE INT CON MULTI, P583, DOI 10.1109/ICME.2017.8019296
   Ke Y., 2015, NONLINEAR DYNAM, P1
   Khalil K, 2018, INT SOC DESIGN CONF, P152, DOI 10.1109/SOCC.2018.8618525
   Khalil K, 2018, IEEE I C ELECT CIRC, P745, DOI 10.1109/ICECS.2018.8617887
   Khalil K, 2017, IEEE I C ELECT CIRC, P330, DOI 10.1109/ICECS.2017.8292030
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lemley J, 2017, IEEE CONSUM ELECTR M, V6, P48, DOI 10.1109/MCE.2016.2640698
   Moghaddam Amin Hedayati, 2016, Journal of Economics, Finance and Administrative Science, V21, P89
   Rasul RA, 2017, MIDWEST SYMP CIRCUIT, P1216, DOI 10.1109/MWSCAS.2017.8053148
   Sayed MS, 2012, COMPUT MATH APPL, V64, P1301, DOI 10.1016/j.camwa.2012.03.074
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schrimpf M., 2018, BIORXIV, DOI 10.1101/407007v1
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Steinbach L, 2019, APPL ACOUST, V145, P149, DOI 10.1016/j.apacoust.2018.09.024
   Vapnik V, 2017, ANN MATH ARTIF INTEL, V81, P3, DOI 10.1007/s10472-017-9538-x
   Won E, 2007, NUCL INSTRUM METH A, V581, P816, DOI 10.1016/j.nima.2007.08.163
   Zhang ZH, 2017, ENVIRONMENTAL DATA ANALYSIS: METHODS AND APPLICATIONS, P1, DOI 10.1515/9783110424904-002
   Zyarah AM, 2017, MIDWEST SYMP CIRCUIT, P543, DOI 10.1109/MWSCAS.2017.8052980
NR 23
TC 6
Z9 6
U1 0
U2 0
PY 2019
BP 272
EP 277
DI 10.1109/SOCC46988.2019.1570558351
UT WOS:000783951100051
DA 2023-11-16
ER

PT C
AU Silfa, F
   Dot, G
   Arnau, JM
   Gonzàlez, A
AF Silfa, Franyell
   Dot, Gem
   Arnau, Jose-Maria
   Gonzalez, Antonio
GP Assoc Comp Machinery
TI E-PUR: An Energy-Efficient Processing Unit for Recurrent Neural Networks
SO 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION
   TECHNIQUES (PACT 2018)
DT Proceedings Paper
CT 27th IEEE/ACM/IFIP International Conference on Parallel Architectures
   and Compilation Techniques (PACT)
CY NOV 01-04, 2018
CL Limassol, CYPRUS
DE Recurrent Neural Networks; Long Short Term Memory; Accelerators
AB Recurrent Neural Networks (RNNs) are a key technology for emerging applications such as automatic speech recognition, machine translation or image description. Long Short Term Memory (LSTM) networks are the most successful RNN implementation, as they can learn long term dependencies to achieve high accuracy. Unfortunately, the recurrent nature of LSTM networks significantly constrains the amount of parallelism and, hence, multicore CPUs and many-core GPUs exhibit poor efficiency for RNN inference.
   In this paper, we present E-PUR, an energy-efficient processing unit tailored to the requirements of LSTM computation. The main goal of E-PUR is to support large recurrent neural networks for low-power mobile devices. E-PUR provides an efficient hardware implementation of LSTM networks that is flexible to support diverse applications. One of its main novelties is a technique that we call Maximizing Weight Locality (MWL), which improves the temporal locality of the memory accesses for fetching the synaptic weights, reducing the memory requirements by a large extent.
   Our experimental results show that E-PUR achieves real-time performance for different LSTM networks, while reducing energy consumption by orders of magnitude with respect to general-purpose processors and GPUs, and it requires a very small chip area. Compared to a modern mobile SoC, an NVIDIA Tegra X1, E-PUR provides an average energy reduction of 88x.
C1 [Silfa, Franyell; Dot, Gem; Arnau, Jose-Maria; Gonzalez, Antonio] Univ Politecn Cataluna, Barcelona, Spain.
RP Silfa, F (corresponding author), Univ Politecn Cataluna, Barcelona, Spain.
EM fsilfa@ac.upc.edu; gdot@ac.upc.edu; jarnau@ac.upc.edu;
   antonio@ac.upc.edu
CR Al-Rfou Rami, 2016, ARXIV160502688
   [Anonymous], 2015, CORR
   [Anonymous], 2015, P INT C LEARN REPR
   Appleyard J., 2016, CORR
   Baldi P., 2001, Sequence learning. Paradigms, algorithms, and applications (Lecture Notes in Artificial Intelligence Vol.1828), P80
   Chang A.X., 2015, RECURRENT NEURAL NET
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Friesen Merlin, LINUX POWER MANAGEME
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Graves A, 2005, IEEE IJCNN, P2047
   Greff K., 2016, ARXIV150304069, V28, P2222, DOI DOI 10.1109/TNNLS.2016.2582924
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S., 2015, C NEUR INF PROC SYST
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jiang YF, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 2, P343, DOI 10.1109/WCINS.2010.5542315
   Kim J, 2017, INTERSPEECH, P1591, DOI 10.21437/Interspeech.2017-477
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Micron Inc, TN 53 01 LPDDR4 SYST
   Muralimanohar N., 2009, CACTI 60 TOOL MODEL, V27, P28
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104
   Tabani Hamid, 2017, PAR ARCH COMP TECHN
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Yonghui, 2016, GOOGLES NEURAL MACHI
   Yazdani Reza, 2016, P INT S MICROARCHITE, P1, DOI DOI 10.1109/MICRO.2016.7783750
NR 33
TC 18
Z9 18
U1 0
U2 1
PY 2018
DI 10.1145/3243176.3243184
UT WOS:000475553400018
DA 2023-11-16
ER

PT C
AU Seong, JH
   Choi, Y
AF Seong, Jeong Hoon
   Choi, Younggeun
GP IEEE
TI Design and Implementation of User Interface through Hand Movement
   Tracking and Gesture Recognition
SO 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION
   TECHNOLOGY CONVERGENCE (ICTC)
SE International Conference on Information and Communication Technology
   Convergence
DT Proceedings Paper
CT 9th International Conference on Information and Communication Technology
   Convergence (ICTC)
CY OCT 17-19, 2018
CL SOUTH KOREA
DE HCI; wearable devices; gesture recognition; inertial measurement unit
AB In this paper, we investigate about how to track the movement of the hand and how to recognize the click gesture to implement a new type of user interface. We developed a wristwatch-type human computer interface (HCI) device that can estimate and express the user's intuitive hand movements based on a 9-axis inertial measurement unit (IMU) sensor, which includes an accelerator, a magnetometer, and a gyroscope. We defined the Euler angular projection function to map the hand angle intuitively on the screen and to represent its motion reliably. We also proposed a machine-learning-based gesture-recognition algorithm by extracting the window size optimized for the click gesture and collecting the accurate ground truth in a real computing environment with noise. Finally, we designed a natural user interface, which is robust to the actual environment, by integrating hand motion tracking and click gesture recognition. We proved the reliability of motion by comparing the proposed hand motion-tracking function with the conventional method. In the experimental environment with noise, the click gesture recognition algorithm yielded a recognition rate of 98.94%. In conclusion, we modeled the optimized click gesture-recognition algorithm and integrated the mapping functions to track hand movements, and compared the system with existing interface devices. A usability test was performed for evaluation, and usability was verified compared with existing interface equipment.
C1 [Seong, Jeong Hoon; Choi, Younggeun] Dankook Univ, Dept Comp Engn, Yongin, South Korea.
RP Choi, Y (corresponding author), Dankook Univ, Dept Comp Engn, Yongin, South Korea.
EM Jason.sjh7@gmail.com; younggch@dankook.ac.kr
CR Basak S., 2014, INT J COMPUTER APPL
   Hong D., 2008, TELECOMMUNICATIONS R
   Kim YS, 2005, IEEE T IND ELECTRON, V52, P1490, DOI 10.1109/TIE.2005.858736
   Lee C., 2012, STUDY CONTACT TYPE N
   Lee J, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P274, DOI 10.1109/ICTC.2013.6675356
   Xu C, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P9, DOI 10.1145/2699343.2699350
NR 6
TC 3
Z9 3
U1 0
U2 1
PY 2018
BP 552
EP 555
UT WOS:000517984800114
DA 2023-11-16
ER

PT C
AU Chi, P
   Li, SC
   Xu, C
   Zhang, T
   Zhao, JS
   Liu, YP
   Wang, Y
   Xie, Y
AF Chi, Ping
   Li, Shuangchen
   Xu, Cong
   Zhang, Tao
   Zhao, Jishen
   Liu, Yongpan
   Wang, Yu
   Xie, Yuan
GP IEEE
TI PRIME: A Novel Processing-in-memory Architecture for Neural Network
   Computation in ReRAM-based Main Memory
SO 2016 ACM/IEEE 43RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 43rd ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2016
CL Seoul, SOUTH KOREA
DE processing in memory; neural network; resistive random access memory
AB Processing-in-memory (PIM) is a promising solution to address the "memory wall" challenges for future computer systems. Prior proposed PIM architectures put additional computation logic in or near memory. The emerging metal-oxide resistive random access memory (ReRAM) has showed its potential to be used for main memory. Moreover, with its crossbar array structure, ReRAM can perform matrix-vector multiplication efficiently, and has been widely studied to accelerate neural network (NN) applications. In this work, we propose a novel PIM architecture, called PRIME, to accelerate NN applications in ReRAM based main memory. In PRIME, a portion of ReRAM crossbar arrays can be configured as accelerators for NN applications or as normal memory for a larger memory space. We provide microarchitecture and circuit designs to enable the morphable functions with an insignificant area overhead. We also design a software/hardware interface for software developers to implement various NNs on PRIME. Benefiting from both the PIM architecture and the efficiency of using ReRAM for NN computation, PRIME distinguishes itself from prior work on NN acceleration, with significant performance improvement and energy saving. Our experimental results show that, compared with a state-of-the-art neural processing unit design, PRIME improves the performance by similar to 2360x and the energy consumption by similar to 895x, across the evaluated machine learning benchmarks.
C1 [Chi, Ping; Li, Shuangchen; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Xu, Cong] HP Labs, Palo Alto, CA 94304 USA.
   [Zhang, Tao] INVIDIA Corp, Santa Clara, CA 95950 USA.
   [Zhao, Jishen] Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.
   [Liu, Yongpan; Wang, Yu] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
RP Chi, P (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM pingchi@ece.ucsb.edu; shuangchenli@ece.ucsb.edu; yuanxie@ece.ucsb.edu
CR Agarwal N., 2015, P ASPLOS
   Akin B., 2015, P ISCA
   Alibart F., 2011, P AHS
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   [Anonymous], P ISLPED
   [Anonymous], WORKSH MIX LOG DRAM
   [Anonymous], 2016, P ISCA
   [Anonymous], 2014, P ASPLOS
   [Anonymous], P ICML
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], P VLSIT
   [Anonymous], P ASPLOS
   [Anonymous], 1997, WORKSH MIX LOG DRAM
   [Anonymous], 2014, CORR
   [Anonymous], P VLSIT
   [Anonymous], 2004, P ASPLOS
   [Anonymous], 2015, P ISCA
   [Anonymous], P ICS
   [Anonymous], P MICRO
   [Anonymous], P ICCAD
   [Anonymous], 2014, P HPDC
   [Anonymous], P MICRO
   [Anonymous], P IEDM
   [Anonymous], P ISLPED
   [Anonymous], P IJCAI
   [Anonymous], 2015, ICLR
   [Anonymous], P ISCAS
   [Anonymous], P ASPLOS
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Burr G., 2014, P IEDM
   Burr G. W., 2015, P IEDM
   Chen K., 2012, P DATE
   Chi P., 2015, 2015001 SEAL LAB
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Esmaeilzadeh H., 2012, P MICRO
   Esser S. K., 2013, P IJCNN
   Farabet C., 2009, P FPL
   Gao L., 2013, P NVMW
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Guo Q., 2013, P ISCA
   Guo Q., 2011, P MICRO
   Guz Z., 2014, P WONDP
   Hu M., 2015, ICCAD 15 WORKSH EFF
   Hu M., 2013, P CISDA
   Hu M., 2012, P DAC
   Jeddeloh J., 2012, P VLSIT
   Jouppi N. P., 2012, P ICCAD
   Jung M., 2013, P ICS
   Kawahara A., 2012, P ISSCC
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Kozyrakis CE, 1997, COMPUTER, V30, P75, DOI 10.1109/2.612252
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee D. U., 2014, P ISSCC P ISSCC
   Lee MJ, 2011, NAT MATER, V10, P625, DOI [10.1038/NMAT3070, 10.1038/nmat3070]
   Li B., 2014, P ASP DAC
   Li BX, 2015, IEEE T COMPUT AID D, V34, P1905, DOI 10.1109/TCAD.2015.2445741
   Li J., 2011, P IMW
   Li S., 2016, P DAC, P1
   Liu B., 2013, P DAC
   Liu B., 2014, P ICCAD
   Liu S., 2016, P ISCA
   Merolla P., 2011, P CICC
   Mirzadeh N., 2015, P ASBD
   Nair R, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2409732
   Oskin M., 1998, P ISCA
   Patterson D., 1997, P ICCD
   Pawlowski J. T., 2011, P HOT CHIPS S
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Pugsley Seth H., 2014, P ISPASS
   Qureshi M., 2010, P ISCA
   Sahin S, 2006, LECT NOTES COMPUT SC, V4234, P1105
   Schmidhuber J., 2012, P CVPR
   Seo J., 2011, P CICC
   Seshadri V., 2013, P MICRO
   St Amant R., 2014, P ISCA
   Taha T., 2013, P IJCNN
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wu MC, 2012, SEMICOND SCI TECH, V27, DOI 10.1088/0268-1242/27/6/065010
   Xu C., 2015, P HPCA
   Xu C., 2013, P DAC
   Yu SM, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3564883
   Zhang L., 2014, P PACT
NR 84
TC 914
Z9 971
U1 5
U2 92
PY 2016
BP 27
EP 39
DI 10.1109/ISCA.2016.13
UT WOS:000389548600003
DA 2023-11-16
ER

PT J
AU Carrazza, S
   Cruz-Martinez, JM
AF Carrazza, Stefano
   Cruz-Martinez, Juan M.
TI VegasFlow: Accelerating Monte Carlo simulation across multiple hardware
   platforms
SO COMPUTER PHYSICS COMMUNICATIONS
DT Article
DE Monte Carlo; Graphs; Integration; Machine learning; Hardware
   acceleration
AB We present VegasFlow, a new software for fast evaluation of high dimensional integrals based on Monte Carlo integration techniques designed for platforms with hardware accelerators. The growing complexity of calculations and simulations in many areas of science have been accompanied by advances in the computational tools which have helped their developments. VegasFlow enables developers to delegate all complicated aspects of hardware or platform implementation to the library so they can focus on the problem at hand. This software is inspired on the Vegas algorithm, ubiquitous in the particle physics community as the driver of cross section integration, and based on Google's powerful TensorFlow library. We benchmark the performance of this library on many different consumer and professional grade GPUs and CPUs.
   Program summary
   Program Title: VegasFlow
   CPC Library link to program files: http://dx.doi.org/10.17632/rpgcbzzhdt.1
   Developer's repository link: https://github.com/N3PDF/vegasflow
   Licensing provisions: GPLv3
   Programming language: Python
   Nature of problem: The solution of high dimensional integrals requires the implementation of Monte Carlo algorithms such as Vegas. Monte Carlo algorithms are known to require long computation times.
   Solution method: Implementation of the Vegas algorithm using the dataflow graph infrastructure provided by the TensorFlow framework. Extension of the algorithm to take advantage of multi-threading CPU and multi-GPU setups. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Carrazza, Stefano; Cruz-Martinez, Juan M.] Univ Milan, TIF Lab, Dipartimento Fis, Via Celoria 16, I-20133 Milan, Italy.
   [Carrazza, Stefano; Cruz-Martinez, Juan M.] INFN, Sez Milano, Via Celoria 16, I-20133 Milan, Italy.
RP Carrazza, S (corresponding author), Univ Milan, TIF Lab, Dipartimento Fis, Via Celoria 16, I-20133 Milan, Italy.
EM stefano.carrazza@unimi.it
CR Abadi M, 2015, PRELIMINARY WHITE PA
   Alwall J, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2014)079
   [Anonymous], **DATA OBJECT**, DOI DOI 10.5281/ZEN0D0.592154
   [Anonymous], **DATA OBJECT**, DOI DOI 10.5281/ZEN0D0.3691926
   [Anonymous], 1984, TOOLS METHODS LANGUA
   Bothmann E., ARXIV200105478
   Brucherseifer M, 2014, PHYS LETT B, V736, P58, DOI 10.1016/j.physletb.2014.06.075
   Buckley A., 2019, 19 INT WORKSH ADV CO
   Campbell J, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP12(2019)034
   Campbell JM, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3461-2
   Gao C., ARXIV200110028
   Gao C., ARXIV200105486
   Gehrmann T, 2018, POS RADCOR2017, V074, DOI DOI 10.22323/1.290.0074
   Gleisberg T, 2009, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2009/02/007
   Lepage G. P., 1980, VEGAS ADAPTIVE MULTI
   LEPAGE GP, 1978, J COMPUT PHYS, V27, P192
   Muller T., CORR
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
NR 18
TC 9
Z9 9
U1 0
U2 7
PD SEP
PY 2020
VL 254
AR 107376
DI 10.1016/j.cpc.2020.107376
UT WOS:000541251200029
DA 2023-11-16
ER

PT C
AU Danopoulos, D
   Kachris, C
   Soudris, D
AF Danopoulos, Dimitrios
   Kachris, Christoforos
   Soudris, Dimitrios
BE Pnevmatikatos, DN
   Pelcat, M
   Jung, M
TI Approximate Similarity Search with FAISS Framework Using FPGAs on the
   Cloud
SO EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION,
   SAMOS 2019
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 19th International Conference on Embedded Computer Systems:
   Architectures, Modeling, and Simulation (SAMOS)
CY JUL 07-11, 2019
CL Pythagorion, GREECE
DE Big-data; Similarity search; Approximate KNN; Cloud; FPGA;
   Reconfigurable computing
AB Machine Learning algorithms, such as classification and clustering techniques, have gained significant traction over the last years because they are vital to many real-world problems. K-Nearest Neighbor algorithm (KNN) is widely used in text categorization, predictive analysis, data mining etc. but comes at the cost of high computation. In the era of big data, modern data centers adopt this specific algorithm with approximate techniques to compute demanding workloads every day. However, high dimensional nearest neighbor queries on billion-scale datasets still produce a significant computational and energy overhead. In this paper, we describe and implement a novel design to address this problem based on a hardware accelerated approximate KNN algorithm built upon FAISS framework (Facebook Artificial Intelligence Similarity Search) using FPGA-OpenCL platforms on the cloud. This is an original deployment of FPGA architecture on this framework that also shows how the persistent index build times on big scale inputs for similarity search can be handled in hardware and even outperform other high performance systems. The experiments were done on AWS cloud F1 instance achieving 98x FPGA accelerator speed-up over single-core CPU and 2.1x end-to-end system speed-up over a 36-thread Xeon CPU. Also, the performance/watt of the design was 3.5x from the same CPU and 1.2x from a Kepler-class GPU.
C1 [Danopoulos, Dimitrios; Soudris, Dimitrios] NTUA, Dept Elect & Comp Engn, Athens, Greece.
   [Kachris, Christoforos] Democritus Univ Thrace, Athens, Greece.
   [Kachris, Christoforos] ICCS NTUA, Athens, Greece.
RP Danopoulos, D (corresponding author), NTUA, Dept Elect & Comp Engn, Athens, Greece.
EM dimdano@microlab.ntua.gr; kachris@microlab.ntua.gr;
   dsoudris@microlab.ntua.gr
CR Andoni A., 2018, ABS180609823 CORR
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760
   Chen YJ, 2010, SENSORS-BASEL, V10, P11259, DOI 10.3390/s101211259
   Danopoulos D, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hussain H. M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P475, DOI 10.1109/ReConFig.2011.49
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Kouiroukidis N., 2011, 2011 15 PANH C INF, P42
   Kybic J., 2010, APPROXIMATE BEST BIN, V10, P420
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Lu XX, 2020, NEW ENGL J MED, V382, P1663, DOI 10.1056/NEJMc2005073
   Mavridis S, 2017, I C FIELD PROG LOGIC
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Pu YL, 2015, ANN IEEE SYM FIELD P, P167, DOI 10.1109/FCCM.2015.7
   Sharifzadehand M., 2019, APPROXIMATE VORONOI
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
   Zhang JL, 2018, PROC CVPR IEEE, P4924, DOI 10.1109/CVPR.2018.00517
NR 20
TC 3
Z9 3
U1 2
U2 5
PY 2019
VL 11733
BP 373
EP 386
DI 10.1007/978-3-030-27562-4_27
UT WOS:000658850600027
DA 2023-11-16
ER

PT C
AU Ullah, S
   Sahoo, SS
   Kumar, A
AF Ullah, Salim
   Sahoo, Siva Satyendra
   Kumar, Akash
GP IEEE
TI CLAppED: A Design Framework for Implementing Cross-Layer Approximation
   in FPGA-based Embedded Systems
SO 2021 58TH ACM/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 58th ACM/IEEE Design Automation Conference (DAC)
CY DEC 05-09, 2021
CL San Francisco, CA
DE Approximate Computing; Embedded Systems; Cross-layer System Design;
   FPGA; High-level Synthesis
AB With the rising variation and complexity of embedded workloads, FPGA-based systems are being increasingly used for many applications. The reconfigurability and high parallelism offered by FPGAs are used to enhance the overall performance of these applications. However, the resource constraints of embedded platforms can limit the performance in multiple ways. In recent years, Approximate Computing has emerged as a viable tool for improving the performance by utilizing reduced precision data structures and resource-optimized high-performance arithmetic operators. However, most of the related state-of-the-art research has mainly focused on utilizing approximate computing principles individually on different layers of the computing stack. Nonetheless, approximations across different layers of computing stack can substantially enhance the system's performance. To this end, we present a framework to enable the intelligent exploration and highly accurate identification of the feasible design points in the large design space enabled by cross-layer approximations. Our framework proposes a novel polynomial regression-based method to model approximate arithmetic operators. The proposed method enables machine learning models to better correlate approximate operators with their impact on an application's output quality. We use a 2D convolution operator as a test case and present the results for FPGA-based approximate hardware accelerators.
C1 [Ullah, Salim; Sahoo, Siva Satyendra; Kumar, Akash] Tech Univ Dresden, Ctr Adv Elect Dresden CfAED, Dresden, Germany.
RP Ullah, S (corresponding author), Tech Univ Dresden, Ctr Adv Elect Dresden CfAED, Dresden, Germany.
EM salim.ullah@tu-dresden.de; siva_satyendra.sahoo@tu-dresden.de;
   akash.kumar@tu-dresden.de
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Biscani F, 2018, ESAPAGMO2 PAGMO 2 9
   Bruestel M, 2017, DES AUT TEST EUROPE, P298, DOI 10.23919/DATE.2017.7927003
   Chippa V.K., 2013, P 50 ACM EDAC IEEE D, P1, DOI [DOI 10.1145/2463209.2488873, 10.1145/2463209.2488873]
   Chippa VK, 2014, IEEE T VLSI SYST, V22, P2004, DOI 10.1109/TVLSI.2013.2276759
   De la Parra C, 2020, FUTURE GENER COMP SY, V113, P597, DOI 10.1016/j.future.2020.07.031
   De S, 2020, DES AUT TEST EUROPE, P1680, DOI 10.23919/DATE48585.2020.9116552
   Düben P, 2015, DES AUT TEST EUROPE, P764
   Fan YH, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P317, DOI 10.1145/3287624.3287627
   Goiri I, 2015, ACM SIGPLAN NOTICES, V50, P383, DOI [10.1145/2775054.2694351, 10.1145/2694344.2694351]
   Hanif MA, 2018, J LOW POWER ELECTRON, V14, P520, DOI 10.1166/jolpe.2018.1575
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Liu HY, 2013, DES AUT CON
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mehrabi A, 2020, DES AUT TEST EUROPE, P151, DOI 10.23919/DATE48585.2020.9116473
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mockus Jonas, 1974, OPTIMIZATION TECHNIQ, V27, P400, DOI DOI 10.1007/3-540-07165-2_55
   Mrazek V, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317781
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Ullah S., 2020, IEEE T COMPUT
   Ullah S, 2020, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE48585.2020.9116373
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Xilinx, 2018, UG1270 VIV HLS OPT M
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
NR 25
TC 4
Z9 4
U1 0
U2 0
PY 2021
BP 475
EP 480
DI 10.1109/DAC18074.2021.9586260
UT WOS:000766079700080
DA 2023-11-16
ER

PT C
AU Liao, SY
   Li, Z
   Lin, X
   Qiu, QR
   Wang, YZ
   Yuan, B
AF Liao, Siyu
   Li, Zhe
   Lin, Xue
   Qiu, Qinru
   Wang, Yanzhi
   Yuan, Bo
GP IEEE
TI Energy-Efficient, High-Performance, Highly-Compressed Deep Neural
   Network Design using Block-Circulant Matrices
SO 2017 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 36th International Conference on Computer-Aided Design (ICCAD)
CY NOV 13-16, 2017
CL Irvine, CA
AB Deep neural networks (DNNs) have emerged as the most powerful machine learning technique in numerous artificial intelligent applications. However, the large sizes of DNNs make themselves both computation and memory intensive, thereby limiting the hardware performance of dedicated DNN accelerators. In this paper, we propose a holistic framework for energy-efficient high-performance highly-compressed DNN hardware design. First, we propose block-circulant matrix-based DNN training and inference schemes, which theoretically guarantee Big-O complexity reduction in both computational cost (from O(n(2)) to O(n log n)) and storage requirement (from O(n(2)) to O(n)) of DNNs. Second, we dedicatedly optimize the hardware architecture, especially on the key fast Fourier transform (FFT) module, to improve the overall performance in terms of energy efficiency, computation performance and resource cost. Third, we propose a design flow to perform hardware-software cooptimization with the purpose of achieving good balance between test accuracy and hardware performance of DNNs. Based on the proposed design flow, two block-circulant matrix-based DNNs on two different datasets are implemented and evaluated on FPGA. The fixed-point quantization and the proposed block-circulant matrix-based inference scheme enables the network to achieve as high as 3.5 TOPS computation performance and 3.69 TOPS/W energy efficiency while the memory is saved by 108X similar to 116X with negligible accuracy degradation.
C1 [Liao, Siyu; Yuan, Bo] CUNY, New York, NY 10021 USA.
   [Li, Zhe; Qiu, Qinru; Wang, Yanzhi] Syracuse Univ, Syracuse, NY 13244 USA.
   [Lin, Xue] Northeastern Univ, Boston, MA 02115 USA.
RP Liao, SY (corresponding author), CUNY, New York, NY 10021 USA.; Li, Z (corresponding author), Syracuse Univ, Syracuse, NY 13244 USA.
EM sliao2@gradcenter.cuny.edu; zli89@syr.edu; xue.lin@northeastern.edu;
   qiqiu@syr.edu; ywang393@syr.edu; byuan@ccny.cuny.edu
CR Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2015, ARXIV 151000149
   [Anonymous], 2015, DEEP LEARNING, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2015, INAISTATS
   [Anonymous], ACM ICCAD
   [Anonymous], F AST F OURIER T RAN
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327
   Chung J, 2016, DES AUT CON, DOI 10.1145/2897937.2898092
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Jouppi N.P., 2017, P 44 ANN INT S COMPU
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, P 2 INT C NEUR INF P, P598
   LeCun Yann, 1998, MNIST DATABASE HANDW
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Netzer Y., 2011, NEURAL INFORM PROCES, P5
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, V2nd
   Pan Victor, 2012, STRUCTURED MATRICES
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
NR 26
TC 7
Z9 7
U1 0
U2 0
PY 2017
BP 458
EP 465
UT WOS:000424863100061
DA 2023-11-16
ER

PT J
AU Khawaja, SG
   Akram, MU
   Khan, SA
   Shaukat, A
   Rehman, S
AF Khawaja, Sajid Gul
   Akram, M. Usman
   Khan, Shoab Ahmed
   Shaukat, Arslan
   Rehman, Saad
TI Network-on-Chip based MPSoC architecture for <i>k</i>-mean clustering
   algorithm
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE k-means; MPSoC; NoC; Scalable; Unfolding
ID HIGH-PERFORMANCE
AB Data and image segmentation plays pivotal role in the application of machine learning. k-means, as a tool for unsupervised clustering, is a widely used algorithm for segmentation due to its inherent simplicity and efficiency. k-means partitions datasets into subsets based on their fitness value. As such k-means is a well suited algorithm for implementation on hardware platform such as Field Programmable Gate Array (FPGA) but requires high computation time. Hardware accelerators can help in reducing the computation complexity of the algorithm. In this paper, we present a simplified multicore based scalable hardware architecture for implementation of k-means. Mean and fitness modules in proposed architecture are further unfolded to further enhance the speed of k-means clustering algorithm. The unfolding factor has to be selected by keeping the area of the target device in check. In the proposed architecture, the cores are further connected through Network on Chip (NoC) interconnect network which allows for higher scalability while elevating the bottleneck of message passing. The performance of our MPSoC architecture has been evaluated with respect to Average Speedup, Average Throughput and Area consumption with and without use of NoC interconnect. Finally, we compare the use of different NoC interconnect models with respect to maximum Operating Frequency, average Throughput and Area overhead. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Khawaja, Sajid Gul; Akram, M. Usman; Khan, Shoab Ahmed; Shaukat, Arslan; Rehman, Saad] Natl Univ Sci & Technol, Dept Comp Engn, Islamabad, Pakistan.
RP Akram, MU (corresponding author), Natl Univ Sci & Technol, Dept Comp Engn, Islamabad, Pakistan.
EM sajid.gul@ceme.nust.edu.pk; usmakram@gmail.com; kshoab@yahoo.com;
   arslan.asp@gmail.com; rehman.saad@gmail.com
CR [Anonymous], 2001, FPGA 01
   [Anonymous], 2008, P 2008 ACM CONEXT C
   [Anonymous], P IEEE C COMP VIS PA
   Belanovic P., 2002, THESIS
   Benini L, 2002, COMPUTER, V35, P70, DOI 10.1109/2.976921
   Birem M, 2014, J SYST ARCHITECT, V60, P519, DOI 10.1016/j.sysarc.2014.01.006
   Dally W.J., 2004, PRINCIPLES PRACTICES
   Dally WJ, 2001, DES AUT CON, P684, DOI 10.1109/DAC.2001.935594
   Drineas P, 2004, MACH LEARN, V56, P9, DOI 10.1023/B:MACH.0000033113.59016.96
   Estlick M., 2002, THESIS
   Fularz M, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/61434
   Gao SL, 2014, ANN IEEE SYST CONF, P78, DOI 10.1109/SysCon.2014.6819239
   Gokhale M, 2003, J SUPERCOMPUT, V26, P131, DOI 10.1023/A:1024495400663
   Hussain H. M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P475, DOI 10.1109/ReConFig.2011.49
   Hussain H. M., 2011, Proceedings of the 2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), P248, DOI 10.1109/AHS.2011.5963944
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jiang ZL, 2012, COMPUT VIS IMAGE UND, V116, P730, DOI 10.1016/j.cviu.2012.02.004
   Khawaja SG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125230
   Kunzhi X., 2013, 3 INT C MULT TECHN I
   Lavenier D, 2000, FPGA IMPLEMENTATION
   Lee HG, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255460
   Lin Z., 2012, FPL 12, P437
   Mehmood S, 2015, J REAL-TIME IMAGE PR, V10, P75, DOI 10.1007/s11554-012-0256-7
   Mehmood S, 2009, LECT NOTES COMPUT SC, V5484, P369, DOI 10.1007/978-3-642-01129-0_41
   Modarressi M, 2011, IEEE T VLSI SYST, V19, P2010, DOI 10.1109/TVLSI.2010.2066586
   Morro A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124176
   Peng XS, 2013, IEEE T DIELECT EL IN, V20, P754
   González CP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021399
   Qu YR, 2016, IEEE T PARALL DISTR, V27, P197, DOI 10.1109/TPDS.2015.2389239
   Saegusa T, 2007, J REAL-TIME IMAGE PR, V2, P309, DOI 10.1007/s11554-007-0055-8
   Salgarelli L, 2006, STAT TRAFFIC CLASSIF
   Silva DRG, 2014, IEEE I C ELECT CIRC, P431, DOI 10.1109/ICECS.2014.7050014
   Tadesse M., 2015, AFRICON 2015, P1
   Tran AT, 2014, IEEE T VLSI SYST, V22, P1391, DOI 10.1109/TVLSI.2013.2268548
   Winterstein F., 2013, FIELD PROGR LOG APPL, P1
   Woehrle H., 2015, FORMAL MODELING VERI, P311
   Yoneda T, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P679, DOI 10.1109/APCCAS.2014.7032872
   Yu J, 2005, IEEE T PATTERN ANAL, V27, P1197, DOI 10.1109/TPAMI.2005.160
   Zawadzki A, 2015, J SYST ARCHITECT, V61, P681, DOI 10.1016/j.sysarc.2015.08.003
   Zou Y, 2013, INT SYM QUAL ELECT, P643, DOI 10.1109/ISQED.2013.6523678
NR 41
TC 3
Z9 3
U1 0
U2 2
PD OCT
PY 2016
VL 46
BP 1
EP 10
DI 10.1016/j.micpro.2016.08.006
PN A
UT WOS:000389164700001
DA 2023-11-16
ER

PT J
AU Faingnaert, T
   Besard, T
   De Sutter, B
AF Faingnaert, Thomas
   Besard, Tim
   De Sutter, Bjorn
TI Flexible Performant GEMM Kernels on GPUs
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Libraries; Kernel; Graphics processing units; Codes; Programming;
   Instruction sets; Productivity; Matrix multiplication; graphics
   processors; high-level programming languages
ID TENSOR CONTRACTION
AB General Matrix Multiplication or GEMM kernels take centre place in high performance computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by the two-language problem: it requires either low-level programming which implies low programmer productivity or using libraries that only offer a limited set of components. Because rephrasing algorithms in terms of established components often introduces overhead, the libraries' lack of flexibility limits the freedom to explore new algorithms. Researchers using GEMMs can hence not enjoy programming productivity, high performance, and research flexibility at once. In this paper we solve this problem. We present three sets of abstractions and interfaces to program GEMMs within the scientific Julia programming language. The interfaces and abstractions are co-designed for researchers' needs and Julia's features to achieve sufficient separation of concerns and flexibility to easily extend basic GEMMs in many different ways without paying a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS and CUTLASS, we demonstrate that our performance is in the same ballpark of the libraries, and in some cases even exceeds it, without having to write a single line of code in CUDA C++ or assembly, and without facing flexibility limitations.
C1 [Faingnaert, Thomas; De Sutter, Bjorn] Univ Ghent, Dept Elect & Informat Syst, B-9042 Ghent, Belgium.
   [Besard, Tim] Univ Ghent, Julia Comp, B-9042 Ghent, Belgium.
RP De Sutter, B (corresponding author), Univ Ghent, Dept Elect & Informat Syst, B-9042 Ghent, Belgium.
EM thomas.faingnaert@ugent.be; tim@juliacomputing.com;
   bjorn.desutter@ugent.be
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Abdelfattah A, 2019, PROCEEDINGS OF SCALA 2019: 2019 IEEE/ACM 10TH WORKSHOP ON LATEST ADVANCES IN SCALABLE ALGORITHMS FOR LARGE-SCALE SYSTEMS (SCALA), P17, DOI 10.1109/ScalA49573.2019.00008
   Aprà E, 2014, INT CONF HIGH PERFOR, P674, DOI 10.1109/SC.2014.60
   Auer AA, 2006, MOL PHYS, V104, P211, DOI 10.1080/00268970500275780
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   Barham P, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P177, DOI 10.1145/3317550.3321441
   Baskaran MM, 2008, ICS'08: PROCEEDINGS OF THE 2008 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P225
   Besard T, 2019, ADV ENG SOFTW, V132, P29, DOI 10.1016/j.advengsoft.2019.02.002
   Besard T, 2019, IEEE T PARALL DISTR, V30, P827, DOI 10.1109/TPDS.2018.2872064
   Bhaskaracharya S. G., 2020, ARXIV200612645
   BLASContributors, 2017, BLAS BAS LIN ALG SUB
   Bondhugula U., 2020, ARXIV200300532
   Bondhugula U, 2008, ACM SIGPLAN NOTICES, V43, P101, DOI 10.1145/1379022.1375595
   Churavy V, 2020, KERNELABSTRACTIONSJL
   Churavy V., 2020, GPUIFYLOOPSJL SUPPOR
   Di Napoli E, 2014, APPL MATH COMPUT, V235, P454, DOI 10.1016/j.amc.2014.02.051
   Elango V, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P42, DOI 10.1145/3211346.3211354
   Grosser T, 2012, PARALLEL PROCESS LET, V22, DOI 10.1142/S0129626412500107
   Haidar A, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Haidari A, 2019, PROBAB ENG INFORM SC, V33, P460, DOI 10.1017/S0269964818000220
   Hinton Geoffrey E, 2018, INT C LEARN REPR
   Ichimura T, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Julia, 2020, JUL LANG
   JuliaLang.org, 2020, JUL MICR BENCHM
   JuliaLang.org, 2020, JUL LANG OFF DOC
   Khronos Group, 2020, OPENCL OP STAND PAR
   Kim J, 2019, INT SYM CODE GENER, P85, DOI [10.1109/CGO.2019.8661182, 10.6084/m9.figshare.7403732]
   Li JJ, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807671
   LLVM contributors, 2020, LLVM COMPILER INFRAS
   Ma WJ, 2011, J CHEM THEORY COMPUT, V7, P1316, DOI 10.1021/ct1007247
   Matthews DA, 2018, SIAM J SCI COMPUT, V40, pC1, DOI 10.1137/16M108968X
   Mehta V., 2019, P NVIDIA GPU TECHN C
   Nelson T, 2015, PROC INT CONF PARAL, P969, DOI 10.1109/ICPP.2015.106
   NVIDIA, 2020, CUTLASS CUDA TEMPL
   NVIDIA, 2019, DEEP LEARN PERF GUID
   NVIDIA, 2020, CUDA C PROGRAMMING G
   NVIDIA, 2020, NVIDIA V100
   Paszke A, 2019, ADV NEUR IN, V32
   Peng Di, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P350, DOI 10.1109/ICPP.2012.19
   Poya R, 2017, COMPUT PHYS COMMUN, V216, P35, DOI 10.1016/j.cpc.2017.02.016
   Psarras C., CORR 2021ABS21031375
   Revels J., 2016, ARXIV160707892
   Rink NA, 2018, RWDSL2018: PROCEEDINGS OF THE REAL WORLD DOMAIN SPECIFIC LANGUAGES WORKSHOP 2018, DOI 10.1145/3183895.3183900
   Sioutas S, 2020, PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS FOR EMBEDDED SYSTEMS (SCOPES 2020), P36, DOI 10.1145/3378678.3391880
   Solomonik E, 2013, INT PARALL DISTRIB P, P813, DOI 10.1109/IPDPS.2013.112
   Springer P., 2017, P WORKSH BATCH REPR
   Springer P, 2018, ACM T MATH SOFTWARE, V44, DOI 10.1145/3157733
   Van Zee FG, 2020, SIAM J SCI COMPUT, V42, pC221, DOI 10.1137/19M1282040
   Van Zee FG, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2764454
   Verdoolaege S, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400713
   Yan D, 2020, INT PARALL DISTRIB P, P634, DOI 10.1109/IPDPS47924.2020.00071
NR 51
TC 1
Z9 1
U1 1
U2 3
PD SEPT 1
PY 2022
VL 33
IS 9
BP 2230
EP 2248
DI 10.1109/TPDS.2021.3136457
UT WOS:000757848700005
DA 2023-11-16
ER

PT C
AU Vandebon, J
   Coutinho, JGF
   Luk, W
   Nurvitadhi, E
   Naik, M
AF Vandebon, Jessica
   Coutinho, Jose G. F.
   Luk, Wayne
   Nurvitadhi, Eriko
   Naik, Mishali
GP IEEE
TI Enhanced Heterogeneous Cloud: Transparent Acceleration and Elasticity
SO 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2019)
DT Proceedings Paper
CT International Conference on Field-Programmable Technology (ICFPT)
CY DEC 09-13, 2019
CL Tianjin, PEOPLES R CHINA
DE FPGA; PaaS; heterogeneous clouds; transparent acceleration;
   heterogeneous elasticity
AB This paper presents ORIAN, a fully-managed Platform-as-a-Service (PaaS) for deploying high-level applications onto large-scale heterogeneous cloud infrastructures. We aim to make specialised, accelerator resources in the cloud accessible to software developers by extending the traditional homogeneous PaaS execution model to support automatic runtime management of heterogeneous compute resources such as CPUs and FPGAs. In particular, we focus on two mechanisms: transparent acceleration, which automatically maps jobs to the most suitable resource configuration, and heterogeneous elasticity, which performs automatic vertical (type) and horizontal (quantity) scaling of provisioned resources to guarantee QoS (Quality of Service) objectives while minimising cost. We develop a prototype to validate our approach, targeting a hardware platform with combined computational capacity of 28 FPGAs and 36 CPU cores, and evaluate it using case studies in three application domains: machine learning, bioinformatics, and physics. Our transparent acceleration decisions achieve on average 96% of the maximum manually identified static configuration throughput for large workloads, while removing the burden of determining configuration from the user; an elastic ORIAN resource group provides a 2.3 times cost reduction compared to an over-provisioned group for non-uniform, peaked job sequences while guaranteeing QoS objectives; and our malleable architecture extends to support a new, more suitable resource type, automatically reducing the cost by half while maintaining throughput, and achieving a 23% throughput increase while fulfilling resource constraints.
C1 [Vandebon, Jessica; Coutinho, Jose G. F.; Luk, Wayne] Imperial Coll London, London, England.
   [Nurvitadhi, Eriko; Naik, Mishali] Intel Corp, San Jose, CA USA.
RP Vandebon, J (corresponding author), Imperial Coll London, London, England.
EM jessica.vandebon17@imperial.ac.uk; gabriel.figueiredo@imperial.ac.uk;
   w.luk@imperial.ac.uk; eriko.nurvitadhi@intel.com; mishali.naik@intel.com
CR Arram J, 2017, IEEE ACM T COMPUT BI, V14, P668, DOI 10.1109/TCBB.2016.2535385
   Asiatici M, 2017, IEEE ACCESS, V5, P1900, DOI 10.1109/ACCESS.2017.2661582
   Coutinho J., 2017, HARNESS PLATFORM HAR
   Eskandari N, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P262, DOI 10.1145/3289602.3293909
   Graepel T., 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Heroku, SCAL YOUR DYN FORM
   Mbongue J., 2018, 2018 IEEE 11 INT C C
NR 7
TC 2
Z9 2
U1 0
U2 0
PY 2019
BP 162
EP 170
DI 10.1109/ICFPT47387.2019.00027
UT WOS:000574770300019
DA 2023-11-16
ER

PT J
AU Gao, W
   Zhou, PQ
AF Gao, Wei
   Zhou, Pingqiang
TI Customized High Performance and Energy Efficient Communication Networks
   for AI Chips
SO IEEE ACCESS
DT Article
DE AI accelerators; NoC; communication network
AB The convolutional and deep neural networks are prevalent machine learning algorithms for real-world applications. As the neural network needs large computations, many artificial intelligence (AI) chips are designed to accelerate the computation. AI chips have achieved better energy efficiency and high computational capacity in the neural network implementation. The communication network in AI chips influences the data transformation and hardware efficiency. The network-on-chip (NoC) is one feasible solution to meet the data communication requirements in AI chips. This paper introduces the communication network in AI chips and the strategy of mapping neural network to chips with the extensible hierarchical architecture. We also conclude the opportunities for communication optimization in the design of AI chips. In this paper, we propose our processor architecture and optimize the performance and energy of intra-communication in chips from three aspects: data reuse, topology, and router architecture. The experimental results show that our optimization can totally achieve 25.31x latency reduction and 79.92 x energy less than the baseline. The results show that our design can reduce the latency by 5.47x and save communication energy by 7.5x when compared with the state-of-the-art design DaDianNao. When compared with another design Eyeriss, our design can reduce latency by 7.57x and save communication energy by 3.03x.
C1 [Gao, Wei] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.
   [Gao, Wei; Zhou, Pingqiang] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Gao, Wei] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Gao, W (corresponding author), Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.; Gao, W (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.; Gao, W (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM gaowei@shanghaitech.edu.cn
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   [Anonymous], 2018, EYERISS V2 FLEXIBLE
   Bojarski Mariusz, 2016, arXiv
   Chen Y., 2014, MICRO DEC
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cota E., 2012, RELIABILITY AVAILABI, DOI 10.1007/978-1-4614-0791-1
   Dally W.J., 2004, PRINCIPLES PRACTICES
   Deng J., 2009, CVPR JUN
   Emer J., 2017, ISCA TUT JUN
   Farabet C., 2011, CVPR WORKSH JUN
   He Kaiming, 2016, PROC CVPR IEEE
   Hosseinabady M., 2006, DATE MAR
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H., 2007, ICML JUN
   Le QV., 2011, BUILDING HIGH LEVEL
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HG, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255460
   Liu X., 2018, ASPDAC JAN
   Liu XX, 2016, IEEE T CIRCUITS-I, V63, P617, DOI 10.1109/TCSI.2016.2529279
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Ramanujam R. S., 2010, NOCS MAY
   Rhu M., 2016, MICRO OCT
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Van Thiem C, 2011, ICNC DEC
   Vanhoucke V., 2011, NIPS DEC
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
NR 27
TC 5
Z9 5
U1 1
U2 19
PY 2019
VL 7
BP 69434
EP 69446
DI 10.1109/ACCESS.2019.2916338
UT WOS:000471352600001
DA 2023-11-16
ER

PT C
AU Zhou, SJ
   Kannan, R
   Prasanna, VK
AF Zhou, Shijie
   Kannan, Rajgopal
   Prasanna, Viktor K.
BE Athanas, P
   Cumplido, R
   Feregrino, C
   Sass, R
TI Accelerating Low Rank Matrix Completion on FPGA
SO 2017 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS
   (RECONFIG)
SE Proceedings International Conference on Reconfigurable Computing and
   FPGAs
DT Proceedings Paper
CT International Conference on Reconfigurable Computing and FPGAs
   (ReConFig)
CY DEC 04-06, 2017
CL Cancun, MEXICO
DE Analysis of incomplete datasets; Matrix factorization; Machine learning;
   Parallel processing; Data partitioning
AB Low Rank Matrix Completion (LRMC) is widely used in the analysis of incomplete datasets. In this paper, we propose a novel FPGA-based accelerator to speedup a matrix-factorization-based LRMC algorithm that uses stochastic gradient descent. The accelerator is a multi-pipelined architecture with parallel pipelines processing distinct data from a shared on-chip buffer. We propose two distinct on-chip buffer architectures based on a design-space exploration of the performance tradeoffs offered by two competing design methodologies: memory-efficiency versus concurrent conflict-free accesses. Our first design (i.e., memory-efficient design) organizes the buffer into banks and maximally utilizes available on-chip memory for matrix chunk processing without requiring complex address translation tables for on-chip addressing; however, it could incur bank conflicts when concurrent accesses to the same bank occur. The second design (i.e., bank-conflict-free design) exploits parallel multiport memory access and completely eliminates bank conflicts by duplicating the stored data; however, it has much higher on-chip RAM consumption. Intuitively, design one enables (slower) acceleration of (larger) chunks of the input matrix whereas design two enables (faster) processing of (smaller) matrix chunks but requires more iterations for processing the complete matrix. We propose a simple but efficient partitioning approach for supporting large input matrices that do not fit in the on-chip memory of FPGA. We also develop algorithmic optimizations based on matching to reduce data dependencies for parallel pipeline execution. We implement our designs on a state-of-the-art UltraScale+FPGA device. We use real-life datasets for the evaluation and compare these two designs by varying the number of pipelines. The data dependency optimization results in at least 21.6x data dependency reduction and improves the execution time by up to 66.3x compared with non-optimized baseline designs. The memory-efficient design is also shown to be more scalable than the bank-conflict-free design. Compared with the state-of-the-art multi-core implementation and GPU implementation, the bank-conflict-free design achieves 5.4x and 5.2x speedup, respectively; the memory-efficient design achieves 16.7x and 16.2x speedup, respectively.
C1 [Zhou, Shijie; Prasanna, Viktor K.] Univ Southern Calif, Los Angeles, CA 90089 USA.
   [Kannan, Rajgopal] US Army, Res Lab, Los Angeles, CA 90094 USA.
RP Zhou, SJ (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.
EM shijiezh@usc.edu; rajgopal.kannan.civ@mail.mil; prasanna@usc.edu
CR Alwani M., 2016, P MICRO
   Benne J., 2007, P KDD CUP WORKSH
   Brozovsky L., 2007, RECOMMENDER SYSTEM O
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Dean J., 2012, ADV NEURAL INFORM PR, V25, DOI DOI 10.5555/2999134.2999271
   Ding  C., 2017, P MICRO, P11
   Ham TJ, 2016, INT SYMP MICROARCH
   Jain P, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P665
   Kaleem Rashid, 2015, P 8 WORKSHOP GEN PUR, P81
   Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kuppannagari S., 2014, P HPEC
   LaForest CE, 2010, FPGA 10, P41
   Li Y., 2016, P FPL
   Luo Y., 2017, P FPL
   Morris GR, 2006, ANN IEEE SYM FIELD P, P3
   Satish N, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P979, DOI 10.1145/2588555.2610518
   Singer A, 2008, P NATL ACAD SCI USA, V105, P9507, DOI 10.1073/pnas.0709842104
   Tomasi C., 1992, INT J COMPUTER VISIO, V9
   Wei Tan, 2016, P 25 ACM INT S HIGH, P219
   Wilson R., 1996, INTRO GRAPH THEORY
   Zeng H., 2017, P RECONFIG
   Zhang MX, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P285
   Zhou PP, 2016, ANN IEEE SYM FIELD P, P172, DOI 10.1109/FCCM.2016.50
   Zhou S., 2014, P RECONFIG
   Zhou S., 2015, P IPDPSW
   Zhou S., 2016, P FCCM
   Zhou S., 2015, P RECONFIG
   Zhou SJ, 2015, IEEE INT CONF ASAP, P226, DOI 10.1109/ASAP.2015.7245738
NR 30
TC 1
Z9 1
U1 0
U2 0
PY 2017
UT WOS:000426529700004
DA 2023-11-16
ER

PT J
AU Krymova, E
   Obozinski, G
   Schenk, M
   Coyle, L
   Pieloni, T
AF Krymova, Ekaterina
   Obozinski, Guillaume
   Schenk, Michael
   Coyle, Loic
   Pieloni, Tatiana
TI Data-driven modeling of beam loss in the LHC
SO FRONTIERS IN PHYSICS
DT Article
DE beam losses; accelerator control; predictive model; ARMAX; Kalman filter
ID STATE-SPACE
AB In the Large Hadron Collider, the beam losses are continuously measured for machine protection. By design, most of the particle losses occur in the collimation system, where the particles with high oscilla-tion amplitudes or large momentum error are scraped from the beams. The particle loss level is typically optimized manually by changing control parameters, among which are currents in the focusing and defocusing magnets. It is generally challenging to model and predict losses based only on the control parameters, due to the presence of various (non-linear) effects in the system, such as electron clouds, resonance effects, etc., and multiple sources of uncertainty. At the same time understanding the influence of control parameters on the losses is extremely important in order to improve the operation and performance, and future design of accelerators. Prior work [1] showed that modeling the losses as an instantaneous function of the control parameters does not generalize well to data from a different year, which is an indication that the leveraged statistical associations are not capturing the actual mechanisms which should be invariant from 1 year to the next. Given that this is most likely due to lagged effects, we propose to model the losses as a function of not only instantaneous but also previously observed control parameters as well as previous loss values. Using a standard reparameterization, we reformulate the model as a Kalman Filter (KF) which allows for a flexible and efficient estimation procedure. We consider two main variants: one with a scalar loss output, and a second one with a 4D output with loss, horizontal and vertical emittances, and aggregated heatload as components. The two models once learned can be run for a number of steps in the future, and the second model can forecast the evolution of quantities that are relevant to predicting the loss itself. Our results show that the proposed models trained on the beam loss data from 2017 are able to predict the losses on a time horizon of several minutes for the data of 2018 as well and successfully identify both local and global trends in the losses.
C1 [Krymova, Ekaterina; Obozinski, Guillaume] EPFL, Swiss Data Sci Ctr, Zurich, Switzerland.
   [Krymova, Ekaterina; Obozinski, Guillaume] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Schenk, Michael; Coyle, Loic; Pieloni, Tatiana] Ecole Polytech Fed Lausanne, Inst Phys, Particle Accelerator Phys Lab, Lausanne, Switzerland.
   [Coyle, Loic] CERN, Geneva, Switzerland.
RP Krymova, E (corresponding author), EPFL, Swiss Data Sci Ctr, Zurich, Switzerland.; Krymova, E (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
EM ekaterina.krymova@sdsc.ethz.ch
CR Abada A., 2019, European Physical Journal Special Topics, V228, P1109, DOI 10.1140/epjst/e2019-900088-6
   Abada A, 2019, EUR PHYS J-SPEC TOP, V228, P755, DOI 10.1140/epjst/e2019-900087-0
   Abernethy J, 2009, J MACH LEARN RES, V10, P803
   Aquilina N, 2015, NUCL INSTRUM METH A, V778, P6, DOI 10.1016/j.nima.2014.12.081
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Belomestny D, 2021, ECON MODEL, V101, DOI 10.1016/j.econmod.2021.105531
   Brüning O, 2012, PROG PART NUCL PHYS, V67, P705, DOI 10.1016/j.ppnp.2012.03.001
   Casals J, 2012, MATH COMPUT SIMULAT, V82, P924, DOI 10.1016/j.matcom.2012.01.001
   Casals J, 1999, ECON LETT, V65, P329, DOI 10.1016/S0165-1765(99)00165-2
   Coyle L., 2021, PROC 12 INT PARTICLE, P4318, DOI [10.18429/JACoW-IPAC2021-THPAB260, DOI 10.18429/JACOW-IPAC2021-THPAB260]
   Coyle LTD, 2018, MACHINE LEARNING APP
   de Jong P, 2004, STAT PROBABIL LETT, V70, P119, DOI 10.1016/j.spl.2004.08.006
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Edwards D A., 2008, INTRO PHYS HIGH ENER
   Evans L, 2007, NEW J PHYS, V9, DOI 10.1088/1367-2630/9/9/335
   Fokianos K, 2009, J AM STAT ASSOC, V104, P1430, DOI 10.1198/jasa.2009.tm08270
   Hamilton J. D., 2020, TIME SERIES ANAL
   Hermes PD., 2015, 6 INT PART ACC C RIC
   Hou K., 2013, ADV NEURAL INF PROCE, V26, P1
   Koser D, 2022, FRONT PHYS-LAUSANNE, V10, DOI 10.3389/fphy.2022.875889
   Krymova Ekaterina, 2022, Zenodo, DOI 10.5281/ZENODO.7305102
   Li SC, 2021, INFORMATION, V12, DOI 10.3390/info12030121
   Ohtani K, 2000, ECON MODEL, V17, P473, DOI 10.1016/S0264-9993(99)00034-6
   Schenk M., 2021, JACOW IPAC, P1923, DOI [10.18429/JACoW-IPAC2021-TUPAB216, DOI 10.18429/JACOW-IPAC2021-TUPAB216]
   Solfaroli Camillocci M., 2016, P IPAC2016, P1489
   Zimmermann F, 2002, CERN REPORT, V2002, P47
   Zimmermann F, 1997, 95 LHC CERN, P18
NR 27
TC 0
Z9 0
U1 1
U2 2
PD JAN 5
PY 2023
VL 10
AR 960963
DI 10.3389/fphy.2022.960963
UT WOS:000917511700001
DA 2023-11-16
ER

PT J
AU Roy, S
   Sridharan, S
   Jain, S
   Raghunathan, A
AF Roy, Sourjya
   Sridharan, Shrihari
   Jain, Shubham
   Raghunathan, Anand
TI TxSim: Modeling Training of Deep Neural Networks on Resistive Crossbar
   Systems
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Deep neural network (DNN) training; in-memory; computing; neural
   networks; resistive random-access memory (ReRAM)
AB Deep neural networks (DNNs) have gained tremendous popularity in recent years due to their ability to achieve superhuman accuracy in a wide variety of machine learning tasks. However, the compute and memory requirements of DNNs have grown rapidly, creating a need for energy-efficient hardware. Resistive crossbars have attracted significant interest in the design of the next generation of DNN accelerators due to their ability to natively execute massively parallel vector-matrix multiplications within dense memory arrays. However, crossbar-based computations face a major challenge due to device and circuit-level nonidealities, which manifest as errors in the vector-matrix multiplications and eventually degrade DNN accuracy. To address this challenge, there is a need for tools that can model the functional impact of nonidealities on DNN training and inference. Existing efforts toward this goal are either limited to inference or are too slow to be used for large-scale DNN training. We propose TxSim, a fast and customizable modeling framework to functionally evaluate DNN training on crossbar-based hardware considering the impact of nonidealities. The key features of TxSim that differentiate it from prior efforts are: 1) it comprehensively models nonidealities during all training operations (forward propagation, backward propagation, and weight update) and 2) it achieves computational efficiency by mapping crossbar evaluations to well-optimized Basic Linear Algebra Subprograms (BLAS) routines and incorporates speedup techniques to further reduce simulation time with minimal impact on accuracy. TxSim achieves 6x-108x improvement in simulation speed over prior works, and thereby makes it feasible to evaluate the training of large-scale DNNs on crossbars. Our experiments using TxSim reveal that the accuracy degradation in DNN training due to nonidealities can be substantial (3%36.4%) for large-scale DNNs and data sets, underscoring the need for further research in mitigation techniques. We also analyze the impact of various device and circuit- level parameters and the associated nonidealities to provide key insights that can guide the design of crossbar-based DNN training accelerators.
C1 [Roy, Sourjya; Sridharan, Shrihari; Jain, Shubham; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
   [Jain, Shubham] IBM Res, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Roy, S; Sridharan, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
EM roy48@purdue.edu; sridhar4@purdue.edu; shubham.jain35@ibm.com;
   raghunathan@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   Ankit A., 2019, IEEE T COMPUT, V68, P1128
   [Anonymous], 2019, ARXIV190602698
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2014, ARXIV14125567V2CSCL
   [Anonymous], 2011, WW1
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   He ZH, 2020, PSYCHOL MED, V50, P2768, DOI 10.1017/S0033291719002915
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Jain S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947011
   Jain S, 2021, IEEE T COMPUT AID D, V40, P326, DOI 10.1109/TCAD.2020.3000185
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kendall Jack, 2020, ARXIV200601981
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kim S, 2017, MIDWEST SYMP CIRCUIT, P422, DOI 10.1109/MWSCAS.2017.8052950
   Parloff R., REVOLUTION WHY DEEP
   Peng XC, 2021, IEEE T COMPUT AID D, V40, P2306, DOI 10.1109/TCAD.2020.3043731
   Rajendran B, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL WORKSHOP ON THE PHYSICS OF SEMICONDUCTOR DEVICES: IWPSD-2007, P92, DOI 10.1109/IWPSD.2007.4472460
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Schuman D. C., 2017, ARXIV170506963
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Xia LX, 2018, IEEE T COMPUT AID D, V37, P1009, DOI 10.1109/TCAD.2017.2729466
   Zhang JT, 2016, SYMP VLSI CIRCUITS
NR 31
TC 18
Z9 18
U1 0
U2 7
PD APR
PY 2021
VL 29
IS 4
BP 730
EP 738
DI 10.1109/TVLSI.2021.3063543
UT WOS:000637190300012
DA 2023-11-16
ER

PT J
AU Yeh, CW
   Tu, CH
   Hung, SH
AF Yeh, Chih-Wei
   Tu, Chia-Heng
   Hung, Shih-Hao
TI Rapid Hybrid Simulation Methods for Exploring the Design Space of Signal
   Processors with Dynamic and Scalable Timing Models
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Embedded system; Efficient data transfer; Simulation; Approximate timing
   model; Acceleration; Design space exploration
ID EXPLORATION; FRAMEWORK; SYSTEM
AB As today's state-of-the-art signal processing systems often require heterogeneous computing and special-purpose accelerators to offer highly efficient performance for mixed application workloads, including not only traditional signal processing algorithms, but also the demands to enable smart applications with data analytics, machine learning, as well as the capability interacting with both physical and cyber worlds via sensors and networks. Thus, the complexity of such systems has been increasing, and the focus of designing has been shifting to exploring the design space with a mixture of processing cores/accelerators and the interconnection networks between the components to optimize the performance and efficiency at the system level. Traditional simulation tools may offer accurate performance estimation at micro architectural level, but it is highly complicated to combine the simulators for various components to perform complex applications, and they fall in short in terms of their capabilities to profiling application workload. Furthermore, the speed of such complex simulation would be unacceptably slow with traditional system-level simulation framework such as SystemC. To solve the problem, we develop a rapid hybrid emulation/simulation framework that allows the user to execute full-blown system and application software and plug in emulators, simulators, and timing models for various components in the prototype system, switching the timing models dynamically with our just-in-time model selection mechanism, and connect the emulated/simulated components with scalable communication channels, so that the framework can be accelerated effectively by a multicore host. Our just-in-time model selection mechanism is capable of detecting and skipping regular program patterns to save the simulation time dramatically. In addition, our framework is capable of estimating the performance of different system configurations with concurrent multiple timing models, which further saves the time needed for traversing the design space. Our experimental results have shown that our dynamic model selection and multi-model approach collectively can speed up the design space exploration by 13.4 times on a quad-core host for cache simulation.
C1 [Yeh, Chih-Wei; Hung, Shih-Hao] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Tu, Chia-Heng] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
RP Yeh, CW (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM medicinehy@gmail.com; chiaheng@mail.ncku.edu.tw; hungsh@csie.ntu.edu.tw
CR Angiolini F, 2006, DES AUT TEST EUROPE, P1145
   [Anonymous], INTEL PERFORMANCE BO
   [Anonymous], LOADS BLOCK STOR FOR
   [Anonymous], P 2015 C RES AD CONV
   [Anonymous], BUILDROOT MAKING EMB
   [Anonymous], 2011, P 18 INT C CONTROL S
   [Anonymous], INT SYM PERFORM ANAL
   [Anonymous], P 2014 INT C HARDW S
   [Anonymous], INTEL DEV FORUM 4K A
   [Anonymous], 2013, P 50 ANN DES AUT C D
   [Anonymous], 1 INT QEMU US FOR
   [Anonymous], SESC CYCLE ACCURATE
   [Anonymous], 2011, INTRO NETWORK SIMULA
   Beltrame G, 2010, IEEE T COMPUT AID D, V29, P1083, DOI 10.1109/TCAD.2010.2049053
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Binkert NL, 2006, IEEE MICRO, V26, P52, DOI 10.1109/MM.2006.82
   Bray T., 2014, JAVASCRIPT OBJECT NO
   Burger D., 1997, Computer Architecture News, V25, P13, DOI 10.1145/268806.268810
   Calborean H, 2010, 9TH ROEDUNET IEEE INTERNATIONAL CONFERENCE, P202
   Chen TS, 2014, CONF PROC INT SYMP C, P85, DOI 10.1109/ISCA.2014.6853198
   Cheng-Yen Lin, 2010, 2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P95
   Chiou D, 2007, INT SYMP MICROARCH, P249, DOI 10.1109/MICRO.2007.36
   Dubach C, 2007, INT SYMP MICROARCH, P262, DOI 10.1109/MICRO.2007.12
   Durillo JJ, 2010, IEEE C EVOL COMPUTAT
   Dutta R., 1992, Proceedings. 29th ACM/IEEE Design Automation Conference (Cat. No.92CH3144-3), P644, DOI 10.1109/DAC.1992.227806
   Edler J., 1998, DINERO 4 TRACE DRIVE
   Eunsuk Kang, 2010, Foundations of Computer Software. Modeling, Development, and Verification of Adaptive Systems. 16th Monterey Workshop 2010. Revised Selected Papers, P33, DOI 10.1007/978-3-642-21292-5_3
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Hsu HC, 2016, 2016 RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS, P230, DOI 10.1145/2987386.2987431
   Hung SH, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P260, DOI 10.1109/IMIS.2013.52
   Hung SH, 2012, ASIA S PACIF DES AUT, P395, DOI 10.1109/ASPDAC.2012.6164980
   Ipek E, 2007, ACM T ARCHIT CODE OP, V4, DOI 10.1145/1328195.1328196
   Mohanty S, 2002, ACM SIGPLAN NOTICES, V37, P18, DOI 10.1145/566225.513835
   Ozisikyilmaz B, 2008, DES AUT CON, P966
   Power J, 2015, IEEE COMPUT ARCHIT L, V14, P34, DOI 10.1109/LCA.2014.2299539
   Pullini A, 2016, IEEE INT SYMP CIRC S, P2910, DOI 10.1109/ISCAS.2016.7539213
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Sanchez Daniel, 2013, P 40 ANN INT S COMP, P475, DOI DOI 10.1145/2485922.2485963
   Schatz Bernhard, 2010, Proceedings of the 2010 17th IEEE International Conference and Workshops on Engineering of Computer-Based Systems (ECBS 2010), P173, DOI 10.1109/ECBS.2010.25
   Shih-Hao Hung, 2012, 2012 IEEE 1st Global Conference on Consumer Electronics (GCCE 2012), P586, DOI 10.1109/GCCE.2012.6379922
   Stoif C, 2011, IEEE INT SYMP CIRC S, P2557
   Tu CH, 2012, ACM T DES AUTOMAT EL, V17, DOI 10.1145/2348839.2348840
   Ubal R, 2007, INT SYM COMP ARCHIT, P62, DOI 10.1109/SBAC-PAD.2007.17
   Yu K., 2006, P 23 INT C MACH LEAR, P1081
NR 44
TC 0
Z9 0
U1 0
U2 3
PD MAR
PY 2019
VL 91
IS 3-4
SI SI
BP 247
EP 259
DI 10.1007/s11265-017-1285-z
UT WOS:000459428200004
DA 2023-11-16
ER

PT J
AU Ghiglio, P
   Dolinsky, U
   Goli, M
   Narasimhan, K
AF Ghiglio, Pietro
   Dolinsky, Uwe
   Goli, Mehdi
   Narasimhan, Kumudha
TI Improving performance of SYCL applications on CPU architectures using
   LLVM-directed compilation flow
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article; Early Access
DE compiler optimizations; multi-cores; parallel programming; portability;
   software acceleration; standards; SYCL
AB The wide adoption of SYCL as an open-standard API for accelerating C++ software in domains such as HPC, automotive, artificial intelligence, machine learning, and other areas necessitates efficient compiler and runtime support for a growing number of different platforms. Existing SYCL implementations provide support for various devices like CPUs, GPUs, DSPs, FPGAs and so forth, typically via OpenCL or CUDA backends. While accelerators have increased the performance of user applications significantly, employing CPU devices for further performance improvement is beneficial due to the significant presence of CPUs in existing data-centers. SYCL applications on CPUs, currently go through an OpenCL backend. Though an OpenCL backend is valuable in supporting accelerators, it may introduce additional overhead for CPUs since the host and device are the same. Overheads like a run-time compilation of the kernel, transferring of input/output memory to/from the OpenCL device, invoking the OpenCL kernel and so forth, may not be necessary when running on the CPU. While some of these overheads (such as data transfer) can be avoided by modifying the application, it can introduce disparity in the SYCL application's ability to achieve performance portability on other devices. In this article, we propose an alternate approach to running SYCL applications on CPUs. We bypass OpenCL and use a CPU-directed compilation flow, along with the integration of whole function vectorization to generate optimized host and device code together in the same translation unit. We compare the performance of our approach-the CPU-directed compilation flow, with an OpenCL backend for existing SYCL-based applications, with no code modification for BabelStream benchmark, Matmul from the ComputeCpp SDK, N-body simulation benchmarks and SYCL-BLAS (Aliaga et al. Proceedings of the 5th International Workshop on OpenCL; 2017.), on CPUs from different vendors and architectures. We report a performance improvement of up to 72%$$ 72\% $$ on BabelStream benchmarks, up to 63%$$ 63\% $$ on Matmul, up to 21%$$ 21\% $$ on the N-body simulation benchmark and up to 16% on SYCL-BLAS.
C1 [Ghiglio, Pietro; Dolinsky, Uwe; Goli, Mehdi; Narasimhan, Kumudha] Codeplay Software Ltd, Edinburgh, Scotland.
RP Ghiglio, P (corresponding author), Codeplay Software Ltd, Edinburgh, Scotland.
EM pietro.ghiglio@codeplay.com
CR 01.org, ONEAPI DEEP NEURAL N
   Aliaga JI., P 5 INT WORKSH OPENC
   Aliaga JI., 2017, P 5 INT WORKSHOP OPE, DOI [10.1145/3078155.3078189, DOI 10.1145/3078155.3078189]
   Alpay A., P INT WORKSH OPENCL
   [Anonymous], ONEDPL ONEAPI DPC LI
   [Anonymous], NVIDIA CUDA PROGRAMM
   [Anonymous], SYCL N BODY SIMULATI
   [Anonymous], SYCL SPECIFICATION C
   Ashbaugh B., P INT WORKSH OPENCL
   Bellard F., P USENIX ANN TECHN C
   Brown G., P INT WORKSH OPENCL
   Burns R., P INT WORKSH OPENCL, DOI [10.1145/3456669.3456687, DOI 10.1145/3456669.3456687]
   Burns R, 2019, PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19), DOI 10.1145/3318170.3318183
   clang.llvm, CROSS COMPILING CLAN
   Copik M., P 5 INT WORKSH OPENC
   Deakin T, 2016, LECT NOTES COMPUT SC, V9945, P489, DOI 10.1007/978-3-319-46079-6_34
   developer.codeplay, COMPUTECPP COMMUNITY
   Feng W., P INT WORKSH OPENCL
   Ghiglio P., IMPROVING PERFORMANC, DOI [10.1145/3528425.3529099, DOI 10.1145/3528425.3529099]
   github, COMPUTECPP SDK
   github, WHOLE FUNCTION VECTO
   github, HECBENCH
   Goli M., P 4 INT WORKSH OPENC
   Gozillon A., P 2020 INT C HIGH PE
   intel, VECTORIZATION SIMD P
   Karrenberg Ralf, 2015, AUTOMATIC SIMD VECTO, P85
   Ke YA, 2020, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING IN ASIA-PACIFIC REGION (HPC ASIA 2021), P50, DOI 10.1145/3432261.3432268
   Lattner C., P BSD C
   Lawson J, 2021, PARALLEL COMPUT, V107, DOI 10.1016/j.parco.2021.102813
   Meyer J., INT WORKSH OPENCL IW, DOI [10.1145/3529538.3530216, DOI 10.1145/3529538.3530216]
   Murray A., P INT WORKSH OPENCL, DOI [10.1145/3388333.3388652, DOI 10.1145/3388333.3388652]
   oneapi, INTEL ONEAPI MATH KE
   oneapi, ONEAPI SPECIFICATION
   Pheatt C., 2008, J COMPUT SCI COLL, V23, P298
   portablecl, PORTABLE COMPUTING L
   qemu, RISC V SYSTEM EMULAT
   Reinders James, 2021, DATA PARALLEL C MAST
   Sato M., P 2020 19 INT S PAR
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Thoman P., P INT WORKSH OPENCL
   Yamada Y., P S HIGH PERF CHIPS
NR 41
TC 0
Z9 0
U1 1
U2 1
PD 2023 MAY 30
PY 2023
DI 10.1002/cpe.7810
EA MAY 2023
UT WOS:000997026300001
DA 2023-11-16
ER

PT C
AU Koppula, S
   Orosa, L
   Yaglikçi, AG
   Azizi, R
   Shahroodi, T
   Kanellopoulos, K
   Mutlu, O
AF Koppula, Skanda
   Orosa, Lois
   Yaglikci, A. Giray
   Azizi, Roknoddin
   Shahroodi, Taha
   Kanellopoulos, Konstantinos
   Mutlu, Onur
GP Assoc Comp Machinery
TI EDEN: Enabling Energy-Efficient, High-Performance Deep Neural Network
   Inference Using Approximate DRAM
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE deep neural networks; error tolerance; energy efficiency; machine
   learning; DRAM; memory systems
AB The effectiveness of deep neural networks (DNN) in vision, speech, and language processing has prompted a tremendous demand for energy-efficient high-performance DNN inference systems. Due to the increasing memory intensity of most DNN workloads, main memory can dominate the system's energy consumption and stall time. One effective way to reduce the energy consumption and increase the performance of DNN inference systems is by using approximate memory, which operates with reduced supply voltage and reduced access latency parameters that violate standard specifications. Using approximate memory reduces reliability, leading to higher bit error rates. Fortunately, neural networks have an intrinsic capacity to tolerate increased bit errors. This can enable energy-efficient and high-performance neural network inference using approximate DRAM devices.
   Based on this observation, we propose EDEN, the first general framework that reduces DNN energy consumption and DNN evaluation latency by using approximate DRAM devices, while strictly meeting a user-specified target DNN accuracy. EDEN relies on two key ideas: 1) retraining the DNN for a target approximate DRAM device to increase the DNN's error tolerance, and 2) efficient mapping of the error tolerance of each individual DNN data type to a corresponding approximate DRAM partition in a way that meets the user-specified DNN accuracy requirements.
   We evaluate EDEN on multi-core CPUs, GPUs, and DNN accelerators with error models obtained from real approximate DRAM devices. We show that EDEN's DNN retraining technique reliably improves the error resiliency of the DNN by an order of magnitude. For a target accuracy within 1% of the original DNN, our results show that EDEN enables 1) an average DRAM energy reduction of 21%, 37%, 31%, and 32% in CPU, GPU, and two different DNN accelerator architectures, respectively, across a variety of state-of-the-art networks, and 2) an average (maximum) speedup of 8% (17%) and 2.7% (5.5%) in CPU and GPU architectures, respectively, when evaluating latency-bound neural networks.
C1 [Koppula, Skanda; Orosa, Lois; Yaglikci, A. Giray; Azizi, Roknoddin; Shahroodi, Taha; Kanellopoulos, Konstantinos; Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Koppula, S (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Advani S., 2014, ICCD
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Andri R., 2017, TCAD
   [Anonymous], 2009, PERFORMANCE ANAL GUI
   [Anonymous], 2016, MICROARCHITECTURE MI
   [Anonymous], ICCD
   [Anonymous], 2017, THESIS CARNEGIE MELL
   [Anonymous], 2013, DAC
   [Anonymous], 2003, HPCA
   [Anonymous], 2013, THESIS
   Aurisano A., 2016, JINST
   Baek S., 2013, TC
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   Baseman E., 2018, DFT
   Bengio, 2016, ABS160202830 CORR
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3296957.3173177, 10.1145/3173162.3173177]
   Cavigelli L., 2017, TCSVT
   Chandrasekar K., 2012, DRAMPOWER OPEN SOURC
   Chandrasekar K., 2014, DATE
   Chang KK, 2017, P ACM MEAS ANAL COMP, V1, DOI 10.1145/3084447
   Chang KK, 2016, SIGMETRICS/PERFORMANCE 2016: PROCEEDINGS OF THE SIGMETRICS/PERFORMANCE JOINT INTERNATIONAL CONFERENCE ON MEASUREMENT AND MODELING OF COMPUTER SCIENCE, P323, DOI [10.1145/2964791.2901453, 10.1145/2896377.2901453]
   Chang KK, 2016, INT S HIGH PERF COMP, P568, DOI 10.1109/HPCA.2016.7446095
   Chang KKW, 2014, INT S HIGH PERF COMP, P356, DOI 10.1109/HPCA.2014.6835946
   Chen G., 2014, ICASSP
   Chen T., 2016, TRAINING DEEP NETS W
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chetlur S., 2014, ARXIV PREPRINT ARXIV
   Chi P., 2016, P INT S COMP ARCH IS
   Choi J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P223, DOI 10.1145/2749469.2750402
   Chou Y, 2004, CONF PROC INT SYMP C, P76, DOI 10.1109/ISCA.2004.1310765
   Cun Y. L., 1990, NIPS
   Das A., 2018, DAC
   David H., 2011, P 8 ACM INT C AUT CO, P31, DOI DOI 10.1145/1998582.1998590
   De Sa C., 2018, HIGH ACCURACY LOWPRE
   Deng J., 2015, DATE
   Deng QY, 2011, ACM SIGPLAN NOTICES, V46, P225, DOI 10.1145/1961296.1950392
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Du S. S., 2018, ARXIV PREPRINT ARXIV
   Dundas J., 1997, Conference Proceedings of the 1997 International Conference on Supercompting, P68, DOI 10.1145/263580.263597
   Dundas J. D., 1999, TECH REP
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Ghose S., 2019, SIGMETRICS
   Ghose S, 2018, P ACM MEAS ANAL COMP, V2, DOI 10.1145/3224419
   Gomez Aidan N, 2017, ADV NEURAL INFORM PR, V2, P3
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Guan M., 2015, ISQED
   Guo K., 2017, TCAD
   Gupta S., 2018, RAPIDNN IN MEMORY DE
   Hamamoto T., 1998, TED
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hassan H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P129, DOI 10.1145/3307650.3322231
   Hassan H, 2017, INT S HIGH PERF COMP, P241, DOI 10.1109/HPCA.2017.62
   Hassan H, 2016, INT S HIGH PERF COMP, P581, DOI 10.1109/HPCA.2016.7446096
   He K., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1007/978-3-319-46493-0_38
   He Yang, 2019, CVPR
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Hubara I., 2017, IMLR
   Iandola F, 2014, DENSENET IMPLEMENTIN
   Iandola F.N., 2016, SQUEEZENET ALEXNET L
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   JEDEC Standard, 2012, JESD794 JEDEC DDR4 S
   Jin W., 2017, P ADV NEURAL INFORM, P2604
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung M., 2015, MEMSYS
   Jung M., 2016, DAC
   KEETH B, 2000, DRAM CIRCUIT DESIGN
   Khan Samira, 2016, 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). Proceedings, P239, DOI 10.1109/DSN.2016.30
   Khan Samira, 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P519, DOI 10.1145/2591971.2592000
   Kim JS, 2019, INT S HIGH PERF COMP, P582, DOI 10.1109/HPCA.2019.00011
   Kim JS, 2018, PR IEEE COMP DESIGN, P282, DOI 10.1109/ICCD.2018.00051
   Kim JS, 2018, INT S HIGH PERF COMP, P194, DOI 10.1109/HPCA.2018.00026
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kim Y, 2012, CONF PROC INT SYMP C, P368
   Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579
   Kozlov A., 2019, INTELLISYS
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3173162.3173176, 10.1145/3296957.3173176]
   Kwon Hyoukjun, 2018, MAESTRO OPEN SOURCE
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, CTP PBSRI
   LeCun Y., 1989, ADV IN NEURAL INFORM, P598
   LeCun Yann, 2015, NATURE
   Lee D., 2013, HPCA
   Lee D., 2017, SIGMETRICS
   Lee D., 2015, PACT
   Lee D, 2015, INT S HIGH PERF COMP, P489, DOI 10.1109/HPCA.2015.7056057
   Leng Jingwen, 2013, ISCA
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Li H., 2017, PROC INT C LEARN REP
   Li J., 2018, DATE
   Li S., MICRO
   Li S., 2018, MICRO
   Lillicrap T.P., 2016, CONTINUOUS CONTROL D
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JM, 2012, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2012.6237001
   Long Y., 2018, TVLSI
   Lu S.-L., 2015, MICRO
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Marques J., 2017, SIPS
   Meza J, 2015, I C DEPEND SYS NETWO, P415, DOI 10.1109/DSN.2015.57
   Micron, TN4007 MICR
   Mutlu O., 2005, CAL
   Mutlu O., 2015, MORE MOORE TECHNOLOG
   Mutlu O., 2005, ISCA
   Nazemi M., 2018, NULLANET TRAINING DE
   Neggaz M. A., 2018, ICCD
   Neubeck Alexander, 2006, ICPR
   Neyshabur Behnam, 2018, UNDERSTANDING ROLE O
   Nguyen D. T., 2018, ISCAS
   Nguyen D.-T., 2019, DAC
   Novak R., 2018, ICLR
   Oh K.-S., 2004, JPRR
   Panda P., 2016, DAC
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paszke Adam, 2017, ADV NEURAL INFORM PR
   Patel M., 2019, DSN
   Patel M, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P255, DOI 10.1145/3079856.3080242
   Phatak D. S., 1995, TNN
   Qin M., 2017, ROBUSTNESS NEURAL NE
   Qureshi MK, 2015, I C DEPEND SYS NETWO, P427, DOI 10.1109/DSN.2015.58
   Rau PLP, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/263721
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Redmon J., 2013, DARKNET OPEN SOURCE
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salami B., 2018, RESILIENCE RTL NN AC
   Salami B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P724, DOI [10.1109/MICR0.2018.00064, 10.1109/MICRO.2018.00064]
   Salavati A. H., 2012, ISIT
   Samajdar A., 2018, COMPUTING RES REPOSI
   Sanchez D., 2013, ISCA, P475
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroeder B, 2009, PERF E R SI, V37, P193
   Schuiki F., 2018, SCALABLE NEAR MEMORY
   Segler M., 2017, ACS CENTRAL SCI
   Seshadri V., 2019, CORR
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shazeer Noam, 2017, OUTRAGEOUSLY LARGE N
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Shi W., 2014, CASES
   Shixiang Gu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3389, DOI 10.1109/ICRA.2017.7989385
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Son Y. H., 2013, ISCA
   Song L., 2016, P 53 ANN DES AUT C D
   Sprangle E., 2002, ISCA
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sze V, 2017, IEEE CUST INTEGR CIR
   Tang X., 2016, MICRO
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Tu F., 2018, ISCA
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Vogelsang T., 2010, MICRO
   Wang YH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P298, DOI 10.1109/MICRO.2018.00032
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang L., 2017, ISVLSI
   Yang LT, 2017, INT SYM QUAL ELECT, P7, DOI 10.1109/ISQED.2017.7918284
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang J.J., 2018, P VLSI TEST S VTS 20, P1, DOI 10.1109/VTS.2018.8368656
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
   Zhang T, 2014, CONF PROC INT SYMP C, P349, DOI 10.1109/ISCA.2014.6853217
   Zhang X., 2016, MEMSYS
   Zhu C., 2016, ARXIV161201064
NR 179
TC 57
Z9 57
U1 0
U2 8
PY 2019
BP 166
EP 181
DI 10.1145/3352460.3358280
UT WOS:000519057400013
DA 2023-11-16
ER

PT J
AU Mund, K
   Maloney, L
   Lu, B
   Wu, J
   Li, J
   Liu, C
   Yan, GH
AF Mund, Karl
   Maloney, Luke
   Lu, Bo
   Wu, Jian
   Li, Jonathan
   Liu, Chihray
   Yan, Guanghua
TI Reconstruction of volume averaging effect-free continuous photon beam
   profiles from discrete ionization chamber array measurements using a
   machine learning technique
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE artificial neural network; ion chamber array; volume averaging effect
ID QUALITY-ASSURANCE; COMMITTEE
AB Purpose The use of the ionization chamber array ICProfiler (ICP) is limited by its relatively poor detector spatial resolution and the inherent volume averaging effect (VAE). The purpose of this work is to study the feasibility of reconstructing VAE-free continuous photon beam profiles from ICP measurements with a machine learning technique. Methods In- and cross-plane photon beam profiles of a 6 MV beam from an Elekta linear accelerator, ranging from 2 x 2 to 10 x 10 cm(2) at 1.5 cm, 5 cm, and 10 cm depth, were measured with an ICP. The discrete measurements were interpolated with a Makima method to obtain continuous beam profiles. Artificial neural networks (ANNs) were trained to restore the penumbra of the beam profiles. Plane-specific (in- and cr-plane) ANNs and a combined ANN were separately trained. The performance of the ANNs was evaluated using the penumbra width difference (PWD, the difference between the penumbra widths of the reconstructed and the reference profile). The plane-specific and the combined ANNs were compared to study the feasibility of using a single ANN for both in- and cross-plane. Results The profiles reconstructed with all the ANNs had excellent agreement with the reference. For in-plane, the ANNs reduced the PWD from 1.6 +/- 0.7 mm at 1.5 cm depth to 0.1 +/- 0.1 mm, from 1.8 +/- 0.6 mm at 5.0 cm depth to 0.1 +/- 0.1 mm, and from 2.4 +/- 0.1 mm at 10.0 cm depth to 0.0 +/- 0.0 mm; for cross-plane, the ANNs reduced the PWD from 1.2 +/- 0.4 mm at 1.5 cm depth, 1.2 +/- 0.3 mm at 5.0 cm depth, and 1.6 +/- 0.1 mm at 10.0 cm depth, to 0.1 +/- 0.1 mm. Conclusions This study demonstrated the feasibility of using simple ANNs to reconstruct VAE-free continuous photon beam profiles from discrete ICP measurements. A combined ANN can restore the penumbra of in- and cross-plane beam profiles of various fields at different depths.
C1 [Mund, Karl; Maloney, Luke; Lu, Bo; Wu, Jian; Li, Jonathan; Liu, Chihray; Yan, Guanghua] Univ Florida, Dept Radiat Oncol, POB 100385, Gainesville, FL 32610 USA.
RP Yan, GH (corresponding author), Univ Florida, Dept Radiat Oncol, POB 100385, Gainesville, FL 32610 USA.
EM yangua@shands.ufl.edu
CR Barraclough B, 2015, PHYS MED BIOL, V60, P6213, DOI 10.1088/0031-9155/60/16/6213
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Feng M, 2018, FRONT ONCOL, V8, DOI 10.3389/fonc.2018.00110
   Fraass B, 1998, MED PHYS, V25, P1773, DOI 10.1118/1.598373
   Gao S, 2019, J APPL CLIN MED PHYS, V20, P111, DOI 10.1002/acm2.12719
   Kalet AM, 2020, MED PHYS, V47, pE168, DOI 10.1002/mp.13445
   Karimnia V, 2018, J APPL CLIN MED PHYS, V19, P323, DOI 10.1002/acm2.12466
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Liu H, 2018, MED PHYS, V45, P5586, DOI 10.1002/mp.13230
   Low DA, 2003, MED PHYS, V30, P1706, DOI 10.1118/1.1582558
   Mund K, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12865
   Perik TJ, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aae90a
   RIKNER G, 1987, PHYS MED BIOL, V32, P1109, DOI 10.1088/0031-9155/32/9/004
   Simon TA, 2010, MED PHYS, V37, P6101, DOI 10.1118/1.3505452
   Smit K, 2014, PHYS MED BIOL, V59, P1845, DOI 10.1088/0031-9155/59/7/1845
   Valdes G., 2020, FRONT ARTIF INTELL, V3
   Westermark M, 2000, PHYS MED BIOL, V45, P685, DOI 10.1088/0031-9155/45/3/308
   Yan GH, 2008, MED PHYS, V35, P3661, DOI 10.1118/1.2952643
NR 18
TC 2
Z9 2
U1 1
U2 2
PD OCT
PY 2021
VL 22
IS 10
BP 161
EP 168
DI 10.1002/acm2.13411
EA SEP 2021
UT WOS:000692702100001
DA 2023-11-16
ER

PT J
AU Zhang, ZZ
   Zhu, GX
   Wang, R
   Lau, VKN
   Huang, KB
AF Zhang, Zezhong
   Zhu, Guangxu
   Wang, Rui
   Lau, Vincent K. N.
   Huang, Kaibin
TI Turning Channel Noise Into an Accelerator for Over-the-Air Principal
   Component Analysis
SO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
DT Article
DE Principal component analysis; Servers; Distributed databases; Signal to
   noise ratio; Convergence; Atmospheric modeling; Optimization; Federated
   edge learning; principal component analysis (PCA); over-the-air
   computation; power control; convergence analysis
ID APPROXIMATION; QUANTIZATION; RECOGNITION
AB The enormous data distributed at the network edge and ubiquitous connectivity have led to the emergence of the new paradigm of distributed machine learning and large-scale data analytics. Distributed principal component analysis (PCA) concerns finding a low-dimensional subspace that contains the most important information of high-dimensional data distributed over the network edge. The subspace is useful for distributed data compression and feature extraction. This work advocates the application of over-the-air federated learning to efficient implementation of distributed PCA in a wireless network under a data-privacy constraint, termed AirPCA. The design features the exploitation of the waveform-superposition property of a multi-access channel to realize over-the-air aggregation of local subspace updates computed and simultaneously transmitted by devices to a server, thereby reducing the multi-access latency. The original drawback of this class of techniques, namely channel-noise perturbation to uncoded analog modulated signals, is turned into a mechanism for escaping from saddle points during stochastic gradient descent (SGD) in the AirPCA algorithm. As a result, the convergence of the AirPCA algorithm is accelerated. To materialize the idea, descent speeds in different types of descent regions are analyzed mathematically using martingale theory by accounting for wireless propagation and techniques including broadband transmission, over-the-air aggregation, channel fading and noise. The results reveal the accelerating effect of noise in saddle regions and the opposite effect in other types of regions. The insight and results are applied to designing an online scheme for adapting receive signal power to the type of current descent region. Specifically, the scheme amplifies the noise effect in saddle regions by reducing signal power and applies the power savings to suppressing the effect in other regions. From experiments using real datasets, such power control is found to accelerate convergence while achieving the same convergence accuracy as in the ideal case of centralized PCA.
C1 [Zhang, Zezhong; Huang, Kaibin] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China.
   [Zhang, Zezhong] Chinese Univ Hong Kong Shenzhen, Future Network Intelligence Inst FNii, Shenzhen 518172, Peoples R China.
   [Zhu, Guangxu] Shenzhen Res Inst Big Data, Shenzhen 518172, Peoples R China.
   [Wang, Rui] Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen 518055, Peoples R China.
   [Lau, Vincent K. N.] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Peoples R China.
RP Huang, KB (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China.; Wang, R (corresponding author), Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen 518055, Peoples R China.
EM zhangzezhong@cuhk.edu.cn; gxzhu@sribd.cn; wang.r@sustech.edu.cn;
   eeknlau@ust.hk; huangkb@eee.hku.hk
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Amiri MM, 2020, IEEE T WIREL COMMUN, V19, P3546, DOI 10.1109/TWC.2020.2974748
   Balcan MF, 2014, ADV NEURAL INFORM PR, V4, P3113
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bertsekas DP., 1996, NEURO DYNAMIC PROGRA
   Chen MZ, 2021, IEEE T WIREL COMMUN, V20, P269, DOI 10.1109/TWC.2020.3024629
   Du YQ, 2020, IEEE T SIGNAL PROCES, V68, P2128, DOI 10.1109/TSP.2020.2983166
   Fan JQ, 2019, ANN STAT, V47, P3009, DOI 10.1214/18-AOS1713
   Friedlander MP, 2013, SIAM J SCI COMPUT, V35, pB950, DOI 10.1137/130908257
   Grammenos A, 2020, ADV NEURAL INFORM PR, P6453
   Iwen MA, 2016, SIAM J MATRIX ANAL A, V37, P1699, DOI 10.1137/16M1058467
   Jin C, 2017, PR MACH LEARN RES, V70
   Lim WYB, 2020, IEEE COMMUN SURV TUT, V22, P2031, DOI 10.1109/COMST.2020.2986024
   Lin ZY, 2022, IEEE T WIREL COMMUN, V21, P1542, DOI 10.1109/TWC.2021.3104834
   Liu DZ, 2021, IEEE J SEL AREA COMM, V39, P170, DOI 10.1109/JSAC.2020.3036948
   Luo SQ, 2020, IEEE T WIREL COMMUN, V19, P6535, DOI 10.1109/TWC.2020.3003744
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mertikopoulos Panayotis, 2020, ADV NEURAL INFORM PR, V33, P1117
   Narayanamurthy P, 2022, Arxiv, DOI arXiv:2002.12873
   OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3
   Rong Ge, 2015, P 28 C LEARNING THEO, P797, DOI DOI 10.1109/ICMTMA.2015.197
   Samarakoon S, 2020, IEEE T COMMUN, V68, P1146, DOI 10.1109/TCOMM.2019.2956472
   Shlezinger N, 2021, IEEE T SIGNAL PROCES, V69, P500, DOI 10.1109/TSP.2020.3046971
   Sun YW, 2020, IEEE T WIREL COMMUN, V19, P6331, DOI 10.1109/TWC.2020.3002719
   Wang AD, 2020, IEEE T WIREL COMMUN, V19, P6786, DOI 10.1109/TWC.2020.3006042
   Xiaopeng Mo, 2021, Journal of Communications and Information Networks, V6, P110, DOI 10.23919/JCIN.2021.9475121
   YANG B, 1995, IEEE T SIGNAL PROCES, V43, P95, DOI 10.1109/78.365290
   Yang HH, 2020, IEEE T COMMUN, V68, P317, DOI 10.1109/TCOMM.2019.2944169
   Yang K, 2020, IEEE T WIREL COMMUN, V19, P2022, DOI 10.1109/TWC.2019.2961673
   Yang ZH, 2021, IEEE T WIREL COMMUN, V20, P1935, DOI 10.1109/TWC.2020.3037554
   Zeng QS, 2021, IEEE T WIREL COMMUN, V20, P7947, DOI 10.1109/TWC.2021.3088910
   Zhai XF, 2021, IEEE T COMMUN, V69, P2737, DOI 10.1109/TCOMM.2021.3051397
   Zhang NF, 2021, IEEE T WIREL COMMUN, V20, P5115, DOI 10.1109/TWC.2021.3065748
   Zhu GX, 2021, IEEE T WIREL COMMUN, V20, P2120, DOI 10.1109/TWC.2020.3039309
   Zhu GX, 2020, IEEE T WIREL COMMUN, V19, P491, DOI 10.1109/TWC.2019.2946245
   Zhu GX, 2019, IEEE INTERNET THINGS, V6, P6089, DOI 10.1109/JIOT.2018.2871070
NR 37
TC 2
Z9 2
U1 3
U2 6
PD OCT
PY 2022
VL 21
IS 10
BP 7926
EP 7941
DI 10.1109/TWC.2022.3162868
UT WOS:000866499900010
DA 2023-11-16
ER

PT C
AU Mokhtari, A
   Rawls, D
   Huynh, T
   Green, J
   Salehi, MA
AF Mokhtari, Ali
   Rawls, Drake
   Huynh, Tony
   Green, Jeremiah
   Salehi, Mohsen Amini
GP IEEE
TI E2C: A Visual Simulator to Reinforce Education of Heterogeneous
   Computing Systems
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS, IPDPSW
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
ID TOOLKIT
AB Heterogeneity has been an indispensable aspect of distributed computing throughout the history of these systems. In particular, with the increasing popularity of accelerator technologies (e.g., GPUs and TPUs) and the emergence of domain-specific computing via ASICs and FPGA, the matter of heterogeneity and understanding its ramifications on the system performance has become more critical than ever before. However, it is challenging to effectively educate students about the potential impacts of heterogeneity on: (a) the performance of distributed systems; and (b) the logic of resource allocation methods to efficiently utilize the resources. Making use of the real infrastructure (such as those offered by the public cloud providers) for benchmarking the performance of heterogeneous machines, for different applications, with respect to different objectives, and under various workload intensities is cost- and time-prohibitive. Moreover, not all students (globally and nationally) have access or can afford such real infrastructure. To reinforce the quality of learning about various dimensions of heterogeneity, and to decrease the widening gap in education, we develop an open-source simulation tool, called E2C, that can help students researchers and practitioners to study any type of heterogeneous (or homogeneous) computing system and measure its performance under various system configurations. To make the learning curve shallow, E2C is equipped with an intuitive graphical user interface (GUI) that enables its users to easily examine system-level solutions (scheduling, load balancing, scalability, etc.) in a controlled environment within a short time and at no cost. In particular, E2C is a discrete event simulator that offers the following features: (i) simulating a heterogeneous computing system; (ii) implementing a newly developed scheduling method and plugging it into the system, (iii) measuring energy consumption and other output-related metrics; and (iv) powerful visual aspects to ease the learning curve for students. We used E2C as an assignment in the Distributed and Cloud Computing course. Our anonymous survey study indicates that students rated E2C with the score of 8.7 out of 10 for its usefulness in understanding the concepts of scheduling in heterogeneous computing. Moreover, our pre- and post-evaluations indicate that E2C has improved the students' understanding of heterogeneous computing systems by around 18%.
C1 [Mokhtari, Ali; Rawls, Drake; Huynh, Tony; Green, Jeremiah; Salehi, Mohsen Amini] Univ Louisiana Lafayette, Sch Comp & Informat, High Performance Cloud Comp HPCC Lab, Lafayette, LA 70503 USA.
RP Mokhtari, A (corresponding author), Univ Louisiana Lafayette, Sch Comp & Informat, High Performance Cloud Comp HPCC Lab, Lafayette, LA 70503 USA.
EM ali.mokhtaril@louisiana.edu; drake.rawlsl@louisiana.edu;
   tony.huynhl@louisiana.edu; jeremiah.greenl@louisiana.edu;
   amini@louisiana.edu
CR Ali Shoukat, 2000, J APPL SCI ENG, V3, P195
   amazon, AM SAG
   Bobda C, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3506713
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Cardwell Suma George, 2020, SMOKY MOUNTAINS COMP, P349
   Denninnart C, 2020, J PARALLEL DISTR COM, V142, P46, DOI 10.1016/j.jpdc.2020.03.018
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Gentry J, 2019, INT PARALL DISTRIB P, P375, DOI 10.1109/IPDPS.2019.00047
   google, GLASS ENT
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   Jararweh Yaser, 2013, International Journal of Cloud Computing, V2, P237
   Maheswaran M, 1999, J PARALLEL DISTR COM, V59, P107, DOI 10.1006/jpdc.1999.1581
   Mokhtari A, 2020, IEEE SYM PARA DISTR, P17, DOI 10.1109/IPDPSW50202.2020.00013
   Mokhtari Ali, 2022, P 15 IEEE INT C CLOU
   Núñez A, 2012, J GRID COMPUT, V10, P185, DOI 10.1007/s10723-012-9208-5
   Panda SK, 2019, CLUSTER COMPUT, V22, P509, DOI 10.1007/s10586-018-2858-8
   Panda SK, 2015, J SUPERCOMPUT, V71, P1505, DOI 10.1007/s11227-014-1376-6
   qualcomm, QUALC REV WORLDS 1 D
   Sonmez C, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3493
   Taylor MB, 2012, DES AUT CON, P1131
   Taylor MB, 2020, COMMUN ACM, V63, P103, DOI 10.1145/3399734
   Zobaed SM, 2022, P 15 IEEEACM INT C U
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 270
EP 277
DI 10.1109/IPDPSW59300.2023.00052
UT WOS:001055030700034
DA 2023-11-16
ER

PT C
AU Heinz, C
   Koch, A
AF Heinz, Carsten
   Koch, Andreas
GP IEEE Comp Soc
TI Near-Data FPGA-Accelerated Processing of Collective and Inference
   Operations in Disaggregated Memory Systems
SO PROCEEDINGS OF SEVENTH INTERNATIONAL WORKSHOP ON HETEROGENEOUS
   HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC 2021)
DT Proceedings Paper
CT IEEE/ACM 7th International Workshop on Heterogeneous High- Performance
   Reconfigurable Computing (H2RC) Part of International Conference for
   High Performance Computing, Networking, Storage and Analysis (SC)
CY NOV 14-19, 2021
CL St Louis, MO
AB With growing data set sizes, many scientific and data center HPC workloads observe an increasing scaling imbalance, e.g., between compute and memory capacities. As a solution, disaggregated system architectures employ spatial distribution of the different resources. They aim for independent scaling of the different resource kinds (e.g., compute, non-volatile storage, memory), and use fast communication fabrics for their interconnection.
   However, for some bulk operations, such as reductions and collections, it is still beneficial to perform them close to the memories, avoiding the need to move large volumes of data over the fabric.
   This work realizes a disaggregated system capable of performing such near-data processing (NDP) operations by extending the distributed memory controllers with hardware-accelerated compute capabilities. The actual computations execute on FPGAs and can be abstractly described using C/C++ as compilable by high-level hardware synthesis (HLS) tools.
   We have aimed for high usability of our technology also by HPC experts unfamiliar with hardware design. An automated toolflow encapsulates the creation and deployment of the actual accelerators in the disaggregated system. The NDP operations execute distributed across all memory nodes, and are easily accessed using a simple MPI-based programming interface that requires only minimal effort to use in existing applications.
   Our solution is demonstrated using a prototype disaggregated system based on the low-latency EXTOLL fabric for communication. We evaluate both conventional reductions/collectives as well as complete machine-learning inference tasks.
C1 [Heinz, Carsten; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
RP Heinz, C (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM heinz@esa.tu-darmstadt.de; koch@esa.tu-darmstadt.de
CR [Anonymous], 2006, P INT C FIELD PROGRA
   Arap O, 2014, LECT NOTES COMPUT SC, V8632, P632, DOI 10.1007/978-3-319-09873-9_53
   De Matteis T, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356201
   Dua D., 2017, UCI MACHINE LEARNING
   Fröning H, 2013, IEEE ACM INT SYMP, P498, DOI 10.1109/CCGrid.2013.43
   Gen-Z Consortium, COMPUTER IND ALLIANC
   Graham Richard L., 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P53, DOI 10.1109/CCGRID.2010.9
   Graham RL, 2016, PROCEEDINGS OF FIRST WORKSHOP ON OPTIMIZATION OF COMMUNICATION IN HPC RUNTIME SYSTEMS (COM-HPC 2016), P1, DOI [10.1109/COM-HPC.2016.6, 10.1109/COMHPC.2016.006]
   Gropp W., 1999, USING MPI 2 ADV FEAT
   Guz Z, 2017, SYSTOR'17: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL SYSTEMS AND STORAGE CONFERENCE, DOI 10.1145/3078468.3078483
   Heinz C., 2020, P 10 INT WORKSH RUNT
   Koch A, 2019, INT S APPL REC COMP
   Kwon Y, 2019, IEEE MICRO, V39, P82, DOI 10.1109/MM.2019.2929165
   Li JJ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P51, DOI 10.1145/3373087.3375320
   Lim K, 2009, CONF PROC INT SYMP C, P267, DOI 10.1145/1555815.1555789
   Poon H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P689, DOI 10.1109/ICCVW.2011.6130310
   RIKEN, JAP FUG GAINS TITL W
   Ringlein B., 2020, 6 INT WORKSH HET HIG
   Schmidt J., 2017, THESIS
   Schmidt J, 2016, INT C HIGH PERF COMP
   Sommer L, 2020, ANN IEEE SYM FIELD P, P75, DOI 10.1109/FCCM48280.2020.00020
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Vinçon T, 2020, PROC VLDB ENDOW, V13, P2981, DOI 10.14778/3415478.3415524
   Xi Sam Likun, 2015, P 11 INT WORKSH DAT
NR 24
TC 1
Z9 1
U1 0
U2 1
PY 2021
BP 44
EP 51
DI 10.1109/H2RC54759.2021.00010
UT WOS:000788556900005
DA 2023-11-16
ER

PT C
AU Gonugondla, SK
   Sakr, C
   Dbouk, H
   Shanbhag, NR
AF Gonugondla, Sujan K.
   Sakr, Charbel
   Dbouk, Hassan
   Shanbhag, Naresh R.
GP IEEE
TI Fundamental Limits on the Precision of In-memory Architectures (Invited
   Talk)
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
DE in-memory computing; taxonomy of in-memory; in-memory noise; machine
   learning; accelerator; in-memory precision; in-memory accuracy; compute
   in-memory
ID MACRO
AB This paper obtains the fundamental limits on the computational precision of in-memory computing architectures (IMCs). Various compute SNR metrics for IMCs are defined and their interrelationships analyzed to show that the accuracy of IMCs is fundamentally limited by the compute SNR (SNRa) of its analog core, and that activation, weight and output precision needs to be assigned appropriately for the final output SNR SNRT -> SNRa. The minimum precision criterion (MPC) is proposed to minimize the output and hence the column analog-to-digital converter (ADC) precision. The charge summing (QS) compute model and its associated IMC QS-Arch are studied to obtain analytical models for its compute SNR, minimum ADC precision, energy and latency. Compute SNR models of QS-Arch are validated via Monte Carlo simulations in a 65 nm CMOS process. Employing these models, upper bounds on SNRa of a QS-Arch-based IMC employing a 512 row SRAM array are obtained and it is shown that QS-Arch's energy cost reduces by 3.3x for every 6 dB drop in SNRa, and that the maximum achievable SNRa reduces with technology scaling while the energy cost at the same SNRa increases. These models also indicate the existence of an upper bound on the dot product dimension N due to voltage headroom clipping, and this bound can be doubled for every 3 dB drop in SNRa.
C1 [Gonugondla, Sujan K.; Sakr, Charbel; Dbouk, Hassan; Shanbhag, Naresh R.] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
RP Gonugondla, SK (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
EM gonugon2@illinois.edu; sakr2@illinois.edu; hdbouk2@illinois.edu;
   shanbhag@illinois.edu
CR [Anonymous], 2018, ARXIV181104047
   [Anonymous], 2005, UNDERSTANDING DELTA
   [Anonymous], 2019, ADC PERFORMANCE SURV
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Cheng-Xin Xue, 2020, 2020 IEEE International Solid- State Circuits Conference - (ISSCC), P244, DOI 10.1109/ISSCC19947.2020.9063078
   Dbouk H., 2020, P IEEE CUST INT CIRC, P1
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Fick L, 2017, IEEE CUST INTEGR CIR
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/VLSIC.2019.8778028, 10.23919/vlsic.2019.8778028]
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   ITRS-collaborations, 2015, ITRS ROADM TABL
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang M., 2020, DEEP IN MEMORY ARCHI
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang Mingu, 2015, IEEE INT C AC SPEECH
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/vlsic.2019.8778160, 10.23919/VLSIC.2019.8778160]
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Murmann Boris, 2015, IEEE Solid-State Circuits Magazine, V7, P58, DOI 10.1109/MSSC.2015.2442393
   Murmann B, 2008, IEEE CUST INTEGR CIR, P105, DOI 10.1109/CICC.2008.4672032
   Okumura S, 2019, S VLSI TECH, pC248
   Rekhi AS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317770
   Sakr C., 2017, P INT C MACH LEAR, P3007
   Sakr C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1090, DOI 10.1109/ICASSP.2018.8461702
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Shanbhag NR, 2019, P IEEE, V107, P90, DOI 10.1109/JPROC.2018.2869867
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yue Jinshan, 2020, IEEE INT SOL STAT CI, P234
   Zha Y, 2019, SYMP VLSI CIRCUITS, pC206
   Zhang Jia, 2017, Zhongguo Kangshengsu Zazhi, V42, P915
NR 40
TC 0
Z9 0
U1 0
U2 1
PY 2020
DI 10.1145/3400302.3416344
UT WOS:000671087100159
DA 2023-11-16
ER

PT C
AU Ozen, E
   Orailoglu, A
AF Ozen, Elbruz
   Orailoglu, Alex
GP IEEE
TI Just Say Zero: Containing Critical Bit-Error Propagation in Deep Neural
   Networks With Anomalous Feature Suppression
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
DE fault tolerance; deep neural networks; robust machine learning
AB DNNs are abundantly employed in a variety of applications, including real-time systems with strict safety constraints. The consequences of errors prove disastrous in safety-critical systems, such as autonomous driving, healthcare, and industrial applications. DNNs are resilient to limited numerical perturbations yet fragile under large deviations in weights and activations. The traditional error tolerance measures fail to meet the tight design constraints of DNN processing systems due to extensive overheads or limited advantages in abundant error conditions. The algorithmic particularities of DNNs though create novel opportunities to deal with errors more effectively and economically. We revisit the two fundamental tasks in fault-tolerant system design, namely, error detection and correction, and demonstrate that the precise versions of these operations could be replaced by approximated counterparts in DNNs to deliver an extensive bit-error resilience even at high error rates while necessitating no information redundancy. We first maintain DNN accuracy even under extreme error rates by suppressing the numerical contributions of anomalous activations, eliminating any reliance on precise error correction. We tackle the problem of no redundancy error detection by establishing in training numerical associations among activations, and employing them for anomaly detection. Anomalous feature detection and suppression, performed efficiently at inference with minimal resources in a DNN accelerator, is shown to deliver significant resilience boosts while imposing neither information redundancy nor perceptible overheads.
C1 [Ozen, Elbruz; Orailoglu, Alex] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Ozen, E (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM elozen@eng.ucsd.edu; alex@cs.ucsd.edu
CR Baleani M., 2003, P INT C COMPILERS AR, P170
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Choi W, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317908
   dos Santos FF, 2019, IEEE T RELIAB, V68, P663, DOI 10.1109/TR.2018.2878387
   Ernst D, 2004, IEEE MICRO, V24, P10, DOI 10.1109/MM.2004.85
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Zhezhi, 2019, P 56 ANN DES AUT C D P 56 ANN DES AUT C D
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107, DOI DOI 10.5555/3157382.3157557
   Iandola F.N., 2016, CORR ABS160207360
   Jouppi Norman P., 2017, ISCA
   Klachko Michael, 2019, IEEE IJCNN
   Koren Israel, 2010, FAULTTOLERANT SYSTEM
   Krizhevsky Alex, 2022, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Liu Chenchen, 2017, P 54 ANN DES AUT C D P 54 ANN DES AUT C D
   Liu T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317742
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/date.2019.8715178, 10.23919/DATE.2019.8715178]
   Neggaz MA, 2018, PR IEEE COMP DESIGN, P476, DOI 10.1109/ICCD.2018.00077
   Ozen Elbruz, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P169, DOI 10.1109/ASP-DAC47756.2020.9045662
   Ozen E, 2019, ASIAN TEST SYMPOSIUM, P7, DOI 10.1109/ATS47505.2019.000-8
   Paszke A., 2019, P INT C NEUR INF PRO, P8026
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Reagen Brandon, 2018, P 55 ANN DES AUT C D P 55 ANN DES AUT C D
   Schorn C, 2018, LECT NOTES COMPUT SC, V11093, P205, DOI 10.1007/978-3-319-99130-6_14
   Schorn C, 2018, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE.2018.8342151
   Sharma H, 2016, INT SYMP MICROARCH
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang J, 2018, IEEE VLSI TEST SYMP
NR 34
TC 16
Z9 16
U1 0
U2 2
PY 2020
DI 10.1145/3400302.3415680
UT WOS:000671087100047
DA 2023-11-16
ER

PT J
AU Teng, SH
   Lu, M
   Yang, AF
   Zhang, J
   Nian, YJ
   He, M
AF Teng, Shu-Hua
   Lu, Min
   Yang, A-Feng
   Zhang, Jun
   Nian, Yongjian
   He, Mi
TI Efficient attribute reduction from the viewpoint of discernibility
SO INFORMATION SCIENCES
DT Article
DE Rough set; Discernibility viewpoint; Attribute reduction; Attribute
   significance
ID MATRIX SIMPLIFICATION; FEATURE-SELECTION; ROUGH; APPROXIMATION;
   ACCELERATOR; GRANULATION; MODEL
AB Attribute reduction is an important preprocessing step in pattern recognition, machine learning and data mining. As an effective method for attribute reduction, rough set theory offers a useful and formal methodology. It retains the discernibility power of the original datasets; thus, attribute reduction has been extensively studied in rough set theory. However, the inefficiency of the existing attribute reduction algorithms limits the application of rough sets. In this paper, we first analyse the limitations of existing attribute reduction algorithms. Then, a novel measure of attribute quality, called the relative discernibility degree, is proposed based on the discernibility. Theoretical analysis shows that this measure can find relative dispensable attributes and remain unchanged after removing the relative dispensable attributes and redundant objects in the process of selecting attributes. This property can be used to reduce the search space and accelerate the heuristic process of attribute reduction. Consequently, a new attribute reduction algorithm is proposed from the viewpoint of discernibility. Furthermore, the relationships among the reduction definitions of the algebra view, information view and discernibility view are derived. Some non-equivalent relationships among these views of rough set theory in inconsistent decision tables are discovered. A set of numerical experiments was conducted on UCI datasets. Experimental results show that the proposed algorithm is effective and efficient and is applicable to the case of large-scale datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Teng, Shu-Hua; Lu, Min; Yang, A-Feng; Zhang, Jun] Natl Univ Def Technol, Sci & Technol Automat Target Recognit Lab, Changsha 410073, Hunan, Peoples R China.
   [Nian, Yongjian; He, Mi] Third Mil Med Univ, Sch Biomed Engn, Chongqing 400038, Peoples R China.
RP He, M (corresponding author), Third Mil Med Univ, Sch Biomed Engn, Chongqing 400038, Peoples R China.
EM hmcherry@126.com
CR Chen DG, 2012, IEEE T KNOWL DATA EN, V24, P2080, DOI 10.1109/TKDE.2011.89
   Chen DG, 2012, IEEE T FUZZY SYST, V20, P385, DOI 10.1109/TFUZZ.2011.2173695
   Chouchoulas A, 2001, APPL ARTIF INTELL, V15, P843, DOI 10.1080/088395101753210773
   Deng TQ, 2012, PATTERN RECOGN LETT, V33, P1638, DOI 10.1016/j.patrec.2012.03.028
   Hu QH, 2008, KNOWL-BASED SYST, V21, P294, DOI 10.1016/j.knosys.2007.07.001
   Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017
   Hu QH, 2010, IEEE T SYST MAN CY B, V40, P137, DOI 10.1109/TSMCB.2009.2024166
   Hu XH, 2004, FUND INFORM, V59, P135
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6
   Jiang F, 2015, PATTERN RECOGN, V48, P2151, DOI 10.1016/j.patcog.2015.01.023
   Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3
   Lang GM, 2013, KNOWL INF SYST, V37, P611, DOI 10.1007/s10115-012-0589-3
   Li M, 2014, INFORM SCIENCES, V254, P155, DOI 10.1016/j.ins.2013.08.038
   Liang JY, 2013, KNOWL-BASED SYST, V44, P90, DOI 10.1016/j.knosys.2013.01.027
   Mac Parthaláin N, 2009, PATTERN RECOGN, V42, P655, DOI 10.1016/j.patcog.2008.08.029
   Meng ZQ, 2012, INFORM SCIENCES, V204, P44, DOI 10.1016/j.ins.2012.04.004
   Miao DQ, 2009, INFORM SCIENCES, V179, P4140, DOI 10.1016/j.ins.2009.08.020
   Pawlak Z., 1991, ROUGH SETS THEORETIC, V9
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pedrycz W, 2013, GRANULAR COMPUTING A
   Prasad PSVSS, 2009, LECT NOTES ARTIF INT, V5908, P152, DOI 10.1007/978-3-642-10646-0_18
   Qian J, 2011, INT J APPROX REASON, V52, P212, DOI 10.1016/j.ijar.2010.07.011
   Qian J, 2015, KNOWL-BASED SYST, V73, P18, DOI 10.1016/j.knosys.2014.09.001
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2011, PATTERN RECOGN, V44, P1658, DOI 10.1016/j.patcog.2011.02.020
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Skowron A., 1992, INTELLIGENT DECISION, P331, DOI DOI 10.1007/978-94-015-7975-9_21
   Susmaga R, 2004, FUND INFORM, V61, P159
   Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4
   Teng SH, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P471, DOI 10.1109/ICACC.2010.5486877
   Teng SH, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1189, DOI 10.1109/ROBIO.2009.5420845
   Tsang ECC, 2008, IEEE T FUZZY SYST, V16, P1130, DOI 10.1109/TFUZZ.2006.889960
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GY, 2012, FUND INFORM, V115, P219, DOI 10.3233/FI-2012-651
   Wang GY, 2005, FUND INFORM, V68, P289
   Wang GY, 2003, PROC SPIE, V5098, P103, DOI 10.1117/12.486854
   Xu Zhang-Yan, 2006, Chinese Journal of Computers, V29, P391
   Yamaguchi D, 2009, INT J APPROX REASON, V51, P89, DOI 10.1016/j.ijar.2009.08.002
   Yang T, 2013, INFORM SCIENCES, V228, P175, DOI 10.1016/j.ins.2012.11.005
   Yao YY, 2009, INFORM SCIENCES, V179, P867, DOI 10.1016/j.ins.2008.11.020
   Zhang WX, 2007, SCI CHINA SER F, V50, P188, DOI 10.1007/s11432-007-0017-6
   Zhao Y, 2007, INFORM SCIENCES, V177, P4959, DOI 10.1016/j.ins.2007.06.031
NR 43
TC 29
Z9 42
U1 1
U2 41
PD JAN 1
PY 2016
VL 326
BP 297
EP 314
DI 10.1016/j.ins.2015.07.052
UT WOS:000363348400021
DA 2023-11-16
ER

PT C
AU Bal, S
   Mummidi, CS
   Ferreira, VD
   Srinivasan, S
   Kundu, S
AF Bal, Sandeep
   Mummidi, Chandra Sekhar
   Ferreira, Victor da Cruz
   Srinivasan, Sudarshan
   Kundu, Sandip
BE IEEE
TI A Novel Fault-Tolerant Architecture for Tiled Matrix Multiplication
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE accelerator; matrix multiplication; abft; concurrent error detection;
   low power
AB General matrix multiplication (GEMM) is common to many scientific and machine-learning applications. Convolution, the dominant computation in Convolutional Neural Networks (CNNs), can be formulated as a GEMM problem. Due to its widespread use, a new generation of processors features GEMM acceleration in hardware. Intel recently announced an Advanced Matrix Multiplication (AMX (R)) instruction set for GEMM, which is supported by 1kB AMX registers and a Tile Multiplication unit (TMUL) for multiplying tiles (sub-matrices) in hardware. Silent Data Corruption (SDC) is a well-known problem that occurs when hardware generates corrupt output. Google and Meta recently reported findings of SDC in GEMM in their data centers. Algorithm-Based Fault Tolerance (ABFT) is an efficient mechanism for detecting and correcting errors in GEMM, but classic ABFT solutions are not optimized for hardware acceleration. In this paper, we present a novel ABFT implementation directly on hardware. Though the exact implementation of Intel TMUL is not known, we propose two different TMUL architectures representing two design points in the area-power-performance spectrum and illustrate how ABFT can be directly incorporated into the TMUL hardware. This approach has two advantages: (i) an error can be concurrently detected at the tile level, which is an improvement over finding such errors only after performing the full matrix multiplication; and (ii) we further demonstrate that performing ABFT at the hardware level has no performance impact and only a small area, latency, and power overhead.
C1 [Bal, Sandeep; Mummidi, Chandra Sekhar; Kundu, Sandip] Univ Massachusetts, Amherst, MA 01003 USA.
   [Ferreira, Victor da Cruz; Srinivasan, Sudarshan] Intel Corp, Bengaluru, India.
RP Bal, S (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.
CR Asgari B, 2020, ANN IEEE SYM FIELD P, P204, DOI 10.1109/FCCM48280.2020.00035
   Bosilca G, 2009, J PARALLEL DISTR COM, V69, P410, DOI 10.1016/j.jpdc.2008.12.002
   Dixit H. D., 2021, ARXIV
   Frangiotti M, 1995, PROCEEDINGS OF THE EIGHTH INTERNATIONAL KANT CONGRESS, VOL II, PT 1, SECT 1-9, P207, DOI 10.1109/DFTVS.1995.476954
   Georganas E, 2019, Arxiv, DOI arXiv:1906.06440
   Hari SKS, 2022, IEEE T DEPEND SECURE, V19, P2546, DOI 10.1109/TDSC.2021.3063083
   Hochschild P. H., 2021, P WORKSH HOT TOP OP, P9
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Intel, 2021, INT R ARCH INSTR SET
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Koomey JG, 2008, ENVIRON RES LETT, V3, DOI 10.1088/1748-9326/3/3/034008
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Naumov Maxim, 2020, DEEP LEARNING TRAINI
   Note F. W., 2016, BLISLAB SANDBOX OPTI
   Raschka S, 2020, INFORMATION, V11, DOI 10.3390/info11040193
   Roy-Chowdhury A., 1994, Digest of Papers. The Twenty-Fourth International Symposium on Fault-Tolerant Computing (Cat. No.94CH3441-3), P38, DOI 10.1109/FTCS.1994.315659
NR 16
TC 0
Z9 0
U1 0
U2 0
PY 2023
UT WOS:001027444200072
DA 2023-11-16
ER

PT J
AU Chatterjee, S
   Jagadeesan, M
   Qin, W
   Idreos, S
AF Chatterjee, Subarna
   Jagadeesan, Meena
   Qin, Wilson
   Idreos, Stratos
TI Cosine: A Cloud-Cost Optimized Self-Designing Key-Value Storage Engine
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article; Proceedings Paper
CT 48th International Conference on Very Large Data Bases (VLDB)
CY 2022
CL Sydney, AUSTRALIA
AB We present a self-designing key-value storage engine, Cosine, which can always take the shape of the close to "perfect" engine architecture given an input workload, a cloud budget, a target performance, and required cloud SLAs. By identifying and formalizing the first principles of storage engine layouts and core key-value algorithms, Cosine constructs a massive design space comprising of sextillion (1036) possible storage engine designs over a diverse space of hardware and cloud pricing policies for three cloud providers AWS, GCP, and Azure. Cosine spans across diverse designs such as Log-Structured Merge-trees, B-trees, Log-Structured Hash-tables, in-memory accelerators for filters and indexes as well as trillions of hybrid designs that do not appear in the literature or industry but emerge as valid combinations of the above. Cosine includes a unified distribution-aware I/O model and a learned concurrency-aware CPU model that with high accuracy can calculate the performance and cloud cost of any possible design on any workload and virtual machines. Cosine can then search through that space in a matter of seconds to find the best design and materializes the actual code of the resulting storage engine design using a templated Rust implementation. We demonstrate that on average Cosine outperforms state-of-the-art storage engines such as write-optimized RocksDB, read-optimized WiredTiger, and very write-optimized FASTER by 53x, 25x, and 20x, respectively, for diverse workloads, data sizes, and cloud budgets across all YCSB core workloads and many variants.
C1 [Chatterjee, Subarna; Jagadeesan, Meena; Qin, Wilson; Idreos, Stratos] Harvard Univ, Cambridge, MA 02138 USA.
RP Chatterjee, S (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM subarna@seas.harvard.edu; mjagadeesan@seas.harvard.edu;
   wilson@seas.harvard.edu; stratos@seas.harvard.edu
CR Amazon, 2020, CLOUD STOR
   Amdahl Gene M., 1967, PROC SPRING JOINT CO, P483, DOI [DOI 10.1145/1465482.1465560, 10.1145/1465482.1465560]
   [Anonymous], 2021, MUCH ARE STARTUPS SP
   [Anonymous], 2010, NSDI
   Apache, 2020, CASSANDRA
   Apache, 2020, HBASE
   Armstrong T. G., 2013, ACM SIGMOD, P1185, DOI DOI 10.1145/2463676.2465296
   AWS, 2019, CLOUDENDURE DIS REC
   AWS, 2019, PRIOR VERS AM EC2 SE
   AWS, 2019, WHAT IS DEVOPS
   AWS, 2019, AWS DAT MIGR SERV PR
   Azure, 2019, PRIC AZ DEVOPS
   Azure, 2019, AZ DAT MIGR SERV PRI
   Azure, 2019, AZ SIT REC PRIC
   Azure, 2019, SLA VIRT MACH
   Ball Nicholas, 2013, SKYL DYN WORKL AW DA
   Ballani H., 2011, PRICE IS RIGHT LOCAT
   Brazeal F, 2017, WHY AMAZON DYNAMODB
   Bruck J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P2304, DOI 10.1109/ISIT.2006.261978
   Bruno Nicolas, 2018, ENCY DATABASE SYSTEM
   Cao Zhao, 2013, P BIENN C INN DAT SY
   Chandramouli B, 2018, INT CONF MANAGE DATA, P275, DOI 10.1145/3183713.3196898
   Chaudhuri S., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P34, DOI 10.1145/275487.275492
   Cooney M, 2016, 10 BEST CLOUD SLA PR
   Cooper B. F., 2010, SOCC 10, P143, DOI DOI 10.1145/1807128.1807152
   Dai YF, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P155
   Das S, 2019, INT CONF MANAGE DATA, P666, DOI 10.1145/3299869.3314035
   Dayan N, 2018, ACM T DATABASE SYST, V43, DOI 10.1145/3276980
   Dayan N, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P79, DOI 10.1145/3035918.3064054
   DeCandia Giuseppe, 2007, Operating Systems Review, V41, P205, DOI 10.1145/1323293.1294281
   Ditto, 2022, ACCUBITS
   DSM, 2018, AWS AZ OFF CLOUD CON
   Nguyen DT, 2021, IEEE T CLOUD COMPUT, V9, P302, DOI 10.1109/TCC.2018.2844379
   Facebook, 2020, ROCKSDB
   Finkle V., 2015, HERES WHAT WE FOUND
   Fisk N, 2019, OP CLEAR MULT CONF
   GCP, 2019, GOOGL CLOUD FUNCT SE
   GCP, 2019, DEVOPS
   GCP, 2019, DIS REC PLANN GUID
   GCP, 2019, PRIC MIGR WORKL
   Graefe G, 2010, ACM T DATABASE SYST, V35, DOI 10.1145/1806907.1806908
   Gruneir Bram, 2017, SCALABLE SQL MADE EA
   Hein D, 2019, 5 THINGS LOOK CLOUD
   Hennessy JL., 2003, COMPUTER ARCHITECTUR
   Hill MD, 2008, COMPUTER, V41, P33, DOI 10.1109/MC.2008.209
   Hoy Darrell, 2016, P 12 INT C WEB INT E, P73
   Huang HY, 2021, INT CONF MANAGE DATA, P749, DOI 10.1145/3448016.3457297
   Huang KC, 2021, PROC INT CONF DATA, P612, DOI 10.1109/ICDE51399.2021.00059
   Idreos S., 2007, P BIENN C INN DAT SY
   Idreos S., 2019, CIDR
   Idreos S, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2667, DOI 10.1145/3318464.3383133
   Idreos S, 2019, INT CONF MANAGE DATA, P2054, DOI 10.1145/3299869.3314034
   Idreos S, 2018, INT CONF MANAGE DATA, P535, DOI 10.1145/3183713.3199671
   Idreos Stratos, 2021, VLDB
   Jain M. R, 2019, WHY WE CHOOSE BADGER
   Jain V, 2019, INT CONF MANAGE DATA, P1829, DOI 10.1145/3299869.3300097
   Karger D., 1997, P 29 ANN ACM S THEOR, V10, P654, DOI DOI 10.1145/258533.258660
   Kester MS, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P715, DOI 10.1145/3035918.3064049
   Kicinski A., 2019, ICEAA PROF DEV TRAIN
   Kraska T., 2019, BIENN C INN DAT SYST
   Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909
   Lahn M, 2019, MUCH DOES SERVER COS
   Liang JK, 2021, PROC INT CONF DATA, P1032, DOI 10.1109/ICDE51399.2021.00094
   Liao Y., 2020, PROC MACH LEARN SYST
   Lu LY, 2016, 14TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '16), P133
   Luo C, 2020, VLDB J, V29, P393, DOI 10.1007/s00778-019-00555-y
   Luo SQ, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2071, DOI 10.1145/3318464.3389731
   Lustiber Graham, 2017, P ACM SIGMOD INT C M, P13
   Malkowski P, 2018, MYROCKS DISK FULL ED
   Metafilter, 2010, CLOUD MIGHT RUN ME D
   Mogul JC, 2012, ACM SIGCOMM COMP COM, V42, P44, DOI 10.1145/2378956.2378964
   NordicBackup, 2018, 10 MIST COMP MAK CHO
   Oledzki W, 2013, MEMC IS WEIRD CREAT
   Padilha R., 2016, P USENIX ANN TECHN C
   Parlette C, 2018, 7 WAYS CLOUD SERVICE
   Pavlo Andrew, 2017, CIDR, V4
   Preez D. D, 2014, VIBER MIGRATES MONGO
   Ralph J, 2019, WHICH CLOUD IS BEST
   RapidValue, 2018, CHOOS AZ AWS GCP CLO
   Sarkar S, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P893, DOI 10.1145/3318464.3389757
   Sarkar Subhadeep, 2021, PROC VLDB ENDOW
   Selinger Patricia, 1979, P 1979 ACM SIGMOD IN, P23, DOI DOI 10.1145/582095.582099
   Sun W, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1887, DOI 10.1145/2723372.2723732
   Tan J, 2019, PROC VLDB ENDOW, V12, P1221, DOI 10.14778/3339490.3339503
   Tan Junjay, 2019, PVLDB, V12
   Taylor Twain, 2019, ORACLE CLOUD DIGS LO
   Tkatchuk R, 2017, CLOUD IS SO GREAT WH
   Van Aken D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1009, DOI 10.1145/3035918.3064029
   Vinçon T, 2020, PROC VLDB ENDOW, V13, P2981, DOI 10.14778/3415478.3415524
   Wang S, 2018, PROC VLDB ENDOW, V11, P1137, DOI 10.14778/3231751.3231762
   Wasay Abdul, 2021, MORE LESS BUILD CONV
   Wei XD, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P117
   Wei Z, 2012, IEEE T SERV COMPUT, V5, P525, DOI 10.1109/TSC.2011.18
   WIRED INSIDER, 2011, SERVICE LEVEL AGREEM
   WiredTiger, 2020, SOURCE CODE
   Wu CG, 2019, PROC VLDB ENDOW, V12, P624, DOI 10.14778/3311880.3311881
   Wu FG, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P603
   Yang Fan, 2021 IEEE 37 INT C D, P1020
   Zhang HC, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1601, DOI 10.1145/3318464.3380583
NR 99
TC 5
Z9 5
U1 0
U2 4
PD SEP
PY 2021
VL 15
IS 1
BP 112
EP 126
DI 10.14778/3485450.3485461
UT WOS:000742948400010
DA 2023-11-16
ER

PT C
AU Chen, Y
   He, J
   Zhang, XF
   Hao, C
   Chen, DM
AF Chen, Yao
   He, Jiong
   Zhang, Xiaofan
   Hao, Cong
   Chen, Deming
GP ACM
TI Cloud-DNN: An Open Framework for Mapping DNN Models to Cloud FPGAs
SO PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 24-26, 2019
CL Seaside, CA
DE DNN Accelerator; FPGA; High-Level Synthesis; Cloud Computing
AB The efficacy and effectiveness of Convolutional Neural Networks (CNNs) have been proven in a wide range of machine learning applications. However, the high computational complexity of CNNs presents a critical challenge towards their broader adoption in real-time and power-efficient scenarios. FPGAs are poised to take a significant role for high-performance and energy-efficient computation of CNNs for both mobile (e.g., UAVs, self-driving cars, and IoT devices) and cloud computing domains. However, implementing an effective CNN system onto FPGAs efficiently remains problematic. The current cloud-based FPGAs with unique design constraints and architectural characteristics further increase the challenges. To address these challenges, we propose a novel open-source automated tool chain called Cloud-DNN. Our tool chain takes trained CNN models specified in Caffe as input, performs a set of transformations, and maps the model to a cloud-based FPGA. Cloud-DNN can significantly improve the overall design productivity of CNNs on FPGAs while satisfying the emergent computational requirements. Our design provides an alternative solution compared to other cloud-based options (e.g., GPUs or TPUs) while offering flexible, and high performance DNN inferences. The unique features of Cloud-DNN include the optimizations with cloud-platform characteristics and the support of easier and streamlined implementation. Experimental results demonstrate up to 104.55x performance improvement when compared to CPU implementation and comparable usability, flexibility, and strong quality compared to other state-of-the-art DNN inference implementations on standalone FPGAs.
C1 [Chen, Yao; He, Jiong; Chen, Deming] Adv Digital Sci Ctr, Singapore, Singapore.
   [Zhang, Xiaofan; Hao, Cong; Chen, Deming] Univ Illinois, Champaign, IL USA.
RP Chen, Y (corresponding author), Adv Digital Sci Ctr, Singapore, Singapore.
EM yao.chen@adsc-create.edu.sg; Jiong.he@adsc-create.edu.sg;
   xiaofan3@illinois.edu; congh@illinois.edu; dchen@illinois.edu
CR [Anonymous], 2016, ESE EFFICIENT SPEECH
   Canis Andrew, 2011, P FPGA
   Chen DM, 2010, IEEE T VLSI SYST, V18, P564, DOI 10.1109/TVLSI.2009.2013353
   Del Sozzo Emanuele, 2016, P IPDPSW
   DiCecco Roberto, 2016, P FPT
   Guan Yijin, 2017, P FCCM
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Jia Yangqing, 2014, P ACMMM
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li Huimin, 2016, P FPL
   Liu Su, 2011, P SAAHPC
   Liu Xinheng, 2016, P FPGA
   Ma Yufei, 2017, PROF FPL
   Ma Yufei, 2017, P FPGA
   Qin Li, 2019, P ASP DAC
   Qiu J., 2016, P FPGA
   Rupnow Kyle, 2011, P FPT
   Sharma H, 2016, INT SYMP MICROARCH
   Shen Yongming, 2017, P ISCA
   Suda N., 2016, P FPGA
   Wang Junsong, 2018, P FPL
   Xilinx, 2012, LARG FPGA METH GUID
   Zhang C., 2016, P ICCAD, P1
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Jialiang, 2017, P FPGA
   Zhang Xiaofan, 2017, P ICCAD
   Zhang Xiaofan, 2017, P FPL
   Zhang Xiaofan, 2018, P ICCAD
NR 29
TC 67
Z9 67
U1 1
U2 8
PY 2019
BP 73
EP 82
DI 10.1145/3289602.3293915
UT WOS:000522383700009
DA 2023-11-16
ER

PT J
AU Nonlaopon, K
   Khan, MF
   Sulaiman, M
   Alshammari, FS
   Laouini, G
AF Nonlaopon, Kamsing
   Khan, Muhammad Fawad
   Sulaiman, Muhammad
   Alshammari, Fahad Sameer
   Laouini, Ghaylen
TI Analysis of MHD Falkner-Skan Boundary Layer Flow and Heat Transfer Due
   to Symmetric Dynamic Wedge: A Numerical Study via the SCA-SQP-ANN
   Technique
SO SYMMETRY-BASEL
DT Article
DE heat transfer; magnetic field; dynamic wedge; sine-cosine algorithm;
   nonlinear systems; dynamic parameters; sequential quadratic programming;
   machine learning; heuristics
ID SINE-COSINE ALGORITHM; POROUS-MEDIUM; ENTROPY GENERATION; STRETCHING
   SHEET; NANOFLUID FLOW; RADIATION; PLATE; FLUID
AB This article considers Falkner-Skan flow over a dynamic and symmetric wedge under the influence of a magnetic field. The Hall effect on a magnetic field is negligible for small magnetic Reynolds numbers. The magnetic field B(x) is considered over x-axis, which is in line with the wedge i.e., parallel, while the flow is transverse over the y-axis. This study has numerous device-centric applications in engineering, such as power generators, cooling reactor and heat exchanger design, and MHD accelerators. The Third and second-ordered ordinary differential equations characterize the system. A novel hybrid computational technique is designed for the surrogate solutions of the Falkner-Skan flow system. The designed technique is based on the sine-cosine optimization algorithm and sequential quadratic programming. Reference solutions are calculated by using the Runge-Kutta numerical technique. Performance matrices evaluate the accuracy and stability of our surrogate solutions, mean-absolute deviation (MAD), root-mean-square error (RMSE), and error in Nash--Sutcliffe efficiency (ENSE). Furthermore, graphical representations in terms of convergence graphs, mesh graphs, stem graphs, stairs plots, and boxplots are presented to establish the symmetry, reliability, and validity of our solutions.
C1 [Nonlaopon, Kamsing] Khon Kaen Univ, Fac Sci, Dept Math, Khon Kaen 40002, Thailand.
   [Khan, Muhammad Fawad; Sulaiman, Muhammad] Abdul Wali Khan Univ, Dept Math, Mardan 23200, Pakistan.
   [Alshammari, Fahad Sameer] Prince Sattam Bin Abdulaziz Univ, Coll Sci & Humanities Alkharj, Dept Math, Al Kharj 11942, Saudi Arabia.
   [Laouini, Ghaylen] Amer Univ Middle East, Coll Engn & Technol, Egaila 54200, Kuwait.
RP Sulaiman, M (corresponding author), Abdul Wali Khan Univ, Dept Math, Mardan 23200, Pakistan.
EM msulaiman@awkum.edu.pk
CR Abbas Z, 2006, THEOR COMP FLUID DYN, V20, P229, DOI 10.1007/s00162-006-0025-y
   Abbasbandy S, 2009, COMMUN NONLINEAR SCI, V14, P3591, DOI 10.1016/j.cnsns.2009.01.030
   Ali B., 2021, INT J ALGORITHM COMP, V7, P1
   Ali B, 2020, CHINESE J PHYS, V68, P368, DOI 10.1016/j.cjph.2020.09.026
   Ali L, 2022, CHINESE J PHYS, V77, P1963, DOI 10.1016/j.cjph.2021.12.008
   Anusha T, 2022, TRANSPORT POROUS MED, V142, P333, DOI 10.1007/s11242-021-01695-y
   Anusha T, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157527
   Attia AF, 2018, INT J ELEC POWER, V99, P331, DOI 10.1016/j.ijepes.2018.01.024
   Bararnia H, 2012, CURR SCI INDIA, V103, P169
   Bararnia H, 2012, ADV ENG SOFTW, V43, P44, DOI 10.1016/j.advengsoft.2011.08.005
   Bejan A., 1982, ADV HEAT TRANSFER, V15, P1, DOI [10.1016/S0065-2717(08)70172-2, DOI 10.1016/S0065-2717(08)70172-2]
   Berrehal H, 2019, J MECH SCI TECHNOL, V33, P2949, DOI 10.1007/s12206-019-0542-4
   Butt AS, 2013, INT J EXERGY, V13, P85, DOI 10.1504/IJEX.2013.055779
   Cui W, 2022, ENERGY REP, V8, P10203, DOI 10.1016/j.egyr.2022.07.178
   Cui W, 2022, J CLEAN PROD, V367, DOI 10.1016/j.jclepro.2022.133031
   Das C, 2013, SENSOR ACTUAT A-PHYS, V201, P43, DOI 10.1016/j.sna.2013.06.023
   Dasgupta K, 2020, ELECTR POW SYST RES, V178, DOI 10.1016/j.epsr.2019.106018
   Dehsara M, 2014, J MECH SCI TECHNOL, V28, P1819, DOI 10.1007/s12206-014-0329-6
   Elsaid E.M., 2022, RES SQ, DOI [10.21203/rs.3.rs-34729/v1, 10.21203/rs.3.rs-1591028/v1, DOI 10.21203/RS.3.RS-1591028/V1]
   Falkner VM, 1931, PHILOS MAG, V12, P865
   Khan MF, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/9660746
   Garia R, 2021, CHINESE J PHYS, V74, P421, DOI 10.1016/j.cjph.2021.10.030
   Goud BS, 2022, PROC I MECH ENG PART, DOI 10.1177/23977914221100961
   Guo ZG, 2022, ENERG CONVERS MANAGE, V257, DOI 10.1016/j.enconman.2022.115435
   Guo ZG, 2021, INT J HEAT MASS TRAN, V174, DOI 10.1016/j.ijheatmasstransfer.2021.121296
   Habib D, 2022, WAVE RANDOM COMPLEX, DOI 10.1080/17455030.2022.2088892
   Habib D, 2022, INT COMMUN HEAT MASS, V135, DOI 10.1016/j.icheatmasstransfer.2022.106141
   Hekimoglu B, 2019, T I MEAS CONTROL, V41, P1761, DOI 10.1177/0142331218811453
   Howarth L, 1938, PROC R SOC LON SER-A, V164, P0547, DOI 10.1098/rspa.1938.0037
   Huang KX, 2022, APPL THERM ENG, V204, DOI 10.1016/j.applthermaleng.2021.117942
   Huang W, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6639032
   Ishak A, 2009, MAGNETOHYDRODYNAMICS, V45, P103
   Johansen TA, 2004, IEEE T CONTR SYST T, V12, P211, DOI 10.1109/TCST.2003.821952
   Khan MF, 2022, IEEE ACCESS, V10, P34133, DOI 10.1109/ACCESS.2022.3159973
   Khan MF, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111513
   Khan MF, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111448
   Khan NA, 2021, PHYS FLUIDS, V33, DOI 10.1063/5.0042676
   Khazayinejad M, 2022, INT J THERM SCI, V172, DOI 10.1016/j.ijthermalsci.2021.107265
   Kudenatti RB, 2013, COMMUN NONLINEAR SCI, V18, P1151, DOI 10.1016/j.cnsns.2012.09.029
   Makinde OD, 2012, INT J EXERGY, V10, P142, DOI 10.1504/IJEX.2012.045862
   Marinca V, 2008, INT COMMUN HEAT MASS, V35, P710, DOI 10.1016/j.icheatmasstransfer.2008.02.010
   Mehmood A, 2020, NEURAL COMPUT APPL, V32, P10337, DOI 10.1007/s00521-019-04573-3
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili SM, 2020, NATURE INSPIRED OPTI, P201, DOI DOI 10.1007/978-3-030-12127-3_12
   Mukhopadhyay S, 2005, INT J HEAT MASS TRAN, V48, P4460, DOI 10.1016/j.ijheatmasstransfer.2005.05.027
   Qi H, 2016, OPT EXPRESS, V24, P24297, DOI 10.1364/OE.24.024297
   Rai P., 2022, J ADV RES FLUID MECH, V95, P120
   RamReddy C, 2022, P I MECH ENG E-J PRO, V236, P2558, DOI 10.1177/09544089221102404
   Sayyed SR, 2018, APPL MATH COMPUT, V321, P472, DOI 10.1016/j.amc.2017.10.062
   Siddique I, 2022, ARAB J SCI ENG, DOI 10.1007/s13369-022-07129-1
   Sindhu R, 2017, NEURAL COMPUT APPL, V28, P2947, DOI 10.1007/s00521-017-2837-7
   Suid MH., 2019, INDONES J ELECT ENG, V16, P101, DOI 10.11591/ijeecs.v16.i1.pp101-106
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xia C, 2023, INT J ENGINE RES, V24, P1327, DOI 10.1177/14680874221084052
   Yacob NA, 2011, INT COMMUN HEAT MASS, V38, P149, DOI 10.1016/j.icheatmasstransfer.2010.12.003
   Yaseen M, 2022, J HEAT TRANS-T ASME, V144, DOI 10.1115/1.4055046
   Yazdi MH, 2012, ENTROPY-SWITZ, V14, P1, DOI 10.3390/e14010001
   Zhao MQ, 2020, ENERGIES, V13, DOI 10.3390/en13010215
NR 58
TC 3
Z9 3
U1 3
U2 6
PD OCT
PY 2022
VL 14
IS 10
AR 2180
DI 10.3390/sym14102180
UT WOS:000873592700001
DA 2023-11-16
ER

PT J
AU Mohammadirad, M
   Sojodishijani, O
AF Mohammadirad, Majid
   Sojodishijani, Omid
TI Improving the efficiency of DNN hardware accelerator by replacing
   digital feature extractor with an imprecise neuromorphic hardware
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
DT Article
DE Artificial neural networks; memristor; in-memory computation;
   convolutional neural networks; imprecise computation; fault tolerance
AB Mixed-signal in-memory computation can drastically improve the efficiency of the hardware implementing machine learning (ML) algorithms by (i) removing the need to fetch neural network parameters from internal or external memory and (ii) performing a large number of multiply-accumulate operations in parallel. However, this boost in efficiency comes with some disadvantages. Among them, the inability to precisely program nonvolatile memory devices (NVM) with neural network parameters and sensitivity to noise prevent the mixed-signal hardware to perform a precise and deterministic computation. Unfortunately, these hardware-specific errors can get magnified while propagating along with the layers of the deep neural network. In this paper, we show that the inability to implement parameters of the already trained network with enough precision can completely stop the network from performing any meaningful operation. However, even at this level of degradation, the feature extractor section of the network still extracts enough information from which an acceptable level of performance can be achieved by just retraining the last classification layers of the network. Our results suggest that instead of just blindly trying to implement software algorithms in hardware as precisely as possible, it might be more efficient to implement neural networks with imperfect devices and circuits and let the network itself compensate for these imprecise computations by only retraining few layers.
C1 [Mohammadirad, Majid; Sojodishijani, Omid] Islamic Azad Univ, Dept Comp Engn, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
RP Sojodishijani, O (corresponding author), Islamic Azad Univ, Dept Comp Engn, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
EM o_sojoodi@qiau.ac.ir
CR Bayat FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04482-4
   Bayat FM, 2017, ICCAD-IEEE ACM INT, P549, DOI 10.1109/ICCAD.2017.8203825
   Bojarski Mariusz, 2016, arXiv
   Fouda M.E., 2015, MATH MODELING MEMRIS
   Gibney E, 2016, NATURE, V529, P445, DOI 10.1038/529445a
   Han S., 2016, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1510.00149
   Hannun A., 2014, ARXIV14125567, P1
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Hubara I, 2018, J MACH LEARN RES, V18
   Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073
   Jayakumar H, 2016, ASIA S PACIF DES AUT, P298, DOI 10.1109/ASPDAC.2016.7428027
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Merrikh-Bayat F, 2018, IEEE T NEUR NET LEAR, V29, P4782, DOI 10.1109/TNNLS.2017.2778940
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   WANG XB, 2017, PROC CVPR IEEE, P1, DOI DOI 10.1109/IEDM.2017.8268341
   Williams RS, 2013, CHAOS, CNN, MEMRISTORS AND BEYOND: A FESTSCHRIFT FOR LEON CHUA, P483
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2020
VL 28
IS 5
BP 2797
EP 2807
DI 10.3906/elk-1911-77
UT WOS:000576682500012
DA 2023-11-16
ER

PT J
AU Schuiki, F
   Schaffner, M
   Gürkaynak, FK
   Benini, L
AF Schuiki, Fabian
   Schaffner, Michael
   Gurkaynak, Frank K.
   Benini, Luca
TI A Scalable Near-Memory Architecture for Training Deep Neural Networks on
   Large In-Memory Datasets
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Parallel architectures; memory structures; memory hierarchy; machine
   learning; neural nets
ID POWER
AB Most investigations into near-memory hardware accelerators for deep neural networks have primarily focused on inference, while the potential of accelerating training has received relatively little attention so far. Based on an in-depth analysis of the key computational patterns in state-of-the-art gradient-based training methods, we propose an efficient near-memory acceleration engine called NTX that can be used to train state-of-the-art deep convolutional neural networks at scale. Our main contributions are: (i) a loose coupling of RISC-V cores and NTX co-processors reducing offloading overhead by 7 x over previously published results; (ii) an optimized IEEE 754 compliant data path for fast high-precision convolutions and gradient propagation; (iii) evaluation of near-memory computing with NTX embedded into residual area on the Logic Base die of a Hybrid Memory Cube; and (iv) a scaling analysis to meshes of HMCs in a data center scenario. We demonstrate a 2.7 x energy efficiency improvement of NTX over contemporary GPUs at 4.4 x less silicon area, and a compute performance of 1.2 Tflop/s for training large state-of-the-art networks with full floating-point precision. At the data center scale, a mesh of NTX achieves above 95 percent parallel and energy efficiency, while providing 2.1 x energy savings or 3.1 x performance improvement over a GPU-based system.
C1 [Schuiki, Fabian; Schaffner, Michael] Swiss Fed Inst Technol, D ITET, CH-8092 Zurich, Switzerland.
   [Gurkaynak, Frank K.] Swiss Fed Inst Technol, Microelect Design Ctr, CH-8092 Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, Scuola Ingn & Architettura, Dipartimento Elettron Informat & Sistemist, I-40126 Bologna, Emilia Romagna, Italy.
RP Schuiki, F (corresponding author), Swiss Fed Inst Technol, D ITET, CH-8092 Zurich, Switzerland.
EM fschuiki@iis.ee.ethz.ch; schaffner@iis.ee.ethz.ch; kgf@ee.ethz.ch;
   lbenini@iis.ee.ethz.ch
CR Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, CNN BENCHMARKS
   [Anonymous], 2014, MEASURING DDR4 POWER
   [Anonymous], ARXIV170309039CSCV
   [Anonymous], HOTCHIPS AUG
   [Anonymous], 301342 ISOIEC
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2017, TENSORFLOW BENCHMARK
   [Anonymous], ART INT ARCH
   [Anonymous], 2014, 2 WORKSH NEAR DAT PR
   [Anonymous], 2015, HYBRID MEMORY CUBE S
   [Anonymous], 2017, P 22 INT C ARCHITECT
   [Anonymous], AV PRIC EL ULT CUST
   [Anonymous], 2016, ARXIV160205629CSLG
   [Anonymous], ARXIV160401946CSLG
   [Anonymous], ARXIV150102876CSCV
   [Anonymous], 2017, DEEP LEARNING BENCHM
   [Anonymous], IEDM 2013 PREVIEW
   [Anonymous], 53 DES AUT C AUST TX
   Azarkhish Erfan, 2018, IEEE Transactions on Parallel and Distributed Systems, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Azarkhish Erfan, 2016, Architecture of Computing Systems - ARCS 2016. 29th International Conference. Proceedings: LNCS 9637, P19, DOI 10.1007/978-3-319-30695-7_2
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Gao J, 2014, MACHINE LEARNING APP
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hong S, 2010, CONF PROC INT SYMP C, P280, DOI 10.1145/1816038.1815998
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Koster U., 2017, ADV NEURAL INFORM PR, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Simunic T, 2001, DES AUT CON, P524, DOI 10.1109/DAC.2001.935564
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wen Wei, 2016, ADV NEURAL INFORM PR, P2074
   Zhang C., 2016, PROC IEEEACM INT C C, P1
NR 41
TC 35
Z9 36
U1 3
U2 22
PD APR
PY 2019
VL 68
IS 4
BP 484
EP 497
DI 10.1109/TC.2018.2876312
UT WOS:000461236900002
DA 2023-11-16
ER

PT J
AU da Rosa, MMA
   Paim, G
   da Costa, PUL
   da Costa, EAC
   Soares, RI
   Bampi, S
AF Azevedo da Rosa, Morgana Macedo
   Paim, Guilherme
   Leleu da Costa, Patricia Ucker
   Cesar da Costa, Eduardo Antonio
   Soares, Rafael, I
   Bampi, Sergio
TI AxPPA: Approximate Parallel Prefix Adders
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Adders; Approximate adders (AxA); approximate computing (AxC);
   energy-efficient operators; parallel prefix adders (PPAs)
ID DESIGN; HARDWARE; COMPRESSORS; ALGORITHM
AB Addition units are widely used in many computational kernels of several error-tolerant applications such as machine learning and signal, image, and video processing. Besides their use as stand-alone, additions are essential building blocks for other math operations such as subtraction, comparison, multiplication, squaring, and division. The parallel prefix adders (PPAs) is among the fastest adders. It represents a parallel prefix graph consisting of the carry operator nodes, called prefix operators (POs). The PPAs, in particular, are among the fastest adders because they optimize the parallelization of the carry generation ( $G$ ) and propagation ( $P$ ). In this work, we introduce approximate PPAs (AxPPAs) by exploiting approximations in the POs. To evaluate our proposal for approximate POs (AxPOs), we generate the following AxPPAs, consisting of a set of four PPAs: approximate Brent-Kung (AxPPA-BK), approximate Kogge-Stone (AxPPA-KS), Ladner-Fischer (AxPPA-LF), and Sklansky (AxPPA-SK). We compare four AxPPA architectures with energy-efficient approximate adders (AxAs) i.e., Copy, error-tolerant adder I (ETAI), lower-part or adder (LOA), and Truncation (trunc). We tested them generically in stand-alone cases and embedded them in two important signal processing application kernels: a sum of squared differences (SSDs) video accelerator and a finite impulse response (FIR) filter kernel. The AxPPA-LF provides a new Pareto front in both energy-quality and area-quality results compared to state-of-the-art energy-efficient AxAs.
C1 [Azevedo da Rosa, Morgana Macedo; Soares, Rafael, I] Univ Fed Pelotas UFPel, Dept Comp Sci, BR-96010610 Pelotas, RS, Brazil.
   [Paim, Guilherme; Leleu da Costa, Patricia Ucker; Bampi, Sergio] Univ Fed Rio Grande Sul UFRGS, Dept Microelect, BR-90010150 Porto Alegre, RS, Brazil.
   [Cesar da Costa, Eduardo Antonio] Univ Catolica Pelotas UCPel, Dept Elect & Comp, BR-96015560 Pelotas, RS, Brazil.
RP Soares, RI (corresponding author), Univ Fed Pelotas UFPel, Dept Comp Sci, BR-96010610 Pelotas, RS, Brazil.
EM mmarosa@inf.ufpel.edu.br; gppaim@ieee.org; eduardo.costa@ucpel.edu.br
CR Aksoy L, 2010, MICROPROCESS MICROSY, V34, P151, DOI 10.1016/j.micpro.2009.10.001
   Alhazmi B, 2019, IEEE ACCESS, V7, P58704, DOI 10.1109/ACCESS.2019.2914641
   Arya N, 2021, IEEE T VLSI SYST, V29, P1994, DOI 10.1109/TVLSI.2021.3114616
   Bossen F, 2013, JCTVCL1100
   BRENT RP, 1982, IEEE T COMPUT, V31, P260, DOI 10.1109/TC.1982.1675982
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   da Costa P., 2022, 2022 IEEE 13 LATIN A, P1
   da Rosa M. M. A., 2020, 2020 27 IEEE INT C E, P1
   da Rosa M. M. A., 2022, PROC IEEE INT S CIRC, P1
   Daphni S., 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P103, DOI 10.1109/ICCS1.2017.8325971
   Du K, 2012, DES AUT TEST EUROPE, P1257
   Ene TD, 2021, PR IEEE COMP DESIGN, P125, DOI 10.1109/ICCD53106.2021.00030
   Esposito D, 2018, IEEE T CIRCUITS-I, V65, P4169, DOI 10.1109/TCSI.2018.2839266
   Esposito D, 2016, IEEE T CIRCUITS-I, V63, P1200, DOI 10.1109/TCSI.2016.2564699
   Esposito D, 2015, IEEE T CIRCUITS-I, V62, P1353, DOI 10.1109/TCSI.2015.2403036
   Guidotti V, 2020, CIRC SYST SIGNAL PR, V39, P5729, DOI 10.1007/s00034-020-01431-9
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hisham MB, 2015, IEEE ST CONF RES DEV, P100, DOI 10.1109/SCORED.2015.7449303
   HM, 2017, HEVC TEST MODEL HM 1
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P313, DOI 10.1109/TCSI.2018.2856513
   Kahng AB, 2012, DES AUT CON, P820
   Kim Y, 2013, ICCAD-IEEE ACM INT, P130, DOI 10.1109/ICCAD.2013.6691108
   KOGGE PM, 1973, IEEE T COMPUT, VC-22, P786, DOI 10.1109/TC.1973.5009159
   LADNER RE, 1980, J ACM, V27, P831, DOI 10.1145/322217.322232
   Lee J, 2021, IEEE ACCESS, V9, P119939, DOI 10.1109/ACCESS.2021.3108443
   Liu WQ, 2018, IEEE T CIRCUITS-I, V65, P2856, DOI 10.1109/TCSI.2018.2792902
   Lu SL, 2004, COMPUTER, V37, P67, DOI 10.1109/MC.2004.1274006
   Ma YZ, 2019, IEEE T COMPUT AID D, V38, P2298, DOI 10.1109/TCAD.2018.2878129
   Macedo M, 2017, IEEE I C ELECT CIRC, P298, DOI 10.1109/ICECS.2017.8292078
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Reddy KM, 2020, IEEE T VLSI SYST, V28, P1230, DOI 10.1109/TVLSI.2020.2976131
   Mazahir S., 2016, PROC 53 ACM EDAC IEE, P1
   Miao J, 2012, ICCAD-IEEE ACM INT, P728
   Ning Zhu, 2010, Proceedings 2010 International SoC Design Conference (ISOCC 2010), P323, DOI 10.1109/SOCDC.2010.5682905
   Paim G, 2022, IEEE T CIRC SYST VID, V32, P398, DOI 10.1109/TCSVT.2021.3059229
   Paim G, 2021, IEEE T CIRCUITS-I, V68, P1481, DOI 10.1109/TCSI.2021.3058451
   Paim G, 2020, IEEE T CIRC SYST VID, V30, P3814, DOI 10.1109/TCSVT.2019.2945763
   Paim G, 2019, IEEE T CIRCUITS-I, V66, P680, DOI 10.1109/TCSI.2018.2868513
   Paim G, 2017, IEEE I C ELECT CIRC, P482, DOI 10.1109/ICECS.2017.8292070
   Paim G, 2017, 2017 30TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN (SBCCI 2017): CHOP ON SANDS, P168, DOI 10.1145/3109984.3110021
   Paim G, 2016, IEEE I C ELECT CIRC, P261, DOI 10.1109/ICECS.2016.7841182
   Pashaeifar M, 2019, IEEE T CIRCUITS-I, V66, P327, DOI 10.1109/TCSI.2018.2856757
   Pereira P.M., 2021, 2021 TEL C CONFTELE, P1
   Pereira PTL, 2022, IEEE T CIRCUITS-I, V69, P4524, DOI 10.1109/TCSI.2022.3191180
   Pudi V, 2017, IEEE T COMPUT, V66, P1824, DOI 10.1109/TC.2017.2696524
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Roy Rajarshi, 2021, 2021 58th ACM/IEEE Design Automation Conference (DAC), P853, DOI 10.1109/DAC18074.2021.9586094
   Roy S, 2013, DES AUT CON
   Seidel HB, 2021, IEEE T CIRCUITS-I, V68, P1814, DOI 10.1109/TCSI.2021.3057584
   Seidel I, 2016, IEEE LAT AMER SYMP, P327, DOI 10.1109/LASCAS.2016.7451076
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Sklansky J., 1960, IRE EC, V9, P226, DOI DOI 10.1109/TEC.1960.5219822
   Soares L. B., 2015, P IEEE INT NEW CIRCU, P1, DOI DOI 10.1109/NEWCAS.2015.7182095
   Soares LB, 2020, CIRC SYST SIGNAL PR, V39, P6098, DOI 10.1007/s00034-020-01448-0
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Strollo AGM, 2020, IEEE T CIRCUITS-I, V67, P3021, DOI 10.1109/TCSI.2020.2988353
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Tsai KL, 2021, IEEE T CIRCUITS-I, V68, P3328, DOI 10.1109/TCSI.2021.3085572
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Verma AK, 2008, DES AUT TEST EUROPE, P1092
   Weste N.H., 2015, CMOS VLSI DESIGN CIR
   Ye R, 2013, ICCAD-IEEE ACM INT, P48, DOI 10.1109/ICCAD.2013.6691096
   Zhu N, 2009, PROCEEDINGS OF THE 2009 12TH INTERNATIONAL SYMPOSIUM ON INTEGRATED CIRCUITS (ISIC 2009), P400
   Zhu N, 2010, IEEE T VLSI SYST, V18, P1225, DOI 10.1109/TVLSI.2009.2020591
NR 67
TC 5
Z9 5
U1 1
U2 4
PD JAN
PY 2023
VL 31
IS 1
BP 17
EP 28
DI 10.1109/TVLSI.2022.3218021
EA NOV 2022
UT WOS:000890863000001
DA 2023-11-16
ER

PT C
AU Lee, Y
   Choi, H
   Min, S
   Lee, H
   Beak, S
   Jeong, D
   Lee, JW
   Ham, TJ
AF Lee, Yejin
   Choi, Hyunji
   Min, Sunhong
   Lee, Hyunseung
   Beak, Sangwon
   Jeong, Dawoon
   Lee, Jae W.
   Ham, Tae Jun
GP IEEE Comp Soc
TI ANNA: Specialized Architecture for Approximate Nearest Neighbor Search
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE Similarity Search; Hardware Accelerator; Approximate Nearest Neighbor
   Search; Product Quantization
AB Similarity search or nearest neighbor search is a task of retrieving a set of vectors in the (vector) database that are most similar to the provided query vector. It has been a key kernel for many applications for a long time. However, it is becoming especially more important in recent days as modern neural networks and machine learning models represent the semantics of images, videos, and documents as high-dimensional vectors called embeddings. Finding a set of similar embeddings for the provided query embedding is now the critical operation for modern recommender systems and semantic search engines. Since exhaustively searching for the most similar vectors out of billion vectors is such a prohibitive task, approximate nearest neighbor search (ANNS) is often utilized in many real-world use cases. Unfortunately, we find that utilizing the server-class CPUs and GPUs for the ANNS task leads to suboptimal performance and energy efficiency. To address such limitations, we propose a specialized architecture named ANNA (Approximate Nearest Neighbor search Accelerator), which is compatible with state-of-the-art ANNS algorithms such as Google ScaNN and Facebook Faiss. By combining the benefits of a specialized dataflow pipeline and efficient data reuse, ANNA achieves multiple orders of magnitude higher energy efficiency, 2.3-61.6x higher throughput, and 4.3-82.1x lower latency than the conventional CPU or GPU for both million- and billion-scale datasets.
C1 [Lee, Yejin; Choi, Hyunji; Min, Sunhong; Lee, Hyunseung; Beak, Sangwon; Jeong, Dawoon; Lee, Jae W.; Ham, Tae Jun] Seoul Natl Univ, Seoul, South Korea.
RP Lee, Y (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM yejinlee@snu.ac.kr; hyunjichoi@snu.ac.kr; sunhongmin@snu.ac.kr;
   hs_lee@snu.ac.kr; bsw1907@gmail.com; daun20211@snu.ac.kr;
   jaewlee@snu.ac.kr; ham.taejun@gmail.com
CR Abdelhadi AMS, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P90, DOI 10.1109/ICFPT47387.2019.00019
   Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Barz B, 2019, IEEE WINT CONF APPL, P638, DOI 10.1109/WACV.2019.00073
   berkeley.edu, ABT US
   Bhagwan R., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P538, DOI 10.1109/INFCOM.2000.832227
   Cer D, 2018, Arxiv, DOI arXiv:1803.11175
   Chen QW, 2019, 1ST INTERNATIONAL WORKSHOP ON DEEP LEARNING PRACTICE FOR HIGH-DIMENSIONAL SPARSE DATA WITH KDD (DLP-KDD 2019), DOI 10.1145/3326937.3341261
   Chen W, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107002
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Danopoulos D, 2019, 2019 14TH INTERNATIONAL SYMPOSIUM ON RECONFIGURABLE COMMUNICATION-CENTRIC SYSTEMS-ON-CHIP (RECOSOC 2019), P59, DOI 10.1109/ReCoSoC48741.2019.9034938
   Datar M., 2004, P 20 ANN S COMP GEOM, P253
   Dong Y., 2021, IEEE INTERNET THINGS, P1
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   github, ANNOY
   github.com, KGRAPH LIB APPR NEAR
   github.com, NEIGHBORHOOD GRAPH T
   github.com, 2018, SPTAG LIB FAST APPRO
   github.com, FALCONN FAST LOOKUPS
   github.com, BENCHMARKING NEAREST
   github.com, FAISS
   gsitechnology.com, GEM APU EN HIGH PERF
   Guo RQ, 2020, PR MACH LEARN RES, V119
   Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616
   Hyv”nen V, 2016, Arxiv, DOI arXiv:1509.06957
   Iwasaki M, 2016, LECT NOTES COMPUT SC, V9939, P20, DOI 10.1007/978-3-319-46759-7_2
   Jégou H, 2011, INT CONF ACOUST SPEE, P861
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Klein B, 2019, PROC CVPR IEEE, P5036, DOI 10.1109/CVPR.2019.00518
   Lu A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P139, DOI 10.1109/ICFPT51103.2020.00027
   Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473
   Matsui Y, 2018, ITE TRANS MEDIA TECH, V6, P2, DOI 10.3169/mta.6.2
   Matsumoto T, 2015, IEEE DATA MINING, P320, DOI 10.1109/ICDM.2015.125
   microsoft.com, BING VECTOR SEARCH
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muthusundari S, 2021, ANN ROMANIAN SOC CEL, V25, P2602
   Naumov Maxim, 2019, ARXIV
   Nvidia, NVIDIA VIS PROF
   nvidia. com, 2020, NVIDIA V100 TENS COR
   nvidia.com, NVIDIA MERLIN
   nvidia.com, NVIDIA NSIGHT SYSTEM
   Pennington J., 2014, P 2014 C EMP METH NA, V14, P1532, DOI 10.3115/v1/D14-1162
   Pu YL, 2015, ANN IEEE SYM FIELD P, P167, DOI 10.1109/FCCM.2015.7
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Shrivastava A, 2014, Arxiv, DOI arXiv:1405.5869
   Sun H, 2020, IEEE T CIRCUITS-II, V67, P1644, DOI 10.1109/TCSII.2020.3013758
   Wang RX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1785, DOI 10.1145/3442381.3450078
   wikichip.org, LCC SOC SKYLAKE SERV
   Xu TC, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P629, DOI 10.1145/3352460.3358259
   yandex.com, BENCHMARKS BILLION S
   Zhan JT, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2487, DOI 10.1145/3459637.3482358
   Zhang JL, 2018, PROC CVPR IEEE, P4924, DOI 10.1109/CVPR.2018.00517
   Zhao WJ, 2020, PROC INT CONF DATA, P1033, DOI 10.1109/ICDE48307.2020.00094
NR 56
TC 0
Z9 0
U1 1
U2 5
PY 2022
BP 169
EP 183
DI 10.1109/HPCA53966.2022.00021
UT WOS:000838704300013
DA 2023-11-16
ER

PT C
AU Khoram, S
   Zhang, JL
   Strange, M
   Li, J
AF Khoram, Soroosh
   Zhang, Jialiang
   Strange, Maxwell
   Li, Jing
GP ACM
TI Accelerating Graph Analytics by Co-Optimizing Storage and Access on an
   FPGA-HMC Platform
SO PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 25-27, 2018
CL Monterey, CA
DE Graph Analytics; Graph Clustering; Hybrid Memory Cube; Reconfigurable
   Logic; Hardware Accelerators
ID ALGORITHM
AB Graph analytics, which explores the relationships among interconnected entities, is becoming increasingly important due to its broad applicability, from machine learning to social sciences. However, due to the irregular data access patterns in graph computations, one major challenge for graph processing systems is performance. The algorithms, softwares, and hardwares that have been tailored for mainstream parallel applications are generally not effective for massive, sparse graphs from the real-world problems, due to their complex and irregular structures.
   To address the performance issues in large-scale graph analytics, we leverage the exceptional random access performance of the emerging Hybrid Memory Cube (HMC) combined with the flexibility and efficiency of modern FPGAs. In particular, we develop a collaborative software/hardware technique to perform a level-synchronized Breadth First Search (BFS) on a FPGA-HMC platform. From the software perspective, we develop an architecture-aware graph clustering algorithm that exploits the FPGA-HMC platform's capability to improve data locality and memory access efficiency. From the hardware perspective, we further improve the FPGA-HMC graph processor architecture by designing a memory request merging unit to take advantage of the increased data locality resulting from graph clustering. We evaluate the performance of our BFS implementation using the AC-510 development kit from Micron and achieve 2.8x average performance improvement compared to the latest FPGA-HMC based graph processing system over a set of benchmarks from a wide range of applications.
C1 [Khoram, Soroosh; Zhang, Jialiang; Strange, Maxwell; Li, Jing] Univ Wisconsin, Dept Elect & Comp Engn, Madison, WI 53706 USA.
RP Khoram, S (corresponding author), Univ Wisconsin, Dept Elect & Comp Engn, Madison, WI 53706 USA.
EM khoram@wisc.edu; jialiang.zhang@ece.wisc.edu; mbstrange@wisc.edu;
   jli@ece.wisc.edu
CR Bader GD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-2
   Beamer S, 2012, INT CONF HIGH PERFOR
   Blatt M, 1996, PHYS REV LETT, V76, P3251, DOI 10.1103/PhysRevLett.76.3251
   Brandes U, 2003, LECT NOTES COMPUT SC, V2832, P568
   Brohée S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-488
   Dai GH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P105, DOI 10.1145/2847263.2847339
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Felzenszwalb PF, 2011, IEEE T PATTERN ANAL, V33, P721, DOI 10.1109/TPAMI.2010.135
   Gjoka M, 2010, IEEE INFOCOM SER, DOI 10.1109/infcom.2010.5462078
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   King AD, 2004, BIOINFORMATICS, V20, P3013, DOI 10.1093/bioinformatics/bth351
   Koyutürk M, 2004, BIOINFORMATICS, V20, P200, DOI 10.1093/bioinformatics/bth919
   Lee BC, 2010, COMMUN ACM, V53, P99, DOI 10.1145/1785414.1785441
   Lei Guoqing, 2015, ENG SCI TECHNOLOGY I, V5, P313
   Locke Kyle, 2011, PARAMETERIZABLE CONT
   Merrill D, 2012, ACM SIGPLAN NOTICES, V47, P117, DOI 10.1145/2370036.2145832
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Picocomputing, ULTR BAS SUPERPROCES
   Picocomputing, HYBR MEM CUB HMC CON
   Rosenfeld P., 2014, PERFORMANCE EXPLORAT
   Umuroglu Yaman, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293939
   Van Dongen S. M., 2000, GRAPH CLUSTERING FLO
   Wang YZH, 2015, ACM SIGPLAN NOTICES, V50, P265, DOI [10.1145/2688500.2688538, 10.1145/2858788.2688538]
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P207, DOI 10.1145/3020078.3021737
NR 24
TC 21
Z9 24
U1 0
U2 0
PY 2018
BP 239
EP 248
DI 10.1145/3174243.3174260
UT WOS:000788508500026
DA 2023-11-16
ER

PT J
AU Ambrogio, S
   Narayanan, P
   Tsai, HY
   Shelby, RM
   Boybat, I
   di Nolfo, C
   Sidler, S
   Giordano, M
   Bodini, M
   Farinha, NCP
   Killeen, B
   Cheng, C
   Jaoudi, Y
   Burr, GW
AF Ambrogio, Stefano
   Narayanan, Pritish
   Tsai, Hsinyu
   Shelby, Robert M.
   Boybat, Irem
   di Nolfo, Carmelo
   Sidler, Severin
   Giordano, Massimo
   Bodini, Martina
   Farinha, Nathan C. P.
   Killeen, Benjamin
   Cheng, Christina
   Jaoudi, Yassine
   Burr, Geoffrey W.
TI Equivalent-accuracy accelerated neural-network training using analogue
   memory
SO NATURE
DT Article
ID SYNAPSES; DEVICES
AB Neural-network training can be slow and energy intensive, owing to the need to transfer the weight data for the network between conventional digital memory chips and processor chips. Analogue non-volatile memory can accelerate the neural-network training algorithm known as backpropagation by performing parallelized multiply-accumulate operations in the analogue domain at the location of the weight data. However, the classification accuracies of such in situ training using non-volatile-memory hardware have generally been less than those of software-based training, owing to insufficient dynamic range and excessive weight-update asymmetry. Here we demonstrate mixed hardware-software neural-network implementations that involve up to 204,900 synapses and that combine long-term storage in phase-change memory, near-linear updates of volatile capacitors and weight-data transfer with 'polarity inversion' to cancel out inherent device-to-device variations. We achieve generalization accuracies (on previously unseen data) equivalent to those of software-based training on various commonly used machine-learning test datasets (MNIST, MNIST-backrand, CIFAR-10 and CIFAR-100). The computational energy efficiency of 28,065 billion operations per second per watt and throughput per area of 3.6 trillion operations per second per square millimetre that we calculate for our implementation exceed those of today's graphical processing units by two orders of magnitude. This work provides a path towards hardware accelerators that are both fast and energy efficient, particularly on fully connected neural-network layers.
C1 [Ambrogio, Stefano; Narayanan, Pritish; Tsai, Hsinyu; Shelby, Robert M.; di Nolfo, Carmelo; Sidler, Severin; Giordano, Massimo; Bodini, Martina; Farinha, Nathan C. P.; Killeen, Benjamin; Cheng, Christina; Jaoudi, Yassine; Burr, Geoffrey W.] IBM Res Almaden, San Jose, CA 95120 USA.
   [Boybat, Irem] IBM Res Zurich, Ruschlikon, Switzerland.
   [Boybat, Irem; di Nolfo, Carmelo; Sidler, Severin; Bodini, Martina] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
RP Burr, GW (corresponding author), IBM Res Almaden, San Jose, CA 95120 USA.
EM gwburr@us.ibm.com
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Andrew, 2013, P 30 INT C MACH LEAR, P1337
   [Anonymous], 2017, PREPRINT
   [Anonymous], 2015 IEEE INT EL DEV
   [Anonymous], 2017 S VLSI TECHN T1
   [Anonymous], WCCFTECH
   [Anonymous], 2015, DEEP LEARNING, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 1997, NEURAL COMPUT, DOI 10.1162/neco.1997.9.8.1735
   [Anonymous], 2014, PREPRINT
   [Anonymous], 2016, PREPRINT
   [Anonymous], 2014 IEEE INT EL DEV
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2009, ACMSIGDA NEWSLETTER
   [Anonymous], 2009, LEARNING MULTIPLE LA
   Bengio Yoshua, 2009, PROC INT C MACH LEAR, P41, DOI DOI 10.1145/1553374.1553380
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Gao LG, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/45/455204
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Ielmini D, 2007, IEEE T ELECTRON DEV, V54, P308, DOI 10.1109/TED.2006.888752
   Jang JW, 2015, IEEE ELECTR DEVICE L, V36, P457, DOI 10.1109/LED.2015.2418342
   Jeong Y, 2015, APPL PHYS LETT, V107, DOI 10.1063/1.4934818
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaneko Y, 2014, IEEE T ELECTRON DEV, V61, P2827, DOI 10.1109/TED.2014.2331707
   Kim S, 2017, MIDWEST SYMP CIRCUIT, P422, DOI 10.1109/MWSCAS.2017.8052950
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   MORIE T, 1994, IEEE J SOLID-ST CIRC, V29, P1086, DOI 10.1109/4.309904
   Narayanan P, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2716579
   Narayanan P., 2017, 2017 IEEE INT S CIRC, P1
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Papandreou N, 2011, IEEE INT SYMP CIRC S, P329
   PELGROM MJM, 1989, IEEE J SOLID-ST CIRC, V24, P1433, DOI 10.1109/JSSC.1989.572629
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/NMAT4856, 10.1038/nmat4856]
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
NR 44
TC 643
Z9 658
U1 14
U2 288
PD JUN 7
PY 2018
VL 558
IS 7708
BP 60
EP +
DI 10.1038/s41586-018-0180-5
UT WOS:000434273300037
HC Y
HP N
DA 2023-11-16
ER

PT J
AU Borbon, JMR
   Huang, JJ
   Wong, BM
   Najjar, W
AF Borbon, Jose M. Rodriguez
   Huang, Junjie
   Wong, Bryan M.
   Najjar, Walid
TI Acceleration of Parallel-Blocked QR Decomposition of Tall-and-Skinny
   Matrices on FPGAs
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE QR decomposition; accelerators; FPGA; reconfigurable computing
AB QR decomposition is one of the most useful factorization kernels in modern numerical linear algebra algorithms. In particular, the decomposition of tall-and-skinny matrices (TSMs) has major applications in scientific computing, machine learning, image processing, wireless networks, and numerical methods. Traditionally, CPUs and GPUs have achieved better throughput on these applications by using large cache hierarchies and compute cores running at a high frequency, leading to high power consumption. With the advent of heterogeneous platforms, however, FPGAs are emerging as a promising viable alternative. In this work, we propose a high-throughput FPGA-based engine that has a very high computational efficiency (ratio of achieved to peak throughput) compared to similar QR solvers running on FPGAs. Although comparable QR solvers achieve an efficiency of 36%, our design exhibits an efficiency of 54%. For TSMs, our experimental results show that our design can outperform highly optimized QR solvers running on CPUs and CPUs. For TSMs with more than 50K rows, our design outperforms the Intel MKL solver running on an Intel quad-core processor by a factor of 1.5x. For TSMs containing 256 columns or less, our design outperforms the NVIDIA CUBLAS solver running on a K40 GPU by a factor of 3.0x. In addition to being fast, our design is energy efficient-competing platforms execute up to 0.6 GFLOPS/Joule, whereas our design executes more than 1.0 GFLOPS/Joule.
C1 [Borbon, Jose M. Rodriguez; Huang, Junjie; Najjar, Walid] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
   [Wong, Bryan M.] Univ Calif Riverside, Dept Chem & Environm Engn, Riverside, CA 92521 USA.
RP Borbon, JMR (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
EM jrodr050@ucr.edu; jhuan308@ucr.edu; bryan.wong@ucr.edu;
   najjar@cs.ucr.edu
CR Agullo E., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P932, DOI 10.1109/IPDPS.2011.90
   Anderson M., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P48, DOI 10.1109/IPDPS.2011.15
   [Anonymous], 2016, PROGRAMMING MASSIVEL
   [Anonymous], 2011, MAPREDUCE 11 P 2 INT, DOI DOI 10.1145/1996092.1996103
   [Anonymous], 2004, FPGA 04 P 2004 ACMSI
   [Anonymous], 2009, P 2 WORKSHOP GEN PUR
   Aslan S, 2012, MIDWEST SYMP CIRCUIT, P470, DOI 10.1109/MWSCAS.2012.6292059
   Benson AR, 2013, IEEE INT CONF BIG DA
   BISCHOF C, 1987, SIAM J SCI STAT COMP, V8, pS2, DOI 10.1137/0908009
   Boonpoonga A, 2010, LECT NOTES COMPUT SC, V5992, P394, DOI 10.1007/978-3-642-12133-3_39
   Burtscher M, P WORKSHOP GEN PURPO, P28, DOI [10.1145/2588768.2576783, DOI 10.1145/2576779.2576783]
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chauhan Abha, 2014, 2014 International Conference on Electronic Systems, Signal Processing and Computing Technologies (ICESC), P69, DOI 10.1109/ICESC.2014.20
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Cong J, 2018, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2018.00023
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [DOI 10.1145/1735688.1735702, 10.1145, 10.1145/1735688.1735702]
   Demmel J, 2012, SIAM J SCI COMPUT, V34, pA206, DOI 10.1137/080731992
   Dongarra J, 2000, COMPUT SCI ENG, V2, P22, DOI 10.1109/MCISE.2000.814652
   Dua D., 2017, UCI MACHINE LEARNING
   Feist Tom, 2012, WP416 XIL
   Gerards M, 2009, PROCEEDINGS OF THE 2009 12TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN, ARCHITECTURES, METHODS AND TOOLS, P287, DOI 10.1109/DSD.2009.141
   Golub G. H., 1996, MATRIX COMPUTATIONS
   Hadri B, 2010, 2010 IEEE INT S PAR, P1, DOI [10.1109/IPDPS.2010.5470443, DOI 10.1109/IPDPS.2010.5470443]
   Hill Tom, 2009, WP357 XIL
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   HOUSEHOLDER AS, 1958, J ACM, V5, P339, DOI 10.1145/320941.320947
   Kahn G., 1974, IFIP 74 N HOLLAND, P471
   Langhammer M, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P183, DOI 10.1145/3174243.3174273
   Micron, 2020, MICR SB 852 WOLV 2
   Micron, 2018, CONV PDK REF MAN
   Muñoz SD, 2015, IEEE T CIRCUITS-II, V62, P861, DOI 10.1109/TCSII.2015.2435753
   NVIDIA, 2018, CUBLAS NVIDIAS DENS
   NVIDIA, 2018, CUDA TOOLK DOC
   NVIDIA, 2019, NVML API REF
   Ofenbeck G, 2014, INT SYM PERFORM ANAL, P76, DOI 10.1109/ISPASS.2014.6844463
   Omran Safaa S., 2018, 2018 International Conference on Advanced Science and Engineering (ICOASE), P189, DOI 10.1109/ICOASE.2018.8548895
   Parker M, 2016, PROC NAECON IEEE NAT, P416, DOI 10.1109/NAECON.2016.7856841
   Rafique A., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P443, DOI 10.1109/FPL.2012.6339142
   Rodríguez-Borbón JM, 2020, J CHEM THEORY COMPUT, V16, P2085, DOI 10.1021/acs.jctc.9b01284
   Sergyienko A, 2002, LECT NOTES COMPUT SC, V2328, P458
   Shannon L, 2015, ANN IEEE SYM FIELD P, P1, DOI 10.1109/FCCM.2015.11
   Sirowy S., 2008, WHERES BEEF WHY FPGA
   Stewart GW, 2000, COMPUT SCI ENG, V2, P50, DOI 10.1109/5992.814658
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
   Trefethen L. N., 1997, NUMERICAL LINEAR ALG
   Treibig J., 2010, 2010 39th International Conference on Parallel Processing Workshops (ICPPW), P207, DOI 10.1109/ICPPW.2010.38
   Wang E., 2014, INTEL MATH KERNEL LI
   Wang Q, 2014, INT J APPL CERAM TEC, V11, P911, DOI 10.1111/ijac.12065
   Wang XJ, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596535
   Watkins D. S., 2004, FUNDAMENTALS MATRIX
   Xinying Wang, 2014, 2014 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P541, DOI 10.1109/ISVLSI.2014.92
   Yi-Gang Tai, 2011, 2011 International Conference on Field Programmable Logic and Applications, P464, DOI 10.1109/FPL.2011.91
   Zhuo L, 2007, IEEE T PARALL DISTR, V18, P1377, DOI 10.1109/TPDS.2007.1068
NR 53
TC 0
Z9 0
U1 0
U2 3
PD JUN
PY 2021
VL 18
IS 3
AR 27
DI 10.1145/3447775
UT WOS:000668433900003
DA 2023-11-16
ER

PT J
AU Qin, ZD
   Zhu, D
   Zhu, XW
   Chen, X
   Shi, YH
   Gao, Y
   Lu, ZH
   Shen, QH
   Li, L
   Pan, HB
AF Qin, Zidi
   Zhu, Di
   Zhu, Xingwei
   Chen, Xuan
   Shi, Yinghuan
   Gao, Yang
   Lu, Zhonghai
   Shen, Qinghong
   Li, Li
   Pan, Hongbing
TI Accelerating Deep Neural Networks by Combining Block-Circulant Matrices
   and Low-Precision Weights
SO ELECTRONICS
DT Article
DE hardware acceleration; deep neural networks (DNNs); fully-connected
   layers; network compression; VLSI
ID EXTREME LEARNING-MACHINE
AB As a key ingredient of deep neural networks (DNNs), fully-connected (FC) layers are widely used in various artificial intelligence applications. However, there are many parameters in FC layers, so the efficient process of FC layers is restricted by memory bandwidth. In this paper, we propose a compression approach combining block-circulant matrix-based weight representation and power-of-two quantization. Applying block-circulant matrices in FC layers can reduce the storage complexity from <mml:semantics>O(k2)</mml:semantics> to <mml:semantics>O(k)</mml:semantics>. By quantizing the weights into integer powers of two, the multiplications in the reference can be replaced by shift and add operations. The memory usages of models for MNIST, CIFAR-10 and ImageNet can be compressed by <mml:semantics>171x</mml:semantics>, <mml:semantics>2731x</mml:semantics> and <mml:semantics>128x</mml:semantics> with minimal accuracy loss, respectively. A configurable parallel hardware architecture is then proposed for processing the compressed FC layers efficiently. Without multipliers, a block matrix-vector multiplication module (B-MV) is used as the computing kernel. The architecture is flexible to support FC layers of various compression ratios with small footprint. Simultaneously, the memory access can be significantly reduced by using the configurable architecture. Measurement results show that the accelerator has a processing power of 409.6 GOPS, and achieves 5.3 TOPS/W energy efficiency at 800 MHz.
C1 [Qin, Zidi; Zhu, Di; Zhu, Xingwei; Chen, Xuan; Shen, Qinghong; Li, Li; Pan, Hongbing] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
   [Shi, Yinghuan; Gao, Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Lu, Zhonghai] KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, S-11428 Stockholm, Sweden.
RP Pan, HB (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
EM qinzidi@smail.nju.edu.cn; zhudi@smail.nju.edu.cn; flzs@smail.nju.edu.cn;
   cx0705@smail.nju.edu.cn; syh@nju.edu.cn; gaoy@nju.edu.cn;
   zhonghai@kth.se; qhshen@nju.edu.cn; lili@nju.edu.cn; phb@nju.edu.cn
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2017, ICCAD-IEEE ACM INT
   [Anonymous], 2015, INT C NEUR INF PROC
   Cheng Y., 2015, ARXIV150203436
   Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327
   Choi Y., 2016, P INT C LEARN REPR S
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Dominguez-Sanchez A, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110301
   Han S., 2016, P INT C LEARN REPR S
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu XF, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7060078
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mirza B, 2016, PROC ADAPT LEARN OPT, V6, P39, DOI 10.1007/978-3-319-28397-5_4
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Nguyen TV, 2017, NEUROCOMPUTING, V260, P123, DOI 10.1016/j.neucom.2017.04.007
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Simonyan K., 2015, ARXIV
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tang ZL, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7070122
   TEIXEIRA M, 1995, IEEE SIGNAL PROC LET, V2, P92, DOI 10.1109/97.386287
   Teixeira M, 2008, IEEE T SIGNAL PROCES, V56, P2755, DOI 10.1109/TSP.2008.917375
   Wang XQ, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110302
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Wang ZS, 2017, IEEE T VLSI SYST, V25, P2763, DOI 10.1109/TVLSI.2017.2717950
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Zhao L., 2017, CORR
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
NR 31
TC 3
Z9 4
U1 0
U2 5
PD JAN
PY 2019
VL 8
IS 1
AR 78
DI 10.3390/electronics8010078
UT WOS:000457142800078
DA 2023-11-16
ER

PT C
AU Tri, N
   Becchi, M
AF Tri Nguyen
   Becchi, Michela
GP IEEE
TI A GPU-accelerated Data Transformation Framework Rooted in Pushdown
   Transducers
SO 2022 IEEE 29TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS, HIPC
SE International Conference on High Performance Computing
DT Proceedings Paper
CT 29th Annual IEEE International Conference on High Performance Computing,
   Data, and Analytics (HiPC)
CY DEC 18-21, 2022
CL Bangalore, INDIA
DE Finite state transducers; Pushdown transducers; Data transformation; GPU
   acceleration
ID FINITE-STATE TRANSDUCERS; ARCHITECTURE; EFFICIENT
AB With the rise of machine learning and data analytics, the ability to process large and diverse sets of data efficiently has become crucial. Research has shown that data transformation is a key performance bottleneck for applications across a variety of domains, from data analytics to scientific computing. Custom hardware accelerators and GPU implementations targeting specific data transformation tasks can alleviate the problem, but suffer from narrow applicability and lack of generality.
   To tackle this problem, we propose a GPU-accelerated data transformation engine grounded on pushdown transducers. We define an extended pushdown transducer abstraction (effPDT) that allows expressing a wide range of data transformations in a memory-efficient fashion, and is thus amenable for GPU deployment. The effPDT execution engine utilizes a data streaming model that reduces the application's memory requirements significantly, facilitating deployment on high- and low-end systems. We showcase our GPU-accelerated engine on a diverse set of transformation tasks covering data encoding/decoding, parsing and querying of structured data, and matrix transformation, and we evaluate it against publicly available CPU and GPU library implementations of the considered data transformation tasks. To understand the benefits of the effPDT abstraction, we extend our data transformation engine to also support finite state transducers (FSTs), we map the considered data transformation tasks on FSTs, and we compare the performance and resource requirements of the FST-based and the effPDT-based implementations.
C1 [Tri Nguyen; Becchi, Michela] NC State Univ, Raleigh, NC 27606 USA.
RP Tri, N (corresponding author), NC State Univ, Raleigh, NC 27606 USA.
EM tmnguye7@ncsu.edu; mbecchi@ncsu.edu
CR A. Parquet, US
   Alur R, 2020, THEOR COMPUT SCI, V807, P15, DOI 10.1016/j.tcs.2019.11.018
   [Anonymous], PAND
   [Anonymous], CUD TOOLK
   [Anonymous], GNU SCI LIB
   [Anonymous], OP GPU DAT SCI
   [Anonymous], CANT COR
   [Anonymous], RAL OP DAT
   [Anonymous], INT MKL
   Becchi M., 2008, P 4 ACM IEEE S ARCH, P50, DOI DOI 10.1145/1477942.1477950
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Brodie BC, 2006, CONF PROC INT SYMP C, P191, DOI 10.1145/1150019.1136500
   Das T., 2012, PROC 9 USENIX S NETW, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Filiot E, 2018, J COMPUT SYST SCI, V97, P147, DOI 10.1016/j.jcss.2018.05.002
   Ghemawat S., 2003, SOSP, P29, DOI 10.1145/1165389.945450
   Grathwohl BB, 2016, ACM SIGPLAN NOTICES, V51, P284, DOI 10.1145/2914770.2837647
   Kanev S, 2016, IEEE MICRO, V36, P54, DOI 10.1109/MM.2016.38
   Khairoutdinov MF, 2001, GEOPHYS RES LETT, V28, P3617, DOI 10.1029/2001GL013552
   Kourtis K, 2011, ACM SIGPLAN NOTICES, V46, P247, DOI 10.1145/2038037.1941587
   Langr D, 2016, IEEE T PARALL DISTR, V27, P428, DOI 10.1109/TPDS.2015.2401575
   Liu HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P908, DOI [10.1109/MICRO.2018.00078, 10.1109/MICR0.2018.00078]
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Meduna A., 2000, AUTOMATA LANGUAGES T
   Mitra A., 2007, PROC 2007 ACMIEEE S, P127
   Mohri M, 1997, COMPUT LINGUIST, V23, P269
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   Moon SK, 2019, MULTIMED TOOLS APPL, V78, P22045, DOI 10.1007/s11042-019-7503-x
   Nishtala Rajesh, 2013, P 10 USENIX S NETW S, P385
   Ousterhout Kay, 2015, 12 USENIX S NETW SYS, P293
   Page L., 1999, WEB C, DOI DOI 10.1007/978-3-319-08789-4_10
   Papadimitriou C. H, 1994, COMPLEXITY THEORY
   Qiu JQ, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P887, DOI 10.1145/3445814.3446705
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Safieh M, 2019, IET CIRC DEVICE SYST, V13, P576, DOI 10.1049/iet-cds.2018.5017
   Sidhu R., 2001, 9 ANN IEEE S FIELD P, P227, DOI [10.1109/FCCM.2001.22, DOI 10.1109/FCCM.2001.22]
   Stuedi P., 2014, ACM S CLOUD COMP NOV, P1, DOI [DOI 10.1145/2670979.2670994, 10.1145/2670979.2670994]
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Sugimoto T, 2017, IEEE T BROADCAST, V63, P426, DOI 10.1109/TBC.2017.2687699
   T. A. University, SUIT MATR COLL
   van Lunteren J, 2012, INT SYMP MICROARCH, P461, DOI 10.1109/MICRO.2012.49
   Veanes M, 2012, POPL 12: PROCEEDINGS OF THE 39TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P137
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wang H, 2019, IEEE T VLSI SYST, V27, P2423, DOI 10.1109/TVLSI.2019.2921249
   Yu X., 2013, P ACM INT C COMPUTIN, DOI [10.1145/2482767.2482791, DOI 10.1145/2482767.2482791]
   Zhang Y, 2010, ACM SIGCOMM COMP COM, V40, P20, DOI 10.1145/1880153.1880157
   Zhao Y, 2018, ACM SIGPLAN NOTICES, V53, P94, DOI 10.1145/3200691.3178495
   Zhao ZJ, 2015, ACM SIGPLAN NOTICES, V50, P619, DOI [10.1145/2694344.2694369, 10.1145/2775054.2694369]
   Zu Y, 2012, ACM SIGPLAN NOTICES, V47, P129, DOI 10.1145/2370036.2145833
NR 51
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 215
EP 225
DI 10.1109/HiPC56025.2022.00038
UT WOS:000990551500025
DA 2023-11-16
ER

PT C
AU Liu, G
   Primmer, J
   Zhang, ZR
AF Liu, Gai
   Primmer, Joseph
   Zhang, Zhiru
GP ACM
TI Rapid Generation of High-Quality RISC-V Processors from Functional
   Instruction Set Specifications
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
AB The increasing popularity of compute acceleration for emerging domains such as artificial intelligence and computer vision has led to the growing need for domain-specific accelerators, often implemented as specialized processors that execute a set of domain-optimized instructions. The ability to rapidly explore (1) various possibilities of the customized instruction set, and (2) its corresponding micro-architectural features is critical to achieve the best quality-of-results (QoRs). However, this ability is frequently hindered by the manual design process at the register transfer level (RTL). Such an RTL-based methodology is often expensive and slow to react when the design specifications change at the instruction-set level and/or micro-architectural level.
   We address this deficiency in domain-specific processor design with ASSIST, a behavior-level synthesis framework for RISC-V processors. From an untimed functional instruction set description, ASSIST generates a spectrum of RISC-V processors implementing varying micro-architectural design choices, which enables effective tradeoffs between different QoR metrics. We demonstrate the automatic synthesis of more than 60 in-order processor implementations with varying pipeline structures from the RISC-V 32I instruction set, some of which dominate the manually optimized counterparts in the area-performance Pareto frontier. In addition, we propose an autotuning-based approach for optimizing the implementations under a given performance constraint and the technology target. We further present case studies of synthesizing various custom instruction extensions and customized instruction sets for cryptography and machine learning applications.
C1 [Liu, Gai; Primmer, Joseph; Zhang, Zhiru] Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14850 USA.
   [Liu, Gai] Xilinx Inc, San Jose, CA 95124 USA.
RP Liu, G (corresponding author), Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14850 USA.; Liu, G (corresponding author), Xilinx Inc, San Jose, CA 95124 USA.
EM gai.liu@xilinx.com; jp2228@cornell.edu; zhiruz@cornell.edu
CR [Anonymous], 2017, VIVADO DESIGN SUITE
   [Anonymous], 2017, INT S COMP ARCH ISCA
   [Anonymous], 2014, INT S COMP ARCH ISCA
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Arvind R. S. Nikhil, 2004, INT C COMP AID DES I
   Asanovic K., 2014, UCBEECS2014146 EECS
   Borkar S, 2011, COMMUN ACM, V54, P67, DOI 10.1145/1941487.1941507
   Buchty R., 2004, INT C ARCH COMP SYST
   Celio C, SODOR PROCESSOR COLL
   Choudhary N. K., 2011, INT S COMP ARCH ISCA
   Cong J., 2014, DESIGN AUTOMATION C
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dreesen R., 2012, INT C HARDW SOFTW CO
   Gonzalez RE, 2000, IEEE MICRO, V20, P60, DOI 10.1109/40.848473
   Hara Y., 2008, INT S CIRC SYST ISCA
   LEISERSON CE, 1991, ALGORITHMICA, V6, P5, DOI 10.1007/BF01759032
   Mishra P., 2004, ACM T DES AUTOMAT EL, V11, P626
   Mokhov A, 2014, IEEE T COMPUT, V63, P1551, DOI 10.1109/TC.2013.37
   Nurvitadhi E, 2011, IEEE T COMPUT AID D, V30, P441, DOI 10.1109/TCAD.2010.2088950
   Schliebusch O., 2002, AS S PAC DES AUT C A
   Zhu Q., 2018, U.S. Patent, Patent No. 9965824
NR 21
TC 2
Z9 2
U1 0
U2 1
PY 2019
DI 10.1145/3316781.3317890
UT WOS:000482058200122
DA 2023-11-16
ER

PT C
AU Kybaniec, R
   Przygoda, K
   Ayvazyan, V
   Branlard, J
   Butkowski, L
   Cichalewski, W
   Pfeiffer, S
   Schmidt, C
   Schlarb, H
   Sekutowicz, J
AF Kybaniec, Radoslaw
   Przygoda, Konrad
   Ayvazyan, Valeri
   Branlard, Julien
   Butkowski, Lukasz
   Cichalewski, Wojciech
   Pfeiffer, Sven
   Schmidt, Christian
   Schlarb, Holger
   Sekutowicz, Jacek
GP IEEE
TI FPGA Based RF and Piezo Controllers for SRF Cavities in CW Mode
SO 2016 IEEE-NPSS REAL TIME CONFERENCE (RT)
DT Proceedings Paper
CT IEEE-NPSS Real Time Conference (RT)
CY JUN 06-10, 2016
CL ITALY
AB Modern digital low level radio frequency (LLRF) control systems used to stabilize the accelerating field in facilities such as Free Electron Laser in Hamburg (FLASH) or European X-Ray Free Electron Laser (E-XFEL) are based on the Field Programmable Gate Array (FPGA) technology. Presently these accelerator facilities are operated with pulsed RF. In future, these facilities should be operated with continuous wave (CW) which requires significant modifications on the real-time feedbacks realized within the FPGA. For example, higher loaded quality factor of the cavities when operated in a CW mode requires sophisticated resonance control methods. However, iterative learning techniques widely used for machines operated in pulsed mode are not applicable for CW. In addition, the mechanical characteristic of the cavities have now a much more important impact on the choice of the feedback scheme. To overcome the limitations of classical PI-controllers novel real-time adaptive feed forward algorithm is implemented in the FPGA. Also, the high power RF amplifier which is an inductive output tube (IOT) for continuous wave operation instead of a klystron for the pulsed mode has major impact on the design and implementation of the firmware for regulation. In this paper, we report on our successful approach to control multi-cavities with ultra-high precision (dA/A<0.01%, dphi<0.02 deg) using a single IOT source and individual resonance control through piezo actuators. Performance measurements of the proposed solution were conducted at Cryo Module Test Bench (CMTB) facility.
C1 [Kybaniec, Radoslaw] Warsaw Univ Technol, PL-00661 Warsaw, Poland.
   [Przygoda, Konrad; Ayvazyan, Valeri; Branlard, Julien; Butkowski, Lukasz; Pfeiffer, Sven; Schmidt, Christian; Schlarb, Holger; Sekutowicz, Jacek] Deutsch Elektronen Synchrotron DESY, D-22607 Hamburg, Germany.
   [Cichalewski, Wojciech] Lodz Univ Technol TUL, PL-90924 Lodz, Poland.
RP Kybaniec, R (corresponding author), Warsaw Univ Technol, PL-00661 Warsaw, Poland.
EM rrybanie@mion.elka.pw.edu.pl
CR Kuo SM, 1999, P IEEE, V87, P943, DOI 10.1109/5.763310
   Przygoda K., 2011, THESIS
   Rutkowski I., 2015, IEEE T NUCL SCI
   Rutkowski I, 2013, IEEE T NUCL SCI, V60, P3609, DOI 10.1109/TNS.2013.2278372
   Rybaniec R., 2014, P 5 INT PART ACC C
   Schilcher T., 1998, THESIS
   Sekutowicz J, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.050701
   [No title captured]
NR 8
TC 0
Z9 0
U1 0
U2 1
PY 2016
UT WOS:000389775600042
DA 2023-11-16
ER

PT C
AU Abdolrashidi, A
   Wang, LS
   Agrawal, S
   Malmaud, J
   Rybakov, O
   Leichner, C
   Lew, L
AF Abdolrashidi, AmirAli
   Wang, Lisa
   Agrawal, Shivani
   Malmaud, Jonathan
   Rybakov, Oleg
   Leichner, Chas
   Lew, Lukasz
GP IEEE Comp Soc
TI Pareto-Optimal Quantized ResNet Is Mostly 4-bit
SO 2021 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   WORKSHOPS, CVPRW 2021
SE IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops
DT Proceedings Paper
CT IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 19-25, 2021
CL ELECTR NETWORK
AB Quantization has become a popular technique to compress neural networks and reduce compute cost, but most prior work focuses on studying quantization without changing the network size. Many real-world applications of neural networks have compute cost and memory budgets, which can be traded off with model quality by changing the number of parameters. In this work, we use ResNet as a case study to systematically investigate the effects of quantization on inference compute cost-quality tradeoff curves. Our results suggest that for each bfloat16 ResNet model, there are quantized models with lower cost and higher accuracy; in other words, the bfloat16 compute cost-quality tradeoff curve is Pareto-dominated by the 4-bit and 8-bit curves, with models primarily quantized to 4-bit yielding the best Pareto curve. Furthermore, we achieve state-of-the-art results on ImageNet for 4-bit ResNet-50 with quantization-aware training, obtaining a top-1 eval accuracy of 77.09%. We demonstrate the regularizing effect of quantization by measuring the generalization gap. The quantization method we used is optimized for practicality: It requires little tuning and is designed with hardware capabilities in mind. Our work motivates further research into optimal numeric formats for quantization, as well as the development of machine learning accelerators supporting these formats. As part of this work, we contribute a quantization library written in JAX, which is open-sourced at https://github.com/google-research/google-research/tree/master/aqt.
C1 [Abdolrashidi, AmirAli] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Wang, Lisa; Agrawal, Shivani; Malmaud, Jonathan; Rybakov, Oleg; Leichner, Chas; Lew, Lukasz] Google Res, Mountain View, CA 94043 USA.
RP Wang, LS; Lew, L (corresponding author), Google Res, Mountain View, CA 94043 USA.
EM amirali.abdolrashidi@email.ucr.edu; wanglisa@google.com;
   shivaniagrawal@google.com; malmaud@google.com; rybakov@google.com;
   cleichner@google.com; lew@google.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agarwal RC, 1995, IBM J RES DEV, V39, P575, DOI 10.1147/rd.395.0575
   Baskin C., 2018, ARXIV PREPRINT ARXIV
   Bradbury James, 2018, JAX COMPOSABLE TRANS
   Choi J., 2018, ARXIV PREPRINT ARXIV
   Dai Steve, 2021, ARXIV210204503
   Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038
   Elsken T, 2019, J MACH LEARN RES, V20
   Garg Sahaj, 2021, ARXIV210206366
   He K., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1007/978-3-319-46493-0_38
   Heek Jonathan, 2020, FLAX NEURAL NETWORK
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jain Sambhav R, 2019, ARXIV190308066
   Jun Fang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P69, DOI 10.1007/978-3-030-58536-5_5
   Krizhevsky A., 2010, CONVOLUTIONAL DEEP B, V40, P1, DOI DOI 10.1145/3065386
   Lee J, 2020, IEEE ACCESS, V8, P94000, DOI 10.1109/ACCESS.2020.2995184
   Li GL, 2018, LECT NOTES COMPUT SC, V11139, P402, DOI 10.1007/978-3-030-01418-6_40
   McKinstry J. L., 2018, ARXIV180904191
   NVIDIA, 2020, NVID A100 TENS COR G
   Oh Jihun, 2020, ARXIV200805767
   Paszke Adam, 2017, ADV NEURAL INFORM PR
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shkolnik Moran, 2020, ARXIV200207686
   Song H., 2016, DEEP COMPRESSION COM
   Sun Qigong, 2021, ARXIV210302904
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.00881, 10.1109/CVPR.2019.01218]
   Wu Hao, 2020, ARXIV200409602
   Xilinx, 2020, CONV NEUR NETW INT4
   Yaohui Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13166, DOI 10.1109/CVPR42600.2020.01318
   Yichi Zhang, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P171, DOI 10.1145/3431920.3439296
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   ZHAO R, 2019, INT C MACH LEARN PML, V97
   Zhuang BH, 2018, PROC CVPR IEEE, P7920, DOI 10.1109/CVPR.2018.00826
   Zoph B, 2016, ARXIV161101578
NR 38
TC 1
Z9 1
U1 0
U2 2
PY 2021
BP 3085
EP 3093
DI 10.1109/CVPRW53098.2021.00345
UT WOS:000705890203020
DA 2023-11-16
ER

PT J
AU Lee, SS
   Nguyen, TD
   Meher, PK
   Park, SY
AF Lee, Sun Sik
   Nguyen, Thanh Dat
   Meher, Pramod Kumar
   Park, Sang Yoon
TI Energy-Efficient High-Speed ASIC Implementation of Convolutional Neural
   Network Using Novel Reduced Critical-Path Design
SO IEEE ACCESS
DT Article
DE Computer architecture; Convolutional neural networks; Convolution;
   Feature extraction; Kernel; Hardware; Convolutional codes; Convolutional
   neural network (CNN); convolution layer; modified Booth encoder; Wallace
   reduction tree; ASIC
ID ARCHITECTURE; ACCELERATOR; CNN
AB Convolutional Neural Network (CNN) plays an important role in several machine learning tasks related to speech, image, and video processing applications. The increasing demand for faster processing in real-time applications requires high-speed implementation of CNN. However, in general, CNN involves higher latency due to the computationally intensive behavior of the convolutional layer. While state-of-the-art architecture provides efficient dataflow of the convolutional operations, this paper proposes a hardware-efficient, high-speed convolution block for ASIC implementation of the CNN algorithm. The proposed convolution block is designed using a novel bit-level-multiply-accumulator (BLMAC) with a modified Booth encoder and a Wallace reduction tree. The critical path of the overall architecture is significantly shortened due to the time-optimized implementation of the proposed BLMAC, which is a main component of the convolution process. Critical path analysis and dataflow strategy are also provided to demonstrate the acceleration of the proposed design. The proposed architecture was synthesized using Synopsys Design Compiler to prove its accelerated processing. The ASIC synthesis results of the proposed architecture using a 65nm standard cell library show at least 53% reduction in latency, 52.2% reduction in area-delay product, and 54.2% reduction in power-delay product compared to the state-of-the-art architecture.
C1 [Lee, Sun Sik; Nguyen, Thanh Dat; Park, Sang Yoon] Myongji Univ, Dept Elect Engn, Yongin 17058, South Korea.
   [Meher, Pramod Kumar] CV Raman Global Univ, Dept Comp Sci & Engn, Bhubaneswar 752054, Odisha, India.
RP Park, SY (corresponding author), Myongji Univ, Dept Elect Engn, Yongin 17058, South Korea.
EM sypark@mju.ac.kr
CR Alawad M, 2018, IEEE T MULTI-SCALE C, V4, P888, DOI 10.1109/TMSCS.2018.2886266
   Albert A, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1357, DOI 10.1145/3097983.3098070
   Ardakani A, 2018, IEEE T CIRCUITS-I, V65, P1349, DOI 10.1109/TCSI.2017.2757036
   Chen L, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P695, DOI 10.1109/ACPR.2015.7486592
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jo J, 2018, IEEE T CIRCUITS-I, V65, P4196, DOI 10.1109/TCSI.2018.2840092
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang SR, 2009, IEEE T CIRCUITS-II, V56, P404, DOI 10.1109/TCSII.2009.2019334
   Liu Q, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224871
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Napoletano P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010209
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vansteenkiste E, 2016, THESIS GHENT U GHENT
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Wu Y., 2020, IEEE INT SYMP CIRC S, P1, DOI DOI 10.1109/iscas45731.2020.9180406
   Xu JW, 2021, IEEE T CIRCUITS-II, V68, P2142, DOI 10.1109/TCSII.2020.3038897
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
NR 24
TC 2
Z9 2
U1 2
U2 9
PY 2022
VL 10
BP 34032
EP 34045
DI 10.1109/ACCESS.2022.3162066
UT WOS:000777290200001
DA 2023-11-16
ER

PT J
AU Ma, YF
   He, Y
   Wang, L
   Zhang, JR
AF Ma, Yafei
   He, Yu
   Wang, Lei
   Zhang, Jianren
TI Probabilistic reconstruction for spatiotemporal sensor data integrated
   with Gaussian process regression
SO PROBABILISTIC ENGINEERING MECHANICS
DT Article
DE Sensor failure; Spatiotemporal correlation; Gaussian process regression;
   Data reconstruction
ID SPECTRUM ESTIMATION SUBJECT; PREDICTION; MODEL; IDENTIFICATION;
   INTERPOLATION
AB The effective health management of sensor networks is very important for the reliability assessment of engineering structures. Sensor failure and data missing occur frequently due to the influences of signal noise and adverse environment. This paper proposes a probabilistic reconstruction framework of missing data using spatiotemporal correlation of synchronous sensors. Faulty sensors in multi-sensor network are detected by projecting high-dimension feature into a visualization optimal discriminant vector space. The Gaussian process regression (GPR) machine learning is developed to reconstruct the structural dynamic nonlinear response by integrating with temporal and spatial information. The Bayesian posterior probabilistic output rather than point estimation is used to quantify the inherent uncertainty induced by non-stationary stochastic process. Various types of prior kernel functions are modeled to obtain the optimal function according to the characteristic of sensor data. A subset of sensor networks with different correlation coefficients is proposed to obtain the optimal selection strategy. The proposed framework is demonstrated by accelerator sensors data collected from Canton tower in Guangzhou. The results show that the reconstructed data agree well with the measured values in time and frequency domain. The GPR data-driven method can achieve a higher accuracy than artificial neural network approach. The selection of sensors has a significant impact on missing data reconstruction. Selecting some highly correlated sensors is as accurate as applying the entire network sensors.
C1 [Ma, Yafei; He, Yu; Wang, Lei; Zhang, Jianren] Changsha Univ Sci & Technol, Sch Civil Engn, Changsha 410114, Peoples R China.
RP Wang, L (corresponding author), Changsha Univ Sci & Technol, Sch Civil Engn, Changsha 410114, Peoples R China.
EM leiwang@csust.edu.cn
CR Caywood MS, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00647
   Comerford L., 2017, 2017 IEEE S SERIES C, DOI [10.1109/SSCI.2017.8285295, DOI 10.1109/SSCI.2017.8285295]
   Comerford L, 2016, PROBABILIST ENG MECH, V44, P66, DOI 10.1016/j.probengmech.2015.09.015
   Comerford L, 2015, STRUCT SAF, V52, P150, DOI 10.1016/j.strusafe.2014.10.001
   Fan G, 2021, ENG STRUCT, V234, DOI 10.1016/j.engstruct.2021.111970
   Fan G, 2021, STRUCT HEALTH MONIT, V20, P1373, DOI 10.1177/1475921720916881
   Guan XF, 2012, RELIAB ENG SYST SAFE, V97, P1, DOI 10.1016/j.ress.2011.09.008
   Guan YN, 2021, NEUROCOMPUTING, V426, P174, DOI 10.1016/j.neucom.2020.10.043
   Guo YR, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104033
   Hur SH, 2021, ENERGY REP, V7, P1046, DOI 10.1016/j.egyr.2020.12.020
   Kougioumtzoglou IA, 2017, MECH SYST SIGNAL PR, V94, P279, DOI 10.1016/j.ymssp.2017.03.004
   Kullaa J, 2010, MECH SYST SIGNAL PR, V24, P1444, DOI 10.1016/j.ymssp.2009.12.001
   Li CZ, 2017, AIAA J, V55, P930, DOI 10.2514/1.J055201
   Li D, 2016, ENERG BUILDINGS, V128, P519, DOI 10.1016/j.enbuild.2016.07.014
   Li D, 2020, NEUROCOMPUTING, V411, P351, DOI 10.1016/j.neucom.2020.05.033
   [梁智 Liang Zhi], 2020, [太阳能学报, Acta Energiae Solaris Sinica], V41, P45
   Lio WH, 2021, RENEW ENERG, V169, P670, DOI 10.1016/j.renene.2021.01.040
   Liu YQ, 2020, APPL ENERG, V260, DOI 10.1016/j.apenergy.2019.114259
   Ma XL, 2019, J WIND ENG IND AEROD, V188, P30, DOI 10.1016/j.jweia.2019.02.002
   Ma YF, 2014, J BRIDGE ENG, V19, DOI 10.1061/(ASCE)BE.1943-5592.0000611
   Ma YF, 2013, STRUCT SAF, V44, P102, DOI 10.1016/j.strusafe.2013.07.006
   Ni FT, 2020, COMPUT-AIDED CIV INF, V35, P685, DOI 10.1111/mice.12528
   Ni YQ, 2016, MEASUREMENT, V88, P468, DOI 10.1016/j.measurement.2016.04.049
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Shao CX, 2014, INT CONF INFO SCI, P176, DOI 10.1109/ICIST.2014.6920359
   [邵建新 Shao Jianxin], 2014, [仪器仪表学报, Chinese Journal of Scientific Instrument], V35, P580
   Shewchuk J.R., 1994, SCH COMPUTER SCI
   Su GS, 2014, ADV STRUCT ENG, V17, P1257, DOI 10.1260/1369-4332.17.9.1257
   Wan HP, 2018, J STRUCT ENG, V144, DOI 10.1061/(ASCE)ST.1943-541X.0002085
   Wan HP, 2016, MECH SYST SIGNAL PR, V70-71, P245, DOI 10.1016/j.ymssp.2015.08.011
   Wang BX, 2016, COMP MATER SCI, V125, P136, DOI 10.1016/j.commatsci.2016.08.035
   Wang QA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153311
   Wang XW, 2021, STRUCTURES, V29, P1537, DOI 10.1016/j.istruc.2020.12.036
   Wang YL, 2020, COMPUT CHEM ENG, V140, DOI 10.1016/j.compchemeng.2020.106964
   Wang YH, 2021, RELIAB ENG SYST SAFE, V214, DOI 10.1016/j.ress.2021.107762
   Xia Y, 2009, ADV SCI TECH, V56, P489
   [谢晓凯 Xie Xiaokai], 2019, [空间结构, Spatial Structures], V25, P38
   Yan WC, 2019, ENG STRUCT, V193, P91, DOI 10.1016/j.engstruct.2019.05.028
   Yi TH, 2017, MEASUREMENT, V109, P200, DOI 10.1016/j.measurement.2017.05.064
   Zhang ZY, 2017, MECH SYST SIGNAL PR, V91, P266, DOI 10.1016/j.ymssp.2017.01.018
   Zhou YG, 2021, MEASUREMENT, V178, DOI 10.1016/j.measurement.2021.109298
   Zhu J, 2019, INT J FATIGUE, V118, P44, DOI 10.1016/j.ijfatigue.2018.08.037
NR 42
TC 14
Z9 14
U1 4
U2 15
PD JUL
PY 2022
VL 69
AR 103264
DI 10.1016/j.probengmech.2022.103264
EA APR 2022
UT WOS:000830277700002
DA 2023-11-16
ER

PT C
AU Salamat, S
   Imani, M
   Gupta, S
   Rosing, T
AF Salamat, Sahand
   Imani, Mohsen
   Gupta, Sarangh
   Rosing, Tajana
GP IEEE
TI RNSnet: In-Memory Neural Network Acceleration Using Residue Number
   System
SO 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
DT Proceedings Paper
CT 3rd IEEE International Conference on Rebooting Computing (ICRC)
CY NOV 07-09, 2018
CL Tysons, VA
ID CONVERTER
AB We live in a world where technological advances are continually creating more data than what we can deal with. Machine learning algorithms, in particular Deep Neural Networks (DNNs), are essential to process such large data. Computation of DNNs requires loading the trained network on the processing element and storing the result in memory. Therefore, running these applications need a high memory bandwidth. Traditional cores are memory limited in terms of the memory bandwidth. Hence, running DNNs on traditional cores results in high energy consumption and slows down processing speed due to a large amount of data movement between memory and processing units. Several prior works tried to address data movement issue by enabling Processing In-Memory (PIM) using crossbar analog multiplication. However, these designs suffer from the large overhead of data conversion between analog and digital domains. In this work, we propose RNSnet, which uses Residue Number System (RNS) to execute neural network completely in the digital domain in memory. RNSnet simplifies the fundamental neural network operations and maps them to in-memory addition and data access. We test the efficiency of the proposed design on several popular neural network applications. Our experimental result shows that RNSnet consumes 145.5x less energy and obtains 35.4x speedup as compared to NVIDIA GPU GTX 1080. In addition, our results show that RNSnet can achieve 8.5x higher energy-delay product as compared to the state-of-the-art neural network accelerators.
C1 [Salamat, Sahand; Imani, Mohsen; Gupta, Sarangh; Rosing, Tajana] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Salamat, S (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM sasalama@ucsd.edu; moimani@ucsd.edu; sgupta@ucsd.edu; tajana@ucsd.edu
CR Abadi M., 2016, PROC 12 USENIX C OPE
   Akhlaghi Vahideh, 2018, ISCA
   Alia G, 2005, NEURAL NETWORKS, V18, P179, DOI 10.1016/j.neunet.2004.11.006
   [Anonymous], 2007, RESIDUE NUMBER SYSTE
   [Anonymous], 2017, P 54 ANN DES AUT C 2
   [Anonymous], J COMMUN COMPUT
   [Anonymous], 2017, INT J APPL ENG RES
   [Anonymous], 2015, FPL
   [Anonymous], DIG SYST DES 2003 P
   [Anonymous], 2010, 2010 IEEE INT S PARA
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], IEEE J SOLID STATE C
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, P INT S LOW POW EL D
   [Anonymous], ARXIV180104014
   [Anonymous], 2016, RESIDUE NUMBER SYSTE
   [Anonymous], DATE
   [Anonymous], 2017, IEEE T CONTROL NETW
   [Anonymous], CIRC SYST ISCAS 2018
   [Anonymous], 2016, P 35 INT C COMP AID
   [Anonymous], CIRC SYST ISCAS 2018
   [Anonymous], 2017, ACSSC
   [Anonymous], ITMQIS
   [Anonymous], 2016, 2016 CO INT C RADAR
   [Anonymous], IEEE ACM ICCAD
   [Anonymous], ISCAS
   [Anonymous], ICROIT
   [Anonymous], 2015, 32 ICML
   [Anonymous], ITHINGS GREENCOM CPS
   [Anonymous], IACR CRYPTOLOGY EPRI
   [Anonymous], MIXDES
   Aziz A, 2018, DES AUT TEST EUROPE, P1289, DOI 10.23919/DATE.2018.8342213
   Chen XM, 2018, DES AUT TEST EUROPE, P1205, DOI 10.23919/DATE.2018.8342199
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dong X., 2014, EMERGING MEMORY TECH, P15, DOI DOI 10.1007/978-1-4419-9551-ARXIV:ARXIV:1011.1669V3
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Hiasat AA, 1998, IEEE T CIRCUITS-II, V45, P204, DOI 10.1109/82.661651
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Imani M, 2016, DES AUT TEST EUROPE, P373
   James J, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1793, DOI 10.1109/ICACCI.2015.7275875
   Jiao X, 2018, DES AUT TEST EUROPE, P1223, DOI 10.23919/DATE.2018.8342202
   Kim Y, 2017, ICCAD-IEEE ACM INT, P25, DOI 10.1109/ICCAD.2017.8203756
   Krasnobayev VA, 2016, CYBERN SYST ANAL+, V52, P145, DOI 10.1007/s10559-016-9809-2
   Kvatinsky S, 2015, IEEE T CIRCUITS-II, V62, P786, DOI 10.1109/TCSII.2015.2433536
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   LAM LayYong, 2004, FLEETING FOOTSTEPS T, VRevised edition
   LeCun Y., 1998, MNIST DATABASE HANDW
   Lin S, 2018, DES AUT TEST EUROPE, P1045, DOI 10.23919/DATE.2018.8342166
   Manabe T, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P299, DOI 10.1109/FPT.2017.8280165
   Matutino PM, 2015, IEEE T VLSI SYST, V23, P603, DOI 10.1109/TVLSI.2014.2314174
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Salamat S, 2017, INT SYM QUAL ELECT, P419, DOI 10.1109/ISQED.2017.7918352
   Serrano-Gotarredona T, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00002
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sousa L, 2017, CIRC SYST SIGNAL PR, V36, P1224, DOI 10.1007/s00034-016-0354-z
   Talati N, 2016, IEEE T NANOTECHNOL, V15, P635, DOI 10.1109/TNANO.2016.2570248
   Tay T.F., 2017, EMBEDDED SYSTEMS DES, P65
   Tay TF, 2014, IEEE INT SYMP CIRC S, P1748, DOI 10.1109/ISCAS.2014.6865493
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
NR 60
TC 25
Z9 26
U1 0
U2 1
PY 2018
BP 219
EP 230
UT WOS:000467925800029
DA 2023-11-16
ER

PT J
AU Yao, TC
   Wang, J
   Wan, M
   Xin, ZK
   Wang, YA
   Cao, RQ
   Li, SG
   Chi, XB
AF Yao, Tiechui
   Wang, Jue
   Wan, Meng
   Xin, Zhikuang
   Wang, Yangang
   Cao, Rongqiang
   Li, Shigang
   Chi, Xuebin
TI VenusAI: An artificial intelligence platform for scientific discovery on
   supercomputers
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE AI platform; Scientific discovery; Large-scale computation;
   Supercomputer; AI application
ID ENERGY MINIMIZATION; SPECIAL-ISSUE; IMPLEMENTATION; CONVERGENCE; MODELS
AB Since the machine learning platform can provide one-stop artificial intelligence (AI) application solutions, it has been widely used in the industrial and commercial internet fields in recent years. Based on the heterogeneous accelerator cards, scientific discovery using large-scale computation and massive data is a significant tendency in the future. However, building a platform for scientific discovery remains challenging, including large-scale heterogeneous resource scheduling and support for massive multi-source data. To free researchers from tedious resource management and environmental configuration, we propose a VenusAI platform for large-scale computing scenarios in scientific research, based on heterogeneous resources scheduling framework. This paper firstly illustrates the VenusAI platform architecture design scheme based on the supercomputers and elaborates on the virtualization and containerization of the underlying hardware resources. Next, a technical framework for heterogeneous resource aggregation and scheduling is proposed. A unified resource interface in the application service layer is introduced. Considering the core three parts of the AI scenario: data, model, and computing power, modularized service decoupling is carried out. Furthermore, three types of experiments are evaluated on the supercomputers and show that the performance of the scheduling framework on virtual clusters is better than that on common clusters. Finally, three scientific discovery applications deployed on VenusAI, i.e., new energy forecasting, materials design, and unmanned aerial vehicle planning, demonstrate the advantages of the platform in solving practical scientific problems.
C1 [Yao, Tiechui; Wang, Jue; Wan, Meng; Xin, Zhikuang; Wang, Yangang; Cao, Rongqiang; Chi, Xuebin] Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
   [Yao, Tiechui; Wang, Jue; Xin, Zhikuang; Wang, Yangang; Cao, Rongqiang; Chi, Xuebin] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Li, Shigang] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
RP Wang, J (corresponding author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China.
EM yaotiechui@cnic.cn; wangjue@sccas.cn; wanmengdamon@cnic.cn;
   xinzhikuang@cnic.cn; wangyg@sccas.cn; caorq@sccas.cn;
   shigang.li@inf.ethz.ch; chi@sccas.cn
CR Acosta-Quinonez RI, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101897
   Artrith N, 2017, PHYS REV B, V96, DOI 10.1103/PhysRevB.96.014112
   Asch M, 2018, INT J HIGH PERFORM C, V32, P435, DOI 10.1177/1094342018778123
   Baidu, 2021, WHAT IS EASYDL BAIDU
   Behler J, 2011, J CHEM PHYS, V134, DOI 10.1063/1.3553717
   Brayford David, 2020, PASC '20: Proceedings of the Platform for Advanced Scientific Computing Conference, DOI 10.1145/3394277.3401850
   [陈珺娴 Chen Junxian], 2020, [高分子通报, Polymer Bulletin], P1
   Colton S, 2012, FRONT ARTIF INTEL AP, V242, P21, DOI 10.3233/978-1-61499-098-7-21
   Elbadawi M, 2020, DRUG DISCOV TODAY, V26, P769, DOI 10.1016/j.drudis.2020.12.003
   Feng H, 2021, J SYST ARCHITECT, V116, DOI 10.1016/j.sysarc.2021.102048
   Ficco M, 2019, J SYST ARCHITECT, V97, P107, DOI 10.1016/j.sysarc.2019.04.004
   Jia WL, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00009
   Jia WL, 2017, COMPUT PHYS COMMUN, V211, P8, DOI 10.1016/j.cpc.2016.07.003
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   KitCheck, 2015, AMAZON WEB SERVICES
   Li J., 2013, ACM T EMBEDDED COMPU, V12, P1
   Li JL, 2020, MATTER-US, V3, P393, DOI 10.1016/j.matt.2020.06.011
   Lillicrap T. P., 2015, INT C LEARNING REPRE
   [刘全 Liu Quan], 2018, [计算机学报, Chinese Journal of Computers], V41, P1
   Liu Z., COMPUT SYST APPL, V30, P40
   Makridakis S, 1997, J FORECASTING, V16, P147, DOI 10.1002/(SICI)1099-131X(199705)16:3<147::AID-FOR652>3.0.CO;2-X
   Makridakis S, 2017, FUTURES, V90, P46, DOI 10.1016/j.futures.2017.03.006
   Meikang Qiu, 2011, 2011 IEEE/ACM International Conference on Green Computing and Communications, P56, DOI 10.1109/GreenCom.2011.18
   Meikang Qiu, 2006, Web Intelligence and Agent Systems, V4, P43
   Mittal S, 2019, J SYST ARCHITECT, V97, P428, DOI 10.1016/j.sysarc.2019.01.011
   Mucha T., 2020, ETLA WORKING PAPERS, V76
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qiu H, 2020, INFORM FUSION, V55, P59, DOI 10.1016/j.inffus.2019.07.012
   Qiu M., 2009, ACM SYM APPL COMP, P1637
   Qiu M., 2019, REINFORCEMENT LEARNI
   Qiu MK, 2008, J PARALLEL DISTR COM, V68, P443, DOI 10.1016/j.jpdc.2007.06.014
   Qiu MK, 2006, LECT NOTES COMPUT SC, V4096, P25
   Qiu MK, 2019, IEEE T SUST COMPUT, V4, P1, DOI 10.1109/TSUSC.2018.2880127
   Qiu MK, 2016, INT J COMMUN SYST, V29, P2364, DOI 10.1002/dac.2959
   Qiu MK, 2015, IEEE T EMERG TOP COM, V3, P544, DOI 10.1109/TETC.2015.2398824
   Qiu MK, 2009, J PARALLEL DISTR COM, V69, P546, DOI 10.1016/j.jpdc.2009.02.005
   Qiu MK, 2003, 200S IEEE SYMPOSIUM ON HUMAN CENTRIC COMPUTING LANGUAGES AND ENVIRONMENTS, P84
   Raghu M., 2020, ARXIV
   Schwarz N., 2020, SMOKY MOUNTAINS COMP, P145
   Shao ZL, 2006, IEEE T COMPUT, V55, P443, DOI 10.1109/TC.2006.59
   Sutskever I., 2014, CORR, P3104
   Tang DJ, 2021, J SYST ARCHITECT, V116, DOI 10.1016/j.sysarc.2021.102055
   Tencent, 2021, TENC AI LAB YUN SHEN
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Wang CY, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102016
   Wang J, 2020, INT J HIGH PERFORM C, V34, P157, DOI 10.1177/1094342020905932
   Wang J, 2017, COMPUT PHYS COMMUN, V211, P1, DOI 10.1016/j.cpc.2016.08.017
   Wang J, 2016, FUTURE GENER COMP SY, V54, P501, DOI 10.1016/j.future.2015.02.011
   Wang Y., 2020, FRONT DATA COMPUT, V1, P86
   Wu CH, 2004, IEEE T INTELL TRANSP, V5, P276, DOI 10.1109/TITS.2004.837813
   Wu G, 2013, J PARALLEL DISTR COM, V73, P330, DOI 10.1016/j.jpdc.2012.09.007
   Yang R, 2021, INT J MED ROBOT COMP, V17, DOI 10.1002/rcs.2194
   Yao TC, 2022, IEEE T SUSTAIN ENERG, V13, P607, DOI 10.1109/TSTE.2021.3123337
   Yao tiechui, 2021, Computer Engineering, V47, P316, DOI 10.19678/j.issn.1000-3428.0057693
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634
   Zheng CAP, 2020, AAAI CONF ARTIF INTE, V34, P1234
NR 57
TC 5
Z9 6
U1 7
U2 15
PD JUL
PY 2022
VL 128
AR 102550
DI 10.1016/j.sysarc.2022.102550
EA MAY 2022
UT WOS:000802886800004
DA 2023-11-16
ER

PT J
AU Thuy, NN
   Wongthanavasu, S
AF Nguyen Ngoc Thuy
   Wongthanavasu, Sartra
TI An efficient stripped cover-based accelerator for reduction of
   attributes in incomplete decision tables
SO EXPERT SYSTEMS WITH APPLICATIONS
DT Article
DE Rough set; Attribute reduction; Stripped cover; Attribute significance
   measure; Incomplete data
ID FEATURE-SELECTION METHOD; ROUGH SET APPROACH; UNCERTAINTY MEASURES; RULE
   ACQUISITION; ENTROPY; SYSTEMS; APPROXIMATIONS; ALGORITHM
AB Attribute reduction in incomplete decision tables plays an extremely important role in machine learning, data mining, pattern recognition, especially for experts and intelligent systems. Many different reducts have been given in the rough set approach to find a promising reduct. However, efficiently extracting a reduct from large-scale incomplete data sets is time-consuming and becomes a challenging research problem. Although researchers have spent a lot of efforts for improving the computational efficiency, most existing methods have quite high complexity and focus mostly on the positive region reduct. To accelerate the attribute reduction process, we firstly introduce in this paper a new concept of stripped covers. Then, we investigate vital properties of stripped covers as well as provide attribute significance measures. By using these measures, we propose an effective and efficient heuristic algorithm framework for fast computation of popular reduct types. It is also worthwhile to mention that our algorithm has better time complexity than existing methods. Furthermore, the performance of the proposed method is experimentally demonstrated across multiple real-world datasets and compared with the main state-of-the-art methods. The results showed that our method outperforms the compared methods in the terms of obtained reduct size, computational time and classification accuracy. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Nguyen Ngoc Thuy; Wongthanavasu, Sartra] Khon Kaen Univ, Fac Sci, Dept Comp Sci, Khon Kaen 40002, Thailand.
RP Wongthanavasu, S (corresponding author), Khon Kaen Univ, Fac Sci, Dept Comp Sci, Khon Kaen 40002, Thailand.
EM nnthuy.cntthue@gmail.com; wongsar@kku.ac.th
CR [Anonymous], 2012, ARCH ENVIRON CON TOX, DOI [DOI 10.1007/S00244-011-9745-0, 10.1007/s00244-011-9745-0, DOI 10.1007/978-94-011-3534-4]
   Asdaghi F, 2019, KNOWL-BASED SYST, V166, P198, DOI 10.1016/j.knosys.2018.12.026
   Azam N, 2014, KNOWL-BASED SYST, V72, P96, DOI 10.1016/j.knosys.2014.08.030
   Cilia ND, 2019, PATTERN RECOGN LETT, V121, P77, DOI 10.1016/j.patrec.2018.04.007
   Dai JH, 2013, IEEE T CYBERNETICS, V43, P1277, DOI 10.1109/TSMCB.2012.2228480
   Dai JH, 2013, KNOWL-BASED SYST, V39, P207, DOI 10.1016/j.knosys.2012.10.018
   Du WS, 2016, INFORM SCIENCES, V346, P106, DOI 10.1016/j.ins.2016.01.098
   Ge YW, 2018, APPL SOFT COMPUT, V73, P350, DOI 10.1016/j.asoc.2018.08.031
   Hu MJ, 2019, KNOWL-BASED SYST, V165, P92, DOI 10.1016/j.knosys.2018.11.022
   Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6
   Jung JJ, 2012, EXPERT SYST APPL, V39, P4049, DOI 10.1016/j.eswa.2011.09.096
   Kim K, 2018, EXPERT SYST APPL, V109, P49, DOI 10.1016/j.eswa.2018.05.023
   Kim KJ, 2018, EXPERT SYST APPL, V103, P196, DOI 10.1016/j.eswa.2018.03.010
   Kryszkiewicz M, 1999, INFORM SCIENCES, V113, P271, DOI 10.1016/S0020-0255(98)10065-8
   Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1
   Lang GM, 2017, INFORM SCIENCES, V406, P185, DOI 10.1016/j.ins.2017.04.030
   Leung Y, 2003, INFORM SCIENCES, V153, P85, DOI 10.1016/S0020-0255(03)00061-6
   Li JH, 2013, INT J APPROX REASON, V54, P149, DOI 10.1016/j.ijar.2012.07.005
   Liang JY, 2002, INT J UNCERTAIN FUZZ, V10, P95, DOI 10.1142/S021848850200134X
   Lin YJ, 2018, KNOWL-BASED SYST, V152, P51, DOI 10.1016/j.knosys.2018.04.004
   Liu GL, 2018, KNOWL-BASED SYST, V139, P101, DOI 10.1016/j.knosys.2017.10.014
   Liu GL, 2017, KNOWL-BASED SYST, V119, P87, DOI 10.1016/j.knosys.2016.11.027
   Liu GL, 2015, PATTERN RECOGN LETT, V65, P81, DOI 10.1016/j.patrec.2015.06.031
   Meng ZQ, 2016, INFORM SCIENCES, V330, P226, DOI 10.1016/j.ins.2015.09.057
   Meng ZQ, 2012, INFORM SCIENCES, V204, P44, DOI 10.1016/j.ins.2012.04.004
   Meng ZQ, 2009, INFORM SCIENCES, V179, P2774, DOI 10.1016/j.ins.2009.04.002
   Metin SK, 2018, EXPERT SYST APPL, V92, P106, DOI 10.1016/j.eswa.2017.09.047
   Miao DQ, 2009, INFORM SCIENCES, V179, P4140, DOI 10.1016/j.ins.2009.08.020
   Thuy NN, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.106999
   Thuy NN, 2019, EXPERT SYST APPL, V137, P308, DOI 10.1016/j.eswa.2019.06.071
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pourpanah F, 2019, APPL SOFT COMPUT, V80, P761, DOI 10.1016/j.asoc.2019.04.037
   Qian WB, 2018, APPL SOFT COMPUT, V73, P242, DOI 10.1016/j.asoc.2018.08.032
   Qian WB, 2015, NEUROCOMPUTING, V168, P210, DOI 10.1016/j.neucom.2015.05.105
   Qian YH, 2011, PATTERN RECOGN, V44, P1658, DOI 10.1016/j.patcog.2011.02.020
   Qian YH, 2010, KNOWL-BASED SYST, V23, P427, DOI 10.1016/j.knosys.2010.02.004
   Shu WH, 2015, DATA KNOWL ENG, V100, P116, DOI 10.1016/j.datak.2015.06.009
   Shu WH, 2014, KNOWL-BASED SYST, V72, P60, DOI 10.1016/j.knosys.2014.08.024
   Shu WH, 2014, PATTERN RECOGN, V47, P3890, DOI 10.1016/j.patcog.2014.06.002
   Shu WH, 2014, INT J APPROX REASON, V55, P867, DOI 10.1016/j.ijar.2013.09.015
   Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271
   Stefanowski J, 2001, COMPUT INTELL-US, V17, P545, DOI 10.1111/0824-7935.00162
   Sun BZ, 2017, KNOWL-BASED SYST, V123, P61, DOI 10.1016/j.knosys.2017.01.036
   Sun L, 2012, KNOWL-BASED SYST, V36, P206, DOI 10.1016/j.knosys.2012.06.010
   Tang XC, 2019, EXPERT SYST APPL, V120, P207, DOI 10.1016/j.eswa.2018.11.018
   Tiwari AK, 2018, EXPERT SYST APPL, V101, P205, DOI 10.1016/j.eswa.2018.02.009
   Tsang ECC, 2008, COMPUT MATH APPL, V56, P279, DOI 10.1016/j.camwa.2006.12.104
   Wang CZ, 2015, APPL SOFT COMPUT, V26, P235, DOI 10.1016/j.asoc.2014.10.006
   Wei DK, 2006, LECT NOTES COMPUT SC, V4092, P504
   Xie XJ, 2018, INT J APPROX REASON, V93, P443, DOI 10.1016/j.ijar.2017.12.002
   Xie XL, 2019, IEEE ACCESS, V7, P27501, DOI 10.1109/ACCESS.2019.2897752
   Xu JC, 2013, APPL MATH INFORM SCI, V7, P829, DOI 10.12785/amis/070255
   Zhao H, 2014, KNOWL-BASED SYST, V57, P181, DOI 10.1016/j.knosys.2013.12.018
   Zhao XJ, 2017, EXPERT SYST APPL, V84, P272, DOI 10.1016/j.eswa.2017.05.009
   Zheng K, 2014, EXPERT SYST APPL, V41, P6748, DOI 10.1016/j.eswa.2014.04.042
   Zheng KF, 2018, PATTERN RECOGN, V77, P20, DOI 10.1016/j.patcog.2017.12.008
NR 58
TC 7
Z9 8
U1 1
U2 18
PD APR 1
PY 2020
VL 143
AR 113076
DI 10.1016/j.eswa.2019.113076
UT WOS:000509630200025
DA 2023-11-16
ER

PT C
AU Qiu, YH
   Cao, YH
   Dai, Y
   Yin, WB
   Wang, LL
AF Qiu, Yunhui
   Cao, Yuhang
   Dai, Yuan
   Yin, Wenbo
   Wang, Lingli
GP IEEE
TI TRAM: An Open-Source Template-based Reconfigurable Architecture Modeling
   Framework
SO 2022 32ND INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS, FPL
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 32nd International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2022
CL Belfast, NORTH IRELAND
DE CGRA template; unified interconnect model; architecture modeling; CGRA
   mapping
ID EXPLORATION; PROCESSOR
AB Coarse-grained reconfigurable architecture (CGRA) is a promising accelerator design choice due to its high performance and power efficiency in the computation or data-intensive application domains, such as security, multimedia, digital signal processing, machine learning, and high-performance computing. CGRA consists of coarse-grained processing elements (PEs) and interconnects that determine the architecture flexibility to support different applications and also affect the performance and power efficiency significantly. Although multiple types of interconnects have been proposed, a parameterized unified model is still lacking. In this paper, we propose a flexible and scalable CGRA template with a novel interconnect model that can unify the typical neighbor-to-neighbor, switch-based, and FPGA-like interconnects. Furthermore, we present TRAM, an open-source template-based reconfigurable architecture modeling framework that integrates the Chisel-based CGRA modeling, architecture intermediate representation (IR) and Verilog generation, dataflow graph (DFG) mapping, simulation, and evaluation. The mapping flow contains graph-based placement and routing, critical-path-driven data synchronization, and simulated-annealing-based optimization. We evaluate the impacts of the rich design parameters, which demonstrate the significance of such a flexible template to facilitate architecture optimization. Compared with the related work, TRAM can achieve a 4.1x smaller DFG latency and a faster mapping speed for both the 8x8 and 16x16 CGRAs. Moreover, TRAM is able to attain an extremely high PE utilization of 94.4% on average by architecture tuning.
C1 [Qiu, Yunhui; Cao, Yuhang; Dai, Yuan; Yin, Wenbo; Wang, Lingli] Fudan Univ, State Key Lab ASIC & Syst, Shanghai, Peoples R China.
RP Wang, LL (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai, Peoples R China.
EM llwang@fudan.edu.cn
CR Anderson J, 2021, IEEE INT CONF ASAP, P156, DOI 10.1109/ASAP52443.2021.00030
   [Anonymous], 2020, EXPR BENCHM
   Ansaloni G, 2011, IEEE T VLSI SYST, V19, P1062, DOI 10.1109/TVLSI.2010.2044667
   Bahr R, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218553
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chin SA, 2017, IEEE INT CONF ASAP, P184, DOI 10.1109/ASAP.2017.7995277
   Das Satyajit, 2019, 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE). Proceedings, P336, DOI 10.23919/DATE.2019.8715288
   Du YR, 2020, IEEE T VLSI SYST, V28, P1302, DOI 10.1109/TVLSI.2020.2972392
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Farahini N, 2013, IEEE INT SYMP CIRC S, P1448, DOI 10.1109/ISCAS.2013.6572129
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Gobieski G, 2021, CONF PROC INT SYMP C, P1027, DOI 10.1109/ISCA52012.2021.00084
   Hanrahan P., MAGMA GITHUB
   Hartmann M, 2010, J SIGNAL PROCESS SYS, V60, P225, DOI 10.1007/s11265-008-0309-0
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Jayaweera CD, 2017, 2017 3RD INTERNATIONAL MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON), P1, DOI 10.1109/MERCon.2017.7980446
   Jiang SN, 2020, IEEE MICRO, V40, P58, DOI 10.1109/MM.2020.2997638
   Kim JH, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3024063
   Kim Y, 2010, IEEE T VLSI SYST, V18, P1471, DOI 10.1109/TVLSI.2009.2025280
   Ling XY, 2021, 2021 24TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2021), P35, DOI 10.1109/DSD53832.2021.00015
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Liu LB, 2018, IEEE T COMPUT AID D, V37, P3081, DOI 10.1109/TCAD.2018.2801229
   Madhu KT, 2015, IEEE I C EMBED SOFTW, P405, DOI 10.1109/HPCC-CSS-ICESS.2015.139
   Mei B, 2008, J SIGNAL PROCESS SYS, V51, P225, DOI 10.1007/s11265-007-0152-8
   Mei BF, 2005, IEEE DES TEST COMPUT, V22, P90, DOI 10.1109/MDT.2005.27
   Peng GQ, 2020, IEEE J SOLID-ST CIRC, V55, P505, DOI 10.1109/JSSC.2019.2952839
   Podobas A, 2020, IEEE INT CONF ASAP, P1, DOI 10.1109/ASAP49362.2020.00010
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Shi KC, 2023, ACM T RECONFIG TECHN, V16, DOI 10.1145/3519599
   Tan C, 2021, IEEE INT CONF ASAP, P149, DOI 10.1109/ASAP52443.2021.00029
   Tang XF, 2019, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2019.00065
   Torng C, 2021, INT S HIGH PERF COMP, P412, DOI 10.1109/HPCA51647.2021.00042
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Weng J, 2020, ANN I S COM, P268, DOI 10.1109/ISCA45697.2020.00032
   Wijtvliet M, 2019, I C FIELD PROG LOGIC, P17, DOI 10.1109/FPL.2019.00013
   WILTON S J E, 1997, THESIS
NR 37
TC 2
Z9 2
U1 0
U2 0
PY 2022
BP 61
EP 69
DI 10.1109/FPL57034.2022.00021
UT WOS:000975890500009
DA 2023-11-16
ER

PT J
AU Hassan, O
   Faria, R
   Camsari, KY
   Sun, JZ
   Datta, S
AF Hassan, Orchi
   Faria, Rafatul
   Camsari, Kerem Yunus
   Sun, Jonathan Z.
   Datta, Supriyo
TI Low-Barrier Magnet Design for Efficient Hardware Binary Stochastic
   Neurons
SO IEEE MAGNETICS LETTERS
DT Article
DE Spin electronics; binary stochastic neuron; hardware implementation;
   low-barrier magnet; embedded magnetic tunnel junctions; probabilistic
   computing
AB Binary stochastic neurons (BSNs) form an integral part of many machine learning algorithms, motivating the development of hardware accelerators for this complex function. It has been recognized that hardware BSNs can be implemented using low-barrier magnets (LBMs) by minimally modifying present-day magnetoresistive random-access memory (MRAM) devices. A crucial parameter that determines the response of these LBM-based BSN designs is the correlation time of magnetization tau(c). In this letter, we show that, for magnets with low-energy barriers (Delta approximate to k(B)T and below), circular disk magnets with in-plane magnetic anisotropy (IMA) lead to tau(c) values that are two orders of magnitude smaller than tau(c) of magnets with perpendicular magnetic anisotropy (PMA). Analytical descriptions demonstrate that this striking difference in tau(c) is due to a precessionlike fluctuation mechanism that is enabled by the large demagnetization field in IMA magnets. We provide a detailed energy-delay performance evaluation of previously proposed BSN designs based on spin-orbit torque MRAM and spin-transfer torque MRAM employing low-barrier circular IMA magnets by SPICE simulations. The designs exhibit subnanosecond response times leading to energy requirements of approximately a few femtojoules to evaluate the BSN function, orders of magnitude lower than digital CMOS implementations with a much larger surface area. While modern MRAM technology is based on PMA magnets, results in this letter suggest that low-barrier circular IMA magnets may be more suitable for this application.
C1 [Hassan, Orchi; Faria, Rafatul; Camsari, Kerem Yunus; Datta, Supriyo] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
   [Sun, Jonathan Z.] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Hassan, O (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
EM hassan19@purdue.edu
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Amit D. J., 1992, MODELING BRAIN FUNCT
   [Anonymous], 2013, 2013 INT JOINT C NEU
   [Anonymous], 2002, PREDICTIVE TECHNOLOG
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Bhatti S, 2017, MATER TODAY, V20, P530, DOI 10.1016/j.mattod.2017.07.007
   Camsari KY, 2017, IEEE ELECTR DEVICE L, V38, P1767, DOI 10.1109/LED.2017.2768321
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Camsari KY, 2015, SCI REP-UK, V5, DOI 10.1038/srep10571
   CILINGIROGLU U, 1991, IEEE T CIRCUITS SYST, V38, P210, DOI 10.1109/31.68299
   Coffey WT, 2012, J APPL PHYS, V112, DOI 10.1063/1.4754272
   Cowburn RP, 1999, PHYS REV LETT, V83, P1042, DOI 10.1103/PhysRevLett.83.1042
   Debashis P, 2016, INT EL DEVICES MEET
   Faria R, 2017, IEEE MAGN LETT, V8, DOI 10.1109/LMAG.2017.2685358
   Hassan O, 2019, IEEE DES TEST, V36, P15, DOI 10.1109/MDAT.2019.2897964
   Kaiser J., 2019, ARXIV190203312
   Liyanagedera CM, 2017, PHYS REV APPL, V8, DOI 10.1103/PhysRevApplied.8.064017
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mizrahi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03963-w
   Nikonov DE, 2015, IEEE J EXPLOR SOLID-, V1, P3, DOI 10.1109/JXCDC.2015.2418033
   Park C., 2015 IEEE INT ELECT, DOI [10.1109/IEDM.2015.7409771, DOI 10.1109/IEDM.2015.7409771]
   Parks B, 2018, AIP ADV, V8, DOI 10.1063/1.5006422
   Pervaiz AZ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11011-8
   R2RT, 2016, BINARY STOCHASTIC NE
   Sayed S, 2018, ARXIV181200286
   Sun JZ, 2000, PHYS REV B, V62, P570, DOI 10.1103/PhysRevB.62.570
   Sutton B, 2017, SCI REP-UK, V7, DOI 10.1038/srep44370
   Vodenicarevic D, 2017, PHYS REV APPL, V8, DOI 10.1103/PhysRevApplied.8.054045
   Vodenicarevic D, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351771
   Yuan B, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3007193
   Zand R, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3304105
   Zink BR, 2018, J APPL PHYS, V124, DOI 10.1063/1.5042444
   1963, PHYS REV, V130, P1677, DOI DOI 10.1103/PHYSREV.130.1677
   2018, IEEE MAGN LETT, V9
   2002, PHYS REV B, V65
   2010, NANO LETT, V10, P1297, DOI DOI 10.1021/NL904092H
NR 37
TC 43
Z9 43
U1 1
U2 17
PY 2019
VL 10
AR 4502805
DI 10.1109/LMAG.2019.2910787
UT WOS:000467558000001
DA 2023-11-16
ER

PT J
AU Capatina, A
   Cristea, DS
   Micu, A
   Micu, AE
   Empoli, G
   Codignola, F
AF Capatina, Alexandru
   Cristea, Dragos Sebastian
   Micu, Adrian
   Micu, Angela Eliza
   Empoli, Giuseppe
   Codignola, Federica
TI Exploring causal recipes of startup acceptance into business incubators:
   a cross-country study
SO INTERNATIONAL JOURNAL OF ENTREPRENEURIAL BEHAVIOR & RESEARCH
DT Article
DE Business development; Entrepreneurship; Innovation; Multivariate
   analysis
ID ENTREPRENEURIAL ECOSYSTEMS; SCIENCE PARKS; CLEAN-TECH; PERFORMANCE;
   ACCELERATORS; MODEL; CREATIVITY; MANAGEMENT; CAPACITY; TYPOLOGY
AB Purpose - This study aims to outline the influence of various combinations of antecedent conditions for startups being accepted into business incubators in Italy and Romania. The degree to which these conditions affect acceptance is referred to here as the Business Ideas Acceptance Degree (BIAD). The antecedent conditions considered are business idea potential, business plan quality, entrepreneurial team features, business project progress stage, available financial resources, debts of potential incubated companies, commitment to apply for national/EU funds, business area related to incubatormission, proposed technological content level, technological transfer from university/research centres and spin-off of a partner-entity of the incubator.
   Design/methodology/approach - The methodological toolkit used was mixed: correlation-based analysis (CBA), machine learning (ML) techniques and fsQCA. Principal component analysis enabled the selection of the most representative antecedent conditions from both business incubator samples in Italy and Romania, further used in fsQCA analyses. XGBoost algorithm has been also used. K-Means clustering, an unsupervised learning algorithm that groups unlabeled dataset into different clusters, led to the configuration of two clusters associated to each of the countries involved in this study (Romania and Italy).
   Findings - The findings reveal the differences between the different antecedent conditions that can contribute to startups being accepted into business incubators in Italy and Romania. The validation of the fsQCA equifinality principle in both samples shows that the selected antecedent conditions, mixed in combinations of "causal recipes", lead to a high BIAD by business incubators from both countries.
   Originality/value - This study reveals the differences between different antecedent conditions, capable to contribute to the start-up acceptance within business incubators from Italy and Romania. Furthermore, the validation of fsQCA equifinality principle in both samples highlight that the selected antecedent conditions, mixed in combinations of causal recipes, lead to a high degree of business ideas' acceptance in business incubators.
C1 [Capatina, Alexandru; Cristea, Dragos Sebastian; Micu, Adrian] Dunarea de Jos Univ Galati, Galati, Romania.
   [Micu, Angela Eliza] Ovidius Univ Constanta, Constanta, Romania.
   [Empoli, Giuseppe] Univ Foggia, Foggia, Italy.
   [Codignola, Federica] Univ Milano Bicocca, Milan, Italy.
RP Capatina, A (corresponding author), Dunarea de Jos Univ Galati, Galati, Romania.
EM alexandru.capatana@ugal.ro; dragoscristea@yahoo.com;
   adrian.micu@ugal.ro; angelaelizamicu@yahoo.com;
   giuseppe.empoli@unifg.it; federica.codignola@unimib.it
CR Acs ZJ, 2017, SMALL BUS ECON, V49, P1, DOI 10.1007/s11187-017-9864-8
   Aernoudt R, 2004, SMALL BUS ECON, V23, P127, DOI 10.1023/B:SBEJ.0000027665.54173.23
   Aerts K, 2007, TECHNOVATION, V27, P254, DOI 10.1016/j.technovation.2006.12.002
   Al-Omoush KS, 2022, J INNOV KNOWL, V7, DOI 10.1016/j.jik.2022.100181
   Albert P., 2000, ARPENT ANN REV PROGR, V1, P158
   Albort-Morant G, 2016, J BUS RES, V69, P1775, DOI 10.1016/j.jbusres.2015.10.054
   Allen, 1991, ENTREP THEORY PRACT, V15, P61, DOI DOI 10.1177/104225879101500207
   Alsos GA, 2011, INT J ENTREP BEHAV R, V17, P607, DOI 10.1108/13552551111174693
   Alvedalen J, 2017, EUR PLAN STUD, V25, P887, DOI 10.1080/09654313.2017.1299694
   Amezcua AS, 2013, ACAD MANAGE J, V56, P1628, DOI 10.5465/amj.2011.0652
   [Anonymous], 2006, J TECHNOL TRANSFER
   [Anonymous], 1988, AM J SMALL BUSINESS
   Armuna C, 2020, INT ENTREP MANAG J, V16, P69, DOI 10.1007/s11365-019-00627-z
   Audretsch DB, 2019, J TECHNOL TRANSFER, V44, P313, DOI 10.1007/s10961-018-9690-4
   Audretsch DB, 2016, J TECHNOL TRANSFER, V41, P1, DOI [10.1007/s10961-014-9381-8, 10.1007/s10961-016-9473-8]
   Autio E., 2016, ENTREPRENEURSHIP SUP
   Autio E, 2018, STRATEG ENTREP J, V12, P72, DOI 10.1002/sej.1266
   Aversa P, 2015, IND CORP CHANGE, V24, P655, DOI 10.1093/icc/dtv012
   Barbero JL, 2012, TECHNOL FORECAST SOC, V79, P888, DOI 10.1016/j.techfore.2011.12.003
   Belitski M, 2016, J TECHNOL TRANSFER, V41, P1354, DOI 10.1007/s10961-015-9446-3
   Ben Jabeur S, 2022, COMPUT ECON, DOI 10.1007/s10614-021-10227-1
   Bergek A, 2008, TECHNOVATION, V28, P20, DOI 10.1016/j.technovation.2007.07.008
   Bergman BJ, 2022, ENTREP THEORY PRACT, V46, P688, DOI 10.1177/10422587211028736
   Biancalani F, 2022, SMALL BUS ECON, V58, P1699, DOI 10.1007/s11187-021-00468-7
   Bjornali ES, 2014, ENRGY PROCED, V58, P43, DOI 10.1016/j.egypro.2014.10.407
   Bruneel J, 2012, TECHNOVATION, V32, P110, DOI 10.1016/j.technovation.2011.11.003
   Cao Z, 2021, SMALL BUS ECON, V57, P75, DOI 10.1007/s11187-020-00326-y
   Cavallo A, 2021, INT ENTREP MANAG J, V17, P1843, DOI 10.1007/s11365-020-00698-3
   Chan KF, 2005, TECHNOVATION, V25, P1215, DOI 10.1016/j.technovation.2004.03.010
   Cheng SM, 2011, REG DEV, P211
   Choi YR, 2008, J BUS VENTURING, V23, P333, DOI 10.1016/j.jbusvent.2006.11.001
   Clarysse B, 2005, J BUS VENTURING, V20, P183, DOI 10.1016/j.jbusvent.2003.12.004
   Colombo MG, 2002, RES POLICY, V31, P1103, DOI 10.1016/S0048-7333(01)00178-0
   de Lange DE, 2017, J CLEAN PROD, V156, P838, DOI 10.1016/j.jclepro.2017.04.108
   Del Sarto N, 2020, TECHNOVATION, V90-91, DOI 10.1016/j.technovation.2019.102102
   Dragan GB, 2022, INT J ENTREP BEHAV R, V28, P26, DOI 10.1108/IJEBR-05-2021-0400
   Empoli G., 2021, REV MANAGEMENT COMP, V22, P488
   Eveleens CP, 2017, J TECHNOL TRANSFER, V42, P676, DOI 10.1007/s10961-016-9510-7
   Ferreira JJM, 2019, REV MANAG SCI, V13, P181, DOI 10.1007/s11846-017-0242-3
   Galbraith B, 2021, IEEE T ENG MANAGE, V68, P265, DOI 10.1109/TEM.2019.2905297
   Games D, 2021, J SCI TECHNOL POLICY, V12, P176, DOI 10.1108/JSTPM-03-2020-0067
   Goswami K, 2018, STRATEG ENTREP J, V12, P117, DOI 10.1002/sej.1281
   Grimaldi R, 2005, TECHNOVATION, V25, P111, DOI 10.1016/S0166-4972(03)00076-2
   Hackett S.M., 2004, J TECHNOLOGY TRANSFE, V29, P55, DOI DOI 10.1023/B:JOTT.0000011181.11952.0F
   Hallen BL, 2020, ORGAN SCI, V31, P378, DOI 10.1287/orsc.2019.1304
   Hannon PD, 2003, ENVIRON PLANN C, V21, P861, DOI 10.1068/c0215
   Hansen MT, 2000, HARVARD BUS REV, V78, P74
   Harper-Anderson E, 2018, ECON DEV Q, V32, P60, DOI 10.1177/0891242417741961
   Hoogendoorn B, 2019, J BUS ETHICS, V157, P1133, DOI 10.1007/s10551-017-3646-8
   Jacobides MG, 2018, STRATEGIC MANAGE J, V39, P2255, DOI 10.1002/smj.2904
   Jonsson L. O, 2020, ENTREPRENEURIAL U, P93, DOI 10.1007/978-3-030-48013-4
   Kakabadse N, 2020, EUR MANAG REV, V17, P485, DOI 10.1111/emre.12379
   Kraus S, 2018, INT ENTREP MANAG J, V14, P15, DOI 10.1007/s11365-017-0461-8
   Kuratko D., 1987, EC DEV REV, V5, P49
   Kusa R, 2021, J INNOV KNOWL, V6, P234, DOI 10.1016/j.jik.2021.06.001
   Laamanen T, 2018, ACAD MANAG DISCOV, V4, P213, DOI 10.5465/amd.2018.0110
   Lee SS, 2004, J SMALL BUS MANAGE, V42, P418, DOI 10.1111/j.1540-627X.2004.00120.x
   Lee SY, 2004, REG STUD, V38, P879, DOI 10.1080/0034340042000280910
   Li YX, 2022, FORECASTING-BASEL, V4, P184, DOI 10.3390/forecast4010011
   Lukes M, 2019, TECHNOVATION, V82-83, P25, DOI 10.1016/j.technovation.2018.07.008
   Marra A, 2015, ENERG POLICY, V86, P17, DOI 10.1016/j.enpol.2015.06.025
   Mas-Verdú F, 2015, J BUS RES, V68, P793, DOI 10.1016/j.jbusres.2014.11.030
   McAdam M, 2011, ENTREP REGION DEV, V23, P449, DOI 10.1080/08985620903406749
   Merguei N., 2022, J BUS VENTURING INSI, V18
   Mian S., 2011, INT J ENTREPRENEURSH, V13, P113, DOI 10.1504/IJEIM.2011.038854
   Nair S, 2019, TECHNOL ANAL STRATEG, V31, P266, DOI 10.1080/09537325.2018.1495325
   Nicholls-Nixon CL, 2021, INT J ENTREP BEHAV R, V27, P1696, DOI 10.1108/IJEBR-11-2020-0801
   Nyagadza B., 2022, SUSTAINABLE TECHNOLO, V1, DOI [10.1016/j.stae.2022.100020, DOI 10.1016/J.STAE.2022.100020]
   ONEAL T, 2005, ENG MANAGEMENT J, V17, P11, DOI DOI 10.1080/10429247.2005.11415293
   Pappas IO, 2021, INT J INFORM MANAGE, V58, DOI 10.1016/j.ijinfomgt.2021.102310
   Patton D, 2014, INT SMALL BUS J, V32, P897, DOI 10.1177/0266242613482134
   Peters L., 2004, J TECHNOL TRANSFER, V29, P83, DOI https://doi.org/10.1023/B:JOTT.0000011182.82350.df
   Pettersen I.B., 2015, J INNOVATION ENTREPR, V5, P1
   Phan PH, 2005, J BUS VENTURING, V20, P165, DOI 10.1016/j.jbusvent.2003.12.001
   Popescu M., 2019, B TRANSILVANIA U BRA, V12, P107
   Ragin C.C., 2009, REDESIGNING SOCIAL I
   Hajiagha SHR, 2022, INT J ENTREP BEHAV R, V28, P767, DOI 10.1108/IJEBR-05-2021-0387
   Roundy PT., 2017, J BUS VENTURING INSI, V8, P99, DOI 10.1016/j.jbvi.2017.08.002
   Salminen J, 2020, HUM-CENTRIC COMPUT I, V10, DOI 10.1186/s13673-019-0205-6
   Sansone G, 2020, TECHNOL FORECAST SOC, V158, DOI 10.1016/j.techfore.2020.120132
   Schumpeter J. A., 1934, THEORY EC DEV INQUIR
   Schwartz M, 2008, TECHNOVATION, V28, P436, DOI 10.1016/j.technovation.2008.02.003
   Schwartz M, 2010, TECHNOVATION, V30, P485, DOI 10.1016/j.technovation.2010.05.001
   Schwartz M, 2009, J TECHNOL TRANSFER, V34, P403, DOI 10.1007/s10961-008-9095-x
   Siegel DS, 2003, SMALL BUS ECON, V20, P177, DOI 10.1023/A:1022268100133
   Smedlund A, 2006, J INTELLECT CAP, V7, P204, DOI 10.1108/14691930610661863
   SMILOR RW, 1987, IEEE T ENG MANAGE, V34, P146, DOI 10.1109/TEM.1987.6498875
   Somsuk N, 2014, TECHNOL FORECAST SOC, V85, P198, DOI 10.1016/j.techfore.2013.08.007
   Spigel B, 2017, ENTREP THEORY PRACT, V41, P49, DOI 10.1111/etap.12167
   Stam E., 2018, ENTREPRENEURIAL ECOS, P173
   Stam E, 2015, EUR PLAN STUD, V23, P1759, DOI 10.1080/09654313.2015.1061484
   Stemberkova R, 2021, IND HIGHER EDUC, V35, P638, DOI 10.1177/0950422220978046
   Tello S., 2012, J SMALL BUSINESS ENT, V25, P375, DOI DOI 10.1080/08276331.2012.10593579
   Torun M., 2018, INT J INNOVATION STU, V2, P91, DOI [10.1016/j.ijis.2018.08.002, DOI 10.1016/J.IJIS.2018.08]
   Urry J, 2005, THEOR CULT SOC, V22, P1, DOI 10.1177/0263276405057188
   Vedel Benjamin, 2014, International Journal of Entrepreneurship and Small Business, V23, P509, DOI 10.1504/IJESB.2014.065685
   Vis B, 2012, SOCIOL METHOD RES, V41, P168, DOI 10.1177/0049124112442142
   Voisey P, 2006, J SMALL BUS ENTERP D, V13, P454, DOI 10.1108/14626000610680307
   von Zedtwitz M., 2003, International Journal of Entrepreneurship and Innovation Management, V3, P176, DOI 10.1504/IJEIM.2003.002227
   Winborg J, 2015, INT J ENTREP INNOV, V16, P197, DOI 10.5367/ijei.2015.0188
   Wulung RBS, 2014, OPER RES-GER, V14, P409, DOI 10.1007/s12351-014-0148-7
   Yin BQ, 2018, IEEE T ENG MANAGE, V65, P574, DOI 10.1109/TEM.2018.2791501
NR 102
TC 0
Z9 0
U1 6
U2 6
PD JUL 13
PY 2023
VL 29
IS 7
BP 1584
EP 1612
DI 10.1108/IJEBR-06-2022-0527
EA JAN 2023
UT WOS:001040436100001
DA 2023-11-16
ER

PT C
AU Dematties, D
   Thiruvathukal, GK
   Rizzi, S
   Wainselboim, A
   Zanutto, BS
AF Dematties, Dario
   Thiruvathukal, George K.
   Rizzi, Silvio
   Wainselboim, Alejandro
   Zanutto, B. Silvano
BE Foster, I
   Joubert, GR
   Kucera, L
   Nagel, WE
   Peters, F
TI Towards High-End Scalability on Biologically-Inspired Computational
   Models
SO PARALLEL COMPUTING: TECHNOLOGY TRENDS
SE Advances in Parallel Computing
DT Proceedings Paper
CT Conference on Parallel Computing - Technology Trends (ParCo)
CY SEP 10-13, 2019
CL Charles Univ, Prague, CZECH REPUBLIC
HO Charles Univ
DE MPI; OpenMP; Central Processing Units(CPUs); biologically-inspired
   computational models; neuroscience; irregular computation; sparse
   computation
ID 3RD-GENERATION; NETWORKS
AB The interdisciplinary field of neuroscience has made significant progress in recent decades, providing the scientific community in general with a new level of understanding on how the brain works beyond the store-and-fire model found in traditional neural networks. Mean-while, Machine Learning (ML) based on established models has seen a surge of interest in the High Performance Computing (HPC) community, especially through the use of high-end accelerators, such as Graphical Processing Units(GPUs), including HPC clusters of same. In our work, we are motivated to exploit these high-performance computing developments and understand the scaling challenges for newbiologically inspired-learning models on leadership-class HPC resources. These emerging models feature sparse and random connectivity profiles that map to more loosely-coupled parallel architectures with a large number of CPU cores per node. Contrasted with traditional ML codes, these methods exploit loosely-coupled sparse data structures as opposed to tightly-coupled dense matrix computations, which benefit from SIMD-style parallelism found on GPUs. In this paper we introduce a hybrid Message Passing Interface (MPI) and Open Multi-Processing (OpenMP) parallelization scheme to accelerate and scale our computational model based on the dynamics of cortical tissue. We ran computational tests on a leadership class visualization and analysis cluster at Argonne National Laboratory. We include a study of strong and weak scaling, where we obtained parallel efficiency measures with a minimum above 87% and a maximum above 97% for simulations of our biologically inspired neural network on up to 64 computing nodes running 8 threads each. This study shows promise of the MPI+OpenMP hybrid approach to support flexible and biologically-inspired computational experimental scenarios. In addition, we present the viability in the application of these strategies in high-end leadership computers in the future.
C1 [Dematties, Dario; Zanutto, B. Silvano] Univ Buenos Aires, Fac Ingn, Inst Ingn Biomed, Buenos Aires, DF, Argentina.
   [Thiruvathukal, George K.] Loyola Univ Chicago, Dept Comp Sci, Chicago, IL USA.
   [Thiruvathukal, George K.; Rizzi, Silvio] Argonne Natl Lab, Lemont, IL USA.
   [Zanutto, B. Silvano] Consejo Nacl Invest Cient & Tecn, Inst Biol & Med Expt, Buenos Aires, DF, Argentina.
   [Wainselboim, Alejandro] Consejo Nacl Invest Cient & Tecn, Inst Ciencias Humanas Sociales & Ambientales, Ctr Cient Tecnol, Mendoza, Argentina.
RP Dematties, D (corresponding author), Univ Buenos Aires, Fac Ingn, Inst Ingn Biomed, Buenos Aires, DF, Argentina.
CR ABELES M, 1993, J NEUROPHYSIOL, V70, P1629, DOI 10.1152/jn.1993.70.4.1629
   Bair W., 1994, P DYN NEUR PROC INT, P84
   Cooley, ARG LEAD COMP FAC
   Dematties D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217966
   Dinkelbach HÜ, 2012, NETWORK-COMP NEURAL, V23, P212, DOI 10.3109/0954898X.2012.739292
   Ghosh-Dastidar S, 2009, ADV INTEL SOFT COMPU, V61, P167
   Guerguiev J, 2017, ELIFE, V6, DOI 10.7554/eLife.22901
   Hawkins J, 2016, FRONT NEURAL CIRCUIT, V10, DOI 10.3389/fncir.2016.00023
   HODGKIN AL, 1990, B MATH BIOL, V52, P25, DOI 10.1016/S0092-8240(05)80004-7
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Izhikevich EM, 2004, CEREB CORTEX, V14, P933, DOI 10.1093/cercor/bhh053
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Marblestone AH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00094
   MCCULLOCH WS, 1990, B MATH BIOL, V52, P99, DOI 10.1016/S0092-8240(05)80006-0
   Ristov S, 2016, ACSIS-ANN COMPUT SCI, V8, P889, DOI 10.15439/2016F498
   Valiant L. G., 1994, CIRCUITS MIND
NR 17
TC 1
Z9 1
U1 0
U2 1
PY 2020
VL 36
BP 497
EP 506
DI 10.3233/APC200077
UT WOS:000624288400046
DA 2023-11-16
ER

PT C
AU Rheindt, S
   Sabirov, T
   Lenke, O
   Wild, T
   Herkersdorf, A
AF Rheindt, Sven
   Sabirov, Temur
   Lenke, Oliver
   Wild, Thomas
   Herkersdorf, Andreas
GP ACM
TI X-Centric: A Survey on Compute-, Memory- and Application-Centric
   Computer Architectures
SO PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, MEMSYS
   2020
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 28-OCT 01, 2020
CL Washington, DC
DE computer architecture; programming model; architecture evolution;
   memory-centric; application-centric; near-memory computing; survey;
   roofline model; heterogeneous architecture; mobile device
ID CORE ARCHITECTURES; MULTICORE; COHERENCE; TOOLS; DRAM
AB Big Data and machine learning constitute the multifaceted challenge of computer engineering in the past decade. The meaningful processing of vast amounts of unstructured data from a myriad of sensors and devices is a complicated endeavor already. Aggravated by the need to enter the extremely power- and resource-constrained pocket-size mobile domain, the computing as we know it is rapidly evolving. Data-centric in- and near-memory computing, as well as highly heterogeneous accelerator-equipped application-centric architectures, are on the rise to tackle the unsatisfiable demand for evermore compute performance and efficiency.
   To learn from these innovations, this paper surveys compute-, memory-, and application-centric architectures and related programming paradigms and analyzes prominent chances and challenges. The key insights from the particular domains are: 1) The high nominal processing performance of compute-centric systems is thwarted by massively decreasing data-to-task locality and increased data movement. Nevertheless, the commodity of shared-memory programming and the presence of widespread legacy applications keep this domain alive. 2) Memory-centric designs help to mitigate the data locality wall and significantly improve power and performance efficiency. However, a memory-centric programming paradigm is still missing. 3) Heterogeneity, customization, and established ecosystems (like for mobile devices) enable application-centric optimization under often tight thermal, power, and resource constraints. However, a holistic SoC-level design approach is required to utilize and program the diversity of processing units in different application domains efficiently.
   A one-size-fits-all architecture approach seems not in sight because of the wide diversity in domain-specific requirements and constraints. Therefore, established ecosystems, 3D-stacked logic-enhanced memory devices, and commoditized architecture-aware programming models seem fundamental for performant and programmable future-proof computer architectures.
C1 [Rheindt, Sven; Sabirov, Temur; Lenke, Oliver; Wild, Thomas; Herkersdorf, Andreas] Tech Univ Munich, Munich, Germany.
RP Rheindt, S (corresponding author), Tech Univ Munich, Munich, Germany.
EM sven.rheindt@tum.de
CR Advanced MicroDevices Inc, 2015, HIGH BANDW MEM HBM R
   Aladakatti hweta, 2019, EAI ENDORSED IN2020A, V5, P16, DOI [10.4108/eai.5-11-2019.162591, DOI 10.4108/EAI.5-11-2019.162591]
   Aly MMS, 2015, COMPUTER, V48, P24, DOI 10.1109/MC.2015.376
   AMD, 2019, INTR RDNA ARCH
   Amold Oliver, P 2010 INT C EMBEDDE, P116
   AnandTech, 2020, EX 990 SOC LAST CUST
   AnandTech, 2019, SNAPDR 865 PERF PREV
   [Anonymous], 2019, HUAWEI KIRIN 990 SER
   [Anonymous], 2020, AMD RYZEN DESKTOP PR
   [Anonymous], 2017, ARM DYNAMIQ
   [Anonymous], 2019, SNAPDR 865 5G MOB PL
   [Anonymous], 2011, BIGLITTLE PROCESSING
   [Anonymous], 2019, HISILICON KIRIN
   [Anonymous], 2017, ANDROID NEURAL NETWO
   [Anonymous], 2019, INTEL FPGAS DEEP LEA
   [Anonymous], 2018, NVIDIA TITAN RTX
   [Anonymous], 2014, INTEL XEON PHI COPRO
   [Anonymous], 2006, 2006 IEEE ACM INT C, DOI [DOI 10.1109/ICCAD.2006.320067, DOI 10.1145/1233501.1233516]
   [Anonymous], 2019, MEDIATEK DIMENSITY 1
   [Anonymous], 2020, CHAPEL DOCUMENTATION
   [Anonymous], 1996, PARALLEL PROGRAMMING
   [Anonymous], 2019, SAMSUNG EXYNOS 90
   [Anonymous], 2020, AMD RYZEN THREADRIPP
   [Anonymous], 2011, POSIX 10031 1
   Arm, 2018, ACC MOB LAPT PERF AR
   Arm big, 2011, ARM BIG LITTLE
   Asghari-Moghaddam H, 2016, IEEE MICRO, V36, P24, DOI 10.1109/MM.2016.8
   BACKUS J, 1978, COMMUN ACM, V21, P613, DOI 10.1145/359576.359579
   Baczki M, 2011, P 2011 AKIONAL GREEN
   Belikov Evgeni, 2013, SURVEY LIGH LEVEL PA
   Bergman Keren., 2008, 2008 SCALE COMPUTING
   Billet Star., 2008, 2008 MAINAL SOLID ST, P18, DOI [10.1109/ISSCC.2006.1523076, DOI 10.1109/ISSCC.2006.1523076]
   Blake G, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2009.934110
   Boroumand A, 2017, IEEE COMPUT ARCHIT L, V16, P46, DOI 10.1109/LCA.2016.2577557
   Branover A, 2012, IEEE MICRO, V32, P28, DOI 10.1109/MM.2012.2
   Burger D, 1996, 23RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, PROCEEDINGS, P78, DOI 10.1145/232974.232983
   Burger Thomas, 2005, INTEL MULTICORE PROC
   Byn Choi, 2011, Proceedings 2011 International Conference on Parallel Architectures and Compilation Techniques (PACT), P155, DOI 10.1109/PACT.2011.21
   Chai L, 2007, CCGRID 2007: SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P471
   Chen T, 2007, IBM J RES DEV, V51, P559, DOI 10.1147/rd.515.0559
   Chitlur N, 2012, INT S HIGH PERF COMP, P433
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Dally B, 2007, PR IEEE COMP DESIGN, P1
   Damaraju S., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P56, DOI 10.1109/ISSCC.2012.6176876
   De Wael M, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2716320
   dech, 2020, EX 990 SOC LAST CUST
   Dennard R. H., 1968, U.S. Patent, Patent No. 3387286
   Deo Manish, 2016, INTEL STRATIX 10 MX
   Diaz J, 2012, IEEE T PARALL DISTR, V23, P1369, DOI 10.1109/TPDS.2011.308
   Dong XY, 2008, DES AUT CON, P554
   Duran A, 2011, PARALLEL PROCESS LET, V21, P173, DOI 10.1142/S0129626411000151
   Durand Y, 2014, 2014 17TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P206, DOI 10.1109/DSD.2014.15
   Egawa Ryusuke., 2013, 2013 IEEE INT 3D SYS, P1
   Elliott DuncanG, 1992, CUST INT CIRC C, V30, P1
   Endoh T, 2016, IEEE J EM SEL TOP C, V6, P109, DOI 10.1109/JETCAS.2016.2547704
   Falsafi B, 2016, IEEE MICRO, V36, P6, DOI 10.1109/MM.2016.9
   Faraboschi Paolo, 2015, 15 WORKSHOP HOT TOPI
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Feng WC, 2009, COMPUTER, V42, P26, DOI 10.1109/MC.2009.412
   Gabriel H., 2013, PROCESSING IN MEMORY
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Ginsburg D., 2014, OPENGL ES 3 0 PROGRA
   Goslin GR, 1996, P SOC PHOTO-OPT INS, V2914, P321, DOI 10.1117/12.255830
   Halpern M, 2016, INT S HIGH PERF COMP, P64, DOI 10.1109/HPCA.2016.7446054
   Henkel J, 2012, ASIA S PACIF DES AUT, P193, DOI 10.1109/ASPDAC.2012.6164944
   Hill MD, 2019, INT S HIGH PERF COMP, P317, DOI 10.1109/HPCA.2019.00047
   Howard Jason, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P108, DOI 10.1109/ISSCC.2010.5434077
   Hsieh CY, 2019, DES AUT TEST EUROPE, P1265, DOI [10.23919/date.2019.8714970, 10.23919/DATE.2019.8714970]
   Hsieh K, 2016, CONF PROC INT SYMP C, P204, DOI 10.1109/ISCA.2016.27
   Hybrid MemoryCube Consortium, 2014, HYBR MEM CUB SPEC 2
   IBM IDC, 2017, TRANSF HIGH PERF COM
   Ignatov A, 2019, Arxiv, DOI arXiv:1910.06663
   Intel, NVIDIAS NEXT GEN CUD
   Intel CoreProcessor Family, 2020, US
   Intel Corporation, 2018, INT ARR 10 DEV OV
   Intel Corporation, 2020, INT STRAT 10 MX DRAM
   Jayasena Nuwan., 2018, MEMORY CENTRIC ARCHI
   Jiang L, 2010, ICCAD-IEEE ACM INT, P230, DOI 10.1109/ICCAD.2010.5654160
   Jun SW, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P1, DOI 10.1145/2749469.2750412
   Kahle JA, 2005, IBM J RES DEV, V49, P589, DOI 10.1147/rd.494.0589
   Kasim H, 2008, LECT NOTES COMPUT SC, V5245, P266, DOI 10.1007/978-3-540-88140-7_24
   Khronos Group, 2020, VULK OV
   Khronos Group, 2009, OPENCL OV
   Khurshid MJ, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P185, DOI 10.1109/ICCD.2013.6657041
   Kinney W. I., 1987, 1987 International Electron Devices Meeting, IEDM. Technical Digeset (Cat. No.87CH2515-5), P850, DOI 10.1109/IEDM.1987.191567
   Kirk D., 2013, PROGRAMMING MASSIVEL
   Kogge P. M., 1994, Proceedings of the 1994 International Conference on Parallel Processing, P77
   Kogge Peter., 2017, MEMORY INTENSIVE COM
   Kogge PeterM., 1997, WORKSHOP MIXING LOGI, V97
   KRANZ D, 1993, SIGPLAN NOTICES, V28, P54, DOI 10.1145/173284.155338
   Krashinsky Ronny., 2020, NVIDIA AMPERE ARCHIT
   Kumar R, 2005, COMPUTER, V38, P32, DOI 10.1109/MC.2005.379
   Kumar R, 2004, CONF PROC INT SYMP C, P64
   Larsen EScott, 2001, P 2001 ACMIEEE C SUP, P55
   Lee DU, 2014, ISSCC DIG TECH PAP I, V57, P432, DOI 10.1109/ISSCC.2014.6757501
   Liao Heng, 2019, 2019 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875654
   Lin TY, 2016, IEEE HOT CHIP SYMP
   Lotfi-Kamran P, 2012, CONF PROC INT SYMP C, P500, DOI 10.1109/ISCA.2012.6237043
   Martin MMK, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2209249.2209269
   Martin Won S., 2019, INTEL AGILEX FPGAS D
   Matsuyama K, 1997, IEEE T MAGN, V33, P3283, DOI 10.1109/20.617918
   Mattson T.G, 2014, PATTERNS PARALLEL PR
   Minnick RC., 1966, CELLULAR ARRAYS LOGI
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Mittal Sparsh., 2019, SURVEY EVALUATING OP
   Mohr M, 2017, DES AUT TEST EUROPE, P1781, DOI 10.23919/DATE.2017.7927281
   Morales VM, 2014, DES AUT TEST EUROPE, DOI 10.7873/DATE.2014.221
   Motoyoshi M, 2009, P IEEE, V97, P43, DOI 10.1109/JPROC.2008.2007462
   Numrich RW, 1998, SIGPLAN FORTRAN FORU, P1, DOI [DOI 10.1145/289918.289920, 10.1145/289918.289920]
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Patterson D, 1997, ISSCC DIG TECH PAP I, V40, P224, DOI 10.1109/ISSCC.1997.585348
   Patterson DA, 2004, COMMUN ACM, V47, P71, DOI 10.1145/1022594.1022596
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Petersen R. J., 1995, Field-Programmable Logic and Applications. 5th International Workshop, FPL '95. Proceedings, P293
   Pugsley SH, 2014, INT SYM PERFORM ANAL, P190, DOI 10.1109/ISPASS.2014.6844483
   Reddi VJ, 2018, IEEE MICRO, V38, P6, DOI 10.1109/MM.2018.011441560
   Rheindt S, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P3, DOI 10.1145/3357526.3357545
   Saraswat Vijay, 2019, X10 LANGUAGE SPECIFI
   Saulsbury A, 1996, 23RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, PROCEEDINGS, P90, DOI 10.1145/232974.232984
   Schlachter F, 2013, P NATL ACAD SCI USA, V110, P5273, DOI 10.1073/pnas.1302988110
   Shao YS, 2015, IEEE MICRO, V35, P58, DOI 10.1109/MM.2015.50
   Siegl P, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P295, DOI 10.1145/2989081.2989087
   Singh G, 2019, MICROPROCESS MICROSY, V71, DOI 10.1016/j.micpro.2019.102868
   Sodani A, 2016, IEEE MICRO, V36, P34, DOI 10.1109/MM.2016.25
   Sony, 2020, UNV NEW DET PLAY STA
   Sotiriades E, 2007, J VLSI SIG PROC SYST, V48, P189, DOI 10.1007/s11265-007-0069-2
   Srivatsa A, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P286, DOI 10.1109/SOCC.2017.8226059
   STONE HS, 1970, IEEE T COMPUT, VC 19, P73, DOI 10.1109/TC.1970.5008902
   Sze V, 2017, IEEE CUST INTEGR CIR
   Tan C, 2018, CONF PROC INT SYMP C, P575, DOI 10.1109/ISCA.2018.00054
   Tan C, 2018, ACM T EMBED COMPUT S, V17, DOI 10.1145/3122786
   The Economist, 2017, ECONOMIST
   UPC Consortium, 2005, UPC LANG SPEC V1 2, DOI [10.2172/862127, DOI 10.2172/862127]
   Vatajelu EI, 2019, IEEE T EMERG TOP COM, V7, P493, DOI 10.1109/TETC.2017.2691263
   Wentzlaff D, 2007, IEEE MICRO, V27, P15, DOI 10.1109/MM.2007.4378780
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xie Y, 2013, DES AUT TEST EUROPE, P964
   Yan Luxin., 2006, 2006 6 WORLD C INTEL, V2, P10022
   Yelick K, 1998, CONCURRENCY-PRACT EX, V10, P825, DOI 10.1002/(SICI)1096-9128(199809/11)10:11/13<825::AID-CPE383>3.0.CO;2-H
   Yitbarek SF, 2016, DES AUT TEST EUROPE, P1449
   Yuffe M., 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P264, DOI 10.1109/ISSCC.2011.5746311
   Zhan J, 2016, INT SYMP MICROARCH
   Zhang D., 2014, P 23 INT S HIGH PERF, P85
   Zhu YH, 2018, Arxiv, DOI arXiv:1801.06274
NR 146
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 178
EP 193
DI 10.1145/3422575.3422792
UT WOS:001050779500017
DA 2023-11-16
ER

PT J
AU Kuzma, B
   Korostelev, I
   de Carvalho, JPL
   Moreira, JE
   Barton, C
   Araujo, G
   Amaral, JN
AF Kuzma, Braedy
   Korostelev, Ivan
   de Carvalho, Joao P. L.
   Moreira, Jose E.
   Barton, Christopher
   Araujo, Guido
   Amaral, Jose Nelson
TI Fast matrix multiplication via compiler-only layered data reorganization
   and intrinsic lowering
SO SOFTWARE-PRACTICE & EXPERIENCE
DT Article
DE compiler analysis and transformations; GEMM; generating code for
   accelerators; LLVM
ID SOFTWARE
AB The resurgence of machine learning has increased the demand for high-performance basic linear algebra subroutines (BLAS), which have long depended on libraries to achieve peak performance on commodity hardware. High-performance BLAS implementations rely on a layered approach that consists of tiling and packing layers-for data (re)organization-and micro kernels that perform the actual computations. The algorithm for the tiling and packing layers is target independent but is parameterized to the memory hierarchy and register-file size. The creation of high-performance micro kernels requires significant development effort to write tailored assembly code for each architecture. This hand optimization task is complicated by the recent introduction of matrix engines by IBM (R) 's POWER10 (TM) (Matrix Multiply Assist-MMA), Intel (R) (Advanced Matrix eXtensions-AMX), and Arm (R) (Matrix Extensions-ME) to deliver high-performance matrix operations. This article presents a compiler-only alternative to the use of high-performance libraries by incorporating, to the best of our knowledge and for the first time, the automatic generation of the layered approach into LLVM, a production compiler. Modular design of the algorithm, such as the use of LLVM's matrix-multiply intrinsic for a clear interface between the tiling and packing layers and the micro kernel, makes it easy to retarget the code generation to multiple accelerators. The parameterization of the tiling and packing layers is demonstrated in the generation of code for the MMA unit on IBM's POWER10. This article also describes an algorithm that lowers the matrix-multiply intrinsic to the MMA unit. The use of intrinsics enables a comprehensive performance study. In processors without hardware matrix engines, the tiling and packing delivers performance up to 22x (Intel)-for small matrices-and more than 6x (POWER9)-for large matrices-faster than PLuTo, a widely used polyhedral optimizer. The performance also approaches high-performance libraries and is only 34% slower than OpenBLAS and on-par with Eigen for large matrices. With MMA in POWER10 this solution is, for large matrices, over 2.6x faster the vector-extension solution, matches Eigen performance, and achieves up to 96% of BLAS peak performance.
C1 [Kuzma, Braedy; Korostelev, Ivan; de Carvalho, Joao P. L.; Amaral, Jose Nelson] Univ Alberta, Comp Sci Dept, Edmonton, AB, Canada.
   [Moreira, Jose E.] IBM Corp, Thomas J Watson Res Ctr, New York, NY USA.
   [Barton, Christopher] IBM Corp, IBM Canada Software Lab, Markham, ON, Canada.
   [Araujo, Guido] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
   [de Carvalho, Joao P. L.] Univ Alberta, Comp Sci Dept, 8900 114 St NW, Edmonton, AB, Canada.
RP de Carvalho, JPL (corresponding author), Univ Alberta, Comp Sci Dept, 8900 114 St NW, Edmonton, AB, Canada.
EM joao.carvalho@ualberta.ca
CR Alappat Christie L., 2020, High Performance Computing. 35th International Conference, ISC High Performance 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12151), P412, DOI 10.1007/978-3-030-50743-5_21
   [Anonymous], 2018, NVIDIA TENSOR CORE P
   Arm Limited, 2021, ARM ARCHITECTURE REF
   BARNES GH, 1968, IEEE T COMPUT, VC 17, P746, DOI 10.1109/TC.1968.229158
   Bhat Puneeth, 2021, MATRIX MULTIPLY ASSI
   Bondhugula U., 2020, HIGH PERFORMANCE COD
   Bondhugula U, 2008, LECT NOTES COMPUT SC, V4959, P132
   dJPL C., 2021, ACM T ARCHIT CODE OP, V18
   Domke J., 2021, MATRIX ENGINES HIGH
   Fatahalian K., 2004, UNDERSTANDING EFFICI, P133
   Gareev R, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3235029
   Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053
   Grosser T, 2012, PARALLEL PROCESS LET, V22, DOI 10.1142/S0129626412500107
   Guennebaud G., EIGEN V3 2010
   HAN D, 2019, DISTME FAST ELASTIC, P759
   Hassana SA, 2016, MICROPROCESS MICROSY, V47, P369, DOI 10.1016/j.micpro.2016.10.002
   Hemeida AM, 2020, AIN SHAMS ENG J, V11, P1179, DOI 10.1016/j.asej.2020.01.003
   IBM, 2020, POWER ISA VERSION 31
   IBM Corporation, 2020, POWER ISA VERSION 31
   Intel Corporation, 2021, INTEL ARCHITECTURE I
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KUCK DJ, 1968, IEEE T COMPUT, VC 17, P758, DOI 10.1109/TC.1968.229159
   Larsen ES., 2001, FAST MATRIX MULTIPLI, P55
   LI J, 2011, STRASSENS MATRIX MUL, P157
   Liao H., 2019, DAVINCI SCALABLE ARC, P1
   Low TM, 2016, ACM T MATH SOFTWARE, V43, DOI 10.1145/2925987
   Nath R, 2011, LECT NOTES COMPUT SC, V6449, P83, DOI 10.1007/978-3-642-19328-6_10
   Poenaru A, 2020, LECT NOTES COMPUT SC, V12247, P98, DOI 10.1007/978-3-030-57675-2_7
   QIN E, 2020, SIGMA SPARSE IRREGUL, P58, DOI 10.1109/HPCA47549.2020.00015
   Salvador Rohwedder C., 2023, PACK NOT PACK GEN PA, P14
   Starke WJ, 2021, IEEE MICRO, V41, P7, DOI 10.1109/MM.2021.3058632
   van de Geijn R., 2011, ENCY PARALLEL COMPUT, P157
   Van Zee FG, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2764454
   Vasudevan A, 2017, IEEE INT CONF ASAP, P19, DOI 10.1109/ASAP.2017.7995254
   Waugh H., 2020, SMOKY MOUNTAINS COMP, P67
   Whaley RC, 2001, PARALLEL COMPUT, V27, P3, DOI 10.1016/S0167-8191(00)00087-9
   XIANYI Z, 2012, MODEL DRIVEN LEVEL 3, P684, DOI 10.1109/ICPADS.2012.97
NR 37
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 53
IS 9
BP 1793
EP 1814
DI 10.1002/spe.3214
EA MAY 2023
UT WOS:000988585200001
DA 2023-11-16
ER

PT C
AU Wang, BY
   Deng, L
   Sun, F
   Dai, GH
   Liu, L
   Wang, Y
   Xie, Y
AF Wang, Bangyan
   Deng, Lei
   Sun, Fei
   Dai, Guohao
   Liu, Liu
   Wang, Yu
   Xie, Yuan
BE Falsafi, B
   Ferdman, M
   Lu, S
   Weinisch, T
TI A One-for-All and <i>O</i>(<i>V</i> log(<i>V</i>))-Cost Solution for
   Parallel Merge Style Operations on Sorted Key-Value Arrays
SO ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON
   ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 27th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY FEB 28-MAR 04, 2022
CL Lausanne, SWITZERLAND
DE SIMD; Key-value array; Sparse linear algebra; SpGEMM; Merge sort; Graph;
   Join
ID SIMD
AB The processing of sorted key-value arrays using a "merge style operation (MSO)" is a very basic and important problem in domains like scientific computing, deep learning, database, graph analysis, sorting, set-operation etc. MSOs dominate the execution time in some important applications like SpGEMM and graph mining. For example, sparse vector addition as an MSO takes up to 98% execution time in SpGEMM in our experiment. For this reason, accelerating MSOs on CPU, GPU, and accelerators using parallel execution has been extensively studied but the solutions in prior work have three major limitations. (1) They treat different MSOs as isolated problems using incompatible methods and an unified solution is still lacking. (2) They do not have the flexibility to support variable key/value sizes and value calculations in the runtime given a fixed hardware design. (3) They require a quadratic hardware cost (O(V-2)) for given parallelism V in most cases.
   To address above three limitations, we make the following efforts. (1) We present a one-for-all solution to support all interested MSOs based on a unified abstraction model "restricted zip machine (RZM)". (2) We propose a set of composable and parallel primitives for RZM to provide the flexibility to support variable key/value sizes and value calculations. (3) We provide the hardware design to implement the proposed primitives using only O(V log(V)) resource. With the above techniques, a flexible and efficient solution for MSOs has been built. Our design can be used either as a drop-in replacement of the merge unit in prior accelerators to reduce the cost from O(V-2) to O(V log(V)), or as an extension to the SIMD ISA of CPU and GPU. In our evaluation on CPU, when V = 16 (512-bit SIMD, 32-bit element), we achieve significant speedup on a range of representative kernels including set operations (8.4x), database joins (7.3x), sparse vector/matrix/tensor addition/multiplication on real/complex numbers (6.5x), merge sort (8.0x over scalar, 3.4x over the state-of-the-art SIMD), and SpGEMM (4.4x over the best one in the baseline collection).
C1 [Wang, Bangyan; Liu, Liu; Xie, Yuan] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
   [Deng, Lei; Dai, Guohao; Wang, Yu] Tsinghua Univ, Beijing, Peoples R China.
   [Sun, Fei] Alibaba DAMO Acad, Hangzhou, Peoples R China.
RP Wang, BY (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
EM wangbangyan@gmail.com; leideng@mail.tsinghua.edu.cn;
   f.sun@alibaba-inc.com; daiguohao@mail.tsinghua.edu.cn; liuliu@ucsb.edu;
   yu-wang@tsinghua.edu.cn; yuanxie@ucsb.edu
CR [Anonymous], FLEXMINER PATTERN AW
   [Anonymous], INTEL INTRINSICS GUI
   [Anonymous], EIGEN IS C TEMPLATE
   Batcher K. E., 1968, AFIPS CONF P, P307, DOI [10.1145/1468075.1468121, DOI 10.1145/1468075.1468121]
   Berenger Bramas, 2021, PEERJ COMPUT SCI, DOI DOI 10.7717/PEERJ-CS.769
   Casper J., 2014, P 2014 ACMSIGDA INT, P151, DOI [10.1145/2554688.2554787, DOI 10.1145/2554688.2554787]
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Guowei Zhang, 2021, ASPLOS 2021: Proceedings of the 26th International Conference on Architectural Support for Programming Languages and Operating Systems, P687, DOI 10.1145/3445814.3446702
   Han S, 2018, INT CONF MANAGE DATA, P1587, DOI 10.1145/3183713.3196924
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hojabr R, 2021, INT S HIGH PERF COMP, P84, DOI 10.1109/HPCA51647.2021.00017
   Inoue H, 2014, PROC VLDB ENDOW, V8, P293, DOI 10.14778/2735508.2735518
   Inoue H, 2015, PROC VLDB ENDOW, V8, P1274, DOI 10.14778/2809974.2809988
   Kim CK, 2009, PROC VLDB ENDOW, V2, P1378, DOI 10.14778/1687553.1687564
   Nagasaka Y, 2018, INT CONF PARA PROC, DOI 10.1145/3229710.3229720
   Pavon Julian, 2021 IEEE INT S HIGH, P921, DOI [10.1109/HPCA51, DOI 10.1109/HPCA51]
   Ryu Sungju, SPRITE SPARSITY AWAR
   Satish Nadathur, P 2010 ACM SIGMOD IN, P351
   Schlegel Benjamin, FAST SORTED SET INTE
   Srivastava N, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P766, DOI 10.1109/MICRO50266.2020.00068
   Vonarburg-Shmaria zur, GRAPHMINESUITE ENABL
   Zhang J.F., C24 4 SNAP 167 S 215
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
NR 24
TC 0
Z9 0
U1 0
U2 2
PY 2022
BP 669
EP 682
DI 10.1145/3503222.3507728
UT WOS:000810486300047
DA 2023-11-16
ER

PT J
AU Rybalkin, V
   Sudarshan, C
   Weis, C
   Lappas, J
   Wehn, N
   Cheng, L
AF Rybalkin, Vladimir
   Sudarshan, Chirag
   Weis, Christian
   Lappas, Jan
   Wehn, Norbert
   Cheng, Li
TI Efficient Hardware Architectures for 1D-and MD-LSTM Networks
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Long short-term memory; LSTM; MD-LSTM; 2D-LSTM; FPGA; DRAM;
   Processing-in-memory; PIM; Optical character recognition; OCR; MNIST;
   DIBCO; Zynq; Image binarization; Hardware architecture; Deep learning
ID NEURAL-NETWORK; MEMORY
AB Recurrent Neural Networks, in particular One-dimensional and Multidimensional Long Short-Term Memory (1D-LSTM and MD-LSTM) have achieved state-of-the-art classification accuracy in many applications such as machine translation, image caption generation, handwritten text recognition, medical imaging and many more. However, high classification accuracy comes at high compute, storage, and memory bandwidth requirements, which make their deployment challenging, especially for energy-constrained platforms such as portable devices. In comparison to CNNs, not so many investigations exist on efficient hardware implementations for 1D-LSTM especially under energy constraints, and there is no research publication on hardware architecture for MD-LSTM. In this article, we present two novel architectures for LSTM inference: a hardware architecture for MD-LSTM, and a DRAM-based Processing-in-Memory (DRAM-PIM) hardware architecture for 1D-LSTM. We present for the first time a hardware architecture for MD-LSTM, and show a trade-off analysis for accuracy and hardware cost for various precisions. We implement the new architecture as an FPGA-based accelerator that outperforms NVIDIA K80 GPU implementation in terms of runtime by up to 84x and energy efficiency by up to 1238x for a challenging dataset for historical document image binarization from DIBCO 2017 contest, and a well known MNIST dataset for handwritten digits recognition. Our accelerator demonstrates highest accuracy and comparable throughput in comparison to state-of-the-art FPGA-based implementations of multilayer perceptron for MNIST dataset. Furthermore, we present a new DRAM-PIM architecture for 1D-LSTM targeting energy efficient compute platforms such as portable devices. The DRAM-PIM architecture integrates the computation units in a close proximity to the DRAM cells in order to maximize the data parallelism and energy efficiency. The proposed DRAM-PIM design is 16.19 x more energy efficient as compared to FPGA implementation. The total chip area overhead of this design is 18 % compared to a commodity 8 Gb DRAM chip. Our experiments show that the DRAM-PIM implementation delivers a throughput of 1309.16 GOp/s for an optical character recognition application.
C1 [Rybalkin, Vladimir; Sudarshan, Chirag; Weis, Christian; Lappas, Jan; Wehn, Norbert] Tech Univ Kaiserslautern, Kaiserslautern, Germany.
   [Cheng, Li] Huawei Technol Co Ltd, Chengdu, Peoples R China.
RP Rybalkin, V (corresponding author), Tech Univ Kaiserslautern, Kaiserslautern, Germany.
EM rybalkin@eit.uni-kl.de; sudarshan@eit.uni-kl.de; weis@eit.uni-kl.de;
   lappas@eit.uni-kl.de; wehn@eit.uni-kl.de; licheng56@huawei.com
CR Afzal Muhammad Zeshan, 2015, P 3 INT WORKSH HIST, P79, DOI DOI 10.1145/2809544.280956
   Agrawal A, 2019, IEEE T CIRCUITS-I, V66, P3064, DOI 10.1109/TCSI.2019.2907488
   Alemdar H, 2017, IEEE IJCNN, P2547, DOI 10.1109/IJCNN.2017.7966166
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], ARXIV150701526
   [Anonymous], 2018, ARXIV180200150
   Breuel T. M., 2015, ARXIV PREPRINT ARXIV
   BYEON W, 2015, PROC CVPR IEEE, P3547, DOI DOI 10.1109/CVPR.2015.7298977
   Chen XZ, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P133, DOI 10.1145/3287624.3287640
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choe J., 2017, SAMSUNG 18 NM DRAM C
   Choe J., 2018, MICRONS 1X DRAMS EXA
   Choe J., 2017, SK HYNIX 21 NM DRAM
   Davidson B, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26350-3
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Glorot X., 2010, P 13 INT C ARTIFICIA, P249
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2007, LECT NOTES COMPUT SC, V4668, P549
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou Lu, 2016, ICLR
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jiang LY, 2017, J SENSORS, V2017, DOI 10.1155/2017/5757125
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kowsari K, 2018, 2ND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2018), P19, DOI 10.1145/3206098.3206111
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leifert G, 2016, J MACH LEARN RES, V17
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu RQ, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/5920608
   Long Y, 2018, IEEE T VLSI SYST, V26, P2781, DOI 10.1109/TVLSI.2018.2819190
   Long Y, 2016, IEEE IJCNN, P939, DOI 10.1109/IJCNN.2016.7727299
   Mathuriya A., 2019, MEMORY ANALOG NEURAL
   Moysset B., 2018, ARXIV181110899
   Naji O, 2015, PROCEEDINGS INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS - ARCHITECTURES, MODELING AND SIMULATION (SAMOS XV), P149, DOI 10.1109/SAMOS.2015.7363670
   Ngah S., 2016, ARPN J ENG APPL SCI
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Pratikakis I, 2017, PROC INT CONF DOC, P1395, DOI 10.1109/ICDAR.2017.228
   Puigcerver J, 2017, PROC INT CONF DOC, P67, DOI 10.1109/ICDAR.2017.20
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Rybalkin V, 2017, DES AUT TEST EUROPE, P1390, DOI 10.23919/DATE.2017.7927210
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Stollenga M. F., 2015, ADV NEURAL INFORM PR, V2, P2998
   Sudarshan C, 2019, IEEE INT SYMP CIRC S
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.48, 10.1109/ICFHR.2016.0052]
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Wenniger G.M.D.B., 2019, ARXIV190211208
   Yu SM, 2016, INT EL DEVICES MEET
   Zhou Shuchang, 2016, ARXIV160606160
NR 57
TC 8
Z9 8
U1 1
U2 14
PD NOV
PY 2020
VL 92
IS 11
SI SI
BP 1219
EP 1245
DI 10.1007/s11265-020-01554-x
EA JUL 2020
UT WOS:000545070500001
DA 2023-11-16
ER

PT J
AU Wang, Y
   Zhang, QN
   Han, D
   Li, YJ
AF Wang Yi
   Zhang Qiu-Nan
   Han Dong
   Li Yuan-Jing
TI Time of flight technology based on multi-gap resistive plate chamber
SO ACTA PHYSICA SINICA
DT Article
DE multi-gap resistive plate chamber; time resolution; slewing correction;
   machine learning; pulse shape sampling
AB Particle identification is very important in nuclear and particle physics experiments. Time of flight system (TOF) plays an important role in particle identification such as the separation of pion, kaon and proton. Multi-gap resistive plate chamber (MRPC) is a new kind of avalanche gas detector and it has excellent time resolution power. The intrinsic time resolution of narrow gap MRPC is less than 10 ps. So the MRPC technology TOF system is widely used in modern physics experiments for particle identification. With the increase of accelerator energy and luminosity, the TOF system is required to indentify definite particles precisely under high rate environment. The MRPC technology TOF system can be defined as three generations according to the timing and rate requirement. The first-generation TOF is based on the float glass MRPC and its time resolution is around 80 ps, but the rate is relatively low (typically lower than 100 Hz/cm(2)). The typical systems are TOF of RHIC-STAR, LHC-ALICE and BES III endcap. For the second-generation TOF, its time resolution has the same order as that for the first generation, but the rate capability is much higher. Its rate capability can reach 30 kHz/cm(2). The typical experiment with this high rate TOF is FAIR-CBM. The biggest challenge is in the third-generation TOF. For example, the momentum upper limit of K/pi separation is around 7 GeV/c for JLab-SoLID TOF system under high particle rate as high as 20 kHz/cm(2), and the time requirement is around 20 ps. The readout electronics of first two generations is based on time over threshold method, and pulse shape sampling technology will be used in the third-generation TOF. In the same time, the machine learning technology LSTM network is also used to analyze the time performance. As a very successful sample, MRPC barrel TOF has been used in RHIC-STAR for more than ten years and many important physics results have been obtained. A prominent result is the observation of antimatter helium-4 nucleus. This discovery proves the existence of antimatter in the early universe. In this paper, we will describe the evolution of MRPC TOF technology and key technology of each generation of TOFs including MRPC detector and related electronics. The industrial and medical usage of MRPC are also introduced in the work finally.
C1 [Wang Yi; Zhang Qiu-Nan; Han Dong; Li Yuan-Jing] Tsinghua Univ, Dept Engn Phys, Key Lab Particle & Radiat Imaging, Minist Educ, Beijing 100084, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, Dept Engn Phys, Key Lab Particle & Radiat Imaging, Minist Educ, Beijing 100084, Peoples R China.
EM yiwang@mail.tsinghua.edu.cn
CR Abbrescia M, 2018, RESISTIVE GASEOUS DE, P234
   Acosta D, 2004, NUCL INSTRUM METH A, V518, P605, DOI 10.1016/j.nima.2003.11.097
   Agakishiev H, 2011, NATURE, V473, P353, DOI 10.1038/nature10079
   Akindinov A, 2000, NUCL INSTRUM METH A, V456, P16, DOI 10.1016/S0168-9002(00)00954-2
   Anghinolfi F, 2004, IEEE T NUCL SCI, V51, P1974, DOI 10.1109/TNS.2004.836048
   Boine-Frankenheim O., 2010, P INT PART ACC C WEY, P2430
   Cebra D, 2016, ARXIV160905102NUCLEX
   CIOBANU M, 2008, IEEE NUCL SCI S, P2018
   Couceiro M, 2007, NUCL INSTRUM METH A, V580, P915, DOI 10.1016/j.nima.2007.06.099
   Deppner I, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/10/C10014
   Eric O, 2013, ARXIV13094397V1PHYSI
   Flemming H, GSI EVENT DRIVEN TDC, DOI [10.15120/GR-2014-1-FG-CS-11/[2018-12-13], DOI 10.15120/GR-2014-1-FG-CS-11/[2018-12-13]]
   Gao H, 2011, EUR PHYS J PLUS, V126, DOI 10.1140/epjp/i2011-11002-4
   Guida R, 2019, 15 VIENN C INSTR VIE
   Hohne C, 2016, POS, P272
   Ritt S., 2008, 2008 IEEE NUCL SCI S, P1512, DOI DOI 10.1109/NSSMIC.2008.4774700
   Shao M, 2002, NUCL INSTRUM METH A, V492, P344, DOI 10.1016/S0168-9002(02)01355-4
   Wang F Y, 2018, ARXIV181202912V2PHYS
   Wang F Y, 2018, ARXIV180502833PHYSIC
   Wang J, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/11/C11008
   Wang J., 2013, THESIS
   Wang JB, 2013, NUCL INSTRUM METH A, V713, P40, DOI 10.1016/j.nima.2013.02.036
   Wang JB, 2010, NUCL INSTRUM METH A, V621, P151, DOI 10.1016/j.nima.2010.04.056
   Wang JH, 2011, IEEE T NUCL SCI, V58, P2011, DOI 10.1109/TNS.2011.2158551
   Wang Y, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/08/C08007
   Wang Y, 2010, NUCL INSTRUM METH A, V613, P200, DOI 10.1016/j.nima.2009.11.045
   Williams MCS, 1998, NUCL PHYS B, P250, DOI 10.1016/S0920-5632(97)00570-7
   Wu J, 2005, NUCL INSTRUM METH A, V538, P243, DOI 10.1016/j.nima.2004.08.105
NR 28
TC 0
Z9 0
U1 0
U2 3
PD MAY 20
PY 2019
VL 68
IS 10
AR 102901
DI 10.7498/aps.68.20182192
UT WOS:000470257800005
DA 2023-11-16
ER

PT J
AU Friedrich, F
   Hörner-Rieber, J
   Renkamp, CK
   Kluter, S
   Bachert, P
   Ladd, ME
   Knowles, BR
AF Friedrich, Florian
   Hoerner-Rieber, Juliane
   Renkamp, C. Katharina
   Kluter, Sebastian
   Bachert, Peter
   Ladd, Mark E.
   Knowles, Benjamin R.
TI Stability of conventional and machine learning-based tumor
   auto-segmentation techniques using undersampled dynamic radial bSSFP
   acquisitions on a 0.35 T hybrid MR-linac system
SO MEDICAL PHYSICS
DT Article
DE auto-segmentation; golden-angle; machine learning; MR-linac; tumor
   tracking
ID LUNG-CANCER; CINE MRI; TRACKING; RECONSTRUCTION; MOTION; RADIOTHERAPY;
   THERAPY; NETWORK; SENSE; FIELD
AB Purpose: Hybrid MRI-linear accelerator systems (MR-linacs) allow for the incorporation of MR images with high soft-tissue contrast into the radiation therapy procedure prior to, during, or post irradiation. This allows not only for the optimization of the treatment planning, but also for real-time monitoring of the tumor position using cine MRI, from which intrafractional motion can be compensated. Fast imaging and accurate tumor tracking are crucial for effective compensation. This study investigates the application of cine MRI with a radial acquisition scheme on a low-field MR-linac to accelerate the acquisition rate and evaluates the effect on tracking accuracy.
   Methods: An MR sequence using tiny golden-angle radial k-space sampling was developed and applied to cine imaging on patients with liver tumors on a 0.35 T MR-linac.
   Tumor tracking was assessed for accuracy and stability from the cine images with increasing k-space undersampling factors. Tracking was achieved using two different auto-segmentation algorithms: a deformable image registration B-spline similar to that implemented on the MR-linac and a convolutional neural network approach known as U-Net.
   Results: Radial imaging allows for increased temporal resolution with reliable tumor tracking, although tracking robustness decreases as temporal resolution increases. Additional acquisition-based artifacts can be avoided by reducing the angle increment using tiny golden-angles. The U-net algorithm was found to have superior auto-segmentation metrics compared to B-spline. U-net was able to track two well-defined tumors, imaged with just 30 spokes per image (10.6 frames per second), with an average Dice coefficient >= 83%, Hausdorff distance <= 1.4 pixel, and mean contour distance <= 0.5 pixel.
   Conclusions: Radial acquisitions are commonplace in dynamic imaging; however, in MR-guided radiotherapy, robust tumor tracking is also required. This study demonstrates the in vivo feasibility of tumor tracking from radially acquired images on a low-field MR-linac. Radial imaging allows for decreased image acquisition times while maintaining robust tracking. The U-net algorithm can track a tumor with higher accuracy in images with undersampling artifacts than a conventional deformable B-spline algorithm and is a promising tool for tracking in MR-guided radiation therapy.
C1 [Friedrich, Florian; Bachert, Peter; Ladd, Mark E.; Knowles, Benjamin R.] German Canc Res Ctr, Div Med Phys Radiol, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.
   [Friedrich, Florian; Bachert, Peter; Ladd, Mark E.] Heidelberg Univ, Fac Phys & Astron, Neuenheimer Feld 226, D-69120 Heidelberg, Germany.
   [Hoerner-Rieber, Juliane; Renkamp, C. Katharina; Kluter, Sebastian] Univ Hosp Heidelberg, Dept Radiat Oncol, Neuenheimer Feld 400, D-69120 Heidelberg, Germany.
   [Hoerner-Rieber, Juliane; Renkamp, C. Katharina; Kluter, Sebastian] Heidelberg Inst Radiat Oncol HIRO, Neuenheimer Feld 400, D-69120 Heidelberg, Germany.
   [Hoerner-Rieber, Juliane; Renkamp, C. Katharina; Kluter, Sebastian] Natl Ctr Radiat Res Oncol NCRO, Neuenheimer Feld 400, D-69120 Heidelberg, Germany.
   [Hoerner-Rieber, Juliane] German Canc Res Ctr, Clin Cooperat Unit Radiat, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.
   [Ladd, Mark E.] Heidelberg Univ, Fac Med, Neuenheimer Feld 672, D-69120 Heidelberg, Germany.
RP Knowles, BR (corresponding author), German Canc Res Ctr, Div Med Phys Radiol, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.
EM b.knowles@dkfz-heidelberg.de
CR Bourque AE, 2016, MED PHYS, V43, P5161, DOI 10.1118/1.4961403
   Brix L, 2014, MED PHYS, V41, DOI 10.1118/1.4867859
   Bruijnen T, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/aafd6b
   Cerviño LI, 2011, PHYS MED BIOL, V56, P3773, DOI 10.1088/0031-9155/56/13/003
   Crijns SPM, 2012, PHYS MED BIOL, V57, P7863, DOI 10.1088/0031-9155/57/23/7863
   Fast MF, 2017, RADIOTHER ONCOL, V125, P485, DOI 10.1016/j.radonc.2017.09.013
   Friedrich F, 2019, P 27 ANN M ISMRM MON
   GLOVER GH, 1992, MAGNET RESON MED, V28, P275, DOI 10.1002/mrm.1910280209
   Griswold MA, 2002, MAGN RESON MED, V47, P1202, DOI 10.1002/mrm.10171
   Hammernik K, 2018, MAGN RESON MED, V79, P3055, DOI 10.1002/mrm.26977
   Isensee F., 2018, ARXIV
   Leiner L, 2018, P 26 ANN M ISMRM
   Leiner L, 2017, PLANUNG UMSETZUNG PH
   Lim-Reinders S, 2017, INT J RADIAT ONCOL, V99, P994, DOI 10.1016/j.ijrobp.2017.04.023
   Mazur TR, 2016, MED PHYS, V43, P279, DOI 10.1118/1.4938096
   McKibben N, PYTHON PACKAGE PYGRA
   Menten MJ, 2016, RADIOTHER ONCOL, V119, P461, DOI 10.1016/j.radonc.2016.04.019
   Mutic S, 2014, SEMIN RADIAT ONCOL, V24, P196, DOI 10.1016/j.semradonc.2014.02.008
   Niebergall A, 2013, MAGN RESON MED, V69, P477, DOI 10.1002/mrm.24276
   Ong F, PYTHON PACKAGE SIGPY
   Paganelli C, 2015, PHYS MED BIOL, V60, P7165, DOI 10.1088/0031-9155/60/18/7165
   Park JM, 2016, RADIOTHER ONCOL, V120, P279, DOI 10.1016/j.radonc.2016.06.013
   Peters DC, 2000, MAGNET RESON MED, V43, P91, DOI 10.1002/(SICI)1522-2594(200001)43:1<91::AID-MRM11>3.0.CO;2-4
   Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S
   Pruessmann KP, 2001, MAGNET RESON MED, V46, P638, DOI 10.1002/mrm.1241
   RASCHE V, 1995, MAGNET RESON MED, V34, P754, DOI 10.1002/mrm.1910340515
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schaeffter T, 2001, MAGNET RESON MED, V46, P1238, DOI 10.1002/mrm.1322
   Scheffler K, 2003, EUR RADIOL, V13, P2409, DOI 10.1007/s00330-003-1957-x
   Shekhar R, 2007, MED PHYS, V34, P3054, DOI 10.1118/1.2740467
   Shi XT, 2014, MED PHYS, V41, DOI 10.1118/1.4870978
   Shirato H, 2000, INT J RADIAT ONCOL, V48, P1187, DOI 10.1016/S0360-3016(00)00748-3
   Stanisz GJ, 2005, MAGNET RESON MED, V54, P507, DOI 10.1002/mrm.20605
   Sterzing F, 2011, DTSCH ARZTEBL INT, V108, P274, DOI 10.3238/arztebl.2011.0274
   Tryggestad E, 2013, MED PHYS, V40, DOI 10.1118/1.4818656
   Uecker M, 2014, MAGN RESON MED, V71, P990, DOI 10.1002/mrm.24751
   Verellen D, 2007, NAT REV CANCER, V7, P949, DOI 10.1038/nrc2288
   Winkelmann S, 2007, IEEE T MED IMAGING, V26, P68, DOI 10.1109/TMI.2006.885337
   Wundrak S, 2015, IEEE T MED IMAGING, V34, P1262, DOI 10.1109/TMI.2014.2382572
   Yan D, 1997, PHYS MED BIOL, V42, P123, DOI 10.1088/0031-9155/42/1/008
   Yun JY, 2013, MED PHYS, V40, DOI 10.1118/1.4802735
   Yun JY, 2012, MED PHYS, V39, P4423, DOI 10.1118/1.4730294
   Zhan ZF, 2016, IEEE T BIO-MED ENG, V63, P1850, DOI 10.1109/TBME.2015.2503756
   Zhang QH, 2007, MED PHYS, V34, P4772, DOI 10.1118/1.2804576
NR 44
TC 9
Z9 9
U1 1
U2 3
PD FEB
PY 2021
VL 48
IS 2
BP 587
EP 596
DI 10.1002/mp.14659
EA JAN 2021
UT WOS:000605987600001
DA 2023-11-16
ER

PT J
AU Yousuf, O
   Hossen, I
   Daniels, MW
   Lueker-Boden, M
   Dienstfrey, A
   Adam, GC
AF Yousuf, Osama
   Hossen, Imtiaz
   Daniels, Matthew W.
   Lueker-Boden, Martin
   Dienstfrey, Andrew
   Adam, Gina C.
TI Device Modeling Bias in ReRAM-Based Neural Network Simulations
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Hardware neural networks; ReRAM; memristors; device modeling; modeling
   bias
ID MEMORY
AB Emerging technologies based on resistive switching (ReRAM) devices promise to improve the speed and energy efficiency of next generation machine learning accelerators, but further research is required for achieving commercial maturity. System-level prototyping with emerging devices is costly, and algorithmic investigations require hardware neural network modeling which often deviates from experimental reality. In this work, the concept of modeling bias is proposed as a way to quantify this deviation and support reliable evaluation of device populations in the context of neural network algorithms. While applicable to other device modeling techniques, modeling bias is investigated here using jump tables - a promising physics-less technique to model emerging memory devices for hardware networks. Questions about the fidelity of these tables in relation to stochastic device behavior are answered. Two methods of jump table modeling - binning and a novel Optuna-optimized binning - are explored using synthetic data with known distributions for benchmarking and experimental data obtained from TiOx ReRAM devices for practical testing. Novel device metrics are proposed, and it is shown that these metrics can present crucial insights on the device population prior to training the hardware network. Results on a multi-layer perceptron trained on MNIST show that device models based on binning deviate from target network accuracy at a low number of points and high switching noise in the device dataset. The proposed approach opens the possibility for device-algorithm co-design investigations into statistical device models with better performance, as well as experimentally verified modeling bias in different in-memory computing and neural network architectures.
C1 [Yousuf, Osama; Hossen, Imtiaz; Adam, Gina C.] George Washington Univ, Elect & Comp Engn Dept, Washington, DC 20052 USA.
   [Daniels, Matthew W.] NIST, Gaithersburg, MD 20899 USA.
   [Lueker-Boden, Martin] Western Digital Technol, San Jose, CA 95119 USA.
   [Dienstfrey, Andrew] NIST, Boulder, CO 80305 USA.
RP Adam, GC (corresponding author), George Washington Univ, Elect & Comp Engn Dept, Washington, DC 20052 USA.
EM ginaadam@gwu.edu
CR Abbaspour E, 2020, J COMPUT ELECTRON, V19, P1426, DOI 10.1007/s10825-020-01537-y
   Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Aldana S, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/ab7bb6
   Ambrosi E, 2019, FARADAY DISCUSS, V213, P87, DOI 10.1039/c8fd00106e
   Bengel C, 2020, IEEE T CIRCUITS-I, V67, P4618, DOI 10.1109/TCSI.2020.3018502
   Bersuker G, 2011, J APPL PHYS, V110, DOI 10.1063/1.3671565
   Bose P., 2011, ENCY PARALLEL COMPUT, P1593, DOI [10.1007/978-0-387-09766-4_499, DOI 10.1007/978-0-387-09766-4_499]
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Channamadhavuni S., 2021, GLSVLSI, P379, DOI DOI 10.1145/3453688.3461746
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Dalgaty T, 2021, NAT ELECTRON, V4, P151, DOI 10.1038/s41928-020-00523-3
   Deng L., 2012, IEEE SIGNAL PROC MAG, V29, P141, DOI [DOI 10.1109/MSP.2012.2211477, 10.1109/MSP.2012.2211477]
   Gao YM, 2023, IEEE T PATTERN ANAL, V45, P7019, DOI 10.1109/TPAMI.2020.3025062
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   González-Cordero G, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/11/115013
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   Hoskins B., 2021, P INT C NEUR SYST KN, P1, DOI [10.1145/3477145, DOI 10.1145/3477145]
   Hossen I, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09556-4
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Ielmini D, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/25/254022
   INMAN HF, 1989, COMMUN STAT THEORY, V18, P3851, DOI 10.1080/03610928908830127
   Laborieux A, 2020, Arxiv, DOI arXiv:2007.14234
   Luo YCA, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329062
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Menzel S, 2017, J COMPUT ELECTRON, V16, P1017, DOI 10.1007/s10825-017-1051-2
   Niroula J, 2017, J COMPUT ELECTRON, V16, P1144, DOI 10.1007/s10825-017-1107-3
   Padovani A, 2017, J APPL PHYS, V121, DOI 10.1063/1.4979915
   Park SO, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30539-6
   Paszke A, 2019, ADV NEUR IN, V32
   PEACOCK JA, 1983, MON NOT R ASTRON SOC, V202, P615, DOI 10.1093/mnras/202.3.615
   Sidler S, 2016, PROC EUR S-STATE DEV, P440, DOI 10.1109/ESSDERC.2016.7599680
   Stathopoulos S, 2019, IEEE T ELECTRON DEV, V66, P2946, DOI 10.1109/TED.2019.2918102
   Valentian A, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993431
   van Leeuwen J, 2019, ATTEN PERCEPT PSYCHO, V81, P2956, DOI 10.3758/s13414-019-01788-3
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yakopcic C., 2013, 2013 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2013.6706773, DOI 10.1109/IJCNN.2013.6706773]
   Zhao JY, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.749811
NR 40
TC 0
Z9 0
U1 3
U2 3
PD MAR
PY 2023
VL 13
IS 1
BP 382
EP 394
DI 10.1109/JETCAS.2023.3238295
UT WOS:001061303700032
DA 2023-11-16
ER

PT C
AU Koesoema, AP
   Swito, YS
   Riyani, A
   Aulia, MN
   Utama, DQ
   Azhar, TN
AF Koesoema, Allya Paramita
   Swito, Yoke Saadia
   Riyani, Annisa
   Aulia, Masyithah Nur
   Utama, Dody Qori
   Azhar, Tauhid Nur
BE Lhotska, L
   Sukupova, L
   Lackovic, I
   Ibbott, GS
TI Design of a Smart Multimodal Earthquake Response Mobile Application
SO WORLD CONGRESS ON MEDICAL PHYSICS AND BIOMEDICAL ENGINEERING 2018, VOL 1
SE IFMBE Proceedings
DT Proceedings Paper
CT IUPESM World Congress on Medical Physics and Biomedical Engineering
CY JUN 03-08, 2018
CL Prague, CZECH REPUBLIC
DE First keyword; Second keyword; Third keyword
AB Indonesia is located in the Pacific Ring of fire, putting it under constant risk of natural disasters such as volcanic eruptions, earthquakes, and tsunamis. Earthquakes are one of the biggest threat of natural disasters in Indonesia and can strike anytime in any area. A key example is the 2004 Aceh earthquake, which caused a large tsunami, killing more than 160,000 people and destroyed more than 200 shops and homes. While Indonesia has significantly improved its disaster mitigation systems in the past decade, problems remain. Seismological stations are still relatively few and in between, community readiness and resilience for earthquakes remains low, and response activities are often hampered by lack of equipment, such as for finding potential survivors trapped in rubble. In order to help alleviate these issues, this paper describes the design of a smart multimodal earthquake response mobile application. The proposed system has four main functionalities, namely (1) broadcast of earthquake alert to mobile phones from the local earthquake measurement centre, (2) smart voice activated interactive guide to guide community members on how to react to an earthquake event and arrive to a safe place based on their current situation, (3) A system to search for trapped survivors based on Bluetooth and wifi hotspot emitted by survivors, and (4) recording of earthquake waves based on mobile phone accelerators to be used to build a more granular geospatial database on earthquake features. The system implements machine learning algorithm, utilizes voice, picture and text activated interface to match any situation's need, and basic augmented reality to help guide users to a safe place.
C1 [Koesoema, Allya Paramita; Swito, Yoke Saadia] Indonesian EHlth & Telemed Soc, Bandung, Indonesia.
   [Koesoema, Allya Paramita; Swito, Yoke Saadia; Riyani, Annisa; Aulia, Masyithah Nur; Utama, Dody Qori] Inst Teknol Bandung, Biomed Engn, Bandung, Indonesia.
   [Azhar, Tauhid Nur] UNISBA, Bandung, Indonesia.
RP Koesoema, AP (corresponding author), Indonesian EHlth & Telemed Soc, Bandung, Indonesia.
EM apkoesoema@gmail.com
CR Agrafiotis Panagiotis, 2016, P 9 ACM INT C PERV T
   Aydin C, 2016, PROC TECH, V22, P382, DOI 10.1016/j.protcy.2016.01.027
   Bloch T, 2016, ADV ENG INFORM, V30, P65, DOI 10.1016/j.aei.2015.12.001
   Chen KM, 2000, IEEE T BIO-MED ENG, V47, P105, DOI 10.1109/10.817625
   Doulamis Nikolaos, 2017, P 10 INT C PERV TECH
   Fajardo Jovilyn Therese B., 2010, WSEAS Transactions on Communications, V9, P343
   Kong QK, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1501055
   Kong Qingkai, 2015, INN COMM SERV I4CS 2
   Kumar Sayan, 2015, IND EL APPL ICIEA 20
   Li CZ, 2009, IEEE MICROW MAG, V10, P47, DOI 10.1109/MMM.2008.930675
   Lv H, 2014, IEEE T GEOSCI REMOTE, V52, P7195, DOI 10.1109/TGRS.2014.2309141
   Sachs J, 2014, AD HOC NETW, V13, P42, DOI 10.1016/j.adhoc.2012.07.002
   To Hien, 2015, BIG DAT BIG DAT 2015
NR 13
TC 0
Z9 0
U1 0
U2 10
PY 2019
VL 68
IS 1
BP 471
EP 474
DI 10.1007/978-981-10-9035-6_87
UT WOS:000450908300087
DA 2023-11-16
ER

PT C
AU Gupta, S
   Imani, M
   Rosing, T
AF Gupta, Saransh
   Imani, Mohsen
   Rosing, Tajana
GP Assoc Comp Machinery
TI FELIX: Fast and Energy-Efficient Logic in Memory
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
   DIGEST OF TECHNICAL PAPERS
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 37th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 05-08, 2018
CL San Diego, CA
DE Processing in-Memory; Non-volatile memories; Memristors;
   Hyper-dimensional computing; Machine learning; Energy efficiency
ID INTERNET; DESIGN; THINGS
AB The Internet of Things (IoT) has led to the emergence of big data. Processing this amount of data poses a challenge for current computing systems. PIM enables in -place computation which reduces data movement, a major latency bottleneck in conventional systems. In this paper, we propose an in -memory implementation of fast and energy efficient logic (FELIX) which combines the functionality of PIM with memories. To the best of authors' knowledge, FELIX is the first PIM logic to enable the single cycle NOR, NOT, NAND, minority, and OR directly in crossbar memory. We exploit the voltage threshold -based memristors to enable single cycle operations. It is a purely in -memory execution which neither reads out data nor changes sense amplifiers, while preserving data in-memory. We extend these single cycle operations to implement more complex functions like XOR and addition in memory with 2x lower latency than the fastest published PIM technique. We also increase the amount of in -memory parallelism in our design by segmenting bitlines using switches. To evaluate the efficiency of our design at the system level, we design a FELIX-based HyperDimensional (HD) computing accelerator. Our evaluation shows that for all applications tested using HD, FELIX provides on average 128.8x speedup and 5,589.3x lower energy consumption as compared to AMD CPU. F.-TUX HD also achieves on average 2.21 x higher energy efficiency, I.86 x speedup, and 1.68x less memory as compared to the fastest PIM technique.
C1 [Gupta, Saransh; Imani, Mohsen; Rosing, Tajana] Univ Calif San Diego, CSE Dept, La Jolla, CA 92093 USA.
RP Gupta, S (corresponding author), Univ Calif San Diego, CSE Dept, La Jolla, CA 92093 USA.
EM sgupta@ucsd.edu; moimani@ucsd.edu; tajana@ucsd.edu
CR Aly AM, 2012, PROC INT CONF DATA, P1253, DOI 10.1109/ICDE.2012.120
   [Anonymous], 2016, P 53 ANN DES AUT C D
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], DAC
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Griffin G., 2007, 120 CAL I TECHN
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guo Q., 2013, P 40 ANN INT S COMPU, V41, P189, DOI [10.1145/2508148.2485939, DOI 10.1145/2485922.2485939]
   Guo Q, 2011, INT SYMP MICROARCH, P339
   Haj-Ali A., 2018, P IEEE INT S CIRC SY, P1, DOI DOI 10.1109/ISCAS.2018.8351561
   Imani M., 2018, IEEE TCAD
   IMANI M, 2017, ICRC, P97
   Imani M., 2018, DATE
   Imani M, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P8, DOI 10.1109/ICCKE.2017.8167879
   Imani M, 2017, IEEE DES TEST, V34, P94, DOI 10.1109/MDAT.2017.2740839
   Imani M, 2016, I SYMPOS LOW POWER E, P162, DOI 10.1145/2934583.2934595
   Imani M, 2017, ASIA S PACIF DES AUT, P757, DOI 10.1109/ASPDAC.2017.7858415
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Kvatinsky S, 2015, IEEE T CIRCUITS-II, V62, P786, DOI 10.1109/TCSII.2015.2433536
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Kvatinsky S, 2014, IEEE T VLSI SYST, V22, P2054, DOI 10.1109/TVLSI.2013.2282132
   Loh G. H., 2013, WONDP
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Reiss A., 2012, P P 5 INT C PERVASIV, DOI [10.1145/2413097.2413148, DOI 10.1145/2413097.2413148]
   Siemon A, 2015, IEEE J EM SEL TOP C, V5, P64, DOI 10.1109/JETCAS.2015.2398217
   Talati N, 2016, IEEE T NANOTECHNOL, V15, P635, DOI 10.1109/TNANO.2016.2570248
   Yavits L, 2015, IEEE COMPUT ARCHIT L, V14, P148, DOI 10.1109/LCA.2014.2374597
NR 29
TC 83
Z9 85
U1 0
U2 3
PY 2018
DI 10.1145/3240765.3240811
UT WOS:000494640800055
DA 2023-11-16
ER

PT J
AU Steinert, F
   Stabernack, B
AF Steinert, Fritjof
   Stabernack, Benno
TI Architecture of a Low Latency H.264/AVC Video Codec for Robust ML based
   Image Classification How Region of Interests can Minimize the Impact of
   Coding Artifacts
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE H; 264; Advanced Video Codec (AVC); Low Latency; Region of Interest;
   Machine Learning; Inference; FPGA; Hardware accelerator
ID ENCODER CHIP; DESIGN
AB The use of neural networks is considered as the state of the art in the field of image classification. A large number of different networks are available for this purpose, which, appropriately trained, permit a high level of classification accuracy. Typically, these networks are applied to uncompressed image data, since a corresponding training was also carried out using image data of similar high quality. However, if image data contains image errors, the classification accuracy deteriorates drastically. This applies in particular to coding artifacts which occur due to image and video compression. Typical application scenarios for video compression are narrowband transmission channels for which video coding is required but a subsequent classification is to be carried out on the receiver side. In this paper we present a special H.264/Advanced Video Codec (AVC) based video codec that allows certain regions of a picture to be coded with near constant picture quality in order to allow a reliable classification using neural networks, whereas the remaining image will be coded using constant bit rate. We have combined this feature with the ability to run with lowest latency properties, which is usually also required in remote control applications scenarios. The codec has been implemented as a fully hardwired High Definition video capable hardware architecture which is suitable for Field Programmable Gate Arrays.
C1 [Steinert, Fritjof; Stabernack, Benno] Heinrich Hertz Inst HHI, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Einsteinufer, Germany.
   [Steinert, Fritjof; Stabernack, Benno] Univ Potsdam, Potsdam, Germany.
RP Steinert, F (corresponding author), Heinrich Hertz Inst HHI, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Einsteinufer, Germany.; Steinert, F (corresponding author), Univ Potsdam, Potsdam, Germany.
EM fritjof.steinert@hhi-extern.fraunhofer.de;
   benno.stabernack@hhi.fraunhofer.de
CR [Anonymous], 2019, INT TECHN GEN COD MO
   [Anonymous], 2017, H 264 2 REFERENCE SO
   [Anonymous], 2014, AMBA AXI ACE PROT SP
   [Anonymous], 2012, AUD MULT SYST INF H
   Avgousti S, 2016, HEALTHC TECHNOL LETT, V3, P212, DOI 10.1049/htl.2016.0043
   Belhadj N, 2013, I C SCI TECH AUTO CO, P216, DOI 10.1109/STA.2013.6783133
   Castro CA, 2013, IEEE T BIO-MED ENG, V60, P930, DOI 10.1109/TBME.2012.2232926
   Chen JW, 2011, IEEE T CONSUM ELECTR, V57, P1203, DOI 10.1109/TCE.2011.6018875
   Chen TC, 2006, IEEE T CIRC SYST VID, V16, P673, DOI 10.1109/TCSVT.2006.873163
   Chen YH, 2009, IEEE T CIRC SYST VID, V19, P1118, DOI 10.1109/TCSVT.2009.2020323
   Ding LF, 2010, IEEE J SOLID-ST CIRC, V45, P46, DOI 10.1109/JSSC.2009.2031787
   Diniz C, 2011, IEEE INT SYMP CIRC S, P579
   Hase T., 2011, 2011 IEEE 73 VEH TEC, P1
   Huang Hsiang, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P021, DOI 10.1109/ICAIIC48513.2020.9065232
   Hwang J., 2015, 2015 IEEE 17 INT WOR, P1
   Jung JS, 2011, J SIGNAL PROCESS SYS, V64, P161, DOI 10.1007/s11265-010-0574-6
   Keshaveni N., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P646, DOI 10.1109/ACT.2009.164
   Korah R, 2008, J SIGNAL PROCESS SYS, V53, P261, DOI 10.1007/s11265-008-0163-0
   Kthiri M., 2010, P 5 INT S 4 COMM MOB, P1, DOI [10.1109/ISVC.2010.5654826, DOI 10.1109/ISVC.2010.5654826]
   Kuo HC, 2011, IEEE T VLSI SYST, V19, P925, DOI 10.1109/TVLSI.2010.2045402
   Lee YG, 2009, IEEE T CIRC SYST VID, V19, P747, DOI 10.1109/TCSVT.2009.2017413
   Lin YLS, 2010, VLSI DESIGN FOR VIDEO CODING: H.264/AVC ENCODING FROM STANDARD SPECIFICATION TO CHIP, P1, DOI 10.1007/978-1-4419-0959-6
   Lin YK, 2009, IEEE T CIRC SYST VID, V19, P432, DOI 10.1109/TCSVT.2009.2013511
   Liu ZY, 2009, IEEE J SOLID-ST CIRC, V44, P594, DOI 10.1109/JSSC.2008.2010797
   Matsui H., 2011, P 2011 INT S VLSI DE, P1, DOI [10.1109/VDAT.2011.2011.5783632, DOI 10.1109/VDAT.2011.2011.5783632]
   Mukherjee R, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P986
   Mukherjee R., 2012, IET INT C INF SCI CO, P1, DOI [10.1049/cp.2012.2417, DOI 10.1049/CP.2012.2417]
   Pastuszak G, 2015, IEEE T CIRC SYST VID, V25, P1844, DOI 10.1109/TCSVT.2015.2402911
   Pastuszak G, 2014, IEEE INT SYMP DESIGN, P290, DOI 10.1109/DDECS.2014.6868812
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Siblini A., 2013, 2013 8 IEEE DES TEST, P1, DOI [10.1109/IDT.2013.6727116, DOI 10.1109/IDT.2013.6727116]
   Song BC, 2012, J SIGNAL PROCESS SYS, V67, P291, DOI 10.1007/s11265-010-0564-8
   Stabernack Benno, 2021, DASIP '21: Proceedings of the 2021 Workshop on Design and Architectures for Signal and Image Processing (14th edition), P1, DOI 10.1145/3441110.3441149
   Stabernack B, 2015, CONF DESIGN ARCHIT, P54
   Steinert F, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P149, DOI 10.1109/DSD51259.2020.00033
   Wei KJ, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P373, DOI 10.1109/PCS.2012.6213368
   Wei L, 2011, J ZHEJIANG U-SCI C, V12, P499, DOI 10.1631/jzus.C1000201
   Wu JY, 2015, IEEE T CIRC SYST VID, V25, P1988, DOI 10.1109/TCSVT.2015.2441412
   Yu-Kun Lin, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P314
   Zheng J., 2012, ANTICOUNTERFEITING S, P1, DOI [10.1109/ICASID.2012.6325313, DOI 10.1109/ICASID.2012.6325313]
NR 41
TC 2
Z9 2
U1 2
U2 4
PD JUL
PY 2022
VL 94
IS 7
SI SI
BP 693
EP 708
DI 10.1007/s11265-021-01727-2
EA JAN 2022
UT WOS:000750452300001
DA 2023-11-16
ER

PT J
AU Kuo, CY
   Lee, CC
   Lee, YL
   Liou, SC
   Lee, JC
   Su, ECY
   Chen, YW
AF Kuo, Chao-Yang
   Lee, Cheng-Chun
   Lee, Yuh-Lin
   Liou, Shueh-Chun
   Lee, Jia-Cheng
   Su, Emily Chia-Yu
   Chen, Yi-Wei
TI Visual light perceptions caused by medical linear accelerator: Findings
   of machin-elearning algorithms in a prospective questionnaire-based
   case-control study
SO PLOS ONE
DT Article
ID LOGISTIC-REGRESSION; RADIATION-THERAPY; RANDOM FORESTS; FLASHES;
   CLASSIFICATION; PERFORMANCE; GENERATION; PHOSPHENES; BEAM
AB This study aimed to investigate the possible incidence of visual light perceptions (VLPs) during radiation therapy (RT). We analyzed whether VLPs could be affected by differences in the radiation energy, prescription doses, age, sex, or RT locations, and whether all VLPs were caused by radiation. From November 2016 to August 2018, a total of 101 patients who underwent head-and-neck or brain RT were screened. After receiving RT, questionnaires were completed, and the subjects were interviewed. Random forests (RF), a tree-based machine learning algorithm, and logistic regression (LR) analyses were compared by the area under the curve (AUC), and the algorithm that achieved the highest AUC was selected. The dataset sample was based on treatment with non-human units, and a total of 293 treatment fields from 78 patients were analyzed. VLPs were detected only in 122 of the 293 exposure portals (40.16%). The dataset was randomly divided into 80% and 20% as the training set and test set, respectively. In the test set, RF achieved an AUC of 0.888, whereas LR achieved an AUC of 0.773. In this study, the retina fraction dose was the most important continuous variable and had a positive effect on VLP. Age was the most important categorical variable. In conclusion, the visual light perception phenomenon by the human body during RT is induced by radiation rather than being a self-suggested hallucination or induced by phosphenes.
C1 [Kuo, Chao-Yang; Su, Emily Chia-Yu] Taipei Med Univ, Coll Med Sci & Technol, Grad Inst Biomed Informat, Taipei, Taiwan.
   [Lee, Cheng-Chun; Lee, Yuh-Lin; Liou, Shueh-Chun; Lee, Jia-Cheng; Chen, Yi-Wei] Taipei Vet Gen Hosp, Dept Oncol, Radiotherapy Div, Taipei, Taiwan.
   [Lee, Jia-Cheng; Chen, Yi-Wei] Yuanpei Univ Med Technol, Dept Med Imaging & Radiol Technol, Hsinchu, Taiwan.
   [Su, Emily Chia-Yu] Taipei Med Univ Hosp, Clin Big Data Res Ctr, Taipei, Taiwan.
RP Su, ECY (corresponding author), Taipei Med Univ, Coll Med Sci & Technol, Grad Inst Biomed Informat, Taipei, Taiwan.; Chen, YW (corresponding author), Taipei Vet Gen Hosp, Dept Oncol, Radiotherapy Div, Taipei, Taiwan.; Chen, YW (corresponding author), Yuanpei Univ Med Technol, Dept Med Imaging & Radiol Technol, Hsinchu, Taiwan.; Su, ECY (corresponding author), Taipei Med Univ Hosp, Clin Big Data Res Ctr, Taipei, Taiwan.
EM emilysu@tmu.edu.tw; chenyw@vghtpe.gov.tw
CR Baratloo A, 2015, EMERGENCY, V3, P48
   Lissabet JFB, 2019, COMPUT BIOL CHEM, V83, DOI 10.1016/j.compbiolchem.2019.107103
   Blumenthal DT, 2015, RADIOTHER ONCOL, V116, P331, DOI 10.1016/j.radonc.2015.07.034
   Boulesteix AL, 2012, WIRES DATA MIN KNOWL, V2, P493
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen X, 2011, WIRES DATA MIN KNOWL, V1, P55, DOI 10.1002/widm.14
   Chuard D, 2016, LIFE SCI SPACE RES, V10, P23, DOI 10.1016/j.lssr.2016.06.002
   Cooray V, 2011, PHYS LETT A, V375, P3704, DOI 10.1016/j.physleta.2011.08.055
   Couronné R, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2264-5
   Curchoe CL, 2019, J ASSIST REPROD GEN, V36, P591, DOI 10.1007/s10815-019-01408-x
   Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
   de Kruijf W, 2019, RADIOTHER ONCOL, V132, P109, DOI 10.1016/j.radonc.2018.11.010
   Desbordes P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173208
   Farzin M, 2016, EUR J ONCOL, V21, P254
   GARCIA, 1963, SCIENCE, V140, P289, DOI 10.1126/science.140.3564.289
   GARCIA J, 1962, NATURE, V196, P1014, DOI 10.1038/1961014a0
   Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299, DOI 10.1109/TKDE.2005.50
   Jung D, 2013, NEW J PHYS, V15
   Li JQ, 2019, INT J RADIAT ONCOL, V105, P893, DOI 10.1016/j.ijrobp.2019.07.049
   LIPETZ L E, 1955, Br J Ophthalmol, V39, P577, DOI 10.1136/bjo.39.10.577
   Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x
   MCAULAY IR, 1971, NATURE, V232, P421, DOI 10.1038/232421a0
   Mellor A, 2013, REMOTE SENS-BASEL, V5, P2838, DOI 10.3390/rs5062838
   Noda Koji, 2016, Int J Part Ther, V2, P481, DOI 10.14338/IJPT-15-00041.1
   Pandis N, 2017, AM J ORTHOD DENTOFAC, V151, P824, DOI 10.1016/j.ajodo.2017.01.017
   Park HA, 2013, J KOREAN ACAD NURS, V43, P154, DOI 10.4040/jkan.2013.43.2.154
   PINSKY LS, 1974, SCIENCE, V183, P957, DOI 10.1126/science.183.4128.957
   Qi YJ, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P307, DOI 10.1007/978-1-4419-9326-7_11
   Rahman M, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab9452
   Schardt D, 2013, BRAIN STIMUL, V6, P416, DOI [10.1016/j.brs.2012.08.003, DOI 10.1016/J.BRS.2012.08.003]
   Speiser JL, 2015, STAT MED, V34, P887, DOI 10.1002/sim.6351
   Tendler II, 2020, INT J RADIAT ONCOL, V106, P422, DOI [10.1016/j.ijrobp.2019.10.031, DOI 10.1016/J.IJROBP.2019.10.031]
   Weber A, 2018, ANN EPIDEMIOL, V28, P783, DOI 10.1016/j.annepidem.2018.08.008
   Wilhelm-Buchstab T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123440
   Xiong JF, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28243-x
   Zhang RX, 2017, J BIOPHOTONICS, V10, P645, DOI 10.1002/jbio.201500344
NR 37
TC 1
Z9 1
U1 0
U2 1
PD FEB 25
PY 2021
VL 16
IS 2
AR e0247597
DI 10.1371/journal.pone.0247597
UT WOS:000624536800028
DA 2023-11-16
ER

PT J
AU Chen, CY
   Chakrabarty, K
AF Chen, Ching-Yuan
   Chakrabarty, Krishnendu
TI Efficient Identification of Critical Faults in Memristor-Based
   Inferencing Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Deep neural network (DNN); fault tolerance; memristor crossbar;
   resistive random-access memory (ReRAM); testing
AB Deep neural networks (DNNs) are becoming ubiquitous, but hardware-level reliability is a concern when DNN models are mapped to emerging neuromorphic technologies such as memristor-based crossbars. As DNN architectures are inherently fault tolerant and many faults do not affect inferencing accuracy, careful analysis must be carried out to identify faults that are critical for a given application. We present a misclassification-driven training (MDT) algorithm to efficiently identify critical faults (FCFs) in the crossbar. Our results for three DNNs on the CIFAR-10 data set show that MDT can rapidly and accurately identify a large number of FCFs-up to 20x faster than a baseline method of forward inferencing with randomly injected faults. We use the set of FCFs obtained using MDT and the set of benign faults obtained using forward inferencing to train a machine learning (ML) model to efficiently classify all the crossbar faults in terms of their criticality. Using the ground truth generated using MDT and forward inferencing, we show that the ML models can classify millions of faults within minutes with a remarkably high classification accuracy of up to 99%. We also show that the ML model trained using CIFAR-10 provides high accuracy when it is used to carry out fault classification for the ImageNet data set. We present a fault-tolerance solution that exploits this high degree of criticality-classification accuracy, leading to a 92.5% reduction in the redundancy needed for fault tolerance.
C1 [Chen, Ching-Yuan; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
RP Chen, CY (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
EM chingyuan.chen@duke.edu; krish@duke.edu
CR Agbo IO, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000175
   Alcolea A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030314
   Breiman L., 2001, RANDOM FORESTS, V45, P5
   Chaudhuri Anirban, 2018, 2018 AIAA Non-Deterministic Approaches Conference, P1
   Chen CY, 2015, IEEE T COMPUT, V64, P180, DOI 10.1109/TC.2014.12
   Chen CY, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1074, DOI 10.23919/DATE51398.2021.9473989
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fackenthal R, 2014, ISSCC DIG TECH PAP I, V57, P338, DOI 10.1109/ISSCC.2014.6757460
   Fieback M, 2019, INT TEST CONF P, DOI [10.1109/itc44170.2019.9000134, 10.1109/CLEOE-EQEC.2019.8872480]
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao YS, 2019, 35TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSA), P113, DOI 10.1145/3359789.3359790
   Gebregiorgis A, 2019, 2019 IEEE INT TEST C, P1
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu TY, 2019, IEEE ACCESS, V7, P47230, DOI 10.1109/ACCESS.2019.2909068
   Hamdioui S, 2015, IEEE T COMPUT, V64, P247, DOI 10.1109/TC.2013.206
   Hastie T., 2009, ELEMENTS STAT LEARNI
   He XS, 2014, 2014 IEEE SYMPOSIUM ON SWARM INTELLIGENCE (SIS), P27, DOI 10.1155/2014/195053
   He ZZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317870
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Kannan S, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P215, DOI 10.1109/ICCD.2013.6657045
   Krizhevsky A., 2009, CIFAR 10 CIFAR 100 D
   Levisse A, 2020, IEEE ACCESS, V8, P109297, DOI 10.1109/ACCESS.2020.3000867
   Lin JL, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P639, DOI 10.1145/3287624.3287715
   Liu CC, 2017, DES AUT CON, DOI 10.1145/3061639.3062310
   Liu M., 2018, PROC EUR TEST SYMP, P1, DOI 10.1109/ETS.2018.8400693
   Liu T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317742
   Madry Aleksander, 2018, P INT C LEARN REPR I
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Tuli Shikhar, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P181, DOI 10.1109/ASP-DAC47756.2020.9045220
   Wang BL, 2019, P IEEE S SECUR PRIV, P707, DOI 10.1109/SP.2019.00031
   Wang JK, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9180658
   Wei LQ, 2019, ISSCC DIG TECH PAP I, V62, P214, DOI 10.1109/ISSCC.2019.8662444
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Xia LX, 2018, IEEE J EM SEL TOP C, V8, P102, DOI 10.1109/JETCAS.2017.2776980
   Xia LX, 2017, DES AUT CON, DOI 10.1145/3061639.3062248
   Xu Z, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000149
   Yong-Xiao Chen, 2015, 2015 IEEE 33rd VLSI Test Symposium (VTS). Proceedings, P1, DOI 10.1109/VTS.2015.7116247
   Zhang BG, 2020, IEEE T COMPUT AID D, V39, P2448, DOI 10.1109/TCAD.2019.2944582
   Zhang SH, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P11, DOI [10.1109/AICAS48895.2020.9073995, 10.1109/aicas48895.2020.9073995]
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 45
TC 1
Z9 1
U1 2
U2 12
PD JUL
PY 2022
VL 41
IS 7
BP 2301
EP 2314
DI 10.1109/TCAD.2021.3102894
UT WOS:000812532700029
DA 2023-11-16
ER

PT J
AU Morris, J
   Hao, YL
   Gupta, S
   Khaleghi, B
   Aksanli, B
   Rosing, T
AF Morris, Justin
   Hao, Yilun
   Gupta, Saransh
   Khaleghi, Behnam
   Aksanli, Baris
   Rosing, Tajana
TI Stochastic-HD: Leveraging Stochastic Computing on the Hyper-Dimensional
   Computing Pipeline
SO FRONTIERS IN NEUROSCIENCE
DT Article
DE Hyper-dimensional computing; stochastic computing; brain inspired
   cognitive architecture; machine learning; processing in memory
ID ARCHITECTURE
AB Brain-inspired Hyper-dimensional(HD) computing is a novel and efficient computing paradigm. However, highly parallel architectures such as Processing-in-Memory(PIM) are bottle-necked by reduction operations required such as accumulation. To reduce this bottle-neck of HD computing in PIM, we present Stochastic-HD that combines the simplicity of operations in Stochastic Computing (SC) with the complex task solving capabilities of the latest HD computing algorithms. Stochastic-HD leverages deterministic SC, which enables all of HD operations to be done as highly parallel bitwise operations and removes all reduction operations, thus improving the throughput of PIM. To this end, we propose an in-memory hardware design for Stochastic-HD that exploits its high level of parallelism and robustness to approximation. Our hardware uses in-memory bitwise operations along with associative memory-like operations to enable a fast and energy-efficient implementation. With Stochastic-HD, we were able to reach a comparable accuracy with the Baseline-HD. Furthermore, by proposing an integrated Stochastic-HD retraining approach Stochastic-HD is able to reduce the accuracy loss to just 0.3%. We additionally accelerate the retraining process in our hardware design to create an end-to-end accelerator for Stochastic-HD. Finally, we also add support for HD Clustering to Stochastic-HD, which is the first to map the HD Clustering operations to the stochastic domain. As compared to the best PIM design for HD, Stochastic-HD is also 4.4% more accurate and 43.1x more energy-efficient.
C1 [Morris, Justin] San Diego State Univ, Dept Elect & Comp Engn, San Diego, CA USA.
   [Hao, Yilun; Khaleghi, Behnam; Aksanli, Baris; Rosing, Tajana] Univ Calif, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
   [Gupta, Saransh] IBM Res, San Jose, CA 95120 USA.
RP Rosing, T (corresponding author), Univ Calif, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM tajana@ucsd.edu
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Benatti Simone, 2014, 7th International Conference on Bio-Inspired Systems and Signal Processing (BIOSIGNALS 2014). Proceedings, P45
   Datta S, 2019, IEEE J EM SEL TOP C, V9, P439, DOI 10.1109/JETCAS.2019.2935464
   Gaines B.R., 1969, ADV INFORM SYSTEMS S, V2, P37, DOI 10.1109/12.954505
   Griffin Gregory, 2007, CALTECH 256 OBJECT C, P5
   Gupta S, 2022, ACM J EMERG TECH COM, V18, DOI 10.1145/3484731
   Gupta S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240811
   Hao YL, 2021, PR IEEE COMP DESIGN, P321, DOI 10.1109/ICCD53106.2021.00058
   Ho C., 2017, 2017 IEEE INT ELECT, P2, DOI [10.1109/IEDM.2017.8268314, DOI 10.1109/IEDM.2017.8268314]
   Imani Mohsen, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P271, DOI 10.1109/BHI.2018.8333421
   Imani M, 2020, IEEE T COMPUT AID D, V39, P2422, DOI 10.1109/TCAD.2019.2952544
   Imani M, 2020, IEEE T COMPUT AID D, V39, P2268, DOI 10.1109/TCAD.2019.2954472
   Imani M, 2020, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA47549.2020.00011
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Imani M, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317785
   Imani M, 2019, ANN IEEE SYM FIELD P, P190, DOI 10.1109/FCCM.2019.00034
   Imani M, 2019, DES AUT TEST EUROPE, P126, DOI [10.23919/date.2019.8714821, 10.23919/DATE.2019.8714821]
   Imani M, 2019, DES AUT TEST EUROPE, P1591, DOI [10.23919/date.2019.8715147, 10.23919/DATE.2019.8715147]
   Imani M, 2019, IEEE T EMERG TOP COM, V7, P271, DOI 10.1109/TETC.2016.2642057
   Imani M, 2017, DES AUT CON, DOI 10.1145/3061639.3062210
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Jenson D, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2966988
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Kim K, 2016, DES AUT CON, DOI 10.1145/2897937.2898011
   Kim Y, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS (IOT'18), DOI 10.1145/3277593.3277617
   Kvatinsky S, 2015, IEEE T CIRCUITS-II, V62, P786, DOI 10.1109/TCSII.2015.2433536
   Lee VT, 2017, DES AUT TEST EUROPE, P13, DOI 10.23919/DATE.2017.7926951
   Li BZ, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P36, DOI 10.1145/2847263.2847340
   Li C, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372119
   Morris J, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P723, DOI 10.23919/DATE51398.2021.9474218
   Morris Justin, 2019, I SYMPOS LOW POWER E, P1, DOI [DOI 10.1109/islped.2019.8824908, DOI 10.1109/ISLPED.2019.8824908]
   Qian WK, 2011, IEEE T COMPUT, V60, P93, DOI 10.1109/TC.2010.202
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Rahimi A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
   Räsänen OJ, 2016, IEEE T NEUR NET LEAR, V27, P1878, DOI 10.1109/TNNLS.2015.2462721
   Salamat S, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P53, DOI 10.1145/3289602.3293913
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Ultsch Alfred, 2005, LWA, P240
   Zhakatayev A, 2018, DES AUT CON, DOI [10.1145/3195970.3196113, 10.1109/DAC.2018.8465807]
NR 40
TC 0
Z9 0
U1 10
U2 13
PD MAY 30
PY 2022
VL 16
AR 867192
DI 10.3389/fnins.2022.867192
UT WOS:000810192800001
DA 2023-11-16
ER

PT C
AU Kim, Y
   Venkataramani, S
   Sen, S
   Raghunathan, A
AF Kim, Younghoon
   Venkataramani, Swagath
   Sen, Sanchari
   Raghunathan, Anand
GP IEEE
TI Value Similarity Extensions for Approximate Computing in General-Purpose
   Processors
SO PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2021)
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY FEB 01-05, 2021
CL ELECTR NETWORK
AB Approximate Computing (AxC) is a popular design paradigm wherein selected computations are executed approximately to gain efficiency with minimal impact on application-level quality. Most efforts in AxC target specialized accelerators and domain-specific processors, with relatively limited focus on General-Purpose Processors (GPPs). However, GPPs are still broadly used to execute applications that are amenable to AxC, making AxC for GPPs a critical challenge.
   A key bottleneck in applying AxC to GPPs is that their execution units account for only a small fraction of total energy, requiring a holistic approach targeting compute, memory and control front-ends. This paper proposes such an approach that leverages the application property of value similarity, i.e., input operands to computations that occur close-in-time take similar values. Such similar computations are dynamically pre-detected and the fetch-decode-execute of entire instruction sequences are skipped to benefit performance. To this end, we propose a set of lightweight micro-architectural and ISA extensions called VSX that enable: (i) similarity detection amongst values in a cache-line, (ii) skipping of pre-defined instructions and/or loop iterations when similarity is detected, and (iii) substituting outputs of skipped instructions with saved results from previously executed computations. We also develop compiler techniques, guided by user annotations, to benefit from VSX in the context of common Machine Learning (ML) kernels. Our RTL implementation of VSX for a low-power RISC-V processor incurred 2.13% area overhead and yielded 1.19x-3.84x speedup with <0.5% accuracy loss on 6 ML benchmarks.
C1 [Kim, Younghoon; Raghunathan, Anand] Purdue Univ, W Lafayette, IN 47907 USA.
   [Venkataramani, Swagath; Sen, Sanchari] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
RP Kim, Y (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM kim1606@purdue.edu; swagath.venkataramani@ibm.com; sanchari.sen@ibm.com;
   raghunathan@purdue.edu
CR Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Aurangzeb R, 2017, PROC ICS
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chakradhar ST, 2010, DES AUT CON, P865
   Esmaeilzadeh H, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P301
   He X, 2016, ASIA S PACIF DES AUT, P643, DOI 10.1109/ASPDAC.2016.7428084
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim Y, 2019, DES AUT TEST EUROPE, P576, DOI [10.23919/DATE.2019.8714872, 10.23919/date.2019.8714872]
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Narayanan S, 2010, DES AUT TEST EUROPE, P335
   Raha A, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126531
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Samadi M, 2014, ACM SIGPLAN NOTICES, V49, P35, DOI 10.1145/2541940.2541948
   San Miguel J, 2014, INT SYMP MICROARCH, P127, DOI 10.1109/MICRO.2014.22
   Sato Y, 2015, INT SYMPOS COMPUT NE, P378, DOI 10.1109/CANDAR.2015.35
   Sen S, 2019, IEEE T COMPUT, V68, P912, DOI 10.1109/TC.2018.2879434
   Sidiroglou-Douskos S., 2011, P ESEC FSE
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Wong D, 2016, INT S HIGH PERF COMP, P176, DOI 10.1109/HPCA.2016.7446063
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
   Yazdanbakhsh A, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2836168
NR 22
TC 4
Z9 4
U1 0
U2 0
PY 2021
BP 481
EP 486
UT WOS:000805289900089
DA 2023-11-16
ER

PT J
AU Chen, T
   van Gelder, J
   van de Ven, B
   Amitonov, SV
   de Wilde, B
   Euler, HCR
   Broersma, H
   Bobbert, PA
   Zwanenburg, FA
   van der Wiel, WG
AF Chen, Tao
   van Gelder, Jeroen
   van de Ven, Bram
   Amitonov, Sergey V.
   de Wilde, Bram
   Euler, Hans-Christian Ruiz
   Broersma, Hajo
   Bobbert, Peter A.
   Zwanenburg, Floris A.
   van der Wiel, Wilfred G.
TI Classification with a disordered dopantatom network in silicon
SO NATURE
DT Article
ID ACCELERATOR; EVOLUTION
AB Classification is an important task at which both biological and artificial neural networks excel(1,2). In machine learning, nonlinear projection into a high-dimensional feature space can make data linearly separable(3,4), simplifying the classification of complex features. Such nonlinear projections are computationally expensive in conventional computers. A promising approach is to exploit physical materials systems that perform this nonlinear projection intrinsically, because of their high computational density(5), inherent parallelism and energy efficiency(6,7). However, existing approaches either rely on the systems' time dynamics, which requires sequential data processing and therefore hinders parallel computation(5,6,8), or employ large materials systems that are difficult to scale up(7). Here we use a parallel, nanoscale approach inspired by filters in the brain(1) and artificial neural networks(2) to perform nonlinear classification and feature extraction. We exploit the nonlinearity of hopping conduction(9-11) through an electrically tunable network of boron dopant atoms in silicon, reconfiguring the network through artificial evolution to realize different computational functions. We first solve the canonical two-input binary classification problem, realizing all Boolean logic gates(12) up to room temperature, demonstrating nonlinear classification with the nanomaterial system. We then evolve our dopant network to realize feature filters(2) that can perform four-input binary classification on the Modified National Institute of Standards and Technology handwritten digit database. Implementation of our material-based filters substantially improves the classification accuracy over that of a linear classifier directly applied to the original data(13). Our results establish a paradigm of silicon-based electronics for smallfootprint and energy-efficient computation(14).
C1 [Chen, Tao; van Gelder, Jeroen; van de Ven, Bram; Amitonov, Sergey V.; de Wilde, Bram; Euler, Hans-Christian Ruiz; Bobbert, Peter A.; Zwanenburg, Floris A.; van der Wiel, Wilfred G.] Univ Twente, MESA Inst Nanotechnol, NanoElect Grp, Enschede, Netherlands.
   [Chen, Tao; van Gelder, Jeroen; van de Ven, Bram; Amitonov, Sergey V.; de Wilde, Bram; Euler, Hans-Christian Ruiz; Broersma, Hajo; Bobbert, Peter A.; Zwanenburg, Floris A.; van der Wiel, Wilfred G.] Univ Twente, BRAINS Ctr Brain Inspired Nano Syst, Enschede, Netherlands.
   [Broersma, Hajo] Univ Twente, DSI Digital Soc Inst, MESA Inst Nanotechnol, Programmable Nanosyst & Formal Methods & Tools, Enschede, Netherlands.
   [Bobbert, Peter A.] Eindhoven Univ Technol, Mol Mat & Nanosyst, Eindhoven, Netherlands.
   [Bobbert, Peter A.] Eindhoven Univ Technol, Ctr Computat Energy Res, Dept Appl Phys, Eindhoven, Netherlands.
RP van der Wiel, WG (corresponding author), Univ Twente, MESA Inst Nanotechnol, NanoElect Grp, Enschede, Netherlands.; van der Wiel, WG (corresponding author), Univ Twente, BRAINS Ctr Brain Inspired Nano Syst, Enschede, Netherlands.
EM W.G.vanderWiel@utwente.nl
CR AHARONY A, 1992, PHYS REV LETT, V68, P3900, DOI 10.1103/PhysRevLett.68.3900
   BACKUS J, 1978, COMMUN ACM, V21, P613, DOI 10.1145/359576.359579
   Björk MT, 2009, NAT NANOTECHNOL, V4, P103, DOI [10.1038/nnano.2008.400, 10.1038/NNANO.2008.400]
   Bose SK, 2015, NAT NANOTECHNOL, V10, P1048, DOI [10.1038/NNANO.2015.207, 10.1038/nnano.2015.207]
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137
   Dale M., 2016, COMPUTATIONAL INTELL, P1, DOI 10.1109/SSCI.2016.7850170
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Gantmakher V.F., 2005, ELECT DISORDER SOLID
   Harding S, 2004, IEEE C EVOL COMPUTAT, P1800, DOI 10.1109/CEC.2004.1331114
   HARTSTEIN A, 1975, J PHYS C SOLID STATE, V8, pL249, DOI 10.1088/0022-3719/8/11/007
   Haykin S., 2008, NEURAL NETWORKS LEAR
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   HUNG CS, 1954, PHYS REV, V96, P1226, DOI 10.1103/PhysRev.96.1226
   Jenderka M, 2013, PHYS REV B, V88, DOI 10.1103/PhysRevB.88.045111
   Kingma DP., 2017, ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955
   Miller JF, 2002, 2002 NASA/DOD CONFERENCE ON EVOLABLE HARDWARE, PROCEEDINGS, P167, DOI 10.1109/EH.2002.1029882
   Minsky M., 1969, PERCEPTRONS INTRO CO
   Mohid M, 2015, ECAL 2015: THE THIRTEENTH EUROPEAN CONFERENCE ON ARTIFICIAL LIFE, P106, DOI 10.7551/978-0-262-33027-5-ch025
   Mott N. F., 1968, Journal of Non-Crystalline Solids, V1, P1, DOI 10.1016/0022-3093(68)90002-1
   Pettersson J, 1996, PHYS REV B, V53, P13272, DOI 10.1103/PhysRevB.53.R13272
   Pierre M, 2010, NAT NANOTECHNOL, V5, P133, DOI [10.1038/NNANO.2009.373, 10.1038/nnano.2009.373]
   Such F.P., 2017, PREPRINT
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Tapson J, 2013, NEURAL NETWORKS, V45, P94, DOI 10.1016/j.neunet.2013.02.008
   Torrejon J, 2017, NATURE, V547, P428, DOI 10.1038/nature23011
   WOLFRAM S, 1986, PHYSICA D, V22, P385, DOI 10.1016/0167-2789(86)90309-X
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Zabrodskii A. G., 1984, Soviet Physics - JETP, V59, P425
NR 36
TC 44
Z9 45
U1 5
U2 69
PD JAN 16
PY 2020
VL 577
IS 7790
BP 341
EP +
DI 10.1038/s41586-019-1901-0
UT WOS:000509570100027
DA 2023-11-16
ER

PT C
AU Sehgal, R
   Kulkarni, JP
AF Sehgal, Rishabh
   Kulkarni, Jaydeep P.
GP IEEE
TI Trends in Analog and Digital Intensive Compute-in-SRAM Designs
SO 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   CIRCUITS AND SYSTEMS (AICAS)
DT Proceedings Paper
CT IEEE 3rd International Conference on Artificial Intelligence Circuits
   and Systems (AICAS)
CY JUN 06-09, 2021
CL ELECTR NETWORK
ID MACRO
AB The unprecedented growth in Deep Neural Networks (DNN) model size has resulted into a massive amount of data movement from off-chip memory to on-chip processing cores in modern Machine Learning (ML) accelerators. Compute-In-Memory (CIM) designs performing DNN computations within memory arrays are being explored to mitigate this 'Memory Wall' bottleneck of latency and energy overheads. Among the incumbent embedded memories, the Static Access Random Memory (SRAM) built using high performance logic transistors and interconnects can enable custom CIM designs while offering low pJ/bit access energy, high-endurance, high-performance, and high- bandwidth. The wordline and bitline voltages and pulse-widths are modulated to realize analog or digital domain multiply-and-accumulate (MAC) computations using multiple SRAM bitcell variants. This paper describes the trends in recent CIM-SRAM designs utilizing such analog and digitally-intensive approaches. In an analog CIM-SRAM design,the inputs/activations are transformed into analog voltage or pulsewidth and applied on wordlines and/or bitlines. Multi-bit MAC computations often involve peripheral data converter circuits which need to be optimized significantly to minimize the area and energy overheads. On the other hand, digitally-intensive CIM-SRAM approaches try to avoid analog circuits by implementing smaller bit-width wordline/bitline computations and utilize sense amplifiers for performing basic logic operations and/or employ small digital logic block next to the SRAM column I/O circuits forming compute-in/near SRAM designs. Key design trends in both the approaches and qualitative comparisons are presented with a perspective on future CIM-SRAM designs.
C1 [Sehgal, Rishabh; Kulkarni, Jaydeep P.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78751 USA.
RP Sehgal, R (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78751 USA.
EM sehgal.rish@utexas.edu; jaydeep@austin.utexas.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agrawal A, 2020, IEEE J EM SEL TOP C, V10, P295, DOI 10.1109/JETCAS.2020.3014250
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chiu YC, 2020, IEEE J SOLID-ST CIRC, V55, P2790, DOI 10.1109/JSSC.2020.3005754
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Guo B, 2017, IEEE T MOBILE COMPUT, V16, P2379, DOI 10.1109/TMC.2016.2620980
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/VLSIC.2019.8778028, 10.23919/vlsic.2019.8778028]
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/vlsic.2019.8778160, 10.23919/VLSIC.2019.8778160]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Wang J, 2020, IEEE JSSC, P240
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zhang J, 2017, IEEE JSSC, V52, P915
NR 21
TC 0
Z9 0
U1 0
U2 4
PY 2021
DI 10.1109/AICAS51828.2021.9458576
UT WOS:000722241000081
DA 2023-11-16
ER

PT C
AU Nardi, L
   Koeplinger, D
   Olukotun, K
AF Nardi, Luigi
   Koeplinger, David
   Olukotun, Kunle
GP IEEE
TI Practical Design Space Exploration
SO 2019 IEEE 27TH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS, AND
   SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS (MASCOTS 2019)
SE International Symposium on Modeling Analysis and Simulation of Computer
   and Telecommunication Systems Proceedings
DT Proceedings Paper
CT IEEE 27th International Symposium on Modeling, Analysis, and Simulation
   of Computer and Telecommunication Systems (MASCOTS)
CY OCT 22-25, 2019
CL Rennes, FRANCE
DE Pareto-optimal front; Design space exploration; Hardware design;
   Performance modeling; Optimizing compilers; Machine learning driven
   optimization
AB Multi-objective optimization is a crucial matter in computer systems design space exploration because real-world applications often rely on a trade-off between several objectives. Derivatives are usually not available or impractical to compute and the feasibility of an experiment can not always be determined in advance. These problems are particularly difficult when the feasible region is relatively small, and it may be prohibitive to even find a feasible experiment, let alone an optimal one.
   We introduce a new methodology and corresponding software framework, HyperMapper 2.0, which handles multi-objective optimization, unknown feasibility constraints, and categorical/ordinal variables. This new methodology also supports injection of the user prior knowledge in the search when available. All of these features are common requirements in computer systems but rarely exposed in existing design space exploration systems. The proposed methodology follows a white-box model which is simple to understand and interpret (unlike, for example, neural networks) and can be used by the user to better understand the results of the automatic search.
   We apply and evaluate the new methodology to the automatic static tuning of hardware accelerators within the recently introduced Spatial programming language, with minimization of design run-time and compute logic under the constraint of the design fitting in a target field-programmable gate array chip. Our results show that HyperMapper 2.0 provides better Pareto fronts compared to state-of-the-art baselines, with better or competitive hypervolume indicator and with 8x improvement in sampling budget for most of the benchmarks explored.
C1 [Nardi, Luigi; Koeplinger, David; Olukotun, Kunle] Stanford Univ, Stanford, CA 94305 USA.
RP Nardi, L (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM lnardi@stanford.edu; dkoeplin@stanford.edu; kunle@stanford.edu
CR [Anonymous], 2013, DESIGN ANAL COMPUTER
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Bachrach J, 2012, DES AUT CON, P1212
   Balaprakash P, 2016, LECT NOTES COMPUT SC, V9697, P219, DOI 10.1007/978-3-319-41321-1_12
   Balaprakash Prasanna, 2013, IEEE INT C CL COMP
   Bergstra J., 2011, P 24 INT C NEURAL IN, P2546
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bodin B, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P57, DOI 10.1145/2967938.2967963
   Breiman L., 2001, MACH LEARN, V45, P5
   Cianfriglia Marco, 2018, ARXIV PREPRINT ARXIV
   Conn AR, 2009, MOS-SIAM SER OPTIMIZ, V8, P1
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1501/0000000035, 10.1561/0600000035]
   Eunsuk Kang, 2010, Foundations of Computer Software. Modeling, Development, and Verification of Adaptive Systems. 16th Monterey Workshop 2010. Revised Selected Papers, P33, DOI 10.1007/978-3-642-21292-5_3
   Feliot P, 2017, J GLOBAL OPTIM, V67, P97, DOI 10.1007/s10898-016-0427-3
   Gardner JR, 2014, PR MACH LEARN RES, V32, P937
   Gelbart MA, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P250
   Hutter Frank, 2011, Learning and Intelligent Optimization. 5th International Conference, LION 5. Selected Papers, P507, DOI 10.1007/978-3-642-25566-3_40
   Ipek Engin, 2006, EFFICIENTLY EXPLORIN, V41
   Khan S., 2007, 16 INT C PARALLEL AR, P327
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Koeplinger D, 2016, CONF PROC INT SYMP C, P115, DOI 10.1109/ISCA.2016.20
   Nardi L, 2017, IEEE SYM PARA DISTR, P1434, DOI 10.1109/IPDPSW.2017.107
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Rios LM, 2013, J GLOBAL OPTIM, V56, P1247, DOI 10.1007/s10898-012-9951-y
   Saeedi Sajad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5716, DOI 10.1109/ICRA.2017.7989673
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Siegmund N, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P284, DOI 10.1145/2786805.2786845
   Siegmund N, 2012, PROC INT CONF SOFTW, P167, DOI 10.1109/ICSE.2012.6227196
   Snoek J., 2012, ADV NEURAL INFORM PR, V25, P1
   Snoek J, 2015, PR MACH LEARN RES, V37, P2171
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Swiler L.P., 2014, CONSTRAINT PROGRAMMI, P181, DOI DOI 10.1007/978-3-319-04280-0_21
   Zuluaga Marcela, 2013, INT C MACHINE LEARNI, V28, P462
NR 34
TC 25
Z9 25
U1 0
U2 0
PY 2019
BP 347
EP 358
DI 10.1109/MASCOTS.2019.00045
UT WOS:000701363400034
DA 2023-11-16
ER

PT J
AU Fisher, NI
AF Fisher, N. I.
TI A Conversation with Jerry Friedman
SO STATISTICAL SCIENCE
DT Article
DE ACE; boosting; CART; machine learning; MARS; MART; projection pursuit;
   RuleFit; statistical computing; statistical graphics; statistical
   learning
ID PROJECTION PURSUIT; STATISTICAL VIEW; REGRESSION; APPROXIMATION
AB Jerome H. Friedman was born in Yreka, California, USA, on December 29, 1939. He received his high school education at Yreka High School, then spent two years at Chico State College before transferring to the University of California at Berkeley in 1959. He completed an undergraduate degree in physics in 1962 and a Ph.D. in high-energy particle physics in 1968 and was a post-doctoral research physicist at the Lawrence Berkeley Laboratory during 1968-1972. In 1972, he moved to Stanford Linear Accelerator Center (SLAC) as head of the Computation Research Group, retaining this position until 2006. In 1981, he was appointed half time as Professor in the Department of Statistics, Stanford University, remaining half time with his SLAC appointment. He has held visiting appointments at CSIRO in Sydney, CERN and the Department of Statistics at Berkeley, and has had a very active career as a commercial consultant. Jerry became Professor Emeritus in the Department of Statistics in 2007. Apart from some 30 publications in high-energy physics early in his career, Jerry has published over 70 research articles and books in statistics and computer science, including co-authoring the pioneering books Classification and Regression Trees and The Elements of Statistical Learning. Many of his publications have hundreds if not thousands of citations (e.g., the CART book has over 21,000). Much of his software is incorporated in commercial products, including at least one popular search engine. Many of his methods and algorithms are essential inclusions in modern statistical and data mining packages. Honors include the following: the Rietz Lecture (1999) and the Wald Lectures (2009); election to the American Academy of Arts and Sciences (2005) and the US National Academy of Sciences (2010); a Fellow of the American Statistical Association; Paper of the Year (JASA 1980, 1985; Technometrics 1998, 1992); Statistician of the Year (ASA, Chicago Chapter, 1999); ACM Data Mining Lifetime Innovation Award (2002), Emanuel & Carol Parzen Award for Statistical Innovation (2004); Noether Senior Lecturer (American Statistical Association, 2010); and the IEEE Computer Society Data Mining Research Contribution Award (2012).
   The interview was recorded at his home in Palo Alto, California during 3-4 August 2012.
RP Fisher, NI (corresponding author), Univ Sydney, Sch Math & Stat F07, Stat, Sydney, NSW 2006, Australia.
EM Nicholas.Fisher@sydney.edu.au
CR [Anonymous], 1977, CHEMOMETRICS THEORY, DOI DOI 10.1021/BK-1977-0052
   [Anonymous], 5 STANDF U LAB COMP
   Breiman L, 1997, J ROY STAT SOC B MET, V59, P3, DOI 10.1111/1467-9868.00054
   BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473
   Breiman L., 1996, 460 U CAL BERK
   Breiman Leo, 1984, CLASSIFICATION REGRE
   Brillinger DR, 2002, ANN STAT, V30, P1535
   Cover T. M., 1967, IEEE T INFORM THEORY, V13, P2
   de Boor C., 2001, PRACTICAL GUIDE SPLI, V27
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Fisher N. I., 2015, CONVERSATION JERRY S, DOI [10.1214/14-STS509SUPP, DOI 10.1214/14-STS509SUPP]
   Fithian W, 2013, ANN APPL STAT, V7, P1917, DOI 10.1214/13-AOAS667
   FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656
   FREUND Y, 1996, MACH LEARN P 13 INT, V13, P148
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Friedman J. H., 1989, S STAT SCI IND PUBL
   Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817
   FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051
   FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2002, ANN STAT, V30, P1629
   FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722
   FRIEDMAN JH, 1983, ANN STAT, V11, P377, DOI 10.1214/aos/1176346148
   Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914
   FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963
   Friedman JH, 2001, INT STAT REV, V69, P5, DOI 10.1111/j.1751-5823.2001.tb00474.x
   FRIEDMAN JH, 1983, SIAM J SCI STAT COMP, V4, P291, DOI 10.1137/0904023
   FRIEDMAN JH, 1984, J AM STAT ASSOC, V79, P599, DOI 10.2307/2288406
   Hastie T., 2001, ELEMENTS STAT LEARNI
   Kipling R., 1886, 2 LAST COUPLET BETRO
   MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276
   OREAR J., 1982, NOTES STAT PHYS REV
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   TUKEY JW, 1962, ANN MATH STAT, V33, P1, DOI 10.1214/aoms/1177704711
   VARIAN H., 2009, HAL VARIAN WEB CHALE
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 39
TC 2
Z9 2
U1 0
U2 10
PD MAY
PY 2015
VL 30
IS 2
BP 268
EP 295
DI 10.1214/14-STS509
UT WOS:000356644100013
DA 2023-11-16
ER

PT C
AU Jeong, H
   Chen, DM
AF Jeong, Hyunmin
   Chen, Deming
GP IEEE Comp Soc
TI TwinDNN: A Tale of Two Deep Neural Networks
SO 2021 IEEE 32ND INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2021)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 32nd IEEE International Conference on Application-specific Systems,
   Architectures and Processors (ASAP)
CY JUL 07-08, 2021
CL ELECTR NETWORK
DE Hardware Accelerator; High-Level-Synthesis; Machine Learning; Neural
   Network Quantization
AB Compression technologies for deep neural networks (DNNs), such as weight quantization, have been widely investigated to reduce the model size so that they can be implemented on hardware with strict resource restrictions. However, one major downside of model compression is accuracy degradation. To deal with this problem effectively, we propose a new compressed network inference scheme with a high accuracy but slower DNN coupled with its highly compressed DNN version that typically delivers much faster inference speed but with a lower accuracy. During the inference, we determine the confidence of the prediction of the compressed DNN, and infer the original neural network for the inputs that are considered not confident by the compressed DNN. The proposed design uses a balanced number of resources available on the hardware and can deliver overall accuracy close to the high accuracy model, but with the inference speed closer to the compressed DNN. We demonstrate our design on two image classification tasks: CIFAR-10 and ImageNet. Our experiments show that our design can recover up to 94% of accuracy drop caused by extreme network compression, with more than 90% speedup compared to just using the original DNN. This is more than 17% extra accuracy recovery and 36% extra speedup compared to the previous work with a similar concept on VGG-16. This is the first work that considers using a highly compressed DNN along with the original DNN in parallel to achieve high accuracy and speed at the same time, while maintaining the resource balance by using two different main computation sources efficiently on an FPGA.
C1 [Jeong, Hyunmin; Chen, Deming] Univ Illinois, Elect & Comp Engn, Champaign, IL 61820 USA.
RP Jeong, H (corresponding author), Univ Illinois, Elect & Comp Engn, Champaign, IL 61820 USA.
EM hyunmin2@illinois.edu; dchen@illinois.edu
CR Amiri S, 2018, DES AUT TEST EUROPE, P419, DOI 10.23919/DATE.2018.8342046
   [Anonymous], 2016, DOREFANET TRAINING L
   Chen D., 2017, IET CYBER PHYS SYSTE
   Chen Y, 2019, IEEE COMP SOC ANN, P13, DOI 10.1109/ISVLSI.2019.00012
   Courbariaux M, 2015, ADV NEURAL INFORM PR
   Dbouk H., 2020, EUR C COMP VIS ECCV
   Han S., 2016, P INT C LEARNING REP
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ST, 2019, IEEE HIGH PERF EXTR
   Hubara I, 2018, J MACH LEARN RES, V18
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kouris A, 2018, I C FIELD PROG LOGIC, P155, DOI 10.1109/FPL.2018.00034
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li F., 2016, COMPUTING RES REPOSI
   Liu D, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577370
   Misra A., 2020, INT S APPL REC COMP
   Mocerino L., 2014, COMPUTING RES REPOSI
   NVIDIA, TENSORRT
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang JS, 2018, I C FIELD PROG LOGIC, P163, DOI 10.1109/FPL.2018.00035
   Xilinx, DEEP LEARN INT8 OPT
   Zhang X., 2018, ICCAD-IEEE ACM INT, P1, DOI DOI 10.1145/3240765.3240801
   Zhang X., 2020, P MACHINE LEARNING S, V2, P216
   Zhang XF, 2017, ICCAD-IEEE ACM INT, P894, DOI 10.1109/ICCAD.2017.8203875
   Zhao R, 2019, PR MACH LEARN RES, V97
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
NR 26
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 133
EP 140
DI 10.1109/ASAP52443.2021.00027
UT WOS:000698747200020
DA 2023-11-16
ER

PT J
AU Gonugondla, SK
   Sakr, C
   Dbouk, H
   Shanbhag, NR
AF Gonugondla, Sujan K.
   Sakr, Charbel
   Dbouk, Hassan
   Shanbhag, Naresh R.
TI Fundamental Limits on Energy-Delay-Accuracy of In-Memory Architectures
   in Inference Applications
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Analog-to-digital converter (ADC); compute-in-memory; fundamental
   limits; in-memory; machine-learning; precision limits; quantization;
   signal-to-noise ratio (SNR); SRAM
ID COMPUTING SRAM MACRO; ACCELERATOR; XNOR
AB This article obtains fundamental limits on the computational precision of in-memory computing architectures (IMCs). An IMC noise model and associated signal-to-noise ratio (SNR) metrics are defined and their interrelationships analyzed to show that the accuracy of IMCs is fundamentally limited by the compute SNR (SNRa) of its analog core, and that activation, weight, and output (ADC) precision needs to be assigned appropriately for the final output SNR (SNRT) to approach SNRa. The minimum precision criterion (MPC) is proposed to minimize the analog-to-digital converter (ADC) precision and hence its overhead. Three in-memory compute models-charge summing (QS), current summing (IS), and charge redistribution (QR)-are shown to underlie most known IMCs. Noise, energy, and delay expressions for the compute models are developed and employed to derive expressions for the SNR, ADC precision, energy, and latency of IMCs. The compute SNR expressions are validated via Monte Carlo simulations in a 65 nm CMOS process. For a 512 row SRAM array, it is shown that: 1) IMCs have an upper bound on their maximum achievable SNRa due to constraints on energy, area and voltage swing, and this upper bound reduces with technology scaling for QS-based architectures; 2) MPC enables SNRT to approach SNRa to be realized with minimal ADC precision; and 3) QS-based (QR-based) architectures are preferred for low (high) compute SNR scenarios.
C1 [Gonugondla, Sujan K.; Dbouk, Hassan; Shanbhag, Naresh R.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
   [Gonugondla, Sujan K.] Amazon, Amazon Web Serv, New York, NY 10001 USA.
   [Sakr, Charbel] Univ Illinois, Urbana, IL 61801 USA.
   [Sakr, Charbel] NVIDIA, Santa Clara, CA 95051 USA.
RP Gonugondla, SK (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
EM sujangonugondla@gmail.com
CR Abu Lebdeh M, 2017, IEEE T CIRCUITS-I, V64, P2427, DOI 10.1109/TCSI.2017.2706299
   Agrawal A, 2019, IEEE T CIRCUITS-I, V66, P3064, DOI 10.1109/TCSI.2019.2907488
   Ali M, 2020, IEEE T CIRCUITS-I, V67, P2521, DOI 10.1109/TCSI.2020.2981901
   [Anonymous], 2019, ADC PERFORMANCE SURV
   Bankman D, 2016, IEEE ASIAN SOLID STA, P21, DOI 10.1109/ASSCC.2016.7844125
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Dbouk H., 2020, IEEE CUST INTEGR CIR, P1, DOI [10.1109/CICC48029.2020.9075923, DOI 10.1109/cicc48029.2020.9075923]
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Goel M, 1998, IEEE T SIGNAL PROCES, V46, P1763, DOI 10.1109/78.678521
   Gong MX, 2021, IEEE T CIRCUITS-II, V68, P1408, DOI 10.1109/TCSII.2020.3027801
   Gonugondla S. K., 2020, ICCAD, P1
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/VLSIC.2019.8778028, 10.23919/vlsic.2019.8778028]
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   ITRS-Collaborations, 2015, REP ITRS 2015
   Jaiswal A, 2020, IEEE T CIRCUITS-I, V67, P4651, DOI 10.1109/TCSI.2020.3005783
   Jaiswal A, 2019, IEEE T VLSI SYST, V27, P2556, DOI 10.1109/TVLSI.2019.2929245
   Jia Hongyang, 2018, Arxiv, DOI arXiv:1811.04047
   Jiang ZW, 2020, IEEE J SOLID-ST CIRC, V55, P1888, DOI 10.1109/JSSC.2020.2992886
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang M., 2020, DEEP IN MEMORY ARCHI
   Kang M, 2020, IEEE T CIRCUITS-I, V67, P1627, DOI 10.1109/TCSI.2019.2960841
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/vlsic.2019.8778160, 10.23919/VLSIC.2019.8778160]
   Kneip A, 2021, IEEE T CIRCUITS-I, V68, P1931, DOI 10.1109/TCSI.2021.3058510
   Gonugondla SK, 2020, Arxiv, DOI arXiv:2012.13645
   Liu ZY, 2020, IEEE T CIRCUITS-I, V67, P2909, DOI 10.1109/TCSI.2020.2984161
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Murmann B, 2008, IEEE CUST INTEGR CIR, P105, DOI 10.1109/CICC.2008.4672032
   Murmann B, 2021, IEEE T VLSI SYST, V29, P3, DOI 10.1109/TVLSI.2020.3020286
   Okumura S, 2019, S VLSI TECH, pC248
   Rekhi AS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317770
   Sakr C., 2017, P INT C MACH LEAR, P3007
   Sakr C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1090, DOI 10.1109/ICASSP.2018.8461702
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Srinivasa S, 2019, IEEE T CIRCUITS-I, V66, P2533, DOI 10.1109/TCSI.2019.2897497
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Tripathi V, 2014, IEEE T CIRCUITS-I, V61, P2236, DOI 10.1109/TCSI.2014.2332264
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   WEGMANN G, 1987, IEEE J SOLID-ST CIRC, V22, P1091, DOI 10.1109/JSSC.1987.1052859
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yin SH, 2020, IEEE T VLSI SYST, V28, P48, DOI 10.1109/TVLSI.2019.2940649
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang S, 2020, IEEE T CIRCUITS-I, V67, P1867, DOI 10.1109/TCSI.2020.2971642
NR 52
TC 1
Z9 1
U1 0
U2 0
PD OCT
PY 2022
VL 41
IS 10
BP 3188
EP 3201
DI 10.1109/TCAD.2021.3124757
UT WOS:000856129900006
DA 2023-11-16
ER

PT J
AU Xin, Y
   Chen, DL
   Zeng, CY
   Zhang, WC
   Wang, Y
   Cheung, RCC
AF Xin, Yao
   Chen, Donglong
   Zeng, Chongyang
   Zhang, Weichen
   Wang, Yi
   Cheung, Ray C. C.
TI High Throughput Hardware/Software Heterogeneous System for RRPN-Based
   Scene Text Detection
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Proposals; Hardware; Field programmable gate arrays; Central Processing
   Unit; Computer architecture; Graphics processing units; Throughput;
   Convolutional neural networks (CNN); rotation region proposal networks
   (RRPN); scene text detection (STD); filed programmable gate array
   (FPGA); hardware architecture for machine learning
ID NEURAL-NETWORK; CNN ACCELERATOR
AB Rotation Region Proposal Networks (RRPN) are used to generate rotated proposals with the information of text angle for arbitrary oriented scene text detection (STD). However, the computational complexity of RRPN inference is relatively high compared with other methods, which makes it difficult for massive deployment. In this paper, the first full-stack FPGA-CPU heterogeneous system design of RRPN-based STD algorithm is proposed. A hardware/software partition method is presented to analyze and split the tasks to enhance the computation efficiency of hardware. The fast 2D Winograd algorithm and block floating point are utilized to reduce computation complexity while maintaining a relatively high precision. The implementation results show that the peak performance of MAC arrays in the proposed architecture reaches 655.4 GOPS and the energy efficiency achieves 64.9 GOPS/W. By fully exploiting the parallel and pipelined merits in the algorithms, the first hardware architectures for skew non-maximum suppression (S-NMS) layer and rotation region-of-interest (RRoI) polling layer are proposed. The throughput of the proposed hardware/software heterogeneous system achieves 40 times and 1.4 times improvements compared with CPU and GPU, respectively. Moreover, the comprehensive operating expense ratio of pure CPU, GPU, and the proposed system is 80.7:2.5:1, which indicates that it is suitable for massive deployment.
C1 [Xin, Yao; Wang, Yi] Peng Cheng Lab PCL, Shenzhen 518066, Peoples R China.
   [Chen, Donglong] BNU HKBU United Int Coll UIC, Zhuhai 519085, Peoples R China.
   [Zeng, Chongyang] Tencent Technol Co Ltd, Shenzhen, Peoples R China.
   [Zhang, Weichen] Ant Financial Serv Grp, Shenzhen 518000, Peoples R China.
   [Cheung, Ray C. C.] City Univ Hong Kong, Hong Kong, Peoples R China.
RP Chen, DL (corresponding author), BNU HKBU United Int Coll UIC, Zhuhai 519085, Peoples R China.
EM xiny@pcl.ac.cn; donglongchen@uic.edu.cn; zengchongyang@outlook.com;
   weichen.zwc@antgroup.com; wangyi@pcl.ac.cn; r.cheung@cityu.edu.hk
CR Ahmad A, 2019, DES AUT TEST EUROPE, P1106, DOI [10.23919/DATE.2019.8715272, 10.23919/date.2019.8715272]
   [Anonymous], 1980, ARITHMETIC COMPLEXIT
   Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584
   Drumond Mario, 2018, P 32 INT C NEURAL IN, P451
   Ferianc Martin, 2020, Applied Reconfigurable Computing Architectures, Tools, and Applications. 16th International Symposium, ARC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 120830), P3, DOI 10.1007/978-3-030-44534-8_1
   Guan YJ, 2017, LECT NOTES COMPUT SC, V10561, P14, DOI 10.1007/978-3-319-67952-5_2
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kala S, 2019, IEEE T VLSI SYST, V27, P2816, DOI 10.1109/TVLSI.2019.2941250
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li YX, 2020, NEUROCOMPUTING, V398, P45, DOI 10.1016/j.neucom.2020.02.012
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liang Y, 2020, IEEE T COMPUT AID D, V39, P857, DOI 10.1109/TCAD.2019.2897701
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shen JZ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P97, DOI 10.1145/3174243.3174257
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song ZR, 2018, AAAI CONF ARTIF INTE, P816
   Wang EW, 2020, IEEE T COMPUT, V69, P1795, DOI 10.1109/TC.2020.2978817
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Wu E., 2017, I C FIELD PROG LOGIC, P1
   Xing Y, 2020, IEEE T COMPUT AID D, V39, P2668, DOI 10.1109/TCAD.2019.2930577
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yu XY, 2019, I C FIELD PROG LOGIC, P151, DOI 10.1109/FPL.2019.00032
   Yu Y, 2021, IEEE T COMPUT, V70, P45, DOI 10.1109/TC.2020.2983694
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhang QR, 2019, NEUROCOMPUTING, V323, P37, DOI 10.1016/j.neucom.2018.09.038
   Zhao R., 2018, P 2018 ACMSIGDA INT, P285
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 43
TC 1
Z9 1
U1 1
U2 10
PD JUL 1
PY 2022
VL 71
IS 7
BP 1507
EP 1521
DI 10.1109/TC.2021.3092195
UT WOS:000808068000002
DA 2023-11-16
ER

PT C
AU De Bonis, G
   Bozza, C
AF De Bonis, Giulia
   Bozza, Cristiano
BE Morselli, A
   Capone, A
   Fernandez, GR
TI The pLISA project in ASTERICS
SO RICAP16, 6TH ROMA INTERNATIONAL CONFERENCE ON ASTROPARTICLE PHYSICS
SE EPJ Web of Conferences
DT Proceedings Paper
CT 6th Roma International Conference on Astroparticle Physics (RICAP)
CY JUN 21-24, 2016
CL Rome, ITALY
AB In the framework of Horizon 2020, the European Commission approved the ASTERICS initiative (ASTronomy ESFRI and Research Infrastructure CluSter) to collect knowledge and experiences from astronomy, astrophysics and particle physics and foster synergies among existing research infrastructures and scientific communities, hence paving the way for future ones. ASTERICS aims at producing a common set of tools and strategies to be applied in Astronomy ESFRI facilities. In particular, it will target the so-called multi-messenger approach to combine information from optical and radio telescopes, photon counters and neutrino telescopes. pLISA is a software tool under development in ASTERICS to help and promote machine learning as a unified approach to multivariate analysis of astrophysical data and signals. The library will offer a collection of classification parameters, estimators, classes and methods to be linked and used in reconstruction programs (and possibly also extended), to characterize events in terms of particle identification and energy. The pLISA library aims at offering the software infrastructure for applications developed inside different experiments and has been designed with an effort to extrapolate general, physics-related estimators from the specific features of the data model related to each particular experiment. pLISA is oriented towards parallel computing architectures, with awareness of the opportunity of using GPUs as accelerators demanding specifically optimized algorithms and to reduce the costs of processing hardware requested for the reconstruction tasks. Indeed, a fast (ideally, real-time) reconstruction can open the way for the development or improvement of alert systems, typically required by multi-messenger search programmes among the different experimental facilities involved in ASTERICS.
C1 [De Bonis, Giulia] Ist Nazl Fis Nucl, Sez Roma, Rome, Italy.
   [Bozza, Cristiano] Univ Salerno, Dipartimento Fis ER Caianiello, Fisciano, Italy.
   [Bozza, Cristiano] Ist Nazl Fis Nucl, Grp Collegato Salerno, Fisciano, Italy.
RP De Bonis, G (corresponding author), Ist Nazl Fis Nucl, Sez Roma, Rome, Italy.
EM giulia.debonis@roma1.infn.it; cbozza@unisa.it
CR De Bonis G, 2016, EPJ WEB CONF, V121, DOI 10.1051/epjconf/201612105014
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed.
   Sanders J., 2011, CUDA BY EXAMPLES
NR 3
TC 0
Z9 0
U1 0
U2 2
PY 2017
VL 136
AR 01006
DI 10.1051/epjconf/201713601006
UT WOS:000405958300006
DA 2023-11-16
ER

PT C
AU Wang, DH
   Foran, DJ
   Qi, X
   Parashar, M
AF Wang, Daihou
   Foran, David J.
   Qi, Xin
   Parashar, Manish
GP IEEE
TI HetroCV: Auto-tuning Framework and Runtime for Image Processing and
   Computer Vision Applications on Heterogeneous Platform
SO 2015 44TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING WORKSHOPS
SE International Conference on Parallel Processing Workshops
DT Proceedings Paper
CT 44th Annual International Conference on Parallel Processing Workshops
   (ICPPW)
CY SEP 01-04, 2015
CL Beijing, PEOPLES R CHINA
DE Online auto-tuning; runtime; heterogeneous platform; Intel MIC
   architecture; image processing
AB With the wide adoption of high-performance processors and accelerators, large-scale computer vision applications have gained great performance improvement. However, it often requires extensive experiments and expertise to achieve optimal performance from manually-tuned programs, and the programs often need to be re-tuned when transplanted to a different platform, or using a different system configuration.
   To overcome this problem, in this paper we proposed HetroCV, a programmer-directed auto-tuning framework and runtime for computer vision applications on heterogeneous CPU-MIC platform. In HetroCV auto-tuning framework, computation units in the application pipeline are categorized in to one of three patterns: Map, Stencil and MapReduce, and program statistics are extracted from units' meta-information. Machine learning is adopted to train models for each pattern using the tuned parameters and program statistics from trial-run sets, so that when a new unit is presented, HetroCV autotuner can use the corresponding trained model to generate optimized tuning parameters. In HetroCV runtime, performance models for processor and co-processor are built to predict the prospective execution time of each computation unit in the application pipeline. We adopted the maximum-throughput mapping strategy, thus each unit would be mapped dynamically to the processor/co-processor queue, which would generate the minimum overall execution time.
   Experiments on two medical image processing applications running on heterogeneous platform composed of Intel Xeon CPU and Intel Phi co-processor showed advanced performance over naive OpenMP tuning and Genetic Algorithm (GA) based heuristic tuning.
C1 [Wang, Daihou; Parashar, Manish] Rutgers State Univ, Rutgers Discovery Informat Inst, Piscataway, NJ 08854 USA.
   [Foran, David J.; Qi, Xin] Rutgers Canc Inst New Jersey, New Brunswick, NJ USA.
RP Wang, DH (corresponding author), Rutgers State Univ, Rutgers Discovery Informat Inst, Piscataway, NJ 08854 USA.
EM daihou.wang@rutgers.edu; foran@cinj.rutgers.edu; qixi@cinj.rutgers.edu;
   parashar@rutgers.edu
CR [Anonymous], 2011, P 2011 INT C HIGH PE
   [Anonymous], 2004, P 6 S OP SYST DES I
   Ansel J., P 30 ACM SIGPLAN C P, P38
   Ansel J, 2012, CASES'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURES AND SYNTHESIS FOR EMBEDDED SYSTEMS, P91
   Basu P., 2013, INT J HIGH PERFO NOV, P379
   Boyer M., P 27 INT PAR DISTR P, P1097
   Boyer M., P IEEE INT S PAR DIS, P1
   Brown K. J., P 2011 INT C PAR ARC, P89
   Dwith CYN, 2012, 2012 13TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS, AND TECHNOLOGIES (PDCAT 2012), P755, DOI 10.1109/PDCAT.2012.107
   Hong S., P 36 ANN INT S COMP, P152
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Membarth R, 2012, INT PARALL DISTRIB P, P569, DOI 10.1109/IPDPS.2012.59
   Meng J., P 2011 INT C HIGH PE, P1
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Muralidharan S., P IEEE 28 INT PAR DI, P501
   Phothilimthana P. M., P 18 INT C ARCH SUPP, P431
   Poli G., P 20 INT S ARCH COMP, P81
   Qi X, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-287
   Qi X, 2012, IEEE T BIO-MED ENG, V59, P754, DOI 10.1109/TBME.2011.2179298
   Ragan-Kelley J., P 34 ACM SIGPLAN C P, P519
   Shin Jaewook, P 24 ACM INT C SUP I, P253
   Sujeeth A. K., P 28 INT C MACH LEAR
   Sujeeth Arvind K., 2013, P 12 INT C GEN PROGR
   Teodoro G, 2013, INT PARALL DISTRIB P, P103, DOI 10.1109/IPDPS.2013.11
   Teodoro G, 2012, INT PARALL DISTRIB P, P1093, DOI 10.1109/IPDPS.2012.101
   Walker D. W., P CLOUDS DAT SCI COM
   Walters J. P., P IEEE INT S PAR DIS, P1
NR 27
TC 3
Z9 3
U1 0
U2 0
PY 2015
BP 119
EP 128
DI 10.1109/ICPPW.2015.21
UT WOS:000377378800018
DA 2023-11-16
ER

PT C
AU Sabih, M
   Hannig, F
   Teich, J
AF Sabih, Muhammad
   Hannig, Frank
   Teich, Juergen
GP IEEE Comp Soc
TI Fault-Tolerant Low-Precision DNNs using Explainable AI
SO 51ST ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND
   NETWORKS (DSN-W 2021)
SE International Conference on Dependable Systems and Networks Workshops
DT Proceedings Paper
CT 51st Annual IEEE/IFIP International Conference on Dependable Systems and
   Networks (DSN)
CY JUN 21-24, 2021
CL ELECTR NETWORK
DE Explainable AI; reliable DNNs; robust DNNs
AB Hardware-efficient machine learning systems deployed in safety-critical systems need to be optimized for two conflicting objectives. One is making neural networks more compact and efficient by techniques such as quantization and pruning. The other is making them robust against faults. Robustness of Deep Neural Networks (DNNs) becomes a challenge in low-bit precision neural networks such as networks quantized with 8-bit integer precision or less and on custom DNN accelerators with emerging memory technologies and techniques such as approximate memory. Errors in the processing of DNNs can be modeled as bit-flips at the software level. These bit-flips can be caused by persistent memory errors, manifesting themselves in corrupted DNN weights, or they can be caused by transient soft errors.
   In this work, we introduce an open-source fault-injection frame-work to simulate both persistent errors and transient errors on PyTorch. Subsequently, we propose novel algorithms that utilize explainable Al methods to make DNNs robust against both kinds, i.e., persistent memory errors and transient soft errors, while keeping the overhead small. We show that our approach can be beneficially used here to mitigate (1) persistent errors by identifying important bits in weights and selectively protecting these using error correcting codes, and (2) transient errors by identifying important samples in activations and selectively protecting these using Triple Modular Redundancy (TMR). Our proposed method outperforms the previously known work on selectively protecting DNN bits in terms of performance and creates further opportunities for research in the area of utilizing explainable AI for robustness.
C1 [Sabih, Muhammad; Hannig, Frank; Teich, Juergen] Friedrich Alexander Univ Erlangen Nurnberg FAU, Erlangen, Germany.
RP Sabih, M (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg FAU, Erlangen, Germany.
EM muhammad.sabih@fau.de; frank.hannig@fau.de; juergen.teich@fau.de
CR [Anonymous], 2006, ART ERROR CORRECTING, DOI DOI 10.1002/0470035706
   [Anonymous], 2018, 26262 ISO
   Binder A, 2016, LECT NOTES COMPUT SC, V9887, P63, DOI 10.1007/978-3-319-44781-0_8
   Chen E., 2010, 2010 68th Annual Device Research Conference (DRC 2010), P249, DOI 10.1109/DRC.2010.5551975
   chenyaofo, 2019, PRETR MOD CIFAR10 10
   Conti F., 2020, ARXIV200405930CSLG
   Dhamdhere K., 2018, ARXIV180512233CSLG
   Fellow, 2019, CORR, V14, P1, DOI 10.1109/tnnls.2020.3027314
   GUAN H, 2019, ARXIV PREPRINT ARXIV
   Herkersdorf A., 2021, DEPENDABLE EMBEDDED, P1, DOI [10.1007/978- 3-030-52017-5 1, DOI 10.1007/978-3-030-52017-51]
   Hirtzlin T., 2019, 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS). Proceedings, P288, DOI 10.1109/AICAS.2019.8771544
   Huang KP, 2020, IEEE INT SYMP INFO, P2694, DOI [10.1109/isit44484.2020.9174137, 10.1109/ISIT44484.2020.9174137]
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kokhlikyan Narine, 2019, PYTORCH CAPTUM
   LeCun Y., 1998, MNIST DATABASE HANDW
   Leino K., 2018, P IEEE INT TEST C IT, P1
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Ning X., 2020, ARXIV200310375EESSSP
   Paszke A, 2019, ADV NEUR IN, V32
   Sabih M., 2020, ARXIV200809072CSCV
   Schorn C, 2018, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE.2018.8342151
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Van Rossum G., 2009, PYTHON 3 REFERENCE M
   Vetrov Dmitry P, 2016, NEURIPS, P947
   Zhang WC, 2019, 2019 EUROPEAN NAVIGATION CONFERENCE (ENC), DOI [10.1109/euronav.2019.8714160, 10.2991/sschd-19.2019.1, 10.1145/3316781.3317797]
NR 28
TC 4
Z9 4
U1 0
U2 1
PY 2021
BP 166
EP 174
DI 10.1109/DSN-W52860.2021.00036
UT WOS:000702266700025
DA 2023-11-16
ER

PT J
AU Shabarinath, BB
   Pullakandam, M
AF Shabarinath, B. B.
   Pullakandam, Muralidhar
TI SoC-based real-time SVM classification with integrated training using
   HLS and PYNQ
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Sequential minimal optimization; High-level synthesis; PYNQ overlay;
   System on chip; Real-time efficiency; Classification accuracy; IP core
ID SUPPORT; ALGORITHM; SYSTEM
AB Support Vector Machines (SVM) are widely used techniques in the field of classification problems because of their ability to effectively deal with datasets that have complex non-linear structures and a high dimensionality. The compute-intensive training algorithm associated with SVM makes it challenging to keep an up-to-date model that accurately reflects the characteristics of newly arriving data points in real-time systems. This paper proposes a novel training algorithm for incremental learning from large datasets, based on a variant of Sequential Minimal Optimization (SMO). High-Level Synthesis (HLS) was used for implementing the Field Programmable Gate Array (FPGA) based Intellectual Property (IP) Core, which includes the computationally intensive kernel computation portion of the training algorithm. In addition to the kernel computation, the inference phase of the SVM classifier is built into the IP core, and its use can be switched on the fly. The computational latency and memory bandwidth of an IP core are optimized using loop pipelining and DMA burst data transfer. With the help of hardware/ software co-design, the IP core is integrated into the design of a flexible and re-usable System on Chip (SoC) called PYNQ Overlay. The experiments show that the overlay outperforms the embedded processor, multiple hardware SVM classifiers, and hardware accelerated Convolutional Neural Networks (CNN) in terms of real-time efficiency. The Overlay makes much less use of the resources available on the chip in comparison to the majority of the CNN accelerators. The overlay achieves an average classification accuracy that is only 1% lower than that of an ARM Cortex-A9 processor, according to experimental results on six datasets. Furthermore, it can increase training speed by an average of 31.82x and inference speed by an average of 31.74x. In addition, the proposed Overlay design achieves a 2.3x improvement in average training speed, as measured in Mega bits per second, compared to existing SVM training implementations, along with incremental learning and multi-class classifi-cation support.
C1 [Shabarinath, B. B.; Pullakandam, Muralidhar] Natl Inst Technol Warangal, Elect & Commun Engn, Warangal 506004, Telangana, India.
RP Shabarinath, BB (corresponding author), Natl Inst Technol Warangal, Elect & Commun Engn, Warangal 506004, Telangana, India.
EM bbshabarinath@student.nitw.ac.in; pmurali@nitw.ac.in
CR [Anonymous], 1999, P WORKSH SUPP VECT M
   Baez A, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121494
   Bi MH, 2019, IEEE ACCESS, V7, P71185, DOI 10.1109/ACCESS.2019.2919344
   Chickering DM, 2004, J MACH LEARN RES, V5, P1287
   Chunjie Luo, 2019, Benchmarking, Measuring, and Optimizing. First BenchCouncil International Symposium, Bench 2018. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11459), P31, DOI 10.1007/978-3-030-32813-9_4
   Feng LC, 2018, IEEE T BIOMED CIRC S, V12, P171, DOI 10.1109/TBCAS.2017.2762721
   Glasmachers T, 2006, J MACH LEARN RES, V7, P1437
   Gomes Filho Jonas, 2010, Proceedings of the VI Southern Programmable Logic Conference (SPL), P107, DOI 10.1109/SPL.2010.5483031
   Gönen M, 2008, IEEE T NEURAL NETWOR, V19, P130, DOI 10.1109/TNN.2007.903157
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu XH, 2019, IEEE ACCESS, V7, P72113, DOI 10.1109/ACCESS.2019.2919527
   John C., 1999, FAST TRAINING SUPPOR
   Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493
   Li CH, 2011, APPL INTELL, V34, P19, DOI 10.1007/s10489-009-0176-9
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Madadum H, 2017, 2017 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P1286
   Madroa al R., 2017, J SYST ARCHITECT, V80
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Noronha DH, 2019, MICROPROCESS MICROSY, V69, P138, DOI 10.1016/j.micpro.2019.06.007
   Platt JC, 2000, ADV NEUR IN, P61
   pynq, 2022, PYNQ PYTH PROD ZYNQ
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Sudharsan Bharath, 2020, P 10 INT C INT THING, DOI [10.1145/3410992.3411014, DOI 10.1145/3410992.3411014, DOI 10.1145/3423423.3423433]
   Tsai TH, 2019, IEEE INT SYMP DESIGN, DOI 10.1109/ddecs.2019.8724665
   Venkateshan S, 2015, IEEE T VLSI SYST, V23, P2221, DOI 10.1109/TVLSI.2014.2361254
   Wang HN, 2019, INT CONF ACOUST SPEE, P1448, DOI 10.1109/ICASSP.2019.8683512
   Xu CR, 2022, IEEE T MOBILE COMPUT, V21, P2610, DOI 10.1109/TMC.2020.3041781
   Zhao Y, 2007, RTAS 2007: 13TH REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P259
   Zhou YM, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P829, DOI 10.1109/ICCSNT.2015.7490869
NR 32
TC 0
Z9 0
U1 7
U2 7
PD SEP
PY 2023
VL 101
AR 104878
DI 10.1016/j.micpro.2023.104878
EA JUN 2023
UT WOS:001013522200001
DA 2023-11-16
ER

PT C
AU Emeras, J
   Varrette, S
   Guzek, M
   Bouvry, P
AF Emeras, Joseph
   Varrette, Sebastien
   Guzek, Mateusz
   Bouvry, Pascal
BE Desai, N
   Cirne, W
TI EVALIX: Classification and Prediction of Job Resource Consumption on HPC
   Platforms
SO JOB SCHEDULING STRATEGIES FOR PARALLEL PROCESSING, JSSPP 2016
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 19th International Workshop on Job Scheduling Strategies for Parallel
   Processing (JSSPP)
CY MAY 26, 2015
CL Hyderabad, INDIA
DE RJMS; HPC; Classification; Machine learning
ID ROC CURVE; KAPPA; AREA
AB At the advent of a wished (or forced) convergence between High Performance Computing HPC platforms, stand-alone accelerators and virtualized resources from Cloud Computing CC systems, this article unveils the job prediction component of the Evalix project. This framework aims at an improved efficiency of the underlying Resource and Job Management System RJMS within heterogeneous HPC facilities by the automatic evaluation and characterization of the submitted workload. The objective is not only to better adapt the scheduled jobs to the available resource capabilities, but also to reduce the energy costs. For that purpose, we collected the resource consumption of all the jobs executed on a production cluster for a period of three months. Based on the analysis then on the classification of the jobs, we computed a resource consumption model. The objective is to train a set of predictors based on the aforementioned model, that will give the estimated CPU, memory and IO used by the jobs. The analysis of the resource consumption highlighted that different classes of jobs have different kinds of resource needs and the classification of the jobs enabled to characterize several application patterns of the users. We also discovered that several users whose resource usage on the cluster is considered as too low, are responsible for a loss of CPU time on the order of five years over the considered three month period. The predictors, trained from a supervised learning algorithm, were able to correctly classify a large set of data. We evaluated them with three performance indicators that gave an information retrieval rate of 71% to 89% and a probability of accurate prediction between 0.7 and 0.8. The results of this work will be particularly helpful for designing an optimal partitioning of the considered heterogeneous platform, taking into consideration the real application needs and thus leading to energy savings and performance improvements. Moreover, apart from the novelty of the contribution, the accurate classification scheme offers new insights of users behavior of interest for the design of future HPC platforms.
C1 [Emeras, Joseph; Guzek, Mateusz] Interdisciplinary Ctr Secur Reliabil & Trust, Luxembourg, Luxembourg.
   [Varrette, Sebastien; Bouvry, Pascal] Comp Sci & Commun CSC Res Unit, 6 Rue Richard Coudenhove Kalergi, L-1359 Luxembourg, Luxembourg.
RP Emeras, J (corresponding author), Interdisciplinary Ctr Secur Reliabil & Trust, Luxembourg, Luxembourg.
EM Joseph.Emeras@uni.lu; Sebastien.Varrette@uni.lu; Mateusz.Guzek@uni.lu;
   Pascal.Bouvry@uni.lu
CR [Anonymous], 1998, JOB SCHEDULING STRAT
   Bailey D.H., 2011, ENCY PARALLEL COMPUT
   Ben-David A, 2008, EXPERT SYST APPL, V34, P825, DOI 10.1016/j.eswa.2006.10.022
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Cao J., 2004, Proceedings. 18th International Parallel and Distributed Processing Symposium
   Capit N, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, VOLS 1 AND 2, P776
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X
   Duan RB, 2009, CCGRID: 2009 9TH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P339, DOI 10.1109/CCGRID.2009.58
   Emeras J, 2014, LECT NOTES COMPUT SC, V8429, P1, DOI 10.1007/978-3-662-43779-7_1
   FEINSTEIN AR, 1990, J CLIN EPIDEMIOL, V43, P543, DOI 10.1016/0895-4356(90)90158-L
   Feitelson D., PARALLEL WORKLOAD AR
   Feitelson DG, 2002, LECT NOTES COMPUT SC, V2459, P114
   Feitelson DG, 1997, LECT NOTES COMPUT SC, V1291, P238
   Feitelson DG, 2014, J PARALLEL DISTR COM, V74, P2967, DOI 10.1016/j.jpdc.2014.06.013
   Gibbons R, 1997, LECT NOTES COMPUT SC, V1291, P58
   Guyon I., 1997, AT T BELL LAB
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Lublin U., 2001, J PARALLEL DISTRIBUT, V63, P1105
   Matsunaga A., 2010, CCGRID
   Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P43
   Szöllosi D, 2012, J CHEMOMETR, V26, P76, DOI 10.1002/cem.2432
   Tsafrir D, 2007, IEEE T PARALL DISTR, V18, P789, DOI [10.1109/TPDS.2007.70606, 10.1109/TPDS.2007.1029]
   UEBERSAX JS, 1982, EDUC PSYCHOL MEAS, V42, P181, DOI 10.1177/0013164482421018
   Varrette S., 2014, P 2014 HPCS C
   Wolter N., 2006, CTWATCH Q, V2, P9
   Zhang J., 2006, IPDPS
NR 29
TC 6
Z9 6
U1 0
U2 1
PY 2017
VL 10353
BP 102
EP 122
DI 10.1007/978-3-319-61756-5_6
UT WOS:000441213000006
DA 2023-11-16
ER

PT J
AU Wuraola, A
   Patel, N
AF Wuraola, Adedamola
   Patel, Nitish
TI Resource efficient activation functions for neural network accelerators
SO NEUROCOMPUTING
DT Article
DE Activation function; FPGA; Square law; Deep neural network; LSTM
ID MULTILAYER FEEDFORWARD NETWORKS; NONLINEAR FUNCTION; IMPLEMENTATION;
   ARCHITECTURE; MEMORY
AB Implementations of machine learning models in resource-limited embedded systems are becoming highly desired. This has led to a need for resource-efficient building blocks for computing the mathematical operations required for neural network training and inferencing. Efficient activation functions for low-end hardware devices with limited hardware capabilities are important. In this work, we present a method for generating symmetric and asymmetric activation functions for deep and convolution neural networks. Furthermore, we propose a solution that simultaneously computes a symmetric activation function with an integrated scaling functionality for Long Short Term Memory (LSTM) models. This effectively eliminates two of the three element-wise multipliers in an LSTM cell. Also, this built-in scaling requires no additional computation time because it is integrated within the computation of the symmetric non-linear mapping. This approach replaces the need to compute several Tanh activation functions and element-wise multipliers separately. A resource-efficient approximate multiplier is also proposed to eliminate the third element-wise multiplier and potentially replace all the resource-hungry multipliers. The digital implementation of the proposed method is highly amenable to parallelization and is extremely resource-efficient. We record an area-saving on field-programmable gate arrays with different precision. Our proposal's formulaic equivalents are also computationally fast on CPU-based engines. On an embedded ARM processor, our method achieves a speedup of at least 4.37x for the proposed functions. We show that LSTMs with our method can achieve up to 3.5x resource footprint saving when compared to the hard activation implementation. We demonstrate that our method achieves competitive results with negligible loss of performance. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Wuraola, Adedamola; Patel, Nitish] Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
RP Wuraola, A (corresponding author), Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
EM awur978@aucklanduni.ac.nz; nd.patel@aucklanduni.ac.nz
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   Aymeric, 2017, TENSORFLOW EXAMPLES
   Azari E, 2019, IEEE INT CONF BIG DA, P4450, DOI 10.1109/BigData47090.2019.9006030
   Basterretxea K, 2007, IEEE T NEURAL NETWOR, V18, P266, DOI 10.1109/TNN.2006.884680
   Brownlee J, 2019, SEQUENCE CLASSIFICAT
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Chang A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P53
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Clevert Djork-Arne, 2016, ICLR 2016
   Courbariaux M., 2014, INT C LEARNING REPRE
   Deng L, 2018, NEURAL NETWORKS, V100, P49, DOI 10.1016/j.neunet.2018.01.010
   Desjardins G., 2015, ADV NEURAL INFORM PR, V28, P2071
   Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
   Fan ZC, 2013, SENSORS-BASEL, V13, P3848, DOI 10.3390/s130303848
   Fayek, 2017, J OPEN SOURCE SOFTWA, V2, P413
   Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002
   Ferreira JC, 2016, PROC INT CONF RECON
   Gomar S, 2016, CONF REC ASILOMAR C, P1586, DOI 10.1109/ACSSC.2016.7869646
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Hajduk Z, 2017, NEUROCOMPUTING, V247, P59, DOI 10.1016/j.neucom.2017.03.044
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Harrison, 2016, RNN W LSTM CELL EXAM
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hendrycks D., 2016, PREPRINT
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Intel, 2018, CYCL V DEV OV
   Kaggle, 2016, US BAB NAM EXPL NAM
   Karevan Z, 2020, NEURAL NETWORKS, V125, P1, DOI 10.1016/j.neunet.2019.12.030
   Klambauer G, 2017, ADV NEUR IN, V30
   Kouretas I, 2018, IEEE I C ELECT CIRC, P525, DOI 10.1109/ICECS.2018.8617897
   Larkin D, 2006, LECT NOTES COMPUT SC, V3973, P1319
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Liao YM, 2020, IEEE ACCESS, V8, P70733, DOI 10.1109/ACCESS.2020.2987206
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Maas Andrew L, 2013, P ICML, V30, P1
   Mahamad A, 2020, INT J INTEGR ENG, V12, P151, DOI 10.30880/ijie.2020.12.02.018
   Manimala K., 2014, INT J ADV RES COMPUT, V2, P225
   Merity S., 2017, 5 INT C LEARNING REP
   Moss DJM, 2019, IEEE T VLSI SYST, V27, P769, DOI 10.1109/TVLSI.2018.2883645
   Ramachandran P., 2017, ICLR WORKSH TRACK
   Roopal, 2017, LSTM TENSORFLOW
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Saichand V, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P159, DOI 10.1109/ISDA.2008.333
   Santorini Beatrice, 1993, COMPUT LINGUIST, V19, P313
   Scardapane S, 2019, NEURAL NETWORKS, V110, P19, DOI 10.1016/j.neunet.2018.11.002
   Siegel JW, 2020, NEURAL NETWORKS, V128, P313, DOI 10.1016/j.neunet.2020.05.019
   Sim H, 2019, NEURAL NETWORKS, V117, P152, DOI 10.1016/j.neunet.2019.04.017
   Sim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062290
   Simonyan K., 2014, VERY DEEP CONVOLUTIO
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tan K.K., 2007, PRECISION MOTION CON
   Terada Y, 2020, NEURAL NETWORKS, V129, P344, DOI 10.1016/j.neunet.2020.05.033
   Tiwari V, 2015, MICROPROCESS MICROSY, V39, P373, DOI 10.1016/j.micpro.2015.05.012
   Tommiska MT, 2003, IEE P-COMPUT DIG T, V150, P403, DOI 10.1049/ip-cdt:20030965
   Tsmots I, 2019, EXP DES APPL CAD SYS, DOI 10.1109/cadsm.2019.8779253
   Virdee, 2018, LSTM NEURAL NETWORK
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wei, 2018, CONVOLUTIONAL NEURAL
   Wu XX, 2020, DES AUT TEST EUROPE, P774, DOI 10.23919/DATE48585.2020.9116475
   Wuraola A, 2021, NEUROCOMPUTING, V442, P73, DOI 10.1016/j.neucom.2021.02.030
   Xiao H., 2017, ARXIV170807747
   Yang T, 2019, IEEE T COMPUT AID D, V38, P1974, DOI 10.1109/TCAD.2018.2871198
   Zaremba Wojciech, 2014, RECURRENT NEURAL NET
NR 68
TC 3
Z9 3
U1 3
U2 11
PD APR 14
PY 2022
VL 482
BP 163
EP 185
DI 10.1016/j.neucom.2021.11.032
EA FEB 2022
UT WOS:000819853500005
DA 2023-11-16
ER

PT J
AU Psarakis, M
   Dounis, A
   Almabrok, A
   Stavrinidis, S
   Gkekas, G
AF Psarakis, Mihalis
   Dounis, Anastasios
   Almabrok, Abdoalnasir
   Stavrinidis, Stavros
   Gkekas, Georgios
TI An FPGA-Based Accelerated Optimization Algorithm for Real-Time
   Applications
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE FPGA-based acceleration; Genetic algorithm; Big bang-big crunch
   optimization algorithm; Real-time applications; ANFIS
ID HARDWARE IMPLEMENTATION; FITNESS APPROXIMATION; DESIGN
AB Many modern applications, such as industrial control, image processing and machine learning, are based on optimization algorithms that must solve compute-intensive problems under real-time constraints taking into account real-world parameters that evolve in time. Among others, evolutionary algorithms (EAs) are increasingly used in real-time applications to solve such complex optimization problems. Moreover, Field Programmable Gate Arrays (FPGAs) have been proved an effective platform for the implementation of these algorithms satisfying real-time and low-power requirements. In this paper, we study the FPGA-based acceleration of the Big Bang-Big Crunch (BB-BC) algorithm. BB-BC is an optimization method inspired by the corresponding evolutionary theory of the universe [1]. The BB-BC method is performed in two phases: in the Bing Bang phase, similarly to other Genetic Algorithms (GAs) it generates a random population of candidate solutions, while in the Big Crunch phase it shrinks these candidates around an optimal point. It has been shown that the BB-BC method outperforms classical GA algorithms for several optimization problems in terms of convergence speed. We show that the BB-BC algorithm does not suffer from the design limitations of the classical GAs that impede the performance of their hardware-based accelerators. We propose an efficient fully pipelined design of both BB-BC phases and a parallel scheme which integrates several BB-BC pipelined engines to improve system performance. We implement the proposed FPGA-based accelerator on a Xilinx Virtex-5 development board for three different fitness functions and compare the execution time against its software counterpart (in C language) and a CUDA program running on a massively parallel computing platform (GPU). We also compare the proposed optimized FPGA architecture with an RTL design generated by a high-level synthesis (HLS) design flow. We propose an Adaptive Neuro-fuzzy Inference System (ANFIS) model for fitness function approximation method to reduce the execution latency of complex fitness functions. We also demonstrate the efficiency of the proposed FPGA architecture on an image search problem, finding the darkest pixel of a grey image. The experimental results show that the proposed approach achieves significant speedup compared to the other software versions of the BB-BC algorithm and converges much faster than a typical GA algorithm making it an ideal solution for real-time embedded applications.
C1 [Psarakis, Mihalis; Almabrok, Abdoalnasir; Gkekas, Georgios] Univ Piraeus, Dept Informat, Piraeus, Greece.
   [Dounis, Anastasios; Stavrinidis, Stavros] Univ West Attica, Dept Ind Design & Prod Engn, Athens, Greece.
RP Psarakis, M (corresponding author), Univ Piraeus, Dept Informat, Piraeus, Greece.
EM mpsarak@unipi.gr; aidounis@uniwa.gr; nassnaan@unipi.gr;
   stavst@hotmail.com; gkekasgeo@gmail.com
CR Akashi Takuya, 2007, J SYSTEMICS CYBERNET, V5, P72
   ALDOUNIS S, FUZZ SYST FUZZ IEEE, P1
   [Anonymous], IEEE T PARALLEL DIST
   Ben Ali YM, 2009, J SIGNAL PROCESS SYS, V54, P231, DOI 10.1007/s11265-008-0200-z
   Camp CV, 2012, J STRUCT ENG, V138, P438, DOI 10.1061/(ASCE)ST.1943-541X.0000461
   DAIDA JM, 1996, ADV GENETIC PROGRAMM, V2, P417
   dos Santos PV, 2013, I C FIELD PROG LOGIC
   Erol OK, 2006, ADV ENG SOFTW, V37, P106, DOI 10.1016/j.advengsoft.2005.04.005
   Feng L, 2018, TECHNOMETRICS, P1
   Fernando PR, 2010, IEEE T EVOLUT COMPUT, V14, P133, DOI 10.1109/TEVC.2009.2025032
   FUNIE AI, 2015, APPL SPEC SYST ARCH
   Ghosh P, 2016, NEUROCOMPUTING, V195, P181, DOI 10.1016/j.neucom.2015.09.123
   Guo L., 2016, SIGARCH COMPUT A SEP, V43, P86, DOI DOI 10.1145/2927964.2927980
   GUO L, 2014, FIELD PROGR LOG APPL
   Guo LC, 2015, ANN IEEE SYM FIELD P, P103, DOI 10.1109/FCCM.2015.64
   Guo LC, 2014, LECT NOTES COMPUT SC, V8602, P714, DOI 10.1007/978-3-662-45523-4_58
   Huang MQ, 2013, IEEE T PARALL DISTR, V24, P1818, DOI 10.1109/TPDS.2012.267
   Jaiswal M.K., 2017, VLSI DES 2017 16 INT, P1, DOI [10.1109/ICVD.2017.7913322, DOI 10.1109/ICVD.2017.7913322]
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Jin Y, 2005, SOFT COMPUT, V9, P3, DOI [10.1007/s00500-003-0328-5, 10.1007/S00500-003-0328-5]
   Kaveh A, 2010, J CONSTR STEEL RES, V66, P412, DOI 10.1016/j.jcsr.2009.10.013
   Kaveh A, 2009, COMPUT STRUCT, V87, P1129, DOI 10.1016/j.compstruc.2009.04.011
   Kim EY, 2006, PATTERN RECOGN LETT, V27, P1252, DOI 10.1016/j.patrec.2005.07.023
   Kumbasar T, 2011, EXPERT SYST APPL, V38, P12356, DOI 10.1016/j.eswa.2011.04.015
   Letras M, 2016, NEUROCOMPUTING, V175, P899, DOI 10.1016/j.neucom.2015.05.128
   Li CY, 2017, J AM CERAM SOC, V100, P2081, DOI 10.1111/jace.14771
   Man K. F., 2012, GENETIC ALGORITHMS C
   Nambiar VP, 2013, COMPUTING, V95, P863, DOI 10.1007/s00607-013-0305-5
   SALDANA HJB, 2010, 2010 IEEE ANDESCON
   SCOTT SD, 1995, P ACM SIGDA 3 INT S, P53, DOI DOI 10.1109/FPGA.1995.241945
   Shackleford B., 2001, Genetic Programming and Evolvable Machines, V2, P33, DOI 10.1023/A:1010018632078
   SHAMSI M, 2009, SOFT COMP PATT REC 2
   Shi L, 2010, ADAPT LEARN OPTIM, V2, P3
   Szenasi S., 2014, International Journal of Circuits, Systems and Signal Processing, V8, P173
   Tachibana T, 2006, ANN IEEE SYM FIELD P, P291
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Tang W, 2004, 2004 47TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL I, CONFERENCE PROCEEDINGS, P549
   Winterstein F, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P362, DOI 10.1109/FPT.2013.6718388
   Yesil E, 2014, APPL SOFT COMPUT, V15, P100, DOI 10.1016/j.asoc.2013.10.031
   Zhu Z, 2007, NEUROCOMPUTING, V71, P95, DOI 10.1016/j.neucom.2006.11.031
   2009, MATLAB MANUAL FUZZY
NR 41
TC 6
Z9 6
U1 0
U2 19
PD OCT
PY 2020
VL 92
IS 10
SI SI
BP 1155
EP 1176
DI 10.1007/s11265-020-01522-5
EA FEB 2020
UT WOS:000516239700001
DA 2023-11-16
ER

PT C
AU Agrawal, A
   Choi, J
   Gopalakrishnan, K
   Gupta, S
   Nair, R
   Oh, J
   Prener, DA
   Shukla, S
   Srinivasan, V
   Sura, Z
AF Agrawal, Ankur
   Choi, Jungwook
   Gopalakrishnan, Kailash
   Gupta, Suyog
   Nair, Ravi
   Oh, Jinwook
   Prener, Daniel A.
   Shukla, Sunil
   Srinivasan, Vijayalakshmi
   Sura, Zehra
GP IEEE
TI Approximate Computing: Challenges And Opportunities
SO 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
DT Proceedings Paper
CT IEEE International Conference on Rebooting Computing (ICRC)
CY OCT 17-19, 2016
CL San Diego, CA
DE Approximate computing; perforation; reduced precision; relaxed
   synchronization
AB Approximate computing is gaining traction as a computing paradigm for data analytics and cognitive applications that aim to extract deep insight from vast quantities of data. In this paper, we demonstrate that multiple approximation techniques can be applied to applications in these domains and can be further combined together to compound their benefits. In assessing the potential of approximation in these applications, we took the liberty of changing multiple layers of the system stack: architecture, programming model, and algorithms. Across a set of applications spanning the domains of DSP, robotics, and machine learning, we show that hot loops in the applications can be perforated by an average of 50% with proportional reduction in execution time, while still producing acceptable quality of results. In addition, the width of the data used in the computation can be reduced to 10-16 bits from the currently common 32/64 bits with potential for significant performance and energy benefits. For parallel applications we reduced execution time by 50% using relaxed synchronization mechanisms. Finally, our results also demonstrate that benefits compounded when these techniques are applied concurrently.
   Our results across different applications demonstrate that approximate computing is a widely applicable paradigm with potential for compounded benefits from applying multiple techniques across the system stack. In order to exploit these benefits it is essential to re-think multiple layers of the system stack to embrace approximations ground-up and to design tightly integrated approximate accelerators. Doing so will enable moving the applications into a world in which the architecture, programming model, and even the algorithms used to implement the application are all fundamentally designed for approximate computing.
C1 [Agrawal, Ankur; Choi, Jungwook; Gopalakrishnan, Kailash; Gupta, Suyog; Nair, Ravi; Oh, Jinwook; Prener, Daniel A.; Shukla, Sunil; Srinivasan, Vijayalakshmi; Sura, Zehra] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Agrawal, A (corresponding author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
CR Alemany J., 1992, Proceedings of the Eleventh Annual ACM Symposium on Principles of Distributed Computing, P125, DOI 10.1145/135419.135446
   Allen F., 1988, Conference Proceedings. 1988 International Conference on Supercomputing, P207, DOI 10.1145/55364.55385
   [Anonymous], 2014, CONF PROC INT SYMP C
   Bailey D. H., 2008, RESOLVING NUMERICAL
   Barker K., 2013, PERFECT POWER EFFICI
   Brown A. W., 2007, P 1 HIPEAC WORKSHOP, P6
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   HERLIHY M, 1993, CONF PROC INT SYMP C, P289, DOI 10.1145/173682.165164
   Hoffmann H., 2009, USING CODE PERFORATI
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   LAMPORT L, 1977, COMMUN ACM, V20, P806, DOI 10.1145/359863.359878
   Lowe D., 1999, P INT C COMPUTER VIS, V2, P1150
   Lucas BD, 1981, P 7 INT JOINT C ART, P674
   Misailovic S, 2011, LECT NOTES COMPUT SC, V6887, P316, DOI 10.1007/978-3-642-23702-7_24
   Renganarayana L., 2012, P 2012 ACM WORKSH RE, P41, DOI DOI 10.1145/2414729.2414737
   Rinard M, 2010, ACM SIGPLAN NOTICES, V45, P806, DOI 10.1145/1932682.1869525
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sampson A, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P164
   Shavit N, 1997, DISTRIB COMPUT, V10, P99, DOI 10.1007/s004460050028
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tong JYF, 2000, IEEE T VLSI SYST, V8, P273, DOI 10.1109/92.845894
   Zhang W., 2015, STALENESS AWARE ASYN
   Zhiyuan Li, 1992, Conference Proceedings. 1992 International Conference on Supercomputing, P313
   Zucker D. F., 1994, CSLTR94616
NR 29
TC 10
Z9 10
U1 0
U2 0
PY 2016
UT WOS:000392138600003
DA 2023-11-16
ER

PT J
AU Yousuf, O
   Hossen, I
   Daniels, MW
   Lueker-Boden, M
   Dienstfrey, A
   Adam, GC
AF Yousuf, Osama
   Hossen, Imtiaz
   Daniels, Matthew W.
   Lueker-Boden, Martin
   Dienstfrey, Andrew
   Adam, Gina C.
TI Device Modeling Bias in ReRAM-Based Neural Network Simulations
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Computational modeling; Neural networks; Standards; Mathematical models;
   Data models; Performance evaluation; Switches; Hardware neural networks;
   ReRAM; memristors; device modeling; modeling bias
ID SYSTEM; MEMORY
AB Emerging technologies based on resistive switching (ReRAM) devices promise to improve the speed and energy efficiency of next generation machine learning accelerators, but further research is required for achieving commercial maturity. System-level prototyping with emerging devices is costly, and algorithmic investigations require hardware neural network modeling which often deviates from experimental reality. In this work, the concept of modeling bias is proposed as a way to quantify this deviation and support reliable evaluation of device populations in the context of neural network algorithms. While applicable to other device modeling techniques, modeling bias is investigated here using jump tables - a promising physics-less technique to model emerging memory devices for hardware networks. Questions about the fidelity of these tables in relation to stochastic device behavior are answered. Two methods of jump table modeling - binning and a novel Optuna-optimized binning - are explored using synthetic data with known distributions for benchmarking and experimental data obtained from TiOx ReRAM devices for practical testing. Novel device metrics are proposed, and it is shown that these metrics can present crucial insights on the device population prior to training the hardware network. Results on a multi-layer perceptron trained on MNIST show that device models based on binning deviate from target network accuracy at a low number of points and high switching noise in the device dataset. The proposed approach opens the possibility for device-algorithm co-design investigations into statistical device models with better performance, as well as experimentally verified modeling bias in different in-memory computing and neural network architectures.
C1 [Yousuf, Osama; Hossen, Imtiaz; Adam, Gina C.] George Washington Univ, Elect & Comp Engn Dept, Washington, DC 20052 USA.
   [Daniels, Matthew W.] NIST, Gaithersburg, MD 20899 USA.
   [Lueker-Boden, Martin] Western Digital Technol, San Jose, CA 95119 USA.
   [Dienstfrey, Andrew] NIST, Boulder, CO 80305 USA.
RP Adam, GC (corresponding author), George Washington Univ, Elect & Comp Engn Dept, Washington, DC 20052 USA.
EM ginaadam@gwu.edu
CR Abbaspour E, 2020, J COMPUT ELECTRON, V19, P1426, DOI 10.1007/s10825-020-01537-y
   Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Aldana S, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/ab7bb6
   Ambrosi E, 2019, FARADAY DISCUSS, V213, P87, DOI 10.1039/c8fd00106e
   Bengel C, 2020, IEEE T CIRCUITS-I, V67, P4618, DOI 10.1109/TCSI.2020.3018502
   Bersuker G, 2011, J APPL PHYS, V110, DOI 10.1063/1.3671565
   Bose P., 2011, ENCY PARALLEL COMPUT, P1593, DOI [10.1007/978-0-387-09766-4_499, DOI 10.1007/978-0-387-09766-4_499]
   Burr G. W., IEEE T ELECT DEVICES
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Channamadhavuni S., 2021, GLSVLSI, P379, DOI DOI 10.1145/3453688.3461746
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Dalgaty T, 2021, NAT ELECTRON, V4, P151, DOI 10.1038/s41928-020-00523-3
   Deng L., 2012, IEEE SIGNAL PROC MAG, V29, P141, DOI [DOI 10.1109/MSP.2012.2211477, 10.1109/MSP.2012.2211477]
   Gao YM, 2023, IEEE T PATTERN ANAL, V45, P7019, DOI 10.1109/TPAMI.2020.3025062
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   González-Cordero G, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/11/115013
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   Hoskins Brian, 2021, ICONS 2021: International Conference on Neuromorphic Systems 2021, DOI 10.1145/3477145.3477260
   Hossen I, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09556-4
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Ielmini D, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/25/254022
   INMAN HF, 1989, COMMUN STAT THEORY, V18, P3851, DOI 10.1080/03610928908830127
   Laborieux A, 2020, Arxiv, DOI arXiv:2007.14234
   Luo YCA, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329062
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Menzel S, 2017, J COMPUT ELECTRON, V16, P1017, DOI 10.1007/s10825-017-1051-2
   Niroula J, 2017, J COMPUT ELECTRON, V16, P1144, DOI 10.1007/s10825-017-1107-3
   Padovani A, 2017, J APPL PHYS, V121, DOI 10.1063/1.4979915
   Park SO, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30539-6
   PEACOCK JA, 1983, MON NOT R ASTRON SOC, V202, P615, DOI 10.1093/mnras/202.3.615
   Sidler S, 2016, PROC EUR S-STATE DEV, P440, DOI 10.1109/ESSDERC.2016.7599680
   Stathopoulos S, 2019, IEEE T ELECTRON DEV, V66, P2946, DOI 10.1109/TED.2019.2918102
   Valentian A, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993431
   van Leeuwen J, 2019, ATTEN PERCEPT PSYCHO, V81, P2956, DOI 10.3758/s13414-019-01788-3
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yakopcic C., 2013, 2013 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2013.6706773, DOI 10.1109/IJCNN.2013.6706773]
   Zhao JY, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.749811
NR 39
TC 0
Z9 0
U1 1
U2 1
PD MAR
PY 2023
VL 13
IS 1
BP 382
EP 394
DI 10.1109/JETCAS.2023.3238295
UT WOS:000966838300001
DA 2023-11-16
ER

PT C
AU Sathe, CG
   Makris, Y
   Schafer, BC
AF Sathe, Chaitali G.
   Makris, Yiorgos
   Schafer, Benjamin Carrion
BE IEEE
TI MANTIS: Machine Learning-Based Approximate ModeliNg of RedacTed
   Integrated CircuitS
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
ID OBFUSCATION
AB With most hardware (HW) design companies now relying on third parties to fabricate their integrated circuits (ICs) it is imperative to develop methods to protect their Intellectual Property (IP). One popular approach is logic locking. One of the problems with traditional locking mechanisms is that the locking circuitry is built into the netlist that the (HW) design company delivers to the foundry which has now access to the entire design including the locking mechanism. This implies that they could potentially tamper with this circuitry or reverse engineer it to obtain the locking key. One relatively new approach that has been coined as hardware redaction is to map a portion of the design to an embedded FPGA (eFPGA). The bitstream of the eFPGA now acts as the locking key.
   In this case the fab receives the design without the bitstream and hence, cannot reverse engineer the functionality of the design. In this work we propose, to the best of our knowledge, the first attack on eFPGA HW redacted ICs by substituting the exact logic mapped onto the eFPGA by a synthesizable predictive model that replicates the behavior of the exact logic. This approach is particularly applicable in the context of approximate computing where hardware accelerators tolerate certain degrees of error at their outputs. One of the main issues addressed in this work is how to generate the training data to generate the synthesizable predictive model. For this we use SAT/SMT solvers as the potential attacker only has access to primary IO of the IP. Experimental results for various degrees of maximum allowable output errors show that our proposed approach is very effective finding suitable predictive models.
C1 [Sathe, Chaitali G.; Makris, Yiorgos; Schafer, Benjamin Carrion] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75080 USA.
RP Sathe, CG (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75080 USA.
EM chaitaligajanan.sathe@utdallas.edu; yiorgos.makris@utdallas.edu;
   schaferb@utdallas.edu
CR [Anonymous], 2011, JMLR, V12, P2825
   Botero UJ, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3464959
   Chakraborty RS, 2009, IEEE T COMPUT AID D, V28, P1493, DOI 10.1109/TCAD.2009.2028166
   Chen JQ, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218519
   Chen JQ, 2021, ASIA S PACIF DES AUT, P542, DOI 10.1145/3394885.3431601
   Chowdhury P., 2022, ISLPED
   Hu B, 2019, PR GR LAK SYMP VLSI, P171, DOI 10.1145/3299874.3317992
   Rahman MT, 2020, INTEGRATION, V72, P39, DOI 10.1016/j.vlsi.2019.12.007
   Rajarathnam RS, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P154, DOI [10.1109/host45689.2020.9300272, 10.1109/HOST45689.2020.9300272]
   Rajendran J., 2013, P 2013 ACM SIGSAC C, P709, DOI DOI 10.1145/2508859.2516656
   Rajendran J, 2015, IEEE T COMPUT, V64, P410, DOI 10.1109/TC.2013.193
   Rajendran J, 2013, DES AUT TEST EUROPE, P1259
   Roy JA, 2008, DES AUT TEST EUROPE, P948
   Schafer BC, 2014, IEEE EMBED SYST LETT, V6, P53, DOI 10.1109/LES.2014.2320556
   Shihab MM, 2019, DES AUT TEST EUROPE, P528, DOI [10.23919/date.2019.8714856, 10.23919/DATE.2019.8714856]
   Subramanyan P, 2014, IEEE T EMERG TOP COM, V2, P63, DOI 10.1109/TETC.2013.2294918
   Tomajoli C. M., 2022, DESIGN AUTOMATION C
   Wang Z, 2021, PR IEEE COMP DESIGN, P591, DOI 10.1109/ICCD53106.2021.00095
   Watkins D., 1996, U.S. Patent, Patent No. [US08/668, 08668]
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2023
UT WOS:001027444200061
DA 2023-11-16
ER

PT C
AU Boroumand, A
   Ghose, S
   Kim, Y
   Ausavarungnirun, R
   Shiu, E
   Thakur, R
   Kim, D
   Kuusela, A
   Knies, A
   Ranganathan, P
   Mutlu, O
AF Boroumand, Amirali
   Ghose, Saugata
   Kim, Youngsok
   Ausavarungnirun, Rachata
   Shiu, Eric
   Thakur, Rahul
   Kim, Daehyun
   Kuusela, Aki
   Knies, Allan
   Ranganathan, Parthasarathy
   Mutlu, Onur
TI GoogleWorkloads for Consumer Devices: Mitigating Data Movement
   Bottlenecks
SO ACM SIGPLAN NOTICES
DT Proceedings Paper
CT 23rd International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY MAR 24-28, 2018
CL Williamsburg, VA
DE processing-in-memory; data movement; consumer workloads; memory systems;
   energy efficiency
AB We are experiencing an explosive growth in the number of consumer devices, including smartphones, tablets, web-based computers such as Chromebooks, and wearable devices. For this class of devices, energy efficiency is a first-class concern due to the limited battery capacity and thermal power budget. We find that data movement is a major contributor to the total system energy and execution time in consumer devices. The energy and performance costs of moving data between the memory system and the compute units are significantly higher than the costs of computation. As a result, addressing data movement is crucial for consumer devices.
   In this work, we comprehensively analyze the energy and performance impact of data movement for several widely-used Google consumer workloads: (1) the Chrome web browser; (2) TensorFlow Mobile, Google's machine learning framework; (3) video playback, and (4) video capture, both of which are used in many video services such as YouTube and Google Hangouts. We find that processing-in-memory (PIM) can significantly reduce data movement for all of these workloads, by performing part of the computation close to memory. Each workload contains simple primitives and functions that contribute to a significant amount of the overall data movement. We investigate whether these primitives and functions are feasible to implement using PIM, given the limited area and power constraints of consumer devices. Our analysis shows that offloading these primitives to PIM logic, consisting of either simple cores or specialized accelerators, eliminates a large amount of data movement, and significantly reduces total system energy (by an average of 55.4% across the workloads) and execution time (by an average of 54.2%).
C1 [Boroumand, Amirali; Ghose, Saugata; Ausavarungnirun, Rachata; Mutlu, Onur] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Kim, Youngsok] Seoul Natl Univ, Dept ECE, Seoul, South Korea.
   [Shiu, Eric; Thakur, Rahul; Kim, Daehyun; Kuusela, Aki; Knies, Allan; Ranganathan, Parthasarathy] Google, Mountain View, CA USA.
   [Kim, Daehyun] Samsung Res, Mountain View, CA USA.
   [Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Boroumand, A (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
CR Abts D., 2006, WCED
   Adolf R., 2016, IISWC
   Akin B., 2015, ISCA
   Al-Shuwaili A., 2017, IEEE WIRELESS COMMUN
   Alexa Internet Inc, WEBS TRAFF STAT AN
   Alzantot M., 2017, EMDL
   [Anonymous], 2016, ISCA
   [Anonymous], 2017, CISC VIS NETW IND GL
   [Anonymous], 2016, ISCA
   [Anonymous], 2015, ISCA
   [Anonymous], JSSC
   [Anonymous], IEEE MICRO
   [Anonymous], 2016, ECCV
   [Anonymous], 2016, ISCA
   [Anonymous], IEEE MICRO
   [Anonymous], 2017, ASPLOS
   [Anonymous], 2007, ZFS LAST WORD FILE S
   [Anonymous], 2017, HPCA
   ARM Holdings PLC, ARM CORT R8
   Binkert N., 2011, COMP ARCH NEWS
   Boroumand A., 2017, IEEE CAL
   Bossen F., 2012, IEEE CSVT
   Cao Q., 2017, EMDL
   Carroll A., 2010, USENIX ATC
   Chadha G., 2015, ISCA
   Chadha G., 2014, PACT
   Chatzopoulos D., 2017, IEEE ACCESS
   Choi J.-A., 2008, PCM
   Chou C., 2015, DSN
   Chromium Project, BLINK REND ENG
   Chromium Project, CAT TEL
   Chromium Project, 2014, GPU RAST CHROM
   Cuervo E., 2010, MOBISYS
   Deng H., 2010, ICCSIT
   Do T. M. T., 2011, ICMI
   Draper J., 2002, ICS
   Drumond M. P., 2017, ISCA
   Dubroy P., 2010, CHI
   eMarketer Inc, 2016, SLOW GROWTH AH WORLD
   Ericsson Inc., 2015, ERICSSON MOBILITY RE
   Gao M., 2015, PACT
   Ghose S., 2018, CORR
   Grange A., VP9 BITSTREAM DECODI
   Gu Q., 2014, WONDP
   Gutierrez Anthony, 2011, IISWC
   Habli H., 2009, SOC
   Hadidi R., 2017, ACM TACO
   Halpern M., 2016, HPCA
   Heater B., 2017, CHROMEBOOK SALES SOA
   Horowitz M., 2003, CSVT
   Hsieh K., 2016, ICCD
   Hsieh Kevin, 2016, ISCA
   Huang Y., 2014, ISPASS
   Huffman D. A., 1952, P IRE
   Hwang D., 2016, NATIVE ONE COPY TEXT
   Hybrid Memory Cube Consortium, 2014, HMC SPEC 2 0
   Jeddeloh J., 2012, VLSIT
   JEDEC Solid State Technology Assn, 2013, JESD235 HIGH BANDW M
   Jennings S., 2013, TRANSPARENT MEMORY C
   Kalali E., 2014, ICIP
   Kane J., 2012, SBAC PAD
   Kang Yi, 2012, ICCD
   Kim JS, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4460-0
   Kim Y., 2015, IEEE CAL
   Kim Y., 2010, MICRO
   Kim Yoongu, 2010, HPCA
   Kogge P. M., 1994, ICPP
   Lai Z., 2017, MOBICOM
   Langroodi M. J., 2015, TOMM
   Lee C., 2008, ISOCC
   Lee D., 2016, ACM TACO
   Lewis P., 2013, AVOIDING UNNECESSARY
   Li T., 2015, MOBISYS
   Liu F., 2013, IEEE WIRELESS COMMUN
   Loh G. H., 2008, ISCA
   Mai Ken, 2000, ISCA
   Mentor Graphics Corp, CAT HIGH LEV SYNTH
   Mirhosseini A., 2017, IEEE CAL
   Mirzadeh N., 2007, ASBD
   Moatamed B., 2016, BSN
   Mosenia A., 2017, IEEE TC
   Mosenia A., 2017, MSCS
   Muralidhara S. P., 2011, MICRO
   Muralimanohar N., 2007, MICRO
   Nachiappan N. C., 2015, ISCA
   Nai L., 2017, HPCA
   Narancic G., 2014, SAMOS
   Net Applications, MARK SHAR STAT INT T
   Nia A. M., 2015, MSCS
   Nielsen Norman Group, PAG PARK MILL MULT M
   Oberhumer M. F. X. J., 2018, LZO REAL TIME DATA C
   Oskin M., 1998, ISCA
   Pandiyan D., 2014, IISWC
   Pandiyan D., 2013, IISWC
   Pattnaik A, 2016, PACT
   Popper B., 2017, GOOGLE SERVICES MONT
   Qualcomm Technologies Inc, SNAPDR 835 MOB PLATF
   Ren J., 2007, ISCE
   Rengasamy P. V., 2017, IISWC
   Rodeh O., 2013, ACM TOS
   Rosen S., 2015, IMC
   Ross F., 2012, JEDEC LPDDR3 S
   Seshadri  V., 2016, ARXIV161009603CSAR
   Seshadri V., 2017, MICRO
   Seshadri V., 2015, CAL
   Seshadri  V., 2017, ADV COMPUTERS, V106
   Shaw D. E., 1981, IEEE DEB
   Shingari D., 2015, IISWC
   Simonyan K., 2015, VERY DEEP CONVOLUTIO, V1, P3
   Smith R., 2015, APPLES A9 SOC IS DUA
   Stankowski J, 2016, INT CONF SYST SIGNAL, P169, DOI 10.1109/IWSSIP.2016.7502731
   Stone H. S., 1970, IEEE TC
   Sukale R., 2015, WHAT ARE REFLOWS REP
   Sutardja S., 2015, ISSCC
   Szegedy C., 2017, AAAI, DOI DOI 10.1609/AAAI.V31I1.11231
   Tang Xulong, 2017, MICRO
   TechInsights, SAMS GAL S6
   Thompson R., 2014, IMPROVE RENDERING PE
   Toderici G., 2017, CVPR
   Vasilakis E., 2015, FORTHICSTR450
   Wegner S., 2016, APPLE IPHONE 7 TEARD
   Wei A., 2017, QUALCOMM SNAPDRAGON
   Xi S. L., 2015, DAMON
   Zhang D., 2014, P HPDC
   Zhang H., 2017, MICRO
   Zhang X., 2017, IEEE TC
   Zhu S., 1997, ICICS
   Zhu Y., 2016, PLDI
   Zhu Y., 2014, ISCA
   Ziv J., 1977, TIT
NR 130
TC 118
Z9 119
U1 0
U2 13
PD FEB
PY 2018
VL 53
IS 2
BP 316
EP 331
DI 10.1145/3173162.3173177
UT WOS:000452465200024
DA 2023-11-16
ER

PT J
AU Salamin, S
   Zervakis, G
   Klemme, F
   Kattan, H
   Chauhan, Y
   Henkel, J
   Amrouch, H
AF Salamin, Sami
   Zervakis, Georgios
   Klemme, Florian
   Kattan, Hammam
   Chauhan, Yogesh
   Henkel, Joerg
   Amrouch, Hussam
TI Impact of NCFET Technology on Eliminating the Cooling Cost and Boosting
   the Efficiency of Google TPU
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Negative capacitance transistor (NCFET); thermoelectric cooling; Google
   TPU; multiphysics; neural processing unit
ID NEGATIVE CAPACITANCE TRANSISTOR; HIGH ON-CURRENT
AB Recent breakthroughs in Neural Networks (NNs) led to significant accuracy improvements of several machine learning applications such as image classification and voice recognition. However, this accuracy improvement comes at the cost of an immense increase in computation demands. NNs became one of the most common and computationally intensive workloads in today's datacenters. To address these computational demands, Google announced in 2016 the Tensor Processing Unit (TPU), an advanced custom ASIC accelerator for NN inference. Two new TPU versions (v2 and v3) followed in 2017 and 2018 that support also training. Google TPUv3 packs an immense processing power (90TFLOPS per chip) in a tiny and condensed area, leading to very high on-chip power densities and thus excessive temperature. In this article, superlattice thermoelectric cooling, which is one of the emerging onchip cooling, is considered as an advanced cooling example for Google TPU and we investigate the impact of Negative Capacitance FET (NCFET), which is one of the recent emerging technologies, on the cooling and efficiency of TPU. Through full-chip design, of the computational core of the TPU, based on 14nm Intel FinFET technology and multiphysics temperature simulations, we demonstrate that NCFET can significantly minimize the required cooling-cost. More than 4000 NCFET configurations are evaluated in order to traverse the entire design space defined by the thickness of the ferroelectric layer of NCFET, the operating voltage, cooling, and the operating frequency, in addition to all possible FinFET's configurations. Moreover, our experimental evaluation shows that by eliminating the cooling cost, NCFET delivers 2.8x higher efficiency compared to the conventional FinFET baseline.
C1 [Salamin, Sami; Zervakis, Georgios; Henkel, Joerg] Karlsruhe Inst Technol KIT, Chair Embedded Syst CES, D-76131 Karlsruhe, Germany.
   [Kattan, Hammam] Karlsruher Inst Technol, Chair Embedded Syst, D-76131 Karlsruhe, Germany.
   [Chauhan, Yogesh] Indian Inst Technol Kanpur IITK, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
   [Klemme, Florian; Amrouch, Hussam] Univ Stuttgart, Fac Elect Engn, Hussam Amrouch Chair Semicond Test & Reliabil STA, Comp Sci, D-70174 Stuttgart, Germany.
RP Salamin, S (corresponding author), Karlsruhe Inst Technol KIT, Chair Embedded Syst CES, D-76131 Karlsruhe, Germany.
EM sami.salamin@kit.edu; georgios.zervakis@kit.edu;
   klemme@iti.uni-stuttgart.de; hammam.kattan@hotmail.com;
   chauhan@iitk.ac.in; henkel@kit.edu; amrouch@iti.uni-stuttgart.de
CR Amrouch H, 2020, IEEE T COMPUT AID D, V39, P3842, DOI 10.1109/TCAD.2020.3012753
   Amrouch H, 2020, IEEE T CIRCUITS-I, V67, P3127, DOI 10.1109/TCSI.2020.2990672
   Amrouch H, 2018, IEEE ACCESS, V6, P52754, DOI 10.1109/ACCESS.2018.2870916
   [Anonymous], 2013, ADV FLIP CHIP PACKAG
   [Anonymous], 2018, SYNTHESIS LECT COMPU
   Balkind J, 2016, ACM SIGPLAN NOTICES, V51, P217, DOI 10.1145/2954679.2872414
   Bulman G, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10302
   Chainer TJ, 2017, IEEE T COMP PACK MAN, V7, P1228, DOI 10.1109/TCPMT.2017.2661700
   Chatterjee K, 2017, IEEE ELECTR DEVICE L, V38, P1328, DOI 10.1109/LED.2017.2731343
   Choday SH, 2013, IEEE T COMP PACK MAN, V3, P2059, DOI 10.1109/TCPMT.2013.2273873
   Chowdhury I, 2009, NAT NANOTECHNOL, V4, P235, DOI [10.1038/nnano.2008.417, 10.1038/NNANO.2008.417]
   Datacenter Knowledge, 2018, GOOGL BRINGS LIQ COO
   DEVONSHIRE AF, 1949, PHILOS MAG, V40, P1040
   Frost. Rosie, 2020, GIANT DATA CENTRES U
   Google, 2019, BFLOAT16 SECR HIGH P
   Google, 2019, HOTCH 2019 TUT
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henkel. J., DEPENDABLE EMBEDDED, P2021
   Hoffmann M, 2018, INT EL DEVICES MEET
   Hoffmann M, 2019, NATURE, V565, P464, DOI 10.1038/s41586-018-0854-z
   Huang W, 2010, P IEEE SEMICOND THER, P198, DOI 10.1109/STHERM.2010.5444290
   Krivokapic Z, 2017, INT EL DEVICES MEET, DOI 10.1109/IEDM.2017.8268393
   Kwon D, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P49, DOI 10.1109/VLSIT.2018.8510626
   Mueller S, 2012, ADV FUNCT MATER, V22, P2412, DOI 10.1002/adfm.201103119
   Natarajan S, 2014, INT EL DEVICES MEET
   Pahwa G, 2019, IEEE T ELECTRON DEV, V66, P1591, DOI 10.1109/TED.2019.2892186
   Pahwa G, 2018, IEEE T ELECTRON DEV, V65, P5130, DOI 10.1109/TED.2018.2870519
   Pahwa G, 2016, IEEE T ELECTRON DEV, V63, P4981, DOI 10.1109/TED.2016.2614432
   Pahwa G, 2016, IEEE T ELECTRON DEV, V63, P4986, DOI 10.1109/TED.2016.2614436
   Pahwa G, 2016, PROC EUR SOLID-STATE, P49, DOI 10.1109/ESSCIRC.2016.7598240
   Rapp M., 2019, P 56 ACM IEEE DES AU, P1
   Salahuddin S, 2008, NANO LETT, V8, P405, DOI 10.1021/nl071804g
   Salamin S, 2021, IEEE T COMPUT, V70, P1484, DOI 10.1109/TC.2020.3013567
   Salamin S, 2020, DES AUT TEST EUROPE, P630, DOI 10.23919/DATE48585.2020.9116301
   Salamin S, 2019, I SYMPOS LOW POWER E
   Samal SK, 2017, I SYMPOS LOW POWER E
   Shyamalindu. G Uttam, 1999, US Patent, Patent No. [US6266962B1, 6266962]
   Synopsys, 2018, SYN EDA TOOL FLOWS
   Wang SX, 2018, MICROMACHINES-BASEL, V9, DOI 10.3390/mi9060287
   Zervakis G, 2020, IEEE ACCESS, V8, P53522, DOI 10.1109/ACCESS.2020.2981395
   Zhao DL, 2014, APPL THERM ENG, V66, P15, DOI 10.1016/j.applthermaleng.2014.01.074
NR 41
TC 4
Z9 4
U1 2
U2 7
PD APR 1
PY 2022
VL 71
IS 4
BP 906
EP 918
DI 10.1109/TC.2021.3065454
UT WOS:000767844300013
DA 2023-11-16
ER

PT C
AU Imani, M
   Salamat, S
   Khaleghi, B
   Samragh, M
   Koushanfar, F
   Rosing, T
AF Imani, Mohsen
   Salamat, Sahand
   Khaleghi, Behnam
   Samragh, Mohammad
   Koushanfar, Farinaz
   Rosing, Tajana
GP IEEE
TI SparseHD: Algorithm-Hardware Co-Optimization for Efficient
   High-Dimensional Computing
SO 2019 27TH IEEE ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 27th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY APR 28-MAY 01, 2019
CL San Diego, CA
AB Hyperdimensional (HD) computing is gaining traction as an alternative light-way machine learning approach for cognition tasks. Inspired by the neural activity patterns of the brain, HD computing performs cognition tasks by exploiting long-size vectors, namely hypervectors, rather than working with scalar numbers as used in conventional computing. Since a hypervector is represented by thousands of dimensions (elements), the majority of prior work assume binary elements to simplify the computation and alleviate the processing cost. In this paper, we first demonstrate that the dimensions need to have more than one bit to provide an acceptable accuracy to make HD computing applicable to real-world cognitive tasks. Increasing the bit-width, however, sacrifices energy efficiency and performance, even when using low-bit integers as the hypervector elements.
   To address this issue, we propose a framework for HD acceleration, dubbed SparseHD, that leverages the advantages of sparsity to improve the efficiency of HD computing. Essentially, SparseHD takes account of statistical properties of a trained HD model and drops the least effective elements of the model, augmented by iterative retraining to compensate the possible quality loss raised by sparsity. Thanks to the bit-level manipulability and abounding parallelism granted by FPGAs, we also propose a novel FPGA-based accelerator to effectively utilize the advantage of sparsity in HD computation. We evaluate the efficiency of our framework for practical classification problems. We observe that SparseHD makes the HD model up to 90% sparse while affording a minimal quality loss (less than 1%) compared to the non-sparse baseline model. Our evaluation shows that, on average, SparseHD provides 48.5x and 15.0x lower energy consumption and faster execution as compared to the AMD R390 GPU implementation.
C1 [Imani, Mohsen; Salamat, Sahand; Khaleghi, Behnam; Samragh, Mohammad; Koushanfar, Farinaz; Rosing, Tajana] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Imani, M (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM moimani@ucsd.edu; sasalama@ucsd.edu; bkhalegh@ucsd.edu;
   msamragh@ucsd.edu; fkoushanfar@ucsd.edu; tajana@ucsd.edu
CR Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2012, CISC VIS NETW IND GL
   [Anonymous], 2013, INTRIGUING PROPERTIE, DOI 10.1364/BOE.8.000579
   [Anonymous], INT S QUANT INT
   [Anonymous], 2013, INT C ADV CLOUD COMP
   [Anonymous], ACM IEEE DES AUT C D
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ARXIV190207342
   [Anonymous], 2019, DATE
   [Anonymous], 2014, ARXIV14125567V2CSCL
   [Anonymous], 2018, ARXIV180708583
   [Anonymous], 2018, IOT
   DeHon A, 2000, COMPUTER, V33, P41, DOI 10.1109/2.839320
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ghasemzadeh M, 2018, ANN IEEE SYM FIELD P, P57, DOI 10.1109/FCCM.2018.00018
   Ghazikhani H, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P1, DOI 10.1109/ICCKE.2018.8566534
   Griffin G., 2007, 120 CAL I TECHN
   Imani Mohsen, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P271, DOI 10.1109/BHI.2018.8333421
   Imani M, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P8, DOI 10.1109/ICCKE.2017.8167879
   Imani M, 2019, IEEE INT CONF CLOUD, P435, DOI 10.1109/CLOUD.2019.00076
   Imani M, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P493, DOI 10.1145/3287624.3287667
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kanerva P., 2010, AAAI FALL S QUANTUM, P2
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Khan R, 2012, 10TH INTERNATIONAL CONFERENCE ON FRONTIERS OF INFORMATION TECHNOLOGY (FIT 2012), P257, DOI 10.1109/FIT.2012.53
   Logan Beth, 2000, ISMIR, V270, P1
   Pachori R. B., 2018, P IEEE SENSORS, P1, DOI DOI 10.1109/ICSENS.2018.8589628
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Räsänen O, 2014, IEEE SIGNAL PROC LET, V21, P899, DOI 10.1109/LSP.2014.2320573
   Räsänen OJ, 2016, IEEE T NEUR NET LEAR, V27, P1878, DOI 10.1109/TNNLS.2015.2462721
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reiss A., 2012, P P 5 INT C PERVASIV, DOI [10.1145/2413097.2413148, DOI 10.1145/2413097.2413148]
   Spaziani L, 2018, PROC INT SYMP POWER, P8, DOI 10.1109/ISPSD.2018.8393590
   Sun YC, 2016, IEEE ACCESS, V4, P766, DOI 10.1109/ACCESS.2016.2529723
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
NR 38
TC 27
Z9 27
U1 0
U2 0
PY 2019
BP 190
EP 198
DI 10.1109/FCCM.2019.00034
UT WOS:000491873200025
DA 2023-11-16
ER

PT C
AU Di Martino, C
   Kalbarczyk, Z
   Iyer, RK
   Baccanico, F
   Fullop, J
   Kramer, W
AF Di Martino, Catello
   Kalbarczyk, Zbigniew
   Iyer, Ravishankar K.
   Baccanico, Fabio
   Fullop, Joseph
   Kramer, William
GP IEEE
TI Lessons Learned From the Analysis of System Failures at Petascale: The
   Case of Blue Waters
SO 2014 44TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE
   SYSTEMS AND NETWORKS (DSN)
SE International Conference on Dependable Systems and Networks
DT Proceedings Paper
CT 44th Annual IEEE/IFIP International Conference on Dependable Systems and
   Networks (DSN)
CY JUN 23-26, 2014
CL Atlanta, GA
DE Failure Analysis; Failure Reports; Cray XE6; Cray XK7; Supercomputer;
   Machine Check; Nvidia GPU errors
ID LARGE-SCALE
AB This paper provides an analysis of failures and their impact for Blue Waters, the Cray hybrid (CPU/GPU) supercomputer at the University of Illinois at Urbana-Champaign. The analysis is based on both manual failure reports and automatically generated event logs collected over 261 days. Results include i) a characterization of the root causes of single-node failures; ii) a direct assessment of the effectiveness of system-level failover as well as memory, processor, network, GPU accelerator, and file system error resiliency; and iii) an analysis of system-wide outages. The major findings of this study are as follows. Hardware is not the main cause of system downtime. This is notwithstanding the fact that hardware-related failures are 42% of all failures. Failures caused by hardware were responsible for only 23% of the total repair time. These results are partially due to the fact that processor and memory protection mechanisms (x8 and x4 Chipkill, ECC, and parity) are able to handle a sustained rate of errors as high as 250 errors/h while providing a coverage of 99.997% out of a set of more than 1.5 million of analyzed errors. Only 28 multiple-bit errors bypassed the employed protection mechanisms. Software, on the other hand, was the largest contributor to the node repair hours (53%), despite being the cause of only 20% of the total number of failures. A total of 29 out of 39 system-wide outages involved the Lustre file system with 42% of them caused by the inadequacy of the automated failover procedures
C1 [Di Martino, Catello; Kalbarczyk, Zbigniew; Iyer, Ravishankar K.] Univ Illinois, Urbana, IL 61801 USA.
   [Baccanico, Fabio] Univ Naples Federico II, Naples, Italy.
   [Fullop, Joseph; Kramer, William] Natl Ctr Supercomp Applicat, Urbana, IL USA.
RP Di Martino, C (corresponding author), Univ Illinois, Urbana, IL 61801 USA.
EM dimart@illinois.edu; kalbarcz@illinois.edu; rkiyer@illinois.edu;
   fbaccanico@unina.it; fullop@ncsa.illinois.edu; wkramer@ncsa.illinois.edu
CR AMD Inc, BIOS KERN DEV GUID A
   [Anonymous], 2012, SC 12 PROC INT C HIG
   [Anonymous], P INT C HIGH PERF CO
   [Anonymous], 2004, 2004 INT C DEPENDABL
   [Anonymous], 1997, WHITE PAPER BENEFITS
   Chen X., 2013, 43 ANN IEEEIFIP C DE, P1
   Cotroneo D./, 2012, IEEEIFIP INT C DEPEN, P1
   Di Martino C, 2013, LECT NOTES COMPUT SC, V7905, P302, DOI 10.1007/978-3-642-38750-0_23
   Gainaru A, 2012, INT PARALL DISTRIB P, P1168, DOI 10.1109/IPDPS.2012.107
   Heien Eric, 2011, INT C HIGH PERF COMP
   Karo M., 2008, APPL LEVEL PLACEMENT
   Liang YL, 2006, I C DEPEND SYS NETWO, P425
   Liang YL, 2005, I C DEPEND SYS NETWO, P476
   Lyu R, 1996, HDB SOFTWARE RELIABI
   Oliner A, 2007, I C DEPEND SYS NETWO, P575, DOI 10.1109/DSN.2007.103
   Oppenheimer D., 2002, P 10 WORKSH ACM SIGO, P255
   Pecchia A, 2011, I C DEPEND SYS NETWO, P97, DOI 10.1109/DSN.2011.5958210
   Schroeder B., 2007, P 5 USENIX C FIL STO
   Schroeder B, 2010, IEEE T DEPEND SECURE, V7, P337, DOI 10.1109/TDSC.2009.4
   Schroeder B, 2009, PERF E R SI, V37, P193
   Stearley Jon, 2012, 2012 WORKSH MAN SYST, P155
NR 21
TC 94
Z9 94
U1 0
U2 2
PY 2014
BP 610
EP 621
DI 10.1109/DSN.2014.62
UT WOS:000361050800054
DA 2023-11-16
ER

PT J
AU Makara, AL
   Reichardt, A
   Csurgai-Horváth, L
AF Makara, Arpad Laszlo
   Reichardt, Andras
   Csurgai-Horvath, Laszlo
TI AI-Based Electrode Optimisation for Small Satellite Ion Thrusters
SO INFOCOMMUNICATIONS JOURNAL
DT Article
DE ion thruster; electrode; optimisation; simulation; artificial
   intelligence; small satellite
ID SIMULATION
AB Computing capacities for numerical modelling are available to an unprecedented extent today. The spread of various artificial intelligence (AI)-based solutions (which in many cases are also resource-intensive operations) is also facilitated by this increase in capacity, which offers several new opportunities in this area. On the one hand, optimization tasks can be done quickly, on the other hand, it is also possible to solve (estimate) problems where we cannot (for some reason) create a model for the initial problem. In our article, we investigate how to apply artificial intelligence-based solutions to electromagnetic field computing tasks as efficiently as possible. The required theoretical summary presents an implemented application: optimization of electrostatic ion engine accelerator electrodes for orbit correction operations. To solve each problem, we used methods from the supervised machine learning toolkit, usually along with LMS (least mean square method) update steps. All inputs required for AI were solved by numerical space calculation (primarily using the finite element method). The data input required to optimize the electrodes of an ion thruster can come from two sources: measurement data or simulation results. Given that the operating environment of a satellite can be modelled in a vacuum chamber, it is a particularly difficult issue to perform the measurement, but even more difficult in the case of optimisation. Therefore, an effective solution to the problem can only be achieved by simulation. The primary goal of this research is to optimise the fuel (in this case, the number of ions) during operation, with the stated aim of maximising the time of operation of the spacecraft.
C1 [Makara, Arpad Laszlo; Reichardt, Andras; Csurgai-Horvath, Laszlo] Budapest Univ Technol & Econ, Dept Broadband Infocommun & Electromagnet Theory, Budapest, Hungary.
RP Makara, AL (corresponding author), Budapest Univ Technol & Econ, Dept Broadband Infocommun & Electromagnet Theory, Budapest, Hungary.
EM makara.arpadlaszlo@edu.bme.hu; reichardt.andras@vik.bme.hu;
   csurgai-horvath.laszlo@vik.bme.hu
CR [Anonymous], 2014, NEURAL NETWORK DESIG, DOI 10
   [Anonymous], 1993, THEORETISCHE ELEKTRO
   Chen ML, 2018, CHINESE J AERONAUT, V31, P719, DOI 10.1016/j.cja.2018.01.020
   Cybulski Ronald J., 1965, RESULTS SERT I ION R
   Hockney R. W., 1989, COMPUTER SIMULATION
   Holste K, 2020, REV SCI INSTRUM, V91, DOI 10.1063/5.0010134
   Jahn R.G., 2003, ENCY PHYS SCI TECHNO, Vthird, P125
   Jugroot M, 2001, AERONAUT J, V105, P613, DOI 10.1017/S0001924000012604
   Korkut B, 2015, IEEE T PLASMA SCI, V43, P1706, DOI 10.1109/TPS.2015.2415458
   Krejci D, 2018, P IEEE, V106, P362, DOI 10.1109/JPROC.2017.2778747
   Kulu E., NANOSATS DATABASE
   Levchenko I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02269-7
   Makara A., 2020, 6 INT C RES TECHN ED
   MATLAB, 2021, PART DIFF EQ TOOLB, P2021
   Murphy Kevin P, 2013, MACHINE LEARNING PRO
   Pollard J. E., 1993, ELECT PROPULSION FLI, DOI DOI 10.2514/6.1993-2221
   Shan K, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/418493
   Thermal Analysis Premium, 2016, METTLER TOLEDO TMA S
   Thrust Mc, 2021, THRUSTME
   Wang J, 2001, J SPACECRAFT ROCKETS, V38, P433, DOI 10.2514/2.3702
NR 20
TC 0
Z9 0
U1 0
U2 0
PD DEC
PY 2021
VL 13
IS 4
BP 3
EP 9
DI 10.36244/ICJ.2021.4.1
UT WOS:000755145000002
DA 2023-11-16
ER

PT J
AU Wang, Y
   Zhang, Q
   Han, D
   Wang, F
   Yu, Y
   Lyu, P
   Li, Y
AF Wang, Y.
   Zhang, Q.
   Han, D.
   Wang, F.
   Yu, Y.
   Lyu, P.
   Li, Y.
TI Status of technology of MRPC time of flight system
SO JOURNAL OF INSTRUMENTATION
DT Article; Proceedings Paper
CT 14th Workshop on Resistive Plate Chambers and Related Detectors (RPC)
CY FEB 19-23, 2018
CL Puerto Vallarta, MEXICO
DE Gaseous detectors; Particle identification methods; Resistive-plate
   chambers; Timing detectors
AB TOF (Time Of Flight) system based on MRPC (Multi-gap Resistive Plate Chamber) technology is widely used in modern physics experiments, and it also plays an important role in particle identification. With the increase of accelerator energy and luminosity, the TOF system is required to identify definite particles precisely under high rate environment. The MRPC technology TOF system can be defined as three generations. The first generation TOF is based on float glass MRPC and its time resolution is around 80 ps, but the rate is relatively low (typically lower than a few hundred Hz/cm(2)). The typical systems are TOF of RHIC-STAR, LHC-ALICE and BES III endcap. For the second generation TOF, its time resolution is in the same order with the first generation, but the rate capability is much higher. Its rate capability can reach 30 kHz/cm(2). The typical experiment with this high rate TOF is FAIR-CBM. The biggest challenge is on the third generation TOF. For example, the momentum upper limit of K/PI separation is around 7 GeV/c for JLab-SoLID TOF system under high particle rate as high as 20 kHz/cm(2), the time requirement is around 20 ps. The readout electronics of the first two generations is based on time over threshold method and pulse shape sampling technology will be used in the third generation TOF. In the same time, the machine learning technology is also designed to analyze the time performance. In this paper, we will describe the evolution of MRPC TOF technology and key technology of each generation TOF.
C1 [Wang, Y.; Zhang, Q.; Han, D.; Wang, F.; Yu, Y.; Lyu, P.; Li, Y.] Tsinghua Univ, Dept Engn Phys, Key Lab Particle & Radiat Imaging, Beijing 100084, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, Dept Engn Phys, Key Lab Particle & Radiat Imaging, Beijing 100084, Peoples R China.
EM yiwang@mail.tsinghua.edu.cn
CR Agakishiev H, 2011, NATURE, V473, P353, DOI 10.1038/nature10079
   Akindinov A, 2002, NUCL INSTRUM METH A, V490, P58, DOI 10.1016/S0168-9002(02)00918-X
   Akindinov A, 2009, NUCL INSTRUM METH A, V602, P709, DOI 10.1016/j.nima.2008.12.095
   Anghinolfi F, 2004, IEEE T NUCL SCI, V51, P1974, DOI 10.1109/TNS.2004.836048
   CBM collaboration, 2014, TECHN DES REP CBM TI
   Christansen J., 2004, HIGH PERFORMANCE TIM
   CIOBANU M, 2008, IEEE NUCL SCI S, P2018
   Deppner I., 2015, RESULTS HEAVY ION BE, P86
   Flemming H., 2014, SCI REPORT 2013 GSI
   STAR Collaboration, 2011, NATURE, V475, P412, DOI 10.1038/nature10264
   Wang F., ARXIV180502833
   Wang FY, 2018, NUCL INSTRUM METH A, V899, P10, DOI 10.1016/j.nima.2018.04.053
   Wang JB, 2010, NUCL INSTRUM METH A, V621, P151, DOI 10.1016/j.nima.2010.04.056
   Wang Y, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/08/C08007
   Wang Y, 2010, NUCL INSTRUM METH A, V613, P200, DOI 10.1016/j.nima.2009.11.045
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
NR 16
TC 5
Z9 5
U1 0
U2 5
PD JUN
PY 2019
VL 14
AR C06015
DI 10.1088/1748-0221/14/06/C06015
UT WOS:000472134300004
DA 2023-11-16
ER

PT J
AU Nayak, A
   Zhang, K
   Setaluri, R
   Carsello, A
   Mann, M
   Torng, C
   Richardson, S
   Bahr, R
   Hanrahan, P
   Horowitz, M
   Raina, P
AF Nayak, Ankita
   Zhang, Keyi
   Setaluri, Rajsekhar
   Carsello, Alex
   Mann, Makai
   Torng, Christopher
   Richardson, Stephen
   Bahr, Rick
   Hanrahan, Pat
   Horowitz, Mark
   Raina, Priyanka
TI Improving Energy Efficiency of CGRAs with Low-Overhead Fine-Grained
   Power Domains
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Reconfigurable computing; coarse-grained reconfigurable arrays; power
   domains; hardware generators
ID ACCELERATOR
AB To effectively minimize static power for a wide range of applications, power domains for coarse-grained reconfigurable array (CGRA) architectures need to be more fine-grained than those found in a typical applicationspecific integrated circuit. However, the special isolation logic needed to ensure electrical protection between off and on domains makes fine-grained power domains area- and timing-inefficient. We propose a novel design of the CGRA routing fabric that reduces the area overhead of power domain boundary protection from around 9% to less than 1% without incurring any extra timing delay from the isolation cells. Conventional Unified Power Format based flow for power domain boundary protection does not support this design choice. Therefore, we create our own compiler-like passes that iteratively introduce the needed design changes, and formally verify the transformations using methods based on satisfiability modulo theories. These passes also let us optimize how we handle test and debug signals through the off tiles in the CGRA. Using our framework, we add power domains to a CGRA that we designed and taped out. The CGRA has 32x16 processing element and memory tiles and 4-MB secondary memory. We address the implementation challenges encountered due to the introduction of fine-grained power domains, including the addressing of the CGRA tiles, the power grid design, well substrate connections, and distribution of global signals. Our CGRA achieves up to 83% reduction in leakage power and 26% reduction in total power versus an identical CGRA without multiple power domains, for a range of image processing and machine learning applications.
C1 [Nayak, Ankita; Zhang, Keyi; Setaluri, Rajsekhar; Carsello, Alex; Mann, Makai; Torng, Christopher; Richardson, Stephen; Bahr, Rick; Hanrahan, Pat; Horowitz, Mark; Raina, Priyanka] Stanford Univ, Stanford, CA 94305 USA.
RP Nayak, A (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM ankitan@stanford.edu; keyi@stanford.edu; setaluri@stanford.edu;
   ajcars@stanford.edu; makaim@stanford.edu; ctorng@stanford.edu;
   steveri@stanford.edu; bahr@stanford.edu; hanrahan@cs.stanford.edu;
   horowitz@ee.stanford.edu; praina@stanford.edu
CR Adams Andrew., HALIDE
   Altera, 2017, STRATIX DEVICE HDB
   Ando K., 2017, CIRCUITS SYSTEMS, V8, P149
   Bin Muslim F, 2015, INT CONF SOFTW, P11, DOI 10.1109/SOFTCOM.2015.7314103
   Brown S. D., 2012, FIELD PROGRAMMABLE G, V180
   Bsoul A. A. M., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P1, DOI 10.1109/FPT.2010.5681533
   Cadence, 2019, CONF LOW POW
   Carroll Allan, 2007, P DEP ENERGY NA 22 U, V20
   Ce Li, 2011, 2011 IEEE 9th International New Circuits and Systems Conference (NEWCAS 2011), P69, DOI 10.1109/NEWCAS.2011.5981221
   Chen YC, 2014, ICCAD-IEEE ACM INT, P647, DOI 10.1109/ICCAD.2014.7001421
   Chen ZY, 2019, IEEE T VLSI SYST, V27, P2655, DOI 10.1109/TVLSI.2019.2925937
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI 10.1109/CVPRW.2011.5981829
   Fei Li, 2001, Proceedings of ISPD'01. 2001 International Symposium on Physical Design, P106
   Gayasen A., 2004, P ACM SIGDA 12 INT S, P51
   Gobieski G, 2021, CONF PROC INT SYMP C, P1027, DOI 10.1109/ISCA52012.2021.00084
   Gourisetty V, 2013, INTERDDISC ENG DES, P28, DOI 10.1109/IEDEC.2013.6526754
   Halfhill Tom R, 2010, MICROPROCESSOR REPOR
   Han K, 2012, DES AUT TEST EUROPE, P1367
   Ishihara S, 2011, IEEE T VLSI SYST, V19, P1394, DOI 10.1109/TVLSI.2010.2050500
   Jafri SMAH, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P506, DOI 10.1109/HPCSim.2014.6903727
   Jafri SMAH, 2013, INT SYM QUAL ELECT, P104, DOI 10.1109/ISQED.2013.6523597
   Kahng Andrew B., 2005, P 2005 INT S PHYS DE, P233
   Karunaratne M, 2017, DES AUT CON, DOI 10.1145/3061639.3062262
   Keating M., 2007, LOW POWER METHODOLOG
   Kim C, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2629610
   Kojima T, 2020, IEEE T VLSI SYST, V28, P2383, DOI 10.1109/TVLSI.2020.3009225
   Korol G, 2020, I C FIELD PROG LOGIC, P33, DOI 10.1109/FPL50879.2020.00017
   Kühn JM, 2015, DES AUT TEST EUROPE, P876
   Lei Y, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9181075
   Li YX, 2019, IEEE T IND ELECTRON, V66, P7407, DOI 10.1109/TIE.2018.2875643
   Lopes J, 2017, PROC INT CONF RECON
   Mathur A, 2009, I CONF VLSI DESIGN, P28, DOI 10.1109/VLSI.Design.2009.113
   Mattarei C, 2018, PROCEEDINGS OF THE 2018 18TH CONFERENCE ON FORMAL METHODS IN COMPUTER AIDED DESIGN (FMCAD), P7
   Mehta N., 2012, XILINX 7 SERIES FPGA
   Miniskar NR, 2016, IEEE INT SYMP CIRC S, P714, DOI 10.1109/ISCAS.2016.7527340
   Nicol Chris, 2017, CISC VIS NETW IND GL
   Ozaki N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.94
   Pat Hanrahan, MAGMA
   Setaluri Raj., GEMSTONE
   Sharafinejad Reza, 2015, 2015 IEEE 33rd VLSI Test Symposium (VTS). Proceedings, P1, DOI 10.1109/VTS.2015.7116288
   SHAW GA, 1995, INT CONF ACOUST SPEE, P2707, DOI 10.1109/ICASSP.1995.480120
   Shin Y, 2010, ACM T DES AUTOMAT EL, V15, DOI 10.1145/1835420.1835421
   Swartz J. S., 1998, FPGA'98. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P140, DOI 10.1145/275107.275134
   Tanomoto M, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P73, DOI 10.1109/MCSoC.2015.41
   UPF, 2018, POW INT STAND
   van Laarhoven P.J.M., 1987, SIMULATED ANNEALING, P7, DOI DOI 10.1007/978-94-015-7744-1_2
   Vasilyev A, 2016, INT SYMP MICROARCH
   Wikipedia, BOOL SAT PROBL
   Wikipedia, SATISFIABILITY MODUL
   Zhou Xingyu, 2020, P 3 USENIX WORKSHOP
NR 50
TC 1
Z9 1
U1 1
U2 1
PD JUN
PY 2023
VL 16
IS 2
AR 26
DI 10.1145/3558394
UT WOS:001020376000010
DA 2023-11-16
ER

PT J
AU Quibuyen, P
   Jiao, T
   Wong, HY
AF Quibuyen, Paul
   Jiao, Tom
   Wong, Hiu Yung
TI A Software-Circuit-Device Co-Optimization Framework for Neuromorphic
   Inference Circuits
SO IEEE ACCESS
DT Article
DE Neuromorphics; Artificial neural networks; SPICE; Integrated circuit
   modeling; Training; Internet of Things; Load modeling; Device-technology
   co-optimization (DTCO); emerging memory; neural network; neuromorphic
   computation; ReRAM; SPICE simulation
AB Neuromorphic circuits, which usually use analog computation for vector-matrix multiplication (VMM) in neural networks (NN), are promising machine learning accelerators with much lower latency and power consumption than digital ones. Analog computation is expected to have a more efficient design space than digital computation since the signals are not digitized. Therefore, it is very suitable for Internet-of-Thing (IoT) applications that require ultra-low power consumption at a low cost. For IoT applications, sometimes it is also desirable to eliminate the digital circuits (such as adders, registers, shifters, multiplexers, and Analog-to-Digital Converters) between the VMM arrays to further reduce the power consumption. However, the optimization of a purely analog circuit is more difficult and requires full SPICE circuit simulations. In this paper, we present a software-circuit-device co-optimization framework using a python wrapper for automatic full circuit SPICE simulation and analysis for neuromorphic circuits. This framework allows users to experiment with how the NN design (software) affects the performance of the hardware neuromorphic circuits. It takes Verilog-A or SPICE models from calibrations or PDK in various technologies and emerging memories (such as ReRAM) without further calibration (unlike using behavior models). We show that the simulation time is reasonable even with hundreds of thousands of synapses under limited computation resources. Using ReRAM and a 45nm generic technology as an example, the effects of feedback network and OpAmp design, software ML architecture, and input data accuracy on the inference accuracy are studied.
C1 [Quibuyen, Paul; Jiao, Tom; Wong, Hiu Yung] San Jose State Univ, Elect Engn Dept, San Jose, CA 95192 USA.
RP Wong, HY (corresponding author), San Jose State Univ, Elect Engn Dept, San Jose, CA 95192 USA.
EM hiuyung.wong@sjsu.edu
CR [Anonymous], 2014, NANOHUB, DOI DOI 10.4231/D37H1DN48
   Azghadi, 2020, ARXIV200410971
   Baumann A., 2013, 2013 Symposium on VLSI Circuits, pC202
   Cao H, 2021, IEEE MIRCOELECT ELEC, P11, DOI 10.1109/WMED49473.2021.9425210
   Chang YF, 2017, IEEE T ELECTRON DEV, V64, P2977, DOI 10.1109/TED.2017.2699679
   Demirag Y., 2021, ARXIV210801804
   Dua D., 2019, MACHINE LEARNING REP
   García-Martín E, 2019, J PARALLEL DISTR COM, V134, P75, DOI 10.1016/j.jpdc.2019.07.007
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   He ZZ, 2017, PR IEEE COMP DESIGN, P439, DOI 10.1109/ICCD.2017.78
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Kao YF, 2018, NANOSCALE RES LETT, V13, DOI 10.1186/s11671-018-2619-x
   Ko S., 2020, ARXIV200400243
   Lammie C., 2022, ARXIV220106703
   Lammie C., 2022, ARRAY, V13, DOI [10.1016/j.array.2021.100116, DOI 10.1016/J.ARRAY.2021.100116]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., MNIST DATABASE HANDW
   Liu WY, 2017, INT CONF DAT MIN WOR, P134, DOI 10.1109/ICDMW.2017.23
   Mathew DM, 2019, LECT NOTES COMPUT SC, V11733, P34, DOI 10.1007/978-3-030-27562-4_3
   Muller A.C., 2016, INTRO MACHINE LEARNI
   Nguyen A., 2021, THESIS SAN JOSE STAT
   Nguyen A, 2020, INT CONF SIM SEMI PR, P201, DOI [10.23919/sispad49475.2020.9241635, 10.23919/SISPAD49475.2020.9241635]
   Niu DW, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P209, DOI 10.1109/ICCT.2012.6511216
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Quibuyen P., 2022, THESIS SAN JOSE STAT
   RASCH MJ, 2021, P IEEE 3 INT C ART I, P1, DOI DOI 10.1109/AICAS51828.2021.9458494
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Sklearn, NEUR NETW MLPCLASSIE
   Sun XL, 2020, INT J OCCUP SAF ERGO, V26, P740, DOI 10.1080/10803548.2018.1486528
   Tang JS, 2018, INT EL DEVICES MEET
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Ueki M, 2015, S VLSI TECH
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong H. Y., 2022, P IEEE 4 INT C ART I, P1
   Xu C, 2011, DES AUT TEST EUROPE, P734
   Xu C, 2015, INT S HIGH PERF COMP, P476, DOI 10.1109/HPCA.2015.7056056
   Yu SM, 2013, ADV MATER, V25, P1774, DOI 10.1002/adma.201203680
NR 39
TC 0
Z9 0
U1 2
U2 6
PY 2022
VL 10
BP 41078
EP 41086
DI 10.1109/ACCESS.2022.3167709
UT WOS:000786078700001
DA 2023-11-16
ER

PT J
AU Kaymak, MC
   Rahnamoun, A
   O'Hearn, KA
   van Duin, ACT
   Merz, KM
   Aktulga, HM
AF Kaymak, Mehmet Cagri
   Rahnamoun, Ali
   O'Hearn, Kurt A.
   van Duin, Adri C. T.
   Merz, Kenneth M., Jr.
   Aktulga, Hasan Metin
TI JAX-ReaxFF: A Gradient-Based Framework for Fast Optimization of Reactive
   Force Fields
SO JOURNAL OF CHEMICAL THEORY AND COMPUTATION
DT Article; Early Access
ID MOLECULAR-DYNAMICS; GLOBAL OPTIMIZATION; PARAMETERIZATION; ALGORITHMS;
   EFFICIENT
AB The reactive force field (ReaxFF) model bridges the gap between traditional classical models and quantum mechanical (QM) models by incorporating dynamic bonding and polarizability. To achieve realistic simulations using ReaxFF, model parameters must be optimized against high fidelity training data which typically come from QM calculations. Existing parameter optimization methods for ReaxFF consist of black box techniques using genetic algorithms or Monte Carlo methods. Due to the stochastic behavior of these methods, the optimization process oftentimes requires millions of error evaluations for complex parameter fitting tasks, thereby significantly hampering the rapid development of high quality parameter sets. Rapid optimization of the parameters is essential for developing and refining Reax force fields because producing a force field which exhibits empirical accuracy in terms of dynamics typically requires multiple refinements to the training data as well as to the parameters under optimization. In this work, we present JAX-ReaxFF, a novel software tool that leverages modern machine learning infrastructure to enable fast optimization of ReaxFF parameters. By calculating gradients of the loss function using the JAX library, JAX-ReaxFF utilizes highly effective local optimization methods that are initiated from multiple guesses in the high dimensional optimization space to obtain high quality results. Leveraging the architectural portability of the JAX framework, JAX-ReaxFF can execute efficiently on multicore CPUs, graphics processing units (GPUs), or even tensor processing units (TPUs). As a result of using the gradient information and modern hardware accelerators, we are able to decrease ReaxFF parameter optimization time from days to mere minutes. Furthermore, the JAX-ReaxFF framework can also serve as a sandbox environment for domain scientists to explore customizing the ReaxFF functional form for more accurate modeling.
C1 [Kaymak, Mehmet Cagri; O'Hearn, Kurt A.; Aktulga, Hasan Metin] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
   [Rahnamoun, Ali; Merz, Kenneth M., Jr.] Michigan State Univ, Dept Chem, E Lansing, MI 48824 USA.
   [van Duin, Adri C. T.] Penn State Univ, Dept Mech Engn, University Pk, PA 16802 USA.
RP Kaymak, MC (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
EM kaymakme@msu.edu
CR Aktulga HM, 2012, PARALLEL COMPUT, V38, P245, DOI 10.1016/j.parco.2011.08.005
   Aktulga HM, 2012, SIAM J SCI COMPUT, V34, pC1, DOI 10.1137/100808599
   Bradbury James, 2018, JAX COMPOSABLE TRANS
   Brenner DW, 2002, J PHYS-CONDENS MAT, V14, P783, DOI 10.1088/0953-8984/14/4/312
   Case D.A, 2021, AMBER 20, DOI 10.13140/RG.2.2.15902.66881
   Daksha CM, 2021, COMP MATER SCI, V187, DOI 10.1016/j.commatsci.2020.110107
   Dittner M, 2015, J COMPUT CHEM, V36, P1550, DOI 10.1002/jcc.23966
   Fogarty JC, 2010, J CHEM PHYS, V132, DOI 10.1063/1.3407433
   Frenkel D., 2002, UNDERSTANDING MOL SI
   Furman D, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0013906
   Furman D, 2018, J CHEM THEORY COMPUT, V14, P3100, DOI 10.1021/acs.jctc.7b01272
   Gale JD, 2011, PHYS CHEM CHEM PHYS, V13, P16666, DOI 10.1039/c1cp21034c
   Guo F, 2020, COMP MATER SCI, V172, DOI 10.1016/j.commatsci.2019.109393
   Hess B, 2008, J CHEM THEORY COMPUT, V4, P435, DOI 10.1021/ct700301q
   Hubin PO, 2016, J COMPUT CHEM, V37, P2564, DOI 10.1002/jcc.24481
   Iype E, 2013, J COMPUT CHEM, V34, P1143, DOI 10.1002/jcc.23246
   Jaramillo-Botero A, 2014, J CHEM THEORY COMPUT, V10, P1426, DOI 10.1021/ct5001044
   Jung J, 2019, J COMPUT CHEM, V40, P1919, DOI 10.1002/jcc.25840
   Kraft D., 1988, SOFTWARE PACKAGE SEQ
   Kylasa SB, 2014, J COMPUT PHYS, V272, P343, DOI 10.1016/j.jcp.2014.04.035
   LaBrosse MR, 2010, J PHYS CHEM A, V114, P5855, DOI 10.1021/jp911867r
   Larsson HR, 2013, J COMPUT CHEM, V34, P2178, DOI 10.1002/jcc.23382
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MORTIER WJ, 1986, J AM CHEM SOC, V108, P4315, DOI 10.1021/ja00275a013
   MOZZI RL, 1969, J APPL CRYSTALLOGR, V2, P164, DOI 10.1107/S0021889869006868
   Müller J, 2016, J CHEM THEORY COMPUT, V12, P3913, DOI 10.1021/acs.jctc.6b00461
   Nakata H, 2019, J COMPUT CHEM, V40, P2000, DOI 10.1002/jcc.25841
   O'Hearn KA, 2020, SIAM J SCI COMPUT, V42, pC1, DOI 10.1137/18M1224684
   Phillips JC, 2005, J COMPUT CHEM, V26, P1781, DOI 10.1002/jcc.20289
   PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039
   Pun GPP, 2012, PHYS REV B, V86, DOI 10.1103/PhysRevB.86.134116
   Sabne Amit., 2020, XLA COMPILING MACHIN
   Senftle TP, 2016, NPJ COMPUT MATER, V2, DOI 10.1038/npjcompumats.2015.11
   Sengul MY, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00534-4
   Shchygol G, 2019, J CHEM THEORY COMPUT, V15, P6799, DOI 10.1021/acs.jctc.9b00769
   TERSOFF J, 1989, PHYS REV B, V39, P5566, DOI 10.1103/PhysRevB.39.5566
   Thompson AP, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108171
   Trnka T, 2018, J CHEM THEORY COMPUT, V14, P291, DOI 10.1021/acs.jctc.7b00870
   van Duin ACT, 2001, J PHYS CHEM A, V105, P9396, DOI 10.1021/jp004368u
   VANDUIN ACT, 1994, J CHEM SOC FARADAY T, V90, P2881, DOI 10.1039/ft9949002881
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 41
TC 5
Z9 6
U1 25
U2 64
PD 2022 AUG 17
PY 2022
DI 10.1021/acs.jctc.2c00363
EA AUG 2022
UT WOS:000843338800001
DA 2023-11-16
ER

PT J
AU Chen, C
   Min, HR
   Peng, Y
   Yang, YK
   Wang, Z
AF Chen, Chao
   Min, Hongrui
   Peng, Yi
   Yang, Yongkui
   Wang, Zheng
TI An Intelligent Real-Time Object Detection System on Drones
SO APPLIED SCIENCES-BASEL
DT Article
DE neural network accelerator; FPGA; object detection; intelligent system;
   machine learning
AB Drones have been widely used in everyday life and they can help deal with various tasks, including photography, searching, and surveillance. Nonetheless, it is difficult for drones to perform customized online real-time object detection. In this study, we propose an intelligent real-time object detection system for drones. It is composed of an FPGA and a drone. A neural-network (NN) engine is designed on the FPGA for NN model acceleration. The FPGA receives activation data from an NN model, which are assembled into the data stream. Multiple fetch and jump pointers catch required activation values from the data stream, which are then filtered and sent to each thread independently. To accelerate processing speed, multiple processing elements (PEs) deal with tasks in parallel by using multiple weights and threads. The image data are transferred from the drone host to the FPGA, which are tackled with high speed by the NN engine. The NN engine results are returned to the host, which is used to adjust the flying route accordingly. Experimental results reveal that our proposed FPGA design well utilizes FPGA computing resources with 81.56% DSP and 72.80% LUT utilization rates, respectively. By using the Yolov3-tiny model for fast object detection, our system can detect objects at the speed of 8 frames per second and achieves a much lower power consumption compared to state-of-the-art methods. More importantly, the intelligent object detection techniques provide more pixels for the target of interest and they can increase the detection confidence score from 0.74 to 0.90 and from 0.70 to 0.84 for persons and cars, respectively.
C1 [Chen, Chao; Min, Hongrui; Peng, Yi; Yang, Yongkui; Wang, Zheng] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Min, Hongrui; Peng, Yi] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
RP Wang, Z (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM zheng.wang@siat.ac.cn
CR Ali S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073514
   Daud SMSM, 2022, SCI JUSTICE, V62, P30, DOI 10.1016/j.scijus.2021.11.002
   Deepa N, 2021, J SUPERCOMPUT, V77, P1998, DOI 10.1007/s11227-020-03347-2
   Ding CW, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P33, DOI 10.1145/3289602.3293904
   Gadekallu TR, 2022, IEEE INTERNET THINGS, V9, P964, DOI 10.1109/JIOT.2021.3119639
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Girshick R., 2015, P IEEE INT C COMP VI, P1440
   Glowacz A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217245
   Rodríguez GG, 2020, J INTELL MANUF, V31, P1257, DOI 10.1007/s10845-019-01510-y
   Guo KY, 2016, IEEE HOT CHIP SYMP
   Ha N, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000063
   Haseeb K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092468
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Husni NL, 2021, SMART CITIES-BASEL, V4, P1496, DOI 10.3390/smartcities4040079
   Injadat M, 2021, ARTIF INTELL REV, V54, P3299, DOI 10.1007/s10462-020-09948-w
   Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2
   Jin Wang, 2021, 2021 11th International Conference on Information Science and Technology (ICIST), P571, DOI 10.1109/ICIST52614.2021.9440554
   Khan AA, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108234
   Krul S, 2021, DRONES-BASEL, V5, DOI 10.3390/drones5020041
   Li YY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157811
   Lin T., 2014, ARXIV
   Liu Y, 2020, SCI BULL, V65, P70, DOI 10.1016/j.scib.2019.10.021
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma J., 2018, DIGITAL TV WIRELESS, P224, DOI DOI 10.1007/978-981-10-8108-8_21
   Moshref-Javadi M, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114854
   Prencipe B, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073247
   Qiu S, 2022, INT J INTELL SYST, V37, P1646, DOI 10.1002/int.22689
   Rapuano E, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13081518
   Redmon J., P IEEE C COMPUTER VI, P779
   Shahmoradi J, 2020, DRONES-BASEL, V4, DOI 10.3390/drones4030034
   Ul Haq A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092649
   Wang Z, 2020, J SEMICOND, V41, DOI 10.1088/1674-4926/41/2/022401
   Wenbin Li, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1160), P35, DOI 10.1007/978-3-030-45691-7_4
   Zekic-Susac M, 2021, INT J INFORM MANAGE, V58, DOI 10.1016/j.ijinfomgt.2020.102074
NR 35
TC 1
Z9 1
U1 6
U2 15
PD OCT
PY 2022
VL 12
IS 20
AR 10227
DI 10.3390/app122010227
UT WOS:000872155200001
DA 2023-11-16
ER

PT J
AU Aktulga, HM
   Kaymak, MC
   Rahnamoun, A
   O'Hearn, KA
   Merz, KM
   van Duin, ACT
AF Aktulga, Hasan Metin
   Kaymak, Mehmet Cagri
   Rahnamoun, Ali
   O'Hearn, Kurt A.
   Merz Jr, Kenneth M.
   van Duin, Adri C. T.
TI JAX-ReaxFF: A Gradient-Based Framework for Fast Optimization of Reactive
   Force Fields
SO JOURNAL OF CHEMICAL THEORY AND COMPUTATION
DT Article
ID MOLECULAR-DYNAMICS; GLOBAL OPTIMIZATION; PARAMETERIZATION; ALGORITHMS;
   EFFICIENT
AB The reactive force field (ReaxFF) model bridges the gap between traditional classical models and quantum mechanical (QM) models by incorporating dynamic bonding and polar-izability. To achieve realistic simulations using ReaxFF, model parameters must be optimized against high fidelity training data which typically come from QM calculations. Existing parameter optimization methods for ReaxFF consist of black box techniques using genetic algorithms or Monte Carlo methods. Due to the stochastic behavior of these methods, the optimization process oftentimes requires millions of error evaluations for complex parameter fitting tasks, thereby significantly hampering the rapid development of high quality parameter sets. Rapid optimization of the parameters is essential for developing and refining Reax force fields because producing a force field which exhibits empirical accuracy in terms of dynamics typically requires multiple refinements to the training data as well as to the parameters under optimization. In this work, we present JAX-ReaxFF, a novel software tool that leverages modern machine learning infrastructure to enable fast optimization of ReaxFF parameters. By calculating gradients of the loss function using the JAX library, JAX-ReaxFF utilizes highly effective local optimization methods that are initiated from multiple guesses in the high dimensional optimization space to obtain high quality results. Leveraging the architectural portability of the JAX framework, JAX-ReaxFF can execute efficiently on multicore CPUs, graphics processing units (GPUs), or even tensor processing units (TPUs). As a result of using the gradient information and modern hardware accelerators, we are able to decrease ReaxFF parameter optimization time from days to mere minutes. Furthermore, the JAX-ReaxFF framework can also serve as a sandbox environment for domain scientists to explore customizing the ReaxFF functional form for more accurate modeling.
C1 [Rahnamoun, Ali] Michigan State Univ, Dept Chem, E Lansing, MI 48824 USA.
   [Aktulga, Hasan Metin; Kaymak, Mehmet Cagri; O'Hearn, Kurt A.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
   [Rahnamoun, Ali] Penn State Univ, Dept Mech Engn, State Coll, PA 16802 USA.
RP Kaymak, MC (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
EM kaymakme@msu.edu
CR Aktulga HM, 2012, PARALLEL COMPUT, V38, P245, DOI 10.1016/j.parco.2011.08.005
   Aktulga HM, 2012, SIAM J SCI COMPUT, V34, pC1, DOI 10.1137/100808599
   Bradbury James, 2018, JAX COMPOSABLE TRANS
   Brenner DW, 2002, J PHYS-CONDENS MAT, V14, P783, DOI 10.1088/0953-8984/14/4/312
   Case D. A., 2020, AMBER 2020
   Daksha CM, 2021, COMP MATER SCI, V187, DOI 10.1016/j.commatsci.2020.110107
   Dittner M, 2015, J COMPUT CHEM, V36, P1550, DOI 10.1002/jcc.23966
   Fogarty JC, 2010, J CHEM PHYS, V132, DOI 10.1063/1.3407433
   Frenkel D., 2002, UNDERSTANDING MOL SI
   Furman D, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0013906
   Furman D, 2018, J CHEM THEORY COMPUT, V14, P3100, DOI 10.1021/acs.jctc.7b01272
   Gale JD, 2011, PHYS CHEM CHEM PHYS, V13, P16666, DOI 10.1039/c1cp21034c
   Guo F, 2020, COMP MATER SCI, V172, DOI 10.1016/j.commatsci.2019.109393
   Hess B, 2008, J CHEM THEORY COMPUT, V4, P435, DOI 10.1021/ct700301q
   Hubin PO, 2016, J COMPUT CHEM, V37, P2564, DOI 10.1002/jcc.24481
   Iype E, 2013, J COMPUT CHEM, V34, P1143, DOI 10.1002/jcc.23246
   Jaramillo-Botero A, 2014, J CHEM THEORY COMPUT, V10, P1426, DOI 10.1021/ct5001044
   Jung J, 2019, J COMPUT CHEM, V40, P1919, DOI 10.1002/jcc.25840
   Kraft D., 1988, 8828 DFVLRFB DLR GER
   Kylasa SB, 2014, J COMPUT PHYS, V272, P343, DOI 10.1016/j.jcp.2014.04.035
   LaBrosse MR, 2010, J PHYS CHEM A, V114, P5855, DOI 10.1021/jp911867r
   Larsson HR, 2013, J COMPUT CHEM, V34, P2178, DOI 10.1002/jcc.23382
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MORTIER WJ, 1986, J AM CHEM SOC, V108, P4315, DOI 10.1021/ja00275a013
   MOZZI RL, 1969, J APPL CRYSTALLOGR, V2, P164, DOI 10.1107/S0021889869006868
   Müller J, 2016, J CHEM THEORY COMPUT, V12, P3913, DOI 10.1021/acs.jctc.6b00461
   Nakata H, 2019, J COMPUT CHEM, V40, P2000, DOI 10.1002/jcc.25841
   O'Hearn KA, 2020, SIAM J SCI COMPUT, V42, pC1, DOI 10.1137/18M1224684
   Phillips JC, 2005, J COMPUT CHEM, V26, P1781, DOI 10.1002/jcc.20289
   PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039
   Pun GPP, 2012, PHYS REV B, V86, DOI 10.1103/PhysRevB.86.134116
   Sabne Amit., 2020, XLA COMPILING MACHIN
   Senftle TP, 2016, NPJ COMPUT MATER, V2, DOI 10.1038/npjcompumats.2015.11
   Sengul MY, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00534-4
   Shchygol G, 2019, J CHEM THEORY COMPUT, V15, P6799, DOI 10.1021/acs.jctc.9b00769
   TERSOFF J, 1989, PHYS REV B, V39, P5566, DOI 10.1103/PhysRevB.39.5566
   Thompson AP, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108171
   Trnka T, 2018, J CHEM THEORY COMPUT, V14, P291, DOI 10.1021/acs.jctc.7b00870
   van Duin ACT, 2001, J PHYS CHEM A, V105, P9396, DOI 10.1021/jp004368u
   VANDUIN ACT, 1994, J CHEM SOC FARADAY T, V90, P2881, DOI 10.1039/ft9949002881
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 41
TC 5
Z9 6
U1 25
U2 64
PD SEP 13
PY 2022
VL 18
IS 9
BP 5181
EP 5194
DI 10.1021/acs.jctc.2c003635181
UT WOS:000857310000001
DA 2023-11-16
ER

PT J
AU Asnaashari, K
   Gholami, S
   Khosravi, HR
AF Asnaashari, K.
   Gholami, S.
   Khosravi, H. R.
TI Lessons learnt from errors in radiotherapy centers
SO INTERNATIONAL JOURNAL OF RADIATION RESEARCH
DT Article
DE Quality control; radiotherapy errors; clinical audit; lack of technology
ID QUALITY-ASSURANCE; RADIATION-THERAPY; CANCER-TREATMENT; PATIENT SAFETY;
   ONCOLOGY; IMPACT
AB Background: The purpose of this work is to discover and analyze errors and incidents in some radiotherapy centers, and to introduce methods that could reduce their occurrences, especially those which had happened due to the use of improper and inadequate equipment. This work is a first step toward clarifying the role of education in a risk-conscious culture, and changing the attitude of radiotherapy staff when they are working under encouraging conditions that remove barriers for reporting errors. Materials and Methods: For the present study clinical investigation, the data of 6000 patients were checked. They were treated at a few radiotherapy centers during one year. Patients were treated by linear accelerator or cobalt machine, photon or electron beams. A purposely designed check list was used for error data collection. Incidents were discovered by manual check at different steps of treatment. By highlighting frequency of occurrence, further investigation for preventing error repetition can be possible. Eighty five incidents were reported by Technologists, fifty four were reported by Physicists, and twenty six events were pointed out by Radiation Oncologists. Results: About fifty percent of total 165 detected events were classified as treatment field errors. Geometrical misses in treatment field have the highest probability for both photon and electron beams. Conclusion: Incident prevention considering likelihood of individual event can be possible when using facilities like record-and-verification (R&V) system and electronic-portal-image-device (EPID), taking seriously QA, defining and implementing layers of defense in depth, and making an organized system for reporting and analyzing errors.
C1 [Asnaashari, K.] Univ Tehran Med Sci, Sch Allied Med Sci, Tehran, Iran.
   [Gholami, S.] Univ Tehran Med Sci, Dept Med Phys & Biomed Engn, Tehran, Iran.
   [Khosravi, H. R.] Iran Nucl Regulatory Author, Nucl & Radiat Support Dept, Tehran, Iran.
RP Gholami, S (corresponding author), Univ Tehran Med Sci, Dept Med Phys & Biomed Engn, Tehran, Iran.
EM s-gholami@razi.tums.ac.ir
CR Baiotto B, 2009, TUMORI, V95, P467
   Delaney G, 2005, CANCER-AM CANCER SOC, V104, P1129, DOI 10.1002/cncr.21324
   Fraass B, 1998, MED PHYS, V25, P1773, DOI 10.1118/1.598373
   Gerard K, 2009, J QUAL MAINT ENG, V15, P331, DOI 10.1108/13552510910997715
   Gluhchev G, 1996, PATTERN RECOGN LETT, V17, P1233, DOI 10.1016/0167-8655(96)00097-9
   ICRU, 1976, DET ABS DOS PAT IRR
   International Atomic Energy Agency, 2000, IAEA SAF REP SER
   Ishikura S, 2008, JPN J CLIN ONCOL, V38, P723, DOI 10.1093/jjco/hyn112
   Karp SJ, 1999, J EVAL CLIN PRACT, V5, P179, DOI 10.1046/j.1365-2753.1999.00176.x
   Klein EE, 2005, J APPL CLIN MED PHYS, V6, P81, DOI 10.1120/jacmp.2025.25355
   Lefresne S, 2013, INT J RADIAT ONCOL, V85, pE117, DOI 10.1016/j.ijrobp.2012.10.015
   Möller TR, 2003, ACTA ONCOL, V42, P376, DOI 10.1080/02841860310011113
   Ortiz P, 2009, ANN ICRP, V39, P63
   Pennsylvania Patient Safety Advisory, 2009, ERRORS RAD THERAPY, V6, P87
   THWAITES D, 1995, RADIOTHER ONCOL, V35, P61, DOI 10.1016/0167-8140(95)01549-V
   Williams MV, 2007, BRIT J RADIOL, V80, P297, DOI 10.1259/bjr/29018029
   World Health Organization (WHO), 2008, RADIOTHERAPY RISK PR
NR 17
TC 5
Z9 5
U1 0
U2 10
PD OCT
PY 2014
VL 12
IS 4
BP 361
EP 367
UT WOS:000348584000012
DA 2023-11-16
ER

PT J
AU Shafiee, A
   Pasricha, S
   Nikdast, M
AF Shafiee, Amin
   Pasricha, Sudeep
   Nikdast, Mahdi
TI A Survey on Optical Phase-Change Memory: The Promise and Challenges
SO IEEE ACCESS
DT Article
DE Photonics; Phase change materials; Phase change memory; Nonvolatile
   memory; Optical sensors; Optical pulses; Adaptive optics; phase-change
   memory; in-memory photonic computing; photonic integrated circuits;
   silicon photonics
ID RANDOM-ACCESS MEMORY; SILICON; DESIGN; DEPENDENCE; GE2SB2TE5; THICKNESS;
   LATENCY; FUTURE
AB Silicon photonics (SiPh) technology has facilitated the deployment of integrated photonics across different application domains, from ultra-fast communication in Datacom applications to energy-efficient optical computation in emerging hardware accelerators for machine learning. More recently, the integration of SiPh and phase change materials has created a unique opportunity to realize adaptable, reconfigurable, and programmable photonic platforms. In particular, the nonvolatile programmability in phase change materials has made them a promising candidate for implementing photonic memory cells and architectures. Accordingly, photonic memory systems and even in-memory photonic computing paradigms are on the rise, especially given their potential for improving data access in electronic and photonic processors. However, there are still many challenges in the design and fabrication of phase-change photonic integrated circuits, which need to be addressed. This article presents a comprehensive survey on the recent advances and challenges for the integration of phase change materials with contemporary photonic devices while focusing on the photonic memory application. In particular, we explore phase-change photonic memory from the material level to the architecture level by presenting an overview of different material-level characteristics of phase change materials with their optical, electrical, and thermal properties as well as their integration into SiPh devices and photonic memory architectures and their application for in-memory photonic computing. We also present a comparison with electronic memory and discuss open research challenges that must be addressed to further advance phase-change photonic memory towards successful integration into emerging computing systems.
C1 [Shafiee, Amin; Pasricha, Sudeep; Nikdast, Mahdi] Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO 80523 USA.
RP Nikdast, M (corresponding author), Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO 80523 USA.
EM mahdi.nikdast@colostate.edu
CR Abdollahramezani S, 2020, NANOPHOTONICS-BERLIN, V9, P1189, DOI 10.1515/nanoph-2020-0039
   Alexoudi T, 2020, LIGHT-SCI APPL, V9, DOI 10.1038/s41377-020-0325-9
   [Anonymous], 2001, SILICON NITRIDE SI3N
   [Anonymous], 2016, PROC OPT FIBER COMMU
   Antolini A, 2021, MATERIALS, V14, DOI 10.3390/ma14071624
   Arjunan MS, 2021, PHYS STATUS SOLIDI-R, V15, DOI 10.1002/pssr.202100291
   Aryana K, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20661-8
   Ashwin P, 2008, J APPL PHYS, V104, DOI 10.1063/1.2978334
   Bahadori M, 2016, J LIGHTWAVE TECHNOL, V34, P4043, DOI 10.1109/JLT.2016.2588459
   Banerjee S., 2022, P 2021 DESIGN AUTOMA, DOI [10.1109/JLT.2022.3193658, DOI 10.1109/JLT.2022.3193658]
   Banerjee S, 2021, PHYTOTHER RES, V35, P5668, DOI 10.1002/ptr.7203
   Banerjee S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P98, DOI 10.23919/DATE51398.2021.9474000
   Bangari V, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2945540
   Bedeschi Ferdinando, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P428, DOI 10.1109/ISSCC.2008.4523240
   Bogaerts W, 2012, LASER PHOTONICS REV, V6, P47, DOI 10.1002/lpor.201100017
   Boukhobza J, 2018, ACM T DES AUTOMAT EL, V23, DOI 10.1145/3131848
   Boybat I., 2021, IEDM, P3
   Brückerhoff-Plückelmann F, 2022, NANOPHOTONICS-BERLIN, V11, P4063, DOI 10.1515/nanoph-2021-0752
   Brückerhoff-Plückelmann F, 2021, J APPL PHYS, V129, DOI 10.1063/5.0042549
   Burr GW, 2010, J VAC SCI TECHNOL B, V28, P223, DOI 10.1116/1.3301579
   Cabrini A, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON MEMORY TECHNOLOGY, DESIGN, AND TESTING, PROCEEDINGS, P3, DOI 10.1109/MTDT.2009.11
   Chakraborty I, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.014063
   Chen R, 2022, ACS PHOTONICS, V9, P3181, DOI 10.1021/acsphotonics.2c00976
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Cheng ZG, 2018, ADV MATER, V30, DOI 10.1002/adma.201802435
   Cheng ZG, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1700160
   Chittamuru S. V. Reddy, 2017, PROC ACMIEEE INT WOR, P1
   Clements WR, 2016, OPTICA, V3, P1460, DOI 10.1364/OPTICA.3.001460
   de Lima TF, 2019, J LIGHTWAVE TECHNOL, V37, P1515, DOI 10.1109/JLT.2019.2903474
   de Magalhaes FG, 2016, IEEE COMMUN LETT, V20, P462, DOI 10.1109/LCOMM.2016.2515583
   Duong L. H. K., IEEE T VLSI SYST, V24
   Fang Z., NAT NANOTECHNOL, V17
   Fang ZR, 2022, IEEE J SEL TOP QUANT, V28, DOI 10.1109/JSTQE.2021.3120713
   Fang ZR, 2020, PROC SPIE, V11276, DOI 10.1117/12.2548309
   Fantini P, 2012, APPL PHYS LETT, V100, DOI 10.1063/1.3674311
   Feldmann J, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01506-3
   Feldmann J., NATURE, V589, pno
   Feldmann J, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2956871
   Gemo E, 2021, J APPL PHYS, V129, DOI 10.1063/5.0042962
   Gemo E, 2019, OPT EXPRESS, V27, P24724, DOI 10.1364/OE.27.024724
   Ghione G., 2009, SEMICONDUCTOR DEVICE
   Giannopoulos I., 2018, IEDM, P7
   Gosciniak J., 2021, ARXIV
   Guo Pengxing, 2022, Opt Express, V30, P37051, DOI 10.1364/OE.468456
   Hanqing Zhu, 2022, 2022 27th Asia and South Pacific Design Automation Conference (ASP-DAC), P332, DOI 10.1109/ASP-DAC52403.2022.9712497
   Je-Min Hung, 2021, IEEE Open Journal of the Solid-State Circuits Society, V1, P171, DOI 10.1109/OJSSCS.2021.3123287
   Jiang L, 2014, CONF PROC INT SYMP C, P397, DOI 10.1109/ISCA.2014.6853194
   Jouppi N, 2017, PROC ACMIEEE INT S, P1
   Kim HJ, 2021, J PHYS-PHOTONICS, V3, DOI 10.1088/2515-7647/abeb55
   Kim SK, 2018, MRS BULL, V43, P334, DOI 10.1557/mrs.2018.95
   Kohary K, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3595408
   Kuwahara M, 2007, JPN J APPL PHYS 1, V46, P3909, DOI 10.1143/JJAP.46.3909
   Lacaita AL, 2008, PHYS STATUS SOLIDI A, V205, P2281, DOI 10.1002/pssa.200723561
   Lazarenko P, 2021, APL MATER, V9, DOI 10.1063/5.0066387
   Le Gallo M, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/ab7794
   Lee BC, 2009, CONF PROC INT SYMP C, P2, DOI 10.1145/1555815.1555758
   Lefurgy C, 2003, COMPUTER, V36, P39, DOI 10.1109/MC.2003.1250880
   Li C, 2018, J MATER CHEM C, V6, P3387, DOI 10.1039/c8tc00222c
   Li X, 2020, OPTICA, V7, P218, DOI 10.1364/OPTICA.379228
   Li X, 2019, OPTICA, V6, P1, DOI 10.1364/OPTICA.6.000001
   Li ZQ, 2013, INT S HIGH PERF COMP, P210, DOI 10.1109/HPCA.2013.6522320
   Lian CY, 2022, NANOPHOTONICS-BERLIN, V11, P3823, DOI 10.1515/nanoph-2022-0089
   Liu HK, 2021, J COMPUT SCI TECH-CH, V36, P4, DOI 10.1007/s11390-020-0780-z
   Mahdian MA, 2020, AEU-INT J ELECTRON C, V126, DOI 10.1016/j.aeue.2020.153403
   Margalit N, 2021, APPL PHYS LETT, V118, DOI 10.1063/5.0050117
   Miao XS, 1999, JPN J APPL PHYS 1, V38, P1638, DOI 10.1143/JJAP.38.1638
   Mirza A, 2022, IEEE T NANOTECHNOL, V21, P763, DOI 10.1109/TNANO.2022.3223915
   Mirza A, 2022, IEEE T COMPUT AID D, V41, P3359, DOI 10.1109/TCAD.2021.3132555
   Miscuglio M, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0001942
   Miscuglio M, 2019, APL MATER, V7, DOI 10.1063/1.5109689
   Mittal S., 2018, J HARDWARE SYSTEMS S, V2, P179
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1537, DOI 10.1109/TPDS.2015.2442980
   Mutlu O, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P21, DOI 10.1109/IMW.2013.6582088
   Narayan A., 2022, CLIMATE CHANGE 2014, V19, P1
   Nikdast M., 2021, SILICON PHOTONICS HI
   Nikdast M, 2016, 2016 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC)
   Nikdast M, 2016, J LIGHTWAVE TECHNOL, V34, P3682, DOI 10.1109/JLT.2016.2563781
   Nikdast M, 2015, IEEE T VLSI SYST, V23, P2552, DOI 10.1109/TVLSI.2014.2370892
   Nikdast M, 2015, IEEE T VLSI SYST, V23, P156, DOI 10.1109/TVLSI.2014.2300534
   Nikdast M, 2014, 2014 EIGHTH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS), P172, DOI 10.1109/NOCS.2014.7008779
   Nirschl T, 2007, INT EL DEVICES MEET, P461, DOI 10.1109/IEDM.2007.4418973
   Nisar MS, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8060205
   Palmer AW, 2020, IEEE INT C INTELL TR, DOI 10.1109/itsc45102.2020.9294699
   Parra J, 2021, LASER PHOTONICS REV, V15, DOI 10.1002/lpor.202000501
   Pasricha S, 2008, MORG KAUF SER SYST, P1
   Pasricha S, 2020, IEEE DES TEST, V37, P60, DOI 10.1109/MDAT.2020.2982628
   Qu YR, 2017, LASER PHOTONICS REV, V11, DOI 10.1002/lpor.201700091
   Raoux S, 2008, IBM J RES DEV, V52, P465, DOI 10.1147/rd.524.0465
   Raoux S, 2008, J APPL PHYS, V103, DOI 10.1063/1.2938076
   Raoux S, 2009, ANNU REV MATER RES, V39, P25, DOI [10.1146/annurev-matsci-082908-145405, 10.1146/annurev.matsci.082908-145405]
   Raoux S, 2008, MICROELECTRON ENG, V85, P2330, DOI 10.1016/j.mee.2008.08.004
   Raty JY, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8467
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Rios Carlos, 2021, 2021 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEO/Europe-EQEC52157.2021.9541979
   Rios C., 2021, PROC SPIE, V11796
   Rios C., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.06010
   Ríos C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau5759
   Rios C, 2018, OPT MATER EXPRESS, V8, P2455, DOI 10.1364/OME.8.002455
   Ríos C, 2016, IEEE PHOTON CONF, P408, DOI 10.1109/IPCon.2016.7831160
   Ríos C, 2015, NAT PHOTONICS, V9, P725, DOI [10.1038/NPHOTON.2015.182, 10.1038/nphoton.2015.182]
   Rios C, 2014, ADV MATER, V26, P1372, DOI 10.1002/adma.201304476
   Risk WP, 2009, APPL PHYS LETT, V94, DOI 10.1063/1.3097353
   Rudé M, 2013, APPL PHYS LETT, V103, DOI 10.1063/1.4824714
   Rütten M, 2015, SCI REP-UK, V5, DOI 10.1038/srep17362
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Sebastian A, 2019, J PHYS D APPL PHYS, V52, DOI 10.1088/1361-6463/ab37b6
   Sebastian A, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5314
   Senkader S, 2004, J APPL PHYS, V95, P504, DOI 10.1063/1.1633984
   Shafee A., 2021, P INT S NETW COMP CO, P1, DOI [10.1109/ISNCC52172.2021.9615776, DOI 10.1109/ISNCC52172.2021.9615776]
   Shafiee Amin, 2022, GLSVLSI '22: Proceedings of the Great Lakes Symposium on VLSI 2022, P351, DOI 10.1145/3526241.3530365
   Shafiee A., 2022, WILEY ENCY ELECT ELE, P1
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Shokraneh F, 2020, J LIGHTWAVE TECHNOL, V38, P1258, DOI 10.1109/JLT.2020.2966949
   Shokraneh F, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2952562
   Stegmaier M, 2017, ADV OPT MATER, V5, DOI 10.1002/adom.201600346
   Stegmaier M, 2016, ACS PHOTONICS, V3, P828, DOI 10.1021/acsphotonics.6b00032
   Sun W, 2022, PHOTONICS-BASEL, V9, DOI 10.3390/photonics9030132
   Sunny F, 2021, Arxiv, DOI arXiv:2109.04459
   Sunny F, 2022, IEEE COMPUT SOC, P98, DOI 10.1109/ISVLSI54635.2022.00030
   Sunny F, 2021, DES AUT CON, P1069, DOI 10.1109/DAC18074.2021.9586161
   Sunny FP, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3459009
   Sunny FP, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3476988
   Tabatabaei F, 2017, J APPL PHYS, V122, DOI 10.1063/1.4996429
   Taheri Ebadollah, 2022, 2022 IEEE/ACM International Conference On Computer Aided Design (ICCAD), P1
   Tait AN, 2022, PHYS REV APPL, V17, DOI 10.1103/PhysRevApplied.17.054029
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   TAIT AN, 2017, SCI REPORTS, V7, P1, DOI DOI 10.1038/S41598-017-07754-Z
   Teo TY, 2022, OPT MATER EXPRESS, V12, P606, DOI 10.1364/OME.447289
   Thakkar IG, 2018, IEEE T COMPUT AID D, V37, P1760, DOI 10.1109/TCAD.2017.2762921
   Wang H, 2019, MATER LETT, V254, P182, DOI 10.1016/j.matlet.2019.07.031
   Wang JM, 2020, IEEE ACCESS, V8, P121211, DOI 10.1109/ACCESS.2020.3006899
   Wang Q, 2021, ADV ELECTRON MATER, V7, DOI 10.1002/aelm.202001241
   Wang Y., 2021, MULTIPHYSICS GCA COD
   Wang YX, 2021, NPJ QUANTUM INFORM, V7, DOI 10.1038/s41534-021-00362-w
   Wei XQ, 2007, JPN J APPL PHYS 1, V46, P2211, DOI 10.1143/JJAP.46.2211
   Wilmart Q., APPL SCI-BASEL
   Wright CD, 2013, ADV FUNCT MATER, V23, P2248, DOI 10.1002/adfm.201202383
   Wu XW, 2015, IEEE T VLSI SYST, V23, P678, DOI 10.1109/TVLSI.2014.2319089
   Wuttig M, 2017, NAT PHOTONICS, V11, P465, DOI [10.1038/nphoton.2017.126, 10.1038/NPHOTON.2017.126]
   Wuttig M, 2007, NAT MATER, V6, P824, DOI 10.1038/nmat2009
   Wuttig M, 2012, Z ANORG ALLG CHEM, V638, P2455, DOI 10.1002/zaac.201200448
   Xie YY, 2013, IEEE T VLSI SYST, V21, P1823, DOI 10.1109/TVLSI.2012.2220573
   Xue C. J., 2011, 2011 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P325
   Yang X, 2021, OPT LETT, V46, P4224, DOI 10.1364/OL.435552
   Youngblood N, 2019, ADV FUNCT MATER, V29, DOI 10.1002/adfm.201807571
   Yu T, 2021, Arxiv, DOI arXiv:2102.10398
   Zhang HY, 2019, ACS PHOTONICS, V6, P2205, DOI 10.1021/acsphotonics.9b00819
   Zhang H, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3066500
   Zhang M, 2021, OPTICA, V8, P652, DOI 10.1364/OPTICA.415762
   Zhang QM, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0151-0
   Zhang Y., NAT NANOTECHNOL
   Zhang YF, 2021, APPL PHYS LETT, V118, DOI 10.1063/5.0054114
   Zhang YF, 2019, PROC SPIE, V11081, DOI 10.1117/12.2528993
   Zhang YP, 2019, NAT COMMUN, V10, DOI [10.1038/s41467-019-09005-3, 10.1038/s41467-019-12196-4]
NR 155
TC 2
Z9 2
U1 22
U2 30
PY 2023
VL 11
BP 11781
EP 11803
DI 10.1109/ACCESS.2023.3241146
UT WOS:000932812300001
DA 2023-11-16
ER

PT C
AU Andri, R
   Bussolino, B
   Cipolletta, A
   Cavigelli, L
   Wang, Z
AF Andri, Renzo
   Bussolino, Beatrice
   Cipolletta, Antonio
   Cavigelli, Lukas
   Wang, Zhe
GP IEEE Comp Soc
TI Going Further With Winograd Convolutions: Tap-Wise Quantization for
   Efficient Inference on 4x4 Tiles
SO 2022 55TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
SE International Symposium on Microarchitecture Proceedings
DT Proceedings Paper
CT 55th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 01-05, 2022
CL Chicago, IL
DE Machine Learning Acceleration; Winograd Convolution; ML System Design
ID NEURAL-NETWORK; ACCELERATION; PERFORMANCE
AB Most of today's computer vision pipelines are built around deep neural networks, where convolution operations require most of the generally high compute effort. The Winograd convolution algorithm computes convolutions with fewer multiply-accumulate operations (MACs) compared to the standard algorithm, reducing the operation count by a factor of 2.25x for 3x3 convolutions when using the version with 2x2-sized tiles F-2. Even though the gain is significant, the Winograd algorithm with larger tile sizes, i.e., F-4, offers even more potential in improving throughput and energy efficiency, as it reduces the required MACs by 4x. Unfortunately, the Winograd algorithm with larger tile sizes introduces numerical issues that prevent its use on integer domain-specific accelerators (DSAs) and higher computational overhead to transform input and output data between spatial and Winograd domains.
   To unlock the full potential of Winograd F-4, we propose a novel tap-wise quantization method that overcomes the numerical issues of using larger tiles, enabling integer-only inference. Moreover, we present custom hardware units that process the Winograd transformations in a power- and area-efficient way, and we show how to integrate such custom modules in an industrial-grade, programmable DSA. An extensive experimental evaluation on a large set of state-of-the-art computer vision benchmarks reveals that the tap-wise quantization algorithm makes the quantized Winograd F-4 network almost as accurate as the FP32 baseline. The Winograd-enhanced DSA achieves up to 1.85x gain in energy efficiency and up to 1.83x end-to-end speed-up for state-of-the-art segmentation and detection networks.
C1 [Andri, Renzo; Bussolino, Beatrice; Cipolletta, Antonio; Cavigelli, Lukas; Wang, Zhe] Huawei Zurich Res Ctr, Comp Syst Lab, Zurich, Switzerland.
   [Bussolino, Beatrice] Politecn Torino, DET, Turin, Italy.
RP Andri, R (corresponding author), Huawei Zurich Res Ctr, Comp Syst Lab, Zurich, Switzerland.
CR Alam S. A., 2022, ARXIV
   Barabasz, 2020, ARXIV
   Barabasz B, 2020, ACM T MATH SOFTWARE, V46, DOI 10.1145/3412380
   Barabasz B, 2019, LECT NOTES COMPUT SC, V11946, P307, DOI 10.1007/978-3-030-35166-3_22
   Bengio Yoshua, 2013, ABS13083432 CORR
   Blahut RE., 2010, FAST ALGORITHMS SIGN
   Castro RL, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9172033
   Chellapilla K., 2006, PROC 10 INT WORKSHOP
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choquette J, 2021, IEEE MICRO, V41, P29, DOI 10.1109/MM.2021.3061394
   Fernandez-Marques J., 2021, MLSYS
   Gong Jiong, 2018, METHOD APPARATUS KEE
   Guo Y., 2018, SURVEY METHODS THEOR
   Hackenberg D, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P896, DOI 10.1109/IPDPSW.2015.70
   Han S, 2015, ADV NEUR IN, V28
   Hinton Geoffrey, 2015, ARXIV150302531
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Jain S. R., ARXIV
   Jouppi N, 2016, GOOGLE SUPERCHARGES
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang P, 2021, IEICE T INF SYST, VE104D, P394, DOI 10.1587/transinf.2020EDP7160
   Kim S., 2021, IEEE ACCESS, V9
   Kingma DP., 2017, ARXIV
   Krishnamoorthi R., 2018, ARXIV
   Krizhevsky A, 2009, HDB SYST AUTOIMMUNE, V1, P1
   Krizhevsky A, 2012, NIPS 2012, V1, P1097, DOI 10.1061/(ASCE)GT.1943-5606.0001284
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3173162.3173176, 10.1145/3296957.3173176]
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li Dongsheng, 2021, 50 INT C PAR PROC, P1
   Li G., 2021, PROC 50 INT C PARALL, P1
   Li GL, 2020, INT CONF ACOUST SPEE, P3842, DOI [10.1109/ICASSP40776.2020.9054562, 10.1109/icassp40776.2020.9054562]
   Li S. Y, ARXIV
   Li W., 2021, INT C MACHINE LEARNI, P6307
   Liang TL, 2021, NEUROCOMPUTING, V461, P370, DOI 10.1016/j.neucom.2021.07.045
   Liao Heng, 2019, 2019 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875654
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu J., 2021, PROC IEEE 5 ELECT DE, P1
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X., 2018, ARXIV
   Liu XH, 2021, IEEE INT CONF ASAP, P258, DOI 10.1109/ASAP52443.2021.00045
   Liu YZ, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1025
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Mahale G, 2020, IEEE T COMPUT AID D, V39, P4278, DOI 10.1109/TCAD.2020.3013096
   Maji P, 2019, 2019 2ND WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2 2019), P1, DOI 10.1109/EMC249363.2019.00008
   Meng L., 2019, ARXIV
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Nagadomi, 2014, KAGGL CIFAR10 TORCH7
   Nayak P, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P52, DOI 10.1109/EMC2-NIPS53020.2019.00020
   Norrie T, 2021, IEEE MICRO, V41, P56, DOI 10.1109/MM.2021.3058217
   NVIDIA, NVDLA PRIM NVDLA DOC
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saglietti L., 2022, MATH SCI MACHINE LEA, P809
   Smith J. E., 1982, 9th Annual Symposium on Computer Architecture, P112
   Steiner Lukas, 2021, MBMV 2021 24 WORKSH, P1
   Tao Yang, 2021, Arabian Journal of Geosciences, DOI 10.1007/s12517-021-07673-4
   Villa O, 2021, INT S HIGH PERF COMP, P868, DOI 10.1109/HPCA51647.2021.00077
   Wang SH, 2021, IEEE INT CONF ASAP, P65, DOI 10.1109/ASAP52443.2021.00018
   Wang ZR, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P736, DOI 10.1145/3307650.3322229
   Winograd S., 1980, ARITHMETIC COMPLEXIT, V33
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xygkis A, 2018, DES AUT CON, DOI 10.1145/3195970.3196041
   Yang C, 2020, IEEE T CIRCUITS-I, V67, P3007, DOI 10.1109/TCSI.2020.2985727
   Yepez J, 2020, IEEE T VLSI SYST, V28, P853, DOI 10.1109/TVLSI.2019.2961602
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao YL, 2018, ALGORITHMS, V11, DOI 10.3390/a11100159
   Zhi-Gang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P53, DOI 10.1007/978-3-030-58529-7_4
   Zhu F, 2020, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR42600.2020.00204
NR 70
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 582
EP 598
DI 10.1109/MICRO56248.2022.00048
UT WOS:000886530600034
DA 2023-11-16
ER

PT C
AU Datta, G
   Kundu, S
   Yin, Z
   Mathai, J
   Liu, Z
   Wang, Z
   Tian, M
   Lu, S
   Lakkireddy, RT
   Schmidt, A
   Abd-Almageed, W
   Jacob, A
   Jaiswal, A
   Beerel, P
AF Datta, Gourav
   Kundu, Souvik
   Yin, Zihan
   Mathai, Joe
   Liu, Zeyu
   Wang, Zixu
   Tian, Mulin
   Lu, Shunlin
   Lakkireddy, Ravi Teja
   Schmidt, Andrew
   Abd-Almageed, Wael
   Jacob, Ajey
   Jaiswal, Akhilesh
   Beerel, Peter
GP IEEE
TI P<SUP>2</SUP>M-DeTrack: Processing-in-Pixel-in-Memory for
   Energy-efficient and Real-Time Multi-Object Detection and Tracking
SO PROCEEDINGS OF THE 2022 IFIP/IEEE 30TH INTERNATIONAL CONFERENCE ON VERY
   LARGE SCALE INTEGRATION (VLSI-SOC)
DT Proceedings Paper
CT 30th IFIP/IEEE International Conference on Very Large Scale Integration
   (VLSI-SoC)
CY OCT 03-05, 2022
CL Univ Patras, Patras, GREECE
HO Univ Patras
DE autonomous vehicles; detection; tracking; processing-in-pixel-in-memory;
   faster R-CNN
AB Today's high resolution, high frame rate cameras in autonomous vehicles generate a large volume of data that needs to be transferred and processed by a downstream processor or machine learning (ML) accelerator to enable intelligent computing tasks, such as multi-object detection and tracking. The massive amount of data transfer incurs significant energy, latency, and bandwidth bottlenecks, which hinders real-time processing. To mitigate this problem, we propose an algorithm-hardware co-design framework called Processing-in-Pixel-in-Memory-based object Detection and Tracking ((PM)-M-2-DeTrack). (PM)-M-2-DeTrack is based on a custom faster R-CNN-based model that is distributed partly inside the pixel array (front-end) and partly in a separate FPGA/ASIC (back-end). The proposed front-end in-pixel processing down-samples the input feature maps significantly with judiciously optimized strided convolution and pooling. Compared to a conventional baseline design that transfers frames of RGB pixels to the back-end, the resulting (PM)-M-2-DeTrack designs reduce the data bandwidth between sensor and back-end by up to 24x. The designs also reduce the sensor and total energy (obtained from in-house circuit simulations at Globalfoundries 22nm technology node) per frame by 5.7x and 1.14x, respectively. Lastly, they reduce the sensing and total frame latency by an estimated 1.7x and 3x, respectively. We evaluate our approach on the multi-object object detection (tracking) task of the large-scale BDD100K dataset and observe only a 0.5% reduction in the mean average precision (0.8% reduction in the identification F1 score) compared to the state-of-the-art.
C1 [Datta, Gourav; Kundu, Souvik; Yin, Zihan; Liu, Zeyu; Wang, Zixu; Tian, Mulin; Lu, Shunlin; Lakkireddy, Ravi Teja; Jaiswal, Akhilesh; Beerel, Peter] Univ Southern Calif, Los Angeles, CA USA.
   [Kundu, Souvik] Intel Labs, San Diego, CA USA.
   [Mathai, Joe; Schmidt, Andrew; Abd-Almageed, Wael; Jacob, Ajey; Jaiswal, Akhilesh] Informat Sci Inst, Marina Del Rey, CA USA.
RP Datta, G (corresponding author), Univ Southern Calif, Los Angeles, CA USA.
EM gdatta@usc.edu
CR Angizi S, 2022, Arxiv, DOI arXiv:2202.09035
   [Anonymous], 2021, DEMOSAICING QUAD BAY
   [Anonymous], 2017, BIG DATA COGN COMPUT, DOI DOI 10.3390/BDCC1010005
   Bose L, 2020, EUROPEAN C COMPUTER, P488
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen Z, 2020, IEEE T CIRCUITS-I, V67, P389, DOI 10.1109/TCSI.2019.2937227
   Datta G., 2022, ARXIV PREPRINT ARXIV
   Datta Gourav., FRONT NEUROSCI-SWITZ, P400
   Datta Gourav, 2022, ARXIV
   Gan YM, 2020, INT CONFER PARA, P329, DOI 10.1145/3410463.3414650
   Gupta M, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372068
   Jacob Ajey., 2021, US Patent, Patent No. [11,069,402, 11069402]
   Jaiswal Akhilesh, 2021, US Patent., Patent No. [11,195,580, 11195580]
   Kodukula V, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030926
   Kundu S, 2021, ASIA S PACIF DES AUT, P344, DOI 10.1145/3394885.3431542
   Kundu S, 2020, IEEE T COMPUT, V69, P1045, DOI 10.1109/TC.2020.2972520
   Li WT, 2020, ANN I S COM, P832, DOI 10.1109/ISCA45697.2020.00073
   Mennel L, 2020, NATURE, V579, P62, DOI 10.1038/s41586-020-2038-x
   Motoyoshi M, 2009, P IEEE, V97, P43, DOI 10.1109/JPROC.2008.2007462
   OECD, 2019, Health at a Glance 2019:�OECD Indicators, DOI 10.1787/4dd50c09-en
   ON Semiconductor, CMOS IM SENS 1 2 MP
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Ren A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P925, DOI 10.1145/3297858.3304076
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Saha O, 2020, ADV NEURAL INFORM PR
   Song Ruibing, 2021, ARXIV
   Subudhi BN, 2019, MULTIMED TOOLS APPL, V78, P26129, DOI 10.1007/s11042-019-07793-w
   Tianrui Ma, 2019, 2019 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA), P150, DOI 10.1109/ICTA48799.2019.9012906
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vargas J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165397
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yu FS, 2020, Arxiv, DOI arXiv:1805.04687
NR 32
TC 0
Z9 0
U1 1
U2 1
PY 2022
DI 10.1109/VLSI-SoC54400.2022.9939582
UT WOS:000889978800016
DA 2023-11-16
ER

PT J
AU Kin, NW
   Asaari, MSM
   Rosdi, BA
   Akbar, MF
AF Kin, Ng Wai
   Asaari, Mohd Shahrimie Mohd
   Rosdi, Bakhtiar Affendi
   Akbar, Muhammad Firdaus
TI FPGA IMPLEMENTATION OF CNN FOR DEFECT CLASSIFICATION ON CMP RING
SO JURNAL TEKNOLOGI-SCIENCES & ENGINEERING
DT Article
DE Convolutional Neural Network; Deep learning; Field Programmable Gate
   Array; Defect Classification; Automatic visual inspection
AB Defect inspection is a crucial part of industrial manufacturing. However, it relies heavily on human effort on manual visual inspection. Various machine vision techniques have been introduced to replace human labour and to improve inspection quality and efficiency. The limitation of these techniques is that the algorithms need to be engineered again with each different use case. In this work, a Convolutional Neural Network (CNN) is used to classify the defects of the Chemical Mechanical Planarization (CMP) ring. The trained CNN model achieved an accuracy of 91% and the time taken for each inference process is around 1800 msec. To achieve computational efficiency, the CNN model is performed on the embedded device. The previous implementation of embedded CNN deploys OpenCL-based high-level synthesis accelerator on a high-end Field Programmable Gate Array (FPGA) board. In this work, the model inference is accelerated by PipeCNN FPGA implementation on Cyclone-VSE DE1-SoC, a low-end embedded FPGA board. Several configurations of hardware parameters are tested to search for the best setup of the FPGA resources. The hardware implementation has improved approximately seven times faster, as the inference time for each classification has improved from 1800 msec to 250 msec. However, the model implemented using the hardware is observed to produce lower inference accuracy as the accuracy drops from 91% to 81%. In conclusion, despite a slight decrease in accuracy, the implementation using FPGA manages to accelerate the inference performance of the CNN model up to 4 frames/sec, confirming the high potential of this approach to be used for high-throughput defect classification on CMP ring. (C) 2021 Penerbit UTM Press. All rights reserved
C1 [Kin, Ng Wai; Asaari, Mohd Shahrimie Mohd; Rosdi, Bakhtiar Affendi; Akbar, Muhammad Firdaus] Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
RP Asaari, MSM (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM mohdshahrimie@usm.my
CR Anderson J. H., 2013, P ACM SIGDA INT S FI, DOI [10.1145/2435264.2435269, DOI 10.1145/2435264.2435269]
   [Anonymous], 2018, P 5 INT WORKSHOP FPG
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   Dong W., 2016, PIPECNN OPENCL BASED
   Ghaffari A., 2020, CNN2GATE DESIGNING G
   Hanh PX, 2019, PROCEDIA COMPUT SCI, V151, P651, DOI 10.1016/j.procs.2019.04.087
   Huai L, 2015, INT CONF ASIC
   Huang SH, 2015, COMPUT IND, V66, P1, DOI 10.1016/j.compind.2014.10.006
   Jiaxiang Shi, 2020, IOP Conference Series: Materials Science and Engineering, V768, DOI 10.1088/1757-899X/768/7/072014
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS-ASIA (ICCE-ASIA)
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Linsangan NB, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON BIOMEDICAL AND BIOINFORMATICS ENGINEERING (ICBBE 2018), P100, DOI 10.1145/3301879.3301905
   Liu B, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030281
   Luk W., 2017, LECT NOTES COMPUT SC, P255, DOI DOI 10.1007/978-3-319-56258-2_22
   Oztemel E, 2020, J INTELL MANUF, V31, P127, DOI 10.1007/s10845-018-1433-8
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sundararajan S, 1999, J ELECTROCHEM SOC, V146, P761, DOI 10.1149/1.1391678
   Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x
   Wang CC, 2013, IEEE T SEMICONDUCT M, V26, P378, DOI 10.1109/TSM.2013.2261566
   Wang J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060620
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 24
TC 0
Z9 0
U1 0
U2 4
PD SEP
PY 2021
VL 83
IS 5
BP 101
EP 108
DI 10.11113/jurnalteknologi.v83.16967
UT WOS:000698789000012
DA 2023-11-16
ER

PT J
AU Giacomin, E
   Gudaparthi, S
   Boemmels, J
   Balasubramonian, R
   Catthoor, F
   Gaillardon, PE
AF Giacomin, Edouard
   Gudaparthi, Sumanth
   Boemmels, Juergen
   Balasubramonian, Rajeev
   Catthoor, Francky
   Gaillardon, Pierre-Emmanuel
TI A Multiply-and-Accumulate Array for Machine Learning Applications Based
   on a 3D Nanofabric Flow
SO IEEE TRANSACTIONS ON NANOTECHNOLOGY
DT Article
DE 3D logic integration; emerging technologies; hardware accelerators;
   nanotechnologies
AB To keep pushing Moore's law cadence and improve integrated circuits area, delay, and power, novel fabrication schemes such as parallel and monolithic 3D integration have been recently proposed. While parallel 3D is limited by the large TSV pitch, monolithic 3D suffers from the high cost of the additional masks and processing steps, limiting the number of stacked transistor layers. In our previous work, we introduced a novel 3D integration scheme called 3D Nanofabric. Inspired by the 3D NAND flash process, the flow consists of N identical vertical tiers where multiple vertical layers can be patterned simultaneously, significantly reducing the manufacturing cost. In this paper, we propose to build low-footprint Multiply-And-Accumulate (MAC) units using our 3D Nanofabric flow. Since a MAC unit can be laid out as a regular array, we demonstrate how to arrange in a 3D fashion across several vertical tiers of the 3D Nanofabric. Through circuit-level evaluations, we show that for a 64-input bit MAC unit consisting of 64 stacked vertical tiers, the area and area-delay-product are reduced by 21.0x and 16.7x, respectively, compared to a traditional 2D implementation using a 28 nm FDSOI technology, with only a 43% energy overhead. More importantly, the total fabrication cost is reduced, producing a cost scaling roadmap. Additionally, we show how to build a systolic 3D MAC array aimed at convolutional neural networks. Through architectural evaluations, we demonstrate that when running VGG-16, our 3D MAC array can improve the TOPs/mm(2) by 2.8x compared to a TPU-like 2D systolic array.
C1 [Giacomin, Edouard; Gaillardon, Pierre-Emmanuel] Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
   [Gudaparthi, Sumanth; Balasubramonian, Rajeev] Univ Utah, Dept Comp Sci, Salt Lake City, UT 84112 USA.
   [Boemmels, Juergen; Catthoor, Francky] IMEC, B-3001 Leuven, Belgium.
   [Catthoor, Francky] KU, B-3001 Leuven, Belgium.
RP Giacomin, E (corresponding author), Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
EM edouard.giacomin@gmail.com; sgudapar@cs.utah.edu;
   Juergen.Boemmels@imec.be; rajeev@cs.utah.edu; Francky.catthoor@imec.be;
   pierre-emmanuel.gaillardon@utah.edu
CR Aly MMS, 2015, COMPUTER, V48, P24, DOI 10.1109/MC.2015.376
   Andreev AA, 2018, IEEE T COMPUT, V67, P73, DOI 10.1109/TC.2017.2695179
   [Anonymous], 2012, 2012 INT C MICROWAVE
   [Anonymous], 2015, PROC IEEE SOI 3D SUB, DOI DOI 10.1109/S3S.2015.7333538
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Brunschwiler T, 2009, MICROSYST TECHNOL, V15, P57, DOI 10.1007/s00542-008-0690-4
   Chen R, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371905
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cho J, 2021, ISSCC DIG TECH PAP I, V64, P426, DOI 10.1109/ISSCC42613.2021.9366054
   Cho JH, 2018, ISSCC DIG TECH PAP I, P208, DOI 10.1109/ISSCC.2018.8310257
   Colinge J.P., 2007, FINFET OTHER MULTIGA
   Derakhshandeh J, 2020, 2020 IEEE 8TH ELECTRONICS SYSTEM-INTEGRATION TECHNOLOGY CONFERENCE (ESTC), DOI 10.1109/estc48849.2020.9229785
   Fenouillet-Beranger C., S VLSI TECHN, P1
   Giacomin E., P IEEE INT S CIRC SY, V2021, P23
   Giacomin E, 2020, IEEE INT CONF VLSI, P34, DOI 10.1109/VLSI-SOC46417.2020.9344089
   Gitlin D., 2016, 2016 IEEE SOI3DS, P1
   Gudaparthi S, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P1, DOI 10.1145/3352460.3358316
   Higuchi T, P IEEE INT SOL STAT, V2021, P428
   Jang J, 2009, 2009 SYMPOSIUM ON VLSI TECHNOLOGY, DIGEST OF TECHNICAL PAPERS, P192
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jourdain A, 2020, ELEC COMP C, P42, DOI 10.1109/ECTC32862.2020.00020
   Lee CC, 2016, ELEC COMP C, P1439, DOI 10.1109/ECTC.2016.348
   Lhostis S, 2016, ELEC COMP C, P869, DOI 10.1109/ECTC.2016.202
   Li MY, 2016, IEEE COMP SOC ANN, P403, DOI 10.1109/ISVLSI.2016.56
   Li XYS, 2005, ACM T MATH SOFTWARE, V31, P302, DOI 10.1145/1089014.1089017
   Lin JY, 2017, IEEE T CIRCUITS-I, V64, P562, DOI 10.1109/TCSI.2016.2613505
   Liu DM, 2020, S VLSI TECH, DOI 10.1109/vlsitechnology18217.2020.9265008
   Lo HC, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P215, DOI 10.1109/VLSIT.2018.8510632
   Macha NK, 2016, IEEE INT SYMP NANO, P151, DOI 10.1145/2950067.2950079
   Natarajan S, 2014, INT EL DEVICES MEET
   Park JW, 2021, ISSCC DIG TECH PAP I, V64, P422, DOI 10.1109/ISSCC42613.2021.9365809
   Planes N., 2012, 2012 IEEE Symposium on VLSI Technology, P133, DOI 10.1109/VLSIT.2012.6242497
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shulaker MM, 2017, NATURE, V547, P74, DOI 10.1038/nature22994
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sridhar A, 2010, ICCAD-IEEE ACM INT, P463, DOI 10.1109/ICCAD.2010.5653749
   Subramanian S, 2020, S VLSI TECH, DOI 10.1109/vlsitechnology18217.2020.9265073
   Wan Z, 2018, IEEE SOI3DSUB MICRO
   Wei TW, 2021, IEEE T COMP PACK MAN, V11, P415, DOI 10.1109/TCPMT.2020.3045113
NR 39
TC 1
Z9 1
U1 0
U2 4
PY 2021
VL 20
BP 873
EP 882
DI 10.1109/TNANO.2021.3132224
UT WOS:000730463800003
DA 2023-11-16
ER

PT J
AU Li, Q
   Liu, ZY
   Qiao, F
   Wei, Q
   Yang, HZ
AF Li, Qin
   Liu, Zheyu
   Qiao, Fei
   Wei, Qi
   Yang, Huazhong
TI Could We Realize the Fully Flexible System by Real-Time Computing with
   Thin-Film Transistors?
SO APPLIED SCIENCES-BASEL
DT Article
DE flexible electronics; thin-film transistors; image signal processing;
   machine learning; analog-to-information processing; physical computing
AB Flexible electronic devices, such as the typical thin-film transistors, are widely adopted in the area of sensors, displayers, wearable equipment, and such large-area applications, for their features of bending and stretching; additionally, in some applications of lower-resolution data converters recently, where a trend appears that implementing more parts of system with flexible devices to realize the fully flexible system. Nevertheless, relatively fewer works on the computation parts with flexible electronic devices are reported, due to their poor carrier mobility, which blocks the way to realize the fully flexible systems with uniform manufacturing process. In this paper, a novel circuit architecture for image processing accelerator using Oxide Thin-film transistor (TFT), which could realize real-time image pre-processing and classification in the analog domain, is proposed, where the performance and fault-tolerance of image signal processing is exploited. All of the computation is done in the analog signal domain and no clock signal is needed. Therefore, certain weaknesses of flexible electronic devices, such as low carrier mobility, could be remedied dramatically. In this paper, Simulations based on Oxide TFT device model have demonstrated that the flexible computing parts could perform 5 x 5 Gaussian convolution operation at a speed of 3.3 MOPS/s with the energy efficiency of 1.83 TOPS/J, and realize image classification at a speed of 10 k fps, with the energy efficiency of 5.25 GOPS/J, which means that the potential applications to realize real-time computing parts of complex algorithms with flexible electronic devices, as well as the future fully flexible systems containing sensors, data converters, energy suppliers, and real-time signal processing modules, all with flexible devices.
C1 [Li, Qin; Liu, Zheyu; Qiao, Fei; Wei, Qi; Yang, Huazhong] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
RP Qiao, F; Wei, Q (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM li-q16@mails.tsinghua.edu.cn; zy-liu15@mails.tsinghua.edu.cn;
   qiaofei@tsinghua.edu.cn; weiqi@tsinghua.edu.cn; yanghz@tsinghua.edu.cn
CR [Anonymous], P INT C COMP VIS
   Bae JU, 2017, 2017 24TH INTERNATIONAL WORKSHOP ON ACTIVE-MATRIX FLATPANEL DISPLAYS AND DEVICES (AM-FPD), P309
   Chandan N., 2017, P 2014 IEEE WORKSH S, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   GILBERT B, 1968, IEEE J SOLID-ST CIRC, VSC 3, P365, DOI 10.1109/JSSC.1968.1049925
   Green MA, 2015, PROG PHOTOVOLTAICS, V23, P1, DOI [10.1002/pip.2728, 10.1002/pip.2573]
   Kang K, 2010, IEEE T CIRCUITS-I, V57, P1513, DOI 10.1109/TCSI.2009.2034234
   Li Q, 2017, INT J PHOTOENERGY, V2017, DOI [10.1109/TPWRS.2017.2712697, 10.1155/2017/8107073]
   Li Y, 2015, IEEE INT SYMP CIRC S, P2057, DOI 10.1109/ISCAS.2015.7169082
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051
   Liu ZM, 2016, INT J POLYM SCI, V2016, DOI 10.1155/2016/9351725
   Myny K, 2014, ISSCC DIG TECH PAP I, V57, P486, DOI 10.1109/ISSCC.2014.6757523
   Nomura K, 2004, NATURE, V432, P488, DOI 10.1038/nature03090
   Park JS, 2009, APPL PHYS LETT, V95, DOI 10.1063/1.3159832
   Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, DOI DOI 10.7551/MITPRESS/5236.001.0001
   Schwartz G, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2832
   Song I, 2008, IEEE ELECTR DEVICE L, V29, P549, DOI 10.1109/LED.2008.920965
   Sun W, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P127, DOI 10.1109/GSIS.2017.8077686
   Verhelst Marian, 2015, IEEE Solid-State Circuits Magazine, V7, P67, DOI 10.1109/MSSC.2015.2442394
   Wang XW, 2017, SMALL, V13, DOI 10.1002/smll.201602790
   Wu N, 2016, IEEE COMP SOC ANN, P455, DOI 10.1109/ISVLSI.2016.87
   Xie HT, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101099
   Yoon J, 2015, ADV OPT MATER, V3, P1313, DOI 10.1002/adom.201500365
   Zhang YJ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/463930
NR 25
TC 2
Z9 2
U1 0
U2 9
PD DEC
PY 2017
VL 7
IS 12
AR 1224
DI 10.3390/app7121224
UT WOS:000419175800020
DA 2023-11-16
ER

PT C
AU Chen, LC
   Huo, X
   Agrawal, G
AF Chen, Linchuan
   Huo, Xin
   Agrawal, Gagan
GP IEEE
TI Accelerating MapReduce on a Coupled CPU-GPU Architecture
SO 2012 INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING,
   NETWORKING, STORAGE AND ANALYSIS (SC)
SE International Conference for High Performance Computing Networking
   Storage and Analysis
DT Proceedings Paper
CT 25th ACM/IEEE International Conference for High Performance Computing,
   Networking, Storage and Analysis (SC)
CY NOV 10-16, 2012
CL Salt Lake City, UT
ID PRACTICAL SCHEDULING SCHEME
AB The work presented here is driven by two observations. First, heterogeneous architectures that integrate a CPU and a GPU on the same chip are emerging, and hold much promise for supporting power-efficient and scalable high performance computing. Second, MapReduce has emerged as a suitable framework for simplified parallel application development for many classes of applications, including data mining and machine learning applications that benefit from accelerators.
   This paper focuses on the challenge of scaling a MapReduce application using the CPU and GPU together in an integrated architecture. We develop different methods for dividing the work, which are the map-dividing scheme, where map tasks are divided between both devices, and the pipelining scheme, which pipelines the map and the reduce stages on different devices. We develop dynamic work distribution schemes for both the approaches. To achieve high load balance while keeping scheduling costs low, we use a runtime tuning method to adjust task block sizes for the map-dividing scheme. Our implementation of MapReduce is based on a continuous reduction method, which avoids the memory overheads of storing key-value pairs.
   We have evaluated the different design decisions using 5 popular MapReduce applications. For 4 of the applications, our system achieves 1.21 to 2.1 speedup over the better of the CPU-only and GPU-only versions. The speedups over a single CPU core execution range from 3.25 to 28.68. The runtime tuning method we have developed achieves very low load imbalance, while keeping scheduling overheads low. Though our current work is specific to MapReduce, many underlying ideas are also applicable towards intra-node acceleration of other applications on integrated CPU-GPU nodes.
C1 [Chen, Linchuan; Huo, Xin; Agrawal, Gagan] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
RP Chen, LC (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM chenlinc@cse.ohio-state.edu; huox@cse.ohio-state.edu;
   agrawal@cse.ohio-state.edu
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1007/BF00153759
   [Anonymous], 2009, IEEE INT C CLUSTER C
   [Anonymous], 2010, 19 ACM IN TERNATION
   [Anonymous], 1988, ALGORITHMS CLUSTERIN
   Catanzaro Bryan, 2008, 3 WORKSH SOFTW TOOLS
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   Chu C. T., 2006, NIPS, P281
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Elteir Marwa, 2011, ICPADS 11 TAIW TAIW
   Feng Ji, 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P805, DOI 10.1109/IPDPS.2011.80
   Gillick D, 2008, MAPREDUCE DISTRIBUTE
   Govindaraju N., 2010, SIGMOD 06, P325
   He BS, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P260, DOI 10.1145/1454115.1454152
   Hong CT, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P217, DOI 10.1145/1854273.1854303
   HUMMEL SF, 1992, COMMUN ACM, V35, P90, DOI 10.1145/135226.135232
   Liu J., 1993, Proceedings SUPERCOMPUTING '93, P814, DOI 10.1145/169627.169841
   Markatos E. P., 1992, Proceedings. Supercomputing '92. (Cat. No.92CH3216-9), P104, DOI 10.1109/SUPERC.1992.236705
   POLYCHRONOPOULOS CD, 1987, IEEE T COMPUT, V36, P1425, DOI 10.1109/TC.1987.5009495
   Ranger C, 2007, INT S HIGH PERF COMP, P13
   Ravi Vignesh T., 2010, P INT C SUP ICS
   Shirahata Koichi, 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P733, DOI 10.1109/CloudCom.2010.55
   Stuart J. A., 2011, IPDPS
   TZEN TH, 1993, IEEE T PARALL DISTR, V4, P87, DOI 10.1109/71.205655
   Venkatasubramanian S, 2009, ICS'09: PROCEEDINGS OF THE 2009 ACM SIGARCH INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P244, DOI 10.1145/1542275.1542312
   Yoo RM, 2009, I S WORKL CHAR PROC, P198, DOI 10.1109/IISWC.2009.5306783
NR 25
TC 2
Z9 2
U1 0
U2 0
PY 2012
UT WOS:000316911000049
DA 2023-11-16
ER

PT J
AU Li, WT
   Sun, XY
   Huang, SS
   Jiang, HW
   Yu, SM
AF Li, Wantong
   Sun, Xiaoyu
   Huang, Shanshi
   Jiang, Hongwu
   Yu, Shimeng
TI A 40-nm MLC-RRAM Compute-in-Memory Macro With Sparsity Control, On-Chip
   Write-Verify, and Temperature-Independent ADC References
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE System-on-chip; Resistance; Common Information Model (computing);
   Sensors; Nonvolatile memory; Programming; Quantization (signal);
   Emerging non-volatile memories (NVMs); hardware accelerators; in-memory
   computing; machine learning
ID MONOLITHICALLY INTEGRATED RRAM; INFERENCE; CMOS
AB Resistive random access memory (RRAM)-based compute-in-memory (CIM) has shown great potential for accelerating deep neural network (DNN) inference. However, device characteristics, such as low-resistance values, susceptibility to drift, and single-level cells, may limit the capabilities of RRAM-based CIM. In addition, prior works generally used the off-chip write-verify scheme to tighten RRAM resistance distributions and used off-chip analog-to-digital converter (ADC) references for fine-tuning partial sum quantization. Although off-chip techniques are viable for testing purposes, they may be unsuitable for practical applications. In this work, we present an RRAM-CIM macro to accelerate DNN inference. The chip features: 1) multi-level cell (MLC) RRAM for improving compute performance and density; 2) sparsity-aware input control to leverage the high activation sparsity in DNN models; 3) on-chip write-verify to speed up initial weight programming and periodically refresh cells to compensate for resistance drift under stress; and 4) on-chip ADC reference generation that provides column-wise tunability and stability with varying temperatures to guarantee the CIFAR-10 accuracy of 85.8% at 120 degrees C. The design is fabricated in TSMC 40-nm process with embedded RRAM technology and achieves a macro-level peak performance of 97.8 GOPS/mm(2) and 44.5 TOPS/W for multiply-and-accumulate (MAC) operations on VGG-8 network with ternary weights.
C1 [Li, Wantong; Huang, Shanshi; Jiang, Hongwu; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Sun, Xiaoyu] Taiwan Semicond Mfg Co TSMC, San Jose, CA 95132 USA.
RP Li, WT (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM wli360@gatech.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cheng-Xin Xue, 2021, 2021 IEEE International Solid- State Circuits Conference (ISSCC), P245, DOI 10.1109/ISSCC42613.2021.9365769
   Correll JM, 2020, IEEE J EXPLOR SOLID-, V6, P36, DOI 10.1109/JXCDC.2020.2992228
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   He WX, 2020, IEEE SOLID-ST CIRC L, V3, P194, DOI 10.1109/LSSC.2020.3010795
   Jiang HW, 2022, IEEE DES TEST, V39, P48, DOI 10.1109/MDAT.2021.3050715
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Lee JZ, 2021, PACE, V44, P513, DOI 10.1111/pace.14175
   Li WT, 2021, PROC EUR S-STATE DEV, P79, DOI 10.1109/ESSDERC53440.2021.9631810
   Li WK, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533325
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   Luo YD, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9181022
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Peng XC, 2019, INT EL DEVICES MEET
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Shim W, 2020, SEMICOND SCI TECH, V35, DOI 10.1088/1361-6641/abb842
   Shim W, 2020, IEEE T ELECTRON DEV, V67, P2318, DOI 10.1109/TED.2020.2985013
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   WAN WE, 2020, ISSCC DIG TECH PAP I, P498, DOI DOI 10.1109/ISSCC19947.2020.9062979
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yin SH, 2020, IEEE T ELECTRON DEV, V67, P4185, DOI 10.1109/TED.2020.3015178
   Yin SH, 2019, IEEE MICRO, V39, P54, DOI 10.1109/MM.2019.2943047
   Yoon JH, 2022, IEEE J SOLID-ST CIRC, V57, P68, DOI 10.1109/JSSC.2021.3101209
   Yu SM, 2021, IEEE T CIRCUITS-I, V68, P2753, DOI 10.1109/TCSI.2021.3072200
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
NR 37
TC 11
Z9 11
U1 8
U2 31
PD SEP
PY 2022
VL 57
IS 9
BP 2868
EP 2877
DI 10.1109/JSSC.2022.3163197
EA APR 2022
UT WOS:000782833200001
DA 2023-11-16
ER

PT J
AU Zhao, Y
   Li, ZP
   Liu, WH
   Wan, JY
   Jiao, Y
AF Zhao, Yu
   Li, Zhiping
   Liu, Weihang
   Wan, Jinyu
   Jiao, Yi
TI Physics issues of the diffraction-limited storage ring light source
SO CHINESE SCIENCE BULLETIN-CHINESE
DT Review
DE synchrotron radiation light source; diffraction-limited storage ring;
   multi-bend achromat; machine leaf ing; free electron laser
ID X-RAY; COHERENT RADIATION; EMITTANCE GROWTH; PARTICLE SWARM; 1ST
   OPERATION; DESIGN; OPTIMIZATION; GENERATION; ARC
AB 0The synchrotron radiation light source based on electron storage ring is the most widely used high-performance X-ray source in the field of basic scientific research in the 20th century, and has undergone three generations of development. One important direction of the new generation light source, i.e., the fourth generation light source, is the so-called diffractionlimited storage ring (DL SR) light source. DL SR. with ultra-high average brightness, high repetition frequency, multi-user, high stability, complementary to the free electron laser (FEL), has a great development in recent decades. By adopting lattice design based on compact multi-bend achromats (MBAs). DL SR allows to achieve one or two orders of magnitude lower emittance approaching the diffraction limit of X-rays, and much higher brightness and coherence than available in the third generation light source, while inheriting the high brightness, multi-user and high stability advantages of existing ring light sources. In this paper, the progress made in the last few decades in physics design and optimization of the DL SR, especially on the ultralow-emittance lattice and injection schemes, will be overviewed. To achieve an ultralow emittance, lattice structures of standard MBA and hybrid MBA, and novel magnets of high-gradient quadrupole, antibend, longitudinal gradient dipole and complex bend, have been proposed. To obtain optimized beam dynamics in a DLSR, theoretical and numerical methods have been developed to date. Due to the fact that the nonlinearities are extremely high in a DLSR and the nonlinear dynamics is greatly coupled with the linear optics, the most effective and most commonly used way is global and stochastic optimization of the ring performance evaluated by numerical tracking. To deal with the challenges of injecting to a DLSR with small dynamic acceptance, different injection schemes, such as, pulsed multipole injection, on-axis swap-out injection and on-axis longitudinal injection, have been proposed. Collective effects, especially the intra beam scattering and the Touschek effects, become significant as emittance decreases, requiring methods of bunch lengthening and transverse feedback to ensure the stability of the particle motion at a high beam current. Besides, a few developing topics in DLSR physics will be discussed. Machine learning, the method of transferring disorder data into useful information, is an important branch of artificial intelligence, and has been used in accelerator control system and beam commissioning. This method would be very useful and helpful in the design and optimization. initial commissioning and daily operation of a DLSR. A rational combination of machine learning and multi-objective optimization algorithm, like multi-objective genetic algorithm and multi-objective particle swarm algorithm, can effectively improve the optimization performance, and has been successfully applied in nonlinear optimization of light sources. In addition, improving the performance of synchrotron radiation by combining the beam physics of DLSR and the principle of FEL is one developing research topic which might be able to provide base for further development of the DLSR. Combined with bypass and transverse gradient undulator, high gain FEL could be achieved in the storage ring. Besides, double ring light source, divided into two loops, the inner ring is DLSR, and the other is FEL with more long straight sections, was proposed to improve the utilization rate of the beams.
C1 [Zhao, Yu; Li, Zhiping; Liu, Weihang; Wan, Jinyu; Jiao, Yi] Chinese Acad Sci, Inst High Energy Phys, Beijing 100049, Peoples R China.
   [Zhao, Yu; Li, Zhiping; Liu, Weihang; Wan, Jinyu; Jiao, Yi] Univ Chinese Acad Sci, Sch Phys Sci, Beijing 100049, Peoples R China.
   [Zhao, Yu; Li, Zhiping; Liu, Weihang] Spallat Neutron Source Sci Ctr, Dongguan 523803, Peoples R China.
RP Jiao, Y (corresponding author), Chinese Acad Sci, Inst High Energy Phys, Beijing 100049, Peoples R China.; Jiao, Y (corresponding author), Univ Chinese Acad Sci, Sch Phys Sci, Beijing 100049, Peoples R China.
EM jiaoyi@ihcp.ac.cn
CR Aiba M, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.020701
   Bai Z., 2011, P IPAC11 SAN SEB SPA, P2271
   Bai Z H, 2016, P 7 INT PART ACC C B, P2889
   Bassi G, 2006, NUCL INSTRUM METH A, V557, P189, DOI 10.1016/j.nima.2005.10.067
   Bazarov I V, 2015, PHYS REV SPEC TOP-AC, V8
   Bei M, 2010, NUCL INSTRUM METH A, V622, P518, DOI 10.1016/j.nima.2010.01.045
   Bilderback DH, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/3/035011
   BILLARDON M, 1983, PHYS REV LETT, V51, P1652, DOI 10.1103/PhysRevLett.51.1652
   Borland M, 2006, NUCL INSTRUM METH A, V557, P230, DOI 10.1016/j.nima.2005.10.076
   Borland M., 2016, P NAPAC16 CHIC US, P877, DOI [10.18429/JACoW-NAPAC2016-WEPOB01, DOI 10.18429/JACOW-NAPAC2016-WEPOB01]
   Borland M., 2009, P 23 PART ACC C VANC, P3850
   Borland M, 2014, J SYNCHROTRON RADIAT, V21, P912, DOI 10.1107/S1600577514015203
   Braun H, 2000, PHYS REV LETT, V84, P658, DOI 10.1103/PhysRevLett.84.658
   Cai YH, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.054002
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Carmignani N., 2015, THESIS
   Chao A W, 2012, SLACPUB9574
   DEACON DAG, 1977, PHYS REV LETT, V38, P892, DOI 10.1103/PhysRevLett.38.892
   Deng HX, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.084801
   Di Mitri S, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/11/113006
   Di Mitri S, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.014801
   Di Mitri S, 2019, J SYNCHROTRON RADIAT, V26, P1523, DOI 10.1107/S1600577519009901
   Dohlus M, 1997, NUCL INSTRUM METH A, V393, P494, DOI 10.1016/S0168-9002(97)00552-4
   Edelen A.L., 2015, P IPAC 2015 MAY 3 8, P1217
   Einfeld D, 1996, PROCEEDINGS OF THE 1995 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P177
   Eriksson M, 2014, J SYNCHROTRON RADIAT, V21, P837, DOI 10.1107/S1600577514019286
   Evain C, 2012, NEW J PHYS, V14, DOI 10.1088/1367-2630/14/2/023003
   Farvacque L., 2013, P IPAC SHANGH CHIN, P79, DOI DOI 10.1080/08940886.2014.970931
   Feng C, 2018, NUCL SCI TECH, V29, DOI 10.1007/s41365-018-0490-1
   Feng C, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04962-5
   Feng C, 2014, NEW J PHYS, V16, DOI 10.1088/1367-2630/16/4/043021
   Gao WW, 2017, CHINESE PHYS C, V41, DOI 10.1088/1674-1137/41/7/078101
   Gao WW, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.094001
   GIRARD B, 1984, PHYS REV LETT, V53, P2405, DOI 10.1103/PhysRevLett.53.2405
   Guo J., 2002, P 8 EUR PART ACC C P, P1136
   Hajima R, 2004, NUCL INSTRUM METH A, V528, P335, DOI 10.1016/j.nima.2004.04.063
   Harada K, 2007, PHYS REV SPEC TOP-AC, V10, DOI 10.1103/PhysRevSTAB.10.123501
   Heifets S, 2002, PHYS REV SPEC TOP-AC, V5, DOI 10.1103/PhysRevSTAB.5.064401
   Hettel R, 2014, J SYNCHROTRON RADIAT, V21, P843, DOI 10.1107/S1600577514011515
   Huang X B., 2017, P 8 INT PART ACC C C, P2836
   Huang XB, 2014, NUCL INSTRUM METH A, V757, P48, DOI 10.1016/j.nima.2014.04.078
   Huang ZR, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.204801
   Jiang BC, 2016, NUCL INSTRUM METH A, V814, P1, DOI 10.1016/j.nima.2016.01.024
   Jiang SC, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.110701
   JIAO L, 2015, HIGH POWER LASER PAR, V27
   Jiao Y, 2018, J SYNCHROTRON RADIAT, V25, P1611, DOI 10.1107/S1600577518012110
   Jiao Y, 2017, CHINESE PHYS C, V41, DOI 10.1088/1674-1137/41/2/027001
   Jiao Y, 2015, CHINESE PHYS C, V39, DOI 10.1088/1674-1137/39/6/067004
   Jiao Y, 2014, PHYS REV SPEC TOP-AC, V17, DOI 10.1103/PhysRevSTAB.17.060701
   Jiao Y, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.054002
   Kim K J, 2017, P 38 INT FREE EL LAS
   KIM KJ, 1985, NUCL INSTRUM METH A, V239, P54, DOI 10.1016/0168-9002(85)90698-9
   Kim KJ, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.244802
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Li W, 2019, P 10 INT PART ACC C, P1501
   Li YJ, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.054601
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Liu L, 2014, J SYNCHROTRON RADIAT, V21, P904, DOI 10.1107/S1600577514011928
   Liu WH, 2018, NUCL SCI TECH, V29, DOI 10.1007/s41365-018-0476-z
   MURPHY JB, 1985, J OPT SOC AM B, V2, P259, DOI 10.1364/JOSAB.2.000259
   Nagaoka R, 2017, NUCL INSTRUM METH A, V575, P292
   Nagaoka R, 2014, J SYNCHROTRON RADIAT, V21, P937, DOI 10.1107/S1600577514015215
   NAKAZATO T, 1989, PHYS REV LETT, V63, P2433, DOI 10.1103/PhysRevLett.63.2433.3
   Pang X, 2014, NUCL INSTRUM METH A, V741, P124, DOI 10.1016/j.nima.2013.12.042
   Papapphilippou Y, 2015, P PART ACC C KON TN, P2086
   Pellegrini C, 2016, REV MOD PHYS, V88, DOI 10.1103/RevModPhys.88.015006
   Pellegrini C, 2012, EUR PHYS J H, V37, P659, DOI 10.1140/epjh/e2012-20064-5
   Piwinski A, 1999, PHYSICS9903034 ARXIV
   Piwinski A, 1988, FRONTIERS PARTICLE B
   Riemann B, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.021601
   Sagan D, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.040703
   Saldin EL, 1997, NUCL INSTRUM METH A, V398, P373, DOI 10.1016/S0168-9002(97)00822-X
   Sands M, C P 1970, P257
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Seeman J T, 1992, C 9204126 9
   Shaftan T, 2019, BNL2112112019TECH
   Streun A, 2015, NUCL INSTRUM METH A, V770, P98, DOI 10.1016/j.nima.2014.10.002
   Streun A, 2014, NUCL INSTRUM METH A, V737, P148, DOI 10.1016/j.nima.2013.11.064
   Streun A., 2015, P IPAC15 RICHM US, P1724
   Stupakov G, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.074801
   Sun C., 2017, PROC 8 INT PARTICLE, P2827, DOI [10.18429/JACoW-IPAC2017-WEPAB105, DOI 10.18429/JACOW-IPAC2017-WEPAB105]
   Takaki H, 2010, PHYS REV SPEC TOP-AC, V13, DOI 10.1103/PhysRevSTAB.13.020705
   Tavares PF, 2014, J SYNCHROTRON RADIAT, V21, P862, DOI 10.1107/S1600577514011503
   Teng L, 1984, FERMILABTM1269
   Vivoli A, 2019, P 10 INT PART ACC C, P3106
   Wan JY, 2019, NUCL INSTRUM METH A, V946, DOI 10.1016/j.nima.2019.162683
   Wang CX, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.061001
   Wang G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.110703
   Wang G, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.100703
   Wang XF, 2019, J SYNCHROTRON RADIAT, V26, P677, DOI 10.1107/S1600577519002674
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
   Xiang D, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.030702
   Xu D, 2016, 2016 INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA 2016), P320, DOI 10.1109/ICSGEA.2016.87
   Yakimenko V, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.164802
   Yang LY, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.054001
   Yang LY, 2009, NUCL INSTRUM METH A, V609, P50, DOI 10.1016/j.nima.2009.08.027
   YU LH, 1991, PHYS REV A, V44, P5178, DOI 10.1103/PhysRevA.44.5178
   Yunhai Cai, 2013, Synchrotron Radiation News, V26, P39, DOI 10.1080/08940886.2013.791216
   Zhao ZT, 2010, REV ACCEL SCI TECH, V3, P57, DOI 10.1142/S1793626810000361
   Zholents AA, 1996, PHYS REV LETT, V76, P912, DOI 10.1103/PhysRevLett.76.912
NR 100
TC 2
Z9 8
U1 2
U2 10
PY 2020
VL 65
IS 24
BP 2587
EP 2600
DI 10.1360/TB-2020-0165
UT WOS:000565891900008
DA 2023-11-16
ER

PT J
AU Osman, AFI
   Maalej, NM
   Jayesh, K
AF Osman, Alexander F. I.
   Maalej, Nabil M.
   Jayesh, Kunnanchath
TI Prediction of the individual multileaf collimator positional deviations
   during dynamic IMRT delivery <i>priori</i> with artificial neural
   network
SO MEDICAL PHYSICS
DT Article
DE artificial neural network; log files; MLC positional deviations;
   radiation therapy; virtual IMRT plan QA
ID QUALITY-ASSURANCE; MLC PERFORMANCE; LEARNING APPROACH; LOG FILES;
   ACCURACY; VERIFICATION; QA; ERRORS; COMMUNICATION; REQUIREMENTS
AB Purposes Multileaf collimator (MLC) positional accuracy during dynamic intensity modulation radiotherapy (IMRT) delivery is crucial for safe and accurate patient treatment. The deviations of individual leaf positions from its intended positions can lead to errors in the dose delivered to the patient and hence may adversely affect the treatment outcome. In this study, we propose a state-of-the-art machine learning (ML) method based on an artificial neural network (ANN) for accurately predicting the MLC leaf positional deviations during the dynamic IMRT treatment delivery priori using log file data. Methods Data of ten patients treated with sliding window dynamic IMRT delivery were retrospectively retrieved from a single-institution database. The patients' plans were redelivered with no patient on the couch using a Varian linear accelerator equipped with a Millennium 120 HD MLC system. Then the machine recorded log files data, a total of over 400 files containing 360 800 control points, were collected. A total of 14 parameters were extracted from the planning data in the log files such as leaf planned positions, dose fraction, leaf velocity, leaf moving status, leaf gap, and others. Next, we developed a feed-forward ANN architecture mapping the input parameters with the output to predict the MLC leaf positional deviations during the delivery priori. The proposed model was trained on 70% of the total data using the delivered leaf positional data as a target response. The trained model was then validated and tested on 30% of the available data. The model accuracy was evaluated using the mean squared error (MSE), regression plot, and error histogram. Results The deviations between the individual MLC planned and delivered positions can reach up to a few millimeters, with a maximum deviation of 1.2 mm. The predicted leaf positions at control points closely matched the delivered positions for all MLC leaves during the treatment delivery. The ANN model achieved a maximum MSE of 0.0001 mm(2) (root MSE of 0.0097 mm) in predicting the leaf positions at control points of test data for each leaf. The correlation coefficient, that measures the goodness of fit, was perfect (R = 0.999) in all plots indicating an excellent agreement between the predicted and delivered MLC positions for the training, validation, and test data. Conclusions We successfully demonstrated a proposed ANN-based method capable of accurately predicting the individual MLC leaf positional deviations during the dynamic IMRT delivery priori. Our ML model based on ANN outperformed the reported accuracy in the literature of various ML models. The results of this study could be extended to actual application in the dose calculation/optimization, hence enhancing the gamma passing rate for patient-specific IMRT quality assurance.
C1 [Osman, Alexander F. I.] Amer Univ, Beirut Med Ctr, Dept Radiat Oncol, Beirut 11072020, Lebanon.
   [Osman, Alexander F. I.] Al Neelain Univ, Dept Med Phys, Khartoum 11121, Sudan.
   [Maalej, Nabil M.] King Fahd Univ Petr & Minerals, Dept Phys, Dhahran 31261, Saudi Arabia.
   [Jayesh, Kunnanchath] Amer Hosp Dubai, Dept Radiat Oncol, Dubai, U Arab Emirates.
RP Osman, AFI (corresponding author), Amer Univ, Beirut Med Ctr, Dept Radiat Oncol, Beirut 11072020, Lebanon.; Osman, AFI (corresponding author), Al Neelain Univ, Dept Med Phys, Khartoum 11121, Sudan.
EM alexanderfadul@yahoo.com
CR Agnew A, 2014, PHYS MED BIOL, V59, pN49, DOI 10.1088/0031-9155/59/9/N49
   Alber M, 2008, GUIDELINES VERIFICAT, V9, P89
   [Anonymous], 2015, 10001369808 VAR MED
   Bayouth JE, 2008, INT J RADIAT ONCOL, V71, pS93, DOI 10.1016/j.ijrobp.2007.07.2394
   Boyer AL, 2001, INT J RADIAT ONCOL, V51, P880, DOI 10.1016/S0360-3016(01)01749-7
   Budgell GJ, 2000, PHYS MED BIOL, V45, P1211, DOI 10.1088/0031-9155/45/5/310
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Chang J, 2004, MED PHYS, V31, P2091, DOI 10.1118/1.1760187
   Chen F, 2011, MED PHYS, V38, P6106, DOI 10.1118/1.3651698
   Du WL, 2014, MED PHYS, V41, DOI 10.1118/1.4861821
   El Naqa I, 2018, MED PHYS, V45, pE834, DOI 10.1002/mp.12811
   Galvin J. M., 1999, P AAPM ANN M NASHV T
   Granville DA, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab142e
   Hoppensteadt FC, 1997, WEAKLY CONNECTED NEU
   Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890
   Ju S, 2014, MED PHYS, V41, P267, DOI 10.1118/1.4888525
   Kabat CN, 2019, MED PHYS, V46, P1397, DOI 10.1002/mp.13374
   Kerns JR, 2014, RADIAT ONCOL, V9, DOI 10.1186/1748-717X-9-176
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Levenberg Kenneth, 1944, Q APPL MATH, V2, P3, DOI 10.1090/QAM/10666
   Li JG, 2003, MED PHYS, V30, P799, DOI 10.1118/1.1567951
   Li JQ, 2019, INT J RADIAT ONCOL, V105, P893, DOI 10.1016/j.ijrobp.2019.07.049
   Litzenberg DW, 2002, MED PHYS, V29, P810, DOI 10.1118/1.1470499
   Liu C, 2008, INT J RADIAT ONCOL, V71, pS89, DOI 10.1016/j.ijrobp.2007.07.2392
   LoSasso T, 2001, MED PHYS, V28, P2209, DOI 10.1118/1.1410123
   Losasso T., 2003, INTENSITY MODULATED, P561
   Losasso T, 2008, INT J RADIAT ONCOL, V71, pS85, DOI 10.1016/j.ijrobp.2007.06.082
   Luo W, 2006, MED PHYS, V33, P2557, DOI 10.1118/1.2208916
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Nithiyanantham K, 2015, J APPL CLIN MED PHYS, V16, P296, DOI 10.1120/jacmp.v16i5.5515
   Nyflot MJ, 2019, MED PHYS, V46, P456, DOI 10.1002/mp.13338
   Olasolo-Alonso J, 2017, PHYS MEDICA, V33, P87, DOI 10.1016/j.ejmp.2016.12.013
   Osman A, 2018, MED PHYS, V45, pE357
   Parent L, 2006, MED PHYS, V33, P3174, DOI 10.1118/1.2335490
   Park JM, 2015, BRIT J RADIOL, V88, DOI 10.1259/bjr.20140698
   Park SY, 2018, RADIAT ONCOL, V13, DOI 10.1186/s13014-018-1193-9
   Popple RA, 2011, MED PHYS, V38, P6039, DOI 10.1118/1.3651628
   Rangel A, 2009, MED PHYS, V36, P3304, DOI 10.1118/1.3134244
   Richart J, 2012, PHYS MEDICA, V28, P262, DOI 10.1016/j.ejmp.2011.06.046
   Rowshanfarzad P, 2014, RADIAT ONCOL, V9, DOI 10.1186/s13014-014-0249-8
   Rowshanfarzad P, 2012, MED PHYS, V39, P6192, DOI 10.1118/1.4752207
   Rowshanfarzad P, 2012, PHYS MED BIOL, V57, pN209, DOI 10.1088/0031-9155/57/12/N209
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Stell AM, 2004, MED PHYS, V31, P1593, DOI 10.1118/1.1751011
   Sumida I, 2012, J RADIAT RES, V53, P798, DOI 10.1093/jrr/rrs038
   Tatsumi D, 2011, PHYS MED BIOL, V56, pN237, DOI 10.1088/0031-9155/56/20/N03
   Tomori S, 2018, MED PHYS, V45, P4055, DOI 10.1002/mp.13112
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Valdes G, 2017, J APPL CLIN MED PHYS, V18, P279, DOI 10.1002/acm2.12161
   Wang XH, 1996, MED PHYS, V23, P317, DOI 10.1118/1.597661
   Webb S, 2003, PHYS MED BIOL, V48, P2051, DOI 10.1088/0031-9155/48/14/301
   Webb S., 2015, MED SCI SER
   Xia P, 2002, MED PHYS, V29, P412, DOI 10.1118/1.1449496
   Zeidan OA, 2004, MED PHYS, V31, P463, DOI 10.1118/1.1644518
   Zhang YH, 2012, RADIAT PHYS CHEM, V81, P1813, DOI 10.1016/j.radphyschem.2012.07.012
   Zygmanski P, 2003, MED PHYS, V30, P2736, DOI 10.1118/1.1598674
NR 57
TC 26
Z9 27
U1 2
U2 16
PD APR
PY 2020
VL 47
IS 4
BP 1421
EP 1430
DI 10.1002/mp.14014
EA JAN 2020
UT WOS:000510172200001
DA 2023-11-16
ER

PT C
AU Kanellopoulos, K
   Vijaykumar, N
   Giannoula, C
   Azizi, R
   Koppula, S
   Ghiasi, NM
   Shahroodi, T
   Luna, JG
   Mutlu, O
AF Kanellopoulos, Konstantinos
   Vijaykumar, Nandita
   Giannoula, Christina
   Azizi, Roknoddin
   Koppula, Skanda
   Ghiasi, Nika Mansouri
   Shahroodi, Taha
   Luna, Juan Gomez
   Mutlu, Onur
GP Assoc Comp Machinery
TI SMASH: Co-designing Software Compression and Hardware-Accelerated
   Indexing for Efficient Sparse Matrix Operations
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE sparse matrices; compression; hardware-software cooperation;
   accelerators; memory; efficiency; specialized architectures; linear
   algebra; graph processing
AB Important workloads, such as machine learning and graph analytics applications, heavily involve sparse linear algebra operations. These operations use sparse matrix compression as an effective means to avoid storing zeros and performing unnecessary computation on zero elements. However, compression techniques like Compressed Sparse Row (CSR) that are widely used today introduce significant instruction overhead and expensive pointer-chasing operations to discover the positions of the non-zero elements. In this paper, we identify the discovery of the positions (i.e., indexing) of non-zero elements as a key bottleneck in sparse matrix-based workloads, which greatly reduces the benefits of compression.
   We propose SMASH, a hardware-software cooperative mechanism that enables highly-efficient indexing and storage of sparse matrices. The key idea of SMASH is to explicitly enable the hardware to recognize and exploit sparsity in data. To this end, we devise a novel software encoding based on a hierarchy of bitmaps. This encoding can be used to efficiently compress any sparse matrix, regardless of the extent and structure of sparsity. At the same time, the bitmap encoding can be directly interpreted by the hardware. We design a lightweight hardware unit, the Bitmap Management Unit (BMU), that buffers and scans the bitmap hierarchy to perform highly-efficient indexing of sparse matrices. SMASH exposes an expressive and rich ISA to communicate with the BMU, which enables its use in accelerating any sparse matrix computation.
   We demonstrate the benefits of SMASH on four use cases that include sparse matrix kernels and graph analytics applications. Our evaluations show that SMASH provides average performance improvements of 38% for Sparse Matrix Vector Multiplication and 44% for Sparse Matrix Matrix Multiplication, over a state-of-the-art CSR implementation, on a wide variety of matrices with different characteristics. SMASH incurs a very modest hardware area overhead of up to 0.076% of an out-of-order CPU core.
C1 [Kanellopoulos, Konstantinos; Vijaykumar, Nandita; Giannoula, Christina; Azizi, Roknoddin; Koppula, Skanda; Ghiasi, Nika Mansouri; Shahroodi, Taha; Luna, Juan Gomez; Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Vijaykumar, Nandita; Mutlu, Onur] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Giannoula, Christina] Natl Tech Univ Athens, Athens, Greece.
RP Kanellopoulos, K (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Ahn J., 2015, PIM ENABLED INSTRUCT
   Akbudak K., 2017, TPDS
   [Anonymous], 2016, MICRO
   [Anonymous], 2013, HPEC
   [Anonymous], 2018, HPCA
   [Anonymous], 2013, PPOPP
   [Anonymous], 2015, CVPR
   [Anonymous], HPCC
   [Anonymous], 2015, ISCA
   [Anonymous], ASP DAC
   [Anonymous], 1998, WWW
   [Anonymous], 2014, FCCM
   [Anonymous], 2017, ASPLOS
   [Anonymous], 2014, SPATIALLY SPARSE CON
   Belgin M., 2009, ISC
   Besta M., 2017, HPDC
   Besta Maciej, 2017, IPDPS
   BOLZ J, 2003, SIGGRAPH
   Boroumand A., 2018, ASPLOS
   Buluc A., 2012, SISC
   Buluc A., 2009, SPAA
   Buluc A., 2011, IPDPS
   Buluc A., 2008, ICPP
   Cui J., 2016, ISCAS
   Dalton S., 2015, TMS
   Davis T. A., 2011, TOMS
   Dongarra Jack, 1994, SPARSE MATRIX LIB C
   Dziekonski A., 2018, IEEE ACCESS
   Elafrou A., 2018, TOMS
   Elafrou A., 2017, ICPP
   Falgout R. D., 2006, COMPUTING SCI ENG
   Falgout R. D., 2002, ICCS
   Feng S., 2018, HPCA
   FREEMAN LC, 1977, SOCIOMETRY
   Greathouse J. L., 2014, SC
   Gremse F., 2015, SIAM
   Grigoras P., 2015, FCCM
   Gupta Udit, 2019, CORR
   Henon P., 2002, PMAA
   Hong Changwan, 2018, HPDC
   Hsieh Kevin, 2016, ACCELERATING POINTER
   Im E., 2004, IJHPCA
   Im E.-J., 1999, PPSC
   Kestyn J., 2016, SC
   Kjolstad F., 2017, ASE
   Kourtis K., 2008, CF
   Kourtis K., 2011, PPOPP
   Kurd N. A., 2010, ISSCC
   Langr D., 2016, TPDS
   Leskovec J., 2016, TIST
   Li J., 2013, PLDI
   Li S., 2011, CAD
   Lin C. Y., 2013, FPT
   Linden G., 2003, IC
   Liu W., 2015, ICS
   Liu W., 2015, JPDC
   Liu W., 2014, IPDPS
   Liu Xu, 2013, SC
   Matam Kiran, 2012, HIPC
   Mellor-Crummey J.M., 2004, IJHPCA
   Merrill D., 2016, PPOPP
   Merrill D., 2016, SC
   Mukkara A., 2018, MICRO
   Naumov M., 2019, CORR
   Nishtala R., 2007, AAECC
   Nurvitadhi E., 2015, CASES
   Nurvitadhi E., 2016, DAC
   Page L., 1999, TECH REP
   Penn G., 2006, AMILP
   Pinar Ali, 1999, SC
   Ren L., 2012, DAC
   Saad Y., 2003, ITERATIVE METHODS SP
   Sanchez D., 2013, ISCA, P475
   Sengupta S., 2007, GH
   Seshadri  V., 2015, ISCA
   Smith M, 2013, TLS-TIMES LIT SUPPL, P6
   Su B.-Y., 2012, ICS
   Sulatycke P. D., 1998, IPPS
   Toledo S., 1997, IBM J RES DEV
   Tsai P.-A., 2019, ASPLOS
   Tsai P.-A., 2018, MICRO
   Umuroglu Y., 2014, ICCD
   Van Dongen S., 2008, SIMAX
   Vijaykumar N., 2018, ISCA
   Wang Q, 2013, SC
   White J. B., 1997, HIPC
   Willcock J., 2006, ICS
   Williams S., 2007, SC
   Wu T., 2010, ICPP
   Xianyi Z., 2012, ICPADS
   Yan S., 2014, PPOPP
   Yavits Leonid, 2017, CORR
   Zhang M., 2018, HPCA
   Zhao Y., 2018, PPOPP
   Zhou X., 2018, MICRO
   Zhuo Y., 2019, MICRO
NR 96
TC 34
Z9 34
U1 0
U2 10
PY 2019
BP 600
EP 614
DI 10.1145/3352460.3358286
UT WOS:000519057400045
DA 2023-11-16
ER

PT J
AU Zaruba, F
   Schuiki, F
   Hoefler, T
   Benini, L
AF Zaruba, Florian
   Schuiki, Fabian
   Hoefler, Torsten
   Benini, Luca
TI Snitch: A Tiny Pseudo Dual-Issue Processor for Area and Energy Efficient
   Execution of Floating-Point Intensive Workloads
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Computer architecture; Registers; Instruction sets; Kernel; Task
   analysis; Hardware; Semantics; RISC-V; many-core; energy efficiency;
   general purpose
AB Data-parallel applications, such as data analytics, machine learning, and scientific computing, are placing an ever-growing demand on floating-point operations per second on emerging systems. With increasing integration density, the quest for energy efficiency becomes the number one design concern. While dedicated accelerators provide high energy efficiency, they are over-specialized and hard to adjust to algorithmic changes. We propose an architectural concept that tackles the issues of achieving extreme energy efficiency while still maintaining high flexibility as a general-purpose compute engine. The key idea is to pair a tiny 10kGE (kilo gate equivalent) control core, called Snitch, with a double-precision floating-point unit (FPU) to adjust the compute to control ratio. While traditionally minimizing non-floating-point unit (FPU) area and achieving high floating-point utilization has been a trade-off, with Snitch, we achieve them both, by enhancing the ISA with two minimally intrusive extensions: stream semantic registers (SSR) and a floating-point repetition instruction (FREP). SSRs allow the core to implicitly encode load/store instructions as register reads/writes, eliding many explicit memory instructions. The FREP extension decouples the floating-point and integer pipeline by sequencing instructions from a micro-loop buffer. These ISA extensions significantly reduce the pressure on the core and free it up for other tasks, making Snitch and FPU effectively dual-issue at a minimal incremental cost of 3.2 percent. The two low overhead ISA extensions make Snitch more flexible than a contemporary vector processor lane, achieving a $2\times$2x energy-efficiency improvement. We have evaluated the proposed core and ISA extensions on an octa-core cluster in 22 nm technology. We achieve more than $6\times$6x multi-core speed-up and a $3.5\times$3.5x gain in energy efficiency on several parallel microkernels.
C1 [Zaruba, Florian; Schuiki, Fabian; Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab IIS, CH-8092 Zurich, Switzerland.
   [Hoefler, Torsten] Swiss Fed Inst Technol, Scalable Parallel Comp Lab SPCL, CH-8092 Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn DEI, I-40126 Bologna, Italy.
RP Zaruba, F (corresponding author), Swiss Fed Inst Technol, Integrated Syst Lab IIS, CH-8092 Zurich, Switzerland.
EM zarubaf@iis.ee.ethz.ch; fschuiki@iis.ee.ethz.ch; htor@inf.ethz.ch;
   benini@iis.ee.ethz.ch
CR [Anonymous], 2017, NVID TESL V100 GPU A, P1
   [Anonymous], 2010, MCP, DOI DOI 10.2200/S00309ED1V01Y201011CAC012
   [Anonymous], 2004, TEXAS LNSTRUMENTS, V5, P2
   [Anonymous], 2020, RISC V VECT INTR
   Blackman D., 2018, ARXIV180501407
   Cavalcante M, 2020, IEEE T VLSI SYST, V28, P530, DOI 10.1109/TVLSI.2019.2950087
   Celio C., 2017, P 1 WORKSH COMP ARCH
   Charles P, 2020, COMPUTELIBRARY
   Cornea M, 2015, INTEL AVX 512 INSTRU, P1
   Dabbelt D, 2016, THIRD ACM INTERNATIONAL WORKSHOP ON MANY-CORE EMBEDDED SYSTEMS (MES 2016), P10, DOI 10.1145/2934495.2934497
   Ditty M., 2018, HOT CHIPS S HIGH PER
   Feng WC, 2007, COMPUTER, V40, P50, DOI 10.1109/MC.2007.445
   Fuchs A, 2019, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2019.00023
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Goldreich O, 1996, J ACM, V43, P431, DOI 10.1145/233551.233553
   Hennessy J.L., 2011, COMPUTER ARCHITECTUR
   I. Corporation, 2016, INT 64 IA 32 ARCH SO
   Jia Z, 2018, ARXIV180406826
   Kurth A, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218661
   Mach S, 2019, IEEE INT CONF VLSI, P95, DOI 10.1109/VLSI-SoC.2019.8920307
   Nowatzki T, 2016, INT S HIGH PERF COMP, P27, DOI 10.1109/HPCA.2016.7446051
   NVIDIA, 2017, TESL V100 GPU ARCH W TESL V100 GPU ARCH W
   Nvidia C, 2007, CUBLAS LIB PROGRAMMI, V1, P1
   Reddy V. G, 2008, ARM CORPORATION, V4, P1
   RISC-V Vector Task Group, 2020, RISC V VECT EXT
   RUSSELL RM, 1978, COMMUN ACM, V21, P63, DOI 10.1145/359327.359336
   Schuiki F., 2020, IEEE T COMPUT
   Schuiki F, 2019, IEEE T COMPUT, V68, P484, DOI 10.1109/TC.2018.2876312
   Singh T, 2020, ISSCC DIG TECH PAP I, P42, DOI 10.1109/ISSCC19947.2020.9063113
   Stephens N, 2017, IEEE MICRO, V37, P26, DOI 10.1109/MM.2017.35
   Taylor MB, 2018, DES AUT CON, DOI 10.1145/3195970.3199848
   Wolf C., 2019, RISC V FORMAL VERIFI
   Xianyi Z., 2012, OPENBLAS
   Yao Y, 2020, IEEE T COMPUT, V69, P410, DOI 10.1109/TC.2019.2949807
   Yoshida T., 2018, HOT CHIPS S HIGH PER, P1
   Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114
   Zhao J., 2020, P 4 WORKSH COMP ARCH
NR 37
TC 13
Z9 13
U1 0
U2 5
PD NOV 1
PY 2021
VL 70
IS 11
BP 1845
EP 1860
DI 10.1109/TC.2020.3027900
UT WOS:000704824100006
DA 2023-11-16
ER

PT J
AU Pérez, V
   Sommer, L
   Lomüller, V
   Narasimhan, K
   Goli, M
AF Perez, Victor
   Sommer, Lukas
   Lomuller, Victor
   Narasimhan, Kumudha
   Goli, Mehdi
TI User-driven Online Kernel Fusion for SYCL
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE Just-in-time compilers; runtime environments; parallel programming
   languages
AB Heterogeneous programming models are becoming increasingly popular to support the ever-evolving hardware architectures, especially for new and emerging specialized accelerators optimizing specific tasks. While such programs provide performance portability of the existing applications across various heterogeneous architectures to some extent, short-running device kernels can affect an application performance due to overheads of data transfer, synchronization, and kernel launch. While in applications with one or two short-running kernels the overhead can be negligible, it can be noticeable when these short-running kernels dominate the overall number of kernels in an application, as it is the case in graph-based neural network models, where there are several small memory-bound nodes alongside few large compute-bound nodes.
   To reduce the overhead, combining several kernels into a single, more optimized kernel is an active area of research. However, this task can be time-consuming and error-prone given the huge set of potential combinations. This can push programmers to seek a tradeoffbetween (a) task-specific kernels with low overhead but hard to maintain and (b) smaller modular kernels with higher overhead but easier to maintain. While there are DSL-based approaches, such as those provided for machine learning frameworks, which offer the possibility of such a fusion, they are limited to a particular domain and exploit specific knowledge of that domain and, as a consequence, are hard to port elsewhere. This study explores the feasibility of a user-driven kernel fusion through an extension to the SYCL API to address the automation of kernel fusion. The proposed solution requires programmers to define the subgraph regions that are potentially suitable for fusion without any modification to the kernel code or the function signature. We evaluate the performance benefit of our approach on common neural networks and study the performance improvement in detail.
C1 [Perez, Victor; Sommer, Lukas; Lomuller, Victor; Narasimhan, Kumudha; Goli, Mehdi] Codeplay Software Ltd, Level C Argyle House,3 Lady Lawson St, Edinburgh EH3 9DR, Scotland.
RP Pérez, V (corresponding author), Codeplay Software Ltd, Level C Argyle House,3 Lady Lawson St, Edinburgh EH3 9DR, Scotland.
EM victor.perez@codeplay.com; lukas.sommer@codeplay.com;
   victor@codeplay.com; kumudha.narasimhan@codeplay.com;
   mehdi.goli@codeplay.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alpay A., 2020, INT WORKSH OPENCL
   [Anonymous], 2022, ONNX RUNTIME DEV
   [Anonymous], 2014, EIGEN C LINEAR ALGEB
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Burns R, 2019, Arxiv, DOI arXiv:1904.04174
   Burns R, 2019, PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19), DOI 10.1145/3318170.3318183
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Codeplay Software Ltd, 2022, COMPUTECPP COMP
   Codeplay Software Ltd, 2022, SYCL BLAS IMPL BLAS
   Codeplay Software Ltd, 2022, SYCL DNN NEUR NETW A
   Doumoulakis Anastasios, 2017, SYCL C OPENCL INTERO
   Filipovic J, 2015, J SUPERCOMPUT, V71, P3934, DOI 10.1007/s11227-015-1483-z
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Intel, 2022, DPC COMP
   Intel, 2022, ONEDPL ONEAPI DPC LI
   Intel, 2022, INT ONEAPI MATH KERN
   Intel, 2022, ONEAPI DEEP NEUR NET
   Intel Corporation, 2019, OPENVINO TOOLK
   Kessenich John, 2021, SPIR V SPECIFICATION
   Lal Sohan, 2020, INT WORKSHOP OPENCL, DOI [10.1145/3388333.3388669, DOI 10.1145/3388333.3388669]
   Lal Sohan, 2020, 26 INT EUROPEAN C PA
   Lamzed-Short A, 2020, PROCEEDINGS OF SIXTH WORKSHOP ON THE LLVM COMPILER INFRASTRUCTURE IN HPC AND WORKSHOP ON HIERARCHICAL PARALLELISM FOR EXASCALE COMPUTING (LLVM-HPC2020 AND HIPAR 2020), P45, DOI 10.1109/LLVMHPCHiPar51896.2020.00010
   Lawson John W., 2019, CROSS PLATFORM PERFO
   Li A, 2022, INT SYM CODE GENER, P14, DOI 10.1109/CGO53902.2022.9741270
   Mishra A, 2019, INT SYM CODE GENER, P283, DOI [10.1109/CGO.2019.8661188, 10.1109/cgo.2019.8661188]
   Nvidia Corporation, 2022, NVIDIA CUDA PROGR MO
   Open Neural Network Exchange (ONNX), 2022, MODELS
   Qiao B, 2019, INT SYM CODE GENER, P242, DOI [10.5281/zenodo.2240193, 10.1109/CGO.2019.8661176]
   Rotem N, 2019, Arxiv, DOI arXiv:1805.00907
   Rovatsou Maria, 2021, SYCL 2020 SPECIFICAT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Wahib M, 2014, INT CONF HIGH PERFOR, P191, DOI 10.1109/SC.2014.21
   Zheng Z, 2021, Arxiv, DOI arXiv:2009.10924
   Zhu Kai, 2021, ARXIV, DOI [10.48550/ARXIV.2103.05288, DOI 10.48550/ARXIV.2103.05288]
NR 36
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2023
VL 20
IS 2
AR 21
DI 10.1145/3571284
UT WOS:001002590600002
DA 2023-11-16
ER

PT C
AU Pradillo, MA
   Hoimyr, N
   Sanmillan, PL
   Jylhänkangas, MT
AF Pradillo, Maria Alandes
   Hoimyr, Nils
   Sanmillan, Pablo Llopis
   Jylhankangas, Markus Tapani
BE Doglioni, C
   Kim, D
   Stewart, GA
   Silvestris, L
   Jackson, P
   Kamleh, W
TI Migrating Engineering Windows HPC applications to Linux HTCondor and
   Slurm Clusters
SO 24TH INTERNATIONAL CONFERENCE ON COMPUTING IN HIGH ENERGY AND NUCLEAR
   PHYSICS (CHEP 2019)
SE EPJ Web of Conferences
DT Proceedings Paper
CT 24th International Conference on Computing in High Energy and Nuclear
   Physics (CHEP)
CY NOV 04-08, 2019
CL Univ Adelaide, Adelaide, AUSTRALIA
HO Univ Adelaide
AB The CERN IT department has been maintaining different High Performance Computing (HPC) services over the past five years. While the bulk of computing facilities at CERN are running under Linux, a Windows cluster was dedicated for engineering simulations and analysis related to accelerator technology development. The Windows cluster consisted of machines with powerful CPUs, big memory, and a low-latency interconnect. The Linux cluster resources are accessible through HTCondor, and are used for general purpose parallel but single-node type jobs, providing computing power to the CERN experiments and departments for tasks such as physics event reconstruction, data analysis, and simulation. For HPC workloads that require multi-node parallel environments for Message Passing Interface (MPI) based programs, there is another Linux-based HPC service that is comprised of several clusters running under the Slurm batch system, and consist of powerful hardware with low-latency interconnects.
   In 2018, it was decided to consolidate compute intensive jobs in Linux to make a better use of the existing resources. Moreover, this was also in line with CERN IT strategy to reduce its dependencies on Microsoft products. This paper focuses on the migration of Ansys [1], COMSOL [2] and CST [3] users from Windows HPC to Linux clusters. Ansys, COMSOL and CST are three engineering applications used at CERN for different domains, like multiphysics simulations and electromagnetic field problems. Users of these applications are in different departments, with di fferent needs and levels of expertise. In most cases, the users have no prior knowledge of Linux. The paper will present the technical strategy to allow the engineering users to submit their simulations to the appropriate Linux cluster, depending on their simulation requirements. We also describe the technical solution to integrate their Windows workstations in order from them to be able to submit to Linux clusters. Finally, we discuss the challenges and lessons learnt during the migration.
C1 [Pradillo, Maria Alandes; Hoimyr, Nils; Sanmillan, Pablo Llopis; Jylhankangas, Markus Tapani] European Org Nucl Res CERN, Geneva, Switzerland.
RP Jylhänkangas, MT (corresponding author), European Org Nucl Res CERN, Geneva, Switzerland.
EM maria.alandes.pradillo@cern.ch
CR Ansys Inc, ANS
   Bockelman B, 2015, J PHYS CONF SER, V664, DOI 10.1088/1742-6596/664/6/062003
   CERN, LXPLUS SERV
   COMSOL Inc, COMSOL
   Husejko M, 2015, J PHYS CONF SER, V664, DOI 10.1088/1742-6596/664/9/092012
   Jones B, 2015, J PHYS CONF SER, V664, DOI 10.1088/1742-6596/664/2/022026
   Labrador HG, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921404038
   Llopis P, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921407025
   Microsoft, MICR HPC PACK
   Pradillo S.B. Maria Alandes, 2020, EPJ WEB C
   Shiers J, 2007, COMPUT PHYS COMMUN, V177, P219, DOI 10.1016/j.cpc.2007.02.021
   Thain D, 2005, CONCURR COMP-PRACT E, V17, P323, DOI 10.1002/cpe.938
   Walker DW, 1996, SUPERCOMPUTER, V12, P56
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
NR 14
TC 0
Z9 0
U1 1
U2 1
PY 2020
VL 245
AR 09016
DI 10.1051/epjconf/202024509016
UT WOS:000652214300351
DA 2023-11-16
ER

PT C
AU Gerardi, F
   Rademakers-Di Rosa, O
   Rossi, S
AF Gerardi, F
   Rademakers-Di Rosa, O
   Rossi, S
BE Chen, HS
TI Knowledge management and electronic publishing for the CNAO with EDMS
SO PROCEEDINGS OF CHEP 2001
DT Proceedings Paper
CT International Conference on Computing in High Energy and Nuclear Physics
   (CHEP 01)
CY SEP 03-07, 2001
CL BEIJING, PEOPLES R CHINA
DE technology transfer electronic document management quality assurance
   collaborative; tools
AB The Italian Government has recently approved the construction of a National Center for Oncological Hadrontherapy (CNAO). TERA (Foundation for Oncological Hadrontherapy) will lead the high technology projects of the CNAO, whose machine design is a spin-off to the medical world of the collaboration with CERN.
   The CERN EDMS (Engineering Data Management System) was initially launched at CERN to support the LHC project but has since become a general service available for all divisions and recognized experiments. As TERA is closely associated to CERN, TERA decided to profit from EDMS and to use it to support the ambitious Quality Assurance plan for the CNAO project. With this EDMS project TERA transfers know-how that has been developed in the HEP Community to a social sector of major importance that also has high-density information management needs.
   The features available in the CERN EDMS system provide the tools for managing the complete lifecycle of any technical document including a distributed approval process and a controlled distributed collaborative work environment using the World Wide Web.
   The system allows management of structures representing projects and relative documents including drawings within working contexts and with a customizable release procedure.
   TERA is customizing CERN EDMS to document the CNAO project activities, to ensure that the medical accelerator and its auxiliary installations can be properly managed throughout its lifecycle, from design to maintenance and possibly dismantling. The technical performance requirements of EDMS are identical to those for LHC and CERN in general.
   We will describe what we have learned about how to set-up an EDMS project, and how it benefits a challenging initiative like the CNAO Project of the TERA collaboration. The knowledge managed by the system will facilitate later installations of similar centers (planned for Lyon and Stockholm) and will allow the reuse of experience gained in Italy.
C1 Fdn Oncol Hadrontherapy, I-28100 Novara, Italy.
RP Gerardi, F (corresponding author), Fdn Oncol Hadrontherapy, Via Puccini 1, I-28100 Novara, Italy.
CR Amaldi U, 1999, NUCL PHYS A, V654, p375C, DOI 10.1016/S0375-9474(99)00264-X
   *PIMMS ACC COMPL S, 1999, 99010DI CERNPS
   *PIMMS ACC COMPL S, 2000, 2000007DR CERNPS
   Rousseau B., 2000, P CHEP 2000 PAD 7 11
   *TERA FDN, 1998, PROJ CTR TRAIT CANC
NR 5
TC 0
Z9 0
U1 0
U2 3
PY 2001
BP 400
EP 403
UT WOS:000176592500107
DA 2023-11-16
ER

PT J
AU Rodriguez-Conde, I
   Campos, C
   Fdez-Riverola, F
AF Rodriguez-Conde, Ivan
   Campos, Celso
   Fdez-Riverola, Florentino
TI Optimized convolutional neural network architectures for efficient
   on-device vision-based object detection
SO NEURAL COMPUTING & APPLICATIONS
DT Article
DE Convolutional neural networks; Object detection; On-device machine
   learning; Efficient architectures
ID DEEP; CLOUD; ACCELERATOR; SCALE
AB Convolutional neural networks have pushed forward image analysis research and computer vision over the last decade, constituting a state-of-the-art approach in object detection today. The design of increasingly deeper and wider architectures has made it possible to achieve unprecedented levels of detection accuracy, albeit at the cost of both a dramatic computational burden and a large memory footprint. In such a context, cloud systems have become a mainstream technological solution due to their tremendous scalability, providing researchers and practitioners with virtually unlimited resources. However, these resources are typically made available as remote services, requiring communication over the network to be accessed, thus compromising the speed of response, availability, and security of the implemented solution. In view of these limitations, the on-device paradigm has emerged as a recent yet widely explored alternative, pursuing more compact and efficient networks to ultimately enable the execution of the derived models directly on resource-constrained client devices. This study provides an up-to-date review of the more relevant scientific research carried out in this vein, circumscribed to the object detection problem. In particular, the paper contributes to the field with a comprehensive architectural overview of both the existing lightweight object detection frameworks targeted to mobile and embedded devices, and the underlying convolutional neural networks that make up their internal structure. More specifically, it addresses the main structural-level strategies used for conceiving the various components of a detection pipeline (i.e., backbone, neck, and head), as well as the most salient techniques proposed for adapting such structures and the resulting architectures to more austere deployment environments. Finally, the study concludes with a discussion of the specific challenges and next steps to be taken to move toward a more convenient accuracy-speed trade-off.
C1 [Rodriguez-Conde, Ivan] Univ Arkansas, Dept Comp Sci, 2801 South Univ Ave, Little Rock, AR 72204 USA.
   [Campos, Celso] Univ Vigo, Dept Comp Sci, ESEI Escuela Super Ingn Informat, Orense 32004, Spain.
   [Fdez-Riverola, Florentino] Univ Vigo, Dept Comp Sci, CINBIO, ESEI Escuela Super Ingn Informat, Orense 32004, Spain.
   [Fdez-Riverola, Florentino] SERGAS UVIGO, Galicia Sur Hlth Res Inst IIS Galicia Sur, SING Res Grp, Vigo, Spain.
RP Fdez-Riverola, F (corresponding author), Univ Vigo, Dept Comp Sci, CINBIO, ESEI Escuela Super Ingn Informat, Orense 32004, Spain.; Fdez-Riverola, F (corresponding author), SERGAS UVIGO, Galicia Sur Hlth Res Inst IIS Galicia Sur, SING Res Grp, Vigo, Spain.
EM riverola@uvigo.es
CR Andargie FA, 2017, AFRICON, P945, DOI 10.1109/AFRCON.2017.8095609
   [Anonymous], 2016, NIPS 2016 WORKSH EFF
   Azimi SM, 2019, LECT NOTES COMPUT SC, V11130, P88, DOI 10.1007/978-3-030-11012-3_7
   Bhattacharya Sourav, 2016, P 14 ACM C EMBEDDED, P176
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai H, 2019, IEEE INT CONF COMP V, P2509, DOI 10.1109/ICCVW.2019.00307
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carion N., 2020, LECT NOTES COMPUTER, P213
   Chahal K, 2018, SURVEY MODERN OBJECT
   Chen C, 2020, IEEE COMPUT SOC CONF, P2997, DOI 10.1109/CVPRW50498.2020.00358
   Chen D, 2020, IEEE ACCESS, V8, P86564, DOI 10.1109/ACCESS.2020.2992516
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Chinchali S, 2021, AUTON ROBOT, V45, P997, DOI 10.1007/s10514-021-09987-4
   Chiu YC, 2020, 2020 INT C SYSTEM SC, P1, DOI [10.1109/ICSSE50014.2020.9219319, DOI 10.1109/ICSSE50014.2020.9219319]
   Choi H, 2018, IEEE IMAGE PROC, P3743, DOI 10.1109/ICIP.2018.8451100
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Dhar S, 2019, ARXIV PREPRINT ARXIV
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan BQ, 2019, IEEE IMAGE PROC, P3920, DOI [10.1109/ICIP.2019.8803683, 10.1109/icip.2019.8803683]
   Fang W, 2020, IEEE ACCESS, V8, P1935, DOI 10.1109/ACCESS.2019.2961959
   Fedorov I, 2019, SPARSE SPARSE ARCHIT
   Gao HY, 2021, IEEE T PATTERN ANAL, V43, P2570, DOI 10.1109/TPAMI.2020.2975796
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Gholami A, 2018, IEEE COMPUT SOC CONF, P1719, DOI 10.1109/CVPRW.2018.00215
   Girshick R. B., 2014, CORR, P580, DOI DOI 10.1109/CVPR.2014.81
   Gong H, 2019, CHIN AUTOM CONGR, P3240, DOI [10.1109/CAC48633.2019.8996750, 10.1109/cac48633.2019.8996750]
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   GUO S, 2021, P 16 INT JOINT C COM, P25
   Han J, 2021, J REAL-TIME IMAGE PR, V18, P2527, DOI 10.1007/s11554-021-01145-4
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He WP, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163225
   He YH, 2019, IEEE WINT CONF APPL, P1213, DOI 10.1109/WACV.2019.00134
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Howard Andrew G., 2017, MOBILENETS EFFICIENT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Hu LN, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P151, DOI 10.5220/0010234401510158
   Huang G., 2017, 2017 IEEE C COMPUTER, P4700
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Iandola F.N., 2016, SQUEEZENET ALEXNET L
   Ishakian V, 2018, INT CONF CLOUD ENG, P257, DOI 10.1109/IC2E.2018.00052
   Jauro F, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106582
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kaarmukilan S, 2020, 2020 4 INT C COMP ME, P471, DOI DOI 10.1109/ICCMC48092.2020.ICCMC-00088
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang YP, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P615, DOI 10.1145/3037697.3037698
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P516
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kyrkou C, 2020, IET COMPUT VIS, V14, P417, DOI 10.1049/iet-cvi.2019.0897
   Law H, 2020, 31 BRIT MACH VIS C 2
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee YW, 2019, IEEE COMPUT SOC CONF, P752, DOI 10.1109/CVPRW.2019.00103
   Li Y, 2018, 29 BRIT MACH VIS C B
   Li Z., 2017, ARXIV171200960
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Li Zeming, 2017, ARXIV171107264
   Liau HF, 2018, FIRE SSD WIDE FIRE M
   Lin T.-Y., 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.106
   Ling H, 2020, 2019 30 BRIT MACH VI, P1
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Mehta S, 2022, IEEE T PATTERN ANAL, V44, P2416, DOI 10.1109/TPAMI.2020.3041871
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Mishra B, 2020, COMPUT COMMUN, V156, P1, DOI 10.1016/j.comcom.2020.03.012
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oh S, 2020, FRDET BALANCED LIGHT
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qayyum A, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.587139
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qin HT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107281
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Redmon J., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen ZQ, 2020, IEEE T PATTERN ANAL, V42, P398, DOI 10.1109/TPAMI.2019.2922181
   Simons T, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060661
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stamoulis D, 2020, LECT NOTES ARTIF INT, V11907, P481, DOI 10.1007/978-3-030-46147-8_29
   Sultana F., 2020, Intelligent Computing: Image Processing Based Applications. Advances in Intelligent Systems and Computing (AISC 1157), P1, DOI 10.1007/978-981-15-4288-6_1
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tang QK, 2020, INT CONF ACOUST SPEE, P2243, DOI [10.1109/icassp40776.2020.9054101, 10.1109/ICASSP40776.2020.9054101]
   Teerapittayanon S, 2017, INT CON DISTR COMP S, P328, DOI 10.1109/ICDCS.2017.226
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tolstikhin I., 2021, ARXIV210501601, V34, P24261, DOI DOI 10.48550/ARXIV.2105.01601
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Ullah S, 2020, INT CONF BIG DATA, P477, DOI 10.1109/BigComp48618.2020.00-21
   Varghese B, 2018, FUTURE GENER COMP SY, V79, P849, DOI 10.1016/j.future.2017.09.020
   Wai Y.J., 2019, INT J RECONFIGURABLE, V8, P206, DOI DOI 10.11591/IJRES.V8.I3.PP206-214
   Wan Alvin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12962, DOI 10.1109/CVPR42600.2020.01298
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang J., 2018, P ADV NEUR INF PROC, P1967
   Wang J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2407, DOI 10.1145/3219819.3220106
   Wang J, 2019, PROCEEDINGS OF THE 22ND INTERNATIONAL SYMPOSIUM ON RESEARCH IN ATTACKS, INTRUSIONS AND DEFENSES, P1, DOI 10.1109/TCYB.2019.2891265
   Wang W, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8817849
   Wang Y, 2021, INT C PATT RECOG, P4657, DOI 10.1109/ICPR48806.2021.9413066
   Wei J, 2020, IEEE T INTELL TRANSP, V21, P1572, DOI 10.1109/TITS.2019.2910643
   Wong A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P95, DOI 10.1109/CRV.2018.00023
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Wu HM, 2020, IEEE INTERNET THINGS, V7, P8099, DOI 10.1109/JIOT.2020.2996784
   Wu HM, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00168-9
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Wu SQ, 2014, IEEE SIGNAL PROC LET, V21, P687, DOI 10.1109/LSP.2014.2313570
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xie XK, 2020, IEEE IMAGE PROC, P2930, DOI [10.1109/icip40778.2020.9191334, 10.1109/ICIP40778.2020.9191334]
   Xiong Y, 2019, ANTNETS MOBILE CONVO
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yanpeng Sun, 2019, 2019 IEEE International Conferences on Ubiquitous Computing & Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS), P506, DOI 10.1109/IUCC/DSCI/SmartCNS.2019.00110
   Yin X, 2019, PEER PEER NETW APPL, V12, P310, DOI 10.1007/s12083-017-0615-z
   Zhang Chen, 2015, P 2015 ACMSIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang DQ, 2018, PROC CVPR IEEE, P7912, DOI 10.1109/CVPR.2018.00825
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao D, 2019, IEEE INT SOC CONF, P118, DOI 10.1109/SOCC46988.2019.1570561207
   Zhao HP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071861
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou Q, 2021, MOBILE NETW APPL, V26, P77, DOI 10.1007/s11036-020-01723-z
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 142
TC 6
Z9 6
U1 5
U2 26
PD JUL
PY 2022
VL 34
IS 13
SI SI
BP 10469
EP 10501
DI 10.1007/s00521-021-06830-w
EA DEC 2021
UT WOS:000734701200002
DA 2023-11-16
ER

PT J
AU Imani, M
   Rahimi, A
   Mercati, P
   Rosing, TS
AF Imani, Mohsen
   Rahimi, Abbas
   Mercati, Pietro
   Rosing, Tajana Simunic
TI Multi-Stage Tunable Approximate Search in Resistive Associative Memory
SO IEEE TRANSACTIONS ON MULTI-SCALE COMPUTING SYSTEMS
DT Article
DE Associative memory; approximate computing; resistive memory; GPUs;
   ternary content addressable memory (TCAM); non-volatile memory
ID NONVOLATILE TCAM
AB General-purpose graphics processing units (GPGPUs), as programmable accelerators, improve energy efficiency by integrating a large number of relatively small cores. In this paper, we focus on improving energy efficiency of such processing core by integrating an associative memory where function responses are prestored. Associative memories can search and recall function responses for a subset of input values therefore avoiding the actual function execution on the processing core that leads to energy saving. We propose a novel low-energy Resistive Multi-stage Associative Memory (ReMAM) architecture to significantly reduce energy of a search operation by employing selective row activation and in-advance precharging techniques. ReMAM splits the search operations in a ternary content addressable memory (TCAM) to a number of shorter searches in consecutive stages. Then, it selectively activates TCAM rows at each stage based on the hits of previous stages, thus enabling energy savings. The proposed inadvance precharging technique mitigates the delay of the sequential TCAM search and limits the number of precharges to two low-cost steps. ReMAM further implements approximation on the selective TCAM blocks to reduce the search energy that relaxes the function output in a fine-grained granularity with very low impact on accuracy of the results. Its multi-stage search operation makes ReMAM applicable to many applications such as search engines, sorting, image coding, pattern recognition, query processing, and machine learning. In this work, we show an application of proposed ReMAM on AMD Southern Island GPUs. Our experimental evaluation shows that ReMAM reduces on average GPGPU energy consumption by 35 percent in the exact mode, and 58 percent in approximate mode with average relative error lower than 10 percent. These energy savings are 1.8 x and 1.5 x higher than state-of-the-art associative memories used in GPGPUs in exact and approximate modes.
C1 [Imani, Mohsen; Mercati, Pietro; Rosing, Tajana Simunic] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
   [Rahimi, Abbas] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
RP Imani, M (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM moimani@ucsd.edu; abbas@eecs.berkeley.edu; dperoni@ucsd.edu;
   tajana@ucsd.edu
CR [Anonymous], 2012, ASS MEMORY SYSTEM TH
   [Anonymous], 2014, S VLSI CIRCUITS DIG
   [Anonymous], 2016, ARXIV160708086
   [Anonymous], AMD APP SDK V2 5
   [Anonymous], P 35 INT C COMP AID
   [Anonymous], IEEE COMMUN SURV TUT
   [Anonymous], COMP DES R T L US MO
   [Anonymous], 2007, 2007 ACM SIGMOD INT
   Beigi MV, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P415, DOI 10.1145/2989081.2989085
   Beigi MV, 2016, PR IEEE COMP DESIGN, P344, DOI 10.1109/ICCD.2016.7753299
   Chang MF, 2015, ISSCC DIG TECH PAP I, V58, P318, DOI 10.1109/ISSCC.2015.7063054
   Eatherton W, 2004, ACM SIGCOMM COMP COM, V34, P97, DOI 10.1145/997150.997160
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Guo Q., 2013, P 40 ANN INT S COMPU, V41, P189, DOI [10.1145/2508148.2485939, DOI 10.1145/2485922.2485939]
   Hanyu T, 2015, DES AUT TEST EUROPE, P1006
   Hsu CH, 2015, INT S HIGH PERF COMP, P271, DOI 10.1109/HPCA.2015.7056039
   Imani M., 2017, PROC INT S HIGHPERFO, P1
   Imani M, 2018, IEEE T EMERG TOP COM, V6, P305, DOI 10.1109/TETC.2016.2565262
   Imani M, 2019, IEEE T EMERG TOP COM, V7, P271, DOI 10.1109/TETC.2016.2642057
   Imani M, 2016, I SYMPOS LOW POWER E, P162, DOI 10.1145/2934583.2934595
   Imani M, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P208, DOI 10.1145/2989081.2989086
   Imani M, 2016, INT SYM QUAL ELECT, P101, DOI 10.1109/ISQED.2016.7479183
   Imani M, 2016, DES AUT TEST EUROPE, P1327
   Imani M, 2016, DES AUT TEST EUROPE, P373
   Khoshavi N, 2016, INT SYM QUAL ELECT, P6, DOI 10.1109/ISQED.2016.7479148
   Kim Y, 2015, ICCAD-IEEE ACM INT, P690, DOI 10.1109/ICCAD.2015.7372637
   Kvatinsky S, 2015, IEEE T CIRCUITS-II, V62, P786, DOI 10.1109/TCSII.2015.2433536
   Lakshminarayanan K, 2005, ACM SIGCOMM COMP COM, V35, P193, DOI 10.1145/1090191.1080115
   Li J, 2014, IEEE J SOLID-ST CIRC, V49, P896, DOI 10.1109/JSSC.2013.2292055
   Mancini C, 2016, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ANIMAL-COMPUTER INTERACTION, ACI 2016, DOI 10.1145/2995257.2995395
   Manyika James, 2011, BIG DATA NEXT FRONTI
   Matsunaga S., 2012, 2012 IEEE Symposium on VLSI Circuits, P44, DOI 10.1109/VLSIC.2012.6243781
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Paul S, 2009, 2009 9TH IEEE CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P880
   Pinckney Nathaniel, 2013, 2013 Symposium on VLSI Circuits, pC290
   Rahimi A, 2015, DES AUT TEST EUROPE, P1497
   Rahimi A, 2013, IEEE T CIRCUITS-II, V60, P847, DOI 10.1109/TCSII.2013.2281934
   Rajabi S, 2015, SOLID STATE ELECTRON, V106, P27, DOI 10.1016/j.sse.2014.12.019
   Ranger C, 2007, INT S HIGH PERF COMP, P13
   Rouhani BD, 2015, ANN IEEE SYM FIELD P, P187, DOI 10.1109/FCCM.2015.56
   Saremi M, 2016, SOLID STATE IONICS, V290, P1, DOI 10.1016/j.ssi.2016.04.002
   Ubal R, 2012, INT CONFER PARA, P335
   Vijayasarathi DS, 2005, PR IEEE COMP DESIGN, P243, DOI 10.1109/ICCD.2005.95
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Yang JJ, 2008, NAT NANOTECHNOL, V3, P429, DOI 10.1038/nnano.2008.160
   Yang YC, 2012, APPL PHYS LETT, V100, DOI 10.1063/1.4719198
   Yin XZ, 2016, DES AUT TEST EUROPE, P367
   Zhang H, 2014, PLANT BIOTECHNOL J, V12, P797, DOI 10.1111/pbi.12200
NR 48
TC 9
Z9 9
U1 1
U2 3
PD JAN-MAR
PY 2018
VL 4
IS 1
BP 17
EP 29
DI 10.1109/TMSCS.2017.2665462
UT WOS:000428654900003
DA 2023-11-16
ER

PT J
AU Joseph, J
   Singh, A
   Pournami, PN
   Jayaraj, PB
   Puzhakkal, N
AF Joseph, Jiffy
   Singh, Aparajit
   Pournami, P. N.
   Jayaraj, P. B.
   Puzhakkal, Niyas
TI Cone beam computed tomography enhancement using feature-embedded
   variational autoencoder with a perceptual loss function
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
DT Article
DE cone beam computed tomography; fan beam computed tomography;
   image-guided radiation therapy; perceptual loss function; variational
   autoencoder
ID HEAD-AND-NECK; RADIOTHERAPY
AB Image-Guided Radiation Therapy (IGRT) is a cancer treatment method. IGRT usually follows a fragmented treatment track. The weight loss of a patient causes the first treatment plan to be flawed. Medical experts can avert retaking Fan Beam Computed Tomography (FBCT) images before each session of the therapy if the Cone Beam Computed Tomography (CBCT), which is mounted on a Medical Linear Accelerator (LINAC), gives high-quality images. Rather than improvising the CBCT machine, deep-learning techniques can be used to enhance the CBCT images. This paper proposes a Feature-Embedded Variational AutoEncoder (FE-VAE) for CBCT image enhancement. A feature embedding is incorporated using a MultiResUNet-based feature extractor to preserve structural information in the input image. A perceptual loss function, which is the product of Mean Absolute Error (MAE) and inverse Structural Similarity Index Measure (SSIM), is proposed in this work. The model is trained using Head-and-Neck (H&N) CBCT-FBCT pairs of 59 cancer patients. Our proposed architecture successfully generates images much closer to the ground truth FBCT images. The model gives an average peak signal-to-noise ratio of 32.89 dB, mean squared error of 297.36, MAE of 32.37 HU, and SSIM of 0.99. The trained model gave the least deviated SSIM and MAE, implying that the model is well-optimised. The experimentation with different losses proves the prominence of the proposed loss function. The visual quality of the results obtained is also comparable with the ground truth. The results indicate that the model produces enhanced CBCT images. Hence, the proposed FE-VAE is useful in fractionated radiotherapy to minimise the number of scanning sessions for replanning the dosimetry.
C1 [Joseph, Jiffy; Singh, Aparajit; Pournami, P. N.; Jayaraj, P. B.] Natl Inst Technol Calicut, Dept Comp Sci & Engn, Calicut, Kerala, India.
   [Puzhakkal, Niyas] MVR Canc Ctr & Res Inst, Dept Med Phys, Calicut, Kerala, India.
   [Joseph, Jiffy] Natl Inst Technol Calicut, Dept Comp Sci & Engn, Calicut 673601, Kerala, India.
RP Joseph, J (corresponding author), Natl Inst Technol Calicut, Dept Comp Sci & Engn, Calicut 673601, Kerala, India.
EM jiffy_p190037cs@nitc.ac.in
CR Abramoff M. D., 2004, BIOPHOTON INT, V11, P36, DOI DOI 10.1201/9781420005615.AX4
   Bai T, 2021, MED PHYS, V48, P2258, DOI 10.1002/mp.14796
   Chen LY, 2020, MED PHYS, V47, P1115, DOI 10.1002/mp.13978
   Gao L., 2021, RADIAT ONCOL LONDON, V16, P1, DOI 10.1186/s13014-021-01928-w
   Gholizadeh-Ansari M, 2020, J DIGIT IMAGING, V33, P504, DOI 10.1007/s10278-019-00274-4
   Goodfellow Ian J., 2014, GENERATIVE ADVERSARI, P2672, DOI [DOI 10.48550/ARXIV.1406.2661, DOI 10.1145/3422622]
   Gu J, 2021, IEEE T COMPUT IMAG, V7, P73, DOI 10.1109/TCI.2021.3050266
   Han ZF, 2022, IEEE J BIOMED HEALTH, V26, P3251, DOI 10.1109/JBHI.2022.3155788
   Harms J, 2019, MED PHYS, V46, P3998, DOI 10.1002/mp.13656
   Huang ZZ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3128703
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Isola P, 2017, PROC CVPR IEEE, P1125, DOI DOI 10.1109/CVPR.2017.632
   Jun-Yan Zhu, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2242, DOI 10.1109/ICCV.2017.244
   Kawahara D, 2021, J APPL CLIN MED PHYS, V22, P184, DOI 10.1002/acm2.13190
   Kida S, 2020, MED PHYS, V47, P998, DOI 10.1002/mp.13963
   Kida S, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.2548
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Kingma Diederik P, 2013, ARXIV13126114
   Kurz C, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab4d8c
   Kwon T, 2021, IEEE T COMPUT IMAG, V7, P1354, DOI 10.1109/TCI.2021.3129369
   Li M, 2020, IEEE T MED IMAGING, V39, P2289, DOI 10.1109/TMI.2020.2968472
   Li YH, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab2770
   Liang X, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab22f9
   Liu YZ, 2020, MED PHYS, V47, P2472, DOI 10.1002/mp.14121
   Maspero M., 2019, CORR, V14, P24, DOI [10.1016/j.phro.2020.04.002, DOI 10.1016/J.PHRO.2020.04.002]
   Maspero M, 2020, PHYS IMAG RADIAT ONC, V14, P24, DOI 10.1016/j.phro.2020.04.002
   Noble DJ, 2019, RADIOTHER ONCOL, V130, P32, DOI 10.1016/j.radonc.2018.07.009
   Radaideh KM, 2020, J RADIAT RES APPL SC, V13, P301, DOI 10.1080/16878507.2020.1731125
   Szegedy C., 2017, P 31 AAAI C ARTIFICI, V31, DOI 10.1609/aaai.v31i1.11231
   Szegedy C., 2015, 2015 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thummerer A, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab7d54
   Tien HJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80803-2
   Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51
   Wang XT, 2022, J RADIAT RES APPL SC, V15, P275, DOI 10.1016/j.jrras.2022.03.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Yang X, 2020, IEEE J BIOMED HEALTH, V24, P855, DOI 10.1109/JBHI.2019.2922986
   Yi X, 2018, J DIGIT IMAGING, V31, P655, DOI 10.1007/s10278-018-0056-0
   Yuan NM, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba939
   Zhang Y, 2021, MED PHYS, V48, P2816, DOI 10.1002/mp.14624
NR 40
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 33
IS 5
BP 1767
EP 1778
DI 10.1002/ima.22899
EA APR 2023
UT WOS:000976679900001
DA 2023-11-16
ER

PT J
AU Raman, SRS
   Nibhanupudi, SST
   Kulkarni, JP
AF Raman, Siddhartha Raman Sundara
   Nibhanupudi, S. S. Teja
   Kulkarni, Jaydeep P.
TI Enabling In-Memory Computations in Non-Volatile SRAM Designs
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Random access memory; Resistance; Transistors; Performance evaluation;
   Nonvolatile memory; Programming; System-on-chip; Non-volatile SRAM;
   6T-2R-2S; 8T-2R; resistive RAM; phase transition material; compute in
   memory
ID MODEL
AB The rapid growth in development of neural networks has necessitated the requirement of large capacity on-chip SRAM's for Machine Learning accelerators. This has resulted in SRAM's occupying significant portion of the die area. Furthermore, due to increased short channel effects in advanced CMOS technology nodes, the Vt of the transistors are increased to reduce the leakage power effectively. Vt increase results in direct increase in V (MIN) (minimum operating voltage) of the device. The conventional 6T SRAM with the use of RRAM(R) to store the bitcell storage node values and PTM(S) as a selector device (6T-2R-2S) can help in decoupling V (MIN) and Vt requirement with minimum area overhead. Functionalities of 6T-2R-2S bitcell are investigated to present a 2T-2R-2S mode and SRAM-RRAM hybrid mode of operation, further utilized in performing Compute in Memory(CIM). The above functionalities can be presented in a 8T2R bitcell, that makes use of transistor in place of PTM. 2T-2R-2S/2T-2R mode is a fully non-differential mode of operation, leveraging only the NVM portion of the bitcell. Furthermore, SRAM-RRAM hybrid mode is proposed making use of the SRAM read port transistors to perform read operation of the data stored on the RRAM, during standby mode. The architecture study of set-associative cache made of 6T-2R-2S array is also presented. The 2T-2R-2S/2T-2R mode coupled with SRAM-only mode can be efficiently used to perform CIM for dot product and XNOR computation with co-locating the weights and activations stored onto the same bitcell. System level study highlighting energy efficiency and speedup along with the proposed CIM architecture's analysis on CIFAR-10 dataset is presented. Design sensitivity analysis with respect to PTM and RRAM parameters is discussed for both the bitcells.
C1 [Raman, Siddhartha Raman Sundara; Nibhanupudi, S. S. Teja; Kulkarni, Jaydeep P.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Raman, SRS (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM s.siddhartharaman@utexas.edu; jaydeep@austin.utexas.edu
CR Bengio, 2016, ABS160202830 CORR
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3296957.3173177, 10.1145/3173162.3173177]
   Chang J, 2017, ISSCC DIG TECH PAP I, P206, DOI 10.1109/ISSCC.2017.7870333
   Chiu PF, 2010, SYMP VLSI CIRCUITS, P229, DOI 10.1109/VLSIC.2010.5560286
   Clark LT, 2016, MICROELECTRON J, V53, P105, DOI 10.1016/j.mejo.2016.04.006
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Hamzaoglu F, 2000, ISLPED '00: PROCEEDINGS OF THE 2000 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P15, DOI 10.1109/LPE.2000.876750
   Jiang ZZ, 2014, INT CONF SIM SEMI PR, P41, DOI 10.1109/SISPAD.2014.6931558
   Kolar P, 2011, IEEE J SOLID-ST CIRC, V46, P76, DOI 10.1109/JSSC.2010.2084490
   Lee A, 2015, SYMP VLSI CIRCUITS, DOI 10.1109/VLSIC.2015.7231368
   Morifuji E, 2006, IEEE T ELECTRON DEV, V53, P1427, DOI 10.1109/TED.2006.874752
   Nibhanupudi SST, 2021, IEEE T ELECTRON DEV, V68, P2281, DOI 10.1109/TED.2021.3067849
   Nibhanupudi S. S. Teja, 2019, PROC INT S VLSI TECH, P1
   Sheu SS, 2013, IEEE ASIAN SOLID STA, P245, DOI 10.1109/ASSCC.2013.6691028
   Wang W., 2006, IEDM, P1, DOI [10.1109/IEDM.2006.346730, DOI 10.1109/IEDM.2006.346730]
   Wang Y., 2011, IEDM, P32, DOI 10.1109/IEDM.2011.6131655
   Xie SS, 2021, ISSCC DIG TECH PAP I, V64, P248, DOI 10.1109/ISSCC42613.2021.9365932
   Yamamoto S, 2009, IEEE CUST INTEGR CIR, P531, DOI 10.1109/CICC.2009.5280761
NR 18
TC 3
Z9 3
U1 1
U2 6
PD JUN
PY 2022
VL 12
IS 2
BP 557
EP 568
DI 10.1109/JETCAS.2022.3174148
UT WOS:000811585100022
DA 2023-11-16
ER

PT J
AU Bertholet, J
   Knopf, A
   Eiben, B
   McClelland, J
   Grimwood, A
   Harris, E
   Menten, M
   Poulsen, P
   Nguyen, DT
   Keall, P
   Oelfke, U
AF Bertholet, Jenny
   Knopf, Antje
   Eiben, Bjorn
   McClelland, Jamie
   Grimwood, Alexander
   Harris, Emma
   Menten, Martin
   Poulsen, Per
   Doan Trang Nguyen
   Keall, Paul
   Oelfke, Uwe
TI Real-time intrafraction motion monitoring in external beam radiotherapy
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Review
DE motion monitoring; IGRT; MR-guided RT; tumour motion; particle therapy;
   ultrasound imaging; tracking
ID IMAGE-GUIDED RADIOTHERAPY; BODY RADIATION-THERAPY; INSPIRATION
   BREATH-HOLD; TUMOR-TRACKING RADIOTHERAPY; IMPLANTED FIDUCIAL MARKERS;
   TREATMENT-COUCH TRACKING; MODULATED ARC THERAPY; STEREOTACTIC ABLATIVE
   RADIOTHERAPY; LEAF COLLIMATOR TRACKING; GIMBALED LINAC SYSTEM
AB Radiotherapy (RT) aims to deliver a spatially conformal dose of radiation to tumours while maximizing the dose sparing to healthy tissues. However, the internal patient anatomy is constantly moving due to respiratory, cardiac, gastrointestinal and urinary activity. The long term goal of the RT community to 'see what we treat, as we treat' and to act on this information instantaneously has resulted in rapid technological innovation. Specialized treatment machines, such as robotic or gimbal-steered linear accelerators (linac) with in-room imaging suites, have been developed specifically for real-time treatment adaptation. Additional equipment, such as stereoscopic kilovoltage (kV) imaging, ultrasound transducers and electromagnetic transponders, has been developed for intrafraction motion monitoring on conventional linacs. Magnetic resonance imaging (MRI) has been integrated with cobalt treatment units and more recently with linacs. In addition to hardware innovation, software development has played a substantial role in the development of motion monitoring methods based on respiratory motion surrogates and planar kV or Megavoltage (MV) imaging that is available on standard equipped linacs.
   In this paper, we review and compare the different intrafraction motion monitoring methods proposed in the literature and demonstrated in real-time on clinical data as well as their possible future developments. We then discuss general considerations on validation and quality assurance for clinical implementation.
   Besides photon RT, particle therapy is increasingly used to treat moving targets. However, transferring motion monitoring technologies from linacs to particle beam lines presents substantial challenges. Lessons learned from the implementation of real-time intrafraction monitoring for photon RT will be used as a basis to discuss the implementation of these methods for particle RT.
C1 [Bertholet, Jenny; Grimwood, Alexander; Harris, Emma; Menten, Martin; Oelfke, Uwe] Inst Canc Res, Joint Dept Phys, London, England.
   [Bertholet, Jenny; Grimwood, Alexander; Harris, Emma; Menten, Martin; Oelfke, Uwe] Royal Marsden NHS Fdn Trust, London, England.
   [Knopf, Antje] Univ Groningen, Univ Med Ctr Groningen, Dept Radiat Oncol, Groningen, Netherlands.
   [Eiben, Bjorn; McClelland, Jamie] UCL, Dept Med Phys & Biomed Engn, Ctr Med Image Comp, London, England.
   [Poulsen, Per] Aarhus Univ Hosp, Dept Oncol, Aarhus, Denmark.
   [Doan Trang Nguyen; Keall, Paul] Univ Sydney, ACRF Image X Inst, Sydney, NSW, Australia.
   [Doan Trang Nguyen] Univ Technol Sydney, Sch Biomed Engn, Sydney, NSW, Australia.
RP Bertholet, J (corresponding author), Inst Canc Res, Joint Dept Phys, London, England.; Bertholet, J (corresponding author), Royal Marsden NHS Fdn Trust, London, England.
EM jenny.bertholet@icr.ac.uk
CR Acharya S, 2016, INT J RADIAT ONCOL, V94, P394, DOI 10.1016/j.ijrobp.2015.10.015
   Adler JR, 1997, STEREOT FUNCT NEUROS, V69, P124, DOI 10.1159/000099863
   Ahn YC, 2004, YONSEI MED J, V45, P584, DOI 10.3349/ymj.2004.45.4.584
   Akimoto M, 2013, MED PHYS, V40, DOI 10.1118/1.4817236
   Aristophanous M, 2011, MED PHYS, V38, P495, DOI 10.1118/1.3532821
   Aubry JF, 2004, INT J RADIAT ONCOL, V60, P30, DOI 10.1016/j.ijrobp.2004.02.045
   Bainbridge HE, 2017, RADIOTHER ONCOL, V125, P280, DOI 10.1016/j.radonc.2017.09.009
   Ballhausen H, 2015, PHYS MED BIOL, V60, P549, DOI 10.1088/0031-9155/60/2/549
   Balter JM, 2005, INT J RADIAT ONCOL, V61, P933, DOI 10.1016/j.ijrobp.2004.11.009
   Batin E, 2016, PRACT RADIAT ONCOL, V6, pE235, DOI 10.1016/j.prro.2016.02.001
   Bazalova-Carter M, 2015, MED PHYS, V42, P5745, DOI 10.1118/1.4929978
   Becker N, 2010, PHYS MED BIOL, V55, P7439, DOI 10.1088/0031-9155/55/24/004
   Bentzen SM, 2010, INT J RADIAT ONCOL, V76, pS3, DOI 10.1016/j.ijrobp.2009.09.040
   Berbeco R, 2005, MED PHYS, V32, P2124, DOI 10.1118/1.1998506
   Berbeco RI, 2005, PHYS MED BIOL, V50, P4481, DOI 10.1088/0031-9155/50/19/004
   Berbeco RI, 2004, PHYS MED BIOL, V49, P243, DOI 10.1088/0031-9155/49/2/005
   BERNSTEIN MA, 2004, HDB MRI PULSE SEQUEN
   Bert C, 2011, PHYS MED BIOL, V56, pR113, DOI 10.1088/0031-9155/56/16/R01
   Bert C, 2007, MED PHYS, V34, P4768, DOI 10.1118/1.2815934
   Bert C, 2009, INT J RADIAT ONCOL, V73, P1270, DOI 10.1016/j.ijrobp.2008.11.014
   Bertholet J, 2017, PHYS MED BIOL, V62, P1327, DOI 10.1088/1361-6560/aa52f7
   Bertholet J, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaae8b
   Bertholet J, 2016, INT J RADIAT ONCOL, V95, P802, DOI 10.1016/j.ijrobp.2016.01.033
   Betgen A, 2013, RADIOTHER ONCOL, V106, P225, DOI 10.1016/j.radonc.2012.12.016
   Bibault J-E, 2014, RADIAT ONCOL, V7, P1
   Biederer J, 2006, ROFO-FORTSCHR RONTG, V178, P1067, DOI 10.1055/s-2006-927149
   Biederer J, 2003, RADIOLOGY, V226, P250, DOI 10.1148/radiol.2261011275
   Bjerre T, 2013, PHYS MED BIOL, V58, P4943, DOI 10.1088/0031-9155/58/14/4943
   Boda-Heggemann J, 2016, INT J RADIAT ONCOL, V96, pE604, DOI 10.1016/j.ijrobp.2016.06.2144
   Booth JT, 2016, RADIOTHER ONCOL, V121, P19, DOI 10.1016/j.radonc.2016.08.025
   Bourque AE, 2016, MED PHYS, V43, P5161, DOI 10.1118/1.4961403
   Bova FJ, 1997, INT J RADIAT ONCOL, V38, P875, DOI 10.1016/S0360-3016(97)00055-2
   Braide K, 2018, RADIOTHER ONCOL, V128, P336, DOI 10.1016/j.radonc.2018.05.031
   Butler WM, 2013, J APPL CLIN MED PHYS, V14, P198, DOI 10.1120/jacmp.v14i2.4141
   Campbell WG, 2017, RADIOTHER ONCOL, V124, P168, DOI 10.1016/j.radonc.2017.05.013
   Campbell WG, 2017, MED PHYS, V44, P364, DOI 10.1002/mp.12073
   Camps S M, 2018, 31 C NEUR INF PROC S
   Camps SM, 2018, MED PHYS, V45, P3185, DOI 10.1002/mp.12972
   Case RB, 2009, INT J RADIAT ONCOL, V75, P302, DOI 10.1016/j.ijrobp.2009.03.058
   Castellanos E, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.3526
   Cerviño LI, 2011, PHYS MED BIOL, V56, P3773, DOI 10.1088/0031-9155/56/13/003
   Chang JY, 2017, INT J RADIAT ONCOL, V99, P41, DOI 10.1016/j.ijrobp.2017.05.014
   Chen T, 2014, RADIOTHER ONCOL, V112, P365, DOI 10.1016/j.radonc.2014.08.007
   Cheung Y, 2015, MED PHYS, V42, P2585, DOI 10.1118/1.4918581
   Chi Y, 2017, PHYS MED BIOL, V62, P5509, DOI 10.1088/1361-6560/aa6e37
   Cho B, 2012, PHYS MED BIOL, V57, P7395, DOI 10.1088/0031-9155/57/22/7395
   Cho B, 2010, PHYS MED BIOL, V55, P3299, DOI 10.1088/0031-9155/55/12/003
   Cho J, 2017, J RADIAT RES, V58, P710, DOI 10.1093/jrr/rrw131
   Chung H, 2016, MED PHYS, V43, P4643, DOI 10.1118/1.4958678
   Ciocca M, 2016, PHYS MEDICA, V32, P1667, DOI 10.1016/j.ejmp.2016.11.107
   Colvill E, 2014, MED PHYS, V41, DOI 10.1118/1.4892605
   Colvill E, 2016, RADIOTHER ONCOL, V119, P159, DOI 10.1016/j.radonc.2016.03.006
   Datta A, 2018, CLIN ONCOL-UK, V30, P702, DOI 10.1016/j.clon.2018.08.005
   de Koste JRVS, 2015, MED PHYS, V42, P1640, DOI 10.1118/1.4914401
   de Kruijf WJM, 2013, INT J RADIAT ONCOL, V85, P555, DOI 10.1016/j.ijrobp.2012.03.064
   De Los Santos J, 2013, INT J RADIAT ONCOL, V87, P33, DOI 10.1016/j.ijrobp.2013.02.021
   De Luca V, 2018, MED PHYS, V45, P4986, DOI 10.1002/mp.13152
   De Ruysscher D, 2015, CANCERS, V7, P1143, DOI 10.3390/cancers7030829
   Delcoudert L, 2017, PHYS MEDICA, V44, P4
   Depuydt T, 2014, RADIOTHER ONCOL, V112, P343, DOI 10.1016/j.radonc.2014.05.017
   Depuydt T, 2013, RADIOTHER ONCOL, V106, P236, DOI 10.1016/j.radonc.2012.12.015
   Deshmane A, 2012, J MAGN RESON IMAGING, V36, P55, DOI 10.1002/jmri.23639
   Deutschmann H, 2012, INT J RADIAT ONCOL, V83, P1624, DOI 10.1016/j.ijrobp.2011.10.009
   Dhont J, 2017, RADIOTHER ONCOL, V126, P339
   Azcona JD, 2013, INT J RADIAT ONCOL, V86, P762, DOI 10.1016/j.ijrobp.2013.03.007
   Dieterich S, 2011, MED PHYS, V38, P2914, DOI 10.1118/1.3579139
   Dieterich S, 2008, MED PHYS, V35, P5684, DOI 10.1118/1.3020593
   Nguyen DT, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aadf2c
   Eccles C, 2006, INT J RADIAT ONCOL, V64, P751, DOI 10.1016/j.ijrobp.2005.05.066
   Ehrbar S, 2019, MED PHYS, V46, P839, DOI 10.1002/mp.13359
   Ehrbar S, 2017, RADIOTHER ONCOL, V125, P445, DOI 10.1016/j.radonc.2017.08.035
   Ehrbar S, 2017, MED PHYS, V44, P2466, DOI 10.1002/mp.12236
   Ehrbar S, 2016, RADIOTHER ONCOL, V121, P328, DOI 10.1016/j.radonc.2016.10.011
   Engelsman M, 2013, SEMIN RADIAT ONCOL, V23, P88, DOI 10.1016/j.semradonc.2012.11.003
   Fallone BG, 2014, SEMIN RADIAT ONCOL, V24, P200, DOI 10.1016/j.semradonc.2014.02.011
   Fang-Fang Y, 2009, ROLE IN ROOM KV XRAY
   Fargier-Voiron M, 2016, PHYS MEDICA, V32, P499, DOI 10.1016/j.ejmp.2016.01.481
   Fassi A, 2018, J APPL CLIN MED PHYS, V19, P35, DOI 10.1002/acm2.12321
   Fast MF, 2016, MED PHYS, V43, P4628, DOI 10.1118/1.4955440
   Fattori G, 2016, NUCL INSTRUM METH A, V827, P39, DOI 10.1016/j.nima.2016.04.066
   Fattori G, 2017, RADIAT ONCOL, V12, P1
   Feng Y, 2016, J APPL CLIN MED PHYS, V17, P441, DOI 10.1120/jacmp.v17i2.5820
   Fischer-Valuck BW, 2017, ADV RADIAT ONCOL, V2, P485, DOI 10.1016/j.adro.2017.05.006
   Fledelius W, 2014, PHYS MED BIOL, V59, P2787, DOI 10.1088/0031-9155/59/11/2787
   Fledelius W, 2011, ACTA ONCOL, V50, P952, DOI 10.3109/0284186X.2011.581693
   Friedland JL, 2009, TECHNOL CANCER RES T, V8, P387, DOI 10.1177/153303460900800509
   Fuchs H, 2017, MED PHYS, V44, P1149, DOI 10.1002/mp.12105
   Fukada J, 2013, INT J RADIAT ONCOL, V85, P991, DOI 10.1016/j.ijrobp.2012.07.2358
   Gerlach S, 2017, BRIT J RADIOL, V90, DOI 10.1259/bjr.20160926
   Gevaert T, 2012, INT J RADIAT ONCOL, V83, P467, DOI 10.1016/j.ijrobp.2011.05.048
   Ghilezan MJ, 2005, INT J RADIAT ONCOL, V62, P406, DOI 10.1016/j.ijrobp.2003.10.017
   Ginn JS, 2017, PHYS MED BIOL, V62, P4525, DOI 10.1088/1361-6560/aa6e1a
   Glitzner M, 2018, RADIOTHER ONCOL, V127, pS101, DOI 10.1016/S0167-8140(18)30499-7
   Green OL, 2018, MED PHYS, V45, P3728, DOI 10.1002/mp.13002
   Grimwood A, 2018, INT J RADIAT ONCOL, V102, P912, DOI 10.1016/j.ijrobp.2018.04.008
   Grözinger SO, 2008, RADIAT ONCOL, V3, DOI 10.1186/1748-717X-3-34
   Haas OCL, 2014, MED PHYS, V41, DOI 10.1118/1.4860662
   Habermehl D, 2013, J RADIAT RES, V54, P61, DOI 10.1093/jrr/rrt071
   Han B, 2018, RADIAT ONCOL, V13, DOI 10.1186/s13014-018-1097-8
   Hanazawa H, 2017, RADIOTHER ONCOL, V123, P43, DOI 10.1016/j.radonc.2017.02.010
   Hartman J, 2015, PHYS MED BIOL, V60, P5955, DOI 10.1088/0031-9155/60/15/5955
   Hashimoto T, 2005, INT J RADIAT ONCOL, V61, P1559, DOI 10.1016/j.ijrobp.2005.01.006
   Hazelaar C, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aac1a9
   Hazelaar C, 2018, RADIOTHER ONCOL, V129, P234, DOI 10.1016/j.radonc.2018.08.007
   Hazelaar C, 2018, INT J RADIAT ONCOL, V101, P1253, DOI 10.1016/j.ijrobp.2018.04.046
   Hazelaar C, 2018, MED PHYS, V45, P92, DOI 10.1002/mp.12644
   He P, 2014, MED PHYS, V41, P1
   Henke L, 2018, RADIOTHER ONCOL, V126, P519, DOI 10.1016/j.radonc.2017.11.032
   Herschtal A, 2013, PHYS MED BIOL, V58, P319, DOI 10.1088/0031-9155/58/2/319
   Hoisak JDP, 2004, INT J RADIAT ONCOL, V60, P1298, DOI 10.1016/j.ijrobp.2004.07.681
   Hoisak JDP, 2018, SEMIN RADIAT ONCOL, V28, P185, DOI 10.1016/j.semradonc.2018.02.003
   Hoogeman M, 2009, INT J RADIAT ONCOL, V74, P297, DOI 10.1016/j.ijrobp.2008.12.041
   Huang CY, 2015, INT J RADIAT ONCOL, V91, P368, DOI 10.1016/j.ijrobp.2014.09.040
   Hunt MA, 2016, J APPL CLIN MED PHYS, V17, P473, DOI 10.1120/jacmp.v17i2.5836
   International Organization for Standardization, 572511994 ISO
   Ipsen Svenja, 2017, Current Directions in Biomedical Engineering, V3, P75, DOI 10.1515/cdbme-2017-0016
   Ipsen S, 2016, MED PHYS, V43, P5695, DOI 10.1118/1.4962932
   Jaffray DA, 2012, NAT REV CLIN ONCOL, V9, P688, DOI 10.1038/nrclinonc.2012.194
   James J, 2016, MED PHYS, V43, P2794, DOI 10.1118/1.4948669
   Jin JY, 2008, MED DOSIM, V33, P124, DOI 10.1016/j.meddos.2008.02.005
   Jones BL, 2015, RADIOTHER ONCOL, V115, P217, DOI 10.1016/j.radonc.2015.03.029
   Kalman R.E., 1960, J BASIC ENG, V82, P35
   Kamerling CP, 2016, MED PHYS, V43, P3879, DOI 10.1118/1.4958169
   Kamerling CP, 2017, MED PHYS, V44, P5997, DOI 10.1002/mp.12522
   Kamerling CP, 2016, MED PHYS, V43, P6072, DOI 10.1118/1.4965045
   Kamino Y, 2006, INT J RADIAT ONCOL, V66, P271, DOI 10.1016/j.ijrobp.2006.04.044
   Kashani R, 2007, MED PHYS, V34, P199, DOI 10.1118/1.2400612
   Keall PJ, 2006, MED PHYS, V33, P3874, DOI 10.1118/1.2349696
   Keall PJ, 2018, INT J RADIAT ONCOL, V102, P922, DOI 10.1016/j.ijrobp.2018.04.016
   Keall PJ, 2018, RADIOTHER ONCOL, V127, P6, DOI 10.1016/j.radonc.2018.01.001
   Keall PJ, 2016, INT J RADIAT ONCOL, V94, P1015, DOI 10.1016/j.ijrobp.2015.10.009
   Keall PJ, 2015, MED PHYS, V42, P354, DOI 10.1118/1.4904023
   Keall PJ, 2014, SEMIN RADIAT ONCOL, V24, P203, DOI 10.1016/j.semradonc.2014.02.015
   Keall PJ, 2014, MED PHYS, V41, DOI 10.1118/1.4862509
   Kim JH, 2017, PHYS MED BIOL, V62, P5744, DOI 10.1088/1361-6560/aa6ed7
   Kindblom J, 2009, RADIOTHER ONCOL, V90, P307, DOI 10.1016/j.radonc.2008.08.018
   King CR, 2012, INT J RADIAT ONCOL, V82, P877, DOI 10.1016/j.ijrobp.2010.11.054
   Kinoshita R, 2008, INT J RADIAT ONCOL, V70, P931, DOI 10.1016/j.ijrobp.2007.10.003
   Kitamura K, 2003, INT J RADIAT ONCOL, V56, P221, DOI 10.1016/S0360-3016(03)00082-8
   Kitamura K, 2002, RADIOTHER ONCOL, V62, P275, DOI 10.1016/S0167-8140(02)00017-8
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Klimpki G, 2018, Phys Med Biol, V63, P145006, DOI 10.1088/1361-6560/aacd27
   Knopf AC, 2016, PHYS MEDICA, V32, P874, DOI 10.1016/j.ejmp.2016.05.064
   Kontaxis C, 2017, PHYS MED BIOL, V62, P7233, DOI 10.1088/1361-6560/aa82ae
   Kothary N, 2009, J VASC INTERV RADIOL, V20, P235, DOI 10.1016/j.jvir.2008.09.026
   Krieger M, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaad1e
   Kubiak T, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20150275
   Kubo HD, 1996, PHYS MED BIOL, V41, P83, DOI 10.1088/0031-9155/41/1/007
   Kupelian P, 2007, INT J RADIAT ONCOL, V67, P1088, DOI 10.1016/j.ijrobp.2006.10.026
   Lewis JH, 2010, PHYS MED BIOL, V55, P2505, DOI 10.1088/0031-9155/55/9/006
   Li G, 2011, MED PHYS, V38, P3981, DOI 10.1118/1.3596526
   Li ML, 2017, STRAHLENTHER ONKOL, V193, P459, DOI 10.1007/s00066-017-1105-1
   Li RJ, 2012, MED PHYS, V39, P2686, DOI 10.1118/1.4704729
   Li RJ, 2011, MED PHYS, V38, P4205, DOI 10.1118/1.3598435
   Lightstone AW, 2005, MED PHYS, V32, P2380, DOI 10.1118/1.1945347
   Lin WY, 2013, MED PHYS, V40, DOI 10.1118/1.4771931
   Liney GP, 2016, MED PHYS, V43, P5188, DOI 10.1118/1.4961395
   Luo W, 2008, MED PHYS, V35, P5501, DOI 10.1118/1.3002313
   Ma Z., 2018, ATMOS CHEM PHYS DISC, V2018, P1
   Malinowski K, 2007, PROC SPIE, V6510, DOI 10.1117/12.713841
   Malinowski K, 2013, MED PHYS, V40, DOI 10.1118/1.4808119
   Malinowski K, 2012, INT J RADIAT ONCOL, V82, P1665, DOI 10.1016/j.ijrobp.2011.02.048
   Mao W, 2008, MED PHYS, V35, P1942, DOI 10.1118/1.2905225
   Marchant TE, 2012, MED PHYS, V39, P1322, DOI 10.1118/1.3684959
   Martin J, 2014, J PHYS CONF SER, V489, DOI 10.1088/1742-6596/489/1/012034
   Mazur TR, 2016, MED PHYS, V43, P279, DOI 10.1118/1.4938096
   McClelland JR, 2013, MED IMAGE ANAL, V17, P19, DOI 10.1016/j.media.2012.09.005
   McClelland JR, 2017, PHYS MED BIOL, V62, P4273, DOI 10.1088/1361-6560/aa6070
   McNair HA, 2009, RADIOTHER ONCOL, V93, P424, DOI 10.1016/j.radonc.2009.09.012
   Meijers A, 2019, MED PHYS, V46, P1140, DOI 10.1002/mp.13371
   Menten MJ, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aae74d
   Menten MJ, 2012, MED PHYS, V39, P7032, DOI 10.1118/1.4761868
   Meschini G, 2017, PHYS MEDICA, V34, P28, DOI 10.1016/j.ejmp.2017.01.009
   Minohara S, 2000, INT J RADIAT ONCOL, V47, P1097, DOI 10.1016/S0360-3016(00)00524-1
   Mishra P, 2012, PHYS MED BIOL, V57, P3597, DOI 10.1088/0031-9155/57/11/3597
   Molloy JA, 2011, MED PHYS, V38, P857, DOI 10.1118/1.3531674
   Montanaro T, 2018, MED PHYS, V45, P1222, DOI 10.1002/mp.12765
   Mori S, 2016, INT J RADIAT ONCOL, V95, P258, DOI 10.1016/j.ijrobp.2016.01.014
   Mostafaei F, 2018, MED PHYS, V45, P4619, DOI 10.1002/mp.13104
   Moteabbed M, 2014, MED PHYS, V41, DOI 10.1118/1.4897570
   Murphy M J, 2000, Comput Aided Surg, V5, P278, DOI 10.3109/10929080009148895
   Murphy MJ, 2007, MED PHYS, V34, P4041, DOI 10.1118/1.2775667
   Mutic S, 2016, INT J RADIAT ONCOL, V96, pE641, DOI 10.1016/j.ijrobp.2016.06.2234
   Mutic S, 2014, SEMIN RADIAT ONCOL, V24, P196, DOI 10.1016/j.semradonc.2014.02.008
   Nankali S, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aacdda
   Ng JA, 2014, MED PHYS, V41, DOI 10.1118/1.4898119
   Ng JA, 2013, PHYS MED BIOL, V58, P5983, DOI 10.1088/0031-9155/58/17/5983
   Ng JA, 2012, INT J RADIAT ONCOL, V84, pE655, DOI 10.1016/j.ijrobp.2012.07.2367
   Nguyen DT, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aa986f
   Nguyen DT, 2017, RADIOTHER ONCOL, V123, P37, DOI 10.1016/j.radonc.2017.02.013
   Nioutsikou E, 2006, PHYS MED BIOL, V51, P3359, DOI 10.1088/0031-9155/51/14/005
   Oborn BM, 2015, MED PHYS, V42, P2113, DOI 10.1118/1.4916661
   Oborn BM, 2017, MED PHYS, V44, pE77, DOI 10.1002/mp.12371
   Omari EA, 2016, MED PHYS, V43, P5252, DOI 10.1118/1.4960004
   Onishi H, 2007, J THORAC ONCOL, V2, pS94, DOI 10.1097/JTO.0b013e318074de34
   Ozhasoglu C, 2008, MED DOSIM, V33, P117, DOI 10.1016/j.meddos.2008.02.004
   Paganelli C, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaebcf
   Paganelli C, 2017, MED BIOL ENG COMPUT, V55, P2001, DOI 10.1007/s11517-017-1646-6
   Paganelli C, 2015, PHYS MED BIOL, V60, P7165, DOI 10.1088/0031-9155/60/18/7165
   Pan H, 2012, NEUROSURGERY, V71, P844, DOI 10.1227/NEU.0b013e3182647ad5
   Park JC, 2012, MED PHYS, V39, P6431, DOI 10.1118/1.4754658
   Patel R, 2015, MED PHYS, V42, P254, DOI 10.1118/1.4903892
   Pedroni E, 2006, Patent WO, Patent No. [2006/ 094533/ A1, 2006/094533/A1]
   Perrin RL, 2017, PHYS MED BIOL, V62, P2486, DOI 10.1088/1361-6560/62/6/2486
   Pfeiler T, 2018, Z MED PHYS, V28, P121, DOI 10.1016/j.zemedi.2017.07.005
   Poels K, 2015, RADIOTHER ONCOL, V115, P419, DOI 10.1016/j.radonc.2015.05.004
   Poels K, 2014, RADIOTHER ONCOL, V112, P352, DOI 10.1016/j.radonc.2014.09.007
   Poulsen PR, 2008, PHYS MED BIOL, V53, P4331, DOI 10.1088/0031-9155/53/16/008
   Poulsen PR, 2015, ACTA ONCOL, V54, P1445, DOI 10.3109/0284186X.2015.1062134
   Poulsen PR, 2015, MED PHYS, V42, P6549, DOI 10.1118/1.4933248
   Poulsen PR, 2014, RADIOTHER ONCOL, V111, P424, DOI 10.1016/j.radonc.2014.05.007
   Poulsen PR, 2012, MED PHYS, V39, P6237, DOI 10.1118/1.4754297
   Poulsen PR, 2008, INT J RADIAT ONCOL, V72, P1587, DOI 10.1016/j.ijrobp.2008.07.037
   Poulsen PR, 2012, INT J RADIAT ONCOL, V82, P321
   Prall M, 2014, MED PHYS, V41, DOI 10.1118/1.4868459
   Prévost JBG, 2008, EUR RADIOL, V18, P1569, DOI 10.1007/s00330-008-0933-x
   Raaymakers BW, 2008, MED PHYS, V35, DOI 10.1118/1.2962128
   Raaymakers BW, 2009, PHYS MED BIOL, V54, pN229, DOI 10.1088/0031-9155/54/12/N01
   Ravkilde T, 2018, MED PHYS, V45, P3893, DOI 10.1002/mp.13037
   Ravkilde T, 2014, PHYS MED BIOL, V59, P7279, DOI 10.1088/0031-9155/59/23/7279
   Regmi R, 2014, MED PHYS, V41, DOI 10.1118/1.4881335
   Remmert G, 2007, PHYS MED BIOL, V52, pN401, DOI 10.1088/0031-9155/52/18/N02
   Remouchamps VM, 2003, INT J RADIAT ONCOL, V57, P968, DOI 10.1016/S0360-3016(03)00710-7
   Ren L, 2014, MED PHYS, V41, DOI 10.1118/1.4861820
   Riboldi M, 2012, LANCET ONCOL, V13, pE383, DOI 10.1016/S1470-2045(12)70243-7
   Richter A, 2010, INT J RADIAT ONCOL, V78, P618, DOI 10.1016/j.ijrobp.2009.11.028
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rose M, 2014, J THORAC ONCOL, V9, P1579, DOI 10.1097/JTO.0000000000000268
   Rottmann J, 2013, PHYS MED BIOL, V58, P4195, DOI 10.1088/0031-9155/58/12/4195
   Ruan D, 2008, PHYS MED BIOL, V53, P2923, DOI 10.1088/0031-9155/53/11/011
   Rydhög JS, 2017, RADIOTHER ONCOL, V123, P78, DOI 10.1016/j.radonc.2017.02.003
   Safai S, 2012, TRANSL CANCER RES, V1, P196, DOI 10.3978/j.issn.2218-676X.2012.10.08
   Santanam L, 2009, MED PHYS, V36, P3477, DOI 10.1118/1.3158812
   Sawant A, 2010, MED PHYS, V37, P6466, DOI 10.1118/1.3517837
   Schellhammer SM, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaece8
   Schlosser J, 2016, MED PHYS, V43, P5951, DOI 10.1118/1.4964454
   Schlosser J, 2016, IEEE T MED IMAGING, V35, P2292, DOI 10.1109/TMI.2016.2559499
   Schlosser J, 2012, INT J RADIAT ONCOL, V83, P1633, DOI 10.1016/j.ijrobp.2011.10.049
   Schlosser J, 2010, MED PHYS, V37, P6357, DOI 10.1118/1.3515457
   Schmidt ML, 2016, RADIOTHER ONCOL, V121, P52, DOI 10.1016/j.radonc.2016.07.015
   Schmitt D, 2017, STRAHLENTHER ONKOL, V193, P840, DOI 10.1007/s00066-017-1183-0
   Schnarr E, 2018, MED PHYS, V45, P1329, DOI 10.1002/mp.12791
   Seco J, 2015, ACTA ONCOL, V54, P1254, DOI 10.3109/0284186X.2015.1075665
   Segars WP, 2010, MED PHYS, V37, P4902, DOI 10.1118/1.3480985
   Seiler PG, 2000, PHYS MED BIOL, V45, pN103, DOI 10.1088/0031-9155/45/9/402
   Sen HT, 2017, IEEE T BIO-MED ENG, V64, P1608, DOI 10.1109/TBME.2016.2612229
   Seppenwoolde Y, 2011, PHYS MED BIOL, V56, P5445, DOI 10.1088/0031-9155/56/17/001
   Seppenwoolde Y, 2002, INT J RADIAT ONCOL, V53, P822, DOI 10.1016/S0360-3016(02)02803-1
   Seppenwoolde Y, 2007, MED PHYS, V34, P2774, DOI 10.1118/1.2739811
   Serban M, 2008, MED PHYS, V35, P1094, DOI 10.1118/1.2836417
   Shah AP, 2013, INT J RADIAT ONCOL, V86, P477, DOI 10.1016/j.ijrobp.2012.12.030
   Shah AP, 2011, RADIOTHER ONCOL, V99, P37, DOI 10.1016/j.radonc.2011.02.012
   Shchory T, 2009, INT J RADIAT ONCOL, V75, pS587, DOI 10.1016/j.ijrobp.2009.07.1342
   Shieh CC, 2017, PHYS MED BIOL, V62, P3065, DOI 10.1088/1361-6560/aa6393
   Shiinoki T, 2017, PHYS MED BIOL, V62, DOI 10.1088/1361-6560/aa587d
   SHIMIZU S, 2014, PLOS ONE, V9, P3
   Shinohara ET, 2012, INT J RADIAT ONCOL, V83, P566, DOI 10.1016/j.ijrobp.2011.07.025
   Shirato H, 2004, INT J RADIAT ONCOL, V60, P335, DOI 10.1016/j.ijrobp.2004.04.028
   Shirato H, 1999, LANCET, V353, P1331, DOI 10.1016/S0140-6736(99)00700-X
   Shirato H, 2000, INT J RADIAT ONCOL, V48, P1187, DOI 10.1016/S0360-3016(00)00748-3
   Shirato H, 2007, INT J CLIN ONCOL, V12, P8, DOI 10.1007/s10147-006-0633-y
   Shirato H, 2012, CANCER SCI, V103, P1, DOI 10.1111/j.1349-7006.2011.02114.x
   Sihono DSK, 2017, STRAHLENTHER ONKOL, V193, P213, DOI 10.1007/s00066-016-1076-7
   Siochi RA, 2015, J APPL CLIN MED PHYS, V16, P8, DOI 10.1120/jacmp.v16i1.4444
   Skouboe S, 2019, RADIOTHER ONCOL, V133, pS286, DOI 10.1016/S0167-8140(19)30963-6
   Steidl P, 2012, PHYS MED BIOL, V57, P2235, DOI 10.1088/0031-9155/57/8/2235
   Stemkens B, 2016, PHYS MED BIOL, V61, P5335, DOI 10.1088/0031-9155/61/14/5335
   Stevens MTR, 2016, MED PHYS, V43, P2558, DOI 10.1118/1.4947295
   Stroom JC, 2002, RADIOTHER ONCOL, V64, P75, DOI 10.1016/S0167-8140(02)00140-8
   Su L, 2017, J APPL CLIN MED PHYS, V18, P84, DOI 10.1002/acm2.12100
   Su TS, 2017, INT J RADIAT ONCOL, V98, P639, DOI 10.1016/j.ijrobp.2017.02.095
   Su Z, 2011, INT J RADIAT ONCOL, V81, P880, DOI 10.1016/j.ijrobp.2010.07.1978
   Tang XL, 2007, PHYS MED BIOL, V52, P4081, DOI 10.1088/0031-9155/52/14/005
   Tang XL, 2014, PRACT RADIAT ONCOL, V4, pE151, DOI 10.1016/j.prro.2013.05.004
   Tetar S, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.2236
   Thomas D, 2014, INT J RADIAT ONCOL, V89, P191, DOI 10.1016/j.ijrobp.2014.01.016
   Tijssen RHN, 2019, RADIOTHER ONCOL, V132, P114, DOI 10.1016/j.radonc.2018.12.011
   Toftegaard J, 2017, MED PHYS, V44, P798, DOI 10.1002/mp.12104
   Tran EH, 2018, RADIOTHER ONCOL, V127, pS211, DOI 10.1016/S0167-8140(18)30721-7
   Trnková P, 2018, PHYS MEDICA, V54, P121, DOI 10.1016/j.ejmp.2018.10.002
   Tryggestad E, 2013, MED PHYS, V40, DOI 10.1118/1.4818656
   Ueki N, 2014, RADIOTHER ONCOL, V110, P523, DOI 10.1016/j.radonc.2014.01.014
   Umezawa M, 2015, HITACHI REV, V64, P506
   van Herk M, 2004, SEMIN RADIAT ONCOL, V14, P52, DOI 10.1053/j.semradonc.2003.10.003
   Vandemeulebroucke J, 2009, LECT NOTES COMPUT SC, V5762, P365, DOI 10.1007/978-3-642-04271-3_45
   Vanhanen A, 2018, PHYS MEDICA, V56, P10, DOI 10.1016/j.ejmp.2018.11.007
   Vanhanen A, 2016, BIOMED PHYS ENG EXPR, V2, DOI 10.1088/2057-1976/2/3/035021
   Verellen D, 2006, INT J RADIAT ONCOL, V66, pS108, DOI 10.1016/j.ijrobp.2005.11.032
   Vogel L, 2018, RADIOTHER ONCOL, V129, P441, DOI 10.1016/j.radonc.2018.07.007
   von Siebenthal M, 2007, PHYS MED BIOL, V52, P1547, DOI 10.1088/0031-9155/52/6/001
   Wan HL, 2016, PHYS MED BIOL, V61, P2552, DOI 10.1088/0031-9155/61/6/2552
   Wan HL, 2014, PHYS MED BIOL, V59, P1935, DOI 10.1088/0031-9155/59/8/1935
   Willoughby T, 2012, MED PHYS, V39, P1728, DOI 10.1118/1.3681967
   Willoughby TR, 2006, INT J RADIAT ONCOL, V66, P568, DOI 10.1016/j.ijrobp.2006.05.029
   Willoughby TR, 2006, INT J RADIAT ONCOL, V65, P528, DOI 10.1016/j.ijrobp.2006.01.050
   Wölfelschneider J, 2017, MED PHYS, V44, P2066, DOI 10.1002/mp.12243
   Wolf R, 2012, PHYS MED BIOL, V57, pN329, DOI 10.1088/0031-9155/57/17/N329
   Wolthaus JWH, 2008, INT J RADIAT ONCOL, V70, P1229, DOI 10.1016/j.ijrobp.2007.11.042
   Wong JW, 1999, INT J RADIAT ONCOL, V44, P911, DOI 10.1016/S0360-3016(99)00056-5
   Worm ES, 2018, INT J RADIAT ONCOL, V101, P366, DOI 10.1016/j.ijrobp.2018.02.010
   Worm ES, 2016, RADIOTHER ONCOL, V121, P75, DOI 10.1016/j.radonc.2016.07.023
   Worm ES, 2013, INT J RADIAT ONCOL, V86, P190, DOI 10.1016/j.ijrobp.2012.12.017
   Worm ES, 2012, INT J RADIAT ONCOL, V83, pE145, DOI 10.1016/j.ijrobp.2011.12.007
   Xu QY, 2014, INT J RADIAT ONCOL, V90, P94, DOI 10.1016/j.ijrobp.2014.05.007
   Yamada T, 2016, PHYS MEDICA, V32, P932, DOI 10.1016/j.ejmp.2016.06.002
   Yip E, 2018, MED PHYS, V45, P307, DOI 10.1002/mp.12687
   Yun J, 2015, MED PHYS, V42, P2296, DOI 10.1118/1.4916657
   Zagar TM, 2017, INT J RADIAT ONCOL, V97, P903, DOI 10.1016/j.ijrobp.2016.12.017
   Zhang PP, 2018, MED PHYS, V45, P5555, DOI 10.1002/mp.13259
   Zhang PP, 2016, MED PHYS, V43, P2024, DOI 10.1118/1.4944737
   Zhang XY, 2014, PHYS MED BIOL, V59, P4897, DOI 10.1088/0031-9155/59/17/4897
   Zhang Y, 2015, PHYS MED BIOL, V60, P8141, DOI 10.1088/0031-9155/60/20/8141
   Zhang Y, 2014, PHYS MED BIOL, V59, P7793, DOI 10.1088/0031-9155/59/24/7793
   Zhang Y, 2013, PHYS MED BIOL, V58, P8621, DOI 10.1088/0031-9155/58/24/8621
   Zhu MY, 2013, INT J RADIAT ONCOL, V85, P1038, DOI 10.1016/j.ijrobp.2012.08.001
   Zhu X, 2009, PHYS MED BIOL, V54, pN393, DOI 10.1088/0031-9155/54/17/N03
   Zou W, 2013, J APPL CLIN MED PHYS, V14, P72, DOI 10.1120/jacmp.v14i3.4138
NR 317
TC 104
Z9 106
U1 2
U2 29
PD AUG
PY 2019
VL 64
IS 15
AR 15TRO1
DI 10.1088/1361-6560/ab2ba8
UT WOS:000480292500001
DA 2023-11-16
ER

PT J
AU Lu, LQ
   Liang, Y
AF Lu, Liqiang
   Liang, Yun
TI Morphling: A Reconfigurable Architecture for Tensor Computation
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Tensors; Computer architecture; Computational modeling; Algebra;
   Hardware; Sparse matrices; Field programmable gate arrays; Accelerator
   architectures; data flow computing; reconfigurable architectures; sparse
   matrices
ID ALGEBRA; DECOMPOSITIONS; MODEL
AB Tensor algebra plays a major role in various applications, including data analysis, machine learning, and hydrodynamics simulation. Different tensor algebra inherently varies in dimension, size, and computation, leading to different execution preference, including parallelization, data arrangement, and accumulation. Another critical aspect for tensor algebra is the involved tensors can be with varying mixes of dense and sparse representation. Such diversified applications are notoriously difficult to accelerate. Prior ASIC architectures do not meet the needs due to fixed dataflow and prior fine-grained fabrics (e.g., FPGAs) solutions offer limited performance and power improvement due to bit-level reconfigurable structure. In this article, we propose Morphling, a reconfigurable architecture that can flexibly handle both dense and sparse tensor computation. We first generalize a flexible execution model that decomposes tensor operations into three steps, including tensor vectorization, vector computation, and output reduction. The dense and sparse tensor computation share the same execution model, but differ in the vector computation step where the multiplications are conducted. Depending on the number of inputs and outputs that are linked together in the computation step, we define three parallel patterns, including many-to-one, one-to-many, and one-to-one, which correspond to different implementations for dense and sparse computation. Furthermore, to efficiently support sparse tensor, we design a tiled-BCSR format that enables high parallelism and balanced workload. At the architecture level, we propose a reconfigurable design to support the execution model. The hardware units can be reconfigured to support different datapath and enable different types of data reuse. We evaluate Morphling using various tensor operations and compare it with CPU, GPU, FPGA, and state-of-the-art ASIC designs. Overall, Morphling achieves 13.4X, 677.7X, 44.7X energy efficiency over Xilinx ZC706 FPGA, Intel i7-9700K CPU, and NVIDIA TitanX GPU.
C1 [Lu, Liqiang; Liang, Yun] Peking Univ, Ctr Energy Efficient Comp & Applicat, Sch EECS, Beijing 100871, Peoples R China.
RP Liang, Y (corresponding author), Peking Univ, Ctr Energy Efficient Comp & Applicat, Sch EECS, Beijing 100871, Peoples R China.
EM liqianglu@pku.edu.cn; ericlyun@pku.edu.cn
CR Abadi M., 2016, TENSORFLOW LARGE SCA
   Anandkumar A, 2014, J MACH LEARN RES, V15, P2773
   [Anonymous], NELL 2
   [Anonymous], 2009, CASES 09
   Bachrach J, 2012, DES AUT CON, P1212
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Benabderrahmane MW, 2010, LECT NOTES COMPUT SC, V6011, P283, DOI 10.1007/978-3-642-11970-5_16
   Bennett J., 2007, KDD CUP WORKSH CONJ
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Calhoun BH, 2010, P IEEE, V98, P267, DOI 10.1109/JPROC.2009.2037211
   Casper J., 2014, P 2014 ACMSIGDA INT, P151, DOI [10.1145/2554688.2554787, DOI 10.1145/2554688.2554787]
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cronquist DC, 1999, 20TH ANNIVERSARY CONFERENCE ON ADVANCED RESEARCH IN VLSI, PROCEEDINGS, P23, DOI 10.1109/ARVLSI.1999.756035
   CuBLAS, 2019, US
   CuDNN, 2019, US
   CuSPARSE, 2019, US
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   De Sutter B, 2010, HANDBOOK OF SIGNAL PROCESSING SYSTEMS, P449, DOI 10.1007/978-1-4419-6345-1_17
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Dunlavy DM, 2011, SOFTW ENVIRON TOOLS, V22, P85
   Ebeling C., 2002, UWCSE020602
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   FREYD P, 1966, COLLOQ MATH, V14, P89, DOI 10.4064/cm-14-1-89-106
   Govindaraju V, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.51
   Guowei Zhang, 2021, ASPLOS 2021: Proceedings of the 26th International Conference on Architectural Support for Programming Languages and Operating Systems, P687, DOI 10.1145/3445814.3446702
   Gustavson F. G., 1978, ACM Transactions on Mathematical Software, V4, P250, DOI 10.1145/355791.355796
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hartenstein R, 2001, PROCEEDINGS OF THE ASP-DAC 2001: ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE 2001, P564, DOI 10.1109/ASPDAC.2001.913368
   Hartenstein R, 2001, DESIGN, AUTOMATION AND TEST IN EUROPE, CONFERENCE AND EXHIBITION 2001, PROCEEDINGS, P642, DOI 10.1109/DATE.2001.915091
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   I. S. Library, 2019, US
   Jia LC, 2021, DES AUT CON, P865, DOI 10.1109/DAC18074.2021.9586329
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kanellopoulos K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P600, DOI 10.1145/3352460.3358286
   Karunaratne M, 2017, DES AUT CON, DOI 10.1145/3061639.3062262
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Kuon I, 2007, FOUND TRENDS ELECTRO, V2, P135, DOI 10.1561/1000000005
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3173162.3173176, 10.1145/3296957.3173176]
   Liang Y, 2022, IEEE T COMPUT AID D, V41, P597, DOI 10.1109/TCAD.2021.3066563
   Liang Y, 2021, IEEE T COMPUT AID D, V40, P1648, DOI 10.1109/TCAD.2020.3023903
   Liang Y, 2020, IEEE T COMPUT AID D, V39, P857, DOI 10.1109/TCAD.2019.2897701
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lu L., 2021, INT S MICR, P977
   Lu LQ, 2021, CONF PROC INT SYMP C, P720, DOI 10.1109/ISCA52012.2021.00062
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   McAuley Julian, 2013, P 7 ACM C RECOMMENDE, P165
   Mei BF, 2003, LECT NOTES COMPUT SC, V2778, P61
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pedram A, 2012, IEEE T COMPUT, V61, P1724, DOI 10.1109/TC.2012.132
   Poon KKW, 2005, ACM T DES AUTOMAT EL, V10, P279, DOI 10.1145/1059876.1059881
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   PyTorch, 2019, US
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI [DOI 10.1145/2485922.2485925, 10.1145/2485922.2485925]
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Rucker A., 2021, PROC MICRO, P1029
   Smith SC, 2015, PALG STUD URBAN EDUC, P1, DOI 10.1007/978-1-137-48202-0
   Srivastava N, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P766, DOI 10.1109/MICRO50266.2020.00068
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Steeb WH, 1997, MATRIX CALCULUS KRON
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vilim M, 2021, CONF PROC INT SYMP C, P402, DOI 10.1109/ISCA52012.2021.00039
   Vilim M, 2020, ANN I S COM, P309, DOI 10.1109/ISCA45697.2020.00035
   Viswanath B, 2009, 2ND ACM SIGCOMM WORKSHOP ON ONLINE SOCIAL NETWORKS (WOSN 09), P37
   Wei XC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240856
   Wei XC, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317875
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Xiao QC, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218748
   Xiao QC, 2021, CONF PROC INT SYMP C, P1055, DOI 10.1109/ISCA52012.2021.00086
   Xilinx, 2019, US
   Yin SY, 2017, SYMP VLSI CIRCUITS, pC26, DOI 10.23919/VLSIC.2017.8008534
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
   Zhao YW, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P788, DOI 10.1145/3307650.3322226
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 92
TC 1
Z9 1
U1 1
U2 7
PD NOV
PY 2022
VL 41
IS 11
BP 4733
EP 4746
DI 10.1109/TCAD.2021.3135322
UT WOS:000877295000101
DA 2023-11-16
ER

PT J
AU Jain, S
   Lin, LY
   Alioto, M
AF Jain, Saurabh
   Lin, Longyang
   Alioto, Massimo
TI ±CIM SRAM for Signed In-Memory Broad-Purpose Computing From DSP to
   Neural Processing
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Computer architecture; Random access memory; Neural networks; Digital
   signal processing; Task analysis; Common Information Model (computing);
   Time-domain analysis; Digital signal processing (DSP); in-memory
   computing; machine learning; neural network
ID FINFET CMOS; SAR ADC; ACCELERATOR; TOPS/W; MACRO
AB This work introduces the +/- CIM SRAM macro having the unique capability of performing in-memory multiply-and-accumulate computation with signed inputs and signed weights. This uniquely enables the execution of a broad set of workloads, ranging from storage, subsequent signal processing, and pre-conditioning or feature extraction to final convolutional neural network (CNN) computations. The ability to handle arbitrary input/weight sign in any operand within the same array and the same access cycle enables true end-to-end data locality, preserving the inherent benefits of in-memory computing along the entire signal chain. The proposed broad-purpose computing SRAM is based on a commercial 8T dual-port bitcell, and its simplicity allows the enhanced periphery to be pitch-matched with the array, making it amenable for automated design via memory compilers. The +/- CIM pipelined architecture allows concurrent read/write and compute operations, avoiding the traditional memory unavailability in compute mode for improved throughput and easier system integration. A 40-nm test chip demonstrating the +/- CIM architecture with adjustable input/weight precision exhibits an energy efficiency up to 41 TOPS/W, at an area (energy) overhead of 38% (25%) and negligible performance overhead compared to a compiled SRAM baseline. The sub-LSB computation mean-squared error associated with mismatch (0.38 LSB) and temporal noise (0.62 LSB) confirms the inherent robustness of the architecture. When used for neural network tasks (LeNet-5 and VGG), the accuracy drop is kept between 0.3% and 3.4%, compared to a double-precision software implementation. As an example of digital signal processing (DSP) workload, a frequency-domain feature extractor for voice activity detection keeps the accuracy drop lower than 3.8%.
C1 [Jain, Saurabh; Alioto, Massimo] Natl Univ Singapore, Dept Elect & Comp Engn ECE, Singapore 117583, Singapore.
   [Jain, Saurabh] Intel Labs, Processor Architecture Res Lab, Bengaluru 560054, India.
   [Lin, Longyang] Southern Univ Sci & Technol, Sch Microelect, Shenzhen 518055, Peoples R China.
RP Lin, LY (corresponding author), Southern Univ Sci & Technol, Sch Microelect, Shenzhen 518055, Peoples R China.
EM saurabhj@u.nus.edu; linly@sustech.edu.cn; malioto@ieee.org
CR Alioto M., 2017, ENABLING INTERNET TH
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Fujiwara H, 2019, ISSCC DIG TECH PAP I, V62, P390, DOI 10.1109/ISSCC.2019.8662415
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Harpe PJA, 2011, IEEE J SOLID-ST CIRC, V46, P1585, DOI 10.1109/JSSC.2011.2143870
   Jain S., 2020, ADAPTIVE DIGITAL CIR
   Jain S., 2020, IEEE SOLID STATE CIR, V3, P394
   Jain S, 2020, IEEE J SOLID-ST CIRC, V55, P2670, DOI 10.1109/JSSC.2020.3005778
   Jia HY, 2020, IEEE J SOLID-ST CIRC, V55, P2609, DOI 10.1109/JSSC.2020.2987714
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kulkarni JP, 2017, IEEE J SOLID-ST CIRC, V52, P229, DOI 10.1109/JSSC.2016.2607219
   Li ZY, 2018, IEEE J SOLID-ST CIRC, V53, P76, DOI 10.1109/JSSC.2017.2751501
   Lin LY, 2021, IEEE J SOLID-ST CIRC, V56, P1618, DOI 10.1109/JSSC.2020.3038115
   Liu CC, 2010, IEEE J SOLID-ST CIRC, V45, P731, DOI 10.1109/JSSC.2010.2042254
   Moons B, 2018, IEEE CUST INTEGR CIR
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Raychowdhury A., 2012, P CICC SEP, P1
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Sinangil ME, 2021, IEEE J SOLID-ST CIRC, V56, P188, DOI 10.1109/JSSC.2020.3031290
   Su JW, 2021, ISSCC DIG TECH PAP I, V64, P250, DOI 10.1109/ISSCC42613.2021.9365984
   Su YQ, 2020, ISSCC DIG TECH PAP I, P480, DOI 10.1109/ISSCC19947.2020.9062938
   Teo JH, 2020, IEEE T CIRCUITS-I, V67, P1378, DOI 10.1109/TCSI.2019.2960843
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yang MH, 2018, ISSCC DIG TECH PAP I, P346, DOI 10.1109/ISSCC.2018.8310326
   Yang YK, 2015, IEEE C ELEC DEVICES, P213, DOI 10.1109/EDSSC.2015.7285088
   Yu CS, 2020, IEEE CUST INTEGR CIR
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Zhan J, 2016, INT SYMP MICROARCH
NR 35
TC 17
Z9 18
U1 1
U2 14
PD OCT
PY 2021
VL 56
IS 10
BP 2981
EP 2992
DI 10.1109/JSSC.2021.3092759
UT WOS:000698895200014
DA 2023-11-16
ER

PT C
AU Abrash, M
AF Abrash, Michael
GP IEEE
TI Creating the Future: Augmented Reality, the next Human-Machine Interface
SO 2021 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
SE IEEE International Electron Devices Meeting
DT Proceedings Paper
CT IEEE International Electron Devices Meeting (IEDM)
CY DEC 11-16, 2021
CL San Francisco, CA
AB XR, consisting of Virtual Reality (VR) and Augmented Reality (AR) together, will be the next general computing platform, dominating our relationship with the digital world for the next 50 years, much as personal computing has dominated the last 50. XR will be the way people work, play, and connect. VR headsets will create deeply immersive new experiences and will enable the richest Metaverse experiences. Always-available AR glasses will be with us when we're on the go, letting us act with extremely low latency and friction, allowing us to use virtual entities of all sorts to annotate our world, share with others, and communicate, and extending our perceptions, memory, and cognition with an Artificial Intelligence (AI) assistant that truly understands our context and our personal needs. Both will be centered around people rather than technology, allowing us to connect more strongly than ever before, and providing a contextually personalized interface that is far more intuitive and natural than anything that exists today. However, VR and particularly AR are at a very early stage, and need a great deal of innovation and development, across multiple technologies, before they can offer the level of performance that would cause billions of people to make XR a part of their everyday lives. Those technologies include optics, projectors, display systems, graphics, audio, hand tracking, eye tracking, face tracking, body tracking, world mapping and reconstruction, contextual understanding, sensors, interaction, and AI. VR headsets operate within tight power, weight, and thermal budgets, and AR glasses will need to operate within extraordinarily tight budgets; for AR glasses, the constraints include light weight, very low power, and all-day comfort and all-day operation in a socially acceptable form factor,. Breakthroughs are needed in every one of the areas listed above, and in almost every case, innovative, highly customized semiconductor technologies will be needed to achieve those breakthroughs. This will notably require new materials, miniaturization of the key components, and very-large-scale 3D heterogeneous integration of circuits and systems to create new functions. In addition, specialization at the level of architecture and domain-oriented accelerators, especially with respect to Machine Learning (ML), will be essential, and algorithm optimization will need to evolve in new directions. Finally, the challenges of AR can only be solved by true co-design of hardware and software; technology development will need to be driven from end to end, based on delivering important use cases with a full-system approach. This will create unforeseen opportunities and challenges for semiconductor technologies for decades to come.
C1 [Abrash, Michael] Facebook Real Labs Res, Redmond, WA 98052 USA.
RP Abrash, M (corresponding author), Facebook Real Labs Res, Redmond, WA 98052 USA.
CR Adelstein BD., 2003, P HUM FACT ERG SOC 4, V47, P2083, DOI [DOI 10.1177/1541931203047020, DOI 10.1177/154193120304702001, 10.1177/154193120304702001]
   [Anonymous], 2021, FAC CONN KEYN FAC CO
   AR-VR, CREATING FUTURE PERS
   Colburn M., PROC IEEE IEDM 2020
   De Salvo B., 2021, CONNECTING HETEROGEN
   Doretto Morais Gabriel, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: Biosignals, P227
   facebook, REALITYLABS RESPONSI
   Gauchi R, 2019, IEEE INT CONF VLSI, P166, DOI [10.1109/VLSI-SoC.2019.8920373, 10.1109/vlsi-soc.2019.8920373]
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Klein George, 2007, P1
   Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016
   Liu Chiao, PROC IEEE IEDM 2020
   Liu Chiao, PROC IEEE IEDM 2019
   Newcombe R, ICRA2021 WORKSHOP PE
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Park J, 2021, NAT PHOTONICS, V15, P449, DOI 10.1038/s41566-021-00783-1
   Tourbabin V, 2019, IEEE WORK APPL SIG, P383, DOI [10.1109/waspaa.2019.8937233, 10.1109/WASPAA.2019.8937233]
   Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030
NR 19
TC 6
Z9 6
U1 2
U2 17
PY 2021
DI 10.1109/IEDM19574.2021.9720526
UT WOS:000812325400032
DA 2023-11-16
ER

PT J
AU Cho, YB
   Farrokhkish, M
   Norrlinger, B
   Heaton, R
   Jaffray, D
   Islam, M
AF Cho, Young-Bin
   Farrokhkish, Makan
   Norrlinger, Bern
   Heaton, Robert
   Jaffray, David
   Islam, Mohammad
TI An artificial neural network to model response of a radiotherapy beam
   monitoring system
SO MEDICAL PHYSICS
DT Article
DE artificial intelligence in numerical model; artificial neural network;
   integral quality monitoring (IQM) system; machine learning for quality
   assurance; radiation therapy
ID RADIATION; IMRT; THERAPY
AB Purpose The integral quality monitor (IQM) is a real-time radiotherapy beam monitoring system, which consists of a spatially sensitive large-area ion chamber, mounted at the collimator of the linear accelerator (linac), and a calculation algorithm to predict the detector signal for each beam segment. By comparing the measured and predicted signals the system validates the beam delivery. The current commercial version of IQM uses an analytic method to predict the signal, which requires a semi-empirical approach to determine and optimize various calculation parameters. The process of developing the calculation model is complex and time consuming, and moreover, the model cannot be easily generalized across various beam delivery platforms with different combinations of beam energy, beam flattening, beam shaping elements, and Linac models. Therefore, as an alternative solution, we investigated the feasibility of developing a machine learning (ML) method, using an artificial neural network (ANN), to predict the ion chamber signal. In developing an ANN, it is not necessary to explicitly account for each of the elements of beam interactions with various structures in the beam path to the ion chamber.
   Methods The ANN was designed with multilayer perceptron (MLP). The input layer consisted of multiple features, derived from the geometrical characteristics of beam segments. Gradient descent error backpropagation technique was used to train the ANN. The combined training dataset included 270 rectangular fields, and 801 clinical IMRT fields delivered using 6 MV beams on Varian TrueBeam (TM) and Elekta Infinity (TM). Each of 12 different ANN configurations (3 different sets of input features x 4 different sets of number of hidden nodes) was simulated 10 times with randomly selected 80% of data for training and the remaining data for validation.
   Results Artificial neural networks with one hidden layer, consisting of 10 nodes, and 10 input features provided optimum results. Once the feature sets were extracted, the time required for the network training was on the order of a few minutes, and the time required to perform an output calculation per field was only fraction of a second. More than 95% of clinical intensity-modulated radiation therapy (IMRT) segments were calculated within +/- 3.0% modeling error for Varian Truebeam (90% and +/- 3.3% for Elekta Infinity). A total of 3320 volumetric-modulated arc therapy (VMAT) segments from Truebeam were calculated using the ANN trained with IMRT fields. More than 95% of the cumulative VMAT beam segments were within 3.6% modeling error, similar to the performance for IMRT segments. In general the modeling error was found to be inversely proportional to the size and intensity of the beam segment.
   Conclusions A prototype ANN has been developed for predicting the signals of the IQM system, with substantially less efforts compared to the analytic model. The performance of the ANN was found to be at least equivalent to that of the analytic method, in terms of average and maximum error, for 6 MV beams on both Varian TrueBeam and Elekta Infinity platforms.
C1 [Cho, Young-Bin; Farrokhkish, Makan; Norrlinger, Bern; Heaton, Robert; Jaffray, David; Islam, Mohammad] Univ Hlth Network, Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON M5G 2C1, Canada.
   [Cho, Young-Bin; Heaton, Robert; Jaffray, David; Islam, Mohammad] Univ Toronto, Dept Radiat Oncol, Toronto, ON M5T 1P5, Canada.
   [Cho, Young-Bin; Jaffray, David; Islam, Mohammad] Univ Hlth Network, Techna Inst, Toronto, ON M5G 1L5, Canada.
   [Jaffray, David; Islam, Mohammad] Univ Toronto, Inst Biomat & Biomed Engn, Toronto, ON M5S 3G9, Canada.
   [Jaffray, David] Univ Toronto, Dept Med Biophys, Toronto, ON M5G 1L7, Canada.
RP Cho, YB (corresponding author), Univ Hlth Network, Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON M5G 2C1, Canada.; Cho, YB (corresponding author), Univ Toronto, Dept Radiat Oncol, Toronto, ON M5T 1P5, Canada.; Cho, YB (corresponding author), Univ Hlth Network, Techna Inst, Toronto, ON M5G 1L5, Canada.
EM choy2@ccf.org
CR Boyer AL, 1999, SEMIN RADIAT ONCOL, V9, P48, DOI 10.1016/S1053-4296(99)80054-X
   Casar B, 2017, Z MED PHYS, V27, P232, DOI 10.1016/j.zemedi.2016.10.001
   HETCHTNIELSEN R, 1989, IEEE INT C NEUR NETW, V2, P359
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoffman D, 2017, J APPL CLIN MED PHYS, V18, P40, DOI 10.1002/acm2.12014
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Ioffe S., 2015, PR MACH LEARN RES, P448
   Irie B., 1988, IEEE INT C NEURAL NE, V1, P641
   Islam MK, 2009, MED PHYS, V36, P5420, DOI 10.1118/1.3250859
   JAFFRAY DA, 1993, MED PHYS, V20, P1417, DOI 10.1118/1.597106
   Jaffray DA, 2000, MED PHYS, V27, P1311, DOI 10.1118/1.599009
   Kingma DP., 2017, ARXIV
   Marrazzo L, 2018, STRAHLENTHER ONKOL, V194, P243, DOI 10.1007/s00066-017-1245-3
   Otto K, 2008, MED PHYS, V35, P310, DOI 10.1118/1.2818738
   Raaijmakers AJE, 2007, PHYS MED BIOL, V52, P7045, DOI 10.1088/0031-9155/52/23/018
   Saito M, 2018, J APPL CLIN MED PHYS, V19, P87, DOI 10.1002/acm2.12288
   Sharpe MB, 1995, MED PHYS, V22, P2065, DOI 10.1118/1.597648
   Sifaoui A., 2008, INT J SCI, V2, P386
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   WEBB S, 1994, PHYS MED BIOL, V39, P2229, DOI 10.1088/0031-9155/39/12/007
NR 20
TC 3
Z9 4
U1 0
U2 8
PD APR
PY 2020
VL 47
IS 4
BP 1983
EP 1994
DI 10.1002/mp.14033
EA FEB 2020
UT WOS:000510696100001
DA 2023-11-16
ER

PT J
AU Oancea, C
   Solc, J
   Bourgouin, A
   Granja, C
   Jakubek, J
   Pivec, J
   Riemer, F
   Vykydal, Z
   Worm, S
   Marek, L
AF Oancea, Cristina
   Solc, Jaroslav
   Bourgouin, Alexandra
   Granja, Carlos
   Jakubek, Jan
   Pivec, Jiri
   Riemer, Felix
   Vykydal, Zdenek
   Worm, Steven
   Marek, Lukas
TI Thermal neutron detection and track recognition method in reference and
   out-of-field radiotherapy FLASH electron fields using Timepix3 detectors
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE FLASH electron radiotherapy; thermal neutrons; Timepix3 pixel detector;
   6LiF converter; out-of-field dose from neutrons; particle type
   discrimination; equivalent dose
ID X-RAY; DOSIMETRY; PROTON; ACCELERATOR; SPECTRA; WORKING; IMPACT; TOOL
AB Objective. This work presents a method for enhanced detection, imaging, and measurement of the thermal neutron flux. Approach. Measurements were performed in a water tank, while the detector is positioned out-of-field of a 20 MeV ultra-high pulse dose rate electron beam. A semiconductor pixel detector Timepix3 with a silicon sensor partially covered by a (LiF)-Li-6 neutron converter was used to measure the flux, spatial, and time characteristics of the neutron field. To provide absolute measurements of thermal neutron flux, the detection efficiency calibration of the detectors was performed in a reference thermal neutron field. Neutron signals are recognized and discriminated against other particles such as gamma rays and x-rays. This is achieved by the resolving power of the pixel detector using machine learning algorithms and high-resolution pattern recognition analysis of the high-energy tracks created by thermal neutron interactions in the converter. Main results. The resulting thermal neutrons equivalent dose was obtained using conversion factor (2.13(10) pSv center dot cm(2)) from thermal neutron fluence to thermal neutron equivalent dose obtained by Monte Carlo simulations. The calibrated detectors were used to characterize scattered radiation created by electron beams. The results at 12.0 cm depth in the beam axis inside of the water for a delivered dose per pulse of 1.85 Gy (pulse length of 2.4 mu s) at the reference depth, showed a contribution of flux of 4.07(8) x 10(3) particles center dot cm(-2)center dot s(-1) and equivalent dose of 1.73(3) nSv per pulse, which is lower by similar to 9 orders of magnitude than the delivered dose. Significance. The presented methodology for in-water measurements and identification of characteristic thermal neutrons tracks serves for the selective quantification of equivalent dose made by thermal neutrons in out-of-field particle therapy.
C1 [Oancea, Cristina; Granja, Carlos; Jakubek, Jan; Pivec, Jiri; Marek, Lukas] ADVACAM, U Pergamenky 12, Prague 7, Czech Republic.
   [Oancea, Cristina] Univ Bucharest, Bucharest, Romania.
   [Solc, Jaroslav; Vykydal, Zdenek] Czech Metrol Inst, Okruzni 31, Brno 63800, Czech Republic.
   [Bourgouin, Alexandra] Phys Tech Bundesanstalt PTB, Dosimetry Radiat Therapy & Diagnost Radiol, D-38116 Braunschweig, Germany.
   [Riemer, Felix; Worm, Steven] Deutsch Elektronen Synchrotron DESY, Platanenallee 6, D-15738 Zeuthen, Germany.
   [Marek, Lukas] Charles Univ Prague, Fac Math & Phys, Prague, Czech Republic.
RP Oancea, C (corresponding author), ADVACAM, U Pergamenky 12, Prague 7, Czech Republic.; Oancea, C (corresponding author), Univ Bucharest, Bucharest, Romania.
EM cristina.oancea@advacam.cz
CR Abadi M, 2016, Arxiv, DOI [arXiv:1605.08695, DOI 10.48550/ARXIV.1605.08695]
   Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, DOI [10.1007/978-3-319-94463-0, DOI 10.1007/978-3-319-94463-0]
   AGOSTEO S, 1993, MED PHYS, V20, P407, DOI 10.1118/1.597140
   Attix F.H., 2008, INTRO RADIOLOGICAL P
   Beni MS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181281
   Bordy JM, 2013, RADIAT MEAS, V57, P29, DOI 10.1016/j.radmeas.2013.06.010
   Bourgouin A, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac950b
   Bourgouin A, 2022, MED PHYS, V49, P6635, DOI 10.1002/mp.15899
   Bourgouin A, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac5de8
   Bourgouin A, 2020, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.567340
   Campbell M., 2013, ANAL RAD FIELD ATLAS
   Chadwick MB, 2006, NUCL DATA SHEETS, V107, P2931, DOI 10.1016/j.nds.2006.11.001
   Charyyev S, 2022, Arxiv, DOI arXiv:2209.01178
   Conlin J L., 2018, LAUR1824034 LOS AL N
   D'Errico F, 1998, INT J RADIAT ONCOL, V41, P1185, DOI 10.1016/S0360-3016(98)00162-X
   De Saint-Hubert M, 2021, RADIAT MEAS, V149, DOI 10.1016/j.radmeas.2021.106665
   Di Fulvio A, 2013, RADIAT MEAS, V57, P19, DOI 10.1016/j.radmeas.2012.11.022
   Finocchiaro P, 2018, EPJ WEB CONF, V170, DOI 10.1051/epjconf/201817001004
   Gohl S, 2022, J INSTRUM, V17, DOI 10.1088/1748-0221/17/01/C01066
   Granja C, 2023, J INSTRUM, V18, DOI 10.1088/1748-0221/18/01/P01003
   Granja C, 2022, J INSTRUM, V17, DOI 10.1088/1748-0221/17/03/C03019
   Granja C, 2021, NUCL INSTRUM METH A, V988, DOI 10.1016/j.nima.2020.164901
   Granja C, 2018, NUCL INSTRUM METH A, V908, P60, DOI 10.1016/j.nima.2018.08.014
   GUM-2008, 2008, EV MEAS DAT GUID EXP, V134
   Harrison R, 2017, PHYS MEDICA, V42, P239, DOI 10.1016/j.ejmp.2017.02.001
   ICRP, 2009, ICRP PUBL, V38, pp 2
   ICRU, 2020, J ICRU, V20, P13
   Jakubek J., 2009, SPIE P, V7449, DOI [10.1109/NSSMIC.2009.5402420, DOI 10.1109/NSSMIC.2009.5402420]
   Jakubek J, 2011, NUCL INSTRUM METH A, V633, pS262, DOI 10.1016/j.nima.2010.06.183
   Jaradat AK, 2008, MED PHYS, V35, P1711, DOI 10.1118/1.2898144
   Khan FM., 2014, KHANS PHYS RAD THERA
   Knezevic Ä, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.904563
   Koivunoro H, 2011, APPL RADIAT ISOTOPES, V69, P1904, DOI 10.1016/j.apradiso.2011.03.028
   Konefal A, 2020, APPL RADIAT ISOTOPES, V163, DOI 10.1016/j.apradiso.2020.109206
   Konefal A, 2012, REP PRACT ONCOL RADI, V17, P339, DOI 10.1016/j.rpor.2012.06.004
   Králík M, 2015, RADIAT PROT DOSIM, V163, P373, DOI 10.1093/rpd/ncu192
   Kranzer R, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac594e
   Krejci F, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/12/C12026
   Mathew F, 2020, PHYS MEDICA, V80, P125, DOI 10.1016/j.ejmp.2020.10.016
   MEADOWS JW, 1970, NUCL SCI ENG, V40, P12, DOI 10.13182/NSE70-A18875
   Miljanic S, 2014, RADIAT MEAS, V71, P270, DOI 10.1016/j.radmeas.2014.04.026
   Mukherjee B, 2017, RADIAT MEAS, V106, P336, DOI 10.1016/j.radmeas.2017.04.015
   Nair V., 2010, PROC 27 INT C INT C
   NCRP, 1984, 79 NCRP
   Novak A, 2023, J INSTRUM, V18, DOI 10.1088/1748-0221/18/01/C01022
   Oancea C, 2022, J INSTRUM, V17, DOI 10.1088/1748-0221/17/01/C01003
   Oancea C, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aae656
   Oancea C, 2018, RADIAT MEAS, V110, P7, DOI 10.1016/j.radmeas.2018.01.003
   Oancea C, 2023, PHYS MEDICA, V106, DOI 10.1016/j.ejmp.2023.102529
   Peters LJ, 2010, J CLIN ONCOL, V28, P2996, DOI 10.1200/JCO.2009.27.4498
   Petoussi-Henss N, 2010, Ann ICRP, V40, P1, DOI 10.1016/j.icrp.2011.10.001
   Poikela T, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/05/C05013
   Rosenfeld A, 2020, RADIAT MEAS, V130, DOI 10.1016/j.radmeas.2019.106211
   ROY SC, 1987, NUCL INSTRUM METH A, V255, P199, DOI 10.1016/0168-9002(87)91101-6
   Rubovic P, 2017, RADIAT MEAS, V107, P39, DOI 10.1016/j.radmeas.2017.10.012
   Sá AC, 2020, PHYS MEDICA, V71, P53, DOI 10.1016/j.ejmp.2020.02.008
   Safavi-Naeini M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34643-w
   Schneider U, 2015, FRONT ONCOL, V5, DOI 10.3389/fonc.2015.00235
   Schüller A, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/03/P03003
   Schüller A, 2019, IFMBE PROC, V68, P589, DOI 10.1007/978-981-10-9023-3_109
   Solc J, 2022, PHYS MEDICA, V101, P79, DOI 10.1016/j.ejmp.2022.08.002
   The International Commission of Radiological Protection, 2007, 2007 RECOMMENDATIONS, V103, DOI DOI 10.1016/J.ICRP.2007.10.003
   Turecek D, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/12/C12065
   Vanhavere F, 1998, RADIAT MEAS, V29, P573, DOI 10.1016/S1350-4487(98)00071-7
   Voytchev M, 2003, NUCL INSTRUM METH A, V512, P546, DOI 10.1016/S0168-9002(03)02013-8
   Vykydal Z, 2016, RADIAT PROT DOSIM, V172, P341, DOI 10.1093/rpd/ncv504
   Vykydal Z, 2018, RADIAT PROT DOSIM, V180, P51, DOI 10.1093/rpd/ncx190
   Werner C J., 2018, MCNP VERSION 6 2 REL, DOI DOI 10.2172/1419730
   Werner J C., 2017, LAUR1729981 LOS AL N
   Wong YM, 2023, PHYS MEDICA, V105, DOI 10.1016/j.ejmp.2022.102513
NR 70
TC 0
Z9 0
U1 3
U2 3
PD SEP 21
PY 2023
VL 68
IS 18
AR 185017
DI 10.1088/1361-6560/acf2e1
UT WOS:001090437100001
DA 2023-11-16
ER

PT J
AU Jaiswal, A
   Chakraborty, I
   Agrawal, A
   Roy, K
AF Jaiswal, Akhilesh
   Chakraborty, Indranil
   Agrawal, Amogh
   Roy, Kaushik
TI 8T SRAM Cell as a Multibit Dot-Product Engine for Beyond Von Neumann
   Computing
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Convolution; dot product; in-memory computing; SRAMs; von Neumann
   bottleneck
AB Large-scale digital computing almost exclusively relies on the von Neumann architecture, which comprises separate units for storage and computations. The energy-expensive transfer of data from the memory units to the computing cores results in the well-known von Neumann bottleneck. Various approaches aimed toward bypassing the von Neumann bottleneck are being extensively explored in the literature. These include in-memory computing based on CMOS and beyond CMOS technologies, wherein by making modifications to the memory array, vector computations can be carried out as close to the memory units as possible. Interestingly, in-memory techniques based on CMOS technology are of special importance due to the ubiquitous presence of field-effect transistors and the resultant ease of large-scale manufacturing and commercialization. On the other hand, perhaps the most important computation required for applications such as machine learning, etc., comprises the dot-product operation. Emerging nonvolatile memristive technologies have been shown to be very efficient in computing analog dot products in an in situ fashion. The memristive analog computation of the dot product results in much faster operation as opposed to digital vector in-memory bitwise Boolean computations. However, challenges with respect to large-scale manufacturing coupled with the limited endurance of memristors have hindered rapid commercialization of memristive-based computing solutions. In this paper, we show that the standard 8 transistor (8T) digital SRAM array can be configured as an analoglike in-memory multibit dot-product engine (DPE). By applying appropriate analog voltages to the read ports of the 8T SRAM array and sensing the output current, an approximate analog-digital DPE can be implemented. We present two different configurations for enabling multibit dot-product computations in the 8T SRAM cell array, without modifying the standard bit-cell structure. We also demonstrate the robustness of the present proposal in presence of nonidealities such as the effect of line resistances and transistor threshold voltage variations. Since our proposal preserves the standard 8T-SRAM array structure, it can be used as a storage element with standard read-write instructions and also as an on-demand analoglike dot-product accelerator.
C1 [Jaiswal, Akhilesh; Chakraborty, Indranil; Agrawal, Amogh] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Roy, Kaushik] Purdue Univ, Sch Elect Engn, W Lafayette, IN 47907 USA.
RP Jaiswal, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM jaiswal@purdue.edu
CR Agrawal A, 2017, ARXIV171205096
   [Anonymous], 2012, COMPUTER BRAIN
   [Anonymous], 2008, HPL200820
   [Anonymous], 2018, P 55 ANN DES AUT C J
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chang L, 2005, 2005 Symposium on VLSI Technology, Digest of Technical Papers, P128
   Chang L, 2007, 2007 SYMPOSIUM ON VLSI CIRCUITS, DIGEST OF TECHNICAL PAPERS, P252, DOI 10.1109/VLSIC.2007.4342739
   Changpinyo S., 2017, POWER SPARSITY CONVO
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dong Q, 2017, SYMP VLSI CIRCUITS, pC160, DOI 10.23919/VLSIC.2017.8008465
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Han S., 2015, C NEUR INF PROC SYST
   HONG ZN, 2010, IEEE ISSCC, P386
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Jaiswal A., 2018, ARXIV180208601
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kuhn KJ, 2011, IEEE T ELECTRON DEV, V58, P2197, DOI 10.1109/TED.2011.2121913
   Lee J, 2017, IEEE T VLSI SYST, V25, P2714, DOI 10.1109/TVLSI.2017.2664069
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Liu CC, 2017, DES AUT CON, DOI 10.1145/3061639.3062310
   Muralimanohar N., 2009, HPL200985, P3
   Palm R. B., 2012, IMMMSC201231 U DENM, V5
   Posser G, 2014, IEEE I C ELECT CIRC, P682, DOI 10.1109/ICECS.2014.7050077
   Rumelhart D.E., 1985, ICS8506 CAL U
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhao W, 2006, IEEE T ELECTRON DEV, V53, P2816, DOI 10.1109/TED.2006.884077
NR 35
TC 65
Z9 69
U1 0
U2 17
PD NOV
PY 2019
VL 27
IS 11
BP 2556
EP 2567
DI 10.1109/TVLSI.2019.2929245
UT WOS:000493284600009
DA 2023-11-16
ER

PT J
AU Medus, LD
   Iakymchuk, T
   Frances-Villora, JV
   Bataller-Mompeán, M
   Rosado-Muñoz, A
AF Medus, Leandro D.
   Iakymchuk, Taras
   Frances-Villora, Jose Vicente
   Bataller-Mompean, Manuel
   Rosado-Munoz, Alfredo
TI A Novel Systolic Parallel Hardware Architecture for the FPGA
   Acceleration of Feedforward Neural Networks
SO IEEE ACCESS
DT Article
DE Feedforward neural networks - FFNN; systolic hardware architecture; FPGA
   implementation; neural network acceleration; deep neural networks
ID LOGISTIC-REGRESSION; ACTIVATION FUNCTION; CLASSIFICATION;
   IMPLEMENTATION; CONTROLLER; ALGORITHM
AB New chips for machine learning applications appear, they are tuned for a specific topology, being efficient by using highly parallel designs at the cost of high power or large complex devices. However, the computational demands of deep neural networks require flexible and efficient hardware architectures able to fit different applications, neural network types, number of inputs, outputs, layers, and units in each layer, making the migration from software to hardware easy. This paper describes novel hardware implementing any feedforward neural network (FFNN): multilayer perceptron, autoencoder, and logistic regression. The architecture admits an arbitrary input and output number, units in layers, and a number of layers. The hardware combines matrix algebra concepts with serial-parallel computation. It is based on a systolic ring of neural processing elements (NPE), only requiring as many NPEs as neuron units in the largest layer, no matter the number of layers. The use of resources grows linearly with the number of NPEs. This versatile architecture serves as an accelerator in real-time applications and its size does not affect the system clock frequency. Unlike most approaches, a single activation function block (AFB) for the whole FFNN is required. Performance, resource usage, and accuracy for several network topologies and activation functions are evaluated. The architecture reaches 550 MHz clock speed in a Virtex7 FPGA. The proposed implementation uses 18-bit fixed point achieving similar classification performance to a floating point approach. A reduced weight bit size does not affect the accuracy, allowing more weights in the same memory. Different FFNN for Iris and MNIST datasets were evaluated and, for a real-time application of abnormal cardiac detection, a x256 acceleration was achieved. The proposed architecture can perform up to 1980 Giga operations per second (GOPS), implementing the multilayer FFNN of up to 3600 neurons per layer in a single chip. The architecture can be extended to bigger capacity devices or multi-chip by the simple NPE ring extension.
C1 [Medus, Leandro D.; Iakymchuk, Taras; Frances-Villora, Jose Vicente; Bataller-Mompean, Manuel; Rosado-Munoz, Alfredo] Univ Valencia, Dept Elect Engn, Grp Proc & Digital Design, E-46100 Burjassot, Spain.
RP Rosado-Muñoz, A (corresponding author), Univ Valencia, Dept Elect Engn, Grp Proc & Digital Design, E-46100 Burjassot, Spain.
EM alfredo.rosado@uv.es
CR [Anonymous], ALGORITHM IMPLEMENTA
   [Anonymous], ARM CORT M4 PROC TEC
   [Anonymous], 2012, PREDICTION CANDIDATE
   [Anonymous], 2014, PAPER PRESENTED INT
   [Anonymous], 2017, P 2017 INT C EMERGIN
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2009, AUTOENCODER NEURAL N, DOI DOI 10.5555/1795842
   [Anonymous], CORR
   Clemente JA, 2016, NEUROCOMPUTING, V171, P1606, DOI 10.1016/j.neucom.2015.06.038
   Bataller-Mompeán M, 2016, IEEE T IND INFORM, V12, P1114, DOI 10.1109/TII.2016.2554521
   Bengio Y., 2006, ADV NEURAL INFORM PR, P153
   Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1
   do A. Ferreira Antonyus P., 2010, Proceedings of the 2010 17th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2010), P742, DOI 10.1109/ICECS.2010.5724619
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Frances-Villora JV, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110308
   Frances-Villora JV, 2016, COMPUT ELECTR ENG, V51, P139, DOI 10.1016/j.compeleceng.2016.02.007
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Greenwald S. D., 1986, THESIS MIT CAMBRIDGE
   Harshvardhan G, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1534, DOI 10.1109/WiSPNET.2016.7566393
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Iakymchuk T, 2016, IEEE T COMPUT, V65, P3470, DOI 10.1109/TC.2016.2538235
   Iranpour E, 2017, T I MEAS CONTROL, V39, P1522, DOI 10.1177/0142331216644042
   Juang CF, 2014, IEEE T NEUR NET LEAR, V25, P216, DOI 10.1109/TNNLS.2013.2253799
   Kim LW, 2018, IEEE T NEUR NET LEAR, V29, P1441, DOI 10.1109/TNNLS.2017.2665555
   KWAN HK, 1992, ELECTRON LETT, V28, P1379, DOI 10.1049/el:19920877
   Kyrkou C, 2016, IEEE T NEUR NET LEAR, V27, P99, DOI 10.1109/TNNLS.2015.2428738
   Maas A, 2016, ISPRS ANN PHOTO REM, V3, P133, DOI 10.5194/isprsannals-III-7-133-2016
   Messalti S, 2017, RENEW SUST ENERG REV, V68, P221, DOI 10.1016/j.rser.2016.09.131
   Mjahad A, 2017, COMPUT METH PROG BIO, V141, P119, DOI 10.1016/j.cmpb.2017.02.010
   Nasrabadi N.M., 2007, PATTERN RECOGN, V16, DOI 10.1117/1.2819119
   Nedjah N, 2016, NEUROCOMPUTING, V183, P39, DOI 10.1016/j.neucom.2015.05.138
   Nedjah N, 2012, EXPERT SYST APPL, V39, P9191, DOI 10.1016/j.eswa.2012.02.085
   Oliveira JGM, 2017, INT CARIBB CONF DEVI, P41, DOI 10.1109/ICCDCS.2017.7959699
   Ortega-Zamorano F, 2016, IEEE T NEUR NET LEAR, V27, P1840, DOI 10.1109/TNNLS.2015.2460991
   Rosado-Munoz A, 2008, J UNIVERS COMPUT SCI, V14, P1678
   Rumelhart D.E., 1987, LEARNING INTERNAL RE, P318
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Soleimani H, 2015, IEEE T NEUR NET LEAR, V26, P127, DOI 10.1109/TNNLS.2014.2311839
   Suzuki A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194049
   Tang ZL, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7070122
   Huynh TV, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P254, DOI 10.1109/NAFOSTED.2017.8108073
   Tisan A, 2016, IEEE T IND INFORM, V12, P1124, DOI 10.1109/TII.2016.2555936
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vranjkovic V., 2016, PROC INT C SYST SIGN, P1
   Wang RC, 2017, IEEE T BIOMED CIRC S, V11, P574, DOI 10.1109/TBCAS.2017.2666883
   Xing C, 2016, J SENSORS, V2016, DOI 10.1155/2016/3632943
   Zhai XJ, 2016, IEEE ACCESS, V4, P8138, DOI 10.1109/ACCESS.2016.2619181
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang M, 1996, IEEE T COMPUT, V45, P1045, DOI 10.1109/12.537127
   Zhou YT, 2015, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2015.45
   Zhu JH, 2003, LECT NOTES COMPUT SC, V2778, P1062
   Zhu X, 2015, LECT NOTES COMPUT SC, V9391, P29, DOI 10.1007/978-3-319-23531-8_3
NR 55
TC 25
Z9 25
U1 0
U2 8
PY 2019
VL 7
BP 76084
EP 76103
DI 10.1109/ACCESS.2019.2920885
UT WOS:000473362300001
DA 2023-11-16
ER

PT J
AU Peltekis, C
   Filippas, D
   Dimitrakopoulos, G
   Nicopoulos, C
AF Peltekis, Christodoulos
   Filippas, Dionysios
   Dimitrakopoulos, Giorgos
   Nicopoulos, Chrysostomos
TI Exploiting data encoding and reordering for low-power streaming in
   systolic arrays
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Systolic arrays; Bus-invert coding; Zero -value clock gating; Weight
   reordering; Traveling salesman problem; Low-power design; Machine
   learning accelerators
AB Systolic Array (SA) architectures are well-suited for accelerating matrix multiplications through the use of a pipelined array of Processing Elements (PEs) communicating with local connections and pre-orchestrated data movements. Even though most of the dynamic power consumption in SAs is due to multiplications and additions, pipelined data movement within the SA constitutes an additional important contributor. The goal of this work is to reduce the dynamic power consumption associated with the feeding of data to the SA, by employing both dynamic (run-time) and static (offline) techniques. At the hardware level, the proposed architecture synergistically applies bus-invert coding and zero-value clock gating. By exploiting salient attributes of state-of-the-art CNNs, such as the value distribution of the weights, the proposed SA applies appropriate encoding only to the data that exhibits high switching activity. Similarly, when one of the inputs is zero, unnecessary operations are entirely skipped. In addition to this duet of run-time techniques, the proposed methodology also leverages the inherent property of the weight matrix to remain unchanged throughout the inference phase. As such, the weight matrix is appropriately reordered offline to minimize the switching activity between consecutive values, as the matrix is repeatedly loaded into the array. The weight reordering process is formulated as a Traveling Salesman Problem (TSP) and its solution is translated into a switching-activity-aware row permutation of the weight matrix. The symbiotic combination of selectively targeted, application-aware dynamic encoding and offline weight reordering is demonstrated to reduce the switching activity by 38%, on average. This translates to an overall dynamic power reduction of 17.1%-23% when executing state-of-the-art CNN layers on an SA of size 32 x 32. These power savings scale with the array size; for an array of size 64 x 64, the proposed design consumes 29.7%-35.4% less power.
C1 [Peltekis, Christodoulos; Filippas, Dionysios; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Dept Elect & Comp Engn, Nicosia, Cyprus.
RP Peltekis, C (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
EM cpeltekis@ee.duth.gr
CR Acquaviva A, 2000, ISLPED '00: PROCEEDINGS OF THE 2000 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P238, DOI 10.1109/LPE.2000.876793
   Andersch M., 2022, NVIDIA HOPPER ARCHIT
   Asgari B, 2020, PR IEEE COMP DESIGN, P130, DOI 10.1109/ICCD50377.2020.00036
   Benini L, 1997, PR GR LAK SYMP VLSI, P77, DOI 10.1109/GLSV.1997.580414
   Benini L., 1999, Proceedings 1999 Design Automation Conference (Cat. No. 99CH36361), P128, DOI 10.1109/DAC.1999.781297
   Benini L, 1998, DESIGN, AUTOMATION AND TEST IN EUROPE, PROCEEDINGS, P861, DOI 10.1109/DATE.1998.655959
   Feinberg B, 2020, ANN I S COM, P1076, DOI 10.1109/ISCA45697.2020.00091
   Filippas D., 2023, IEEE INT C ART INT C
   Fornaciari W., 2000, Proceedings of the Eighth International Workshop on Hardware/Software Codesign. CODES 2000 (IEEE Cat. No.00TH8518), P29, DOI 10.1109/HSC.2000.843702
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Genc H, 2021, DES AUT CON, P769, DOI 10.1109/DAC18074.2021.9586216
   Google, 2022, BFLOAT16 NUM FORM
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henning R, 2002, IEEE T CIRCUITS-II, V49, P339, DOI 10.1109/TCSII.2002.801209
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jha CK, 2021, IEEE T CIRCUITS-I, V68, P3337, DOI 10.1109/TCSI.2021.3081623
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Lee D, 2018, INT S HIGH PERF COMP, P40, DOI 10.1109/HPCA.2018.00014
   Lee J, 2021, DES AUT CON, P247, DOI 10.1109/DAC18074.2021.9586312
   Liu ZG, 2022, INT S HIGH PERF COMP, P573, DOI 10.1109/HPCA53966.2022.00049
   Masselos K, 2000, ISLPED '00: PROCEEDINGS OF THE 2000 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P234, DOI 10.1109/LPE.2000.876792
   Mittal S, 2019, J SYST ARCHITECT, V97, P373, DOI 10.1016/j.sysarc.2018.11.001
   Musoll E., 1995, Proceedings. 1995 International Symposium on Low Power Design, P99, DOI 10.1145/224081.224099
   Peltekis C, 2023, DES AUT TEST EUROPE
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Shin Y, 2001, IEEE T VLSI SYST, V9, P377, DOI 10.1109/92.924059
   STAN MR, 1995, IEEE T VLSI SYST, V3, P49, DOI 10.1109/92.365453
   Ullah I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218585
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wimer S, 2014, IEEE T VLSI SYST, V22, P771, DOI 10.1109/TVLSI.2013.2253338
   Xu R, 2022, IEEE T PARALL DISTR, V33, P2860, DOI 10.1109/TPDS.2021.3129647
   Xu R, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3460776
   Yang J, 2004, ACM T DES AUTOMAT EL, V9, P354, DOI 10.1145/1013948.1013953
NR 36
TC 0
Z9 0
U1 0
U2 0
PD OCT
PY 2023
VL 102
AR 104938
DI 10.1016/j.micpro.2023.104938
UT WOS:001091782800001
DA 2023-11-16
ER

PT C
AU Luo, YK
   Xu, XL
AF Luo, Yukui
   Xu, Xiaolin
GP IEEE
TI A Quantitative Defense Framework against Power Attacks on Multi-tenant
   FPGA
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
AB The development and application of various Machine Learning algorithms demand high computing capabilities. As a result, field-programmable gate arrays (FPGAs) are being used as hardware accelerators, and more recently deployed in cloud servers by leading vendors to provide reconfigurable computing capabilities. Although such cloud-FPGA platform is bringing significant performance benefits, it also creates a unique attack surface where the hardware resources of an FPGA are shared by multiple users. Power attack targeting the power distribution network (PDN) is among the most threatening ones against multi-tenant FPGAs. In such attack, the malicious users leverage power plundering circuits to manipulate the PDN and cause a voltage drop, thus injecting timing faults to the victim applications. Besides, since most cloud-FPGAs are being used for computing-intensive tasks that consume a large amount of power, therefore, typical FPGA applications may still encounter timing faults even without power attacks. Unlike power attacks, we classify this problem as a reliability issue.
   To comprehensively mitigate the reliability and security issues caused by a non-malicious or malicious voltage drop, in this paper, we introduce a quantitative defense framework. The proposed framework provides a two-fold defense method: static and dynamic frequency scaling, to manage the clock frequency of the FPGA applications. The frequency scaling strategy is based on quantifying the relationship between the adversarial circuit and the voltage drop that can be injected. The proposed framework provides a delay-frequency pair table, which can be pre-configured to control the run-time clock frequency of the FPGA application. For practical applicability, the proposed framework utilizes the existing on-chip clock management components like mixed-model clock manager (MMCM) and phase-locked loop (PLL). Additionally, to assist the frequency scaling, we propose an on-chip sensor that can accurately quantify the real-time voltage drop. The performance of the proposed framework is validated with open-source benchmarks and real-world Advanced Encryption Standard (AES) implementation on an Xilinx NetFPGA. The experimental results demonstrate the effectiveness of the proposed method in mitigating security and reliability issues caused by a voltage drop.
C1 [Luo, Yukui; Xu, Xiaolin] Northeastern Univ, Boston, MA 02115 USA.
RP Luo, YK (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM luo.yuk@northeastern.edu; x.xu@northeastern.edu
CR Alam Md Mahbub, 2019, 2019 Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC). Proceedings, P48, DOI 10.1109/FDTC.2019.00015
   Albrecht C., 2005, IWLS 2005 BENCHMARKS
   [Anonymous], 2018, MD5 PIPELINED
   [Anonymous], 2014, ALTERA IBM UNVEIL FP
   [Anonymous], 2017, VIVADO DESIGN SUITE
   [Anonymous], 2014, VIVADO TIMING CLOSUR
   [Anonymous], 2016, AES128 ENCRYPTION
   [Anonymous], 2019, DOUBLE FPU VERILOG
   [Anonymous], 2018, SHA CORES
   [Anonymous], 2016, HERES WHAT INTEL BRO
   Bag Arnab, 2018, ARXIV PREPRINT ARXIV
   Danger JL, 2009, MICROELECTRON J, V40, P1650, DOI 10.1016/j.mejo.2009.02.004
   Elnaggar R, 2019, DES AUT TEST EUROPE, P7, DOI [10.23919/DATE.2019.8714904, 10.23919/date.2019.8714904]
   Fischer V, 2008, I C FIELD PROG LOGIC, P245, DOI 10.1109/FPL.2008.4629939
   Giechaskiel I, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P15, DOI 10.1145/3196494.3196518
   Gnad DRE, 2017, I C FIELD PROG LOGIC
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Krautter J., 2018, IACR TCHES, P44, DOI 10.13154/tches.v2018.i3.44-68
   Luo YK, 2020, ANN IEEE SYM FIELD P, P210, DOI 10.1109/FCCM48280.2020.00041
   Luo YK, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P331, DOI 10.1109/ICFPT47387.2019.00060
   Mahmoud D, 2019, DES AUT TEST EUROPE, P1745, DOI [10.23919/date.2019.8715263, 10.23919/DATE.2019.8715263]
   Maiti Abhranil, 2010, 2010 IEEE International Symposium on Hardware-Oriented Security and Trust (HOST 2010), P94, DOI 10.1109/HST.2010.5513108
   Maiti A, 2011, J CRYPTOL, V24, P375, DOI 10.1007/s00145-010-9088-4
   Murdock K, 2020, P IEEE S SECUR PRIV, P1466, DOI 10.1109/SP40000.2020.00057
   Provelengios G, 2019, I C FIELD PROG LOGIC, P194, DOI 10.1109/FPL.2019.00038
   Qiu PF, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P195, DOI 10.1145/3319535.3354201
   Ramesh Chethan, 2018, 2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), P45, DOI 10.1109/FCCM.2018.00016
   Wold K, 2009, INT J RECONFIGURABLE, V2009, DOI 10.1155/2009/501672
   Xilinx,Inc, 2019, MMCM PLL DYN REC XAP MMCM PLL DYN REC XAP
   Xilinx,Inc, 2019, KINTEX 7 FPGAS DAT S KINTEX 7 FPGAS DAT S
   Xilinx Inc, 2018, 7 SER FPGAS CLOCK RE
   Xin Xin, 2011, Proceedings of the 2011 14th Euromicro Conference on Digital System Design. Architectures, Methods and Tools. (DSD 2011), P651, DOI 10.1109/DSD.2011.88
   Yazdanshenas Sadegh, 2019, IEEE T VERY LARGE SC
   ZaneWeissman Thore Tiemann, 2019, ARXIV PREPRINT ARXIV
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
NR 35
TC 11
Z9 11
U1 0
U2 0
PY 2020
DI 10.1145/3400302.3415694
UT WOS:000671087100027
DA 2023-11-16
ER

PT J
AU Tao, C
   Roy, D
   Chakraborty, I
   Roy, K
AF Tao, Chun
   Roy, Deboleena
   Chakraborty, Indranil
   Roy, Kaushik
TI On Noise Stability and Robustness of Adversarially Trained Networks on
   NVM Crossbars
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Robustness; Hardware; Stability analysis; Training; Nonvolatile memory;
   Thermal stability; Phase change random access memory; Adversarial
   attacks; adversarial training; analog computing; machine learning (ML)
   acceleration; nonvolatile memories (NVMs); projected gradient descent
   (PGD)
ID MEMORY; SCALE
AB Applications based on deep neural networks (DNNs) have grown exponentially in the past decade. To match their increasing computational needs, several nonvolatile memory (NVM) crossbar-based accelerators have been proposed. Recently, researchers have shown that apart from improved energy efficiency and performance, such approximate hardware also possess intrinsic robustness for defense against adversarial attacks. Prior works have focused on quantifying this intrinsic robustness for vanilla networks, that is DNNs trained on unperturbed inputs. However, adversarial training of DNNs, i.e., training with adversarially perturbed images, is the benchmark technique for robustness, and sole reliance on intrinsic robustness of the hardware may not be sufficient. In this work, we explore the design of robust DNNs through the amalgamation of adversarial training and the intrinsic robustness offered by NVM crossbar-based analog hardware. First, we study the noise stability of such networks on unperturbed inputs and observe that internal activations of adversarially trained networks have lower signal-to-noise ratio (SNR), and are sensitive to noise compared to vanilla networks. As a result, they suffer significantly higher performance degradation due to the approximate computations on analog hardware; on an average 2x accuracy drop. Noise stability analyses clearly show the instability of adversarially trained DNNs. On the other hand, for adversarial images generated using Square Black Box attacks, ResNet-10/20 adversarially trained on CIFAR-10/100 display a robustness improvement of 20%-30% under high epsilon(attack) (degree of input perturbation). For adversarial images generated using projected-gradient-descent (PGD) White-Box attacks, the adversarially trained DNNs present a 5%-10% gain in robust accuracy due to the underlying NVM crossbar when epsilon(attack) is greater than the epsilon of the adversarial training (epsilon(train)). Our results indicate that implementing adversarially trained networks on analog hardware requires careful calibration between hardware nonidealities and epsilon(train) to achieve optimum robustness and performance.
C1 [Tao, Chun; Roy, Deboleena; Chakraborty, Indranil; Roy, Kaushik] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Tao, C (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM tao88@purdue.edu; roy77@purdue.edu; ichakra@purdue.edu;
   kaushik@purdue.edu
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Andriushchenko, 2019, ARXIV
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Arora S, 2018, PR MACH LEARN RES, V80
   Athalye A, 2018, ARXIV
   Buckman Jacob, 2018, INT C LEARN REPR ICL
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Cappelli A., 2021, ARXIV
   Chakraborty I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218688
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Cheng H.-T., 2016, P 1 WORKSHOP DEEP LE, P7, DOI DOI 10.1145/2988450.2988454
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Dhillon Guneet S, 2018, STOCHASTIC ACTIVATIO
   Duesterwald, 2019, ARXIV
   Fong XY, 2016, IEEE T COMPUT AID D, V35, P1, DOI 10.1109/TCAD.2015.2481793
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow Ian J., 2015, EXPLAINING HARNESSIN
   Guan XM, 2012, IEEE ELECTR DEVICE L, V33, P1405, DOI 10.1109/LED.2012.2210856
   Guesmi A, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P990, DOI 10.1145/3445814.3446747
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Jia Zhihao, 2019, P MACH LEARN SYST 20
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Langford J., 2002, P ADV NEUR INF PROC, V14, P1
   Liu C., 2020, P ADV NEUR INF PROC, V33, P1
   Madry Aleksander, 2018, DEEP LEARNING MODELS
   Moon S., 2019, ICML, P4636
   Morcos Ari S., 2018, IMPORTANCE SINGLE DI
   Negi S., 2021, ARXIV
   Roy, 2020, ARXIV
   Roy D., 2021, ARXIV
   Schaller RR, 1997, IEEE SPECTRUM, V34, P52, DOI 10.1109/6.591665
   Shafahi A, 2019, ADV NEUR IN, V32
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wong, 2019, PROC INT C LEARN REP
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
NR 44
TC 0
Z9 0
U1 1
U2 4
PD OCT
PY 2022
VL 30
IS 10
BP 1448
EP 1460
DI 10.1109/TVLSI.2022.3193312
EA JUL 2022
UT WOS:000833058700001
DA 2023-11-16
ER

PT C
AU Mutlu, O
AF Mutlu, Onur
GP Assoc Comp Machinery
TI Processing Data Where It Makes Sense in Modern Computing Systems:
   Enabling In-Memory Computation
SO GLSVLSI '19 - PROCEEDINGS OF THE 2019 ON GREAT LAKES SYMPOSIUM ON VLSI
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT 29th Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 09-11, 2019
CL Tysons Corner, VA
DE processing-in-memory; near-data processing; data movement; accelerators;
   memory systems; 3D-stacked memory; DRAM; analog computing; energy
   efficiency; virtual memory; cache coherence; computing paradigms
AB Today's systems are overwhelmingly designed to move data to computation. This design choice goes directly against at least three key trends in systems that cause performance, scalability and energy bottlenecks: 1) data access from memory is already a key bottleneck as applications become more data-intensive and memory bandwidth and energy do not scale well, 2) energy consumption is a key constraint in especially mobile and server systems, 3) data movement is very expensive in terms of bandwidth, energy and latency, much more so than computation [1-3]. These trends are especially severely-felt in the data-intensive server and energy-constrained mobile systems of today.
   At the same time, conventional memory technology is facing many scaling challenges in terms of reliability, energy, and performance [4-5]. As a result, memory system architects are open to organizing memory in different ways and making it more intelligent, at the expense of slightly higher cost. The emergence of 3D-stacked memory plus logic [6], the adoption of error correcting codes inside the latest DRAM chips [7-8], and intelligent memory controllers to solve the Row-Hammer problem [9-11] are an evidence of this trend.
   In this talk, I will discuss some recent research that aims to practically enable computation close to data. After motivating trends in applications as well as technology, we will discuss at least two promising directions: 1) performing massively-parallel bulk operations in memory by exploiting the analog operational properties of DRAM, with low-cost changes [3, 12-14, 23], 2) exploiting the logic layer in 3D-stacked memory technology in various ways to accelerate important data-intensive applications [2, 15-22]. In both approaches, we will discuss relevant crosslayer research, design, and adoption challenges in devices, architecture, systems, applications, and programming models [1]. Our focus will be the development of in-memory processing designs that can be adopted in real computing platforms and real data-intensive applications, spanning machine learning, graph processing, data analytics, and genome analysis, at low cost [26]. If time permits, we will also discuss simulation and evaluation infrastructures that can enable exciting and forward-looking research in future memory systems, including Ramulator [24] and SoftMC [25].
C1 [Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Mutlu, O (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
EM onur.mutlu@inf.ethz.ch
CR [Anonymous], ASPLOS 2018
   [Anonymous], ISCA 2016
   [Anonymous], ISCA 2019
   [Anonymous], ISCA 2015
   [Anonymous], ICCD 2016
   Boroumand Amirali, IEEE CAL 2017
   Chang Kevin, HPCA 2016
   Ghose Saugata, 2019, ENABLING ADOPTION PR
   Hassan Hasan, HPCA 2018
   Kang Uksong, MEMORY FORUM 2014
   Kim JS, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4460-0
   Kim Yoongu, IEEE CAL 2016
   Kim Yoongu, ISCA 2014
   Lee Donghyuk, ACM TACO 2016
   Mutlu Onur, SUPERFRI 2015
   Mutlu Onur, IMW 2013
   Mutlu Onur, DATE 2017
   Mutlu Onur, MICPRO 2019
   Mutlu Onur, IEEE TCAD 2019
   Patel Minesh, DSN 2019
   Pattnaik Ashutosh, PACT 2016
   Seshadri Vivek, MICRO 2013
   Seshadri Vivek, 2018, ADV COMPUTERS
   Seshadri Vivek, MICRO 2017
   Seshadri Vivek, IEEE CAL 2015
NR 25
TC 15
Z9 15
U1 0
U2 5
PY 2019
BP 5
EP 6
DI 10.1145/3299874.3322805
UT WOS:000474339800003
DA 2023-11-16
ER

PT J
AU Thompson, AP
   Aktulga, HM
   Berger, R
   Bolintineanu, DS
   Brown, WM
   Crozier, PS
   Veld, PJI
   Kohlmeyer, A
   Moore, SG
   Nguyen, TD
   Shan, R
   Stevens, MJ
   Tranchida, J
   Trott, C
   Plimpton, SJ
AF Thompson, Aidan P.
   Aktulga, H. Metin
   Berger, Richard
   Bolintineanu, Dan S.
   Brown, W. Michael
   Crozier, Paul S.
   Veld, Pieter J. in 't
   Kohlmeyer, Axel
   Moore, Stan G.
   Nguyen, Trung Dac
   Shan, Ray
   Stevens, Mark J.
   Tranchida, Julien
   Trott, Christian
   Plimpton, Steven J.
TI LAMMPS-a flexible simulation tool for particle-based materials modeling
   at the atomic, meso, and continuum scales
SO COMPUTER PHYSICS COMMUNICATIONS
DT Article
DE Molecular dynamics; Materials modeling; Parallel algorithms; LAMMPS
ID MOLECULAR-DYNAMICS SIMULATIONS; REACTIVE FORCE-FIELD;
   MONTE-CARLO-SIMULATION; COARSE-GRAINED MODEL; ELECTRONEGATIVITY
   EQUALIZATION; SPIN DYNAMICS; EWALD SUMS; PERFORMANCE; POTENTIALS;
   ALGORITHM
AB Since the classical molecular dynamics simulator LAMMPS was released as an open source code in 2004, it has become a widely-used tool for particle-based modeling of materials at length scales ranging from atomic to mesoscale to continuum. Reasons for its popularity are that it provides a wide variety of particle interaction models for different materials, that it runs on any platform from a single CPU core to the largest supercomputers with accelerators, and that it gives users control over simulation details, either via the input script or by adding code for new interatomic potentials, constraints, diagnostics, or other features needed for their models. As a result, hundreds of people have contributed new capabilities to LAMMPS and it has grown from fifty thousand lines of code in 2004 to a million lines today. In this paper several of the fundamental algorithms used in LAMMPS are described along with the design strategies which have made it flexible for both users and developers. We also highlight some capabilities recently added to the code which were enabled by this flexibility, including dynamic load balancing, on-the-fly visualization, magnetic spin dynamics models, and quantum-accuracy machine learning interatomic potentials. Program Summary Program Title: Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) CPC Library link to program files: https://doi .org /10 .17632 /cxbxs9btsv.1 Developer's repository link: https://github .com /lammps /lammps Licensing provisions: GPLv2 Programming language: C++, Python, C, Fortran Supplementary material: https://www.lammps .org Nature of problem: Many science applications in physics, chemistry, materials science, and related fields require parallel, scalable, and efficient generation of long, stable classical particle dynamics trajectories. Within this common problem definition, there lies a great diversity of use cases, distinguished by different particle interaction models, external constraints, as well as timescales and lengthscales ranging from atomic to mesoscale to macroscopic. Solution method: The LAMMPS code uses parallel spatial decomposition, distributed neighbor lists, and parallel FFTs for long-range Coulombic interactions [1]. The time integration algorithm is based on the Stormer-Verlet symplectic integrator [2], which provides better stability than higher-order non-symplectic methods. In addition, LAMMPS supports a wide range of interatomic potentials, constraints, diagnostics, software interfaces, and pre- and post-processing features. Additional comments including restrictions and unusual features: This paper serves as the definitive reference for the LAMMPS code. References [1] S. Plimpton, Fast parallel algorithms for short-range molecular dynamics. J. Comp. Phys. 117 (1995) 1-19. [2] L. Verlet, Computer experiments on classical fluids: I. Thermodynamical properties of Lennard-Jones molecules, Phys. Rev. 159 (1967) 98-103. (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Thompson, Aidan P.; Bolintineanu, Dan S.; Crozier, Paul S.; Moore, Stan G.; Stevens, Mark J.; Tranchida, Julien; Trott, Christian; Plimpton, Steven J.] Sandia Natl Labs, Albuquerque, NM 87185 USA.
   [Aktulga, H. Metin] Michigan State Univ, E Lansing, MI 48824 USA.
   [Berger, Richard; Kohlmeyer, Axel] Temple Univ, Philadelphia, PA 19122 USA.
   [Brown, W. Michael] Intel Corp, Hillsboro, OR 97124 USA.
   [Veld, Pieter J. in 't] BASF SE, Ludwigshafen, Germany.
   [Nguyen, Trung Dac] Northwestern Univ, Evanston, IL 60208 USA.
   [Shan, Ray] Mat Design Inc, San Diego, CA 92131 USA.
RP Thompson, AP; Plimpton, SJ (corresponding author), Sandia Natl Labs, Albuquerque, NM 87185 USA.
EM athomps@sandia.gov; sjplimp@sandia.gov
CR Abraham Mark James, 2015, SoftwareX, V1-2, P19, DOI 10.1016/j.softx.2015.06.001
   Aktulga HM, 2012, PARALLEL COMPUT, V38, P245, DOI 10.1016/j.parco.2011.08.005
   ANDERSEN HC, 1983, J COMPUT PHYS, V52, P24, DOI 10.1016/0021-9991(83)90014-1
   Anderson J.A, 2002, COMP MATER SCI, V173
   [Anonymous], 2016, HDB PERIDYNAMIC MODE, DOI DOI 10.1201/9781315373331
   [Anonymous], 1996, UNDERSTANDING MOL DY
   [Anonymous], 2008, STAT MECH NONEQUILIB
   Antropov VP, 1996, PHYS REV B, V54, P1019, DOI 10.1103/PhysRevB.54.1019
   Auhl R, 2003, J CHEM PHYS, V119, P12718, DOI 10.1063/1.1628670
   Barnes TA, 2021, COMPUT PHYS COMMUN, V261, DOI 10.1016/j.cpc.2020.107688
   Bartók AP, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.136403
   BASKES MI, 1989, PHYS REV B, V40, P6085, DOI 10.1103/PhysRevB.40.6085
   BASKES MI, 1992, PHYS REV B, V46, P2727, DOI 10.1103/PhysRevB.46.2727
   Beazley DM, 2003, FUTURE GENER COMP SY, V19, P599, DOI 10.1016/S0167-739X(02)00171-1
   Begau C, 2015, COMPUT PHYS COMMUN, V190, P51, DOI 10.1016/j.cpc.2015.01.009
   Behler J, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.146401
   Berardi R, 1998, CHEM PHYS LETT, V297, P8, DOI 10.1016/S0009-2614(98)01090-2
   BERGER MJ, 1987, IEEE T COMPUT, V36, P570, DOI 10.1109/TC.1987.1676942
   Bessarab PF, 2015, COMPUT PHYS COMMUN, V196, P335, DOI 10.1016/j.cpc.2015.07.001
   BISHOP M, 1979, J CHEM PHYS, V70, P1299, DOI 10.1063/1.437567
   Bitzek E, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.170201
   Bock N., LATTE, P2021
   Bolintineanu DS, 2014, COMPUT PART MECH, V1, P321, DOI 10.1007/s40571-014-0007-6
   Bollinger JA, 2018, SOFT MATTER, V14, P1748, DOI 10.1039/c7sm02033c
   Botu V, 2015, INT J QUANTUM CHEM, V115, P1074, DOI 10.1002/qua.24836
   Brenner DW, 2002, J PHYS-CONDENS MAT, V14, P783, DOI 10.1088/0953-8984/14/4/312
   Brooks BR, 2009, J COMPUT CHEM, V30, P1545, DOI 10.1002/jcc.21287
   Brown WM, 2015, COMPUT PHYS COMMUN, V195, P95, DOI 10.1016/j.cpc.2015.05.004
   Brown WM, 2013, COMPUT PHYS COMMUN, V184, P2785, DOI 10.1016/j.cpc.2013.08.002
   Brown WM, 2012, COMPUT PHYS COMMUN, V183, P449, DOI 10.1016/j.cpc.2011.10.012
   Brown WM, 2011, COMPUT PHYS COMMUN, V182, P898, DOI 10.1016/j.cpc.2010.12.021
   Bussi G, 2020, NAT REV PHYS, V2, P200, DOI 10.1038/s42254-020-0153-0
   CAR R, 1985, PHYS REV LETT, V55, P2471, DOI 10.1103/PhysRevLett.55.2471
   Case DA, 2005, J COMPUT CHEM, V26, P1668, DOI 10.1002/jcc.20290
   Cerdà JJ, 2008, J CHEM PHYS, V129, DOI 10.1063/1.3000389
   Chauleau JY, 2020, NAT MATER, V19, P386, DOI 10.1038/s41563-019-0516-z
   Chenoweth K, 2008, J PHYS CHEM A, V112, P1040, DOI 10.1021/jp709896w
   Coleman SP, 2014, JOM-US, V66, P408, DOI 10.1007/s11837-013-0829-3
   Curk T, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.138003
   Cusentino MA, 2021, NUCL FUSION, V61, DOI 10.1088/1741-4326/abe7bd
   Cusentino MA, 2020, J PHYS CHEM A, V124, P5456, DOI 10.1021/acs.jpca.0c02450
   DARDEN T, 1993, J CHEM PHYS, V98, P10089, DOI 10.1063/1.464397
   DAW MS, 1984, PHYS REV B, V29, P6443, DOI 10.1103/PhysRevB.29.6443
   DERJAGUIN B, 1993, PROG SURF SCI, V43, P30, DOI 10.1016/0079-6816(93)90013-L
   Deserno M, 1998, J CHEM PHYS, V109, P7678, DOI 10.1063/1.477414
   Dickel D, 2021, COMP MATER SCI, V196, DOI 10.1016/j.commatsci.2021.110481
   Dobson M, 2014, J CHEM PHYS, V141, DOI 10.1063/1.4901276
   Dos Santos G, 2020, PHYS REV B, V102, DOI 10.1103/PhysRevB.102.184426
   Dragoni D, 2018, PHYS REV MATER, V2, DOI 10.1103/PhysRevMaterials.2.013808
   Drautz R, 2020, PHYS REV B, V102, DOI 10.1103/PhysRevB.102.024104
   Duffy DM, 2007, J PHYS-CONDENS MAT, V19, DOI 10.1088/0953-8984/19/1/016207
   Eriksson O, 2017, ATOMISTIC SPIN DYNAMICS: FOUNDATIONS AND APPLICATIONS, DOI 10.1093/oso/9780198788669.001.0001
   Español P, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.026705
   ESSMANN U, 1995, J CHEM PHYS, V103, P8577, DOI 10.1063/1.470117
   EVANS DJ, 1984, PHYS REV A, V30, P1528, DOI 10.1103/PhysRevA.30.1528
   Evans R. F, 2020, HDB MAT MODELING APP, P427
   Everaers R, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.041710
   Faken D., 1994, Computational Materials Science, V2, P279, DOI 10.1016/0927-0256(94)90109-0
   Fattebert JL, 2012, COMPUT PHYS COMMUN, V183, P2608, DOI 10.1016/j.cpc.2012.07.013
   Finkelstein J, 2020, MOL PHYS, V118, DOI 10.1080/00268976.2019.1649493
   Fiorin G, 2013, MOL PHYS, V111, P3345, DOI 10.1080/00268976.2013.813594
   Foster JT, 2010, INT J NUMER METH ENG, V81, P1242, DOI 10.1002/nme.2725
   Fraige FY, 2008, PARTICUOLOGY, V6, P455, DOI 10.1016/j.partic.2008.07.019
   FrantzDale B, 2010, ENG COMPUT-GERMANY, V26, P205, DOI 10.1007/s00366-009-0156-z
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Gallis MA, 2015, PHYS FLUIDS, V27, DOI 10.1063/1.4928338
   Gayatri R., 2020, ARXIV201112875
   Ge T, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.098301
   GIBSON JB, 1960, PHYS REV, V120, P1229, DOI 10.1103/PhysRev.120.1229
   Gissinger JR, 2020, MACROMOLECULES, V53, P9953, DOI 10.1021/acs.macromol.0c02012
   Gissinger JR, 2017, POLYMER, V128, P211, DOI 10.1016/j.polymer.2017.09.038
   Goetz R, 1998, J CHEM PHYS, V108, P7397, DOI 10.1063/1.476160
   Goldman N, 2013, J PHYS CHEM A, V117, P5124, DOI 10.1021/jp402976n
   GREST GS, 1989, COMPUT PHYS COMMUN, V55, P269, DOI 10.1016/0010-4655(89)90125-2
   Griebel M., 2007, NUMERICAL SIMULATION
   Gschneidner KA, 2012, SCRIPTA MATER, V67, P572, DOI 10.1016/j.scriptamat.2011.12.042
   Ha YD, 2011, ENG FRACT MECH, V78, P1156, DOI 10.1016/j.engfracmech.2010.11.020
   Hallil A, 2006, PHYS REV B, V73, DOI 10.1103/PhysRevB.73.165406
   HEFFELFINGER GS, 1994, J CHEM PHYS, V100, P7548, DOI 10.1063/1.466849
   Henkelman G, 2000, J CHEM PHYS, V113, P9901, DOI 10.1063/1.1329672
   Henrich O, 2018, EUR PHYS J E, V41, DOI 10.1140/epje/i2018-11669-8
   Larsen AH, 2017, J PHYS-CONDENS MAT, V29, DOI 10.1088/1361-648X/aa680e
   Hockney RW., 1988, COMPUTER SIMULATION
   HOOGERBRUGGE PJ, 1992, EUROPHYS LETT, V19, P155, DOI 10.1209/0295-5075/19/3/001
   Hourahine B, 2020, J CHEM PHYS, V152, DOI 10.1063/1.5143190
   Huang R, 2018, PHYS REV MATER, V2, DOI 10.1103/PhysRevMaterials.2.126002
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Husic BE, 2018, J AM CHEM SOC, V140, P2386, DOI 10.1021/jacs.7b12191
   in't Veld PJ, 2008, COMPUT PHYS COMMUN, V179, P320, DOI 10.1016/j.cpc.2008.03.005
   In't Veld PJ, 2003, MACROMOLECULES, V36, P7358, DOI 10.1021/ma0346658
   Isele-Holder RE, 2012, J CHEM PHYS, V137, DOI 10.1063/1.4764089
   Ivanov AV, 2021, COMPUT PHYS COMMUN, V260, DOI 10.1016/j.cpc.2020.107749
   Ivanov AV, 2020, J PHYS-CONDENS MAT, V32, DOI 10.1088/1361-648X/ab8b9c
   Jaime M, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00096-4
   Jaramillo-Botero A, 2011, J COMPUT CHEM, V32, P497, DOI 10.1002/jcc.21637
   Jewett AI, 2021, J MOL BIOL, V433, DOI 10.1016/j.jmb.2021.166841
   Jones RE, 2016, SPRINGER SER MATER S, V245, P223, DOI 10.1007/978-3-319-33480-6_7
   Kadau K, 2004, INT J MOD PHYS C, V15, P193, DOI 10.1142/S0129183104005590
   Kelchner CL, 1998, PHYS REV B, V58, P11085, DOI 10.1103/PhysRevB.58.11085
   Kim SY, 2013, J CHEM PHYS, V139, DOI 10.1063/1.4824389
   Klein ML, 2008, SCIENCE, V321, P798, DOI 10.1126/science.1157834
   Kloss C, 2012, PROG COMPUT FLUID DY, V12, P140, DOI 10.1504/PCFD.2012.047457
   KOFKE DA, 1988, MOL PHYS, V64, P1105, DOI 10.1080/00268978800100743
   Kondratyuk N, 2021, INT J HIGH PERFORM C, V35, P312, DOI 10.1177/10943420211008288
   Kong LT, 2011, COMPUT PHYS COMMUN, V182, P2201, DOI 10.1016/j.cpc.2011.04.019
   KREMER K, 1990, J CHEM PHYS, V92, P5057, DOI 10.1063/1.458541
   Kumar A, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.051401
   Lamoureux G, 2003, J CHEM PHYS, V119, P3025, DOI 10.1063/1.1589749
   Larsen PM, 2016, MODEL SIMUL MATER SC, V24, DOI 10.1088/0965-0393/24/5/055007
   Leroch S, 2016, INT J SOLIDS STRUCT, V81, P188, DOI 10.1016/j.ijsolstr.2015.11.025
   Li Z, 2016, J CHEM PHYS, V145, DOI 10.1063/1.4959121
   Li Z, 2015, J CHEM PHYS, V143, DOI 10.1063/1.4923254
   Li Z, 2014, J COMPUT PHYS, V265, P113, DOI 10.1016/j.jcp.2014.02.003
   Li Z, 2013, PHYS FLUIDS, V25, DOI 10.1063/1.4812366
   Liang T, 2013, MAT SCI ENG R, V74, P255, DOI 10.1016/j.mser.2013.07.001
   Lot R, 2020, COMPUT PHYS COMMUN, V256, DOI 10.1016/j.cpc.2020.107402
   Lubbers Nicholas., 2020, COMMUNICATION
   Lykov K, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005726
   Lysogorskiy Y, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00559-9
   Ma P.-W., 2020, HDB MAT MODELING MET, P1017, DOI DOI 10.1007/978-3-319-44677-6_97
   Ma PW, 2014, PHYS REV B, V90, DOI 10.1103/PhysRevB.90.024425
   Ma PW, 2008, PHYS REV B, V78, DOI 10.1103/PhysRevB.78.024434
   Mackay FE, 2013, COMPUT PHYS COMMUN, V184, P2021, DOI 10.1016/j.cpc.2013.03.024
   Malevanets A, 1999, J CHEM PHYS, V110, P8605, DOI 10.1063/1.478857
   Martínez E, 2012, PHYS REV B, V86, DOI 10.1103/PhysRevB.86.214109
   Mashayak SY, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131754
   Mattox TI, 2018, MOL PHYS, V116, P2061, DOI 10.1080/00268976.2018.1471532
   Meloni S, 2007, J CHEM PHYS, V126, DOI 10.1063/1.2719690
   Milano G, 2005, J PHYS CHEM B, V109, P18609, DOI 10.1021/jp0523571
   Milde F, 2014, COMPUT PART MECH, V1, P211, DOI 10.1007/s40571-014-0017-4
   MINTMIRE JW, 1994, PHYS REV B, V49, P14859, DOI 10.1103/PhysRevB.49.14859
   MITCHELL PJ, 1993, J PHYS-CONDENS MAT, V5, P1031, DOI 10.1088/0953-8984/5/8/006
   Monaghan JJ, 2012, ANNU REV FLUID MECH, V44, P323, DOI 10.1146/annurev-fluid-120710-101220
   Moore SG, 2014, J CHEM PHYS, V140, DOI 10.1063/1.4883695
   Mori H, 2020, PHYS REV MATER, V4, DOI 10.1103/PhysRevMaterials.4.040601
   MORTIER WJ, 1985, J AM CHEM SOC, V107, P829, DOI 10.1021/ja00290a017
   MORTIER WJ, 1986, J AM CHEM SOC, V108, P4315, DOI 10.1021/ja00275a013
   Müller-Plathe F, 1999, PHYS REV E, V59, P4894, DOI 10.1103/PhysRevE.59.4894
   MullerPlathe F, 1997, J CHEM PHYS, V106, P6082, DOI 10.1063/1.473271
   Murdick DA, 2006, PHYS REV B, V73, DOI 10.1103/PhysRevB.73.045206
   Nguyen-Cong K., 2021, SC 21 P INT C HIGH P, DOI [10.1145/3458817.3487400, DOI 10.1145/3458817.3487400]
   Nicholson DA, 2016, J CHEM PHYS, V145, DOI 10.1063/1.4972894
   Nieves P, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.094437
   Noid WG, 2008, J CHEM PHYS, V128, DOI 10.1063/1.2938857
   Noid WG, 2013, J CHEM PHYS, V139, DOI 10.1063/1.4818908
   Noid WG, 2008, J CHEM PHYS, V128, DOI 10.1063/1.2938860
   O'Connor TC, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.047801
   Omelyan IP, 2001, PHYS REV LETT, V86, P898, DOI 10.1103/PhysRevLett.86.898
   Ouldridge TE, 2011, J CHEM PHYS, V134, DOI 10.1063/1.3552946
   Padding JT, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.031402
   PANAGIOTOPOULOS AZ, 1987, MOL PHYS, V61, P813, DOI 10.1080/00268978700101491
   Paquay S, 2016, BIOPHYS J, V110, P1226, DOI 10.1016/j.bpj.2016.02.017
   Parks ML, 2008, COMPUT PHYS COMMUN, V179, P777, DOI 10.1016/j.cpc.2008.06.011
   PARR RG, 1978, J CHEM PHYS, V68, P3801, DOI 10.1063/1.436185
   Perez D, 2016, J CHEM THEORY COMPUT, V12, P18, DOI 10.1021/acs.jctc.5b00916
   Perez D, 2009, ANN REP COMP CHEM, V5, P79, DOI 10.1016/S1574-1400(09)00504-0
   Perriot R, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00708-z
   Pettifor DG, 1999, PHYS REV B, V59, P8487, DOI 10.1103/PhysRevB.59.8487
   Phillips CL, 2010, J CHEM PHYS, V133, DOI 10.1063/1.3481356
   Phillips JC, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0014475
   Plimpton S., 1997, P 8 SIAM C PAR PROC
   Plimpton SJ, 2019, PHYS FLUIDS, V31, DOI 10.1063/1.5108534
   Plimpton SJ, 2021, J PARALLEL DISTR COM, V147, P184, DOI 10.1016/j.jpdc.2020.09.001
   Plimpton SJ, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0014448
   Plimpton SJ, 2013, CURR OPIN SOLID ST M, V17, P271, DOI 10.1016/j.cossms.2013.09.005
   Plimpton SJ, 2012, MRS BULL, V37, P513, DOI 10.1557/mrs.2012.96
   Pollock EL, 1996, COMPUT PHYS COMMUN, V95, P93, DOI 10.1016/0010-4655(96)00043-4
   Pun GPP, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10343-5
   Rackers J.A., 2021, ARXIV PREPRINT ARXIV
   Rackers JA, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5081060
   Rahman A., 1964, PHYS REV           A, V136, P405
   RAPPE AK, 1991, J PHYS CHEM-US, V95, P3358, DOI 10.1021/j100161a070
   Ravelo R, 2004, PHYS REV B, V70, DOI 10.1103/PhysRevB.70.014103
   Reed EJ, 2003, PHYS REV LETT, V90, DOI 10.1103/PhysRevLett.90.235503
   Ren PY, 2003, J PHYS CHEM B, V107, P5933, DOI 10.1021/jp027815+
   RICK SW, 1994, J CHEM PHYS, V101, P6141, DOI 10.1063/1.468398
   Rühle V, 2009, J CHEM THEORY COMPUT, V5, P3211, DOI 10.1021/ct900369w
   Rutherford AM, 2007, J PHYS-CONDENS MAT, V19, DOI 10.1088/0953-8984/19/49/496201
   Rycroft CH, 2009, CHAOS, V19, DOI 10.1063/1.3215722
   Salerno KM, 2018, PHYS REV E, V98, DOI 10.1103/PhysRevE.98.050901
   SANDERSON RT, 1983, J AM CHEM SOC, V105, P2259, DOI 10.1021/ja00346a026
   Santos AP, 2020, PHYS REV E, V102, DOI 10.1103/PhysRevE.102.032903
   Seko A, 2019, PHYS REV B, V99, DOI 10.1103/PhysRevB.99.214108
   Shan T.-R, 2010, PHYS REV B, V82
   Shan TR, 2010, PHYS REV B, V81, DOI 10.1103/PhysRevB.81.125328
   Shapeev AV, 2016, MULTISCALE MODEL SIM, V14, P1153, DOI 10.1137/15M1054183
   Shell MS, 2016, ADV CHEM PHYS, V161, P395
   Shi Y, 2013, J CHEM THEORY COMPUT, V9, P4046, DOI 10.1021/ct4003702
   Shinoda W, 2007, MOL SIMULAT, V33, P27, DOI 10.1080/08927020601054050
   Shire T, 2021, COMPUT PART MECH, V8, P653, DOI 10.1007/s40571-020-00361-2
   Silling SA, 2021, THEOR APPL FRACT MEC, V113, DOI 10.1016/j.tafmec.2021.102947
   Silling SA, 2017, INT J IMPACT ENG, V107, P47, DOI 10.1016/j.ijimpeng.2017.04.022
   Singraber A, 2019, J CHEM THEORY COMPUT, V15, P3075, DOI 10.1021/acs.jctc.8b01092
   Smith DGA, 2021, WIRES COMPUT MOL SCI, V11, DOI 10.1002/wcms.1491
   Smith J.S., 2021, NAT COMMUN, V12, P1
   Sorensen MR, 2000, J CHEM PHYS, V112, P9599, DOI 10.1063/1.481576
   Stevens MJ, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5055243
   Stevens MJ, 2004, J CHEM PHYS, V121, P11942, DOI 10.1063/1.1814058
   STREITZ FH, 1994, PHYS REV B, V50, P11996, DOI 10.1103/PhysRevB.50.11996
   Stuart SJ, 2000, J CHEM PHYS, V112, P6472, DOI 10.1063/1.481208
   Stukowski A, 2010, MODEL SIMUL MATER SC, V18, DOI 10.1088/0965-0393/18/1/015012
   Sugita Y, 1999, CHEM PHYS LETT, V314, P141, DOI 10.1016/S0009-2614(99)01123-9
   Sulc P, 2012, J CHEM PHYS, V137, DOI 10.1063/1.4754132
   Surblys D, 2019, PHYS REV E, V99, DOI 10.1103/PhysRevE.99.051301
   Surh MP, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.085701
   Sutmann G., 2014, P SOC ENG SCI 51 ANN
   Swamy V, 2002, SURF SCI, V504, P115, DOI 10.1016/S0039-6028(01)01925-2
   Tadmor EB, 2011, JOM-US, V63, P17, DOI 10.1007/s11837-011-0102-6
   TERSOFF J, 1988, PHYS REV B, V37, P6991, DOI 10.1103/PhysRevB.37.6991
   Thomas BS, 2004, PHYS REV B, V69, DOI 10.1103/PhysRevB.69.144122
   Thompson AP, 2015, J COMPUT PHYS, V285, P316, DOI 10.1016/j.jcp.2014.12.018
   Thompson AP, 2009, J CHEM PHYS, V131, DOI 10.1063/1.3245303
   Todorov IT, 2006, J MATER CHEM, V16, P1911, DOI 10.1039/b517931a
   Tranchida J, 2018, J COMPUT PHYS, V372, P406, DOI 10.1016/j.jcp.2018.06.042
   Tribello GA, 2014, COMPUT PHYS COMMUN, V185, P604, DOI 10.1016/j.cpc.2013.09.018
   Trott C., 2021, IEEE T PARALL DISTR, P1
   Trott C, 2021, COMPUT SCI ENG, V23, P10, DOI 10.1109/MCSE.2021.3098509
   Nguyen TD, 2019, COMPUT PHYS COMMUN, V243, P12, DOI 10.1016/j.cpc.2019.05.010
   Nguyen TD, 2019, COMPUT PHYS COMMUN, V241, P80, DOI 10.1016/j.cpc.2019.03.006
   Nguyen TD, 2014, NANOSCALE, V6, P3083, DOI 10.1039/c3nr05413f
   Tsuzuki H, 2007, COMPUT PHYS COMMUN, V177, P518, DOI 10.1016/j.cpc.2007.05.018
   TUCKERMAN M, 1992, J CHEM PHYS, V97, P1990, DOI 10.1063/1.463137
   Uzdin VM, 2018, J MAGN MAGN MATER, V459, P236, DOI 10.1016/j.jmmm.2017.10.100
   van Duin ACT, 2001, J PHYS CHEM A, V105, P9396, DOI 10.1021/jp004368u
   van Duin ACT, 2003, J PHYS CHEM A, V107, P3803, DOI 10.1021/jp0276303
   VERLET L, 1967, PHYS REV, V159, P98, DOI 10.1103/PhysRev.159.98
   Verwey E. J. W., 1999, THEORY STABILITY LYO
   Voter AF, 1998, PHYS REV B, V57, P13985, DOI 10.1103/PhysRevB.57.R13985
   Voter AF, 1997, J CHEM PHYS, V106, P4665, DOI 10.1063/1.473503
   Voth Gregory A., 2009, P1
   Wang H, 2018, COMPUT PHYS COMMUN, V228, P178, DOI 10.1016/j.cpc.2018.03.016
   Wang J, 2011, GRANUL MATTER, V13, P1, DOI 10.1007/s10035-010-0217-4
   Ward DK, 2012, PHYS REV B, V85, DOI 10.1103/PhysRevB.85.115206
   Wen MJ, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-00390-8
   Wen MJ, 2019, PHYS REV B, V100, DOI 10.1103/PhysRevB.100.195419
   Wood MA, 2018, PHYS REV B, V97, DOI 10.1103/PhysRevB.97.014109
   Wood MA, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5017641
   Yang YI, 2019, J CHEM PHYS, V151, DOI 10.1063/1.5109531
   Yanxon H, 2020, J CHEM PHYS, V153, DOI 10.1063/5.0014677
   Yu A, 2021, BIOPHYS J, V120, P1097, DOI 10.1016/j.bpj.2020.10.048
   Yu J., 2007, PHYS REV B, V75
   Zepeda-Ruiz LA, 2017, NATURE, V550, P492, DOI 10.1038/nature23472
   Zhou XW, 2008, PHYS REV B, V78, DOI 10.1103/PhysRevB.78.224307
   Zhou XW, 2004, PHYS REV B, V69, DOI 10.1103/PhysRevB.69.035402
   Zhou YG, 2020, PHYS REV B, V101, DOI 10.1103/PhysRevB.101.224303
   Zuo YX, 2020, J PHYS CHEM A, V124, P731, DOI 10.1021/acs.jpca.9b08723
NR 246
TC 1852
Z9 1861
U1 192
U2 593
PD FEB
PY 2022
VL 271
AR 108171
DI 10.1016/j.cpc.2021.108171
EA OCT 2021
UT WOS:000720461800009
HC Y
HP Y
DA 2023-11-16
ER

PT J
AU Lu, J
   Jia, HY
   Verma, N
   Jha, NK
AF Lu, Jie
   Jia, Hongyang
   Verma, Naveen
   Jha, Niraj K.
TI Genetic Programming for Energy-Efficient and Energy-Scalable Approximate
   Feature Computation in Embedded Inference Systems
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Approximate computing; energy efficiency; error-aware inference; feature
   extraction; genetic programming; machine learning
ID CLASSIFICATION; RESILIENCE; SIGNALS; DESIGN
AB With the increasing interest in deploying embedded sensors in a range of applications, there is also interest in deploying embedded inference capabilities. Doing so under the strict and often variable energy constraints of the embedded platforms requires algorithmic, in addition to circuit and architectural, approaches to reducing energy. A broad approach that has recently received considerable attention in the context of inference systems is approximate computing. This stems from the observation that many inference systems exhibit various forms of tolerance to data noise. While some systems have demonstrated significant approximation-versus-energy knobs to exploit this, they have been applicable to specific kernels and architectures; the more generally available knobs have been relatively weak, resulting in large data noise for relatively modest energy savings (e.g., voltage overscaling, bit-precision scaling). In this work, we explore the use of genetic programming (GP) to compute approximate features. Further, we leverage a method that enhances tolerance to feature-data noise through directed retraining of the inference stage. Previous work in GP has shown that it generalizes well to enable approximation of a broad range of computations, raising the potential for broad applicability of the proposed approach. The focus on feature extraction is deliberate because they involve diverse, often highly nonlinear, operations, challenging general applicability of energy-reducing approaches. We evaluate the proposed methodologies through two case studies, based on energy modeling of a custom low-power microprocessor with a classification accelerator. The first case study is on electroencephalogram-based seizure detection. We find that the choice of two primitive functions (square root, subtraction) out of seven possible primitive functions (addition, subtraction, multiplication, logarithm, exponential, square root, and square) enables us to approximate features in 0.41mJ per feature vector (FV), as compared to 4.79mJ per FV required for baseline feature extraction. This represents a feature extraction energy reduction of 11.68x. The important system-level performance metrics for seizure detection are sensitivity, latency, and number of false alarms per hour. Our set of GP models achieves 100 percent sensitivity, 4.37 second latency, and 0.15 false alarms per hour. The baseline performance is 100 percent sensitivity, 3.84 second latency, and 0.06 false alarms per hour. The second case study is on electrocardiogram-based arrhythmia detection. In this case, just one primitive function ( multiplication) suffices to approximate features in 1.13 mu J per FV, as compared to 11.69 mu J per FV required for baseline feature extraction. This represents a feature extraction energy reduction of 10.35x. The important system-level metrics in this case are sensitivity, specificity, and accuracy. Our set of GP models achieves 81.17 percent sensitivity, 80.63 percent specificity, and 81.86 percent accuracy, whereas the baseline achieves 82.05 percent sensitivity, 88.12 percent specificity, and 87.92 percent accuracy. These case studies demonstrate the possibility of a significant reduction in feature extraction energy at the expense of a slight degradation in system performance.
C1 [Lu, Jie; Jia, Hongyang; Verma, Naveen; Jha, Niraj K.] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Lu, J (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM jielu@princeton.edu; hjia@princeton.edu; nverma@princeton.edu;
   jha@princeton.edu
CR Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   [Anonymous], 2016, ACM COMPUT SURV, DOI DOI 10.1145/2893356
   [Anonymous], TECH REP
   Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P1197, DOI 10.1016/S0031-3203(01)00108-X
   Bhowan U, 2013, IEEE T EVOLUT COMPUT, V17, P368, DOI 10.1109/TEVC.2012.2199119
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chippa VK, 2010, DES AUT CON, P555
   Chippa VK, 2014, IEEE T VLSI SYST, V22, P2004, DOI 10.1109/TVLSI.2013.2276759
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Estévez PA, 2005, ELECTRON LETT, V41, P1141, DOI 10.1049/el:20052475
   Gandomi AH, 2012, NEURAL COMPUT APPL, V21, P171, DOI 10.1007/s00521-011-0734-z
   García-Pedrajas N, 2003, IEEE T NEURAL NETWOR, V14, P575, DOI 10.1109/TNN.2003.810618
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Guo H, 2005, IEEE T SYST MAN CY B, V35, P89, DOI 10.1109/TSMCB.2004.841426
   Guyon I., 2008, FEATURE EXTRACTION F, V207
   Harvey DY, 2015, IEEE T EVOLUT COMPUT, V19, P474, DOI 10.1109/TEVC.2014.2341451
   IAR Systems, 2015, SLAA329 IAR SYST
   Jia HY, 2017, SYMP VLSI CIRCUITS, pC28, DOI 10.23919/VLSIC.2017.8008535
   Kahng AB, 2012, DES AUT CON, P820
   Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235
   Kotani M., 1999, 1999 Third International Conference on Knowledge-Based Intelligent Information Engineering Systems. Proceedings (Cat. No.99TH8410), P149, DOI 10.1109/KES.1999.820141
   Koza J. R., 1992, GENETIC PROGRAMMING, P17
   Kumar R, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P81
   Kyong Ho Lee, 2013, 2013 Symposium on VLSI Circuits, pC250
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Lingamneni A., 2014, P IEEE CUST INT CIRC, P1
   Martis RJ, 2012, J MED SYST, V36, P677, DOI 10.1007/s10916-010-9535-7
   Miguel J., 2013, P IEEE ACM INT S MIC, P127
   Miller JF, 2000, LECT NOTES COMPUT SC, V1802, P121
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Moriarty DE, 1997, EVOL COMPUT, V5, P373, DOI 10.1162/evco.1997.5.4.373
   Nag K, 2016, IEEE T CYBERNETICS, V46, P499, DOI 10.1109/TCYB.2015.2404806
   Park J, 2010, IEEE T VLSI SYST, V18, P787, DOI 10.1109/TVLSI.2009.2016839
   Parkins AD, 2004, SIGNAL PROCESS, V84, P2345, DOI 10.1016/j.sigpro.2004.07.027
   Perterson L., 2011, COMPUTER NETWORKS
   Poli R., 2008, FIELD GUIDE GENETIC
   Saripalli V, 2011, IEEE J EM SEL TOP C, V1, P109, DOI 10.1109/JETCAS.2011.2158343
   Sherrah J. R., 1997, Genetic Programming 1997 Proceedings of the Second Annual Conference, P304
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Stanley K. O., 2002, P GENETIC EVOLUTIONA, P569
   Struharik J. R., 2011, Proceedings of the 2011 IEEE 9th International Symposium on Intelligent Systems and Informatics (SISY 2011), P41, DOI 10.1109/SISY.2011.6034358
   Venkat K., 2006, TECH REP
   Verma N, 2012, INT CONF ACOUST SPEE, P5285, DOI 10.1109/ICASSP.2012.6289113
   von Sydow T, 2006, IEEE INT CONF ASAP, P125
   Wang Z, 2015, IEEE T VLSI SYST, V23, P1459, DOI 10.1109/TVLSI.2014.2342153
   Wang Z, 2015, IEEE T CIRCUITS-I, V62, P1136, DOI 10.1109/TCSI.2015.2395591
   Xie Z, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P527, DOI 10.1109/ICSC.2007.52
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
NR 48
TC 8
Z9 8
U1 1
U2 9
PD FEB
PY 2018
VL 67
IS 2
BP 222
EP 236
DI 10.1109/TC.2017.2738642
UT WOS:000422753800006
DA 2023-11-16
ER

EF