FN Clarivate Analytics Web of Science
VR 1.0
PT C
AU Yoshikawa, M
   Terai, H
AF Yoshikawa, Masaya
   Terai, Hidekazu
BE Mastorakis, NE
   Mladenov, V
   Bojkovic, Z
   Simian, D
   Kartalopoulos, S
   Varonides, A
   Udriste, C
   Kindler, E
   Narayanan, S
   Mauri, JL
   Parsiani, H
   Man, KL
TI Genetic-based Machine Learning using Hardware Accelerator
SO PROCEEDINGS OF THE 12TH WSEAS INTERNATIONAL CONFERENCE ON CIRCUITS: NEW
   ASPECTS OF CIRCUITS
SE Recent Advances in Electrical Engineering
DT Proceedings Paper
CT 12th WSEAS International Conference on Circuits
CY JUL 22-25, 2008
CL Heraklion, GREECE
DE Evolutionary robotics; Hardware accelerator; if-then rules;
   Genetic-based machine learning; Quasi-ecosystem
AB This paper discusses new genetic-based learning system. The proposed learning system adopts new if-then rules for acquiring a strategy of the robots. Moreover, it introduces novel hardware accelerator in order to reduce simulation time, since the genetics-based machine learning requires very long computational time. Experiments using quasi-ecosystem demonstrate not only the effectiveness of the proposed learning algorithm, but also that of the proposed architecture of hardware accelerator.
C1 [Yoshikawa, Masaya] Meijo Univ, Dept Informat Engn, 1-501 Tenpaku, Aichi 46882530, Japan.
   [Terai, Hidekazu] Ritsumeikan Univ, Dept VLSI Syst Design, Shiga, 5258577, Japan.
RP Yoshikawa, M (corresponding author), Meijo Univ, Dept Informat Engn, 1-501 Tenpaku, Aichi 46882530, Japan.
CR [Anonymous], 1989, GENETIC ALGORITHM SE
   Graham P, 1996, IEEE SYMPOSIUM ON FPGAS FOR CUSTOM COMPUTING MACHINES, PROCEEDINGS, P216, DOI 10.1109/FPGA.1996.564847
   Holland J. H., 1992, ADAPTATION NATURAL A, DOI DOI 10.7551/MITPRESS/1090.001.0001
   IMAI T, 2002, P IEEE INT C AC SPEE, V3, P3148
   ISHIGURO A, 1999, P IEEE C INT SYST MA, V13, P239
   Kubota N, 2003, IEEE INT CONF FUZZY, P248
   Kubota N, 2001, IEEE C EVOL COMPUTAT, P115, DOI 10.1109/CEC.2001.934379
   KUBOTA N, 2000, P 26 ANN C IEEE IND, V3, P2105
   SCOTT SD, 1995, P ACM SIGDA 3 INT S, P53, DOI DOI 10.1109/FPGA.1995.241945
NR 9
TC 0
Z9 0
U1 0
U2 0
PY 2008
BP 284
EP +
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Brennsteiner, S
   Arslan, T
   Thompson, JS
   McCormick, A
AF Brennsteiner, Stefan
   Arslan, Tughrul
   Thompson, John S.
   McCormick, Andrew
GP IEEE
TI A machine learning enhanced approximate message passing massive MIMO
   accelerator
SO 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS
   AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC
   ERA
DT Proceedings Paper
CT IEEE International Conference on Artificial Intelligence Circuits and
   Systems (AICAS) - Intelligent Technology in the Post-Pandemic Era
CY JUN 13-15, 2022
CL Incheon, SOUTH KOREA
AB Machine learning in the physical layer of communication systems currently receives much attention due to its potential to improve performance over difficult or unknown channels. Model-driven machine learning combines well-established algorithms with machine learning enhancements to realize these performance gains while keeping computational complexity within practical limits. In this work, we present the first model-driven machine-learning accelerator based on Orthogonal Approximate Message Passing (OAMP) for massive MIMO. The accelerator is configurable to support various machine learning enhancements such as those used in the OAMPNet and MMNet algorithms. The accelerator architecture is implemented as a deep pipeline to maximize throughput and we explore a range of antenna, user, and modulation configurations. Our results show the feasibility of deploying machine learning enhanced algorithms in future physical layer processors.
C1 [Brennsteiner, Stefan; Arslan, Tughrul] Univ Edinburgh, Sch Engn, Inst Integrated Micro & Nano Syst, Edinburgh, Midlothian, Scotland.
   [Thompson, John S.] Univ Edinburgh, Sch Engn, Inst Digital Commun, Edinburgh, Midlothian, Scotland.
   [McCormick, Andrew] Alpha Data Parallel Syst Ltd, Edinburgh, Midlothian, Scotland.
RP Brennsteiner, S (corresponding author), Univ Edinburgh, Sch Engn, Inst Integrated Micro & Nano Syst, Edinburgh, Midlothian, Scotland.
CR 3GPP, 2019, 21915 3GPP TR
   Felix A, 2018, IEEE INT WORK SIGN P, P56
   He HT, 2018, IEEE GLOB CONF SIG, P584, DOI 10.1109/GlobalSIP.2018.8646357
   Jeon C, 2019, Arxiv, DOI arXiv:1908.03288
   Khani M, 2019, Arxiv, DOI arXiv:1906.04610
   Li KP, 2017, CONF REC ASILOMAR C, P1532, DOI 10.1109/ACSSC.2017.8335613
   Ma JJ, 2017, IEEE ACCESS, V5, P2020, DOI 10.1109/ACCESS.2017.2653119
   O'Shea T, 2017, IEEE T COGN COMMUN, V3, P563, DOI 10.1109/TCCN.2017.2758370
   Samuel N, 2019, IEEE T SIGNAL PROCES, V67, P2554, DOI 10.1109/TSP.2019.2899805
   Sesia S., 2011, LTE THE UMTS LONG TE
   Tan X., 2018, ARXIV
   Wang TQ, 2017, CHINA COMMUN, V14, P92, DOI 10.1109/CC.2017.8233654
   Ye H, 2018, IEEE WIREL COMMUN LE, V7, P114, DOI 10.1109/LWC.2017.2757490
   Zhang CY, 2019, Arxiv, DOI arXiv:1803.04311
NR 14
TC 0
Z9 0
U1 2
U2 3
PY 2022
BP 443
EP 446
DI 10.1109/AICAS54282.2022.9869942
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lee, SC
   Han, TH
AF Lee, Seung Chan
   Han, Tae Hee
GP IEEE
TI A 4-way Matrix Multiply Unit for High Throughput Machine Learning
   Accelerator
SO 2019 INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC)
SE International SoC Design Conference
DT Proceedings Paper
CT 16th International System-on-Chip Design Conference (ISOCC)
CY OCT 06-09, 2019
CL SOUTH KOREA
DE machine learning accelerator; neural network; matrix multiply unit;
   systolic array
AB With the rapid growth of modern applications based on machine learning, neural network (NN) algorithm has been widely used in various fields. Accordingly, machine learning accelerators with high performance based on FPGA and ASIC design have become necessary. Machine learning accelerators generally include a matrix multiply unit that performs arithmetic. However, despite the development of dedicated hardware, some NN algorithms still suffer from performance degradation due to computation bounds in the matrix multiply units. Resolving the computation bound is crucial for high throughput machine learning accelerator. In this paper, we propose a 4-way matrix unit to resolve the computation bound by minimizing idle state operation logic and improving overall utilization. A 4-way matrix multiply unit resulted in an average throughput improvement of 29 percent and a 24 percent increase in the total area, comparing to the conventional systolic array-based matrix multiply unit.
C1 [Lee, Seung Chan] Sungkyunkwan Univ, Dept Semicond & Display Engn, Suwon, South Korea.
   [Han, Tae Hee] Sungkyunkwan Univ, Dept Artificial Intelligence, Suwon, South Korea.
RP Lee, SC (corresponding author), Sungkyunkwan Univ, Dept Semicond & Display Engn, Suwon, South Korea.
EM chan0614@skku.edu; than@skku.edu
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 4
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 113
EP 114
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Tian, SQ
   Moini, S
   Wolnikowski, A
   Holcomb, D
   Tessier, R
   Szefer, J
AF Tian, Shanquan
   Moini, Shayan
   Wolnikowski, Adam
   Holcomb, Daniel
   Tessier, Russell
   Szefer, Jakub
GP IEEE Comp Soc
TI Remote Power Attacks on the Versatile Tensor Accelerator in Multi-Tenant
   FPGAs
SO 2021 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2021)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 29th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 09-12, 2021
CL ELECTR NETWORK
DE Machine Learning Security; FPGA Security; Hardware Accelerators;
   Hardware Security
AB Architectural details of machine learning models are crucial pieces of intellectual property in many applications. Revealing the structure or types of layers in a model can result in a leak of confidential or proprietary information. This issue becomes especially concerning when the machine learning models are executed on accelerators in multi-tenant FPGAs where attackers can easily co-locate sensing circuitry next to the victim's machine learning accelerator. To evaluate such threats, we present the first remote power attack that can extract details of machine learning models executed on an off-the-shelf domain-specific instruction set architecture (ISA) based neural network accelerator implemented in an FPGA. By leveraging a time-to-digital converter (TDC), an attacker can deduce the composition of instruction groups executing on the victim accelerator, and recover parameters of General Matrix Multiplication (GEMM) instructions within a group, all without requiring physical access to the FPGA. With this information, an attacker can then reverse-engineer the structure and layers of machine learning models executing on the accelerator, leading to potential theft of proprietary information.
C1 [Tian, Shanquan; Wolnikowski, Adam; Szefer, Jakub] Yale Univ, New Haven, CT 06520 USA.
   [Moini, Shayan; Holcomb, Daniel; Tessier, Russell] Univ Massachusetts, Amherst, MA 01003 USA.
RP Tian, SQ (corresponding author), Yale Univ, New Haven, CT 06520 USA.
EM shanquan.tian@yale.edu; smoini@umass.edu; adam.wolnikowski@yale.edu;
   dholcomb@umass.edu; tessier@umass.edu; jakub.szefer@yale.edu
CR Amazon Web Services, AMAZON EC2 F1 INSTAN
   Apache MXNet, MXN GLUON MOD ZOO MXN GLUON MOD ZOO
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Boutros A., 2020, INT C FIELD PROGRAMM
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Dubey A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P197, DOI [10.1109/HOST45689.2020.9300276, 10.1109/host45689.2020.9300276]
   Giechaskiel I., 2019, ACM T RECONFIGURABLE, V12, P1
   Gnad D. R., IACR CRYPTOL EPRINT, V2019, P1394
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Mbongue JM, 2020, IEEE INT CONF ASAP, P125, DOI 10.1109/ASAP49362.2020.00030
   Microsoft Azure, DEPL ML MOD FIELD PR DEPL ML MOD FIELD PR
   Moini S., DESIGN AUTOMATION TE
   Moini S, 2020, MIDWEST SYMP CIRCUIT, P941, DOI [10.1109/MWSCAS48704.2020.9184683, 10.1109/mwscas48704.2020.9184683]
   Moreau T., 2018, ARXIV PREPRINT ARXIV
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Ramesh Chethan, 2018, 2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), P45, DOI 10.1109/FCCM.2018.00016
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   VTA tutorial, SIMPL MATR MULT SIMPL MATR MULT
   Wei JY, 2020, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN48063.2020.00031
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zick K. M., 2013, P ACM SIGDA INT S FI, P101, DOI DOI 10.1145/2435264.2435283
NR 29
TC 12
Z9 12
U1 1
U2 3
PY 2021
BP 242
EP 246
DI 10.1109/FCCM51124.2021.00037
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yu, Q
   Wang, C
   Ma, X
   Li, X
   Zhou, XH
AF Yu, Qi
   Wang, Chao
   Ma, Xiang
   Li, Xi
   Zhou, Xuehai
GP IEEE
TI A Deep Learning prediction process accelerator based FPGA
SO 2015 15TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID
   COMPUTING
SE IEEE-ACM International Symposium on Cluster Cloud and Grid Computing
DT Proceedings Paper
CT 2015 15th IEEE ACM International Symposium on Cluster Cloud and Grid
   Computing (CCGrid 2015)
CY MAY 04-07, 2015
CL Shenzhen, PEOPLES R CHINA
DE FPGA; deep learning; prediction process; accelerator
AB Recently, machine learning is widely used in applications and cloud services. And as the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. To give users better experience, high performance implementations of deep learning applications seem very important. As a common means to accelerate algorithms, FPGA has high performance, low power consumption, small size and other characteristics. So we use FPGA to design a deep learning accelerator, the accelerator focuses on the implementation of the prediction process, data access optimization and pipeline structure. Compared with Core 2 CPU 2.3GHz, our accelerator can achieve promising result.
C1 [Yu, Qi; Wang, Chao; Ma, Xiang; Li, Xi; Zhou, Xuehai] Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
RP Yu, Q (corresponding author), Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
EM yuiq1123@mail.ustc.edu.cn; cswang@ustc.edu.cn; supermaxiang@gmail.com;
   llxx@ustc.edu.cn; xhzhou@ustc.edu.cn
CR [Anonymous], 2010, MOMENTUM
   [Anonymous], 2014, PROC IEEE C EXPO TRA
   Bengio Y, 2006, ADV NEURAL INFORM PR, P19, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Farabet C., 2011, MACHINE LEARNING VER
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kim SK, 2010, ANN IEEE SYM FIELD P, P201, DOI 10.1109/FCCM.2010.38
   Le Ly D, 2010, IEEE T NEURAL NETWOR, V21, P1780, DOI 10.1109/TNN.2010.2073481
NR 9
TC 37
Z9 39
U1 4
U2 35
PY 2015
BP 1159
EP 1162
DI 10.1109/CCGrid.2015.114
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Wang, YZ
   Xie, F
AF Wang, Yanzhao
   Xie, Fei
GP IEEE
TI Extending Tensor Virtual Machine to Support Deep-Learning Accelerators
   with Convolution Cores
SO 2022 26TH INTERNATIONAL CONFERENCE ON ENGINEERING OF COMPLEX COMPUTER
   SYSTEMS (ICECCS 2022)
DT Proceedings Paper
CT 26th International Conference on Engineering of Complex Computer Systems
   (ICECCS)
CY MAR 26-30, 2022
CL ELECTR NETWORK
DE Application Software; Software Architecture; Artificial Intelligence;
   Open Source Software
AB Deep-learning accelerators are increasingly popular. There are two prevalent accelerator architectures: one based on general matrix multiplication units and the other on convolution cores. However, Tensor Virtual Machine (TVM), a widely used deep-learning compiler stack, does not support the latter. This paper proposes a general framework for extending TVM to support deep-learning accelerators with convolution cores. We have applied it to two well-known accelerators: Nvidia's NVDLA and Bitmain's BM1880 successfully. Deep-learning workloads can now be readily deployed to these accelerators through TVM and executed efficiently. This framework can extend TVM to other accelerators with minimum effort.
C1 [Wang, Yanzhao; Xie, Fei] Portland State Univ, Dept Comp Sci, Portland, OR 97229 USA.
RP Wang, YZ (corresponding author), Portland State Univ, Dept Comp Sci, Portland, OR 97229 USA.
EM wyanzhao@pdx.edu; xie@pdx.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   alibabacloud, ALIBABA HANGUANG 800
   Black David C., 2009, SYSTEMC GROUND, V71
   Chen TQ, 2015, Arxiv, DOI arXiv:1512.01274
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   github, INTEGRATE NVDLA AND
   Google, EDGE TPU
   Hatcher WG, 2018, IEEE ACCESS, V6, P24411, DOI 10.1109/ACCESS.2018.2830661
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lin WF, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P214, DOI [10.1109/AICAS.2019.8771510, 10.1109/aicas.2019.8771510]
   Moreau T, 2019, Arxiv, DOI arXiv:1807.04188
   nvdla, NVDLA VIRTUAL PLATFO
   Nvdla, US
   ONNX, US
   sophon, BITMAIN SOPHON
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   T. L. Group, NEXT GENERATION PROC
NR 20
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 189
EP 194
DI 10.1109/ICECCS54210.2022.00031
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Shafique, M
AF Shafique, Muhammad
GP IEEE
TI Emerging Trends in Multi-Accelerator and Distributed System for ML:
   Devices, Architectures, Tools and Applications
SO 2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC
DT Proceedings Paper
CT 60th ACM/IEEE Design Automation Conference (DAC)
CY JUL 09-13, 2023
CL San Francisco, CA
DE Multi-Accelerator; Distributed System; Machine Learning; Deep Learning;
   AI; DNN; Architecture; Memory; Energy; Efficiency
AB As the complexity and diversity of machine/deep learning models is increasing at a rapid pace, multi-accelerator and distributed systems are becoming a critical component of the machine learning (ML) stack. Besides efficient compute engines and communication mechanisms, these systems also require intelligent strategies for mapping workloads to accelerators and memory management to achieve high performance and energy efficiency, while meeting the demands for high-performance ML/AI systems. This article presents an overview of the emerging trends in multi-accelerator and distributed systems designed for handling complex AI-powered application workloads.
C1 [Shafique, Muhammad] New York Univ NYU, Div Engn, EBrain Lab, Abu Dhabi, U Arab Emirates.
RP Shafique, M (corresponding author), New York Univ NYU, Div Engn, EBrain Lab, Abu Dhabi, U Arab Emirates.
EM muhammad.shafique@nyu.edu
CR Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dagli I., 2021, 2021 IEEE ACM RED SC, P1
   Dagli I, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P1069, DOI 10.1145/3489517.3530572
   Fuchs A, 2019, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2019.00023
   Ghasemi M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2021), P25, DOI 10.1109/SMARTCOMP52413.2021.00024
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lou W, 2021, IEEE COMPUT SOC CONF, P3104, DOI 10.1109/CVPRW53098.2021.00347
   Pal S, 2019, IEEE MICRO, V39, P91, DOI 10.1109/MM.2019.2935967
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Tan ZH, 2021, CONF PROC INT SYMP C, P1013, DOI 10.1109/ISCA52012.2021.00083
   Xiaodong Yi, 2020, CoNEXT '20: Proceedings of the 16th International Conference on emerging Networking EXperiments and Technologies, P93, DOI 10.1145/3386367.3432728
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang XF, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415609
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 19
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/DAC56929.2023.10247935
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Papandreou, N
   van Lunteren, J
   Anghel, A
   Parnell, T
   Petermann, M
   Stanisavljevic, M
   Lichtenau, C
   Sica, A
   Röhm, D
   Tzortzatos, E
   Pozidis, H
AF Papandreou, Nikolaos
   van Lunteren, Jan
   Anghel, Andreea
   Parnell, Thomas
   Petermann, Martin
   Stanisavljevic, Milos
   Lichtenau, Cedric
   Sica, Andrew
   Roehm, Dominic
   Tzortzatos, Elpida
   Pozidis, Haralampos
GP IEEE
TI Acceleration of Decision-Tree Ensemble Models on the IBM Telum Processor
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, ISCAS
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT 56th IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 21-25, 2023
CL Monterey, CA
DE Machine learning; decision-trees; gradient-boosting machines; inference;
   AI accelerator
AB This paper presents a tensor-based algorithm that leverages a hardware accelerator for inferencing decision-tree-based machine learning models. The algorithm has been integrated in a public software library and is demonstrated on an IBM z16 server, using the Telum processor with the Integrated Accelerator for AI. We describe the architecture and implementation of the algorithm and present experimental results that demonstrate its superior runtime performance compared with popular CPU-based machine learning inference implementations.
C1 [Papandreou, Nikolaos; van Lunteren, Jan; Anghel, Andreea; Parnell, Thomas; Petermann, Martin; Stanisavljevic, Milos; Pozidis, Haralampos] IBM Res Europe, Ruschlikon, Switzerland.
   [Lichtenau, Cedric; Roehm, Dominic] IBM Deutschland R&D GmbH, Boblingen, Germany.
   [Sica, Andrew; Tzortzatos, Elpida] IBM Syst, Poughkeepsie, NY USA.
   [Stanisavljevic, Milos] Axelera AI, Zurich, Switzerland.
RP Papandreou, N (corresponding author), IBM Res Europe, Ruschlikon, Switzerland.
CR [Anonymous], BIN TREE WIK
   [Anonymous], PRED MOD MARK LANG P
   [Anonymous], 2022, KAGGL STAT DAT SCI M
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Dunner C., 2018, ADV NEURAL INFORM PR, P250
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   IBM Z Deep Neural Network (zDNN), IBM DEEP NEUR NETW Z
   Ke G., 2017, ADV NEURAL INFORM PR, V30, P3146, DOI DOI 10.5555/3294996.3295074
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lettich F., 2018, IEEE T PARALL DISTR, V30, P2075
   Lichtenau C, 2022, CONF PROC INT SYMP C, P1012, DOI 10.1145/3470496.3533042
   Nakandala S, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P899
   ONNX, US
   Prokhorenkova L., 2017, P 32 INT C NEURAL IN, P6638, DOI 10.48550/arxiv.1706.09516
   Rai A, 2020, J ACAD MARKET SCI, V48, P137, DOI 10.1007/s11747-019-00710-5
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajja S, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), P281, DOI 10.1145/3430984.3430995
   Shwartz-Ziv R, 2022, INFORM FUSION, V81, P84, DOI 10.1016/j.inffus.2021.11.011
   Snap Machine Learning (Snap ML), SNAP MACH LEARN SNAP
   Xia YF, 2017, EXPERT SYST APPL, V78, P225, DOI 10.1016/j.eswa.2017.02.017
   Xie Z, 2021, PROCEEDINGS OF THE SIXTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS '21), P426, DOI 10.1145/3447786.3456251
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/ISCAS46773.2023.10181908
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nakai, T
   Suzuki, D
   Fujino, T
AF Nakai, Tsunato
   Suzuki, Daisuke
   Fujino, Takeshi
BE Zhou, J
   Adepu, S
   Alcaraz, C
   Batina, L
   Casalicchio, E
   Chattopadhyay, S
   Jin, C
   Lin, J
   Losiouk, E
   Majumdar, S
   Meng, W
   Picek, S
   Shao, J
   Su, C
   Wang, C
   Zhauniarovich, Y
   Zonouz, S
TI Towards Isolated AI Accelerators with OP-TEE on SoC-FPGAs
SO APPLIED CRYPTOGRAPHY AND NETWORK SECURITY WORKSHOPS, ACNS 2022
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 20th International Conference on Applied Cryptography and Network
   Security (ACNS)
CY JUN 20-23, 2022
CL ELECTR NETWORK
DE Trusted execution environment; Arm TrustZone; NVDLA; ZynqMPSoC
AB An artificial intelligence (AI) accelerator is a specialized hardware accelerator designed to accelerate machine learning applications. The machine learning applications may require an isolated execution for the confidentiality of model information and processing data and the integrity of the application tasks. For example, when critical applications such as biometrics use machine learning, the applications are required to execute in a trusted environment isolated not to be compromised by the other applications. The isolated execution of a machine learning application using an AI accelerator is often achieved with a proprietary hardware architecture consisting of dedicated security circuits for the accelerator. On the other hand, several previous works have proposed using open-source or general-purpose security functions for the isolation execution to reduce design costs and commonly apply to various accelerators. This paper proposes an isolated execution method of AI accelerators using OP-TEE, an open-source Trusted Execution Environment (TEE) implementing the Arm TrustZone technology. The contribution is to analyze the security threats of AI accelerators, propose the countermeasure based on OP-TEE, and evaluate the implementation of the isolated execution.
C1 [Nakai, Tsunato; Suzuki, Daisuke] Mitsubishi Electr Corp, Tokyo, Japan.
   [Nakai, Tsunato; Fujino, Takeshi] Ritsumeikan Univ, Kyoto, Japan.
RP Nakai, T (corresponding author), Mitsubishi Electr Corp, Tokyo, Japan.; Nakai, T (corresponding author), Ritsumeikan Univ, Kyoto, Japan.
EM nakai.tsunato@dy.mitsubishielectric.co.jp
CR [Anonymous], 2020, 004 ETSI GR SAI
   Benhani EM, 2019, IEEE T COMPUT, V68, P1238, DOI 10.1109/TC.2019.2900235
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   github, XILINX CHAIDNN V2
   Gross M, 2019, PROCEEDINGS OF THE 3RD ACM WORKSHOP ON ATTACKS AND SOLUTIONS IN HARDWARE SECURITY WORKSHOP (ASHES '19), P3, DOI 10.1145/3338508.3359568
   Hashemi H., 2021, ABS210500334 CORR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hua WZ, 2022, Arxiv, DOI arXiv:2008.11632
   Isakov Mihailo, 2019, IEEE HIGH PERF EXTR, P1, DOI [DOI 10.1109/hpec.2019.8916519, DOI 10.1109/HPEC.2019.8916519]
   Jia Y., 2014, CAFFE CONVOLUTIONAL
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Linaro OP-TEE, OP PORT TRUST EX ENV
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Nakai T, 2021, LECT NOTES COMPUT SC, V12809, P151, DOI 10.1007/978-3-030-81645-2_10
   nvdla, NVIDIA DEEP LEARNING
   nvidia, NVIDIA H100 TENSOR C
   Park H, 2021, Arxiv, DOI arXiv:2111.03065
   Stajnrod R, 2022, J COMPUT VIROL HACKI, V18, P259, DOI 10.1007/s11416-021-00413-y
   support, APPLE SECURE ENCLAVE
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang XB, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P190, DOI 10.1145/3310273.3323070
   Xie PC, 2020, Arxiv, DOI arXiv:2011.06376
   xilinx, ISOLATION DESIGN EXA
   Xilinx, ZYNQ ULTRASCALE MPSO
   Xu Q, 2021, ASIA S PACIF DES AUT, P449, DOI 10.1145/3394885.3431639
NR 28
TC 0
Z9 0
U1 1
U2 2
PY 2022
VL 13285
BP 200
EP 217
DI 10.1007/978-3-031-16815-4_12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematics, Applied
DA 2023-11-11
ER

PT C
AU Mrazek, V
AF Mrazek, Vojtech
BE Jenihhin, M
   Kubatova, H
   Metens, N
   Raik, J
   Ahmed, F
   Belohoubek, J
TI Approximation of Hardware Accelerators driven by Machine-Learning Models
SO 2023 26TH INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS AND SYSTEMS, DDECS
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 26th International Symposium on Design and Diagnostics of Electronic
   Circuits and Systems (DDECS)
CY MAY 03-05, 2023
CL Tallinn, ESTONIA
DE Approximate computing; Machine Learning; Estimation; Prediction
ID DESIGN
AB The goal of this tutorial is to introduce functional hardware approximation techniques employing machine learning methods. Functional approximation changes the function of a circuit slightly in order to reduce its power consumption. Machine learning models can help to estimate the error and the resulting circuit power consumption. The use of these techniques will be presented at multiple levels - at the individual component level and the higher level of HW accelerator synthesis.
C1 [Mrazek, Vojtech] Brno Univ Technol, Fac Informat Technol, Brno, Czech Republic.
RP Mrazek, V (corresponding author), Brno Univ Technol, Fac Informat Technol, Brno, Czech Republic.
EM mrazek@fit.vutbr.cz
CR Ansari MS, 2020, IEEE T VLSI SYST, V28, P317, DOI 10.1109/TVLSI.2019.2940943
   Ansari MS, 2019, DES AUT TEST EUROPE, P928, DOI [10.23919/date.2019.8714868, 10.23919/DATE.2019.8714868]
   Barone S, 2021, IEEE ACCESS, V9, P86975, DOI 10.1109/ACCESS.2021.3087858
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Hanif MA, 2017, DES AUT CON, DOI 10.1145/3061639.3062306
   Hashemi S, 2018, DES AUT CON, DOI 10.1145/3195970.3196001
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Mitchell J. N., 1962, IRE T ELECT COMPUT, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317781
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Nepal K., 2017, IEEE T EMERGING TOPI
   Prabakaran B. S., 2020, DAC 20
   Scarabottolo I, 2020, P IEEE, V108, P2195, DOI 10.1109/JPROC.2020.3014430
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Shin D, 2011, DES AUT TEST EUROPE, P1566
   Ullah S, 2022, ACM T EMBED COMPUT S, V21, DOI 10.1145/3513262
   Vasicek Z, 2019, DES AUT TEST EUROPE, P96, DOI [10.23919/date.2019.8714977, 10.23919/DATE.2019.8714977]
   Vasicek Z, 2015, IEEE T EVOLUT COMPUT, V19, P432, DOI 10.1109/TEVC.2014.2336175
   Venkataramani S, 2013, DES AUT TEST EUROPE, P1367
   Xie Z., 2020, ICCAD 20
   Xu C., 2022, INT S COMPUTER ARCHI
   Zhang YQ, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218643
   Zhou Y., 2019, SER DAC 19
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 91
EP 92
DI 10.1109/DDECS57882.2023.10139484
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Wang, C
   Gong, L
   Li, X
   Zhou, XH
AF Wang, Chao
   Gong, Lei
   Li, Xi
   Zhou, Xuehai
TI A Ubiquitous Machine Learning Accelerator With Automatic Parallelization
   on FPGA
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Clustering algorithms; Hardware; Machine learning algorithms; Machine
   learning; Out of order; Partitioning algorithms; Parallel processing;
   Machine learning; accelerator; FPGA; out-of-order execution; automatic
   parallelization
AB Machine learning has been widely applied in various emerging data-intensive applications, and has to be optimized and accelerated by powerful engines to process very large scale data. Recently, the instruction set based accelerators on Field Progarmmable Gate Arrays (FPGAs) have been a promising topic for machine learning applications. The customized instructions can be further scheduled to achieve higher instruction-level parallelism. In this article, we design a ubiquitous accelerator with out-of-order automatic parallelization for large-scale data-intensive applications. The accelerator accommodates four representative applications, including clustering algorithms, deep neural networks, genome sequencing, and collaborative filtering. In order to improve the coarse-grained instruction-level parallelism, the accelerator employs an out-of-order scheduling method to enable parallel dataflow computation. We use Colored Petri Net (CPN) tools to analyze the dependences in the applications, and build a hardware prototype on the real FPGA platform. For cluster applications, the accelerator can support four different algorithms, including K-Means, SLINK, PAM, and DBSCAN. For collaborative filtering applications, it accommodates Tanimoto, euclidean, Cosine, and Pearson Correlation as Similarity metrics. For deep learning applications, we implement hardware accelerators for both training process and inference process. Finally, for genome sequencing, we design a hardware accelerator for the BWA-SW algorithm. Experimental results show that the accelerator architecture can reach up to 25X speedup against Intel processors with affordable hardware cost, insignificant power consumption, and high flexibility.
C1 [Wang, Chao; Gong, Lei; Li, Xi; Zhou, Xuehai] Univ Sci & Technol China, Sch Comp Sci, Hefei 230027, Anhui, Peoples R China.
RP Gong, L (corresponding author), Univ Sci & Technol China, Sch Comp Sci, Hefei 230027, Anhui, Peoples R China.
EM cswang@ustc.edu.cn; leigong0203@ustc.edu.cn; llxx@ustc.edu.cn;
   xhzhou@ustc.edu.cn
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   [Anonymous], MSRTR10832014112
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   [Anonymous], NATURE
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chilimbi Trishul, 2014, P USENIX OSDI
   Dai GH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P105, DOI 10.1145/2847263.2847339
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Deng D. Y., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P137, DOI 10.1109/MICRO.2010.17
   Du ZD, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P494, DOI 10.1145/2830772.2830789
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Etsion Y., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P89, DOI 10.1109/MICRO.2010.13
   Feng XY, 2012, BMC SYST BIOL, V6, DOI 10.1186/1752-0509-6-94
   Gong L, 2018, IEEE T COMPUT AID D, V37, P2601, DOI 10.1109/TCAD.2018.2857078
   Gupta G, 2011, INT SYMP MICROARCH, P59
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Jenista JC, 2011, ACM SIGPLAN NOTICES, V46, P57, DOI 10.1145/2038037.1941563
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Li BZ, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P36, DOI 10.1145/2847263.2847340
   Li H, 2010, BIOINFORMATICS, V26, P589, DOI 10.1093/bioinformatics/btp698
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SH, 2016, LECT NOTES ELECTR EN, V377, P393, DOI 10.1007/978-3-662-49367-0_40
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   McKenna A, 2010, GENOME RES, V20, P1297, DOI 10.1101/gr.107524.110
   Mutlu O, 2003, NINTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE, PROCEEDINGS, P129, DOI 10.1109/HPCA.2003.1183532
   Olson CB, 2012, ANN IEEE SYM FIELD P, P161, DOI 10.1109/FCCM.2012.36
   Park S, 2016, ISSCC DIG TECH PAP I, V59, P254
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Qouneh A, 2015, PROC INT CONF PARAL, P1, DOI 10.1109/ICPP.2015.9
   Shendure J, 2008, NAT BIOTECHNOL, V26, P1135, DOI 10.1038/nbt1486
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   TOMASULO RM, 1967, IBM J RES DEV, V11, P25, DOI 10.1147/rd.111.0025
   Wang C, 2017, IEEE T PARALL DISTR, V28, P2993, DOI 10.1109/TPDS.2017.2701828
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang C, 2015, DES AUT TEST EUROPE, P884
   Wang C, 2016, IEEE T PARALL DISTR, V27, P2303, DOI 10.1109/TPDS.2015.2487346
   Wang C, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2459316.2459320
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Winterstein F, 2013, I C FIELD PROG LOGIC
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhao YW, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P788, DOI 10.1145/3307650.3322226
NR 51
TC 21
Z9 21
U1 3
U2 77
PD OCT 1
PY 2020
VL 31
IS 10
BP 2346
EP 2359
DI 10.1109/TPDS.2020.2990924
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zheng, MX
   Chen, F
   Jiang, L
   Lou, Q
AF Zheng, Mengxin
   Chen, Fan
   Jiang, Lei
   Lou, Qian
GP IEEE
TI PriML: An Electro-Optical Accelerator for Private Machine Learning on
   Encrypted Data
SO 2023 24TH INTERNATIONAL SYMPOSIUM ON QUALITY ELECTRONIC DESIGN, ISQED
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 24th International Symposium on Quality Electronic Design (ISQED)
CY APR 05-07, 2023
CL ELECTR NETWORK
DE Privacy-preserving machine learning; Fully homomorphic encryption;
   Electro-optical FHE accelerator
AB The widespread use of machine learning is changing our daily lives. Unfortunately, clients are often concerned about the privacy of their data when using machine learning-based applications. To address these concerns, the development of privacy-preserving machine learning (PPML) is essential. One promising approach is the use of fully homomorphic encryption (FHE) based PPML, which enables services to be performed on encrypted data without decryption. Although the speed of computationally expensive FHE operations can be significantly boosted by prior ASIC-based FHE accelerators, the performance of key-switching, the dominate primitive in various FHE operations, is seriously limited by their small bit-width datapaths and frequent matrix transpositions. In this paper, we present an electro-optical (EO) PPML accelerator, PriML, to accelerate FHE operations. Its 512-bit datapath supporting 510-bit residues greatly reduces the key-switching cost. We also create an in-scratchpad-memory transpose unit to fast transpose matrices. Compared to prior PPML accelerators, on average, PriML reduces the latency of various machine learning applications by > 94.4% and the energy consumption by > 95%.
C1 [Zheng, Mengxin; Chen, Fan; Jiang, Lei] Indiana Univ Bloomington, Bloomington, PA 47405 USA.
   [Lou, Qian] Univ Cent Florida, Orlando, FL USA.
RP Zheng, MX (corresponding author), Indiana Univ Bloomington, Bloomington, PA 47405 USA.
EM zhengme@iu.edu; fc7@iu.edu; jiang60@iu.edu; qian.lou@ucf.edu
CR Banerjee U., 2019, IACR T CRYPTOGR HARD, V2019, P17, DOI [10.46586/tches.v2019.i4.17-61, DOI 10.13154/TCHES.V2019.I4.17-61]
   Brutzkus A, 2019, PR MACH LEARN RES, V97
   Carpov S., 2015, 3 INT WORKSHOP SECUR
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   de Dinechin F., 2010, Proceedings 2010 International Conference on Field Programmable Logic and Applications (FPL 2010), P422, DOI 10.1109/FPL.2010.87
   Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723
   Feng B., 2021, P 2021 C EMPIRICAL M
   Gentry C, 2012, LECT NOTES COMPUT SC, V7417, P850, DOI 10.1007/978-3-642-32009-5_49
   Han MQ, 2022, DES AUT TEST EUROPE, P1353, DOI 10.23919/DATE54114.2022.9774559
   Hoofnagle CJ, 2019, INF COMMUN TECHNOL L, V28, P65, DOI 10.1080/13600834.2019.1573501
   Jiang L, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P235, DOI 10.1145/3489517.3530435
   Jiang L, 2012, DES AUT CON, P907
   Kim M, 2018, JMIR MED INF, V6, P245, DOI 10.2196/medinform.8805
   Kim S, 2022, CONF PROC INT SYMP C, P711, DOI 10.1145/3470496.3527415
   Koch Gregory R., 2015, ICML DEEP LEARN WORK
   Lou Q., 2020, INT C LEARNING REPRE
   Lou Q., 2020, ADV NEURAL INFORM PR, V33, P2364
   Lou Q, 2019, ADV NEUR IN, V32
   Lumerical, FDTD SOL
   Mathew SK, 2016, IEEE J SOLID-ST CIRC, V51, P1695, DOI 10.1109/JSSC.2016.2558490
   Mishra P, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2505
   Neethu MS, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Oleksenko O, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P227
   Palisade, 2020, PALISADE OPERATIONS
   Riazi M. S., 2020, ARCHITECTURAL SUPPOR
   Samardzic N, 2022, CONF PROC INT SYMP C, P173, DOI 10.1145/3470496.3527393
   Tuinhof Hessel, 2019, Machine Learning, Optimization, and Data Science. 4th International Conference, LOD 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11331), P472, DOI 10.1007/978-3-030-13709-0_40
   Ying ZF, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2836955
   Zheng M., 2023, FRONTIERS ELECT, V3
NR 29
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 476
EP 482
DI 10.1109/ISQED57927.2023.10129302
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Nurvitadhi, E
   Mishra, A
   Marr, D
AF Nurvitadhi, Eriko
   Mishra, Asit
   Marr, Debbie
GP IEEE
TI A Sparse Matrix Vector Multiply Accelerator for Support Vector Machine
SO 2015 INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURE AND SYNTHESIS
   FOR EMBEDDED SYSTEMS (CASES)
SE International Conference on Compilers Architecture and Synthesis for
   Embedded Systems
DT Proceedings Paper
CT International Conference on Compilers, Architecture and Synthesis for
   Embedded Systems (CASES)
CY OCT 04-09, 2015
CL Amsterdam, NETHERLANDS
DE Hardware accelerator; machine learning; support vector machine;
   Algorithms; Performance; Design
AB Sparse matrix vector multiplication (SpMV) is a linear algebra construct commonly found in machine learning (ML) algorithms, such as support vector machine (SVM). We profiled a popular SVM software (libSVM) on an energy-efficient microserver and a high-performance server for real-world ML datasets, and observed that SpMV dominates runtime. We propose a novel SpMV algorithm tailored for ML and a hardware accelerator architecture design based on this algorithm. Our evaluations show that the proposed algorithm and hardware accelerator achieves significant efficiency improvements over the conventional SpMV algorithm used in libSVM.
C1 [Nurvitadhi, Eriko; Mishra, Asit; Marr, Debbie] Intel Corp, Hillsboro, OR 97124 USA.
RP Nurvitadhi, E (corresponding author), Intel Corp, Hillsboro, OR 97124 USA.
EM eriko.nurvitadhi@intel.com; asit.k.mishra@intel.com;
   debbie.marr@intel.com
CR [Anonymous], 1998, EUR C MACH LEARN
   Cadambi S., 2010, INT C PAR ARCH COMP
   Cadambi S., 2009, FIELD PROGRAMMABLE C
   Chang Chih-Chung, 2011, ACM T INTELLIGENT SY, V2, P27
   Dorff K. C., 2010, BIOINFORMATICS
   Dorrance R., 2014, INT S FIELD PROGR GA
   Fowers J., 2014, INT S FIELD PROGR CU
   Kestur S., 2012, S FIELD PROGR CUST C
   Lin J., 2012, ACM SIGMOD INT C MAN
   Ma J., 2009, INT C MACH LEARN
   McMahan H. B., 2013, 19 ACM SIGKDD INT C
   Nivre Joakim, 2007, NATURAL LANGUAGE ENG
   Papadonikolakis M., 2010, FIELD PROGRAMMABLE C
   University of California Irvine, MACH LEARN REP
NR 14
TC 19
Z9 24
U1 0
U2 3
PY 2015
BP 109
EP 116
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Chen, TS
   Du, ZD
   Sun, NH
   Wang, J
   Wu, CY
   Chen, YJ
   Temam, O
AF Chen, Tianshi
   Du, Zidong
   Sun, Ninghui
   Wang, Jia
   Wu, Chengyong
   Chen, Yunji
   Temam, Olivier
TI DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous
   Machine-Learning
SO ACM SIGPLAN NOTICES
DT Article
ID NEURAL-NETWORKS; RECOGNITION
AB Machine-Learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope.
   Until now, most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy.
   We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm(2) and 485 mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87x faster, and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications.
C1 [Chen, Tianshi; Du, Zidong; Sun, Ninghui; Wang, Jia; Wu, Chengyong; Chen, Yunji] ICT, SKLCA, Beijing, Peoples R China.
   [Temam, Olivier] Inria, Le Chesnay, France.
RP Chen, TS (corresponding author), ICT, SKLCA, Beijing, Peoples R China.
CR Al Maashri A, 2012, DES AUT CON, P579
   Amant R. S., 2008, INT S MICR COM
   [Anonymous], 2012, P 17 C EL POW DISTR
   [Anonymous], INT C INF KNOWL MAN
   [Anonymous], INT S MICR
   [Anonymous], 2013, INT C MACH LEARN
   [Anonymous], 2012, ARXIV
   [Anonymous], 2013, IEEE INT C ACOUSTICS
   [Anonymous], 2008, INT C PAR ARCH COMP
   [Anonymous], 2011, P DEEP LEARN UNS FEA
   [Anonymous], INT S WORKL CHAR
   [Anonymous], INT C ARCH SUPP PROG
   [Anonymous], EE TIM DES ARM VIRT
   [Anonymous], 1997, P 31 AS C SIGN SYST
   [Anonymous], P 38 INT S COMP ARCH
   [Anonymous], INT S COMP ARCH PORT
   Bengio, 2007, ICML, P473
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Draghici S, 2002, NEURAL NETWORKS, V15, P395, DOI 10.1016/S0893-6080(02)00032-1
   Du Z., 2014, AS S PAC DES AUT C
   Fan K, 2009, INT S HIGH PERF COMP, P313, DOI 10.1109/HPCA.2009.4798266
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Holler M., 1990, ARTIFICIAL NEURAL NE, P50
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Larkin D, 2006, LECT NOTES COMPUT SC, V4234, P1178
   Larkin D, 2006, LECT NOTES COMPUT SC, V3973, P1319
   Le Q. V., 2012, INT C MACH LEARN JUN
   Lecun Y., 1998, P IEEE, P86
   Merolla P, 2011, IEEE CUST INTEGR CIR
   Mnih V., 2012, P 29 INT C MACH LEAR, P567, DOI DOI 10.5555/3042573.3042603
   Qadeer W., 2013, INT S COMP ARCH 2
   Schemmel J, 2008, IEEE IJCNN, P431, DOI 10.1109/IJCNN.2008.4633828
   Sermanet P., 2012, PATTERN RECOGNITION
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   TEMAM O, 1995, FUTURE GENER COMP SY, V11, P519, DOI 10.1016/0167-739X(95)00022-K
   Thoziyoor S., 2008, HPL200820
   Vogelstein RJ, 2007, IEEE T NEURAL NETWOR, V18, P253, DOI 10.1109/TNN.2006.883007
   Yehia S, 2009, INT S HIGH PERF COMP, P277, DOI 10.1109/HPCA.2009.4798263
NR 44
TC 912
Z9 1026
U1 11
U2 275
PD APR
PY 2014
VL 49
IS 4
BP 269
EP 283
DI 10.1145/2541940.2541967
WC Computer Science, Software Engineering
HC Y
HP N
DA 2023-11-11
ER

PT J
AU John, LK
AF John, Lizy Kurian
TI Machine Learning Accelerators and More
SO IEEE MICRO
DT Editorial Material
C1 [John, Lizy Kurian] Univ Texas Austin, Elect & Comp Engn Dept, Austin, TX 78712 USA.
RP John, LK (corresponding author), Univ Texas Austin, Elect & Comp Engn Dept, Austin, TX 78712 USA.
EM ljohn@ece.utexas.edu
NR 0
TC 1
Z9 1
U1 0
U2 3
PD SEP-OCT
PY 2019
VL 39
IS 5
SI SI
BP 4
EP 5
DI 10.1109/MM.2019.2935888
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Reuther, A
   Michaleas, P
   Jones, M
   Gadepally, V
   Samsi, S
   Kepner, J
AF Reuther, Albert
   Michaleas, Peter
   Jones, Michael
   Gadepally, Vijay
   Samsi, Siddharth
   Kepner, Jeremy
GP IEEE
TI Survey and Benchmarking of Machine Learning Accelerators
SO 2019 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 24-26, 2019
CL Waltham, MA
DE Machine learning; GPU; TPU; dataflow; accelerator; embedded inference
ID DESIGN; FLOW
AB Advances in multicore processors and accelerators have opened the flood gates to greater exploration and application of machine learning techniques to a variety of applications. These advances, along with breakdowns of several trends including Moore's Law, have prompted an explosion of processors and accelerators that promise even greater computational and machine learning capabilities. These processors and accelerators are coming in many forms, from CPUs and GPUs to ASICs, FPGAs, and dataflow accelerators.
   This paper surveys the current state of these processors and accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. We then select and benchmark two commercially-available low size, weight, and power (SWaP) accelerators as these processors are the most interesting for embedded and mobile machine learning inference applications that are most applicable to the DoD and other SWaP constrained users. We determine how they actually perform with real-world images and neural network models, compare those results to the reported performance and power consumption values and evaluate them against an Intel CPU that is used in some embedded applications.
C1 [Reuther, Albert; Michaleas, Peter; Jones, Michael; Gadepally, Vijay; Samsi, Siddharth; Kepner, Jeremy] MIT, Lincoln Lab, Supercomp Ctr, 244 Wood St, Lexington, MA 02173 USA.
RP Reuther, A (corresponding author), MIT, Lincoln Lab, Supercomp Ctr, 244 Wood St, Lexington, MA 02173 USA.
EM reuther@ll.mit.edu; pmichaleas@ll.mit.edu; michael.jones@ll.mit.edu;
   vijayg@ll.mit.edu; sid@ll.mit.edu; kepner@ll.mit.edu
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Albanie S., 2019, CONVNET BURDEN
   Alcorn P., 2017, NVIDIA INFUSES DGX 1
   [Anonymous], 2018, AMAZON WEB SERVICES
   [Anonymous], 2019, NVIDIA TESLA V100 TE
   [Anonymous], 2019, CURTISS WRIGHT 3U IN
   [Anonymous], 2019, TECH REP
   [Anonymous], 2018, ROCKCHIP RELEASED IT
   [Anonymous], 2019, MERCURY SYSTEMS BUIL
   [Anonymous], 2019, INTEL XEON PLATINUM
   [Anonymous], 2018, ANNOUNCING AWS INFER
   Armasu L., 2018, MOVE GPUS STARTUPS C
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Canziani A., 2016, ARXIV
   Chafkin M., 2018, BLOOMBERG        JUN
   Chen Y., 2019, IEEE T INTELL TRANSP, V20, P1, DOI DOI 10.1109/TITS.2018.2871269
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cutress I., 2018, CAMBRICON MAKER HAUW
   Cutress I., 2018, NVIDIAS DGX 2 SIXTEE
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Duckett C, 2018, BAIDU CREATES KUNLUN
   Exxactcorp, 2017, TAK DEEP LOOK AMD RA
   Feldman M., 2019, AI CHIP STARTUP PUTS
   Feldman M., 2017, WAVE COMPUTING LAUNC
   Feldman M., 2016, IBM FINDS KILLER APP
   Franklin, 2017, NVIDIA JETSON TX2 DE
   Frumusanu A., 2018, IPHONE XS XS MAX REV
   Frumusanu A., 2018, HISILICON ANNOUNCES
   Frumusanu A., 2018, SAMSUNG GALAXY S9 S9
   Guo K, 2017, ARXIV171208934
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hao K, 2019, TRAINING SINGLE MODE
   Hemsoth N, 2018, INTEL FPGA ARCHITECT
   Hemsoth N., 2018, 1 WAVE SPIKING NEURA
   Hemsoth N., 2017, 1 IN DEPTH VIEW WAVE
   Hemsoth N, 2018, MYTHIC APPROACH DEEP
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Horwitz J., 2019, REUTERS          FEB
   Howard A. G., 2017, ARXIV
   Hruska J, 2017, NEW MOVIDIUS MYRIAD
   Hruska J., 2018, NVIDIAS JETSON XAVIE
   Jeffers J, 2016, INTEL XEON PHI PROCE
   Jiao L, 2017, I C FIELD PROG LOGIC
   Jouppi NP, 2018, COMMUN ACM, V61, P50, DOI 10.1145/3154484
   Kilgariff E., 2018, NVIDIA TURING ARCHIT
   Knight W., 2019, MIT TECHNOLOGY REV
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lacey D, 2017, PRELIMINARY IPU BENC
   Li Z, 2017, FRONT COMPUT SCI-CHI, V11, P746, DOI 10.1007/s11704-016-6159-1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ling P, 2018, CHIN INT CONF ELECTR, P12, DOI 10.1109/CICED.2018.8592328
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   MINSKY M, 1967, COMPUTATION FINITE I
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Morra J., 2017, GROQ PORTRAYS POWER
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Nakano H, 2017, 2017 INTERNATIONAL WORKSHOP ON ANTENNA TECHNOLOGY: SMALL ANTENNAS, INNOVATIVE STRUCTURES, AND APPLICATIONS (IWAT), P1, DOI 10.1109/IWAT.2017.7915280
   Narang S., 2018, P ICLR VANC CAN
   Olofsson A., 2016, EPIPHANY V 1024 CORE
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Rao N., 2018, CPU GPU WHY ENTERPRI
   Rodriguez A., 2017, INTEL PROCESSORS DEE
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2018.00474
   Smith R, 2018, AMD ANNOUNCES RADEON
   Smith R., 2016, NVIDIA ANNOUNCES TES
   Smith R, 2018, 16GB NVIDIA TESLA V1
   Smith R., 2014, NVIDIA LAUNCHES TESL
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Teich P., 2018, TEARING APART GOOGLE
   Tenenbaum D., 2017, COMPUTING MOVES CLOU
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Van Veen F, 2019, NEURAL NETWORK ZOO
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wong W., 2018, BRAINCHIP UNVEILS AK
   Yoshida J., 2018, EE TIMES         MAR
   Yu E., 2018, ZDNET            SEP
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
NR 87
TC 86
Z9 87
U1 1
U2 2
PY 2019
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ro, Y
   Lee, E
   Ahn, JH
AF Ro, Yuhwan
   Lee, Eojin
   Ahn, Jung Ho
TI Evaluating the Impact of Optical Interconnects on a Multi-Chip
   Machine-Learning Architecture
SO ELECTRONICS
DT Article
DE machine learning; accelerator; optical interconnect; multi-chip
   architecture; cluster; Convolutional Neural Network (CNN)
AB Following trends that emphasize neural networks for machine learning, many studies regarding computing systems have focused on accelerating deep neural networks. These studies often propose utilizing the accelerator specialized in a neural network and the cluster architecture composed of interconnected accelerator chips. We observed that inter-accelerator communication within a cluster has a significant impact on the training time of the neural network. In this paper, we show the advantages of optical interconnects for multi-chip machine-learning architecture by demonstrating performance improvements through replacing electrical interconnects with optical ones in an existing multi-chip system. We propose to use highly practical optical interconnect implementation and devise an arithmetic performance model to fairly assess the impact of optical interconnects on a machine-learning accelerator platform. In our evaluation of nine Convolutional Neural Networks with various input sizes, 100 and 400 Gbps optical interconnects reduce the training time by an average of 20.6% and 35.6%, respectively, compared to the baseline system with 25.6 Gbps electrical ones.
C1 [Ro, Yuhwan; Lee, Eojin; Ahn, Jung Ho] Seoul Natl Univ, Dept Transdisciplinary Studies, Seoul 08826, South Korea.
RP Ahn, JH (corresponding author), Seoul Natl Univ, Dept Transdisciplinary Studies, Seoul 08826, South Korea.
EM yuhwanro@scale.snu.ac.kr; ejlee29@scale.snu.ac.kr; gajh@snu.ac.kr
CR [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], SINGL WAV PAM4 DSP C
   Caulfield AM, 2016, INT SYMP MICROARCH
   Chen GQ, 2006, IEEE INT INTERC TECH, P39
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Gonzalez R, 1996, IEEE J SOLID-ST CIRC, V31, P1277, DOI 10.1109/4.535411
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   IEEE LAN/MAN Standards Committee, 8023BS2017 IEEE LAN
   Intel, 100G PAR SINGL MOD D
   Kim D., 2017, P EL PACK TECHN C EP
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Mansuri M, 2013, ISSCC DIG TECH PAP I, V56, P402, DOI 10.1109/ISSCC.2013.6487788
   Okamoto D, 2014, 2014 EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC)
   Park J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P367, DOI 10.1145/3123939.3123979
   Patterson D, 2018, CHIP SCALE REV, V21, P14
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun C, 2015, NATURE, V528, P534, DOI 10.1038/nature16454
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vantrease D, 2008, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA.2008.35
   Wang X., 2015, P IEEE P802 3BS 200
   Wang ZH, 2016, IEEE T VLSI SYST, V24, P1574, DOI 10.1109/TVLSI.2015.2445825
   Welch B, 2014, P IEEE P802 3BS 200
NR 24
TC 2
Z9 2
U1 0
U2 8
PD AUG
PY 2018
VL 7
IS 8
AR 130
DI 10.3390/electronics7080130
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Jung, K
   Woo, J
   Mukhopadhyay, S
AF Jung, Kuchul
   Woo, Jongseok
   Mukhopadhyay, Saibal
GP IEEE
TI An On-chip Accelerator with Hybrid Machine Learning for Modulation
   Classification of Radio Frequency Signals
SO 2022 IEEE/MTT-S INTERNATIONAL MICROWAVE SYMPOSIUM (IMS 2022)
SE IEEE MTT-S International Microwave Symposium
DT Proceedings Paper
CT IEEE/MTT-S International Microwave Symposium (IMS)
CY JUN 19-24, 2022
CL Denver, CO
DE Radio frequency machine learning; convolutional neural network; Short
   time Fourier Transform; accelerator
ID RECOGNITION
AB We present a hybrid radio frequency machine learning (RFML) model that couples Short-time Fourier Transform with Convolutional Neural Network (STFT-CNN) for Automatic Modulation Classification (AMC). The simulation on RadioML2016.10a show 77.9% average accuracy for 0dB or higher Signal to Noise ratio with 16-bit fixed-point operation. An on-chip accelerator for STFT-CNN, designed and synthesized in 28nm CMOS, shows 7x lower power, 2x lower processing time, and 7.5x lower memory than a time-domain CNN accelerator with 32-bit floating point operation.
C1 [Jung, Kuchul; Woo, Jongseok; Mukhopadhyay, Saibal] Georgia Inst Technol, Green Lab, Atlanta, GA USA.
RP Jung, K (corresponding author), Georgia Inst Technol, Green Lab, Atlanta, GA USA.
EM Kjung62@ece.gatech.edu; Jongseok.woo@ece.gatech.edu;
   Saibal.mukhopadhyay@ece.gatech.edu
CR Liu XY, 2019, INT C ELECTR MACH SY, P3165
   Nandi AK, 1998, IEEE T COMMUN, V46, P431, DOI 10.1109/26.664294
   O'Shea TJ, 2016, COMM COM INF SC, V629, P213, DOI 10.1007/978-3-319-44188-7_16
   OShea T.J., 2016, P GNU RAD C, V1
   Sang YJ, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P159, DOI 10.1109/APCCAS.2018.8605691
   Wong MLD, 2004, SIGNAL PROCESS, V84, P351, DOI 10.1016/j.sigpro.2003.10.019
   Woo Jongseok, 2021 IEEE MTT S INT
   Wu YL, 2018, IEEE INT WORK SIGN P, P61
NR 8
TC 0
Z9 0
U1 0
U2 4
PY 2022
BP 487
EP 490
DI 10.1109/IMS37962.2022.9865378
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Low, TM
   Chi, YJ
   Hoe, J
   Kumar, S
   Prabhakara, A
   Shi, LX
   Sridhar, U
   Tukanov, N
   Wang, CY
   Wu, YC
AF Low, Tze Meng
   Chi, Yuejie
   Hoe, James
   Kumar, Swarun
   Prabhakara, Akarsh
   Shi, Laixi
   Sridhar, Upasana
   Tukanov, Nicholai
   Wang, Chengyue
   Wu, Yuchen
GP IEEE
TI Zoom Out: Abstractions for Efficient Radar Algorithms on COTS
   architectures
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON PHASED ARRAY SYSTEMS & TECHNOLOGY
   (PAST)
SE IEEE International Symposium on Phased Array Systems & Technology
DT Proceedings Paper
CT IEEE International Symposium on Phased Array Systems and Technology
   (PAST)
CY OCT 11-14, 2022
CL Waltham, MA
DE Super-resolution; machine-learning; high performance computing;
   efficiency; performance
ID SET
AB The advent of machine learning has resulted in the rapid development of machine learning accelerators that are capable of computing tensor operations efficiently. Specifically, these accelerators compute matrix-matrix multiplication, a key routine in linear algebra libraries and machine learning. While using the accelerators would result in high performance radar signal processing, the algorithms used often require significant redesign in order to efficiently map them on to existing machine-learning hardware. In this paper, we show that higher levels of abstraction facilitate the efficient mapping of array algorithms onto commercial-off-the-shelf (COTS) machine learning hardware that results in higher performance in terms of execution time and/or throughput. Furthermore, similar levels of abstraction can be used to design efficient implementations of ML algorithms for radar processing, resulting in improved radar capabilities.
C1 [Low, Tze Meng; Chi, Yuejie; Hoe, James; Kumar, Swarun; Prabhakara, Akarsh; Shi, Laixi; Sridhar, Upasana; Tukanov, Nicholai; Wang, Chengyue; Wu, Yuchen] Carnegie Mellon Univ, Elect & Comp Engn, Pittsburgh, PA 15213 USA.
RP Low, TM (corresponding author), Carnegie Mellon Univ, Elect & Comp Engn, Pittsburgh, PA 15213 USA.
CR Abadi M., 2015, 10 SORFLOW LARGE SCA
   Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Angerson E., 1990, Proceedings of Supercomputing '90 (Cat. No.90CH2916-5), P2, DOI 10.1109/SUPERC.1990.129995
   Baig Nauman Anwar, 2013, International Journal of Future Computer and Communication, V2, P654, DOI 10.7763/IJFCC.2013.V2.246
   Bezanson J, 2012, Arxiv, DOI [arXiv:1209.5145, DOI 10.48550/ARXIV.1209.5145]
   Chakrabarty S, 2017, IEEE WORK APPL SIG, P136, DOI 10.1109/WASPAA.2017.8170010
   DONGARRA JJ, 1988, ACM T MATH SOFTWARE, V14, P1, DOI 10.1145/42288.42291
   DONGARRA JJ, 1990, ACM T MATH SOFTWARE, V16, P1, DOI 10.1145/77626.79170
   Gentilho E, 2020, J SIGNAL PROCESS SYS, V92, P239, DOI 10.1007/s11265-019-01467-4
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Lang P., 2020, ARXIV
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, P324, DOI [10.1145/355841.355847, 10.1145/355841.355848]
   LeCun, P 27 INT C INT C MAC, P399, DOI DOI 10.5555/3104322.3104374
   Liu WL, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76608-y
   Moler C., 1987, US GUID
   SCHMIDT RO, 1986, IEEE T ANTENN PROPAG, V34, P276, DOI 10.1109/TAP.1986.1143830
   Sprechmann P, 2015, IEEE T PATTERN ANAL, V37, P1821, DOI 10.1109/TPAMI.2015.2392779
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   WARD J, 1995, INT CONF ACOUST SPEE, P2809, DOI 10.1109/ICASSP.1995.479429
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/PAST49659.2022.9975097
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Murakami, K
   Komatsu, K
   Sato, M
   Kobayashi, H
AF Murakami, Kou
   Komatsu, Kazuhiko
   Sato, Masayuki
   Kobayashi, Hiroaki
GP IEEE
TI A Processor Selection Method based on Execution Time Estimation for
   Machine Learning Programs
SO 2021 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
DT Proceedings Paper
CT 35th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY JUN 17-21, 2021
CL Portland, OR
DE Performance modeling; Processor selection; Automatic tuning; Vector
   processor; Accelerator; GPU
AB In recent years, machine learning has become widespread. Since machine learning algorithms have become complex and the amount of data to be handled have become large, the execution times of machine learning programs have been increasing. Processors called accelerators can contribute to the execution of a machine learning program with a short time. However, the processors including the accelerators have different characteristics. Therefore, it is unclear whether existing machine learning programs are executed on the appropriate processor or not. This paper proposes a method for selecting a processor suitable for each machine learning program. In the proposed method, the selection is based on the estimation of the execution time of machine learning programs on each processor. The proposed method does not need to execute a target machine learning program in advance. From the experimental results, it is clarified that the proposed method can achieve up to 5.3 times faster execution than the original implementation by NumPy. These results prove that the proposed method can be used in a system that automatically selects the processor so that each machine learning program can be easily executed on the best processor.
C1 [Murakami, Kou; Sato, Masayuki; Kobayashi, Hiroaki] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
   [Komatsu, Kazuhiko] Tohoku Univ, Cybersci Ctr, Sendai, Miyagi, Japan.
RP Murakami, K (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
EM kou.murakami.r1@dc.tohoku.ac.jp; komatsu@tohoku.ac.jp;
   masa@tohoku.ac.jp; koba@tohoku.ac.jp
CR Afanasyev Ilya, 2018, SUPERCOMPUTING FRONT, V5
   Bauer M, 2019, P DISSERTATION AWARD, P1
   Boyer Michael, 2013, 2013 IEEE International Symposium on Parallel and Distributed Processing, Workshops and PhD Forum (IPDPSW), P1097, DOI 10.1109/IPDPSW.2013.236
   Egawa R, 2017, IEEE INT C CL COMP, P693, DOI 10.1109/CLUSTER.2017.65
   Egawa Ryusuke, 2014, INT C HIGH PERF COMP
   Hosomi Takeo, 2019, SPARK AI SUMMIT 2019
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kikugawa G, 2019, CHEM PHYS LETT, V728, P109, DOI 10.1016/j.cplett.2019.04.075
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kohonen T, 2001, ENG INTELL SYST ELEC, V9, P179
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Komatsu Kazuhiko, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P685, DOI 10.1109/SC.2018.00057
   Komatsu K, 2019, IEEE SYM PARA DISTR, P768, DOI 10.1109/IPDPSW.2019.00127
   Komatsu K, 2018, 2018 IEEE 12TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2018), P117, DOI 10.1109/MCSoC2018.2018.00030
   MacQueen J., 1967, P 5 BERK S MATH STAT, V14, P281
   McCalpin John D., 1995, IEEE COMPUTER SOC TE, P19
   Molchanov P., 2016, 5 INT C LEARNING REP
   Moosavi V., 2014, SOMPY PYTHON LIB SEL
   Nishino R., 2017, 31 CONFERNCE NEURAL, V151
   Sato K., 2011, 2011 IEEE 9th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P135, DOI 10.1109/ISPA.2011.36
   Sato Katsuto, 2010, AUTOMATIC TUNING CUD, P209
   Soga T, 2011, COMPUT FLUIDS, V45, P215, DOI 10.1016/j.compfluid.2010.12.024
   Travis EO., 2006, A GUIDE TO NUMPY, DOI DOI 10.5555/2886196
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wu MY, 2015, CHIN AUTOM CONGR, P542, DOI 10.1109/CAC.2015.7382560
   Yamada Y., 2018, P INTENATIONAL S HIG, VVolume 30, P19
   Zhang R, 2019, INFORM FUSION, V50, P158, DOI 10.1016/j.inffus.2018.11.019
NR 27
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 779
EP 788
DI 10.1109/IPDPSW52791.2021.00116
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Chen, H
   Hao, C
AF Chen, Hanqiu
   Hao, Cong
GP IEEE
TI Hardware/Software Co-design for Machine Learning Accelerators
SO 2023 IEEE 31ST ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES, FCCM
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 31st IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 08-11, 2023
CL Marina Del Rey, CA
DE hardware/software co-design; DNNs; GNNs; accelerator
AB This abstract highlights challenges in machine learning accelerator design and proposes solutions through software/hardware co-design techniques. To optimize single object detection, we introduce Mask-Net, a lightweight network that eliminates redundant computation. To address hardware limitations in Dynamic Graph Neural Networks (DGNNs), we present DGNN-Booster, a graph-agnostic FPGA accelerator. Our designs are open-source, generic, and applicable to real-world scenarios.
C1 [Chen, Hanqiu; Hao, Cong] Georgia Inst Technol, Elect & Comp Engn, Atlanta, GA USA.
RP Chen, H (corresponding author), Georgia Inst Technol, Elect & Comp Engn, Atlanta, GA USA.
EM hchen799@gatech.edu; callie.hao@gatech.edu
CR Abi-Karam S, 2022, Arxiv, DOI arXiv:2201.08475
   Chen H, 2023, 31 IEEE INT S FIELD
   Chen HQ, 2022, I S WORKL CHAR PROC, P130, DOI 10.1109/IISWC55918.2022.00021
   Chen HQ, 2022, IEEE INT CONF ASAP, P131, DOI 10.1109/ASAP54787.2022.00030
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guan M., 2022, P 5 ACM SIGMOD JOINT, P1
   He KM, 2018, Arxiv, DOI [arXiv:1703.06870, 10.48550/arXiv.1703.06870, DOI 10.48550/ARXIV.1703.06870]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salami B, 2020, I C DEPEND SYS NETWO, P138, DOI 10.1109/DSN48063.2020.00032
   Salami B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P724, DOI [10.1109/MICR0.2018.00064, 10.1109/MICRO.2018.00064]
   Sarkar R., 2022, FLOWGNN DATAFLOW ARC
   Sitzmann V., 2020, ARXIV200609661
   Song XK, 2022, IEEE T COMPUT AID D, V41, P116, DOI 10.1109/TCAD.2021.3052138
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Zhang X., 2020, P MACHINE LEARNING S, V2, P216
   Zhou H., 2022, ARXIV
NR 19
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 233
EP 235
DI 10.1109/FCCM57271.2023.00058
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Li, Y
   Yu, FY
   Cai, Q
   Qian, MY
   Liu, PF
   Guo, JW
   Yan, H
   Yuan, K
   Yu, J
AF Li, Yu
   Yu, Fengyuan
   Cai, Qian
   Qian, Meiyu
   Liu, Pengfeng
   Guo, Junwen
   Yan, Huan
   Yuan, Kun
   Yu, Juan
TI Design of Target Recognition System Based on Machine Learning Hardware
   Accelerator
SO WIRELESS PERSONAL COMMUNICATIONS
DT Article
DE FPGA; Target recognition; Machine learning; Hardware acceleration; SOC
AB Target recognition system based on machine learning has the problems of long delay, high power-consuming and high cost, which cause it difficult to be promoted in some small embedded devices. In order to develop a target recognition system based on machine learning that can be utilized in small embedded device, this paper analyzes the commonly used design process of target recognition, the training process of machine learning algorithms, and the working method of FPGA to accelerate the algorithm. In the end, it offers a new solution of target recognition system based on machine learning hardware accelerator. In the solution, the training process of target recognition algorithm based on machine learning is completed in GPU, and then the algorithm is porting to the logic part of SOC in the form of hardware accelerator. The solution be widely used in different needs of the target recognition scenario with the advantage of effectively reduce the system delay, power consumption, size.
C1 [Li, Yu; Yu, Fengyuan; Qian, Meiyu; Liu, Pengfeng; Guo, Junwen; Yan, Huan; Yuan, Kun; Yu, Juan] Wuhan Text Univ, Coll Elect & Elect Engn, Wuhan, Hubei, Peoples R China.
   [Cai, Qian] Wuhan Text Univ, Coll Foreign Languages, Wuhan, Hubei, Peoples R China.
RP Li, Y (corresponding author), Wuhan Text Univ, Coll Elect & Elect Engn, Wuhan, Hubei, Peoples R China.
EM 1459833@qq.com
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Choi W., 2014, COMPUTER VISION ECCV, V7575, P215
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Fu LM, 2014, CURR PHARM DESIGN, V20, P4307
   Gao L, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4959983
   Gentillon H., 2017, F1000 RES, V6, P93
   Kadi M. A., 2014, INT C REC COMP FPGAS, P1
   Kazi M. S. S., 2013, INT J ENG TRENDS TEC, V4, P2302
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Liu Li-feng, 2010, 2010 International Symposium on Information Science and Engineering (ISISE 2010), P370, DOI 10.1109/ISISE.2010.78
   Maxim V, 2012, PROCEDIA ENGINEER, V48, P402, DOI 10.1016/j.proeng.2012.09.532
   Schirner G, 2013, COMPUTER, V46, P36, DOI 10.1109/MC.2013.31
   Sprenger M, 2017, WEATHER FORECAST, V32, P1079, DOI 10.1175/WAF-D-16-0208.1
   Vink JP, 2015, ARTIF INTELL REV, V43, P125, DOI 10.1007/s10462-012-9366-7
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
NR 22
TC 1
Z9 2
U1 1
U2 12
PD SEP
PY 2018
VL 102
IS 2
BP 1557
EP 1571
DI 10.1007/s11277-017-5211-2
WC Telecommunications
DA 2023-11-11
ER

PT J
AU Burr, GW
   Lim, S
   Murmann, B
   Venkatesan, R
   Verhelst, M
AF Burr, Geoffrey W.
   Lim, SukHwan
   Murmann, Boris
   Venkatesan, Rangharajan
   Verhelst, Marian
TI Fair and Comprehensive Benchmarking of Machine Learning Processing Chips
SO IEEE DESIGN & TEST
DT Editorial Material
DE YY Benchmark testing; Computer architecture; Measurement; Integrated
   circuit modeling; Best practices; Computational modeling; AI processing;
   ML accelerator; chip evaluation; benchmarking; deep learning;
   architecture; circuit
ID ACCELERATOR
C1 [Burr, Geoffrey W.] IBM Res Almaden, Cupertino, CA 95014 USA.
   [Lim, SukHwan] Samsung, Hwaseong Si 18448, South Korea.
   [Murmann, Boris] Stanford Univ, Stanford, CA 94305 USA.
   [Venkatesan, Rangharajan] NVIDIA Corp, Santa Clara, CA 95051 USA.
   [Verhelst, Marian] MICAS KU Leuven, B-3001 Heverlee, Belgium.
   [Verhelst, Marian] IMEC, B-3001 Heverlee, Belgium.
RP Verhelst, M (corresponding author), MICAS, Dept Elect Engn, B-3001 Leuven, Belgium.
EM verhelst@kuleuven.be
CR [Anonymous], AITUTU BENCHMARK
   Banbury Colby R., 2020, ARXIV200304821
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Bankman D, 2016, IEEE ASIAN SOLID STA, P21, DOI 10.1109/ASSCC.2016.7844125
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Cai H., 2019, 7 INT C LEARN REPR I
   Camus V, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P57, DOI [10.1109/aicas.2019.8771610, 10.1109/AICAS.2019.8771610]
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Ding Z, 2020, ARXIV200106679
   Giraldo JSP, 2020, IEEE J SOLID-ST CIRC, V55, P868, DOI 10.1109/JSSC.2020.2968800
   Guo K., NEURAL NETWORK ACCEL
   Gupta S, 2015, I C DEPEND SYS NETWO, P37, DOI 10.1109/DSN.2015.52
   Honkote V, 2019, ISSCC DIG TECH PAP I, V62, P48, DOI 10.1109/ISSCC.2019.8662463
   Ignatov A., 2018, P ECCV, P127
   Jain S, 2021, IEEE T COMPUT AID D, V40, P326, DOI 10.1109/TCAD.2020.3000185
   Jiang WW, 2020, IEEE T COMPUT AID D, V39, P4805, DOI 10.1109/TCAD.2020.2986127
   Knag Phil, 2016, 2016 IEEE Symposium on VLSI Circuits (VLSI-Circuits), DOI 10.1109/VLSIC.2016.7573526
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Mei L., 2020, ARXIV200711360
   Moons B, 2018, IEEE CUST INTEGR CIR
   Moons B, 2017, CONF REC ASILOMAR C, P1921, DOI 10.1109/ACSSC.2017.8335699
   Moons B, 2017, DES AUT TEST EUROPE, P488, DOI 10.23919/DATE.2017.7927038
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Reddi, 2019, ARXIV191102549
   Rekhi AS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317770
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yu CS, 2020, IEEE CUST INTEGR CIR
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang XY, 2019, IEEE COMP SOC ANN, P25, DOI 10.1109/ISVLSI.2019.00014
   Zimmer B, 2020, IEEE J SOLID-ST CIRC, V55, P920, DOI 10.1109/JSSC.2019.2960488
NR 35
TC 4
Z9 4
U1 1
U2 6
PD JUN
PY 2022
VL 39
IS 3
BP 18
EP 27
DI 10.1109/MDAT.2021.3063366
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Poddar, S
   Thomas, KA
   Kumar, G
AF Poddar, Soumyajit
   Thomas, Amal K.
   Kumar, Gaurav
GP IEEE Comp Soc
TI Design of Hardware Accelerators for Fractal based Machine Learning
   Applications
SO 2020 6TH IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES
   2020) (FORMERLY INIS)
DT Proceedings Paper
CT 6th IEEE International Symposium on Smart Electronic Systems (IEEE-iSES)
CY DEC 14-16, 2020
CL ELECTR NETWORK
DE Artificial Intelligence; VLSI; Hardware Accelerators
AB Natural processes are non-linear dynamical systems. Samples extracted from such processes are often estimated through non-Euclidean geometry like fractals. Provided such a structure exists in a given data distribution, it becomes imperative to use non-Euclidean space like graphs and manifolds to represent it. Traditional Euclidean machine learning or deep learning techniques may not be sufficient for such spaces. This work provides some insights On how learning or inference for such classes of problems may be accomplished by following some novel hardware software co-design techniques. This work proposes some novel techniques to design hardware accelerators for realizing fractal based machine learning applications.
C1 [Poddar, Soumyajit; Thomas, Amal K.] IIIT Guwahati, Elect & Commun Engn, Gauhati, India.
   [Kumar, Gaurav] Cyrrup Solut Pvt Ltd, Hyderabad, India.
RP Poddar, S (corresponding author), IIIT Guwahati, Elect & Commun Engn, Gauhati, India.
EM poddar18@gmail.com; amal.kakkassery@outlook.com; gaurav.kumar@cyrrup.com
CR Bloem P., 2017, ARXIV PREPRINT ARXIV
   Bloem P, 2016, SINGLE SAMPLE STAT E
   Gallego A., 2013, SCALABLE EVOLVABLE H, V12, P1
   Green S. G, 2005, ACM SIGGRAPH 2005 SK, P15
   He C, 2017, INT ENCY GEOGRAPHY P, P1, DOI DOI 10.1002/9781118786352.WBIEG0444
   Myronenko A., 2009, CLIN ORTHOP RELAT R, V05
   Nilsson P, 2014, 2014 NORCHIP
   Pottathuparambil R., 2008, PROC RSSI, P1
NR 8
TC 0
Z9 0
U1 0
U2 0
PY 2020
BP 71
EP 74
DI 10.1109/iSES50453.2020.00027
WC Green & Sustainable Science & Technology; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Chen, TS
   Zhang, SJ
   Liu, SL
   Du, ZD
   Luo, T
   Gao, Y
   Liu, JJ
   Wang, DS
   Wu, CY
   Sun, NH
   Chen, YJ
   Temam, O
AF Chen, Tianshi
   Zhang, Shijin
   Liu, Shaoli
   Du, Zidong
   Luo, Tao
   Gao, Yuan
   Liu, Junjie
   Wang, Dongsheng
   Wu, Chengyong
   Sun, Ninghui
   Chen, Yunji
   Temam, Olivier
TI A Small-Footprint Accelerator for Large-Scale Neural Networks
SO ACM TRANSACTIONS ON COMPUTER SYSTEMS
DT Article
DE Architecture; Processor; Hardware
ID RECOGNITION
AB Machine-learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve toward heterogeneous multicores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope.
   Until now, most machine-learning accelerator designs have been focusing on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance, and energy.
   We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm(2) and 485mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87x faster, and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications.
C1 [Chen, Tianshi; Zhang, Shijin; Liu, Shaoli; Du, Zidong; Luo, Tao; Wu, Chengyong; Sun, Ninghui; Chen, Yunji] Chinese Acad Sci, ICT, SKLCA, Beijing 100190, Peoples R China.
   [Gao, Yuan; Liu, Junjie; Wang, Dongsheng] Tsinghua Univ, TNLIST, Beijing 100084, Peoples R China.
   [Temam, Olivier] Inria, Saclay, France.
   [Chen, Yunji] Chinese Acad Sci, Ctr Excellence Brain Sci, Beijing 100190, Peoples R China.
RP Chen, YJ (corresponding author), Chinese Acad Sci, ICT, SKLCA, Beijing 100190, Peoples R China.
EM chentianshi@ict.ac.cn; zhangshijin@ict.ac.cn; liushaoli@ict.ac.cn;
   duzidong@ict.ac.cn; luotao@ict.ac.cn; g-y12@mails.tsinghua.edu.cn;
   liujun-jie12@mails.tsinghua.edu.cn; wds@tsinghua.edu.cn; cwu@ict.ac.cn;
   snh@ict.ac.cn; cyj@ict.ac.cn; olivier.temam@inria.fr
CR Al Maashri A, 2012, DES AUT CON, P579
   Amant Renee St., 2008, INT S MICR COM
   [Anonymous], 2012, P 17 C EL POW DISTR
   [Anonymous], INT C INF KNOWL MAN
   [Anonymous], INT S MICR
   [Anonymous], 2013, INT C MACH LEARN
   [Anonymous], 2012, ARXIV
   [Anonymous], 2013, IEEE INT C ACOUSTICS
   [Anonymous], INT S COMP ARCH
   [Anonymous], 2011, P DEEP LEARN UNS FEA
   [Anonymous], INT S WORKL CHAR
   [Anonymous], 1998, P IEEE
   [Anonymous], INT C ARCH SUPP PROG
   [Anonymous], 1997, P 31 AS C SIGN SYST
   [Anonymous], P 38 INT S COMP ARCH
   [Anonymous], INT S COMP ARCH PORT
   Bengio, 2007, ICML, P473
   Bienia Christian, 2008, INT C PAR ARCH COMPL
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen YJ, 2014, IEEE MTT S INT MICR
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Draghici S, 2002, NEURAL NETWORKS, V15, P395, DOI 10.1016/S0893-6080(02)00032-1
   Du Z., 2014, AS S PAC DES AUT C
   Fan K, 2009, INT S HIGH PERF COMP, P313, DOI 10.1109/HPCA.2009.4798266
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Holler M., 1990, ARTIFICIAL NEURAL NE, P50
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Larkin D, 2006, LECT NOTES COMPUT SC, V4234, P1178
   Larkin D, 2006, LECT NOTES COMPUT SC, V3973, P1319
   LeQuoc V., 2012, INT C MACH LEARN
   Merolla P, 2011, IEEE CUST INTEGR CIR
   Mnih V., 2012, P 29 INT C MACH LEAR, P567, DOI DOI 10.5555/3042573.3042603
   Muller Mike, 2010, EE TIMES DES ARM VIR
   Schemmel J, 2008, IEEE IJCNN, P431, DOI 10.1109/IJCNN.2008.4633828
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   TEMAM O, 1995, FUTURE GENER COMP SY, V11, P519, DOI 10.1016/0167-739X(95)00022-K
   Thoziyoor S., 2008, HPL200820
   Vogelstein RJ, 2007, IEEE T NEURAL NETWOR, V18, P253, DOI 10.1109/TNN.2006.883007
   Yehia S, 2009, INT S HIGH PERF COMP, P277, DOI 10.1109/HPCA.2009.4798263
NR 45
TC 3
Z9 3
U1 1
U2 68
PD JUN
PY 2015
VL 33
IS 2
AR 6
DI 10.1145/2701417
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Emani, M
   Xie, Z
   Raskar, S
   Sastry, V
   Arnold, W
   Wilson, B
   Thakur, R
   Vishwanath, V
   Liu, ZC
   Papka, ME
   Bohorquez, CO
   Weisner, R
   Li, K
   Sheng, YN
   Du, Y
   Zhang, J
   Tsyplikhin, A
   Khaira, G
   Fowers, J
   Sivakumar, R
   Godsoe, V
   Macias, A
   Tekur, C
   Boyd, M
AF Emani, Murali
   Xie, Zhen
   Raskar, Siddhisanket
   Sastry, Varuni
   Arnold, William
   Wilson, Bruce
   Thakur, Rajeev
   Vishwanath, Venkatram
   Liu, Zhengchun
   Papka, Michael E.
   Bohorquez, Cindy Orozco
   Weisner, Rick
   Li, Karen
   Sheng, Yongning
   Du, Yun
   Zhang, Jian
   Tsyplikhin, Alexander
   Khaira, Gurdaman
   Fowers, Jeremy
   Sivakumar, Ramakrishnan
   Godsoe, Victoria
   Macias, Adrian
   Tekur, Chetan
   Boyd, Matthew
GP IEEE
TI A Comprehensive Evaluation of Novel AI Accelerators for Deep Learning
   Workloads
SO 2022 IEEE/ACM INTERNATIONAL WORKSHOP ON PERFORMANCE MODELING,
   BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS)
DT Proceedings Paper
CT 13th IEEE/ACM International Workshop on Performance Modeling,
   Benchmarking and Simulation of High Performance Computer Systems (PMBS)
CY NOV 13-18, 2022
CL Dallas, TX
DE Scientific Machine Learning; Deep Learning; Accelerators; Performance
   Evaluation; Benchmarking
AB Scientific applications are increasingly adopting Artificial Intelligence (AI) techniques to advance science. Highperformance computing centers are evaluating emerging novel hardware accelerators to efficiently run AI-driven science applications. With a wide diversity in the hardware architectures and software stacks of these systems, it is challenging to understand how these accelerators perform. The state-of-the-art in the evaluation of deep learning workloads primarily focuses on CPUs and GPUs. In this paper, we present an overview of dataflow-based novel AI accelerators from SambaNova, Cerebras, Graphcore, and Groq. We present a first-of-a-kind evaluation of these accelerators with diverse workloads, such as Deep Learning (DL) primitives, benchmark models, and scientific machine learning applications. We also evaluate the performance of collective communication, which is key for distributed DL implementation, along with a study of scaling efficiency. We then discuss key insights, challenges, and opportunities in integrating these novel AI accelerators in supercomputing systems.
C1 [Emani, Murali; Xie, Zhen; Raskar, Siddhisanket; Sastry, Varuni; Arnold, William; Wilson, Bruce; Thakur, Rajeev; Vishwanath, Venkatram; Liu, Zhengchun; Papka, Michael E.] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Bohorquez, Cindy Orozco] Cerebras Syst, Sunnyvale, CA 95085 USA.
   [Weisner, Rick; Li, Karen; Sheng, Yongning; Du, Yun; Zhang, Jian] SambaNova Syst Inc, Palo Alto, CA 94303 USA.
   [Tsyplikhin, Alexander; Khaira, Gurdaman] Graphcore Inc, Palo Alto, CA 94301 USA.
   [Fowers, Jeremy; Sivakumar, Ramakrishnan; Godsoe, Victoria; Macias, Adrian; Tekur, Chetan; Boyd, Matthew] Groq Inc, Mountain View, CA 94041 USA.
   [Papka, Michael E.] Univ Illinois, Chicago, IL 60637 USA.
RP Emani, M (corresponding author), Argonne Natl Lab, Lemont, IL 60439 USA.
EM memani@anl.gov; zhen.xie@anl.gov; sraskar@anl.gov; vsastry@anl.gov;
   arnoldw@anl.gov; wilsonb@anl.gov; thakur@anl.gov; venkat@anl.gov;
   zhengchun.liu@anl.gov; papka@anl.gov; cindy@cerebras.net;
   rick.weisner@sambanova.ai; xiaoyan.li@sambanova.ai;
   yongning.sheng@sambanova.ai; yun.du@sambanova.ai;
   jian.zhang@sambanova.ai; alext@graphcore.ai; damank@graphcore.ai;
   jfowers@groq.com; rsivakumar@groq.com; vgodsoe@groq.com; am@groq.com;
   ctekur@groq.com; matt@groq.com
CR Abdelfattah A, 2016, LECT NOTES COMPUT SC, V9697, P21, DOI 10.1007/978-3-319-41321-1_2
   Abdelfattah A, 2019, INT PARALL DISTRIB P, P111, DOI 10.1109/IPDPS.2019.00022
   Adolf R, 2016, I S WORKL CHAR PROC, P148
   alcf, ALCF TESTBED
   alcf, AURORA SUPERCOMPUTIN
   [Anonymous], MLPERF
   Anzt H, 2020, PROCEEDINGS OF 2020 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2020), P26, DOI 10.1109/PMBS51919.2020.00009
   Ben-Nun T, 2019, INT PARALL DISTRIB P, P66, DOI 10.1109/IPDPS.2019.00018
   Brace A., 2021, STREAM AI MD STREAMI, DOI [10.1145/3468267.3470578, DOI 10.1145/3468267.3470578]
   Buber E, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CONTROL ENGINEERING & INFORMATION TECHNOLOGY (CEIT)
   Buda M, 2019, COMPUT BIOL MED, V109, P218, DOI 10.1016/j.compbiomed.2019.05.002
   cerebras, CEREBRAS CS 2 SYSTEM
   Chanussot L, 2021, ACS CATAL, V11, P6059, DOI 10.1021/acscatal.0c04525
   Choi Y.-r, 2020, HETPIPE ENABLING LAR
   cloud.google, GOOGLE TENSOR PROCES
   Coleman Cody, 2019, ACM SIGOPS Operating Systems Review, V53, P14, DOI 10.1145/3352020.3352024
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   G, GROQCHIP
   Geng Jinkun, 2019, P 10 WORKSHOP SCI CL, P5
   github, BRAGNN
   github, ECP CANDLE BENCHMARK
   github, 2021, DEEPBENCH
   github, PREDICTING TUMOR DOS
   github, U NET IMPLEMENTATION
   github, 2021, MLPERF HPC BENCHMARK
   github, 2021, HPE DEEP LEARNING BE
   Goodman J., 2020, COAL RUSH TURNING PO
   Graphcore, 2021, GRAPHC INT PROC UN
   Haidar A, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   icl.bitbucket, 2021, HPL AI MIXED PRECISI
   Jain A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00049
   Jia Zhihao, 2019, SYSML, V1, P1
   Jiang Z., 2020, HPC AI500 METHODOLOG
   Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni S., 2020, HARDWARE ACCELERATED
   Kurth Thorsten, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P649, DOI 10.1109/SC.2018.00054
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Li C, 2020, INT PARALL DISTRIB P, P326, DOI 10.1109/IPDPS47924.2020.00042
   Liu Z., 2022, IUCRJ, V9
   Liu ZC, 2021, PROCEEDINGS OF XLOOP 2021: THE 3RD ANNUAL WORKSHOP ON EXTREME-SCALE EXPERIMENT-IN-THE-LOOP COMPUTING, P15, DOI 10.1109/XLOOP54565.2021.00008
   llnl, 2020, CEREBRAS WAFER SCALE
   llnl, CAPITAN
   Louw Thorben, 2021, USING GRAPHCORE IPU
   Mahon S, 2020, 2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2020), P760, DOI 10.1109/CCGrid49817.2020.00-13
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Mathuriya A, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Matsumoto K, 2011, PROCEDIA COMPUT SCI, V4, P342, DOI 10.1016/j.procs.2011.04.036
   Moon G. E., 2021, ARXIV
   Mukunoki Daichi, 2020, High Performance Computing. 35th International Conference, ISC High Performance 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12151), P230, DOI 10.1007/978-3-030-50743-5_12
   Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209
   olcf, FRONTIER
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Rocki K, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00062
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   S. Systems, 2021, ACC COMP REC DAT ARC
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Song LH, 2020, INT S HIGH PERF COMP, P342, DOI 10.1109/HPCA47549.2020.00036
   Stevens R., 2020, SCI REPORT DEP ENERG, DOI [10.2172/1604756, DOI 10.2172/1604756]
   top500, 2021, TOP500 LIST
   Trifan Anda, 2021, BIORXIV, DOI [10.1101/2021.10.09.463779, DOI 10.1101/2021.10.09.463779]
   Vetter Jeffrey S, 2018, DOE ASCR WORKSH EXTR
   Wang Y E, 2019, ARXIV190710701
   Wyatt MR, 2021, PROCEEDINGS OF THE WORKSHOP ON MACHINE LEARNING IN HIGH PERFORMANCE COMPUTING ENVIRONMENTS (MLHPC 2021), P94, DOI 10.1109/MLHPC54614.2021.00014
   Xu A., 2020, P IEEECVF C COMPUTER
   Yan D, 2020, INT PARALL DISTRIB P, P634, DOI 10.1109/IPDPS47924.2020.00071
   Yin J., 2021, BENCHCOUNCIL T BENCH, V1
   Zhang ZH, 2021, Arxiv, DOI arXiv:2105.10430
NR 72
TC 1
Z9 1
U1 1
U2 1
PY 2022
BP 13
EP 25
DI 10.1109/PMBS56514.2022.00007
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Marcato, D
   Arena, G
   Bortolato, D
   Gelain, F
   Martinelli, V
   Munaron, E
   Roetta, M
   Savarese, G
   Susto, GA
AF Marcato, Davide
   Arena, Giovanni
   Bortolato, Damiano
   Gelain, Fabio
   Martinelli, Valentina
   Munaron, Enrico
   Roetta, Marco
   Savarese, Giovanni
   Susto, Gian Antonio
GP IEEE
TI Machine Learning-based Anomaly Detection for Particle Accelerators
SO 5TH IEEE CONFERENCE ON CONTROL TECHNOLOGY AND APPLICATIONS (IEEE CCTA
   2021)
DT Proceedings Paper
CT 5th IEEE Conference on Control Technology and Applications (IEEE CCTA)
CY AUG 08-11, 2021
CL ELECTR NETWORK
DE anomaly detection; explainable machine learning; multivariate
   time-series; particle accelerator; unsupervised learning
AB Particle accelerators are complex systems composed of multiple subsystems that must work together to produce high quality beams employed for physics experiments. A fault or an anomalous behaviour in one of such subsystems can lead to expensive downtime for the whole facility. Thus, it is of paramount importance to be able to promptly detect anomalies. Given the vast amount of streaming data generated by accelerator field sensors, Machine Learning (ML)-based tools are promising candidates for efficient monitoring of such systems: an approach based on unsupervised ML techniques exploiting the data from a Radio Frequency tuning system is here proposed. Feature importance is exploited to guide the definition of the optimal windowing for feature extraction. The proposed approach is here validated on real-world data related to the ALPI accelerator at Legnaro National Laboratories in Italy.
C1 [Marcato, Davide; Arena, Giovanni; Bortolato, Damiano; Gelain, Fabio; Martinelli, Valentina; Munaron, Enrico; Roetta, Marco; Savarese, Giovanni] Ist Nazl Fis Nucl, Legnaro Natl Labs, I-35020 Legnaro, Italy.
   [Marcato, Davide; Susto, Gian Antonio] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
RP Marcato, D (corresponding author), Ist Nazl Fis Nucl, Legnaro Natl Labs, I-35020 Legnaro, Italy.; Marcato, D (corresponding author), Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
EM davide.marcato@lnl.infn.it
CR Agari K, 2020, PAPER WEMPL001, P992
   Altmann A, 2010, BIOINFORMATICS, V26, P1340, DOI 10.1093/bioinformatics/btq134
   Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431), P15
   Barbariol T, 2020, ENERGIES, V13, DOI 10.3390/en13123136
   Bortolato D, 2018, PAPER TUPHA117, P678
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Carmona P. F., 2020, P 17 INT C ACCELERAT
   Dainelli A, 1996, NUCL INSTRUM METH A, V382, P100, DOI 10.1016/S0168-9002(96)00456-1
   Dewitte T., 2019, 17 INT C ACCELERATOR, P1066, DOI [10.18429/JACoW-ICALEPCS2019-WEMPR010, DOI 10.18429/JACOW-ICALEPCS2019-WEMPR010]
   Felsberger Lukas, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P139, DOI 10.1007/978-3-030-57321-8_8
   GARNAUT R, 1992, ECONOMIC REFORM AND INTERNATIONALISATION: CHINA AND THE PACIFIC REGION, P1
   He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5
   Lazarevic A., 2005, P 11 ACM SIGKDD INT, P157, DOI DOI 10.1145/1081870.1081891
   Liu FT, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133363
   Meneghetti L, 2018, IEEE TRANSAC TIONS C
   Pevny T, 2016, MACH LEARN, V102, P275, DOI 10.1007/s10994-015-5521-0
   Ramakrishnan J, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1917, DOI 10.1145/3292500.3330748
   Scheinker A., 2018, P 9 INT PARTICLE ACC
   Solopova A, 2019, P 10 INT PARTICLE AC, VIPAC2019
   Susto Gian Antonio, 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P195, DOI 10.1109/CoASE.2013.6653952
   White G, 2019, P 10 INT PART ACC C, P1216
   Zhao Y, 2019, J MACH LEARN RES, V20
NR 22
TC 0
Z9 0
U1 2
U2 4
PY 2021
BP 240
EP 246
DI 10.1109/CCTA48906.2021.9658806
WC Automation & Control Systems; Computer Science, Cybernetics
DA 2023-11-11
ER

PT C
AU Steinert, F
   Knapheide, J
   Stabernack, B
AF Steinert, Fritjof
   Knapheide, Justin
   Stabernack, Benno
GP IEEE COMP SOC
TI Demonstration of a Distributed Accelerator Framework for
   Energy-efficient ML Processing
SO 2021 31ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL 2021)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 31st International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 30-SEP 03, 2021
CL ELECTR NETWORK
DE Distributed FPGAs; Network-attached Accelerator; Machine Learning
AB The broad field of machine learning (ML) is experiencing rapid growth from being applied to ever more types of applications. This leads to an increasing demand for computing performance. To satisfy the computational demand, accelerators like GPUs or FPGAs are used especially in data centers. Despite the higher energy efficiency of accelerators compared to CPUs, new architectures for accelerator usage are necessary to achieve a significant further improvement in energy efficiency. Therefore, we demonstrate an architecture for distributed ML accelerators. We operate FPGA accelerators directly coupled to the network without a host system, which leads to significant power savings.
C1 [Steinert, Fritjof; Knapheide, Justin; Stabernack, Benno] Fraunhofer Heinrich Hertz Inst, Berlin, Germany.
   [Steinert, Fritjof; Knapheide, Justin; Stabernack, Benno] Univ Potsdam, Potsdam, Germany.
RP Steinert, F (corresponding author), Fraunhofer Heinrich Hertz Inst, Berlin, Germany.; Steinert, F (corresponding author), Univ Potsdam, Potsdam, Germany.
EM fritjof.steinert@hhi-extern.fraunhofer.de;
   justin.knapheide@uni-potsdam.de; benno.stabernack@hhi.fraunhofer.de
CR Knapheide J, 2020, I C FIELD PROG LOGIC, P277, DOI 10.1109/FPL50879.2020.00053
   Steinert F, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P149, DOI 10.1109/DSD51259.2020.00033
NR 2
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 386
EP 386
DI 10.1109/FPL53798.2021.00077
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Kang, M
   Srivastava, P
   Adve, V
   Kim, NS
   Shanbhag, NR
AF Kang, Mingu
   Srivastava, Prakalp
   Adve, Vikram
   Kim, Nam Sung
   Shanbhag, Naresh R.
TI An Energy-Efficient Programmable Mixed Signal Accelerator for Machine
   Learning Algorithms
SO IEEE MICRO
DT Article
AB We propose PROMISE, the first end-to-end design of a PROgrammable Mixed-Signal accElerator from Instruction Set Architecture to high-level language compiler for acceleration of diverse machine learning algorithms by exploiting the advantage of the superior energy efficiency from analog/mixed-signal processing.
C1 [Kang, Mingu] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Srivastava, Prakalp; Kim, Nam Sung; Shanbhag, Naresh R.] Univ Illinois, Urbana, IL USA.
   [Adve, Vikram] Univ Illinois, Comp Sci, Urbana, IL USA.
RP Kang, M (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM mingu.kang@ibm.com; psrivas2@illinois.edu; vadve@illinois.edu;
   nskim@illinois.edu; shanbhag@illinois.edu
CR Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Srivastava P, 2018, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA.2018.00015
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
NR 7
TC 1
Z9 1
U1 0
U2 1
PD SEP-OCT
PY 2019
VL 39
IS 5
SI SI
BP 64
EP 72
DI 10.1109/MM.2019.2929502
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Yavits, L
   Ginosar, R
AF Yavits, Leonid
   Ginosar, Ran
TI Accelerator for Sparse Machine Learning
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Sparse matrix multiplication; sparse matrix by sparse vector
   multiplication; SpMV; accelerator
ID MATRIX-VECTOR MULTIPLICATION
AB Sparse matrix by vector multiplication (SpMV) plays a pivotal role in machine learning and data mining. We propose and investigate an SpMV accelerator, specifically designed to accelerate the sparse matrix by sparse vector multiplication (SpMSpV), and to be integrated in a CPU core. We show that our accelerator outperforms a similar solution by 70x while achieving 8x higher power efficiency, which yields an estimated 29x energy reduction for SpMSpV based applications.
C1 [Yavits, Leonid; Ginosar, Ran] Technion Israel Inst Technol, Dept Elect Engn, IL-3200000 Haifa, Israel.
RP Yavits, L (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-3200000 Haifa, Israel.
EM yavits@technion.ac.il; ran@ee.technion.ac.il
CR ANDERSEN J, 1992, PARALLEL COMPUT, V18, P675, DOI 10.1016/0167-8191(92)90007-T
   [Anonymous], 2013, 2013 IEEE HIGH PERFO
   Beaumont O, 2001, IEEE T PARALL DISTR, V12, P1033, DOI 10.1109/71.963416
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Dorrance Richard, 2014, PROC ISFPGA, P161
   Kieckhager R., 1982, IEEE C CIRC COMP, P380
   Mishra AK, 2017, ASIA S PACIF DES AUT, P635, DOI 10.1109/ASPDAC.2017.7858395
   MISRA M, 1993, PARALLEL COMPUT, V19, P525, DOI 10.1016/0167-8191(93)90004-5
   Natarajan S., 2014, 2014 IEEE International Electron Devices Meeting (IEDM), DOI 10.1109/IEDM.2014.7046976
   Sun J, 2007, ANN IEEE SYM FIELD P, P349, DOI [10.1109/FCCM.2007.60, 10.1109/FCCM.2007.56]
   WING O, 1985, J PARALLEL DISTR COM, V2, P170, DOI 10.1016/0743-7315(85)90033-4
   Yavits L, 2015, IEEE T PARALL DISTR, V26, P3175, DOI 10.1109/TPDS.2014.2370055
   Zhuo Ling, 2005, P 2005 ACMSIGDA 13 I, P63
NR 14
TC 7
Z9 7
U1 0
U2 5
PD JAN-JUN
PY 2018
VL 17
IS 1
BP 21
EP 24
DI 10.1109/LCA.2017.2714667
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Reuther, A
   Michaleas, P
   Jones, M
   Gadepally, V
   Samsi, S
   Kepner, J
AF Reuther, Albert
   Michaleas, Peter
   Jones, Michael
   Gadepally, Vijay
   Samsi, Siddharth
   Kepner, Jeremy
GP IEEE
TI Survey of Machine Learning Accelerators
SO 2020 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 21-25, 2020
CL ELECTR NETWORK
DE Machine learning; GPU; TPU; dataflow; accelerator; embedded inference;
   computational performance
ID NEURAL-NETWORKS; ARCHITECTURES; HARDWARE
AB New machine learning accelerators are being announced and released each month for a variety of applications from speech recognition, video object detection, assisted driving, and many data center applications. This paper updates the survey of of AI accelerators and processors from last year's IEEE-HPEC paper. This paper collects and summarizes the current accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. This year, there are many more announced accelerators that are implemented with many more architectures and technologies from vector engines, dataflow engines, neuromorphic designs, flash-based analog memory processing, and photonic-based processing.
C1 [Reuther, Albert; Michaleas, Peter; Jones, Michael; Gadepally, Vijay; Samsi, Siddharth; Kepner, Jeremy] MIT, Lincoln Lab, Supercomp Ctr, 244 Wood St, Lexington, MA 02173 USA.
RP Reuther, A (corresponding author), MIT, Lincoln Lab, Supercomp Ctr, 244 Wood St, Lexington, MA 02173 USA.
EM reuther@ll.mit.edu; pmichaleas@ll.mit.edu; michael.jones@ll.mit.edu;
   vijayg@ll.mit.edu; sid@ll.mit.edu; kepner@ll.mit.edu
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Agabi O. E., 2016, CELL CULTURE TRANSPO, P1
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Albanie S., 2019, CONVNET BURDEN
   Alcorn P., 2017, NVIDIA INFUSES DGX 1
   [Anonymous], 2020, DELL DSS8440 GRAPHC
   [Anonymous], 2017, TAK DEEP LOOK AMD RA
   [Anonymous], 2018, ROCKCHIP RELEASED IT
   [Anonymous], 2020, HORIZON ROBOTICS JOU
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Campa C., 2020, DEFINING INNOVATION
   Canziani A., 2016, ARXIV
   Chen Y., 2018, CONF PROC INT SYMP C, P1, DOI DOI 10.1109/MM.2017.265085944
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chiou D, 2017, I S WORKL CHAR PROC, P124, DOI 10.1109/IISWC.2017.8167769
   Clarke P., 2020, GRAI MATTER RES GIVE
   Clarke P., 2020, NXP KALRAY DEMO COOL
   Clarke P, 2018, INDO US STARTUP PREP
   Clarke P., 2019, STARTUP REVEALS PROT
   Clarke P., 2018, AI CHIP STARTUP OFFE
   Clarke P., 2016, MILITARY STARTUP AIM
   Cutress I., 2018, CAMBRICON MAKER HAUW
   Cutress I, 2018, NVIDIAS DGX 2 16 TES
   Dahad N., 2019, STARTUP LAUNCHES ITS
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   De Gelas J, 2019, INTELS XEON CASCADE
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Duckett C, 2018, BAIDU CREATES KUNLUN
   Dunietz J., 2017, SCI AM
   Dupont de Dinechin B., 2019, 17 IEEE INT NEW CIRC
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Evangelist C., 2020, DEEP DIVE AMAZON INF
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Feldman M., 2019, IEEE PHOTON CONF
   Feldman M., 2018, OPTALYSYS CLAIMS AI
   Feldman M., 2016, IBM FINDS KILLER APP
   Fick D., 2018, MYTHIC HOT CHIPS 201
   Firu D, 2019, QUADRIC EDGE SUPERCO
   Franklin, 2017, NVIDIA JETSON TX2 DE
   Freund K., 2020, INTEL LAYS OUT STRAT
   Freund K., 2019, MOOR INSIGHTS STRATE
   Gadepally V., 2019, AI ENABLING TECHNOLO
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   Giles M., 2019, B GATES JUST BACKED
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gwennap L., 2019, HABANA WINS CIGAR IN
   Gwennap L., MICROPROCESSOR REPOR
   Gwennap L., 2019, MICROPROCESSOR REPOR
   Gwennap Linley, 2020, MICROPROCESSOR REPOR
   Hamilton J, 2018, AWS INFERENTIA MACHI
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hemsoth N, 2018, INTEL FPGA ARCHITECT
   Hemsoth N., 2018, 1 WAVE SPIKING NEURA
   Hemsoth N, 2018, MYTHIC APPROACH DEEP
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hock A, 2019, INTRO CEREBRAS CS 1
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hruska J, 2017, NEW MOVIDIUS MYRIAD
   Hruska J., 2018, NVIDIAS JETSON XAVIE
   Huawei, 2020, ASCEND 310 PROCESSOR
   Huawei, 2020, ASCEND 910 PROCESSOR
   Jouppi NP, 2018, COMMUN ACM, V61, P50, DOI 10.1145/3154484
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Khan Saif, 2020, AI CHIPS WHAT THEY A
   Kilgariff E., 2018, NVIDIA TURING ARCHIT
   Krashinsky Ronny., 2020, NVIDIA AMPERE ARCHIT
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lacey D., 2020, UPDATED GRAPHCORE IP
   Lacey D, 2017, PRELIMINARY IPU BENC
   Langroudi HF, 2019, PROC SPIE, V11139, DOI 10.1117/12.2529407
   Li Z, 2017, FRONT COMPUT SCI-CHI, V11, P746, DOI 10.1007/s11704-016-6159-1
   Liao, 2001, NEURAL NETWORKS HARD
   LightOn, 2020, PHOT COMP MASS PAR A
   Lin CK, 2018, COMPUTER, V51, P52, DOI 10.1109/MC.2018.157113521
   LINDSEY CS, 1995, P SOC PHOTO-OPT INS, V2492, P1194, DOI 10.1117/12.205116
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   McGrath D., 2019, QUALCOMM TARGETS INF
   McGrath D, 2018, TECH HEAVYWEIGHTS BA
   McGregor J., 2020, PERCEIVE EXITS STEAL
   Medina E, 2020, IEEE MICRO, V40, P17, DOI 10.1109/MM.2020.2975185
   Mehta V, 2020, LINL SPRING PROC C L
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Merritt R., 2019, STARTUP ACCELERATES
   Merritt R, 2018, BAIDU ACCELERATOR RI
   Merritt R., 2019, SAMSUNG TOSHIBA DETA
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Moore S. K., 2020, LOW POWER AI STARTUP
   Morgan T. P., 2017, DRILLING MICROSOFTS
   Narang S., 2018, P ICLR
   Nugent MA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085175
   Park C., 2018, TECHNICAL DIGEST INT
   Patton R. M., 2017, AIDS BEHAV, DOI DOI 10.1007/S10461-017-1727-4
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Peng T, 2019, ALIBABAS NEW AI CHIP
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Roos G, 2019, FPGA ACCELERATION CA
   Schor D, 2020, ARM ETHOS IS UBIQUIT
   Schor D, 2017, 2048 CORE PEZY SC2 S
   Shen KL, 2020, WORLD J PEDIATR, V16, P219, DOI 10.1007/s12519-020-00344-6
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Smith R, 2018, AMD ANNOUNCES RADEON
   Smith R, 2018, 16GB NVIDIA TESLA V1
   SolidRun, 2020, GYRFALCON DEV ARM BA
   Sze V., 2020, EFFICIENT PROCESSING
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Teich P., 2018, TEARING APART GOOGLE
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Turley J, 2020, GAP9 ML EDGE EEJOURN
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Ward-Foxton S, 2019, DETAILS HAILO AI EDG
   Ward-Foxton S., 2020, KNERONS NEXT GEN EDG
   Ward-Foxton S., 2020, XMOS ADAPTS XCORE AI
   Ward-Foxton S, 2019, GYRFALCON UNVEILS 4
   Wheeler B., 2019, BITMAIN SOC BRINGS E
   Yoshida J, 2018, NOVUMINDS AI CHIP SP
   Yoshida J., 2019, BLAIZE FIRES GSP PRO
NR 123
TC 67
Z9 67
U1 0
U2 5
PY 2020
DI 10.1109/hpec43674.2020.9286149
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Taher, FN
   Callenes-Sloan, J
   Schafer, BC
AF Taher, Farah Naz
   Callenes-Sloan, Joseph
   Schafer, Benjamin Carrion
GP IEEE
TI A Machine Learning based Hard Fault Recuperation Model for Approximate
   Hardware Accelerators
SO 2018 55TH ACM/ESDA/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 55th ACM/ESDA/IEEE Design Automation Conference (DAC)
CY JUN 24-28, 2018
CL San Francisco, CA
DE Approximate Hardware Accelerator; Permanent Hardware Fault; Fault
   Tolerance; Error Compensation; Supervised Learning; Machine Learning
AB Continuous pursuit of higher performance and energy efficiency has led to heterogeneous SoC that contains multiple dedicated hardware accelerators. These accelerators exploit the inherent parallelism of tasks and are often tolerant to inaccuracies in their outputs, e.g. image and digital signal processing applications. At the same time, permanent faults are escalating due to process scaling and power restrictions, leading to erroneous outputs. To address this issue, in this paper, we propose a low-cost, universal fault-recovery/repair method that utilizes supervised machine learning techniques to ameliorate the effect of permanent fault(s) in hardware accelerators that can tolerate inexact outputs. The proposed compensation model does not require any information about the accelerator and is highly scalable with low area overhead. Experimental results show, the proposed method improves the accuracy by 50% and decreases the overall mean error rate by 90% with an area overhead of 5% compared to execution without fault compensation.
C1 [Taher, Farah Naz; Schafer, Benjamin Carrion] Univ Texas Dallas, Richardson, TX 75083 USA.
   [Callenes-Sloan, Joseph] Cal Poly State Univ, San Luis Obispo, CA USA.
RP Taher, FN (corresponding author), Univ Texas Dallas, Richardson, TX 75083 USA.
EM farah.taher@utdallas.edu; jcallene@calpoly.edu; schaferb@utdallas.edu
CR Abdallah R. A., 2013, IEEE T MULTIMEDIA
   Agrawal V. D., 2003, INT TEST C ITC
   Almukhaizim S., 2004, VLSI TEST S
   Amaru Luca, 2015, EPFL COMBINATIONAL B
   [Anonymous], IEEE T COMPUTERS
   [Anonymous], IEEE MICRO
   Asanovic K., 2006, LANDSCAPE PARALLEL C
   Breuer M. A., 2004, DESIGN TEST COMPUTER
   Cord M, 2008, COGN TECHNOL, P1, DOI 10.1007/978-3-540-75171-7
   Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107
   Hari SKS, 2012, I C DEPEND SYS NETWO
   Koren I, 1998, P IEEE, V86, P1819, DOI 10.1109/5.705525
   Koren I., 1990, COMPUTER
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Li M.-L., 2008, INT C DEP SYST NETW
   Mentor Graphics, 2011, MODELSIM SE 10 1B
   OpenCores, 2017, FREE OP SOURC IP COR
   Shanbhag N, 2002, DES AUT CON, P830, DOI 10.1109/DAC.2002.1012737
   Sharma A., 2013, INT C COMP DES ICCD
   Shim B., 2003, AS C SIGN SYST COMP
   Stanisavljevic M, 2011, RELIABILITY OF NANOSCALE CIRCUITS AND SYSTEMS: METHODOLOGIES AND CIRCUIT ARCHITECTURES, P1, DOI 10.1007/978-1-4419-6217-1
   Taher F. N., 2015, PAC RIM INT S DEP CO
   Varatkar G. V., 2006, INT S LOW POW EL DES
   Venkataramani S., 2013, C DES AUT TEST EUR D
   Viera AJ, 2005, FAM MED, V37, P360
   Witten Ian., 2005, DATA MINING PRACTICA
   Wolf C., 2014, YOSYS OPEN SYNTHESIS
   Xu S., 2017, IEEE T VERY LARGE SC
NR 28
TC 0
Z9 0
U1 0
U2 1
PY 2018
DI 10.1145/3195970.3195974
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT J
AU Yin, X
   He, W
   Wang, L
   Mo, W
   Li, A
AF Yin, X.
   He, W.
   Wang, L.
   Mo, W.
   Li, A.
TI Classification of Rubber Vulcanizing Accelerators Based on Particle
   Swarm Optimization Extreme Learning Machine and Terahertz Spectra
SO JOURNAL OF APPLIED SPECTROSCOPY
DT Article
DE terahertz spectrum; rubber vulcanization accelerator; particle swarm
   optimization; extreme learning machine; classification
AB In rubber tire production, three popular types of rubber vulcanizing accelerators exist that are similar in appearance (i.e., 2-mercaptobenzothiazole, 4,4 '-dithiodimorpholine, and tetramethyl thiuram monosulfide). Because the rubber vulcanizing accelerator has a great influence on the vulcanized rubber characteristics, it is necessary to classify and identify the three popular types of rubber vulcanizing accelerators to avoid using the wrong accelerator during tire production and to ensure the tire quality. The THz spectra of the accelerator samples were measured using a terahertz time-domain spectral (THz-TDS) system in a frequency range of 0.3-1.6 THz. An extreme learning machine (ELM) model was constructed to classify the three popular types of rubber vulcanizing accelerators via terahertz absorption spectra. To improve the classification accuracy of the model, a particle swarm optimization ELM model was constructed possessing a higher classification accuracy than the ELM model in the classification and identification of rubber vulcanizing accelerators.
C1 [Yin, X.; He, W.; Wang, L.; Mo, W.] Guilin Univ Elect Technol, Sch Elect Engn & Automat, Guilin 541004, Guangxi, Peoples R China.
   [Yin, X.; He, W.; Wang, L.; Mo, W.] Guangxi Key Lab Automat Detecting Technol & Instr, Guilin 541004, Guangxi, Peoples R China.
   [Li, A.] Natl Rubber & Rubber Prod Qual Supervis & Inspect, Guilin 541004, Peoples R China.
RP Yin, X (corresponding author), Guilin Univ Elect Technol, Sch Elect Engn & Automat, Guilin 541004, Guangxi, Peoples R China.; Yin, X (corresponding author), Guangxi Key Lab Automat Detecting Technol & Instr, Guilin 541004, Guangxi, Peoples R China.
EM cpxu_ck@163.com
CR Baek SH, 2016, J INFRARED MILLIM TE, V37, P486, DOI 10.1007/s10762-015-0234-9
   [陈涛 Chen Tao], 2012, [仪器仪表学报, Chinese Journal of Scientific Instrument], V33, P2480
   Chen ZW, 2015, J QUANT SPECTROSC RA, V167, P1, DOI 10.1016/j.jqsrt.2015.07.018
   Dorney TD, 2001, J OPT SOC AM A, V18, P1562, DOI 10.1364/JOSAA.18.001562
   Duvillaret L, 1996, IEEE J SEL TOP QUANT, V2, P739, DOI 10.1109/2944.571775
   Duvillaret L, 1999, APPL OPTICS, V38, P409, DOI 10.1364/AO.38.000409
   Eberhart R., 1999, P 6 INT S MICROMACHI, DOI [10.1109/MHS.1995.494215, DOI 10.1109/MHS.1995.494215]
   Hangyo M, 2015, JPN J APPL PHYS, V54, DOI 10.7567/JJAP.54.120101
   Hua YF, 2010, IEEE T MICROW THEORY, V58, P2064, DOI 10.1109/TMTT.2010.2050184
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Lu M., 2012, CHIN RUBBER SCI TECH, V1, P32
   Mao, 2011, J MOD SCI INSTRUM, V5, P110
   Peters O, 2013, POLYM TEST, V32, P932, DOI 10.1016/j.polymertesting.2013.05.003
   Rong JF., 2016, J PHYS TEST CHEM ANA, V52, P750
   [史欣田 Shi Xintian], 2018, [仪器仪表学报, Chinese Journal of Scientific Instrument], V39, P81
   [许川佩 Xu Chuanpei], 2017, [仪器仪表学报, Chinese Journal of Scientific Instrument], V38, P765
   Yan, 2017, J CHIN RUBBER PLASTI, V43, P47
   Zhang H, 2017, SPECTROCHIM ACTA A, V184, P335, DOI 10.1016/j.saa.2017.05.017
NR 18
TC 0
Z9 0
U1 10
U2 23
PD JAN
PY 2022
VL 88
IS 6
BP 1315
EP 1323
DI 10.1007/s10812-022-01313-9
EA JAN 2022
WC Spectroscopy
DA 2023-11-11
ER

PT S
BE Kim, S
   Deka, GC
TI Hardware Accelerator Systems for Artificial Intelligence and Machine
   Learning
SO HARDWARE ACCELERATOR SYSTEMS FOR ARTIFICIAL INTELLIGENCE AND MACHINE
   LEARNING
SE Advances in Computers
DT Book
NR 0
TC 0
Z9 0
U1 0
U2 0
PY 2021
VL 122
BP 1
EP 402
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT J
AU Wolski, A
   Johnson, MA
   King, M
   Militsyn, BL
   Williams, PH
AF Wolski, A.
   Johnson, M. A.
   King, M.
   Militsyn, B. L.
   Williams, P. H.
TI Transverse phase space tomography in an accelerator test facility using
   image compression and machine learning
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB We describe a novel technique, based on image compression and machine learning, for transverse phase space tomography in two degrees of freedom in an accelerator beamline. The technique has been used in the CLARA accelerator test facility at Daresbury Laboratory: results from the machine learning method are compared with those from a conventional tomography algorithm (algebraic reconstruction) and applied to the same data. The use of machine learning allows reconstruction of the 4D phase space distribution of the beam to be carried out much more rapidly than using conventional tomography algorithms and also enables the use of image compression to reduce significantly the size of the data sets involved in the analysis. Results from the machine learning technique are at least as good as those from the algebraic reconstruction tomography in characterizing the beam behavior, in terms of the variation of the beam size in response to variation of the quadrupole strengths.
C1 [Wolski, A.] Univ Liverpool, Liverpool, England.
   [Wolski, A.] Cockcroft Inst, Daresbury, England.
   [Johnson, M. A.; King, M.; Militsyn, B. L.; Williams, P. H.] Daresbury Lab, STFC, ASTeC, Daresbury, England.
RP Wolski, A (corresponding author), Univ Liverpool, Liverpool, England.; Wolski, A (corresponding author), Cockcroft Inst, Daresbury, England.
EM a.wolski@liverpool.ac.uk
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Alesini D, 2006, NUCL INSTRUM METH A, V568, P488, DOI 10.1016/j.nima.2006.07.050
   Angal-Kalinin D, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044801
   Angal-Kalinin D., 2019, P 10 INT PARTICLE AC, P1851
   [Anonymous], KERAS DOCUMENTATION
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Azzopardi G, 2019, NUCL INSTRUM METH A, V934, P10, DOI 10.1016/j.nima.2019.04.057
   CHEN WH, 1984, IEEE T COMMUN, V32, P225
   Clarke JA, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/05/T05001
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emery L, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.082802
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Hock KM, 2011, NUCL INSTRUM METH A, V642, P36, DOI 10.1016/j.nima.2011.04.002
   Jaster-Merz S., 2022, P 13 INT PARTICLE AC, P279
   Ji FH, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082801
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Li YJ, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.054601
   MCKEE CB, 1995, NUCL INSTRUM METH A, V358, P264, DOI 10.1016/0168-9002(94)01411-6
   Omarov Z, 2022, NUCL INSTRUM METH A, V1026, DOI 10.1016/j.nima.2021.166132
   Rao KR, 2014, DISCRETE COSINE TRAN
   Röhrs M, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.050704
   Scheinker A, 2021, J INSTRUM, V16, DOI 10.1088/1748-0221/16/10/P10008
   Scheinker A., 2022, P 13 INT PARTICLE AC, P776
   Scheinker A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98785-0
   Scott D. J., 2019, P 10 INT PARTICLE AC, P1855
   Stratakis D, 2006, PHYS REV SPEC TOP-AC, V9, DOI 10.1103/PhysRevSTAB.9.112801
   Stratakis D, 2007, PHYS PLASMAS, V14, DOI 10.1063/1.2823037
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Wan JY, 2019, NUCL INSTRUM METH A, V946, DOI 10.1016/j.nima.2019.162683
   Wang G, 2020, NAT MACH INTELL, V2, P737, DOI 10.1038/s42256-020-00273-z
   WHO, 2012, WORLD MALARIA REPORT 2012, P1
   Wolski A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.032804
   Wolski A, 2006, PHYS REV SPEC TOP-AC, V9, DOI 10.1103/PhysRevSTAB.9.024001
   Xiang D, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.022801
   Xing QZ, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.072801
   Xu XY, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.032805
   Yakimenko V, 2003, PHYS REV SPEC TOP-AC, V6, DOI 10.1103/PhysRevSTAB.6.122801
NR 37
TC 3
Z9 3
U1 2
U2 3
PD DEC 15
PY 2022
VL 25
IS 12
AR 122803
DI 10.1103/PhysRevAccelBeams.25.122803
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Turvill, D
   Barnby, L
   Yuan, B
   Zahir, A
AF Turvill, Danielle
   Barnby, Lee
   Yuan, Bo
   Zahir, Ali
GP IEEE Comp Soc
TI A Survey of Interpretability of Machine Learning in Accelerator-based
   High Energy Physics
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING,
   APPLICATIONS AND TECHNOLOGIES (BDCAT 2020)
DT Proceedings Paper
CT 7th IEEE/ACM International Conference on Big Data Computing,
   Applications and Technologies (BDCAT)
CY DEC 07-10, 2020
CL ELECTR NETWORK
DE Explainable Artificial Intelligence (XAI); Machine Learning; Deep
   Learning; High Energy Physics; Big Data
ID NEURAL-NETWORKS; CLASSIFICATION; JET
AB Data intensive studies in the domain of accelerator-based High Energy Physics, HEP, have become increasingly more achievable due to the emergence of machine learning with high-performance computing and big data technologies. In recent years, the intricate nature of physics tasks and data has prompted the use of more complex learning methods. To accurately identify physics of interest, and draw conclusions against proposed theories, it is crucial that these machine learning predictions are explainable. For it is not enough to accept an answer based on accuracy alone, but it is important in the process of physics discovery to understand exactly why an output was generated. That is, completeness of a solution is required. In this paper, we survey the application of machine learning methods to a variety of accelerator-based tasks in a bid to understand what role interpretability plays within this area. The main contribution of this paper is to promote the need for explainable artificial intelligence, XAI, for the future of machine learning in HEP.
C1 [Turvill, Danielle; Barnby, Lee; Yuan, Bo; Zahir, Ali] Univ Derby, Sch Elect Comp & Math, Derby, England.
RP Turvill, D (corresponding author), Univ Derby, Sch Elect Comp & Math, Derby, England.
EM d.turvill@derby.ac.uk; l.barnby@derby.ac.uk; b.yuan@derby.ac.uk;
   ali.zahir@cern.ch
CR Ambriola M, 2003, NUCL INSTRUM METH A, V510, P362, DOI 10.1016/S0168-9002(03)01926-0
   Aurisano A, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/09/P09001
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Baldi P, 2016, EUR PHYS J C, V76, DOI 10.1140/epjc/s10052-016-4099-4
   Carrazza S, 2019, PHYS REV D, V100, DOI 10.1103/PhysRevD.100.014014
   Cerri O, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP05(2019)036
   Chen YCJ, 2020, PHYS REV D, V101, DOI 10.1103/PhysRevD.101.053001
   CHIAPPETTA P, 1994, PHYS LETT B, V322, P219, DOI 10.1016/0370-2693(94)91110-X
   Choi S, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2019)132
   CSABAI I, 1991, PHYS REV D, V44, pR1905, DOI 10.1103/PhysRevD.44.R1905
   de Oliveira L, 2020, NUCL INSTRUM METH A, V951, DOI 10.1016/j.nima.2019.162879
   Dillon BM, 2019, PHYS REV D, V100, DOI 10.1103/PhysRevD.100.056002
   Doshi-Velez, 2017, ARXIV170208608CSSTAT
   Englert C, 2019, EUR PHYS J C, V79, DOI 10.1140/epjc/s10052-018-6511-8
   Erdmann M, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/06/P06006
   Goodman B, 2017, AI MAG, V38, P50, DOI 10.1609/aimag.v38i3.2741
   Guest D, 2018, ANNU REV NUCL PART S, V68, P161, DOI 10.1146/annurev-nucl-101917-021019
   Gunning D., 2017, EXPLAINABLE ARTIFICI, V2, P2, DOI DOI 10.1126/SCIROBOTICS.AAY7120
   Komiske PT, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2019)121
   Lin JS, 2018, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2018)101
   Louppe G, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2019)057
   Lundberg SM, 2017, ADV NEUR IN, V30
   Magesh Pavan Rajkumar, 2020, ARXIV PREPRINT ARXIV
   Martínez JA, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12710-3
   Metodiev EM, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2017)174
   Mjahed M, 2002, NUCL INSTRUM METH A, V481, P601, DOI 10.1016/S0168-9002(01)01339-0
   Pawar U, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBER SITUATIONAL AWARENESS, DATA ANALYTICS AND ASSESSMENT (CYBER SA 2020), DOI 10.1109/cybersa49311.2020.9139655
   Poulin Brett, 1999, PROC NATL CONF ARTIF, V21
   Prasetyawan P, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON APPLIED ENGINEERING (ICAE)
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Roe BP, 2005, NUCL INSTRUM METH A, V543, P577, DOI 10.1016/j.nima.2004.12.018
   Sahin MO, 2016, NUCL INSTRUM METH A, V838, P137, DOI 10.1016/j.nima.2016.09.017
   Simonyan A., 2 INT C LEARN REPR I
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vaiciulis A, 2003, NUCL INSTRUM METH A, V502, P492, DOI 10.1016/S0168-9002(03)00479-0
   Vladymyrov M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/03/P03009
   Whiteson DO, 2003, NEUROCOMPUTING, V55, P251, DOI 10.1016/S0925-2312(03)00366-7
   Zhang YF, 2020, FOUND TRENDS INF RET, V14, P1, DOI 10.1561/1500000066
NR 40
TC 3
Z9 3
U1 1
U2 7
PY 2020
BP 77
EP 86
DI 10.1109/BDCAT50828.2020.00025
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Vilim, M
   Rucker, A
   Zhang, YQ
   Liu, S
   Olukotun, K
AF Vilim, Matthew
   Rucker, Alexander
   Zhang, Yaqi
   Liu, Sophia
   Olukotun, Kunle
GP IEEE
TI Gorgon: Accelerating Machine Learning from Relational Data
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
DE database; machine learning; accelerator; CGRA; Plasticine; Gorgon
ID BIG DATA
AB Accelerator deployment in data centers remains limited despite domain-specific architectures' promise of higher performance. Rapidly-changing applications and high NRE cost make deploying fixed-function accelerators at scale untenable. More flexible than DSAS, FPGAS are gaining traction but remain hampered by cumbersome programming models, long synthesis times, and slow clocks. Coarse-grained reconfigurable architectures (CGRA) are a compelling alternative and offer efficiency while retaining programmability-by providing general-purpose hardware and communication patterns, a single CGRA targets multiple application domains.
   One emerging application is in-database machine learning: a high-performance, low-friction interface for analytics on large databases. We co-locate database and machine learning processing in a unified reconfigurable data analytics accelerator, Gorgon, which flexibly shares resources between DB and ML without compromising performance or incurring excessive overheads in either domain. We distill and integrate database parallel patterns into an existing ML-focused CGRA, increasing area by less than 4% while outperforming a multicore software baseline by 1500X. We also explore the performance impact of unifying DB and ML in a single accelerator, showing up to 4x speedup over split accelerators.
CR [Anonymous], 2014, ISCA 14
   [Anonymous], 2018, PLDI 2018
   [Anonymous], 2016, SIGARCH COMPUT ARCHI
   [Anonymous], 2008, FDN TRENDELECT DES
   [Anonymous], 2017, 2017 IEEE 25 ANN INT
   [Anonymous], 2016, MICRO 49
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2019, MICRO 52
   [Anonymous], 2014, FPGA 14
   [Anonymous], 2019, ISCA 19
   [Anonymous], 2014, PROC ACM SIGDA INT S
   [Anonymous], 2018, ISCA 18
   [Anonymous], 2013, ISCA 13
   Bachrach J, 2012, DES AUT CON, P1212
   Bernstein PA, 2016, COMMUN ACM, V59, P92, DOI 10.1145/2845915
   Bhanushali K., 2015, P 2015 S INT S PHYS, P165
   Chen Yu-Hsin, 2016, ISCA 16
   CODD EF, 1970, COMMUN ACM, V13, P377, DOI 10.1145/357980.358007
   Dallemule L, 2017, HARVARD BUS REV, V95, P112
   Davenport TH, 2012, MIT SLOAN MANAGE REV, V54, P43
   Franks PJS, 2015, ICES J MAR SCI, V72, P1897, DOI 10.1093/icesjms/fsu175
   Ham TJ, 2016, INT SYMP MICROARCH
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Mahajan D, 2018, PROC VLDB ENDOW, V11, P1317, DOI 10.14778/3236187.3236188
   McAfee A, 2012, HARVARD BUS REV, V90, P60
   Melton J, 1996, ACM COMPUT SURV, V28, P141, DOI 10.1145/234313.234374
   Pedram A, 2011, IEEE INT CONF ASAP, P35, DOI 10.1109/ASAP.2011.6043234
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Ratner A, 2017, PROC VLDB ENDOW, V11, P269, DOI 10.14778/3157794.3157797
   Sidler D, 2017, I C FIELD PROG LOGIC
   So Hayden Kwok-Hay, 2016, FPGAS SOFTWARE PROGR, P285
   Turakhia Y, 2018, ACM SIGPLAN NOTICES, V53, P199, DOI [10.1145/3173162.3173193, 10.1145/3296957.3173193]
   Wu LS, 2014, ACM SIGPLAN NOTICES, V49, P255, DOI 10.1145/2541940.2541961
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   Zhang YQ, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P615, DOI 10.1145/3307650.3322249
NR 37
TC 11
Z9 11
U1 0
U2 4
PY 2020
BP 309
EP 321
DI 10.1109/ISCA45697.2020.00035
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT S
AU Kim, S
   Deka, GC
AF Kim, Shiho
   Deka, Ganesh Chandra
BE Kim, S
   Deka, GC
TI Hardware Accelerator Systems for Artificial Intelligence and Machine
   Learning Preface
SO HARDWARE ACCELERATOR SYSTEMS FOR ARTIFICIAL INTELLIGENCE AND MACHINE
   LEARNING
SE Advances in Computers
DT Editorial Material; Book Chapter
C1 [Kim, Shiho] Yonsei Univ, Sch Integrated Technol, Seoul, South Korea.
RP Kim, S (corresponding author), Yonsei Univ, Sch Integrated Technol, Seoul, South Korea.
NR 0
TC 0
Z9 0
U1 0
U2 1
PY 2021
VL 122
BP XI
EP XII
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Kaul, H
   Anders, M
   Mathew, S
   Kim, S
   Krishnamurthy, R
AF Kaul, Himanshu
   Anders, Mark
   Mathew, Sanu
   Kim, Seongjong
   Krishnamurthy, Ram
BE Takagi, N
   Boldo, S
   Langhammer, M
TI Optimized Fused Floating-Point Many-Term Dot-Product Hardware for
   Machine Learning Accelerators
SO 2019 IEEE 26TH SYMPOSIUM ON COMPUTER ARITHMETIC (ARITH)
SE Proceedings Symposium on Computer Arithmetic
DT Proceedings Paper
CT 26th IEEE Symposium on Computer Arithmetic (ARITH)
CY JUN 10-12, 2019
CL Kyoto, JAPAN
DE floating-point; dot-product; machine learning
AB This paper describes optimizations for the critical maximum exponent and alignment operations, with scalability for many-term fused floating-point dot-product units. The impact of these optimizations is quantified for up to 32-term BFloat16 weight/activation inputs with single-precision dot-product output, targeted for machine learning accelerators. Area and energy efficiency results are compared across performance targets, design parameters, and data statistics.
C1 [Kaul, Himanshu; Anders, Mark; Mathew, Sanu; Kim, Seongjong; Krishnamurthy, Ram] Intel Corp, Circuit Res Lab, Hillsboro, OR 97124 USA.
RP Kaul, H (corresponding author), Intel Corp, Circuit Res Lab, Hillsboro, OR 97124 USA.
CR Anders M, 2018, SYMP VLSI CIRCUITS, P39, DOI 10.1109/VLSIC.2018.8502333
   [Anonymous], 2017, INT S COMP ARCH ISCA
   Auth C, 2017, INT EL DEVICES MEET
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Kim D, 2009, IEEE T COMPUT, V58, P890, DOI 10.1109/TC.2008.210
   Kwon Hyoukjun, 2016, S VLSI
   Park S, 2015, ISSCC DIG TECH PAP I, V58, P80, DOI 10.1109/ISSCC.2015.7062935
   Sohn J, 2016, IEEE T CIRCUITS-I, V63, P370, DOI 10.1109/TCSI.2016.2525042
   Sohn J, 2013, P S COMP ARITHM, P41, DOI 10.1109/ARITH.2013.26
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
NR 10
TC 6
Z9 7
U1 0
U2 3
PY 2019
BP 84
EP 87
DI 10.1109/ARITH.2019.00021
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Information Systems; Computer Science,
   Software Engineering; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Ryu, S
   Park, N
   Kim, JJ
AF Ryu, Sungju
   Park, Naebeom
   Kim, Jae-Joon
TI Feedforward-Cutset-Free Pipelined Multiply-Accumulate Unit for the
   Machine Learning Accelerator
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Hardware accelerator; machine learning; multiply-accumulate (MAC) unit;
   pipelining
AB Multiply-accumulate (MAC) computations account for a large part of machine learning accelerator operations. The pipelined structure is usually adopted to improve the performance by reducing the length of critical paths. An increase in the number of flip-flops due to pipelining, however, generally results in significant area and power increase. A large number of flip-flops are often required to meet the feedforward-cutset rule. Based on the observation that this rule can be relaxed in machine learning applications, we propose a pipelining method that eliminates some of the flip-flops selectively. The simulation results show that the proposed MAC unit achieved a 20% energy saving and a 20% area reduction compared with the conventional pipelined MAC.
C1 [Ryu, Sungju; Park, Naebeom; Kim, Jae-Joon] Pohang Univ Sci & Technol, Dept Creat IT Engn, Pohang 37673, South Korea.
RP Kim, JJ (corresponding author), Pohang Univ Sci & Technol, Dept Creat IT Engn, Pohang 37673, South Korea.
EM sungju.ryu@postech.ac.kr; naebeom.park@postech.ac.kr;
   jaejoon@postech.ac.kr
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chorowski J. K., 2015, ADV NEURAL INFORM PR, P577, DOI DOI 10.1016/0167-739X(94)90007-8
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Dadda L., 1965, ALTA FREQ, V34, P349
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hoang TT, 2010, IEEE T CIRCUITS-I, V57, P3073, DOI 10.1109/TCSI.2010.2091191
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Stelling PF, 1997, P S COMP ARITHM, P99, DOI 10.1109/ARITH.1997.614884
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Townsend WJ, 2003, PROC SPIE, V5205, P552, DOI 10.1117/12.507012
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Zisserman A., 2014, 14091556 ARXIV
NR 17
TC 9
Z9 9
U1 1
U2 1
PD JAN
PY 2019
VL 27
IS 1
BP 138
EP 146
DI 10.1109/TVLSI.2018.2873716
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ananthanarayanan, R
   Brandt, P
   Joshi, M
   Sathiamoorthy, M
AF Ananthanarayanan, Rajagopal
   Brandt, Peter
   Joshi, Manasi
   Sathiamoorthy, Maheswaran
GP USENIX Assoc
TI Opportunities and Challenges Of Machine Learning Accelerators In
   Production
SO PROCEEDINGS OF THE 2019 USENIX CONFERENCE ON OPERATIONAL MACHINE
   LEARNING
DT Proceedings Paper
CT USENIX Conference on Operational Machine Learning (OpML)
CY MAY 20, 2019
CL Santa Clara, CA
AB The rise of deep learning has resulted in tremendous demand for compute power, with the FLOPS required for leading machine learning (ML) research doubling roughly every 3.5 months since 2012 [1]. This increase in demand for compute has coincided with the end of Moore's Law [2].
   As a result, major industry players such as NVIDIA, Intel, and Google have invested in ML accelerators that are purpose built for deep learning workloads.
   ML accelerators present many opportunities and challenges in production environments. This paper discusses some high level observations from experience internally at Google.
C1 [Ananthanarayanan, Rajagopal; Brandt, Peter; Joshi, Manasi; Sathiamoorthy, Maheswaran] Google Inc, Mountain View, CA 94043 USA.
RP Ananthanarayanan, R (corresponding author), Google Inc, Mountain View, CA 94043 USA.
EM ananthr@google.com; pbrandt@google.com; manasi@google.com;
   nlogn@google.com
CR [Anonymous], ABS170605137 ARXIV
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Caruana R A, 1993, P 10 INT C MACHINE L, V48, P41, DOI [DOI 10.1016/B978-1-55860-307-3.50012-5, 10.1016/b978-1-55860-307-3.50012-5]
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Devlin J., 2018, PREPRINT
   Ghodsi An, 2011, Computer Communication Review, V41, P507, DOI 10.1145/2018584.2018586
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Jouppi NP, 2018, COMMUN ACM, V61, P50, DOI 10.1145/3154484
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Le Q. V., 2016, ARXIV161101578
   Oord A. V. D., 2016, ARXIV
   Real E., 2019, P AAAI C ART INT, DOI DOI 10.1609/AAAI.V33I01.33014780
   Shallue C.J., 2018, ARXIV181103600
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
NR 16
TC 9
Z9 9
U1 0
U2 0
PY 2019
BP 1
EP 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Silveira, P
   De Rose, CA
   Zorzo, FA
   Xavier, MG
   Milojicic, D
   Chalamalasetti, SR
   Serebryakov, S
AF Silveira, Plinio
   De Rose, Cesar Augusto
   Zorzo, Francisco Avelino
   Xavier, Miguel Gomes
   Milojicic, Dejan
   Chalamalasetti, Sai Rahul
   Serebryakov, Sergey
BE Chan, WK
   Claycomb, B
   Takakura, H
   Yang, JJ
   Teranishi, Y
   Towey, D
   Segura, S
   Shahriar, H
   Reisman, S
   Ahamed, SI
TI Resource Sharing and Security Implications on Machine Learning Inference
   Accelerators
SO 2021 IEEE 45TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE
   (COMPSAC 2021)
SE Proceedings International Computer Software and Applications Conference
DT Proceedings Paper
CT 45th Annual International IEEE-Computer-Society Computers, Software, and
   Applications Conference (COMPSAC)
CY JUL 12-16, 2021
CL ELECTR NETWORK
DE machine learning; deep learning; accelerator; resource management;
   resource sharing; security; inference
AB Due to the increasing adoption of Machine Learning (ML) and in particular Deep Learning (DL), many specialized energy efficient accelerators are being proposed by academia and industry. A number of these accelerators are designed to run a single application at a time in exclusive access mode. This approach gives applications maximum performance but reduces resource efficiency, resulting in increased costs over time. Sharing the device among multiple jobs increases resource utilization and amplifies return on investment. This study is driven by a broad investigation of various spatial resource sharing strategies in machine learning hardware accelerators and performance evaluation in a novel memristor-based accelerator called PUMA [1]. Two methods of spatial sharing are discussed: Model Packing and Logical Allocation. Simulations showed that both methods can be implemented on the PUMA accelerator and have advantages in terms of increased resource utilization. The former spatial sharing strategy achieves higher level of parallelism, fitting more models per device (7 models on 11 tiles), but has higher interference overhead (up to 49%), still being in most cases better than the overhead found for GPUs. The latter spatial sharing strategy achieves better isolation with almost no interference overhead (<1%) with the cost of leaving resources unused (same 7 models consumed 16 tiles). Finally, we discuss security implications of resource sharing for ML and other concerns, presenting a novel ML model integrity check and model bias verification.
C1 [Silveira, Plinio; De Rose, Cesar Augusto; Zorzo, Francisco Avelino; Xavier, Miguel Gomes] Pontificia Univ Catolica Rio Grande do Sul, Sch Technol, Porto Alegre, RS, Brazil.
   [Milojicic, Dejan; Chalamalasetti, Sai Rahul; Serebryakov, Sergey] Hewlett Packard Labs, Palo Alto, CA USA.
RP Silveira, P (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Sch Technol, Porto Alegre, RS, Brazil.
EM plinio.silveira@hpe.com; cesar.derose@pucrs.br; avelino.zorzo@pucrs.br;
   miguel.xavier@pucrs.br; dejan.milojicic@hpe.com;
   sairahul.chalamalasetti@hpe.com; sergey.serebryakov@hpe.com
CR Ambrosi J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P141
   Ankit A, 2020, IEEE T COMPUT, V69, P1128, DOI 10.1109/TC.2020.2998456
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Barreno M, 2010, MACH LEARN, V81, P121, DOI 10.1007/s10994-010-5188-5
   Cass S., 2019, IEEE SPECTRUM, V56, P16, DOI [DOI 10.1109/MSPEC.2019.8701189, 10.1109/MSPEC.2019.8701189]
   Chandrasekaran S., 2020, NVIDIA BLOG MAY
   Chen Xuhui, 2018, AS C MACH LEARN, P646
   Dietterich TG, 1995, TECHNICAL REPORT
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Faraji I, 2015, ESPM 15, P47, DOI [10.1145/2832241.2832247, DOI 10.1145/2832241.2832247]
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gerangelos S, 2019, J SYST SOFTWARE, V150, P37, DOI 10.1016/j.jss.2018.12.029
   Gu Z., 2018, ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2012, ADV NEURAL INF PROCE, P1097
   Huang GL, 2017, IEEE ICC
   Intel<(R), 2019, INTEL NEURAL COMPUTE
   Jain P., 2018, ARXIV PREPRINT ARXIV
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   McGraw G, 2019, COMPUTER, V52, P54, DOI 10.1109/MC.2019.2909955
   Mittal S, 2019, MACH LEARN KNOW EXTR, V1, P75, DOI 10.3390/make1010005
   Narayanan Deepak, 2018, NEURIPS WORKSH SYST
   Ohrimenko O, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P619
   Panda D.K, 2017, P MACHINE LEARNING H, P8
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Radford A., 2019, OPENAI BLOG
   Real M. M., 2016, 2016 11 INT S REC CO, P1
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Vaswani A, 2017, ADV NEUR IN, V30
   Walker J., 2014, NETWORK SYSTEM SECUR, Vsecond, P179, DOI DOI 10.1016/B978-0-12-416689-9.00007-1
   Xiao WC, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P595
NR 32
TC 0
Z9 0
U1 0
U2 2
PY 2021
BP 59
EP 67
DI 10.1109/COMPSAC51774.2021.00020
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering
DA 2023-11-11
ER

PT C
AU Sunny, F
   Taheri, E
   Nikdast, M
   Pasricha, S
AF Sunny, Febin
   Taheri, Ebadollah
   Nikdast, Mahdi
   Pasricha, Sudeep
BE IEEE
TI Machine Learning Accelerators in 2.5D Chiplet Platforms with Silicon
   Photonics
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE 2.5D chiplet platforms; machine learning; silicon photonics; interposer
   networks; manycore computing
AB Domain-specific machine learning (ML) accelerators such as Google's TPU and Apple's Neural Engine now dominate CPUs and GPUs for energy-efficient ML processing. However, the evolution of electronic accelerators is facing fundamental limits due to the limited computation density of monolithic processing chips and the reliance on slow metallic interconnects. In this paper, we present a vision of how optical computation and communication can be integrated into 2.5D chiplet platforms to drive an entirely new class of sustainable and scalable ML hardware accelerators. We describe how cross-layer design and fabrication of optical devices, circuits, and architectures, and hardware/software codesign can help design efficient photonics-based 2.5D chiplet platforms to accelerate emerging ML workloads.
C1 [Sunny, Febin; Taheri, Ebadollah; Nikdast, Mahdi; Pasricha, Sudeep] Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO 80523 USA.
RP Sunny, F (corresponding author), Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO 80523 USA.
EM febin.sunny@colostate.edu; ebad.taheri@colostate.edu;
   mahdi.nikdast@colostate.edu; sudeep@colostate.edu
CR [Anonymous], 2015, U NET CONVOLUTIONAL
   Bahirat S., 2009, IEEE ACM CODES ISSS
   Banerjee S., 2022, IEEE JSTQE
   Bangari V, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2945540
   Beck N, 2018, ISSCC DIG TECH PAP I, P40, DOI 10.1109/ISSCC.2018.8310173
   Bogaerts W, 2012, LASER PHOTONICS REV, V6, P47, DOI 10.1002/lpor.201100017
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Chittamuru SVR, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3060517
   Chittamuru SVR, 2015, IEEE DES TEST, V32, P29, DOI 10.1109/MDAT.2015.2414417
   Demirkiran C, 2022, Arxiv, DOI arXiv:2109.01126
   Ehrett P, 2019, DES AUT TEST EUROPE, P510, DOI [10.23919/date.2019.8714998, 10.23919/DATE.2019.8714998]
   Fotouhi P, 2019, J OPT COMMUN NETW, V11, P333, DOI 10.1364/JOCN.11.000333
   Gu J., 2020, IEEEACM ASP DAC
   Huang J, 2021, NANOPHOTONICS-BERLIN, V10, P1011, DOI 10.1515/nanoph-2020-0494
   Jaiswal S., 2020, ARTIF INTELL
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kim J, 2020, IEEE T VLSI SYST, V28, P2424, DOI 10.1109/TVLSI.2020.3015494
   Kukkala VK, 2020, IEEE T COMPUT AID D, V39, P3698, DOI 10.1109/TCAD.2020.3012749
   Kukkala VK, 2018, IEEE CONSUM ELECTR M, V7, P18, DOI 10.1109/MCE.2018.2828440
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Law FK, 2019, OPT QUANT ELECTRON, V51, DOI 10.1007/s11082-018-1712-9
   Li Y, 2021, DES AUT CON, P931, DOI 10.1109/DAC18074.2021.9586311
   Li Y, 2022, IEEE T PARALL DISTR, V33, P2332, DOI 10.1109/TPDS.2021.3139015
   Liu WC, 2019, DES AUT TEST EUROPE, P1483, DOI [10.23919/date.2019.8715195, 10.23919/DATE.2019.8715195]
   Miller DAB, 2009, P IEEE, V97, P1166, DOI 10.1109/JPROC.2009.2014298
   Nambiar S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071142
   Narayan A., 2020, IEEE TCAD
   Pasricha S., 2021, IEEE DES TEST, V37
   Pasricha S, 2015, 2015 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), P37, DOI 10.1109/CODESISSS.2015.7331366
   Sundaram V, 2013, 2013 IEEE 63RD ELECTRONIC COMPONENTS AND TECHNOLOGY CONFERENCE (ECTC), P342, DOI 10.1109/ECTC.2013.6575593
   Sunny F., 2022, ACM GLSVLSI
   Sunny F, 2022, IEEE COMPUT SOC, P98, DOI 10.1109/ISVLSI54635.2022.00030
   Sunny F, 2021, DES AUT CON, P1069, DOI 10.1109/DAC18074.2021.9586161
   Sunny FP, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3459009
   Sunny FP, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3476988
   Taheri E., 2022, ACM DATE
   Taheri E, 2022, ICCAD-IEEE ACM INT, DOI 10.1145/3508352.3549432
   Tait AN, 2016, IEEE J SEL TOP QUANT, V22, DOI 10.1109/JSTQE.2016.2573583
   Teo TY, 2022, OPT MATER EXPRESS, V12, P606, DOI 10.1364/OME.447289
   Thakkar I., 2017, IEEE ACM NOCS
   Tran MA, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071139
   Xu Y, 2014, IEEE DES TEST, V31, P9, DOI 10.1109/MDAT.2014.2332153
   Zhou ZP, 2015, LIGHT-SCI APPL, V4, DOI 10.1038/lsa.2015.131
   Zokaee F, 2020, DES AUT TEST EUROPE, P1438, DOI 10.23919/DATE48585.2020.9116494
NR 44
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT J
AU Mukherjee, M
   Long, Y
   Woo, J
   Kim, D
   Rahman, NM
   Dash, S
   Mukhopadhyay, S
AF Mukherjee, Mandovi
   Long, Yun
   Woo, Jongseok
   Kim, Daehyun
   Rahman, Nael Mizanur
   Dash, Saurabh
   Mukhopadhyay, Saibal
TI A Flexible Precision Multi-Format In-Memory Vector Matrix Multiplication
   Engine in 65 nm CMOS With RF Machine Learning Support
SO IEEE SOLID-STATE CIRCUITS LETTERS
DT Article
DE Accelerators; processing-in-memory (PIM); radio-frequency (RF) machine
   learning (ML); vector matrix multiplication (VMM)
AB An all-digital flexible precision in-memory accelerator for vector matrix multiplication (VMM) is demonstrated in 65 nm CMOS. The design supports flexible precision, floating point, and complex numbers enabling in-memory radio-frequency machine learning and signal processing computation. The measured compute efficiency normalized to memory size is 34 GOPS/W/KB.
C1 [Mukherjee, Mandovi; Long, Yun; Woo, Jongseok; Kim, Daehyun; Rahman, Nael Mizanur; Dash, Saurabh; Mukhopadhyay, Saibal] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Mukherjee, M (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM mmukherjee8@gatech.edu
CR Noel JP, 2020, IEEE SOLID-ST CIRC L, V3, P286, DOI 10.1109/LSSC.2020.3010377
   Okumura S, 2019, SYMP VLSI CIRCUITS, pC248
   OShea T. J., 2016, PROC GNU RADIO C, V1
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
NR 7
TC 1
Z9 1
U1 0
U2 0
PY 2020
VL 3
BP 450
EP 453
DI 10.1109/LSSC.2020.3023703
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ren, W
   Kozlowski, W
   Koteshwara, S
   Ye, MM
   Franke, H
   Chen, DM
AF Ren, Wei
   Kozlowski, William
   Koteshwara, Sandhya
   Ye, Mengmei
   Franke, Hubertus
   Chen, Deming
GP IEEE
TI AccShield: a New Trusted Execution Environment with Machine-Learning
   Accelerators
SO 2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC
DT Proceedings Paper
CT 60th ACM/IEEE Design Automation Conference (DAC)
CY JUL 09-13, 2023
CL San Francisco, CA
DE Trusted execution environment (TEE); cloud computing; accelerator TEE;
   confidential computing
AB Machine learning accelerators such as the Tensor Processing Unit (TPU) are already being deployed in the hybrid cloud, and we foresee such accelerators proliferating in the future. In such scenarios, secure access to the acceleration service and trustworthiness of the underlying accelerators become a concern. In this work, we present AccShield, a new method to extend trusted execution environments (TEEs) to cloud accelerators which takes both isolation and multi-tenancy into security consideration. We demonstrate the feasibility of accelerator TEEs by a proof of concept on an FPGA board. Experiments with our prototype implementation also provide concrete results and insights for different design choices related to link encryption, isolation using partitioning and memory encryption.
C1 [Ren, Wei; Kozlowski, William; Chen, Deming] Univ Illinois, Champaign, IL 61820 USA.
   [Koteshwara, Sandhya; Ye, Mengmei; Franke, Hubertus] IBM Res, Yorktown Hts, NY USA.
RP Ren, W (corresponding author), Univ Illinois, Champaign, IL 61820 USA.
EM weiren2@illinois.edu; wk10@illinois.edu; sandhya.koteshwara@ibm.com;
   mye@ibm.com; frankeh@us.ibm.com; dchen@illinois.edu
CR Amazon Web Services, 2022, AM EC2 F1 INST
   AMD, 2020, STRENGTH VM IS INT P
   ARM Limited, 2021, ARM CONF COMP ARCH
   ARM Limited, 2009, ARM SEC TECHN BUILD
   Banerjee S., 2020, ARXIV
   Burstein I., 2021, 2021 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HCS52781.2021.9567066
   Chen DM, 2006, ACM T DES AUTOMAT EL, V11, P362, DOI 10.1145/1142155.1142161
   Costan V, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P857
   Dana Neustadter Synopsys, 2022, PROTECTING DATA PCIE
   DMTF, 2021, SEC PROT DAT MOD SPE
   Firestone D, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P51
   Fuhrmann J., 2018, IMPLEMENTATION TENSO
   Gassend B, 2002, 18TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P149, DOI 10.1109/CSAC.2002.1176287
   Göttel C, 2018, SYM REL DIST SYST, P133, DOI 10.1109/SRDS.2018.00024
   Halderman JA, 2009, COMMUN ACM, V52, P91, DOI 10.1145/1506409.1506429
   Hua W., 2022, DAC
   Ignatov A, 2019, LECT NOTES COMPUT SC, V11133, P288, DOI 10.1007/978-3-030-11021-5_19
   Intel, 2022, INT TRUST DOM EXT
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Konigsmark STC, 2017, IEEE INT CONF ASAP, P37, DOI 10.1109/ASAP.2017.7995257
   Konigsmark STC, 2016, DES AUT CON, DOI 10.1145/2897937.2898034
   Konigsmark STC, 2014, ASIA S PACIF DES AUT, P73, DOI 10.1109/ASPDAC.2014.6742869
   Korolija D, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P991
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee D, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387532
   McKeen, 2013, P 2 INT WORKSH HARDW, P10
   NVIDIA, 2022, NVIDIA H100 TENS COR
   Oded G., 2009, FDN CRYPTOGRAPHY, V2
   Oh H, 2021, IEEE ACCESS, V9, P51313, DOI 10.1109/ACCESS.2021.3069223
   Papakonstantinou A, 2009, 2009 IEEE 7TH SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS (SASP 2009), P35, DOI 10.1109/SASP.2009.5226333
   Paverd Andrew, 2014, MODELLING AUTOMATICA
   Ren W, 2021, 2021 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2021), P378, DOI 10.1109/iSES52644.2021.00093
   Russinovich M, 2021, COMMUN ACM, V64, P54, DOI 10.1145/3453930
   Vaswani K., 2022, ARXIV
   Volos S, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P681
   Zhu JP, 2020, P IEEE S SECUR PRIV, P1450, DOI 10.1109/SP40000.2020.00054
NR 37
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/DAC56929.2023.10247768
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Bojnordi, MN
   Ipek, E
AF Bojnordi, Mandi Nazm
   Ipek, Engin
GP IEEE
TI Memristive Boltzmann Machine: A Hardware Accelerator for Combinatorial
   Optimization and Deep Learning
SO 2017 FIFTH BERKELEY SYMPOSIUM ON ENERGY EFFICIENT ELECTRONIC SYSTEMS &
   STEEP TRANSISTORS WORKSHOP (E3S)
DT Proceedings Paper
CT 5th Berkeley Symposium on Energy Efficient Electronic Systems and Steep
   Transistors Workshop (E3S)
CY OCT 19-20, 2017
CL Univ California, Berkeley, CA
HO Univ California
C1 [Bojnordi, Mandi Nazm] Univ Utah, Salt Lake City, UT 84112 USA.
   [Ipek, Engin] Univ Rochester, Rochester, NY 14627 USA.
RP Bojnordi, MN (corresponding author), Univ Utah, Salt Lake City, UT 84112 USA.
EM bojnordi@cs.utah.edu; ipek@ece.rochester.edu
CR [Anonymous], 2016, P ISCA
   Fahlman SE, 1983, P NAT C AI
   U. D. of Energy, 2014, TOP 10 EX RES CHALL
   Wegener I., 2004, EL C COMP COMPL
NR 4
TC 0
Z9 0
U1 0
U2 0
PY 2017
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ankit, A
   Chakraborty, I
   Agrawal, A
   Ali, M
   Roy, K
AF Ankit, Aayush
   Chakraborty, Indranil
   Agrawal, Amogh
   Ali, Mustafa
   Roy, Kaushik
TI Circuits and Architectures for In-Memory Computing-Based Machine
   Learning Accelerators
SO IEEE MICRO
DT Article
DE Random access memory; Nonvolatile memory; CMOS technology; Memory
   management; Feature extraction; Acceleration; Machine learning;
   In-memory computing; architectures; circuits
ID SRAM
AB Machine learning applications, especially deep neural networks (DNNs) have seen ubiquitous use in computer vision, speech recognition, and robotics. However, the growing complexity of DNN models have necessitated efficient hardware implementations. The key compute primitives of DNNs are matrix vector multiplications, which lead to significant data movement between memory and processing units in today's von Neumann systems. A promising alternative would be colocating memory and processing elements, which can be further extended to performing computations inside the memory itself. We believe in-memory computing is a propitious candidate for future DNN accelerators, since it mitigates the memory wall bottleneck. In this article, we discuss various in-memory computing primitives in both CMOS and emerging nonvolatile memory (NVM) technologies. Subsequently, we describe how such primitives can be incorporated in standalone machine learning accelerator architectures. Finally, we analyze the challenges associated with designing such in-memory computing accelerators and explore future opportunities.
C1 [Ankit, Aayush] Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Chakraborty, Indranil; Agrawal, Amogh] Purdue Univ, Nanoelect Res Lab, W Lafayette, IN 47907 USA.
   [Ali, Mustafa; Roy, Kaushik] Purdue Univ, W Lafayette, IN 47907 USA.
RP Ankit, A (corresponding author), Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM aankit@purdue.edu; ichakra@purdue.edu; agrawa64@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Agrawal A., 2019, ARXIV190700285
   Agrawal A, 2019, IEEE T CIRCUITS-I, V66, P3064, DOI 10.1109/TCSI.2019.2907488
   Agrawal A, 2018, IEEE T CIRCUITS-I, V65, P4219, DOI 10.1109/TCSI.2018.2848999
   Ali ME, 2020, IEEE T CIRCUITS-I, V67, P155, DOI 10.1109/TCSI.2019.2945617
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ankit A, 2020, IEEE T COMPUT AID D, V39, P2361, DOI 10.1109/TCAD.2019.2946820
   Ankit A, 2020, IEEE T COMPUT, V69, P1128, DOI 10.1109/TC.2020.2998456
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit A, 2017, DES AUT CON, DOI 10.1145/3061639.3062311
   Ankit A, 2017, ICCAD-IEEE ACM INT, P533, DOI 10.1109/ICCAD.2017.8203823
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Chakraborty I., 2020, P 57 ANN DES AUT C
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chin Y.-W., 2014, P IEEE INT EL DEV M, P6
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fleischer B., 2018, UNLOCKING PROMISE AP
   Fong XY, 2016, IEEE T COMPUT AID D, V35, P1, DOI 10.1109/TCAD.2015.2481793
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hubara I, 2018, J MACH LEARN RES, V18
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jaiswal A, 2019, IEEE T VLSI SYST, V27, P2556, DOI 10.1109/TVLSI.2019.2929245
   Kawahara A, 2013, IEEE J SOLID-ST CIRC, V48, P178, DOI 10.1109/JSSC.2012.2215121
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee DU, 2014, ISSCC DIG TECH PAP I, V57, P432, DOI 10.1109/ISSCC.2014.6757501
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Liang L, 2018, IEEE ACCESS, V6, P58324, DOI 10.1109/ACCESS.2018.2874823
   Liu BY, 2014, ICCAD-IEEE ACM INT, P63, DOI 10.1109/ICCAD.2014.7001330
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Narayanan P, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2716579
   Noguchi H, 2016, ISSCC DIG TECH PAP I, V59, P132, DOI 10.1109/ISSCC.2016.7417942
   Ohyanagi T, 2013, JPN J APPL PHYS, V52, DOI 10.7567/JJAP.52.05FF01
   Sengupta A, 2017, APPL PHYS REV, V4, DOI 10.1063/1.5012763
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Youngdon Choi, 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P46, DOI 10.1109/ISSCC.2012.6176872
NR 44
TC 12
Z9 12
U1 4
U2 28
PD NOV
PY 2020
VL 40
IS 6
BP 8
EP 21
DI 10.1109/MM.2020.3025863
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Qian, XH
   Wang, YZ
   Karanth, A
AF Qian, Xuehai
   Wang, Yanzhi
   Karanth, Avinash
TI Guest Editors' Introduction to the Special Issue on Machine Learning
   Architectures and Accelerators
SO IEEE TRANSACTIONS ON COMPUTERS
DT Editorial Material
C1 [Qian, Xuehai] Univ Southern Calif, Ming Hsieh Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Wang, Yanzhi] Northeastern Univ, Elect & Comp Engn, Boston, MA 02115 USA.
   [Karanth, Avinash] Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
RP Qian, XH (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
EM xuehai.qian@usc.edu; yanz.wang@northeastern.edu; karanth@ohio.edu
NR 0
TC 0
Z9 0
U1 0
U2 0
PD JUL 1
PY 2020
VL 69
IS 7
BP 929
EP 930
DI 10.1109/TC.2020.2997574
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Verhelst, M
AF Verhelst, Marian
GP IEEE
TI Exploiting FDSOI towards minimum energy point operation in processors
   and machine learning accelerators
SO ESSCIRC 2018 - IEEE 44TH EUROPEAN SOLID STATE CIRCUITS CONFERENCE
   (ESSCIRC)
SE Proceedings of the European Solid-State Circuits Conference
DT Proceedings Paper
CT 44th IEEE European Solid State Circuits Conference (ESSCIRC)
CY SEP 03-06, 2018
CL Dresden, GERMANY
C1 [Verhelst, Marian] Katholieke Univ Leuven, ESAT MICAS, Leuven, Belgium.
RP Verhelst, M (corresponding author), Katholieke Univ Leuven, ESAT MICAS, Leuven, Belgium.
EM Marian.Verhelst@esat.kuleuven.be
NR 0
TC 0
Z9 0
U1 0
U2 0
PY 2018
BP 217
EP 217
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Verhelst, M
AF Verhelst, Marian
GP IEEE
TI Exploiting FDSOI towards minimum energy point operation in processors
   and machine learning accelerators
SO 2018 48TH EUROPEAN SOLID-STATE DEVICE RESEARCH CONFERENCE (ESSDERC)
SE Proceedings of the European Solid-State Device Research Conference
DT Proceedings Paper
CT 48th European Solid-State Device Research Conference (ESSDERC)
CY SEP 03-06, 2018
CL Dresden, GERMANY
C1 [Verhelst, Marian] Katholieke Univ Leuven, ESAT MICAS, Leuven, Belgium.
RP Verhelst, M (corresponding author), Katholieke Univ Leuven, ESAT MICAS, Leuven, Belgium.
EM Marian.Verhelst@esat.kuleuven.be
NR 0
TC 0
Z9 0
U1 0
U2 0
PY 2018
BP 157
EP 157
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT S
AU Gupta, N
AF Gupta, Neha
BE Kim, S
   Deka, GC
TI Introduction to hardware accelerator systems for artificial intelligence
   and machine learning
SO HARDWARE ACCELERATOR SYSTEMS FOR ARTIFICIAL INTELLIGENCE AND MACHINE
   LEARNING
SE Advances in Computers
DT Editorial Material; Book Chapter
ID FPGA
AB An AI accelerator is a category of specialized hardware accelerator or automatic data processing system designed to accelerate computer science applications, particularly artificial neural networks, machine visualization and machine learning. Typical applications embrace algorithms for AI, Internet of things and different data-intensive or sensor-driven tasks. Machine learning is widely employed in several modern artificial intelligence applications. Varied hardware platforms are enforced to support such applications. Among them, graphics process unit (GPU) is the most widely used because of its quick computation speed and compatibility with varied algorithms. Field programmable gate arrays (FPGA) show higher energy potency as compared with GPU when computing machine learning algorithm at the cost of low speed. Varied application-specific integrated circuits (ASIC) design are projected to realize the most effective energy potency at the value of less reconfigurability that makes it appropriate for special varieties of machine learning algorithms like a deep convolutional neural network. In this chapter, we will try to relate artificial intelligence and machine learning concepts to accelerate hardware resources. Chapter will discuss software framework for Deep Neural Networks and will give comparison of FPGA, CPU and GPU. At the end of the chapter future directions and conclusion will be given.
C1 [Gupta, Neha] Manav Rachna Int Inst Res & Studies, Fac Comp Applicat, Faridabad, India.
RP Gupta, N (corresponding author), Manav Rachna Int Inst Res & Studies, Fac Comp Applicat, Faridabad, India.
CR [Anonymous], 2019, UCI MACHINE LEARNING
   [Anonymous], 2001, FPGA 01
   [Anonymous], 2013, T SENS SUMM OCT
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Collobert R., 2011, BIGLEARN
   Darabiha A, 2003, PROC CVPR IEEE, P203
   Díaz J, 2006, IEEE T CIRC SYST VID, V16, P274, DOI 10.1109/TCSVT.2005.861947
   Donahue J, 2014, PR MACH LEARN RES, V32
   Esmaeilzadeh H, 2015, COMMUN ACM, V58, P105, DOI 10.1145/2589750
   Fykse E, 2013, THESIS I EL TEL
   Gartner Research, 2015, GARTNER SAYS 64 BILL
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo C., 2012, FPT
   Guo L., 2015, FCCM
   Iandola FN, 2016, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR.2016.284
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2019, THE MNIST DATABASE
   Liu XX, 2015, DES AUT CON, DOI 10.1145/2744769.2744900
   Maliatski B, 2005, IEEE TCSVT, V15
   Marr B., 2015, FORBECOM
   Niitsuma H., 2005, FPL
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Saegusa T, 2007, J REAL-TIME IMAGE PR, V2, P309, DOI 10.1007/s11554-007-0055-8
   Saegusa T, 2008, I C FIELD PROG LOGIC, P77, DOI 10.1109/FPL.2008.4629911
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
NR 28
TC 3
Z9 3
U1 2
U2 8
PY 2021
VL 122
BP 1
EP 21
DI 10.1016/bs.adcom.2020.07.001
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Mahajan, D
   Park, J
   Amaro, E
   Sharma, H
   Yazdanbakhsh, A
   Kim, JK
   Esmaeilzadeh, H
AF Mahajan, Divya
   Park, Jongse
   Amaro, Emmanuel
   Sharma, Hardik
   Yazdanbakhsh, Amir
   Kim, Joon Kyung
   Esmaeilzadeh, Hadi
GP IEEE
TI TABLA: A Unified Template-based Framework for Accelerating Statistical
   Machine Learning
SO PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE
   COMPUTER ARCHITECTURE (HPCA-22)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 22nd IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY MAR 12-16, 2016
CL Barcelona, SPAIN
AB A growing number of commercial and enterprise systems increasingly rely on compute-intensive Machine Learning (ML) algorithms. While the demand for these compute-intensive applications is growing, the performance benefits from general-purpose platforms are diminishing. Field Programmable Gate Arrays (FPGAs) provide a promising path forward to accommodate the needs of machine learning algorithms and represent an intermediate point between the efficiency of ASICs and the programmability of general-purpose processors. However, acceleration with FPGAs still requires long development cycles and extensive expertise in hardware design. To tackle this challenge, instead of designing an accelerator for a machine learning algorithm, we present TABLA, a framework that generates accelerators for a class of machine learning algorithms. The key is to identify the commonalities across a wide range of machine learning algorithms and utilize this commonality to provide a high-level abstraction for programmers. TABLA leverages the insight that many learning algorithms can be expressed as a stochastic optimization problem. Therefore, learning becomes solving an optimization problem using stochastic gradient descent that minimizes an objective function over the training data. The gradient descent solver is fixed while the objective function changes for different learning algorithms. TABLA provides a template-based framework to accelerate this class of learning algorithms. Therefore, a developer can specify the learning task by only expressing the gradient of the objective function using our high-level language. TABLA then automatically generates the synthesizable implementation of the accelerator for FPGA realization using a set of hand-optimized templates.
   We use TABLA to generate accelerators for ten different learning tasks targeted at a Xilinx Zynq FPGA platform. We rigorously compare the benefits of FPGA acceleration to multi-core CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650 Ti, and Tesla K40) using real hardware measurements. TABLA-generated accelerators provide 19.4x and 2.9x average speedup over the ARM and Xeon processors, respectively. These accelerators provide 17.57x, 20.2x, and 33.4x higher Performance-per-Watt in comparison to Tegra, GTX 650 Ti and Tesla, respectively. These benefits are achieved while the programmers write less than 50 lines of code.
C1 [Mahajan, Divya; Park, Jongse; Amaro, Emmanuel; Sharma, Hardik; Yazdanbakhsh, Amir; Kim, Joon Kyung; Esmaeilzadeh, Hadi] Georgia Inst Technol, Alternat Comp Technol ACT Lab, Atlanta, GA 30332 USA.
RP Mahajan, D (corresponding author), Georgia Inst Technol, Alternat Comp Technol ACT Lab, Atlanta, GA 30332 USA.
EM divya_mahajan@gatech.edu; jspark@gatech.edu; amaro@gatech.edu;
   hsharma@gatech.edu; a.yazdanbakhsh@gatech.edu; jkkim@gatech.edu;
   hadi@cc.gatech.edu
CR [Anonymous], 1992, HIGH LEVEL SYNTHESIS
   [Anonymous], 12 INT WORKSH IM AN
   [Anonymous], 2012, INT S MICR MICRO
   [Anonymous], 2014, ZYNQ 7000 ALL PROGR
   [Anonymous], 2014, FCCM
   Boyd S., 2004, CONVEX OPTIMIZATION, DOI 10.1017/CBO9780511804441
   Cadambi S., 2009, FCCM
   Cantador Ivan, 2011, P ACM C REC SYST REC
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chung E. S., 2013, ISCA
   Chung Eric S., 2011, FPGA
   Curtin RR, 2013, J MACH LEARN RES, V14, P801
   Danowitz A, 2012, QUEUE, V10, P10, DOI DOI 10.1145/2181796.2181798
   Dennard R. H., 1974, IEEE J SOLID STATE C
   DuBois D., 2008, FCCM
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Feng Xixuan, 2012, P INT C MAN DAT SIGM
   Filho A. Gda. S., 2003, SBCCI
   Gantz J., EXTRACTING VALUE CHA
   Govindaraju V., 2011, HPCA
   Grajski Kamil A., 1993, PARALLEL DIGITAL IMP, P51
   Gupta Shantanu, 2011, MICRO
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Hauswald J, 2015, ACM SIGPLAN NOTICES, V50, P223, DOI [10.1145/2694344.2694347, 10.1145/2775054.2694347]
   Hussain H. M., 2011, AHS
   Intel Corporation, DISR DAT CTR CREAT D
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Kesler D., 2011, SASP
   King M., 2013, FPL
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LICHMAN M., 2013, UCI MACHINE LEARNING
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Maashri A.A., 2012, DAC
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Majumdar A, 2011, IEEE EMBED SYST LETT, V3, P42, DOI 10.1109/LES.2010.2100802
   Manolakos E.S., 2010, ISCAS
   Maruyama T, 2006, INT C PATT RECOG, P816
   Moreau T., 2015, HPCA
   Morris G.R., 2006, FCCM
   Nissen S., 2003, TECHNICAL REPORT
   Papadonikolakis M., 2010, FCCM
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Putnam Andrew R., 2008, FPGA
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Roldao A, 2010, ACM T RECONFIG TECHN, V3, DOI 10.1145/1661438.1661439
   Shan Yi, 2010, FPGA
   Sirowy S., 2008, WHERES BEEF WHY FPGA
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
   Venkatesh G., 2010, ASPLOS
   Venkatesh G., 2011, MICRO
   Xianyi Zhang, 2012, ICPADS
   Yeh Yao-Jung, 2007, SCIA
NR 56
TC 77
Z9 80
U1 1
U2 3
PY 2016
BP 14
EP 26
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kee, M
   Park, GH
AF Kee, Minkwan
   Park, Gi-Ho
TI A Low-power Programmable Machine Learning Hardware Accelerator Design
   for Intelligent Edge Devices
SO ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS
DT Article
DE Machine learning; hardware accelerator; internet of things; edge
   computing; sensor fusion
ID WEARABLE DEVICES; COMPRESSION
AB With the advent of the machine learning and IoT, many low-power edge devices, such as wearable devices with various sensors, are used for machine learning-based intelligent applications, such as healthcare or motion recognition. While these applications are becoming more complex to provide high-quality services, the performance of conventional low-power edge devices with extremely limited hardware resources is insufficient to support the emerging intelligent applications. We designed a hardware accelerator, called an Intelligence Boost Engine (IBE), for low-power smart edge devices to enable the real-time processing of emerging intelligent applications with energy efficiency and limited programmability. The measurement results confirm that the proposed IBE can reduce the power consumption of the edge node device by 75% and achieve performance improvement in processing the kernel operations of applications such as motion recognition by 69.9 times.
C1 [Kee, Minkwan; Park, Gi-Ho] Sejong Univ, 209 Neungdong Ro, Seoul 05006, South Korea.
RP Park, GH (corresponding author), Sejong Univ, 209 Neungdong Ro, Seoul 05006, South Korea.
EM mkkee@sju.ac.kr; ghpark@sejong.edu
CR Abbas N, 2018, IEEE INTERNET THINGS, V5, P450, DOI 10.1109/JIOT.2017.2750180
   [Anonymous], 2021, NXP SENSOR FUSION
   [Anonymous], 2021, ARM CMSIS NN
   [Anonymous], 2015, FOG COMPUTING INTERN
   Balasubramanian A., 2013, EFFICIENTLY RUNNING
   Bisio I, 2017, IEEE INTERNET THINGS, V4, P135, DOI 10.1109/JIOT.2016.2628938
   Bisio I, 2015, INT J COMMUN SYST, V28, P1753, DOI 10.1002/dac.2778
   Cass Stephen, 2019, IEEE SPECTRUM, V56, P16, DOI DOI 10.1109/MSPEC.2019.8701189
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang KW, 2020, IEEE T CIRCUITS-I, V67, P145, DOI 10.1109/TCSI.2019.2942529
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Colaco Andrea, 2013, P 26 ANN ACM S US IN, P227, DOI [10.1145/2501988.2502042, DOI 10.1145/2501988.2502042]
   Cruz S., 2013, P IEEE 4 LATIN AM S
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hayashikoshi M, 2014, ASIA S PACIF DES AUT, P12, DOI 10.1109/ASPDAC.2014.6742852
   Hu WZ, 2017, IEEE INTERNET THINGS, V4, P1006, DOI 10.1109/JIOT.2017.2704605
   Huang S, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P613, DOI 10.1109/ICSICT.2016.7998993
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Liang Y, 2011, C LOCAL COMPUT NETW, P466, DOI 10.1109/LCN.2011.6115508
   Marantos C, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Shi WS, 2016, COMPUTER, V49, P78, DOI 10.1109/MC.2016.145
   Soh PJ, 2015, IEEE MICROW MAG, V16, P55, DOI 10.1109/MMM.2015.2394021
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
   Zicari P, 2008, MICROPROCESS MICROSY, V32, P53, DOI 10.1016/j.micpro.2007.05.002
   Zordan D, 2014, ACM T SENSOR NETWORK, V11, DOI 10.1145/2629660
NR 26
TC 0
Z9 0
U1 1
U2 5
PD SEP
PY 2022
VL 27
IS 5
AR 51
DI 10.1145/3531479
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Chung, SW
   Wang, JM
AF Chung, SungWon
   Wang, Jiemi
TI Tightly Coupled Machine Learning Coprocessor Architecture With Analog
   In-Memory Computing for Instruction-Level Acceleration
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article; Proceedings Paper
CT 1st AI Compute Symposium (AICS)
CY OCT 25, 2018
CL Yorktown Heights, NY
DE Machine learning hardware accelerator; programmable accelerator;
   approximate analog computing; in-memory computing; analog datapath;
   analog register file; switched capacitor circuit; tightly coupled
   coprocessor; deep learning
ID SAR ADC; PROCESSOR; NETWORK; STORAGE; CMOS; MS/S; SRAM
AB Low-profile mobile computing platforms often need to execute a variety of machine learning algorithms with limited memory and processing power. To address this challenge, this work presents Coara, an instruction-level processor acceleration architecture, which efficiently integrates an approximate analog in-memory computing coprocessor for accelerating general machine learning applications by exploiting analog register file cache. The instruction-level acceleration offers true programmability beyond the degree of freedom provided by reconfigurable machine learning accelerators, and also allows the code generation stage of a compiler back-end to control the coprocessor execution and data flow, so that applications do not need high-level machine learning software frameworks with a large memory footprint. Conventional analog and mixed-signal accelerators suffer from the overhead of frequent data conversion between analog and digital signals. To solve this classical problem, Coara uses an analog register file cache, which interfaces the analog in-memory computing coprocessor with the digital register file of the processor core. As a result, more than 90% of data conversion overhead with ADC and DAC can be eliminated by temporarily storing the result of analog computation in a switched-capacitor analog memory cell until data dependency occurs. Cycle-accurate Verilog RTL model of the proposed architecture is evaluated with 45 nm CMOS technology parameters while executing machine learning benchmark computation codes that are generated by a customized cross-compiler without using machine learning software frameworks.
C1 [Chung, SungWon] Univ Southern Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Wang, Jiemi] Samsung Austin R&D Ctr, Austin, TX 78746 USA.
RP Chung, SW (corresponding author), Univ Southern Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
EM sungwon@ieee.org; jiemi@ieee.org
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], 2009, OPENCL SPECIFICATION
   [Anonymous], 2006, NVIDIA GPU PROGR GUI
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Bong K, 2018, IEEE J SOLID-ST CIRC, V53, P115, DOI 10.1109/JSSC.2017.2767705
   BOSER BE, 1991, IEEE J SOLID-ST CIRC, V26, P2017, DOI 10.1109/4.104196
   Brooks L, 2009, IEEE J SOLID-ST CIRC, V44, P3329, DOI 10.1109/JSSC.2009.2032639
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Cao N., 2010, IEEE INT SOL STAT CI, P222
   Chen Y.-H., 2018, ARXIV180707928V1
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi S, 2018, ISSCC DIG TECH PAP I, P220, DOI 10.1109/ISSCC.2018.8310263
   Daukss D, 2016, NAT REV DRUG DISCOV, V15, P740, DOI 10.1038/nrd.2016.210
   Dressler F, 2016, IEEE COMMUN MAG, V54, P129, DOI 10.1109/MCOM.2016.7378438
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fathy ME, 2015, INT CONF ACOUST SPEE, P1687, DOI 10.1109/ICASSP.2015.7178258
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Guo N, 2016, IEEE J SOLID-ST CIRC, V51, P1514, DOI 10.1109/JSSC.2016.2543729
   Han G, 1998, IEEE T CIRCUITS-II, V45, P1550, DOI 10.1109/82.746667
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Howard A. G., 2017, ARXIV
   Inan OT, 2018, CIRC-HEART FAIL, V11, DOI 10.1161/CIRCHEARTFAILURE.117.004313
   Jeong G. Y., 2004, P INT SOC DES C ISOC, P1
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kim C., 2019, IEEE INT SOL STAT CI
   Kim JY, 2019, PLANT SIGNAL BEHAV, V14, DOI 10.1080/15592324.2019.1617609
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kull L., 2015, IEEE INT SOL STAT CI, P378
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Lee EH, 2016, ISSCC DIG TECH PAP I, V59, P418, DOI 10.1109/ISSCC.2016.7418085
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Li Y, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P25, DOI 10.1109/VLSIT.2018.8510648
   Li YZ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032008
   Liu CY, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02280-y
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Lu J, 2015, IEEE J SOLID-ST CIRC, V50, P270, DOI 10.1109/JSSC.2014.2356197
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   O'Halloran M, 2004, IEEE J SOLID-ST CIRC, V39, P1985, DOI 10.1109/JSSC.2004.835817
   O'Leary G, 2018, IEEE J SOLID-ST CIRC, V53, P3150, DOI 10.1109/JSSC.2018.2869579
   Salinga M, 2018, NAT MATER, V17, P681, DOI 10.1038/s41563-018-0110-9
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Srivastava P, 2018, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA.2018.00015
   Stallman R. M., 2015, GNU COMPILER COLLECT
   Sung BRS, 2015, ISSCC DIG TECH PAP I, V58, P464
   Sussillo D, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026027
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tsai JH, 2015, IEEE J SOLID-ST CIRC, V50, P1382, DOI 10.1109/JSSC.2015.2413850
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Yin SY, 2017, SYMP VLSI CIRCUITS, pC26, DOI 10.23919/VLSIC.2017.8008534
   Yue JS, 2019, ISSCC DIG TECH PAP I, V62, P138
   Zamani M, 2018, IEEE T BIOMED CIRC S, V12, P665, DOI 10.1109/TBCAS.2018.2825421
NR 65
TC 3
Z9 3
U1 1
U2 11
PD SEP
PY 2019
VL 9
IS 3
BP 544
EP 561
DI 10.1109/JETCAS.2019.2934929
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lai, YK
   Chang, KP
   Ku, XW
   Hua, HL
AF Lai, Yu-Kuen
   Chang, Kai-Po
   Ku, Xiu-Wen
   Hua, Hsiang-Lun
GP IEEE
TI A Machine Learning Accelerator for DDoS Attack Detection and
   Classification on FPGA
SO 2022 19TH INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC)
SE International SoC Design Conference
DT Proceedings Paper
CT 19th International SoC Design Conference (ISOCC) - SoC Technology
   Towards a New Era of Innovation
CY OCT 19-22, 2022
CL Gangwon Do, SOUTH KOREA
DE DDoS Detection; Machine Learning; FPGA Acceleration; Entropy; Sketch
AB This paper presents the hardware accelerators to detect and classify DDoS attacks. Two types of neural network models based on different observation methods and features are demonstrated to be capable of processing packet streams at 100Gbps wire speed with good performance. The CIC2019 DDoS dataset is used and processed utilizing data augmentation techniques with enough variation for training the machine learning models. Finally, we discussed the cost of implementing these two models on the Xilinx Alveo U200 Data acceleration card.
C1 [Lai, Yu-Kuen; Chang, Kai-Po; Ku, Xiu-Wen; Hua, Hsiang-Lun] Chung Yuan Christian Univ, Dept Elect Engn, Chungli 32023, Taiwan.
RP Lai, YK (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, Chungli 32023, Taiwan.
EM ylai@cnsrl.cycu.edu.tw; kp.chang@cnsrl.cycu.edu.tw;
   hw.ku@cnsrl.cycu.edu.tw; shian-lun.hua@cnsrl.cycu.edu.tw
CR Alon N, 1999, J COMPUT SYST SCI, V58, P137, DOI 10.1006/jcss.1997.1545
   Boutaba R, 2018, J INTERNET SERV APPL, V9, DOI 10.1186/s13174-018-0087-2
   Clifford P, 2013, Arxiv, DOI arXiv:0908.3961
   Doriguzzi-Corin R, 2020, IEEE T NETW SERV MAN, V17, P876, DOI 10.1109/TNSM.2020.2971776
   FLAJOLET P, 1985, J COMPUT SYST SCI, V31, P182, DOI 10.1016/0022-0000(85)90041-8
   Kayata C. E., 2018, 2018 26 SIGNAL PROCE, P1, DOI [10.1109/SIU.2018.8404348, DOI 10.1109/SIU.2018.8404782]
   Kind Andreas, 2009, IEEE Transactions on Network and Service Management, V6, P110, DOI 10.1109/TNSM.2009.090604
   Lai YK, 2022, IEEE ACCESS, V10, P104934, DOI 10.1109/ACCESS.2022.3210336
   Masson C, 2019, PROC VLDB ENDOW, V12, P2195, DOI 10.14778/3352063.3352135
   Rupp A., PACKET TRACE MANIPUL, V6, P6
   Yuan XY, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P9, DOI 10.1109/smartcomp.2017.7946998
NR 11
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 181
EP 182
DI 10.1109/ISOCC56007.2022.10031506
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zhao, W
   Schueler, E
   Patil, I
   Han, B
   Yang, Y
   Xing, L
AF Zhao, W.
   Schueler, E.
   Patil, I.
   Han, B.
   Yang, Y.
   Xing, L.
TI Harnessing the Power of Machine Learning for Accurate and Efficient
   Linear Accelerator Beam Data Commissioning
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
DT Meeting Abstract
CT 61st Annual Meeting of the American-Society-for-Radiation-Oncology
   (ASTRO)
CY SEP 15-18, 2019
CL Chicago, IL
C1 [Zhao, W.; Xing, L.] Stanford Univ, Stanford, CA 94305 USA.
   [Schueler, E.] Stanford Canc Inst, Dept Radiat Oncol, Stanford, CA USA.
   [Patil, I.] Stanford Univ, Palo Alto, CA 94304 USA.
   [Han, B.] Stanford Univ, Sch Med, Palo Alto, CA 94304 USA.
   [Yang, Y.] Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA.
NR 0
TC 0
Z9 0
U1 0
U2 0
PD SEP 1
PY 2019
VL 105
IS 1
SU S
MA 3603
BP E687
EP E688
DI 10.1016/j.ijrobp.2019.06.920
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Wang, C
   Gong, L
   Jia, FH
   Zhou, XH
AF Wang, Chao
   Gong, Lei
   Jia, Fahui
   Zhou, Xuehai
TI An FPGA Based Accelerator for Clustering Algorithms With Custom
   Instructions
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Clustering algorithms; Hardware; Field programmable gate arrays; Machine
   learning algorithms; Arrays; Logic arrays; Acceleration; Accelerators;
   clustering; custom instructions; machine learning; FPGA
AB Clustering algorithms are becoming popular and widely applied in many academic fields, such as machine learning, pattern recognition, and artificial intelligence. It has posed significant challenges to accelerate the algorithms due to the explosive data scale and wide variety of applications. However, previous studies mainly focus on the raw speedup with insufficient attention to the flexibility of the accelerator to support various applications. In order to accelerate different clustering algorithms in one accelerator, in this article, we design an accelerating framework based on FPGA for four state-of-the-art clustering methods, including K-means, PAM, SLINK, and DBSCAN algorithms. Moreover, we provide both euclidean and Manhattan distances as similarity metrics in the accelerator design paradigm. Moreover, we provide a custom instruction set to operate the accelerators within each application. In order to evaluate the performance and hardware cost of the accelerator, we constructed a hardware prototype on the state-of-the-art Xilinx FPGA platform. Experimental results demonstrate that the accelerator framework is able to achieve up to 23x speedup than Intel Xeon processor, and is 9.46x more energy efficient than NVIDIA GTX 750 GPU accelerators.
C1 [Wang, Chao; Gong, Lei; Zhou, Xuehai] Univ Sci & Technol China, Hefei 230027, Anhui, Peoples R China.
   [Jia, Fahui] Univ Sci & Technol China, Suzhou Inst, Suzhou 215123, Peoples R China.
RP Gong, L (corresponding author), Univ Sci & Technol China, Hefei 230027, Anhui, Peoples R China.
EM cswang@ustc.edu.cn; leigong0203@ustc.edu.cn; fhj@mail.ustc.edu.cn;
   xhzhou@ustc.edu.cn
CR Abdelrahman TS, 2016, IEEE INT CONF ASAP, P176, DOI 10.1109/ASAP.2016.7760789
   [Anonymous], 2013, 23 INT C FIELD PROGR, DOI DOI 10.1109/FPL.2013.6645501
   [Anonymous], 2016, MICRO
   [Anonymous], NATURE
   Canilho J, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577313
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fujiki D, 2018, CONF PROC INT SYMP C, P69, DOI 10.1109/ISCA.2018.00017
   Gong L, 2018, IEEE T COMPUT AID D, V37, P2601, DOI 10.1109/TCAD.2018.2857078
   He ZH, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P233, DOI 10.1145/3373087.3375316
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Nurvitadhi E, 2014, ANN IEEE SYM FIELD P, P25, DOI 10.1109/FCCM.2014.15
   Penha J, 2018, 2018 SYMPOSIUM ON HIGH PERFORMANCE COMPUTING SYSTEMS (WSCAD 2018), P61, DOI 10.1109/WSCAD.2018.00019
   Raghavendra R., 2017, P 5 INT WORKSH BIOM, DOI DOI 10.1109/IWBF.2017.7935108
   Shendure H. J. Jay, 2015, NAT BIOTECHNOL, V26, P1135
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Yan MY, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P615, DOI 10.1145/3352460.3358318
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
   Zhongduo Lin, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P437, DOI 10.1109/FPL.2012.6339141
   Zhou SJ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P259, DOI 10.1145/3174243.3174252
NR 23
TC 8
Z9 8
U1 0
U2 16
PD MAY 1
PY 2021
VL 70
IS 5
BP 725
EP 732
DI 10.1109/TC.2020.2995761
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ahn, S
   Kim, C
   Han, M
   Han, S
   Lee, Y
   Kim, H
   Hong, C
   Kim, J
   Kim, J
AF Ahn, S.
   Kim, C.
   Han, M.
   Han, S.
   Lee, Y.
   Kim, H.
   Hong, C.
   Kim, J.
   Kim, J.
TI A Deep Learning Method Approach for Machine Modeling of Elekta Linear
   Accelerator From Limited Beam Data
SO MEDICAL PHYSICS
DT Meeting Abstract
C1 [Ahn, S.] Sungkyunkwan Univ, Dept Radiat Oncol, Samsung Med Ctr, Sch Med, Seoul 06351, South Korea.
   [Kim, C.; Han, M.; Han, S.; Lee, Y.; Kim, H.; Hong, C.; Kim, J.; Kim, J.] Yonsei Univ, Dept Radiat Oncol, Yonsei Canc Ctr, Coll Med, 50 1 Yonsei Ro, Seoul 03722, South Korea.
NR 0
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2022
VL 49
IS 6
MA PO-GePV-M-
BP E680
EP E680
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Kee, M
   Lee, SJ
   Seon, HS
   Lee, J
   Park, GH
AF Kee, Minkwan
   Lee, Seung-jin
   Seon, Hyun-su
   Lee, Jongsung
   Park, Gi-Ho
GP IEEE
TI Intelligence Boosting Engine (IBE): a Hardware Accelerator for
   Processing Sensor Fusion and Machine Learning Algorithm for a Sensor Hub
   SoC
SO 2017 IEEE SYMPOSIUM IN LOW-POWER AND HIGH-SPEED CHIPS (COOL CHIPS)
SE Proceedings for IEEE COOL CHIPS
DT Proceedings Paper
CT IEEE Symposium on Low-Power and High-Speed Chips (IEEE COOL Chips)
CY APR 19-21, 2017
CL Yokohama, JAPAN
DE Sensor hub; Hardware accelerator; Intelligence boosting engine (IBE);
   Machine learning algorithms; Sensor fusion; Motion detection; Kalman
   filter; Support vector machine (SVM)
AB This paper proposes a hardware accelerator, named IBE (Intelligence Boost Engine), to process both sensor fusion and machine learning algorithms for the Standing-egg SLH200 sensor hub SoC. The IBE is designed to have both efficiency and flexibility to support various emerging applications for future sensor hub SoCs in addition to the sensor fusion and machine learning algorithm (SVM) which are the target applications of the SLH200. With regard to the SLH200 SoC, the IBE was fabricated in the Global Foundry 55nm process, and the performance and power evaluation with IBE have been performed with the evaluation board of the SLH200 SoC. The evaluation results show that the proposed IBE can achieve up to 31.3x faster speed for target kernel operation and 4x faster speed for the target application (SVM polynomial). It reduces the energy consumption up to 75% as well.
C1 [Kee, Minkwan; Lee, Seung-jin; Park, Gi-Ho] Sejong Univ, Dept Comp Engn, Seoul, South Korea.
   [Seon, Hyun-su; Lee, Jongsung] Standing Egg Inc, Seongnam Si, South Korea.
RP Park, GH (corresponding author), Sejong Univ, Dept Comp Engn, Seoul, South Korea.
EM mkkee@sju.ac.kr; seungjinlee@sju.ac.kr; hsseon@standing-egg.co.kr;
   jslee@standing-egg.co.kr; ghpark@sejong.edu
CR [Anonymous], LIBSVM LIB SUPPORT V
   Atmel Inc, 2013, ARM BAS FLASH MCU SA
   Cruz S., 2013, CIRC SYST LASCAS 201, P1, DOI DOI 10.1109/COLOMBIANCC.2013.6637535
   Freescale Semiconductor Inc, 2014, FREESC SENS FUS LIB
   Kumar VBY, 2010, INT J PARALLEL PROG, V38, P322, DOI 10.1007/s10766-010-0131-8
   NXP Inc, 2015, AN11703LPC5410X NXP
   Zicari P, 2008, MICROPROCESS MICROSY, V32, P53, DOI 10.1016/j.micpro.2007.05.002
NR 7
TC 5
Z9 5
U1 0
U2 1
PY 2017
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Akhoon, MS
   Suandi, SA
   Alshahrani, A
   Saad, AMHY
   Albogamy, FR
   Bin Abdullah, MZ
   Loan, SA
AF Akhoon, Mohd Saqib
   Suandi, Shahrel A.
   Alshahrani, Abdullah
   Saad, Abdul-Malik H. Y.
   Albogamy, Fahad R.
   Bin Abdullah, Mohd Zaid
   Loan, Sajad A.
TI High performance accelerators for deep neural networks: A review
SO EXPERT SYSTEMS
DT Review
DE artificial intelligence; convolutional neural networks; deep neural
   network; machine learning; accelerators
ID CNN
AB The availability of huge structured and unstructured data, advanced highly dense memory and high performance computing machines have provided a strong push for the development in artificial intelligence (AI) and machine learning (ML) domains. AI and machine learning has rekindled the hope of efficiently solving complex problems which was not possible in the recent past. The generation and availability of big-data is a strong driving force for the development of AI/ML applications, however, several challenges need to be addressed, like processing speed, memory requirement, high bandwidth, low latency memory access, and highly conductive and flexible connections between processing units and memory blocks. The conventional computing platforms are unable to address these issues with machine learning and AI. Deep neural networks (DNNs) are widely employed for machine learning and AI applications, like speech recognition, computer vison, robotics, and so forth, efficiently and accurately. However, accuracy is achieved at the cost of high computational complexity, sacrificing energy efficiency and throughput like performance measuring parameters along with high latency. To address the problems of latency, energy efficiency, complexity, power consumption, and so forth, a lot of state of the art DNN accelerators have been designed and implemented in the form of application specific integrated circuits (ASICs) and field programmable gate arrays (FPGAs). This work provides the state of the art of all these DNN accelerators which have been developed recently. Various DNN architectures, their computing units, emerging technologies used in improving the performance of DNN accelerators will be discussed. Finally, we will try to explore the scope for further improvement in these accelerator designs, various opportunities and challenges for the future research.
C1 [Akhoon, Mohd Saqib; Suandi, Shahrel A.; Bin Abdullah, Mohd Zaid] Univ Sains, Sch Elect & Elect Engn, Intelligent Biometr Grp, George Town, Malaysia.
   [Alshahrani, Abdullah] Univ Jeddah, Dept Comp Sci & Artificial Intelligence, Coll Comp Sci & Engn, Jeddah, Saudi Arabia.
   [Saad, Abdul-Malik H. Y.] Univ Teknol Malaysia, Div Elect & Comp Engn, Fac Engn, Sch Elect Engn, Johor Baharu, Kagawa, Malaysia.
   [Albogamy, Fahad R.] Taif Univ, Saudi Univ, Turabah Univ Coll, Comp Sci Program, At Taif, Saudi Arabia.
   [Loan, Sajad A.] Jamia Millia Islamia, Dept Elect & Commun, New Delhi 11025, India.
RP Loan, SA (corresponding author), Jamia Millia Islamia, Dept Elect & Commun, New Delhi 11025, India.
EM sloan@jmi.ac.in
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Alwani M., 2016, MICROPAGE, P1
   Ambrogio S, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Ambrogio S., 2020, 2 IEEE INT C ART INT
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Bain A., 1873, MIND BODY THEORIES T, Vvol. 4
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Caulfield AM, 2016, INT SYMP MICROARCH
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Chen A, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Dongale TD, 2015, MAT SCI SEMICON PROC, V35, P174, DOI 10.1016/j.mssp.2015.03.015
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2015, COMMUN ACM, V58, P105, DOI 10.1145/2589750
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Gao Huang ZL, 2017, PROC CVPR IEEE, P4700, DOI DOI 10.1109/CVPR.2017.243
   Google Cloud Next'18, 2019, GOOGL CLOUD NEXT 18
   Google I/O'18, 2019, GOOGL I O 18
   Graham B., 2014, ARXIV1412607, V1412, P607
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Guo P, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S0218126619400048
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Hu XH, 2019, IEEE ACCESS, V7, P72113, DOI 10.1109/ACCESS.2019.2919527
   James W., 1890, PRINCIPLES PSYCHOL, DOI [DOI 10.1037/10538-000, 10.1037/10538-000]
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2019, THE MNIST DATABASE
   Lee C., 2018, P SYSML C
   Lee CY, 2016, JMLR WORKSH CONF PRO, V51, P464
   Lee J., 2018, UNPU 506TOPSW UNIFIE
   Liu D., 2015, PUDIANNAO POLYVALENT
   Liu XX, 2015, DES AUT CON, DOI 10.1145/2744769.2744900
   MCCULLOCH WS, 1990, B MATH BIOL, V52, P99, DOI 10.1016/S0092-8240(05)80006-0
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, DOI DOI 10.2118/18761-MS
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Pawlowski J. T., 2011, P IEEE HOT CHIPS 23, DOI DOI 10.1109/HOTCHIPS.2011.7477494
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qiao XM, 2018, DES AUT CON, DOI 10.1145/3195970.3195998
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sermanet P., 2014, INT C LEARN REPR ICL, DOI DOI 10.1016/J.NEUNET.2012.02.016
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sze V., 2020, EFFICIENT PROCESSING
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Turing A. M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Wan L., 2013, P 30 INT C MACH LEAR, V28, P1058
   Wang PQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196116
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wu IC, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P42, DOI 10.1109/AICAS.2019.8771600
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Zang H., 2020, GLSVLSI 20 P 2020 GR
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
NR 69
TC 3
Z9 3
U1 7
U2 55
PD JAN
PY 2022
VL 39
IS 1
AR e12831
DI 10.1111/exsy.12831
EA OCT 2021
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Ayala, R
   Fabregat, R
   Alarcia, M
   Vilanova, J
   García, MJ
   Ruiz, G
   Gómez, S
   Jiménez, R
   López, MA
AF Ayala, R.
   Fabregat, R.
   Alarcia, M.
   Vilanova, J.
   Garcia, M. J.
   Ruiz, G.
   Gomez, S.
   Jimenez, R.
   Lopez, M. A.
TI Feasibility of a machine learning QA system for failure detection in
   IORT with a mobile accelerator
SO RADIOTHERAPY AND ONCOLOGY
DT Meeting Abstract
CT 37th Meeting of the European-Society-for-Radiotherapy-and-Oncology
   (ESTRO)
CY APR 20-24, 2018
CL Barcelona, SPAIN
C1 [Ayala, R.; Alarcia, M.; Vilanova, J.; Garcia, M. J.; Ruiz, G.; Gomez, S.; Jimenez, R.; Lopez, M. A.] Hosp Gen Univ Gregorio Maranon, Serv Dosimetria & Radioprotecc, Madrid, Spain.
   [Fabregat, R.] Hosp Univ Marques de Valdecilla, Serv Radiofis & Protecc Radiol, Santander, Spain.
NR 0
TC 1
Z9 1
U1 0
U2 0
PD APR
PY 2018
VL 127
SU 1
MA PO-1003
BP E559
EP E560
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Ipek, E
AF Ipek, Engin
TI Memristive Accelerators for Dense and Sparse Linear Algebra: From
   Machine Learning to High-Performance Scientific Computing
SO IEEE MICRO
DT Editorial Material
C1 [Ipek, Engin] Univ Rochester, Elect & Comp Engn, Rochester, NY 14627 USA.
RP Ipek, E (corresponding author), Univ Rochester, Elect & Comp Engn, Rochester, NY 14627 USA.
EM ipek@cs.rochester.edu
CR [Anonymous], TOP 10 EXASCALE RES
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Guo Q., 2013, P 40 ANN INT S COMPU, V41, P189, DOI [10.1145/2508148.2485939, DOI 10.1145/2485922.2485939]
   Han S., 2016, INT C LEARN REPR ICL
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee D, 2018, INT S HIGH PERF COMP, P40, DOI 10.1109/HPCA.2018.00014
   Saad Y., 2003, SIAM, DOI [10.1137/1.9780898718003, DOI 10.1137/1.9780898718003]
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
NR 19
TC 3
Z9 4
U1 0
U2 2
PD JAN-FEB
PY 2019
VL 39
IS 1
SI SI
BP 58
EP 61
DI 10.1109/MM.2018.2885498
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU St John, J
   Herwig, C
   Kafkes, D
   Mitrevski, J
   Pellico, WA
   Perdue, GN
   Quintero-Parra, A
   Schupbach, BA
   Seiya, K
   Fermi, NT
   Schram, M
   Duarte, JM
   Huang, YZ
   Keller, R
AF St John, Jason
   Herwig, Christian
   Kafkes, Diana
   Mitrevski, Jovan
   Pellico, William A.
   Perdue, Gabriel N.
   Quintero-Parra, Andres
   Schupbach, Brian A.
   Seiya, Kiyomi
   Fermi, Nhan Tran
   Schram, Malachi
   Duarte, Javier M.
   Huang, Yunzhi
   Keller, Rachael
TI Real-time artificial intelligence for accelerator control: A study at
   the Fermilab Booster
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
ID DEEP; NETWORKS
AB We describe a method for precisely regulating the gradient magnet power supply (GMPS) at the Fermilab Booster accelerator complex using a neural network trained via reinforcement learning. We demonstrate preliminary results by training a surrogate machine-learning model on real accelerator data to emulate the GMPS, and using this surrogate model in turn to train the neural network for its regulation task. We additionally show how the neural networks to be deployed for control purposes may be compiled to execute on field-programmable gate arrays (FPGAs), and show the first machine-learning based control algorithm implemented on an FPGA for controls at the Fermilab accelerator complex. As there are no surprise latencies on an FPGA, this capability is important for operational stability in complicated environments such as an accelerator facility.
C1 [St John, Jason; Herwig, Christian; Kafkes, Diana; Mitrevski, Jovan; Pellico, William A.; Perdue, Gabriel N.; Quintero-Parra, Andres; Schupbach, Brian A.; Seiya, Kiyomi; Fermi, Nhan Tran] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Schram, Malachi] Thomas Jeerson Natl Accelerator Lab, Newport News, VA 23606 USA.
   [Duarte, Javier M.] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Huang, Yunzhi] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
   [Keller, Rachael] Columbia Univ, Dept Appl Phys & Appl Math, New York, NY 10027 USA.
RP St John, J (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM stjohn@fnal.gov
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   Agarap A. F., ARXIV180308375
   Amundson J, 2014, COMPUT SCI ENG, V16, P32, DOI 10.1109/MCSE.2014.76
   Andrychowicz M., 2017, ADV NEURAL INFORM PR, V30, P5048
   [Anonymous], 2016, MICRO
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], ARXIV180601683
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Banbury C. R., ARXIV200304821
   BARTO AG, 1983, IEEE T SYST MAN CYB, V13, P834, DOI 10.1109/TSMC.1983.6313077
   BELLMAN R, 1952, P NATL ACAD SCI USA, V38, P716, DOI 10.1073/pnas.38.8.716
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Boltz T., 2020, P 17 INT C ACCELERAT, P781, DOI DOI 10.18429/JACOW-ICALEPCS2019
   BRIEGEL C, 1990, NUCL INSTRUM METH A, V293, P235, DOI 10.1016/0168-9002(90)91434-D
   Brockman G., ARXIV160601540
   Bruchon N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050781
   Cahill K., 2008, ICFA BEAM DYN NEWSLE, V47, P106
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Chang SE, 2021, INT S HIGH PERF COMP, P208, DOI [10.1109/HPCA51647.2021.00027, 10.1109/WRCSARA53879.2021.9612678]
   Chollet F, KERAS
   CMS Collaboration, CERNLHCC2020004
   Coelho CN, 2021, NAT MACH INTELL, V3, P675, DOI 10.1038/s42256-021-00356-5
   Crawford J., 2009, BOOSTER ROOKIE BOOK
   Davies A., WIRED GUIDE SELF DRI
   DeepMind, SAF 1 AUT DAT CTR CO
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A., 2019, MACH LEARN PHYS SCI
   Edelen A., 2017, 2 N AM PART ACC C NA, P390, DOI DOI 10.18429/JACOW-NAPAC2016-TUPOA51
   Edelen A., 2018, INT FREE EL LAS C FE, P488, DOI [10.18429/JACoW-FEL2017-WEP031, DOI 10.18429/JACOW-FEL2017-WEP031]
   Edelen A., 2017, 31 C NEUR INF PROC S
   Edelen A., ARXIV181103172
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A. L., 2017, 2 N AM PART ACC C NA, P109, DOI DOI 10.18429/JACOW-NAPAC2016-MOPOB17
   Edelen A. L., 2016, P 7 INT PARTICLE ACC, DOI [DOI 10.18429/JACOW-IPAC2016-THPOY020, 10.18429/JACoW-IPAC2016-THPOY020]
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Fahim F., 2021, ARXIV210305579
   François-Lavet V, 2018, FOUND TRENDS MACH LE, V11, P219, DOI 10.1561/2200000071
   Fujimoto S, 2018, PR MACH LEARN RES, V80
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Hacene GB, 2020, IEEE INT NEW CIRC, P206, DOI [10.1109/newcas49341.2020.9159769, 10.1109/NEWCAS49341.2020.9159769]
   Hanuka A, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.072802
   Hasselt H., 2010, ADV NEURAL INFORM PR, V23, DOI DOI 10.5555/2997046.2997187
   Hirlaender S., 2019, 2 ICFA MIN WORKSH MA
   Hirlaender S., ARXIV201209737
   Hubbard E., 1973, BOOSTER SYNCHROTRON, DOI [10.2172/1155286, DOI 10.2172/1155286]
   Iiyama Y, 2021, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.598927
   Intel Corporation, 2021, UG20129 INT CORP
   Javed H., 2020, FAST MACH LEARN SCI, DOI [10.5281/zenodo.5507649, DOI 10.5281/ZENODO.5507649]
   Kafkes D, 2021, DATA, V6, DOI 10.3390/data6040042
   Kain V, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.124801
   Kim SH, 2020, OPTIM LETT, V14, P989, DOI 10.1007/s11590-019-01428-7
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kirschner J, 2019, PR MACH LEARN RES, V97
   Knight W., THIS FACTORY ROBOT L
   Langston J., IS BUILDING BETTER G
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Lillicrap TP., 2015, ARXIV, DOI DOI 10.1016/S1098-3015(10)67722-4
   Loncar V., 2020, FASTMACHINELEARNINGH, DOI DOI 10.5281/ZENODO.4161550
   Majumder K., ARXIV191207284
   Minorsky N., 1922, J AM SOC NAVAL ENG, V34, P280, DOI [DOI 10.1111/J.1559-3584.1922.TB04958.X, 10.1111/j.1559-3584.1922.tb04958.x]
   Mnih V., 2013, ARXIV, DOI DOI 10.1038/NATURE14236
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nair A, 2018, IEEE INT CONF ROBOT, P6292
   Ngadiuba J, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/aba042
   O'Shea FH, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.122802
   Ögren J, 2021, J INSTRUM, V16, DOI 10.1088/1748-0221/16/05/P05012
   Pascanu R., 2013, INT C MACH LEARN, P1310, DOI DOI 10.5555/3042817.3043083
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Razavimaleki V., 2020, ARXIV201201563
   Ryk J., FERMILABPUB74085
   Scheinker A., 2019, LAUR1932526 ACM4PA, DOI [10.2172/1579684, DOI 10.2172/1579684]
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Schulman John, ARXIV170706347
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Summers S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/05/P05026
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Umuroglu Y., XILINX FINN
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Venieris S. I., ARXIV171108740
   VENIERIS SI, 2017, I C FIELD PROG LOGIC, DOI DOI 10.23919/FPL.2017.8056828
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Watkins C.J.C.H., 1989, THESIS U CAMBRIDGE
   Whatmough P., 2019, ARXIV190211128, V1, P107
   Whatmough P. N., ARM SOFTWAREDEEPFREE
   Xilinx, XILINXVITIS
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   ZIEGLER JG, 1993, J DYN SYST-T ASME, V115, P220, DOI 10.1115/1.2899060
NR 99
TC 6
Z9 6
U1 1
U2 14
PD OCT 15
PY 2021
VL 24
IS 10
AR 104601
DI 10.1103/PhysRevAccelBeams.24.104601
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Britton, T
   Nachman, B
AF Britton, T.
   Nachman, B.
TI Accelerator and detector control for the EIC with machine learning
SO JOURNAL OF INSTRUMENTATION
DT Article; Proceedings Paper
CT Conference on Artificial Intelligence for the Electron Ion Collider
CY SEP 07-10, 2021
CL Stony Brook Univ, Ctr Frontiers Nucl Sci, New York, NY
HO Stony Brook Univ, Ctr Frontiers Nucl Sci
DE Analysis and statistical methods; Control systems
AB This document provides a brief overview of the Accelerator and Detector Control session at the AI4EIC workshop in September 2021.
C1 [Britton, T.] Jefferson Natl Lab, 12000 Jefferson Ave, Newport News, VA 23606 USA.
   [Nachman, B.] Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.
   [Nachman, B.] Berkeley Inst Data Sci, 190 Doe Lib, Berkeley, CA 94720 USA.
RP Nachman, B (corresponding author), Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.; Nachman, B (corresponding author), Berkeley Inst Data Sci, 190 Doe Lib, Berkeley, CA 94720 USA.
EM bpnachman@lbl.gov
CR Britton T., 2021, EPJ WEB C, V251, DOI [10.1051/epjconf/202125104010, DOI 10.1051/EPJCONF/202125104010]
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Feickert M., ARXIV210202770
   Montavon G., 2019, EXPLAINABLE INTERPRE, V11700, P193, DOI [10.1007/978-3-030-28954-6_10/COVER, DOI 10.1007/978-3-030-28954-6_10]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
NR 5
TC 0
Z9 0
U1 0
U2 2
PD FEB
PY 2022
VL 17
IS 2
AR C02022
DI 10.1088/1748-0221/17/02/C02022
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Bojnordi, MN
   Ipek, E
AF Bojnordi, Mahdi Nazm
   Ipek, Engin
GP IEEE
TI Memristive Boltzmann Machine: A Hardware Accelerator for Combinatorial
   Optimization and Deep Learning
SO PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE
   COMPUTER ARCHITECTURE (HPCA-22)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 22nd IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY MAR 12-16, 2016
CL Barcelona, SPAIN
ID DESIGN; MEMORY; CIRCUIT; ACCESS; ARCHITECTURE; MODEL
AB The Boltzmann machine is a massively parallel computational model capable of solving a broad class of combinatorial optimization problems. In recent years, it has been successfully applied to training deep machine learning models on massive datasets. High performance implementations of the Boltzmann machine using GPUs, MPI-based HPC clusters, and FPGAs have been proposed in the literature. Regrettably, the required all-to-all communication among the processing units limits the performance of these efforts.
   This paper examines a new class of hardware accelerators for large-scale combinatorial optimization and deep learning based on memristive Boltzmann machines. A massively parallel, memory-centric hardware accelerator is proposed based on recently developed resistive RAM (RRAM) technology. The proposed accelerator exploits the electrical properties of RRAM to realize in situ, fine-grained parallel computation within memory arrays, thereby eliminating the need for exchanging data between the memory cells and the computational units. Two classical optimization problems, graph partitioning and boolean satisfiability, and a deep belief network application are mapped onto the proposed hardware. As compared to a multicore system, the proposed accelerator achieves 57x higher performance and 25x lower energy with virtually no loss in the quality of the solution to the optimization problems. The memristive accelerator is also compared against an RRAM based processing-in-memory (PIM) system, with respective performance and energy improvements of 6.89x and 5.2x.
C1 [Bojnordi, Mahdi Nazm; Ipek, Engin] Univ Rochester, Rochester, NY 14627 USA.
RP Bojnordi, MN (corresponding author), Univ Rochester, Rochester, NY 14627 USA.
EM bojnordi@ece.rochester.edu; ipek@ece.rochester.edu
CR Aarts E., 1989, SIMULATED ANNEALING
   Advanced Micro Devices Inc., 2010, AMD64 ARCH PROGR MAN, V2
   Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], 2005, AISTATS BRIDGETOWN B
   [Anonymous], ACM T MATH SOFTW
   [Anonymous], 2008, NEURAL NETWORKS GPUS
   [Anonymous], 2003, IA 32 INT ARCH OPT R
   [Anonymous], 2003, P IEEE INT EL DEV M
   Anthony Martin, 2001, DISCRETE MATH NEURAL
   Asenov A, 2003, IEEE T ELECTRON DEV, V50, P1254, DOI 10.1109/TED.2003.813457
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bojnordi MN, 2012, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2012.6237002
   Cheng C., 2010, EL DEV M IEDM 2010 I, P19
   Cheng CH, 2010, S VLSI TECH, P85, DOI 10.1109/VLSIT.2010.5556180
   Choi BJ, 2013, NANO LETT, V13, P3213, DOI 10.1021/nl401283q
   Choudhary NK, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P11, DOI 10.1145/2024723.2000067
   Chung-Wei Hsu, 2013, 2013 Symposium on VLSI Technology, pT166
   DANJOU A, 1993, IEEE T PATTERN ANAL, V15, P514, DOI 10.1109/34.211473
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Duan S, 2013, SCI CHINA INFORM SCI, V57, P1
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Fahlman SE, 1983, P NAT C AI
   Ferguson F. J., 1991, Proceedings. International Test Conference 1991 (IEEE Cat. No.91CH3032-0), P492, DOI 10.1109/TEST.1991.519711
   Fischer Asja, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P14, DOI 10.1007/978-3-642-33275-3_2
   GEIGER NRL, 1990, VLSI DESIGN TECHNIQU
   Genov R, 2002, LECT NOTES COMPUT SC, V2388, P120
   Genov R, 2001, IEEE T CIRCUITS-II, V48, P930, DOI 10.1109/82.974781
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Guo Q., 2013, P 40 ANN INT S COMPU, V41, P189, DOI [10.1145/2508148.2485939, DOI 10.1145/2485922.2485939]
   Guo Q, 2011, INT SYMP MICROARCH, P339
   Hinton G., 2010, 2010003 U TOR DEP CO
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Ho C., 2010, EL DEV M IEDM 2010 I, P19
   HU M, 2011, P INT C COMP AID DES, P345
   Hu M, 2011, ASIA S PACIF DES AUT, DOI 10.1109/ASPDAC.2011.5722193
   KAUTZ H, 1996, SATISFIABILITY PROBL, P573
   Ker MD, 2006, IEEE J SOLID-ST CIRC, V41, P1100, DOI 10.1109/JSSC.2006.872704
   Kester Walt, 2004, DATA CONVERSION HDB
   Kim LW, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2539125
   Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   Kozma R., 2012, ADV NEUROMORPHIC MEM, DOI 10.1007/978-94-007-4491-2
   Larkin D, 2006, LECT NOTES COMPUT SC, V3973, P1319
   LARRABEE T, 1992, IEEE T COMPUT AID D, V11, P4, DOI 10.1109/43.108614
   Le Ly D, 2010, IEEE T NEURAL NETWOR, V21, P1780, DOI 10.1109/TNN.2010.2073481
   Lee MJ, 2011, NAT MATER, V10, P625, DOI [10.1038/nmat3070, 10.1038/NMAT3070]
   LI S, 2009, INT S COMP ARCH
   LO C, 2011, P 19 ACM SIGDA INT S, P189
   Micron, 2009, TN4101 MICR
   Mitchell T.M., 1997, MACH LEARN, V1
   Niu DM, 2012, ASIA S PACIF DES AUT, P79, DOI 10.1109/ASPDAC.2012.6165062
   Niu DM, 2010, DES AUT CON, P877
   O'Donnell R, 2008, ACM S THEORY COMPUT, P335
   Oskin M, 1998, CONF PROC INT SYMP C, P192, DOI 10.1109/ISCA.1998.694774
   Palumbo G, 2010, IEEE CIRC SYST MAG, V10, P31, DOI 10.1109/MCAS.2009.935695
   Pan F, 2014, MAT SCI ENG R, V83, P1, DOI 10.1016/j.mser.2014.06.002
   Papadimitriou C H., 1998, COMBINATORIAL OPTIMI
   Pickett M. D., 2012, NATURE MAT
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Razavi B., 1995, PRINCIPLES DATA CONV
   Renau J., 2005, SESC SIMULATOR
   Sheri AM, 2015, ENG APPL ARTIF INTEL, V37, P336, DOI 10.1016/j.engappai.2014.09.013
   Skubiszewski M., 1992, Proceedings of the Fourth IEEE Symposium on Parallel and Distributed Processing (Cat. No.92TH0492-9), P107, DOI 10.1109/SPDP.1992.242756
   Suzuki H., 2013, SCI REPORTS, V3, P1
   Thoziyoor S, 2008, CONF PROC INT SYMP C, P51, DOI 10.1109/ISCA.2008.16
   Tommiska MT, 2003, IEE P-COMPUT DIG T, V150, P403, DOI 10.1049/ip-cdt:20030965
   Torrezan AC, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/48/485203
   Wang JX, 2013, I SYMPOS LOW POWER E, P175, DOI 10.1109/ISLPED.2013.6629290
   Wawrzynski P, 2011, NEUROCOMPUTING, V74, P2893, DOI 10.1016/j.neucom.2011.03.029
   Wegener I., 2004, ELECT C COMPUTATIONA
   Welling M, 2002, LECT NOTES COMPUT SC, V2415, P351
   Wilton SJE, 1996, IEEE J SOLID-ST CIRC, V31, P677, DOI 10.1109/4.509850
   Yakopcic C, 2014, ELECTRON LETT, V50, P492, DOI 10.1049/el.2014.0464
   Yun Zhu, 2013, 2013 IEEE International Conference on Big Data, P169, DOI 10.1109/BigData.2013.6691750
   Zangeneh M, 2014, IEEE T VLSI SYST, V22, P1815, DOI 10.1109/TVLSI.2013.2277715
   ZHAO W, 2006, INT S QUAL EL DES
NR 77
TC 146
Z9 153
U1 2
U2 20
PY 2016
BP 1
EP 13
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Masadeh, M
   Hasan, O
   Tahar, S
AF Masadeh, Mahmoud
   Hasan, Osman
   Tahar, Sofiene
GP IEEE
TI Machine Learning-Based Self-Compensating Approximate Computing
SO 2020 14TH ANNUAL IEEE INTERNATIONAL SYSTEMS CONFERENCE (SYSCON2020)
SE Annual IEEE Systems Conference
DT Proceedings Paper
CT 14th Annual IEEE International Systems Conference (SysCon)
CY AUG 24-27, 2020
CL ELECTR NETWORK
ID LOW-POWER; ACCELERATORS
AB Dedicated hardware accelerators are suitable for parallel computational tasks. Moreover, they have the tendency to accept inexact results. These hardware accelerators are extensively used in image processing and computer vision applications, e.g., to process the dense 3-D maps required for self-driving cars. Such error-tolerant hardware accelerators can be designed approximately for reduced power consumption and/or processing time. However, since for some inputs the output errors may reach unacceptable levels, the main challenge is to enhance the accuracy of the results of approximate accelerators and keep the error magnitude within an allowed range. Towards this goal, in this paper, we propose a novel machine learning-based self-compensating approximate accelerators for energy efficient systems. The proposed error compensation module, which is integrated within the architecture of approximate hardware accelerators, efficiently reduces the accumulated error at its output. It utilizes lightweight supervised machine learning techniques, i.e., decision tree, to capture input dependency of the error. We consider image blending application in multiplication mode to demonstrate a practical application of self-compensating approximate computing. Simulation results show that the proposed design of self-compensating approximate accelerator can achieve about 9% accuracy enhancement, with negligible overhead in other performance measures, i.e., power, area, delay and energy.
C1 [Masadeh, Mahmoud; Hasan, Osman; Tahar, Sofiene] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
RP Masadeh, M (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
EM m_masa@ece.concordia.ca; o_hasan@ece.concordia.ca;
   tahar@ece.concordia.ca
CR [Anonymous], 2019, MENTOR GRAPHICS MODE
   [Anonymous], 2019, R PROJECT STAT COMPU
   [Anonymous], 2019, PACKAGE C50
   Baek W, 2010, ACM SIGPLAN NOTICES, V45, P198, DOI 10.1145/1809028.1806620
   Brandalero M, 2018, DES AUT CON, DOI 10.1145/3195970.3195993
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Han J, 2013, PROC EUR TEST SYMP
   Masadeh M, 2019, IEEE ACCESS, V7, P147129, DOI 10.1109/ACCESS.2019.2946513
   Masadeh M, 2019, DES AUT TEST EUROPE, P1575, DOI [10.23919/date.2019.8714957, 10.23919/DATE.2019.8714957]
   Masadeh M, 2018, INT C MICROELECTRON, P56, DOI 10.1109/ICM.2018.8704099
   Masadeh M, 2018, PR GR LAK SYMP VLSI, P415, DOI 10.1145/3194554.3194626
   Mazahir S, 2019, MICROELECTRON J, V88, P9, DOI 10.1016/j.mejo.2019.03.008
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Regazzoni F, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243497
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Scanlan AG, 2019, INTEGRATION, V65, P110, DOI 10.1016/j.vlsi.2018.11.010
   Tahar S., 2019, ERROR ANAL APPROXIMA
   Vahdat S, 2017, DES AUT TEST EUROPE, P1635, DOI 10.23919/DATE.2017.7927254
   Venkataramani S, 2015, DES AUT CON, DOI 10.1145/2744769.2744904
   Xu SY, 2017, PR IEEE COMP DESIGN, P113, DOI 10.1109/ICCD.2017.25
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yang ZX, 2013, 2013 13TH IEEE CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P690, DOI 10.1109/NANO.2013.6720793
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/syscon47679.2020.9275895
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Blokland, W
   Rajput, K
   Schram, M
   Jeske, T
   Ramuhalli, P
   Peters, C
   Yucesan, Y
   Zhukov, A
AF Blokland, Willem
   Rajput, Kishansingh
   Schram, Malachi
   Jeske, Torri
   Ramuhalli, Pradeep
   Peters, Charles
   Yucesan, Yigit
   Zhukov, Alexander
TI Uncertainty aware anomaly detection to predict errant beam pulses in the
   Oak Ridge Spallation Neutron Source accelerator
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB High-power particle accelerators are complex machines with thousands of pieces of equipment that are frequently running at the cutting edge of technology. In order to improve the day-to-day operations and maximize the delivery of the science, new analytical techniques are being explored for anomaly detection, classification, and prognostications. As such, we describe the application of an uncertainty aware Machine Learning method using the Siamese neural network model to predict upcoming errant beam pulses using the data from a single monitoring device. By predicting the upcoming failure, we can stop the accelerator before damage occurs. We describe the accelerator operation, related Machine Learning research, the prediction performance required to abort the beam while maintaining operations, the monitoring device and its data, and the uncertainty aware Siamese method and its results. These results show that the researched method can be applied to improve accelerator operations.
C1 [Blokland, Willem; Ramuhalli, Pradeep; Peters, Charles; Yucesan, Yigit; Zhukov, Alexander] Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
   [Rajput, Kishansingh; Schram, Malachi; Jeske, Torri] Thomas Jefferson Natl Accelerator Facil, Newport News, VA 23606 USA.
RP Blokland, W (corresponding author), Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
EM blokland@ornl.gov
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], US
   [Anonymous], 2021, CPU BENCHMARK
   Blokland W., 2013, P 2 INT BEAM INSTR C, P921
   Blokland W., 2019, P 8 INT BEAM INSTRUM, P146, DOI [10.18429/JACoW-IBIC2019-MOPP025, DOI 10.18429/JACOW-IBIC2019-MOPP025]
   Chollet F., 2015, KERAS
   Edelen J. P., 2021, P 2021 IMPROVING SCI, DOI [10.26024/p6mven77, DOI 10.26024/P6MVEN77]
   Edelen JP, 2021, INFORMATION, V12, DOI 10.3390/info12060238
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Fol E, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.102805
   Fol E., 2019, P 10 INT PART ACC C, P2668
   Fol E., 2018, P 39 FREE EL LAS C F, P169
   Hadsell R., 2006, 2006 IEEE COMP SOC C, VVolume 2, P1735, DOI DOI 10.1109/CVPR.2006.100
   Henderson S., 2014, NUCL INSTRUM METHO A, V763, P610, DOI [10.1016/j.nima.2014.03.067, DOI 10.1016/J.NIMA.2014.03.067]
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim SH, 2017, NUCL INSTRUM METH A, V852, P20, DOI 10.1016/j.nima.2017.02.009
   Kim S-H., 2014, P 16 INT C RF SUP SE, P83
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Koch Gregory R., 2015, ICML DEEP LEARN WORK
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Li SC, 2021, INFORMATION, V12, DOI 10.3390/info12030121
   Liu J., ARXIV
   Ma HJ, 2006, PHYS REV SPEC TOP-AC, V9, DOI 10.1103/PhysRevSTAB.9.032001
   Peters C., 2018, P 6 INT BEAM INSTRUM
   Rei M., 2022, NUCL INSTRUM METH A, V1025
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Sanchez-Gonzalez A, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15461
   Scheinker A, 2022, IEEE T CONTR SYST T, V30, P2261, DOI 10.1109/TCST.2021.3136133
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Schwabacher M., 2007, AAAI FALL S, P107
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Valentino G., 2018, P 9 INT PART ACC C, V1067
   Virtanen P, 2020, NAT METHODS, V17, P352, DOI 10.1038/s41592-020-0772-5
   Wielgosz M, 2019, INT J AP MAT COM-POL, V29, P503, DOI 10.2478/amcs-2019-0037
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 36
TC 2
Z9 2
U1 2
U2 3
PD DEC 15
PY 2022
VL 25
IS 12
AR 122802
DI 10.1103/PhysRevAccelBeams.25.122802
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Prakash, S
   Callahan, T
   Bushagour, J
   Banbury, C
   Green, AV
   Warden, P
   Ansell, T
   Reddi, VJ
AF Prakash, Shvetank
   Callahan, Tim
   Bushagour, Joseph
   Banbury, Colby
   Green, Alan V.
   Warden, Pete
   Ansell, Tim
   Reddi, Vijay Janapa
BE IEEE
TI CFU Playground: Want a faster ML processor? Do it yourself!
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
AB The rise of machine learning (ML) has necessitated the development of innovative processing engines. However, development of specialized hardware accelerators can incur enormous one-time engineering expenses that should be avoided in low-cost embedded ML systems. In addition, embedded systems have tight resource constraints that prevent them from affording the "full-blown" machine learning (ML) accelerators seen in many cloud environments. In embedded situations, a custom function unit (CFU) that is more lightweight is preferable. We offer CFU Playground, an open-source toolchain for accelerating embedded machine learning (ML) on FPGAs through the use of CFUs.
C1 [Callahan, Tim; Green, Alan V.; Warden, Pete; Ansell, Tim] Google, Mountain View, CA USA.
   [Bushagour, Joseph] Purdue Univ, W Lafayette, IN USA.
   [Prakash, Shvetank; Banbury, Colby; Reddi, Vijay Janapa] Harvard Univ, Cambridge, MA 02138 USA.
RP Prakash, S (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
CR Andrade L, 2018, DES AUT TEST EUROPE, P1033, DOI 10.23919/DATE.2018.8342164
   Antmicro, 2018, RENODE
   David Robert, 2021, PROC MACHINE LEARNIN, V3, P800
   F. K, 2020, CORR
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, DOI 10.48550/ARXIV.1704.04861]
   Gray J., COMPOSABLE CUSTOM FU
   Murray KE, 2020, IEEE MICRO, V40, P49, DOI 10.1109/MM.2020.2998435
   Papon C., VEXRISCV
   Saha SS, 2022, IEEE SENS J, V22, P21362, DOI [10.1109/JSEN.2022.3210773, 10.1109/jsen.2022.3210773]
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Veripool, VERILATOR
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT J
AU Scanlan, AG
AF Scanlan, Anthony G.
TI Low power & mobile hardware accelerators for deep convolutional neural
   networks
SO INTEGRATION-THE VLSI JOURNAL
DT Article
DE Machine learning; Hardware accelerator; Deep learning; Neural networks;
   Parallel processing; Very large scale integration (VLSI); Low power;
   Switched capacitor
ID ANALOG; GPU
AB This article provides a comprehensive review of recent developments in the field of computational hardware for mobile low power machine learning hardware accelerators. The article provides an introduction to neural networks, convolutional neural networks and details recent developments in state of the art deep convolutional neural networks. The key considerations in the design of low power hardware accelerators are discussed with reference to a conceptual system. Strategies for reducing the energy cost of memory access and computation in state of the art hardware accelerators are detailed. This includes techniques such as dataflow, reduced precision, model compression and sparsity. Recent reported digital mobile accelerators for deep convolutional neural networks with power consumptions of less than 3.3 W are observed to have 4x-20x better efficiency than the reference GPU accelerator at 16-bit precision, and can achieve 20x-1171x better efficiency at less than 4-bit precision. Efficiency improvements of 20x-1171x over a GPU is observed for reported mobile accelerators with reduced precision.
C1 [Scanlan, Anthony G.] Univ Limerick, Limerick, Ireland.
RP Scanlan, AG (corresponding author), Univ Limerick, Limerick, Ireland.
EM tony.scanlan@ul.ie
CR Abadi Martin, 2016, arXiv
   Adolf R., 2016, WORKL CHAR IISWC 201
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ando K., 2017, VLSI CIRC 2017 S
   Andri Renzo, 2016, VLSI ISVLSI 2016 IEE
   Aydonat U., 2017, P 2017 ACM SIGDA INT
   Balavoine A., 2011, DIG SIGN PROC WORKSH
   Bang S., 2017, SOL STAT CIRC C ISSC
   Bankman D., 2016, SOL STAT CIRC C A SS
   Bankman D., 2018, SOL STAT CIRC C ISSC
   Bergstra J., 2010, P PYTH SCI COMP C SC, P3
   Bong K., 2017, SOL STAT CIRC C ISSC
   Bridle J. S., 1990, NEUROCOMPUTING, P227, DOI DOI 10.1007/978-3-642-76153-9_28
   Buhler F. N., 2017, VLSI CIRC 2017 S
   Buhler FN, 2016, SYMP VLSI CIRCUITS
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Collobert R., 2011, BIGLEARN
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Cui HG, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901323
   Denil M., 2013, ADV NEURAL INFORM PR, V26, P2148, DOI DOI 10.5555/2999792.2999852
   Desoli G., 2017, SOL STAT CIRC C ISSC
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Foley D, 2017, IEEE MICRO, V37, P7, DOI 10.1109/MM.2017.37
   Furber SB, 2016, IET COMPUT DIGIT TEC, V10, P299, DOI 10.1049/iet-cdt.2015.0171
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hassibi B., 1992, P ADV NEUR INF PROC, V5, DOI DOI 10.5555/645753.668069
   Hauswald J., 2015, ACM SIGARCH COMPUTER
   He K., 2016, P IEEE C COMPUTER VI
   Horowitz M., 2014, SOL STAT CIRC C ISSC
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jaderberg M., 2014, ARXIV14053866, DOI DOI 10.5244/C.28.88
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni A., 2017, CIRC SYST ISCAS 2017
   Lane ND, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P117, DOI 10.1145/2699343.2699349
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   LeCun Y., 2013, ARXIV PREPRINT ARXIV
   Lee E. H., 2016, SOL STAT CIRC C ISSC
   Lee J., 2018, SOL STAT CIRC C ISSC
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Liu S., 2016, ACM SIGARCH COMPUTER
   Lu J, 2015, IEEE J SOLID-ST CIRC, V50, P270, DOI 10.1109/JSSC.2014.2356197
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Maeda N, 2013, IEEE J SOLID-ST CIRC, V48, P917, DOI 10.1109/JSSC.2012.2237571
   Miyashita D., 2016, ARXIV160301025
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moon UK, 1999, ELECTRON LETT, V35, P1903, DOI 10.1049/el:19991288
   Moons B., 2017, SOL STAT CIRC C ISSC
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park Seongwook, 2015, SOL STAT CIRC C ISSC
   Pham P.-H., 2012, CIRC SYST MWSCAS 201
   Pullini A, 2018, IEEE T CIRCUITS-II, V65, P1094, DOI 10.1109/TCSII.2017.2652982
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarpeshkar R, 1998, NEURAL COMPUT, V10, P1601, DOI 10.1162/089976698300017052
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shin D., 2017, IEEE INT SOL STAT CI
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Ueyoshi K., 2018, SOL STAT CIRC C ISSC
   Vakili S, 2016, IET COMPUT DIGIT TEC, V10, P1, DOI 10.1049/iet-cdt.2014.0188
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Verhelst Marian, 2015, IEEE Solid-State Circuits Magazine, V7, P67, DOI 10.1109/MSSC.2015.2442394
   Wang A., 2017, P 44 ANN INT S COMP
   Wang Z, 2015, IEEE T BIOMED CIRC S, V9, P825, DOI 10.1109/TBCAS.2015.2500101
   Whatmough P. N., 2017, SOL STAT CIRC C ISSC
   WINOGRAD S, 1968, IEEE T COMPUT, VC 17, P693, DOI 10.1109/TC.1968.227420
   Xavier Glorot, 2011, P 14 INT C ARTIFICIA, P315, DOI DOI 10.1002/ECS2.1832
   Xu C., 2014, P 2014 IEEE ACM INT
   Yin S., 2017, VLSI CIRC 2017 S
   Zhan J, 2016, INT SYMP MICROARCH
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 88
TC 6
Z9 7
U1 4
U2 12
PD MAR
PY 2019
VL 65
BP 110
EP 127
DI 10.1016/j.vlsi.2018.11.010
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Lim, J
   Choi, M
   Liu, BW
   Kang, T
   Li, ZY
   Wang, ZH
   Zhang, YQ
   Yang, KY
   Blaauw, D
   Kim, HS
   Sylvester, D
AF Lim, Jongyup
   Choi, Myungjoon
   Liu, Bowen
   Kang, Taewook
   Li, Ziyun
   Wang, Zhehong
   Zhang, Yiqun
   Yang, Kaiyuan
   Blaauw, David
   Kim, Hun-Seok
   Sylvester, Dennis
GP IEEE
TI AA-ResNet: Energy Efficient All-Analog ResNet Accelerator
SO 2020 IEEE 63RD INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT 63rd IEEE International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY APR 09-12, 2020
CL ELECTR NETWORK
DE machine learning accelerator; in-memory computing; analog computing;
   deep residual learning
ID MEMORY
AB High energy efficiency is a major concern for emerging machine learning accelerators designed for IoT edge computing. Recent studies propose in-memory and mixed-signal approaches to minimize energy overhead resulting from frequent memory accesses and extensive digital computation. However, their energy efficiency gain is often limited by the overhead of digital-to-analog and analog-to-digital conversions at the boundary of the compute-memory. In this paper, we propose a new in-memory accelerator that performs all computation in the analog domain for a large, multi-level neural network (NN) for the first time avoiding any digital-to-analog or analog-to-digital conversion overhead. We propose an all-analog ResNet (AA-ResNet) accelerator in 28-nm CMOS, achieving an energy efficiency of 1.2 mu J/inference and inference rate of 325K images/s for the CIFAR-10 and SVHN datasets in SPICE simulation.
C1 [Lim, Jongyup; Choi, Myungjoon; Liu, Bowen; Kang, Taewook; Li, Ziyun; Wang, Zhehong; Zhang, Yiqun; Yang, Kaiyuan; Blaauw, David; Kim, Hun-Seok; Sylvester, Dennis] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
RP Lim, J (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
EM jongyup@umich.edu
CR Amaravati A, 2019, IEEE J SOLID-ST CIRC, V54, P75, DOI 10.1109/JSSC.2018.2881288
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   He K., 2016, P IEEE C COMPUTER VI
   Jia KG, 2018, DES AUT CON, DOI 10.1145/3195970.3196004
   St Amant R, 2014, CONF PROC INT SYMP C, P505, DOI 10.1109/ISCA.2014.6853213
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
NR 8
TC 1
Z9 1
U1 0
U2 2
PY 2020
BP 603
EP 606
DI 10.1109/mwscas48704.2020.9184587
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Bavikadi, S
   Dhavlle, A
   Ganguly, A
   Haridass, A
   Hendy, H
   Merkel, C
   Reddi, VJ
   Sutradhar, PR
   Joseph, A
   Dinakarrao, SMP
AF Bavikadi, Sathwika
   Dhavlle, Abhijitt
   Ganguly, Amlan
   Haridass, Anand
   Hendy, Hagar
   Merkel, Cory
   Reddi, Vijay Janapa
   Sutradhar, Purab Ranjan
   Joseph, Arun
   Pudukotai Dinakarrao, Sai Manoj
TI A Survey on Machine Learning Accelerators and Evolutionary Hardware
   Platforms
SO IEEE DESIGN & TEST
DT Editorial Material
ID DESIGN AUTOMATION; NEURAL-NETWORKS; MEMORY; VERIFICATION; RESILIENCE;
   ACCURACY; EDA
C1 [Bavikadi, Sathwika; Dhavlle, Abhijitt; Pudukotai Dinakarrao, Sai Manoj] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
   [Ganguly, Amlan; Sutradhar, Purab Ranjan] Rochester Inst Technol, Dept Comp Engn, Rochester, NY 14623 USA.
   [Haridass, Anand] Intel Corp, Bengaluru 560103, India.
   [Hendy, Hagar; Merkel, Cory] Rochester Inst Technol, Dept Comp Engn, Rochester, NY 14623 USA.
   [Reddi, Vijay Janapa] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Joseph, Arun] IBM Elect Design Automat, Bengaluru 560045, India.
RP Bavikadi, S (corresponding author), George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
EM spudukot@gmu.edu
CR Abu Talib M, 2021, J SUPERCOMPUT, V77, P1897, DOI 10.1007/s11227-020-03325-8
   Ahmed, 2021, PROC IEEE INT GREEN, V29
   AKERS SB, 1978, IEEE T COMPUT, V27, P509, DOI 10.1109/TC.1978.1675141
   Al-Shedivat M, 2015, I IEEE EMBS C NEUR E, P356, DOI 10.1109/NER.2015.7146633
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Angizi S, 2020, IEEE T COMPUT AID D, V39, P1123, DOI 10.1109/TCAD.2019.2907886
   Angizi S, 2018, DES AUT CON, DOI 10.1145/3195970.3196009
   Angizi S, 2018, ASIA S PACIF DES AUT, P111, DOI 10.1109/ASPDAC.2018.8297291
   [Anonymous], 2020, PROC SI
   [Anonymous], 2018, INT S VLSI DES TEST
   Barve S. D., P ACM GREAT LAK S VL, V2021, P201
   Bavikadi S., 2021, 2021 IEEE 3 INT C AR, P1
   Bavikadi S., 2020, P 2020 GREAT LAK S V, P89
   BENTLEY JL, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P187, DOI 10.1145/98524.98564
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Brayton R, 2010, LECT NOTES COMPUT SC, V6174, P24, DOI 10.1007/978-3-642-14295-6_5
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai H, 2019, IEEE COMP SOC ANN, P111, DOI 10.1109/ISVLSI.2019.00029
   Cali, 2018, ACCELERATING APPROXI
   Chabi D., 2011, 2011 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH), P137, DOI 10.1109/NANOARCH.2011.5941495
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chakradhar ST, 2010, DES AUT CON, P865
   Changyuan Yu, 2018, 2018 27th Wireless and Optical Communication Conference (WOCC), DOI 10.1109/WOCC.2018.8373787
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen ZQ, 2020, DES AUT TEST EUROPE, P358, DOI [10.23919/date48585.2020.9116544, 10.23919/DATE48585.2020.9116544]
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Darringer J, 2000, IEEE T COMPUT AID D, V19, P1476, DOI 10.1109/43.898827
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Dhavlle A., 2020, 2020 11 INT GREEN SU, P1
   Dinakarrao Sai Manoj Pudukotai, 2019, 2019 56th ACM/IEEE Design Automation Conference (DAC). Proceedings, DOI 10.1145/3316781.3317762
   Dinakarrao S. M. P., 2021, PROC IEEE INT GREEN, V29
   Dinakarrao SMP, 2020, IEEE ACCESS, V8, P138508, DOI 10.1109/ACCESS.2020.3011919
   Dong Liu, 2016, 2016 26th International Conference on Field Programmable Logic and Applications (FPL). Proceedings, DOI 10.1109/FPL.2016.7577370
   Dozortsev A, 2018, INT J CIRC THEOR APP, V46, P122, DOI 10.1002/cta.2399
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Ebrahimi Zahra, 2020, GLSVLSI '20. Proceedings of the 2020 Great Lakes Symposium on VLSI, P151, DOI 10.1145/3386263.3406907
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Fouda ME, 2019, CONF REC ASILOMAR C, P495, DOI [10.1109/IEEECONF44664.2019.9049043, 10.1109/ieeeconf44664.2019.9049043]
   Fransén E, 2005, NEUROCOMPUTING, V65, P39, DOI 10.1016/j.neucom.2004.10.085
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Ganguly A, 2019, INT SYM QUAL ELECT, P335, DOI 10.1109/ISQED.2019.8697354
   Gao DW, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P155, DOI 10.1145/3394486.3403058
   Gholami Amir, 2021, ARXIV210313630
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Grigorian B, 2015, INT S HIGH PERF COMP, P615, DOI 10.1109/HPCA.2015.7056067
   Guan H, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P717, DOI 10.1145/3314221.3314652
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Guo XJ, 2019, IEEE DATA MINING, P250, DOI 10.1109/ICDM.2019.00035
   Han JW, 2018, IEEE ELECTR DEVICE L, V39, P1457, DOI 10.1109/LED.2018.2856092
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Hasan R, 2017, MICROELECTRON J, V66, P31, DOI 10.1016/j.mejo.2017.05.005
   HASSEN AU, 2019, P IEEE 62 INT MIDW S, P1183
   Hormigo J, 2013, ACM T RECONFIG TECHN, V6, DOI 10.1145/2490830
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang GY, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3451179
   Hubara I, 2016, ADV NEUR IN, V29
   Hubara I, 2018, J MACH LEARN RES, V18
   Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073
   JACKINS CL, 1983, IEEE T PATTERN ANAL, V5, P533, DOI 10.1109/TPAMI.1983.4767433
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Jones A, 2020, NEUROCOMPUTING, V381, P89, DOI 10.1016/j.neucom.2019.09.098
   Joseph A., 2021, PROC DESIGN AUTOMAT
   Kahng AB, 2015, 2015 ACM/IEEE INTERNATIONAL WORKSHOP ON SYSTEM LEVEL INTERCONNECT PREDICTION (SLIP)
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, CIFAR 10 CANADIAN I
   LECHNER M, 2019, PROC 10 INT GREEN SU, P1
   Lee BS, 2014, J APPL PHYS, V115, DOI 10.1063/1.4865295
   Lee I, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0140-0
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Li SC, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P696, DOI [10.1109/MICRO.2018.00062, 10.1109/MICR0.2018.00062]
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Lin H, 2020, ADV NEURAL INFORM PR, V33, P1796
   Liu D, 2015, PROCEEDINGS OF 2015 INTERNATIONAL SYMPOSIUM - COLLEGE FOREIGN LANGUAGES EDUCATION REFORM AND INNOVATION, P369
   Lu SL, 2012, ICCAD-IEEE ACM INT, P271
   Manoj PDS, 2017, IEEE T CIRCUITS-I, V64, P1432, DOI 10.1109/TCSI.2016.2647322
   MEAD C, 1990, P IEEE, V78, P1629, DOI 10.1109/5.58356
   MEAD CA, 1989, ADVANCED RESEARCH IN VLSI : PROCEEDINGS OF THE DECENNIAL CALTECH CONFERENCE ON VLSI, P1
   Merkel C., 2019, P 7 ANN NEUR COMP EL, P1, DOI DOI 10.1145/3320288.3320298
   Merkel C, 2014, PR GR LAK SYMP VLSI, P241, DOI 10.1145/2591513.2591572
   Merkel C, 2015, I CONF VLSI DESIGN, P99, DOI 10.1109/VLSID.2015.22
   Midya R, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900060
   Milo V, 2016, INT EL DEVICES MEET
   Mirhoseini A, 2020, ARXIV200410746
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Mulaosmanovic H, 2017, S VLSI TECH, pT176, DOI 10.23919/VLSIT.2017.7998165
   MUSTAFA A, 2020, IEEE T CIRCUITS-I, V67, P2521
   Neftci EO, 2019, IEEE SIGNAL PROC MAG, V36, P51, DOI 10.1109/MSP.2019.2931595
   Pagani S, 2020, IEEE T COMPUT AID D, V39, P101, DOI 10.1109/TCAD.2018.2878168
   Pan Y, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2018.2848625
   Panainte EM, 2007, ACM T EMBED COMPUT S, V6, DOI 10.1145/1210268.1210274
   Panda D.K, 2017, P MACHINE LEARNING H, P8
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Pasandi M M, 2020, ARXIV200104062
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Peng, 2018, ARXIV180710458
   Prabakaran BS, 2018, DES AUT TEST EUROPE, P917, DOI 10.23919/DATE.2018.8342140
   Qiao XM, 2018, DES AUT CON, DOI 10.1145/3195970.3195998
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Roesner, 2015, PROC TCE
   Roesner W., 2014, P DES AUT C
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Roy K, 2020, IEEE INT ULTRA SYM
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Saadat H, 2018, IEEE T COMPUT AID D, V37, P2623, DOI 10.1109/TCAD.2018.2857262
   Safieddine M. H., 2015, PROC DVCON, P1
   Safieddine MH, 2019, IEEE T COMPUT AID D, V38, P1529, DOI 10.1109/TCAD.2018.2848589
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Sampson A., 2015, ACCEPT PROGRAMMER GU
   Saxena V, 2021, IEEE T CIRCUITS-II, V68, P581, DOI 10.1109/TCSII.2020.3048034
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shan Y, 2010, FPGA 10, P93
   Shi LY, 2020, NANOSCALE ADV, V2, P1811, DOI 10.1039/d0na00100g
   Shi QC, 2015, IEEE COMPUT ARCHIT L, V14, P85, DOI 10.1109/LCA.2014.2365204
   Shukla Sanket, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P406, DOI 10.1109/ICMLA.2019.00076
   Shukla S, 2021, DES AUT CON, P967, DOI 10.1109/DAC18074.2021.9586330
   Shukla S, 2019, PROC INT C TOOLS ART, P590, DOI 10.1109/ICTAI.2019.00088
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soltiz M, 2013, IEEE T COMPUT, V62, P1597, DOI 10.1109/TC.2013.75
   Song LL, 2016, DES AUT CON, DOI 10.1145/2897937.2897995
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sourikopoulos I, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00123
   Stewart R, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040396
   Stok, 2015, PROC TAU
   Stok L, 2014, IEEE DES TEST, V31, P40, DOI 10.1109/MDAT.2014.2313451
   STONE HS, 1970, IEEE T COMPUT, VC 19, P73, DOI 10.1109/TC.1970.5008902
   Sutradhar PR, 2022, IEEE T PARALL DISTR, V33, P263, DOI 10.1109/TPDS.2021.3066909
   Sutradhar PR, 2020, IEEE COMPUT ARCHIT L, V19, P118, DOI 10.1109/LCA.2020.3011643
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang YB, 2017, ASIA S PACIF DES AUT, P396, DOI 10.1109/ASPDAC.2017.7858355
   Terzo O., 2019, HETEROGENEOUS COMPUT
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3195996
   Vranjkovic V, 2016, INT CONF SYST SIGNAL, P193
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Ward S, 2012, DES AUT CON, P756
   Wawrzynek J, 2007, IEEE MICRO, V27, P46, DOI 10.1109/MM.2007.39
   Wenbin Li, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1160), P35, DOI 10.1007/978-3-030-45691-7_4
   Wess M, 2018, IEEE T COMPUT AID D, V37, P2929, DOI 10.1109/TCAD.2018.2857080
   Xie ZY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240843
   Xu P, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON UNMANNED SYSTEMS (ICUS), P1, DOI 10.1109/ICUS.2017.8278307
   Yantir HE, 2018, IEEE J EM SEL TOP C, V8, P758, DOI 10.1109/JETCAS.2018.2852701
   Yantir HE, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126526
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Zervakis G, 2020, IEEE ACCESS, V8, P53522, DOI 10.1109/ACCESS.2020.2981395
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhao CY, 2016, IEEE T MULTI-SCALE C, V2, P265, DOI 10.1109/TMSCS.2016.2607164
   Zhao JR, 2019, DES AUT TEST EUROPE, P1130, DOI [10.23919/DATE.2019.8714724, 10.23919/date.2019.8714724]
   Zhao R, 2018, IEEE INT CONF SENS, P325
   Zhu CY, 2020, IEEE T VLSI SYST, V28, P1953, DOI 10.1109/TVLSI.2020.3002779
   Zhuo C, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P227, DOI 10.1109/SOCC.2017.8226046
   Zidan MA, 2014, IEEE T NANOTECHNOL, V13, P274, DOI 10.1109/TNANO.2014.2299558
   Zidan MA, 2013, MICROELECTRON J, V44, P176, DOI 10.1016/j.mejo.2012.10.001
   ZUNINO R, 2002, P IEEE INT S CIRC SY, V2, P2
NR 172
TC 7
Z9 7
U1 4
U2 14
PD JUN
PY 2022
VL 39
IS 3
BP 91
EP 116
DI 10.1109/MDAT.2022.3161126
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Wang, C
   Gong, L
   Ma, X
   Li, X
   Zhou, XH
AF Wang, Chao
   Gong, Lei
   Ma, Xiang
   Li, Xi
   Zhou, Xuehai
TI WooKong: A Ubiquitous Accelerator for Recommendation Algorithms With
   Custom Instruction Sets on FPGA
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Prediction algorithms; Field programmable gate arrays; Mathematical
   model; Hardware; Machine learning algorithms; Acceleration; Measurement;
   Accelerator; recommendation algorithms; machine learning;
   domain-specific architecture; FPGA
AB Recommendation algorithms, such as Neighborhood-based Collaborative- Filtering (CF), have been widely applied in various emerging machine learning applications. However, under the circumstance of the explosive big data, it poses significant challenges to CF recommendation algorithms as it is becoming quite time and energy-consuming. It has to be optimized and accelerated by powerful engines to process on large data scale. To solve these problems, in this article, we propose WooKong, a ubiquitous accelerator architecture for the collaborative-filtering recommendation on FPGA. It is able to accommodate three types of CF recommendation algorithms, including User-based CF, Item-based CF, and SlopeOne recommendations algorithms, with five different similarity analysis metrics including Jaccard, Cosine, CosineIR, euclidean, and Pearson. To maintain flexibility for these different CF algorithms and metrics, we adopt custom instruction sets to manipulate the learning and prediction accelerators. We implement a hardware prototype on a real Xilinx Zynq FPGA development board. Experimental results show that the proposed learning and prediction accelerators can achieve 8.0X speedup and 1.7X speedup compared with an Intel i7 processor respectively. The accelerator has the energy benefits of up to 137.4X compared with an NVIDIA Tesla K40C GPU, with the affordable hardware cost.
C1 [Wang, Chao; Gong, Lei; Ma, Xiang; Li, Xi; Zhou, Xuehai] Univ Sci & Technol China, Sch Comp Sci, Hefei 230027, Anhui, Peoples R China.
RP Gong, L (corresponding author), Univ Sci & Technol China, Sch Comp Sci, Hefei 230027, Anhui, Peoples R China.
EM cswang@ustc.edu.cn; leigong0203@ustc.edu.cn; maxiang@ustc.edu.cn;
   llxx@ustc.edu.cn; xhzhou@ustc.edu.cn
CR [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2016, ARXIV160204283
   [Anonymous], NATURE
   [Anonymous], 2016 53 ACM EDAC IEE
   Bastien F, 2012, P DEEP LEARN UNS FEA
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cui HG, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901323
   Dai GH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P105, DOI 10.1145/2847263.2847339
   Du ZD, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P494, DOI 10.1145/2830772.2830789
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim H, 2015, J CONSTR ENG M, V141, DOI 10.1061/(ASCE)CO.1943-7862.0001002
   Li BZ, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P36, DOI 10.1145/2847263.2847340
   Li BX, 2014, IEEE IJCNN, P4062, DOI 10.1109/IJCNN.2014.6889433
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   MovieLens, 2016, MOVIELENS DATASET
   Nadungodage CH, 2013, IEEE INT CONF BIG DA, DOI 10.1109/BigData.2013.6691571
   Nurvitadhi E, 2014, ANN IEEE SYM FIELD P, P25, DOI 10.1109/FCCM.2014.15
   Olson CB, 2012, ANN IEEE SYM FIELD P, P161, DOI 10.1109/FCCM.2012.36
   Park S, 2016, ISSCC DIG TECH PAP I, V59, P254
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Qouneh A, 2015, PROC INT CONF PARAL, P1, DOI 10.1109/ICPP.2015.9
   Segaran T., 2007, PROGRAMMING COLLECTI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shi Y, 2014, PROCEDIA COMPUT SCI, V30, P66, DOI 10.1016/j.procs.2014.05.382
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Song L., 2016, P 53 ANN DES AUT C D
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Vasilache N., 2015, PROC 3RD INT CONF LE
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Weaver V. M., 2012, 2012 41st International Conference on Parallel Processing Workshops (ICPPW 2012), P262, DOI 10.1109/ICPPW.2012.39
   Yazdanbakhsh A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P482, DOI 10.1145/2830772.2830810
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao ZD, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P478, DOI 10.1109/WKDD.2010.54
NR 43
TC 8
Z9 9
U1 2
U2 18
PD JUL 1
PY 2020
VL 69
IS 7
BP 1071
EP 1082
DI 10.1109/TC.2020.2988209
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Mishra, AA
   Edelen, A
   Hanuka, A
   Mayes, C
AF Mishra, Aashwin Ananda
   Edelen, Auralee
   Hanuka, Adi
   Mayes, Christopher
TI Uncertainty quantification for deep learning in particle accelerator
   applications
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
ID NETWORKS
AB With the advent of increased computational resources and improved algorithms, machine learning-based models are being increasingly applied to complex problems in particle accelerators. However, such data -driven models may provide overly confident predictions with unknown errors and uncertainties. For reliable deployment of machine learning models in high-regret and safety-critical systems such as particle accelerators, estimates of prediction uncertainty are needed along with accurate point predictions. In this investigation, we evaluate Bayesian neural networks (BNN) as an approach that can provide accurate predictions along with reliably quantified uncertainties for particle accelerator problems, and compare their performance with bootstrapped ensembles of neural networks. We select three accelerator setups for this evaluation: a storage ring, a photoinjector, and a linac. The problems span different data volumes and dimensionalities (e.g., scalar predictions as well as image outputs). It is found that BNN provide accurate predictions of the mean along with reliable estimates of predictive uncertainty across the test cases. In this vein, BNN may offer an attractive alternative to deterministic deep learning tools to generate accurate predictions with quantified uncertainties in particle accelerator applications.
C1 [Mishra, Aashwin Ananda; Edelen, Auralee; Hanuka, Adi; Mayes, Christopher] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
RP Mishra, AA (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM aashwin@slac.stanford.edu
CR Amaldi U., 2000, EUROPHYS NEWS, V31, P5, DOI DOI 10.1051/EPN:2000601
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], ARXIV160606565
   [Anonymous], 2013, UNCERTAINTY QUANTIFI
   Bellomo P., 1999, SLACR609
   Benson S., 1999, Proceedings of the 1999 Particle Accelerator Conference (Cat. No.99CH36366), P212, DOI 10.1109/PAC.1999.795667
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Dodds L., 2018, TELEGRAPH
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A., 2018, P 9 INT PART ACC C I
   Edelen A., ARXIV161205662
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A. L., 2017, LAUR1728069 LANL
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Fazio M., 2019, 1631121 USDOE OFF SC
   Floettmann K., 2017, DESY32
   Fol E., 2017, THESIS HOCHSCHULE EN
   Franchi A, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.034002
   Gal Y., 2016, UNCERTAINTY DEEP LEA, V1
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2011, ADV NEURAL INFORM PR, P2348, DOI DOI 10.5555/2986459.2986721
   Habib K., 2017, PE16007 NATL HIGHW T
   Hanuka A., ARXIV191101538
   Hein M, 2019, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2019.00013
   Hendrycks D., ARXIV161002136
   Hendrycks D., 2018, P ICLR
   Hettel R., 2005, SLACPUB11679
   Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, P5, DOI 10.1145/168304.168306
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Huang XB, 2013, NUCL INSTRUM METH A, V726, P77, DOI 10.1016/j.nima.2013.05.046
   Huang XW, 2017, LECT NOTES COMPUT SC, V10426, P3, DOI 10.1007/978-3-319-63387-9_1
   Kendall A., 2017, ADV NEURAL INFORM PR, V30, P5574
   Kingma D., 2013, ARXIV
   Lakshminarayanan B., 2017, ADV NEURAL INFORM PR, P6402, DOI DOI 10.5555/3295222.3295387
   Lee S., ARXIV151106314
   Michelmore R., ARXIV181106817
   N. R. Council, 2009, SCI ASS HIGH POW FRE
   N. T. S. B. (NTSB), NTSBHAR17XX NATL TRA
   National Transportation Safety Board (NTSB), 2020, NTSBHAR2001
   National Transportation Safety Board (NTSB), 2017, NTSBHAR1702
   Ng W.J., 2015, 07040188 NAV POSTGR
   Nixon J., 2020, CANT BELIEVE ITS NOT
   Osband I., 2016, ADV NEURAL INFORM PR, P4026
   Osband I., 2016, NIPS WORKSH BAYES DE
   Ovadia Y, 2019, ADV NEUR IN, V32
   Pang X., 2015, P IPAC 15 JACOW EUR
   Pearce T., 2018, INT C MACHINE LEARNI, P4075
   Quionero-Candela J., 2009, DATASET SHIFT MACHIN
   Romano Y., ARXIV190503222
   Ryne R., 1997, AM PHYS SOC PART ACC
   Safranek J, 1997, NUCL INSTRUM METH A, V388, P27, DOI 10.1016/S0168-9002(97)00309-4
   Sagan D, 2006, NUCL INSTRUM METH A, V558, P356, DOI 10.1016/j.nima.2005.11.001
   Scheinker A., 2019, LAUR1932526 LANL
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   SCHULTZ JF, 1992, NUCL INSTRUM METH A, V318, P9, DOI 10.1016/0168-9002(92)91014-Z
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou Z., 2012, ENSEMBLE METHODS FDN
NR 58
TC 6
Z9 6
U1 2
U2 4
PD NOV 29
PY 2021
VL 24
IS 11
AR 114601
DI 10.1103/PhysRevAccelBeams.24.114601
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Guo, HS
   Zhang, AJ
   Wang, WJ
AF Guo, Husheng
   Zhang, Aijuan
   Wang, Wenjian
TI An accelerator for online SVM based on the fixed-size KKT window
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
DT Article
DE Online support vector machine; KKT conditions; Window technology;
   Accelerator
ID SUPPORT VECTOR MACHINE; ALGORITHM; MODEL
AB Support vector machine (SVM), as a general and useful supervised learning tool, is facing with some challenges such as low learning efficiency, poor generalization performance, noise sensitivity, etc. when it is applied to online learning tasks. To overcome these limitations, an accelerator model based on window technology and the KKT conditions for online SVM learning is proposed in this paper. The proposed model is not an independent online algorithm but may be regarded as an accelerator for other online SVM learning algorithms, and it constructs working set of SVM by a fixed-size window with the samples which violate the KKT conditions. The relationship between Lagrangain multipliers in dual problem of SVM and KKT conditions are analyzed in the case of online learning. On this basis, a fixed-size KKT window can be constructed according to whether the samples violate KKT conditions or not. Then, it takes the samples that violate the KKT conditions as the training window, which not only makes the training samples with the same size each time, but also ensures that all samples are useful for the hyperplane updating (it means that the classifier can be updated more smoothly). Two typical and specific online SVM algorithms are used as baseline, and the corresponding speeding online SVM learning algorithms with "X+accelerator" models are proposed to testing the performance of the proposed accelerator. Comprehensive experiments clearly show that the proposed model can accelerate the online learning process effectively and has good robustness and generalization performance.
C1 [Guo, Husheng; Zhang, Aijuan; Wang, Wenjian] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
   [Guo, Husheng; Wang, Wenjian] Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China.
RP Wang, WJ (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
EM guohusheng@sxu.edu.cn; 978375014@qq.com; wjwang@sxu.edu.cn
CR Aine S, 2016, ARTIF INTELL, V234, P49, DOI 10.1016/j.artint.2016.01.009
   [Anonymous], 2001, ADV NEURAL INFORM PR
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bordes A, 2005, LECT NOTES ARTIF INT, V3720, P505, DOI 10.1007/11564096_48
   Bordes A, 2009, J MACH LEARN RES, V10, P1737
   Campbell C, 2014, SPRINGER HANDBOOK OF BIO-/NEUROINFORMATICS, P185
   Fromm T., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P490, DOI 10.1109/MFI.2012.6343014
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Guo HS, 2019, ARTIF INTELL REV, V51, P19, DOI 10.1007/s10462-017-9555-5
   Guo HS, 2016, NEUROCOMPUTING, V211, P22, DOI 10.1016/j.neucom.2015.10.136
   Guo HS, 2015, PATTERN RECOGN, V48, P1577, DOI 10.1016/j.patcog.2014.12.009
   Hashemi S, 2009, DATA MIN KNOWL DISC, V19, P95, DOI 10.1007/s10618-009-0130-9
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Lau KW, 2003, PATTERN RECOGN, V36, P1913, DOI 10.1016/S0031-3203(03)00038-4
   Li XA, 2008, EARTH SCI INFORM, V1, P49, DOI 10.1007/s12145-008-0010-7
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Lin YD, 2013, 2013 FIRST INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR), P1, DOI [10.1109/PLASMA.2013.6633230, 10.1109/CANDAR.2013.7]
   Liu Y, 2004, LECT NOTES COMPUT SC, V3331, P304
   Martin M, 2002, LECT NOTES ARTIF INT, V2430, P282
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Núñez M, 2007, J MACH LEARN RES, V8, P2595
   Oregi I, 2019, PATTERN RECOGN, V88, P506, DOI 10.1016/j.patcog.2018.12.007
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Sartakhti JS, 2019, ENG APPL ARTIF INTEL, V85, P402, DOI 10.1016/j.engappai.2019.06.018
   Singh R, 2010, IMAGE VISION COMPUT, V28, P1098, DOI 10.1016/j.imavis.2010.01.009
   Souza RCSNP, 2013, PATTERN RECOGN LETT, V34, P1394, DOI 10.1016/j.patrec.2013.04.023
   Sánchez AS, 2011, MATH COMPUT MODEL, V54, P1453, DOI 10.1016/j.mcm.2011.04.017
   Syed NA, 1999, P 5 ACM SIGKDD INT C, P317, DOI [DOI 10.1145/312129, 10.1145/312129.312267]
   Tüfekci P, 2016, INTELL DATA ANAL, V20, P357, DOI 10.3233/IDA-160809
   Vapnik, 1998, STAT LEARNING THEORY
   Venkatesan R, 2016, NEUROCOMPUTING, V207, P310, DOI 10.1016/j.neucom.2016.05.006
   Wang D, 2013, IEEE T NEUR NET LEAR, V24, P593, DOI 10.1109/TNNLS.2013.2238556
   Wang M, 2008, BIOINFORMATICS, V24, P94, DOI 10.1093/bioinformatics/btm530
   Wang TH, 2018, IEEE T FUZZY SYST, V26, P3703, DOI 10.1109/TFUZZ.2018.2848224
   Wang WJ, 2008, NEUROCOMPUTING, V71, P550, DOI 10.1016/j.neucom.2007.07.020
   Wen FH, 2014, PROCEDIA COMPUT SCI, V31, P625, DOI 10.1016/j.procs.2014.05.309
   Yang XW, 2011, IEEE T FUZZY SYST, V19, P105, DOI 10.1109/TFUZZ.2010.2087382
   Zhou P, 2019, PATTERN RECOGN, V86, P48, DOI 10.1016/j.patcog.2018.08.009
   Zhou XJ, 2016, ADV INTELL SYST, V382, P269, DOI 10.1007/978-3-662-47926-1_26
NR 39
TC 6
Z9 6
U1 1
U2 7
PD JUN
PY 2020
VL 92
AR 103637
DI 10.1016/j.engappai.2020.103637
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Oliveira, GF
   Boroumand, A
   Ghose, S
   Gómez-Luna, J
   Mutlu, O
AF Oliveira, Geraldo F.
   Boroumand, Amirali
   Ghose, Saugata
   Gomez-Luna, Juan
   Mutlu, Onur
GP IEEE
TI Heterogeneous Data-Centric Architectures for Modern Data-Intensive
   Applications: Case Studies in Machine Learning and Databases
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
ID PROCESSING-IN-MEMORY; ACCELERATOR
C1 [Oliveira, Geraldo F.; Gomez-Luna, Juan; Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Boroumand, Amirali] Google, Mountain View, CA USA.
   [Ghose, Saugata] Univ Illinois, Champaign, IL USA.
RP Oliveira, GF (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Alem SAA, 2020, MATER MANUF PROCESS, V35, P303, DOI 10.1080/10426914.2020.1718698
   Alser M., 2020, IEEE MICRO
   Angizi S., 2018, ASP DAC
   Angizi S., 2020, GLSVLSI
   Angizi S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317764
   Angizi S, 2019, PR GR LAK SYMP VLSI, P45, DOI 10.1145/3299874.3317984
   Angizi S, 2019, DES AUT TEST EUROPE, P378, DOI [10.23919/DATE.2019.8715270, 10.23919/date.2019.8715270]
   Arulraj J, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P583, DOI 10.1145/2882903.2915231
   Awan AJ, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P60, DOI 10.1145/3132402.3132427
   Azarkhish Erfan, 2016, Architecture of Computing Systems - ARCS 2016. 29th International Conference. Proceedings: LNCS 9637, P19, DOI 10.1007/978-3-319-30695-7_2
   Babarinsa O, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2069, DOI 10.1145/2723372.2764942
   Barber R., 2019, ARXIV
   Besta M., 2021, MICRO
   Boroumand A., 2020, THESIS CARNEGIE MELL
   Boroumand A., 2021, ARXIV
   Boroumand A., 2022, ICDE
   Boroumand A., 2021, ARXIV
   Boroumand A, 2021, Arxiv, DOI arXiv:2103.00768
   Boroumand A, 2021, INT CONFER PARA, P159, DOI 10.1109/PACT52795.2021.00019
   Boroumand A, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P629, DOI 10.1145/3307650.3322266
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3173162.3173177, 10.1145/3296957.3173177]
   Bostanci F.N., 2022, HPCA
   Cali D. S, 2022, ISCA
   Cali DS, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P951, DOI 10.1109/MICRO50266.2020.00081
   Cao SS, 2019, Arxiv, DOI arXiv:1906.07407
   Cao TC, 2020, 2020 THE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS'2020), P107, DOI [10.1109/ICoIAS49312.2020.9081857, 10.1109/icoias49312.2020.9081857]
   Chang KK, 2016, INT S HIGH PERF COMP, P568, DOI 10.1109/HPCA.2016.7446095
   Chen F, 2020, ASP DAC
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chisholm S., 2014, ANN ROY COLL SURG
   Cho S, 2020, IEEE ACCESS, V8, P135223, DOI 10.1109/ACCESS.2020.3011265
   Chowdhury Z. I., 2020, JXCDC
   Dai GH, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P120, DOI 10.1145/3287624.3287637
   Dai GH, 2019, IEEE T COMPUT AID D, V38, P640, DOI 10.1109/TCAD.2018.2821565
   Das P, 2018, I CONF VLSI DESIGN, P380, DOI 10.1109/VLSID.2018.94
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Denzler A, 2021, Arxiv, DOI arXiv:2112.14216
   Devaux F., 2019, HCS
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Drumond M, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P639, DOI 10.1145/3079856.3080233
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fernandez I, 2020, PR IEEE COMP DESIGN, P120, DOI 10.1109/ICCD50377.2020.00035
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Gartner Research, 2013, HYBR TRANS AN PROC W
   Ghiasi N. M., 2022, ASPLOS
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Ghose S., 2019, BEYOND CMOS TECHNOLO
   Giannoula C, 2021, INT S HIGH PERF COMP, P263, DOI 10.1109/HPCA51647.2021.00031
   Giceva J., 2018, HYBRID OLTP OLAP
   Glova AO, 2019, DES AUT TEST EUROPE, P800, DOI [10.23919/date.2019.8715108, 10.23919/DATE.2019.8715108]
   Gomez-Luna J., 2021, IGSC
   Gomez-Luna J., 2021, ARXIV
   Gomez-Luna J, 2022, IEEE ACCESS
   Google LLC, EDGE TPU
   Gu B, 2016, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA.2016.23
   Gu P, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P347, DOI 10.1145/2902961.2903512
   Gupta S, 2019, I SYMPOS LOW POWER E, DOI 10.1109/irps.2019.8720595
   Hajinazar N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P329, DOI 10.1145/3445814.3446749
   Han L, 2018, ACM T STORAGE, V14, DOI 10.1145/3177916
   Han L, 2017, IEEE NON-VOLATILE ME
   He YZ, 2019, INT CONF ACOUST SPEE, P6381, DOI 10.1109/ICASSP.2019.8682336
   He ZZ, 2020, ACM J EMERG TECH COM, V16, DOI 10.1145/3369391
   Hsieh K, 2016, PR IEEE COMP DESIGN, P25, DOI 10.1109/ICCD.2016.7753257
   Hsieh K, 2016, CONF PROC INT SYMP C, P204, DOI 10.1109/ISCA.2016.27
   Huang DX, 2020, PROC VLDB ENDOW, V13, P3072, DOI 10.14778/3415478.3415535
   Huang L., 2022, IEEE ACCESS
   Huang Y., 2022, HPCA
   Huang Y, 2020, INT PARALL DISTRIB P, P684, DOI 10.1109/IPDPS47924.2020.00076
   Hybrid Memory Cube Consortium, HMC SPECIFICATION 2, P2
   Imani M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P356, DOI 10.1109/MICRO50266.2020.00039
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Imani M, 2019, PR GR LAK SYMP VLSI, P429, DOI 10.1145/3299874.3319483
   Intel Corp, INTEL MOVIDIUS NEURA
   JEDEC Solid State Technology Assn, 2018, JESD235B HIGH BANDWI
   Kaplan R, 2020, SYSTOR
   Ke L., 2021, IEEE MICRO
   Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070
   Kemper A, 2011, PROC INT CONF DATA, P195, DOI 10.1109/ICDE.2011.5767867
   Kepe TR, 2019, PROC VLDB ENDOW, V13, P334, DOI 10.14778/3368289.3368298
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim E., 2020, MEMSYS
   Kim H, 2019, INT S HIGH PERF COMP, P661, DOI 10.1109/HPCA.2019.00017
   Kim J., 2017, PSB
   Kim J., 2016, RECOMB
   Kim JS, 2019, INT S HIGH PERF COMP, P582, DOI 10.1109/HPCA.2019.00011
   Kim JS, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4460-0
   Kim JS, 2018, INT S HIGH PERF COMP, P194, DOI 10.1109/HPCA.2018.00026
   Kwon Y.-C., 2021, ISSCC
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Larson PÅ, 2015, PROC VLDB ENDOW, V8, P1740
   Lee D., 2020, P INT C EXT DAT TECH
   Lee D, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2832911
   Lee S., 2022, ISSCC
   Lee S, 2021, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA52012.2021.00013
   Lekshmi BG, 2021, I C DATA ENGIN WORKS, P54, DOI 10.1109/ICDEW53142.2021.00017
   Li GS, 2018, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS (MEMSYS 2018), P79, DOI 10.1145/3240302.3240312
   Li JY, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P114, DOI [10.1109/asru46091.2019.9003906, 10.1109/ASRU46091.2019.9003906]
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Li SC, 2016, DES AUT CON, DOI [10.1145/2897937.2898064, 10.1109/ICAUMS.2016.8479697]
   Li W, 2019, IEEE VLSI TEST SYMP
   Li XQ, 2021, J COMPUT SCI TECH-CH, V36, P56, DOI 10.1007/s11390-020-0825-3
   Liu H, 2020, IEEE ACCESS, V8, P104445, DOI 10.1109/ACCESS.2020.2989819
   Liu ZY, 2017, PROCEEDINGS OF THE 29TH ACM SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES (SPAA'17), P235, DOI 10.1145/3087556.3087582
   Long Y., 2020, DAC
   Long Y, 2018, IEEE T VLSI SYST, V26, P2781, DOI 10.1109/TVLSI.2018.2819190
   Lu S., 2019, KSEM
   Makreshanski D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P37, DOI 10.1145/3035918.3035959
   Mutlu O., 2015, MORE MOORE TECHNOLOG
   Mutlu O, 2020, INT SYMPOS VLSI DES, DOI 10.1109/vlsi-dat49148.2020.9196490
   Mutlu O, 2022, Arxiv, DOI arXiv:2012.03112
   Mutlu O, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P318, DOI 10.23919/DATE51398.2021.9474073
   Mutlu O, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3323476
   Mutlu O, 2019, PR GR LAK SYMP VLSI, P5, DOI 10.1145/3299874.3322805
   Mutlu Onur, 2014, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V1, P19
   Mutlu O, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P21, DOI 10.1109/IMW.2013.6582088
   Nag A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P334, DOI 10.1145/3352460.3358308
   Nai L., 2015, P 2015 INT S MEM SYS, P258, DOI DOI 10.1145/2818950.2818982
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nejatollahi H., 2020, DAC
   Niu D., 2022, ISSCC
   Nori A. V, 2021, ISCA
   NVIDIA Corp, NVIDIA JETSON NANO
   Olgun A, 2021, CONF PROC INT SYMP C, P944, DOI 10.1109/ISCA52012.2021.00078
   Oliveira G. F., 2017, ARC
   Oliveira G. F., 2022, POLYNESIA ENABLING H
   Oliveira G. F., GOOGLE NEURAL NETWOR
   Oliveira GF, 2022, Arxiv, DOI arXiv:2105.03725
   Oliveira GF, 2021, IEEE ACCESS, V9, P134457, DOI 10.1109/ACCESS.2021.3110993
   Özcan F, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1771, DOI 10.1145/3035918.3054784
   Park J., 2021, MICRO
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qiu XF, 2018, PROC VLDB ENDOW, V11, P1876, DOI 10.14778/3229863.3229874
   Quah JTS, 2008, EXPERT SYST APPL, V35, P1721, DOI 10.1016/j.eswa.2007.08.093
   Rakin A. S, 2018, ICCD
   Ramnarayan J., 2016, CIDR
   Rao KNS, 2018, Arxiv, DOI arXiv:1801.00841
   Reis D., 2020, COMPUTING IN MEMORY
   Resch S, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P400, DOI 10.1109/MICRO50266.2020.00042
   Rezaei S. H. S, 2020, CAL
   SAFARI Research Group, 2022, POLYNESIA GITHUB REP
   Sahay B. S., 2008, Information Management & Computer Security, V16, P28, DOI 10.1108/09685220810862733
   Sak H, 2014, Arxiv, DOI [arXiv:1402.1128, DOI 10.48550/ARXIV.1402.1128]
   Santos PC, 2017, DES AUT TEST EUROPE, P710, DOI 10.23919/DATE.2017.7927081
   Seshadri V., 2013, MICRO
   Seshadri V, 2016, Arxiv, DOI arXiv:1611.09988
   Seshadri V, 2016, Arxiv, DOI arXiv:1610.09603
   Seshadri V, 2020, Arxiv, DOI arXiv:1905.09822
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Seshadri V, 2017, ADV COMPUT, V106, P107, DOI 10.1016/bs.adcom.2017.04.004
   Seshadri V, 2015, IEEE COMPUT ARCHIT L, V14, P127, DOI 10.1109/LCA.2015.2434872
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharma A, 2018, INT CONF MANAGE DATA, P245, DOI 10.1145/3183713.3196904
   Shin H, 2018, IEEE T COMPUT AID D, V37, P2613, DOI 10.1109/TCAD.2018.2857044
   Si X., 2019, ASICON
   Sikka V, 2013, PROC VLDB ENDOW, V6, P1184, DOI 10.14778/2536222.2536251
   Simon WA, 2020, IEEE T COMPUT, V69, P1349, DOI 10.1109/TC.2020.2972528
   Singh G, 2021, IEEE MICRO, V41, P39, DOI 10.1109/MM.2021.3088396
   Singh G, 2020, I C FIELD PROG LOGIC, P9, DOI 10.1109/FPL50879.2020.00014
   Singh G, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317867
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Sun Y., 2018, TOS
   Ta VD, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2016), P37, DOI 10.1109/ICCCBDA.2016.7529531
   Tomé DG, 2018, DES AUT TEST EUROPE, P261, DOI 10.23919/DATE.2018.8342015
   Vermij E, 2017, ICPP
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang F, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P615, DOI 10.1145/3287624.3287656
   Wang YH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P313, DOI 10.1109/MICRO50266.2020.00036
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
   Wu LX, 2021, CONF PROC INT SYMP C, P251, DOI 10.1109/ISCA52012.2021.00028
   Xi S. L., 2015, DAMON
   Xie CH, 2017, INT S HIGH PERF COMP, P637, DOI 10.1109/HPCA.2017.37
   Xie XF, 2021, INT S HIGH PERF COMP, P570, DOI 10.1109/HPCA51647.2021.00055
   Xiong W., 2022, HPCA
   Xu S., 2020, MICRO
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Yuan G., 2021, ISCA
   Zhang F., 2021, DAC
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zheng L, 2020, INT PARALL DISTRIB P, P696, DOI 10.1109/IPDPS47924.2020.00077
   Zhou J, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1693, DOI 10.1145/3097983.3098029
   Zhou M., 2021, PACT
   Zhou MX, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P591, DOI 10.1145/3287624.3287711
   Zhu Z., 2021, ICCAD
   Zhuo Y., 2021, TOCS
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
NR 191
TC 0
Z9 0
U1 0
U2 10
PY 2022
BP 273
EP 278
DI 10.1109/ISVLSI54635.2022.00060
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Park, B
   Hwang, R
   Yoon, D
   Choi, Y
   Rhu, M
AF Park, Beomsik
   Hwang, Ranggi
   Yoon, Dongho
   Choi, Yoonhyuk
   Rhu, Minsoo
GP IEEE Comp Soc
TI DiVa: An Accelerator for Differentially Private Machine Learning
SO 2022 55TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
SE International Symposium on Microarchitecture Proceedings
DT Proceedings Paper
CT 55th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 01-05, 2022
CL Chicago, IL
DE Differential privacy; accelerator; machine learning; deep learning
AB The widespread deployment of machine learning (ML) is raising serious concerns on protecting the privacy of users who contributed to the collection of training data. Differential privacy (DP) is rapidly gaining momentum in the industry as a practical standard for privacy protection. Despite DP's importance, however, little has been explored within the computer systems community regarding the implication of this emerging ML algorithm on system designs. In this work, we conduct a detailed workload characterization on a state-of-the-art differentially private ML training algorithm named DPSGD. We uncover several unique properties of DP-SGD (e.g., its high memory capacity and computation requirements vs. non-private ML), root-causing its key bottlenecks. Based on our analysis, we propose an accelerator for differentially private ML named DiVa, which provides a significant improvement in compute utilization, leading to 2.6x higher energy-efficiency vs. conventional systolic arrays.
C1 [Park, Beomsik; Hwang, Ranggi; Yoon, Dongho; Choi, Yoonhyuk; Rhu, Minsoo] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
RP Park, B (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
EM parkbeomsik@kaist.ac.kr; ranggi.hwang@kaist.ac.kr;
   dongho.yoon@kaist.ac.kr; yoonhyuk.choi@kaist.ac.kr; mrhu@kaist.ac.kr
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Anil R., 2021, ARXIV
   Apple, 2017, LEARN PRIV SCAL
   Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081
   Bannon P., 2019, HOT CHIPS S HIGH PER
   Bassily R, 2014, ANN IEEE SYMP FOUND, P464, DOI 10.1109/FOCS.2014.56
   Blatt M., 2020, P NATL ACAD SCI
   Bradbury J., 2022, JAX COMPOSABLE TRANS
   Brown T., 2020, P INT C NEURAL INFOR
   Carlini N, 2020, PRIVACY CONSIDERATIO
   Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027
   Devlin J., 2018, PREPRINT
   Diethe T., 2020, P INT C WEB SEARCH D
   Dong H., 2018, IEEE T INF FOREN SEC
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Foerster JN, 2016, ADV NEUR IN, V29
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, DOI 10.48550/ARXIV.1704.04861]
   Ghodrati S., 2020, P INT S MICROARCHITE
   Google, 2018, CLOUD TPU
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gross S., 2016, ARXIV
   H. Labs, 2016, CACTI INT CACH MEM A
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hashemi H., 2021, P INT S MICROARCHITE
   Hayes Jamie, 2019, Proceedings on Privacy Enhancing Technologies, V2019, P133, DOI 10.2478/popets-2019-0008
   Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209
   Hoory S., 2021, FINDINGS ASS COMPUTA
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hua W., 2020, ARXIV
   Hussain SU, 2018, DES AUT CON, DOI 10.1145/3195970.3196074
   Hwang R, 2020, ANN I S COM, P968, DOI 10.1109/ISCA45697.2020.00083
   Hyun B, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1109, DOI 10.1145/3373376.3378494
   Jia Y., 2014, LEARNING SEMANTIC IM
   Jouppi N. P., 2021, P INT S COMPUTER ARC
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kalamkar D., 2019, ARXIV
   Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Kim B, 2021, IEEE COMPUT ARCHIT L, V20, P5, DOI 10.1109/LCA.2020.3042805
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kurakin A, 2022, ARXIV
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Kwon Y, 2021, INT S HIGH PERF COMP, P235, DOI 10.1109/HPCA51647.2021.00029
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Kwon Y, 2019, IEEE MICRO, V39, P82, DOI 10.1109/MM.2019.2929165
   Kwon Y, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P148, DOI 10.1109/MICRO.2018.00021
   Kwon Y, 2018, IEEE COMPUT ARCHIT L, V17, P134, DOI 10.1109/LCA.2018.2823302
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J., 2021, P PRIVACY ENHANCING
   Li X., 2022, P INT C LEARNING REP
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Nasr M, 2019, P IEEE S SECUR PRIV, P739, DOI 10.1109/SP.2019.00065
   Norrie T., 2020, HOT CHIPS S HIGH PER
   NVIDIA, 2018, NVIDIA TESL V100
   NVIDIA, 2020, NVIDIA A100
   Openrouteservice, 2020, US
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Papernot N., 2022, TENSORFLOW PRIVACY
   Papernot N., 2016, ARXIV 161005755
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park J., 2021, P INT S MICROARCHITE
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Radford A., 2019, OPENAI BLOG
   Redmon J., 2016, ARXIV160207360, P779
   Rhu M, 2016, INT SYMP MICROARCH
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Ross J., 2015, U. S. Patent, Patent No. [9747546 B2, 9747546]
   Ross J., 2015, U.S. Patent, Patent No. [9747548 B2, 9747548]
   Ross J., 2015, U.S. Patent, Patent No. [9697463 B2, 9697463]
   Ross J., 2015, U. S. Patent, Patent No. [9805304 B2, 9805304]
   Shazeer, 2017, P 5 INT C LEARN REPR
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Shokri R, 2015, ANN ALLERTON CONF, P909, DOI 10.1109/ALLERTON.2015.7447103
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith S., 2022, ARXIV
   Subramani P., 2021, P INT C NEURAL INFOR
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Yu D., 2022, P INT C LEARNING REP
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
NR 93
TC 0
Z9 0
U1 0
U2 2
PY 2022
BP 1200
EP 1217
DI 10.1109/MICRO56248.2022.00084
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Azad, Z
   Sen, R
   Park, K
   Joshi, A
AF Azad, Zahra
   Sen, Rathijit
   Park, Kwanghyun
   Joshi, Ajay
GP IEEE
TI Hardware Acceleration for DBMS Machine Learning Scoring: Is It Worth the
   Overheads?
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE (ISPASS 2021)
SE IEEE International Symposium on Performance Analysis of Systems and
   Software-ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY MAR 28-30, 2021
CL ELECTR NETWORK
AB Query processing for data analytics with machine learning scoring involves executing heterogeneous operations in a pipelined fashion. Hardware acceleration is one approach to improve the pipeline performance and free up processor resources by offloading computations to the accelerators. However, the performance benefits of accelerators can be limited by the compute and data offloading overheads. Although prior works have studied acceleration opportunities, including with accelerators for machine learning operations, an end-to-end application performance analysis has not been well studied, particularly for data analytics and model scoring pipelines.
   In this paper, we study speedups and overheads of using PCIe-based hardware accelerators in such pipelines. In particular, we analyze the effectiveness of using GPUs and FPGAs to accelerate scoring for random forest, a popular machine learning model, on tabular input data obtained from Microsoft SQL Server. We observe that the offloading decision as well as the choice of the optimal hardware backend should depend at least on the model complexity (e.g., number of features and tree depth), the scoring data size, and the overheads associated with data movement and invocation of the pipeline stages. We also highlight potential future research explorations based on our findings.
C1 [Azad, Zahra; Joshi, Ajay] Boston Univ, Boston, MA 02215 USA.
   [Sen, Rathijit; Park, Kwanghyun] Microsoft Gray Syst Lab, Redmond, WA USA.
RP Azad, Z (corresponding author), Boston Univ, Boston, MA 02215 USA.
EM zazad@bu.edu; rathijit.sen@microsoft.com; kwanghyun.park@microsoft.com;
   joshi@bu.edu
CR Agrawal A., 2020, P C INN DAT SYST RES
   Alonso G., 2019, IEEE DATA ENG B, V42, P19
   Amato F, 2014, STUD COMPUT INTELL, V511, P289, DOI 10.1007/978-3-319-01571-2_34
   [Anonymous], SKLEARN ONNX CONVERT
   Asadi N, 2014, IEEE T KNOWL DATA EN, V26, P2281, DOI 10.1109/TKDE.2013.73
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Bin Altaf MS, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P375, DOI [10.1145/3079856.3080216, 10.1145/3140659.3080216]
   Browne James, 2019, P 2019 SIAM INT C DA, P46, DOI [DOI 10.1137/1.9781611975673.6, 10.1137/1.9781611975673.6]
   Caulfield AM, 2016, INT SYMP MICROARCH
   Chiou D, 2017, I S WORKL CHAR PROC, P124, DOI 10.1109/IISWC.2017.8167769
   Dheeru D., 2017, UCI MACHINE LEARNING
   Elkanishy A, 2019, IEEE HIGH PERF EXTR
   Eryilmaz Z. F., 2021, INT C DAT ENG ICDE
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karanasos K., 2020, P C INN DAT SYST RES
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kune R, 2016, SOFTWARE PRACT EXPER, V46, P79, DOI 10.1002/spe.2374
   Mahajan D, 2018, PROC VLDB ENDOW, V11, P1317, DOI 10.14778/3236187.3236188
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   McKinney W., 2010, P 9 PYTH SCI C, VVol. 445, P51
   Nakandala S., TAMING MODEL SERVING
   Nakandala S., 2020, 14 USENIX S OP SYST
   Oberg J., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P330, DOI 10.1109/FPL.2012.6339226
   Owaida M, 2019, PROC VLDB ENDOW, V13, P71, DOI 10.14778/3357377.3357383
   Owaida M, 2017, I C FIELD PROG LOGIC
   Owaida M, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3340263
   Psallidas Fotis, 2019, DATA SCI LOOKING GLA
   Qu YR, 2014, IEEE HIGH PERF EXTR
   Raschka S, 2020, INFORMATION, V11, DOI 10.3390/info11040193
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Richins D., ARXIV PREPRINT ARXIV
   Sidler D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1659, DOI 10.1145/3035918.3058746
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Zedlewski, 2019, RAPIDS FOREST INFERE
NR 37
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 243
EP 253
DI 10.1109/ISPASS51385.2021.00047
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Kachris, C
   Soudris, D
   Mavridis, S
   Pavlidakis, M
   Symeonidou, C
   Kozanitis, C
   Bilas, A
   Fenacci, D
   Bogaraju, SV
   Vandierendonck, H
   Nikolopoulos, DS
AF Kachris, Christoforos
   Soudris, Dimitrios
   Mavridis, Stelios
   Pavlidakis, Manolis
   Symeonidou, Christi
   Kozanitis, Christos
   Bilas, Angelos
   Fenacci, Damon
   Bogaraju, Sharatchandra Varma
   Vandierendonck, Hans
   Nikolopoulos, Dimitrios S.
GP Assoc Comp Machinery
TI The VINEYARD integrated framework for hardware accelerators in the cloud
SO 2018 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS:
   ARCHITECTURES, MODELING, AND SIMULATION (SAMOS XVIII)
DT Proceedings Paper
CT 18th International Conference on Embedded Computer Systems -
   Architectures, Modeling, and Simulation (SAMOS)
CY JUL 15-19, 2018
CL Pythagorion, GREECE
DE reconfigurable computing; hardware accelerators; FPGAs; machine
   learning; cloud computing
AB Emerging cloud applications like machine learning, AI and big data analytics required high performance computing systems that can sustain the increased amount of data processing without consuming excessive power. Towards this end, many cloud operators have started deploying hardware accelerators, like FPGAs, to increase the performance of computational intensive tasks but increasing the programming complexity to utilize these accelerators. VINEYARD has developed an efficient framework that allows the seamless deployment and utilization of hardware accelerators in the cloud without increasing the programming complexity and offering the flexibility of software packages. This paper presents the main components that have been developed in this framework such as the runtime system, the virtualization and the central acceleratorsaAZ repository. The proposed platform has been demonstrated into 2 real use cases; neurocomputing applications and machine learning algorithms. The performance evaluation shows that the proposed scheme can achieve up to 25x speedup without increasing the programming complexity of these applications and it also demonstrates how it can be used for large suite of applications.
C1 [Kachris, Christoforos; Soudris, Dimitrios] ICCS, Athens, Greece.
   [Mavridis, Stelios; Pavlidakis, Manolis; Symeonidou, Christi; Kozanitis, Christos; Bilas, Angelos] Fdn Res & Technol Hellas FORTH, ICS, Patras, Greece.
   [Fenacci, Damon; Bogaraju, Sharatchandra Varma; Vandierendonck, Hans; Nikolopoulos, Dimitrios S.] Queens Univ Belfast, Belfast, Antrim, North Ireland.
RP Kachris, C (corresponding author), ICCS, Athens, Greece.
EM kachris@microlab.ntua.gr
CR [Anonymous], UNDERSTANDING PERFOR
   [Anonymous], CONCURRENCY COMPUTAT
   [Anonymous], 2013, ACM QUEUE, DOI DOI 10.1145/2436696.2443836
   [Anonymous], 2015, CORR
   [Anonymous], 2016, TECHNICAL REPORT
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chatzikonstantis George, 2017, High Performance Computing. ISC High Performance 2017 International Workshops DRBSD, ExaComm, HCPM, HPC-IODC, IWOPH, IXPUG, P^3MA, VHPC, Visualization at Scale, WOPSSS. Revised Selected Papers: LNCS 10524, P363, DOI 10.1007/978-3-319-67630-2_27
   Chen YT, 2016, ANN IEEE SYM FIELD P, P29, DOI 10.1109/FCCM.2016.18
   Cong J, 2016, DES AUT CON, DOI 10.1145/2897937.2905012
   Huang MH, 2016, PROCEEDINGS OF THE SEVENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC 2016), P456, DOI 10.1145/2987550.2987569
   Kachris Christoforos, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P673, DOI 10.1007/978-3-319-78890-6_54
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Mavridis S, 2017, I C FIELD PROG LOGIC
   Segal O, 2015, IEEE HIGH PERF EXTR
   Segal Oren, 2014, FIELD PROGR LOG APPL, P1, DOI [10.1109/FPL.2014.6927442, DOI 10.1109/FPL.2014.6927442]
   Smaragdos G, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7fc5
   Stamoulias I, 2017, INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION (SAMOS 2017), P278, DOI 10.1109/SAMOS.2017.8344641
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Windh S, 2015, P IEEE, V103, P390, DOI 10.1109/JPROC.2015.2399275
NR 19
TC 0
Z9 0
U1 1
U2 2
PY 2018
BP 236
EP 243
DI 10.1145/3229631.3236093
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Blott, M
   Vasilciuc, A
   Leeser, M
   Doyle, L
AF Blott, Michaela
   Vasilciuc, Alina
   Leeser, Miriam
   Doyle, Linda
TI Evaluating Theoretical Baselines for ML Benchmarking Across Different
   Accelerators
SO IEEE DESIGN & TEST
DT Editorial Material
DE Machine learning; Optimization; Benchmark testing; Micromechanical
   devices; Predictive models; Performance evaluation; Deep Learning;
   Neural Nets; FPGA; GPU; Benchmarking
ID ROOFLINE; MODEL
AB Y
C1 [Blott, Michaela; Vasilciuc, Alina] Xilinx Res, Dublin D24 T683, Ireland.
   [Leeser, Miriam] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
   [Doyle, Linda] Univ Dublin, Trinity Coll Dublin, Dublin D02 PN40, Ireland.
RP Blott, M (corresponding author), Xilinx Res, Dublin D24 T683, Ireland.
EM mblott@xilinx.com; mel@ece.neu.edu
CR [Anonymous], 2020, QUTIBENCH BENCHMARKI
   Banbury Colby R., 2020, ARXIV200304821
   Blott M, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3358700
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Doerfler D, 2016, LECT NOTES COMPUT SC, V9945, P339, DOI 10.1007/978-3-319-46079-6_24
   Han S., 2015, ARXIV151000149
   Hill MD, 2019, INT S HIGH PERF COMP, P317, DOI 10.1109/HPCA.2019.00047
   Ilic A, 2014, IEEE COMPUT ARCHIT L, V13, P21, DOI 10.1109/L-CA.2013.6
   Reddi, 2019, ARXIV191102549
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
NR 11
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2022
VL 39
IS 3
BP 28
EP 36
DI 10.1109/MDAT.2021.3063340
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Reuther, A
   Michaleas, P
   Jones, M
   Gadepally, V
   Samsi, S
   Kepner, J
AF Reuther, Albert
   Michaleas, Peter
   Jones, Michael
   Gadepally, Vijay
   Samsi, Siddharth
   Kepner, Jeremy
GP IEEE
TI AI Accelerator Survey and Trends
SO 2021 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 20-24, 2021
CL ELECTR NETWORK
DE Machine learning; GPU; TPU; dataflow; accelerator; embedded inference;
   computational performance
ID NEURAL-NETWORKS; ARCHITECTURES; HARDWARE
AB Over the past several years, new machine learning accelerators were being announced and released every month for a variety of applications from speech recognition, video object detection, assisted driving, and many data center applications. This paper updates the survey of AI accelerators and processors from past two years. This paper collects and summarizes the current commercial accelerators that have been publicly announced with peak performance and power consumption numbers. The performance and power values are plotted on a scatter graph, and a number of dimensions and observations from the trends on this plot are again discussed and analyzed. This year, we also compile a list of benchmarking performance results and compute the computational efficiency with respect to peak performance.
C1 [Reuther, Albert; Michaleas, Peter; Jones, Michael; Gadepally, Vijay; Samsi, Siddharth; Kepner, Jeremy] MIT, Lincoln Lab, Supercomp Ctr, 244 Wood St, Lexington, MA 02173 USA.
RP Reuther, A (corresponding author), MIT, Lincoln Lab, Supercomp Ctr, 244 Wood St, Lexington, MA 02173 USA.
EM reuther@ll.mit.edu; pmichaleas@ll.mit.edu; michael.jones@ll.mit.edu;
   vijayg@ll.mit.edu; sid@ll.mit.edu; kepner@ll.mit.edu
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Albanie S., 2019, CONVNET BURDEN
   Alcorn P., 2017, NVIDIA INFUSES DGX 1
   [Anonymous], 2020, DELL DSS8440 GRAPHC
   [Anonymous], 2020, INTEL XEON PLATINUM
   [Anonymous], 2018, AIWARE3 HARDWARE IP
   [Anonymous], 2019, NVIDIA TESLA V100 TE
   [Anonymous], 2020, FSD CHIP TESLA
   [Anonymous], 2021, TDA4VM JAC PROC ADAS
   [Anonymous], 2019, EDGE TPU
   [Anonymous], 2020, SOLIDRUN GYRFALCON D
   [Anonymous], 2018, ROCKCHIP RELEASED IT
   [Anonymous], 2019, CORNAMI ACHIEVES UNP
   [Anonymous], 2020, MN CORE
   [Anonymous], 2016, ARXIV161001832
   [Anonymous], 2020, GAP APPL PROCESSORS
   [Anonymous], 2018, EETIMES NOV
   [Anonymous], 2020, HORIZON ROBOTICS JOU
   Campa C., 2020, DEFINING INNOVATION
   Canziani A., 2016, ARXIV
   Chen Y., 2018, CONF PROC INT SYMP C, P1, DOI DOI 10.1109/MM.2017.265085944
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Clarke P., 2020, NXP KALRAY DEMO COOL
   Clarke P, 2018, INDO US STARTUP PREP
   Clarke P, 2019, GLOBALFOUNDRIES AIDS
   Cutress I., 2019, PREFERRED NETWORKS 5
   Cutress I., 2018, CAMBRICON MAKER HAUW
   Cutress I, 2018, NVIDIAS DGX 2 16 TES
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   De Gelas J, 2019, INTELS XEON CASCADE
   Demler M., 2020, TI JACINTO ACCELERAT
   Demler M., 2020, BLAIZE IGNITES EDGE
   Duckett C, 2018, BAIDU CREATES KUNLUN
   Dupont de Dinechin B., 2019, 17 IEEE INT NEW CIRC
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Evangelist C., 2020, DEEP DIVE AMAZON INF
   Exxactcorp, 2017, TAK DEEP LOOK AMD RA
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Feldman M., 2016, IBM FINDS KILLER APP
   Fick D., 2018, MYTHIC HOT CHIPS 201
   Firu D, 2019, QUADRIC EDGE SUPERCO
   Franklin, 2017, NVIDIA JETSON TX2 DE
   Freund K., 2019, MOOR INSIGHTS STRATE
   Gadepally V., 2019, AI ENABLING TECHNOLO
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gwennap L., 2020, UNTETHER DELIVERS AT
   Gwennap L, 2019, HABANA WINS CIGAR AI
   Gwennap L, 2019, KENDRYTE EMBEDS AI S
   Gwennap L., 2019, CENTAUR ADDS AI SERV
   Gwennap Linley, 2020, MICROPROCESSOR REPOR
   Hamilton J, 2018, AWS INFERENTIA MACHI
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harmon W., 2019, NVIDIA TESLA T4 AI I
   Hemsoth N, 2018, INTEL FPGA ARCHITECT
   Hemsoth N, 2020, GROQ SHARES RECIPE T
   Hemsoth N, 2018, MYTHIC APPROACH DEEP
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Henry G, 2020, ANN I S COM, P15, DOI 10.1109/ISCA45697.2020.00013
   Hock A, 2019, INTRO CEREBRAS CS 1
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hruska J, 2017, NEW MOVIDIUS MYRIAD
   Huawei, 2020, ASC 910 AI PROC
   Huawei, 2020, ASC 310 AI PROC
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2018, COMMUN ACM, V61, P50, DOI 10.1145/3154484
   Khan Saif, 2020, AI CHIPS WHAT THEY A
   Kilgariff E., 2018, NVIDIA TURING ARCHIT
   Krashinsky Ronny., 2020, NVIDIA AMPERE ARCHIT
   Krewell K., 2020, VIRTUAL C DELIVERS R
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lacey D, 2017, PRELIMINARY IPU BENC
   Langroudi HF, 2019, PROC SPIE, V11139, DOI 10.1117/12.2529407
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Leiserson CE, 2020, SCIENCE, V368, P1079, DOI 10.1126/science.aam9744
   Liao, 2001, NEURAL NETWORKS HARD
   LINDSEY CS, 1995, P SOC PHOTO-OPT INS, V2492, P1194, DOI 10.1117/12.205116
   Lunden I, 2020, GRAPHCORE UNVEILS NE
   McGrath D, 2018, TECH HEAVYWEIGHTS BA
   McGrath D, 2019, QUALCOMM TARGETS AI
   McGregor J., 2020, PERCEIVE EXITS STEAL
   Medina E, 2020, IEEE MICRO, V40, P17, DOI 10.1109/MM.2020.2975185
   Mehta V., 2020, LINL SPRING PROC C
   Merritt R., 2019, STARTUP ACCELERATES
   Merritt R, 2018, BAIDU ACCELERATOR RI
   Merritt R, 2018, STARTUP ROLLS AI CHI
   Merritt R., 2019, SAMSUNG TOSHIBA DETA
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Morgan T. P., 2017, DRILLING MICROSOFTS
   Morgan T. P., 2021, NVIDIA ROUNDS OUT AM
   Olofsson A, 2014, CONF REC ASILOMAR C, P1719, DOI 10.1109/ACSSC.2014.7094761
   Ouyang J, 2021, ISSCC DIG TECH PAP I, V64, P50, DOI 10.1109/ISSCC42613.2021.9366056
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Peng T, 2019, ALIBABAS NEW AI CHIP
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Roos G, 2019, FPGA ACCELERATION CA
   Rueckert U., 2020, NANOCHIPS 2030 ON CH, P181
   Russell J., 2021, LATEST MLPERF RESULT
   Schor D, 2020, ARM ETHOS IS UBIQUIT
   Schor D, 2017, 2048 CORE PEZY SC2 S
   Smith R, 2018, AMD ANNOUNCES RADEON
   Smith R., 2019, NVIDIA GIVES JETSON
   Smith R, 2018, 16GB NVIDIA TESLA V1
   Sze V., 2020, EFFICIENT PROCESSING
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Teich P., 2018, TEARING APART GOOGLE
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Thompson NC, 2021, COMMUN ACM, V64, P64, DOI 10.1145/3430936
   Toon N, 2020, INTRO 2 GENERATION I
   Trader T., 2021, CEREBRAS DOUBLES AI
   Turley J, 2020, GAP9 ML EDGE EEJOURN
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Ward-Foxton S, 2019, DETAILS HAILO AI EDG
   Ward-Foxton S., 2020, SAMBANOVA EMERGES ST
   Ward-Foxton S., 2020, KNERONS NEXT GEN EDG
   Ward-Foxton S., 2020, XMOS ADAPTS XCORE AI
   Ward-Foxton S, 2021, KNERON ATTRACTS STRA
   Ward-Foxton S., 2021, MYTHIC RESIZES ITS A
   Ward-Foxton S, 2019, GYRFALCON UNVEILS 4
   Ward-Foxton S., 2020, INTEL BENCHMARKS NEU
   Ward-Foxton S, 2020, QUALCOMM CLOUD AI 10
   Ward-Foxton S., 2021, TIS 1 AUTOMOTIVE SOC
   Wheeler B, 2019, BITMAIN SOC BRINGS A
   Wheeler B., 2021, ENFLAME STOKES AI AC
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wu Y, 2018, CHINESE AI CHIP MAKE
   Yoshida J, 2018, NOVUMINDS AI CHIP SP
NR 134
TC 32
Z9 33
U1 1
U2 5
PY 2021
DI 10.1109/HPEC49654.2021.9622867
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Teittinen, J
   Hiienkari, M
   Zliobaite, I
   Hollmen, J
   Berg, H
   Heiskala, J
   Viitanen, T
   Simonsson, J
   Koskinen, L
AF Teittinen, Jukka
   Hiienkari, Markus
   Zliobaite, Indre
   Hollmen, Jaakko
   Berg, Heikki
   Heiskala, Juha
   Viitanen, Timo
   Simonsson, Jesse
   Koskinen, Lauri
TI A 5.3 pJ/op approximate TTA VLIW tailored for machine learning
SO MICROELECTRONICS JOURNAL
DT Article
DE Integrated circuit; Processor; Approximate computing; Minimum energy
   point; Machine learning; Timing error detection
AB To achieve energy efficiency in the Internet-of-Things (IoT), more intelligence is required in the wireless IoT nodes. Otherwise, the energy required by the wireless communication of raw sensor data will prohibit battery lifetime, the backbone of IoT. One option to achive this intelligence is to implement a variety of machine learning algorithms on the IoT sensor instead of the cloud. Shown here is sub-milliwatt machine learning accelerator operating at the Ultra-Low Voltage Minimum-Energy Point. The accelerator is a Transport Triggered Architecture (TTA) Application-Specific Instruction-Set Processor (ASIP) targeted for running various Machine Learning algorithms. The ASIP is implemented in 28 arts FDSOI (Fully Depleted Silicon On Insulator) CMOS process, with an operating voltage of 0.35 V, and is capable of 5.3pJ/cycle and 1.8nJ/iteration when performing conventional machine learning algorithms. The ASIP also includes hardware and compiler support for approximate computing. With the machine learning algorithms, computing approximately brings a maximum of 4.7% energy savings.
C1 [Teittinen, Jukka; Hiienkari, Markus; Simonsson, Jesse; Koskinen, Lauri] Univ Turku, Technol Res Ctr, Turku, Finland.
   [Zliobaite, Indre; Hollmen, Jaakko] Aalto Univ, Dept Informat & Comp Sci, Espoo, Finland.
   [Berg, Heikki; Heiskala, Juha] Nokia Technol, Oulu, Finland.
   [Viitanen, Timo] Tampere Univ Technol, Tampere, Finland.
RP Teittinen, J (corresponding author), Univ Turku, Technol Res Ctr, Turku, Finland.
EM jukka.teittinen@utu.fi
CR [Anonymous], 1997, MICROPROCESSOR ARCHI
   [Anonymous], 2005, SUBTHRESHOLD DESIGN
   Blaauw David, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P400, DOI 10.1109/ISSCC.2008.4523226
   Bull D, 2011, IEEE J SOLID-ST CIRC, V46, P18, DOI 10.1109/JSSC.2010.2079410
   Chen G, 2011, IEEE INT SYMP CIRC S, P57
   Esko O., 2010, Proceedings 2010 International Conference on Field Programmable Logic and Applications (FPL 2010), P217, DOI 10.1109/FPL.2010.51
   Faiedh H, 2001, INT C MICROELECTRON, P189
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Hiienkari M., 2014, P CICC SEPT, P1
   Hoogerbrugge J., 1994, Proceedings of the 27th Annual International Symposium on Microarchitecture. MICRO 27, P191
   Kim EP, 2015, IEEE T VLSI SYST, V23, P598, DOI 10.1109/TVLSI.2014.2311318
   Kultala H, 2013, INT WIREL COMMUN, P1095, DOI 10.1109/IWCMC.2013.6583710
   LICHMAN M., 2013, UCI MACHINE LEARNING
   MacQueen J., 1967, P 5 BERK S MATH STAT, V14, P281
   Makipaa Jani, 2012, Journal of Low Power Electronics and Applications, V2, P180, DOI 10.3390/jlpea2020180
   Moreau T, 2015, IEEE PERVAS COMPUT, V14, P9, DOI 10.1109/MPRV.2015.25
   Scharf L., 1990, STAT SIGNAL PROCESSI
   Shoaib M, 2014, IEEE T CIRCUITS-I, V61, P1105, DOI 10.1109/TCSI.2013.2285912
   Turnquist Matthew, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC320, DOI 10.1109/VLSIC.2015.7231307
   Venkataramani S, 2015, DES AUT CON, DOI 10.1145/2744769.2744904
   Whatmough P., 2013, P IEEE INT SOL STAT, P428
   Whatmough PN, 2013, IEEE T VLSI SYST, V21, P989, DOI 10.1109/TVLSI.2012.2202930
   Wilson R, 2014, ISSCC DIG TECH PAP I, V57, P452, DOI 10.1109/ISSCC.2014.6757509
   Zliobaite I, 2014, SIGMOD REC, V43, P15, DOI 10.1145/2737817.2737821
NR 24
TC 4
Z9 4
U1 0
U2 5
PD MAR
PY 2017
VL 61
BP 106
EP 113
DI 10.1016/j.mejo.2017.01.007
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Kim, JK
   Knag, P
   Chen, T
   Liu, C
   Lee, CE
   Zhang, ZY
AF Kim, Jung Kuk
   Knag, Phil
   Chen, Thomas
   Liu, Chester
   Lee, Ching-En
   Zhang, Zhengya
GP IEEE
TI High-Performance Spiking Neural Net Accelerators for Embedded Computer
   Vision Applications
SO 2017 IEEE SOI-3D-SUBTHRESHOLD MICROELECTRONICS TECHNOLOGY UNIFIED
   CONFERENCE (S3S)
SE IEEE SOI-3D-Subthreshold Microelectronics Technology Unified Conference
DT Proceedings Paper
CT IEEE SOI-3D-Subthreshold Microelectronics Technology Unified Conference
   (S3S)
CY OCT 16-19, 2017
CL Burlingame, CA
AB One key component in computer vision algorithms involves developing and identifying relevant features from raw data. In this work, we designed spiking recurrent neural net accelerators to implement a class of unsupervised machine learning algorithms known as sparse coding. The accelerators perform fast unsupervised learning of features, and extract sparse representations of inputs for low-power classification. Taking advantage of high sparsity, spiking neurons, and error tolerance, the compact accelerator chips are capable of processing images at several hundred megapixels per second, while dissipating less than 10 mW. The accelerators can be embedded in sensors as frontend processors for feature learning, encoding, and compression.
C1 [Kim, Jung Kuk; Knag, Phil; Chen, Thomas; Liu, Chester; Lee, Ching-En; Zhang, Zhengya] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
RP Kim, JK (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
CR Kim J. K., 2014, P S VLSI CIRC, P61
   Kim J. K., 2015, P S VLSI CIRC VLSI C, P50
   Knag P, 2015, IEEE J SOLID-ST CIRC, V50, P1070, DOI 10.1109/JSSC.2014.2386892
   Lee C.-E., 2017, IEEE S VLSI CIRC AUG, P226
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Rozell CJ, 2008, NEURAL COMPUT, V20, P2526, DOI 10.1162/neco.2008.03-07-486
   Zylberberg J, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002250
NR 7
TC 1
Z9 1
U1 0
U2 1
PY 2017
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Gentile, U
   Serio, L
AF Gentile, Ugo
   Serio, Luigi
BE Bardis, N
TI A Machine-learning based methodology for performance analysis in
   particles accelerator facilities
SO 2017 EUROPEAN CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
   (EECS)
DT Proceedings Paper
CT European Conference on Electrical Engineering and Computer Science
   (EECS)
CY NOV 17-19, 2017
CL Bern, SWITZERLAND
DE machine-learning; data mining; big data; particles accelerators
AB CERNs Accelerators facilities require adequate tools to operate, maintain and guide the consolidation of the machines, to fulfil the physics program and deliver the required luminosity for the experiments. It is therefore relevant to identify clear and easy metrics to monitor objectively the activities and guide the management to implement strategies, to improve performances, optimize costs as well as highlight key areas needing prioritization. Model-based is usually adopted to provide an early identification of failures and to reveal among several subsystems hidden dependencies. However system models are complex and require to be constantly updated to be reactive to system changes. Moreover, the availability of economic, high-efficient and smart sensors entails a growing data that, for volume and heterogeneity, are often difficult to analyse and to incorporate within the modelling process. The paper focuses on a novel approach which combines model-based and big data analytics principles. This involves machine learning techniques exploited to extract descriptive and predictive models directly from data, to foresee and react in time to the failures and reducing the downtimes of the machines which operate the largest particles accelerators complex of the world.
C1 [Gentile, Ugo; Serio, Luigi] CERN, Dept Engn, CH-1211 Geneva 23, Switzerland.
RP Gentile, U (corresponding author), CERN, Dept Engn, CH-1211 Geneva 23, Switzerland.
EM ugo.gentile@cern.ch; luigi.serio@cern.ch
CR Bernardi S., 2013, DEPENDABILITY ANAL T
   Bishop CM, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2012.0222
   Challagulla V. U., 2007, COMP SOFTW APPL C CO
   Chigurupati A., 2016, RELIABILITY MAINTAIN
   De Mauro A., 2016, LIB REV, V65
   Gentile U., 2016, INT J GRID UTILITY C, V7
   Iyer A. P., 2016, ARXIV160504652
   Khan  N., 2014, BIG DATA SURVEY TECH
   Ouyang M., 2014, RELIABILITY ENG SYST
   Ozisikyilmaz B., 2008, PAR PROC 37 INT C IE
   Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3
   Rinaldi Steven M, 2001, IEEE CONTROL SYSTEMS, V21, P6
   Rosato V., 2008, INT J CRITICAL INFRA, V4
   Viola N., 2012, SYSTEMS ENG PRACTICE
   Webb G. I., 2001, USER MODELING USERAD
NR 15
TC 2
Z9 2
U1 0
U2 1
PY 2017
BP 90
EP 95
DI 10.1109/EECS.2017.26
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Tian, SQ
   Moini, S
   Holcomb, D
   Tessier, R
   Szefer, J
AF Tian, Shanquan
   Moini, Shayan
   Holcomb, Daniel
   Tessier, Russell
   Szefer, Jakub
BE IEEE
TI A Practical Remote Power Attack on Machine Learning Accelerators in
   Cloud FPGAs
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE Cloud FPGA; FPGA Security; Hardware Accelerators; High-Level Synthesis;
   Machine Learning Security; Vitis
AB The security and performance of FPGA-based accelerators play vital roles in today's cloud services. In addition to supporting convenient access to high-end FPGAs, cloud vendors and third-party developers now provide numerous FPGA accelerators for machine learning models. However, the security of accelerators developed for state-of-the-art Cloud FPGA environments has not been fully explored, since most remote accelerator attacks have been prototyped on local FPGA boards in lab settings, rather than in Cloud FPGA environments. To address existing research gaps, this work analyzes three existing machine learning accelerators developed in Xilinx Vitis to assess the potential threats of power attacks on accelerators in Amazon Web Services (AWS) F1 Cloud FPGA platforms, in a multi-tenant setting. The experiments show that malicious co-tenants in a multi-tenant environment can instantiate voltage sensing circuits as register-transfer level (RTL) kernels within the Vitis design environment to spy on co-tenant modules. A methodology for launching a practical remote power attack on Cloud FPGAs is also presented, which uses an enhanced time-to-digital (TDC) based voltage sensor and auto-triggered mechanism. The TDC is used to capture power signatures, which are then used to identify power consumption spikes and observe activity patterns involving the FPGA shell, DRAM on the FPGA board, or the other co-tenant victim's accelerators. Voltage change patterns related to shell use and accelerators are then used to create an auto-triggered attack that can automatically detect when to capture voltage traces without the need for a hard-wired synchronization signal between victim and attacker. To address the novel threats presented in this work, this paper also discusses defenses that could be leveraged to secure multi-tenant Cloud FPGAs from power-based attacks.
C1 [Tian, Shanquan; Szefer, Jakub] Yale Univ, New Haven, CT 06511 USA.
   [Moini, Shayan; Holcomb, Daniel; Tessier, Russell] Univ Massachusetts, Amherst, MA 01003 USA.
RP Tian, SQ (corresponding author), Yale Univ, New Haven, CT 06511 USA.
EM shanquan.tian@yale.edu; smoini@umass.edu; dholcomb@umass.edu;
   tessier@umass.edu; jakub.szefer@yale.edu
CR Alibaba Cloud, 2019, EL COMP SERV INST TY
   Amazon Web Services, AM EC2 F1 INST
   Amazon Web Services, AWS POW F1 INS
   Amazon Web Services, 2022, AWS FPGA CUST LOG PO
   Amazon Web Services, 2019, OFF REP AWS EC2 FPGA
   Amazon Web Services, 2022, AWS SHELL INT SPEC
   Boutros A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P103, DOI 10.1109/ICFPT51103.2020.00023
   Giechaskiel I, 2019, I C FIELD PROG LOGIC, P45, DOI 10.1109/FPL.2019.00017
   Giechaskil I, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3322483
   Glamocanin O, 2020, DES AUT TEST EUROPE, P1007, DOI 10.23919/DATE48585.2020.9116481
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   István Z, 2018, I C FIELD PROG LOGIC, P119, DOI 10.1109/FPL.2018.00029
   Jagielski M, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1345
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Knodel O., 2018, INT J ADV SYSTEMS ME, V11, P230
   Krautter J, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942094
   La T., 2021, IACR T CRYPTOGRAPHIC, P441
   La TM, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3402937
   Microsoft Research, 2021, PROJ CAT
   Moini S, 2021, IEEE J EM SEL TOP C, V11, P357, DOI 10.1109/JETCAS.2021.3074608
   Moreau T, 2019, Arxiv, DOI arXiv:1807.04188
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Rakin A. S., 2021, USENIX SECURITY C
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Tian SQ, 2021, ANN IEEE SYM FIELD P, P242, DOI 10.1109/FCCM51124.2021.00037
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Xilinx Vitis, 2020, VIT EX VECT ADD
   Xilinx Vitis, 2020, VIT EX SYST ARR
   Zhang YC, 2021, IEEE T INF FOREN SEC, V16, P4377, DOI 10.1109/TIFS.2021.3106169
NR 30
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT J
AU Wang, C
   Gong, L
   Yu, Q
   Li, X
   Xie, Y
   Zhou, XH
AF Wang, Chao
   Gong, Lei
   Yu, Qi
   Li, Xi
   Xie, Yuan
   Zhou, Xuehai
TI DLAU: A Scalable Deep Learning Accelerator Unit on FPGA
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Deep learning; field-programmable gate array (FPGA); hardware
   accelerator; neural network
AB As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. However, the size of the networks becomes increasingly large scale due to the demands of the practical applications, which poses significant challenge to construct a high performance implementations of deep learning neural networks. In order to improve the performance as well as to maintain the low power cost, in this paper we design deep learning accelerator unit (DLAU), which is a scalable accelerator architecture for large-scale deep learning networks using field-programmable gate array (FPGA) as the hardware prototype. The DLAU accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications. Experimental results on the state-of-the-art Xilinx FPGA board demonstrate that the DLAU accelerator is able to achieve up to 36.1x speedup comparing to the Intel Core2 processors, with the power consumption at 234 mW.
C1 [Wang, Chao; Gong, Lei; Yu, Qi; Li, Xi; Zhou, Xuehai] Univ Sci & Technol China, Hefei 230027, Peoples R China.
   [Xie, Yuan] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
RP Wang, C (corresponding author), Univ Sci & Technol China, Hefei 230027, Peoples R China.
EM cswang@ustc.edu.cn; sa514002@mail.ustc.edu.cn; yuiq@mail.ustc.edu.cn;
   llxx@ustc.edu.cn; yuanxie@ece.ucsb.edu; xhzhou@ustc.edu.cn
CR [Anonymous], 2009, P ACMSIGDA INT S FIE
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Qiu J., 2016, I C FIELD PROG LOGIC
   Thibodeau P., DATA CTR NEW POLLUTE
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 9
TC 226
Z9 242
U1 6
U2 180
PD MAR
PY 2017
VL 36
IS 3
BP 513
EP 517
DI 10.1109/TCAD.2016.2587683
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ramadurgam, S
   Perera, DG
AF Ramadurgam, Srikanth
   Perera, Darshika G.
TI An Efficient FPGA-Based Hardware Accelerator for Convex
   Optimization-Based SVM Classifier for Machine Learning on Embedded
   Platforms
SO ELECTRONICS
DT Article
DE FPGAs; hardware accelerators; embedded architectures; machine learning;
   convex optimization; Support Vector Machines
ID SUPPORT VECTOR MACHINES; PARALLEL IMPLEMENTATION; ARCHITECTURES;
   ALGORITHM
AB Machine learning is becoming the cornerstones of smart and autonomous systems. Machine learning algorithms can be categorized into supervised learning (classification) and unsupervised learning (clustering). Among many classification algorithms, the Support Vector Machine (SVM) classifier is one of the most commonly used machine learning algorithms. By incorporating convex optimization techniques into the SVM classifier, we can further enhance the accuracy and classification process of the SVM by finding the optimal solution. Many machine learning algorithms, including SVM classification, are compute-intensive and data-intensive, requiring significant processing power. Furthermore, many machine learning algorithms have found their way into portable and embedded devices, which have stringent requirements. In this research work, we introduce a novel, unique, and efficient Field Programmable Gate Array (FPGA)-based hardware accelerator for a convex optimization-based SVM classifier for embedded platforms, considering the constraints associated with these platforms and the requirements of the applications running on these devices. We incorporate suitable mathematical kernels and decomposition methods to systematically solve the convex optimization for machine learning applications with a large volume of data. Our proposed architectures are generic, parameterized, and scalable; hence, without changing internal architectures, our designs can be used to process different datasets with varying sizes, can be executed on different platforms, and can be utilized for various machine learning applications. We also introduce system-level architectures and techniques to facilitate real-time processing. Experiments are performed using two different benchmark datasets to evaluate the feasibility and efficiency of our hardware architecture, in terms of timing, speedup, area, and accuracy. Our embedded hardware design achieves up to 79 times speedup compared to its embedded software counterpart, and can also achieve up to 100% classification accuracy.
C1 [Ramadurgam, Srikanth; Perera, Darshika G.] Univ Colorado, Dept Elect & Comp Engn, 1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918 USA.
RP Perera, DG (corresponding author), Univ Colorado, Dept Elect & Comp Engn, 1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918 USA.
EM darshika.perera@uccs.edu; darshika.perera@uccs.edu
CR Afifi S., 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00128-9
   Afifi S.M., 2015, INT J INNOV SCI ENG, V2, P732
   Afifi S, 2019, MICROPROCESS MICROSY, V65, P57, DOI 10.1016/j.micpro.2018.12.005
   Alkamil A., 2019, P IEEE INT C REC COM
   Alkamil A, 2020, IEEE ACCESS, V8, P221720, DOI 10.1109/ACCESS.2020.3043750
   Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2005, SUPPORT VECTOR MACHI
   [Anonymous], 1998, ADV KERNEL METHODS S
   [Anonymous], 2011, AXI REF GUID UG761 V
   [Anonymous], 2006, PATTERN RECOGN
   [Anonymous], 2012, SUPPORT VECTOR MACHI
   Boyd S., 2014, CONVEX OPTIMIZATION
   Campbell C., 2010, LEARNING SUPPORT VEC, V10
   Chang CC, 2000, IEEE T NEURAL NETWOR, V11, P1003, DOI 10.1109/72.857780
   Dua D, 2020, UCI MACHINE LEARNING
   Elgawi Osman, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P164, DOI 10.1109/ISVLSI.2019.00038
   Glowacz A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082853
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lopes FE, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060631
   Madsen A. K., 2020, IEEE INT SYMP CIRC S, P1, DOI DOI 10.1109/iscas45731.2020.9181073
   Madsen AK, 2018, EURASIP J EMBED SYST, DOI 10.1186/s13639-018-0084-3
   Marr Bernard, 2016, TOP 10 MACHINE LEARN
   Miro J.P, 2020, THESIS U COLORADO CO
   Mohsin MA, 2018, HEART 2018: PROCEEDINGS OF THE 9TH INTERNATIONAL SYMPOSIUM ON HIGHLY-EFFICIENT ACCELERATORS AND RECONFIGURABLE TECHNOLOGIES, DOI 10.1145/3241793.3241810
   Nilsson P, 2014, 2014 NORCHIP
   Noronha DH, 2019, MICROPROCESS MICROSY, V69, P138, DOI 10.1016/j.micpro.2019.06.007
   Papadonikolakis M., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P283, DOI 10.1109/FPT.2010.5681485
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Papadonikolakis M, 2010, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2010.39
   Perera D. G., 2011, 2011 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing, P100, DOI 10.1109/3PGCIC.2011.25
   Perera DG, 2013, IEEE PAC RIM CONF CO, P369, DOI 10.1109/PACRIM.2013.6625505
   Perera DG, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P730, DOI 10.1109/PACRIM.2011.6032984
   Peters J, 2017, ADAPT COMPUT MACH LE
   Piccialli V, 2018, 4OR-Q J OPER RES, V16, P111, DOI 10.1007/s10288-018-0378-2
   Platt JL, 1998, INT CONGR SER, V1169, P21
   Raghavan R, 2017, IEEE PAC RIM CONF CO
   Ramadurgam S., 2021, THESIS U COLORADO CO
   Shahrouzi SN, 2019, MICROPROCESS MICROSY, V65, P79, DOI 10.1016/j.micpro.2019.01.001
   Shahrouzi SN, 2017, EURASIP J EMBED SYST, DOI 10.1186/s13639-017-0074-x
   Sigillito V., 1989, **DATA OBJECT**
   Simplilearn Inc, 2019, MACH LEARN WHAT IT I
   Siozios K., 2019, P 2019 8 INT C MOD C, P1
   Smola A, 2008, CAMBRIDGE U UK, V32
   Tsoutsouras V, 2017, J SIGNAL PROCESS SYS, V88, P127, DOI 10.1007/s11265-017-1230-1
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   Vapnik V., 1995, NATURE STAT LEARNING
   Venkateshan S, 2015, IEEE T VLSI SYST, V23, P2221, DOI 10.1109/TVLSI.2014.2361254
   Vranjkovic V., 2016, P INT C SYST SIGN IM, P1
   Wang S., 2011, INT C WIRELESS COMMU, P1
   Wolberg W.H., 1995, BREAST CANC WISCONSI
   Xilinx Inc, 2015, VIRTEX 6 FAM OV DS15
   Xilinx Inc., 2011, ML605 HARDW US GUID
   Xilinx Inc, 2011, LOGICORE IP AXI MAST
   Xilinx Inc, 2014, VIRTE 6 FPGA MEM RES
   Xilinx Inc., 2012, DS 816 LOGICORE IP F
   Xilinx Inc, 2016, AXI TIM V2 0 LOGICOR
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
NR 58
TC 4
Z9 4
U1 3
U2 16
PD JUN
PY 2021
VL 10
IS 11
AR 1323
DI 10.3390/electronics10111323
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Lee, KH
   Verma, N
AF Lee, Kyong Ho
   Verma, Naveen
TI A Low-Power Processor With Configurable Embedded Machine-Learning
   Accelerators for High-Order and Adaptive Analysis of Medical-Sensor
   Signals
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article; Proceedings Paper
CT 38th European Solid-State Circuits Conference (ESSCIRC)
CY SEP 17-21, 2012
CL Bordeaux, FRANCE
DE Active learning (subject-specific adaptation); biomedical electronics;
   machine learning (artificial intelligence); medical signal processing;
   support vector machine (SVM)
AB Low-power sensing technologies have emerged for acquiring physiologically indicative patient signals. However, to enable devices with high clinical value, a critical requirement is the ability to analyze the signals to extract specific medical information. Yet given the complexities of the underlying processes, signal analysis poses numerous challenges. Data-driven methods based on machine learning offer distinct solutions, but unfortunately the computations are not well supported by traditional DSP. This paper presents a custom processor that integrates a CPU with configurable accelerators for discriminative machine-learning functions. A support-vector-machine accelerator realizes various classification algorithms as well as various kernel functions and kernel formulations, enabling range of points within an accuracy-versus-energy and -memory trade space. An accelerator for embedded active learning enables prospective adaptation of the signal models by utilizing sensed data for patient-specific customization, while minimizing the effort from human experts. The prototype is implemented in 130-nm CMOS and operates from 1.2 V-0.55 V (0.7 V for SRAMs). Medical applications for EEG-based seizure detection and ECG-based cardiac-arrhythmia detection are demonstrated using clinical data, while consuming 273 mu J and 124 mu J per detection, respectively; this represents 62.4x and 144.7x energy reduction compared to an implementation based on the CPU. A patient-adaptive cardiac-arrhythmia detector is also demonstrated, reducing the analysis-effort required for model customization by 20x.
C1 [Lee, Kyong Ho; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Lee, KH (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM kyonglee@princeton.edu; nverma@princeton.edu
CR Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1007/BF00116828
   [Anonymous], 2012, P MACHINE LEARNING R
   [Anonymous], 1999, P 16 INT JOINT C ART
   [Anonymous], P INT C MACH LEARN J
   Ashouei M., 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P332, DOI 10.1109/ISSCC.2011.5746341
   BAUM EB, 1991, IEEE T NEURAL NETWOR, V2, P5, DOI 10.1109/72.80287
   Brinker K., 2003, P INT C MACH LEARN A
   Chen TC, 2009, IEEE INT SYMP CIRC S, P1253, DOI 10.1109/ISCAS.2009.5117990
   Csavoy A, 2009, SYMP VLSI CIRCUITS, P4
   de Chazal P, 2004, IEEE T BIO-MED ENG, V51, P1196, DOI 10.1109/TBME.2004.827359
   Denison T, 2007, IEEE J SOLID-ST CIRC, V42, P2934, DOI 10.1109/JSSC.2007.908664
   Dugdale D. C., 2012, POSTMYOCARDIAL INFAR
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Jang KJ, 2011, IEEE ENG MED BIO, P2184, DOI 10.1109/IEMBS.2011.6090411
   Karkare V, 2011, IEEE J SOLID-ST CIRC, V46, P1214, DOI 10.1109/JSSC.2011.2116410
   Kim DH, 2012, ANNU REV BIOMED ENG, V14, P113, DOI [10.1146/annurev-bioeng-071811-150018, 10.1146/annurev.bioeng-071811-150018]
   Kwong Joyce, 2010, Proceedings of the 36th European Solid State Circuits Conference (ESSCIRC 2010), P526, DOI 10.1109/ESSCIRC.2010.5619759
   Kyong Ho Lee, 2012, ESSCIRC 2012 - 38th European Solid State Circuits Conference, P285, DOI 10.1109/ESSCIRC.2012.6341275
   Lee KH, 2011, INT CONF ACOUST SPEE, P1597
   Mingoo Seok, 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P342, DOI 10.1109/ISSCC.2011.5746346
   Moosung Chae, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P146
   Raghunathan Shriram, 2011, Journal of Low Power Electronics and Applications, V1, P175, DOI 10.3390/jlpea1010175
   Sarpeshkar R, 2005, IEEE T BIO-MED ENG, V52, P711, DOI 10.1109/TBME.2005.844043
   Shih E., 2008, P 2 INT WORKSH SYST
   SHOEB A, 2009, EMBC 2009 ANN INT C, P4202
   Suffczynski P, 2004, NEUROSCIENCE, V126, P467, DOI 10.1016/j.neuroscience.2004.03.014
   Vapnik V., 1995, NATURE STAT LEARNING
   Verma Naveen, 2011, Journal of Low Power Electronics and Applications, V1, P150, DOI 10.3390/jlpea1010150
   Verma N, 2010, IEEE J SOLID-ST CIRC, V45, P804, DOI 10.1109/JSSC.2010.2042245
   Viventi J, 2011, NAT NEUROSCI, V14, P1599, DOI 10.1038/nn.2973
   Volkmann J, 2002, MOVEMENT DISORD, V17, pS181, DOI 10.1002/mds.10162
   Walther J.S., 1971, P SPRING JOINT COMP, P379, DOI [10.1145/1478786.1478840, DOI 10.1145/1478786.1478840]
   Yazicioglu RF, 2007, IEEE J SOLID-ST CIRC, V42, P1100, DOI 10.1109/JSSC.2007.894804
   Yoo J., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P292, DOI 10.1109/ISSCC.2012.6177019
NR 34
TC 126
Z9 131
U1 2
U2 33
PD JUL
PY 2013
VL 48
IS 7
SI SI
BP 1625
EP 1637
DI 10.1109/JSSC.2013.2253226
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sommer, L
   Oppermann, J
   Molina, A
   Binnig, C
   Kersting, K
   Koch, A
AF Sommer, Lukas
   Oppermann, Julian
   Molina, Alejandro
   Binnig, Carsten
   Kersting, Kristian
   Koch, Andreas
GP IEEE
TI Automatic Mapping of the Sum-Product Network Inference Problem to
   FPGA-based Accelerators
SO 2018 IEEE 36TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 36th IEEE International Conference on Computer Design (ICCD)
CY OCT 07-10, 2018
CL Orlando, FL
DE FPGA; SPN; Machine Learning; Graphical Models; Deep Models
AB In recent years, FPGAs have been successfully employed for the implementation of efficient, application-specific accelerators for a wide range of machine learning tasks. In this work, we consider probabilistic models, namely, (Mixed) Sum-Product Networks (SPN), a deep architecture that can provide tractable inference for multivariate distributions over mixed data-sources. We develop a fully pipelined FPGA accelerator architecture, including a pipelined interface to external memory, for the inference in (mixed) SPNs. To meet the precision constraints of SPNs, all computations are conducted using double-precision floating point arithmetic. Starting from an input description, the custom FPGA-accelerator is synthesized fully automatically by our tool flow. To the best of our knowledge, this work is the first approach to offload the SPN inference problem to FPGA-based accelerators. Our evaluation shows that the SPN inference problem benefits from offloading to our pipelined FPGA accelerator architecture.
C1 [Sommer, Lukas; Oppermann, Julian; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
   [Molina, Alejandro; Kersting, Kristian] Tech Univ Darmstadt, Machine Learning Grp, Darmstadt, Germany.
   [Binnig, Carsten] Tech Univ Darmstadt, Data Management Lab, Darmstadt, Germany.
RP Sommer, L (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM sommer@esa.tu-darmstadt.de; oppermann@esa.tu-darmstadt.de;
   molina@cs.tu-darmstadt.de; carsten.binnig@cs.tu-darmstadt.de;
   kersting@cs.tu-darmstadt.de; koch@esa.tu-darmstadt.de
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Alves J. D., 2015, WORKSH UNC COMP BAYE
   [Anonymous], MICROSOFT FPGA WINS
   [Anonymous], 2016, 49 ANN IEEE ACM INT
   Bekker J., 2015, P NIPS
   Choi A, 2017, PR MACH LEARN RES, V70
   Choi J., 2016, IEEE T CIRCUITS SYST
   Chung E., 2017, HOT CHIPS 29 S HIGH
   Darwiche A, 2003, J ACM, V50, P280, DOI 10.1145/765568.765570
   de Dinechin F., 2011, IEEE DESIGN TEST COM
   Dormiani P., 2005, ADV SIGNAL PROCESSIN, V5910
   Geist J, 2014, LECT NOTES COMPUT SC, V8734, P215, DOI 10.1007/978-3-319-11164-3_18
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Korinth J., 2015, FIELD PROGR CUST COM
   Lopez-Paz D., 2013, ADV NEURAL INFORM PR, P1, DOI DOI 10.1214/A0S/1176345528
   Lowd D., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P334, DOI 10.1109/ICDM.2010.128
   Molina A., 2018, MIXED SUM PRODUCT NE
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Peharz R., 2015, P AISTATS
   Poon H., 2011, P UAI
   Pronobis A., 2017, PRINC APPR DEEP LEAR
   Van Haaren J., 2012, P 26 AAAI C ART INT, P1148
   Zermani S., 2015, PROGN HLTH MAN PHM 2, P1, DOI DOI 10.1109/ICPHM.2015.7245057
   Zhao H., 2015, P ICML
NR 25
TC 14
Z9 14
U1 0
U2 4
PY 2018
BP 350
EP 357
DI 10.1109/ICCD.2018.00060
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Snásel, V
   Dang, TK
   Pham, PNH
   Küng, J
   Kong, LP
AF Snasel, Vaclav
   Tran Khanh Dang
   Pham, Phuong N. H.
   Kueng, Josef
   Kong, Lingping
BE Dang, TK
   Kung, J
   Chung, TM
TI In-Memory Computing Architectures for Big Data and Machine Learning
   Applications
SO FUTURE DATA AND SECURITY ENGINEERING. BIG DATA, SECURITY AND PRIVACY,
   SMART CITY AND INDUSTRY 4.0 APPLICATIONS, FDSE 2022
SE Communications in Computer and Information Science
DT Proceedings Paper
CT 9th International Conference, FDSE
CY NOV 23-25, 2022
CL Ho Chi Minh, VIETNAM
DE In-memory computing; Machining learning; Deep neural network; In-memory
   accelerator
ID NEURAL-NETWORK IMPLEMENTATION; ACCELERATOR; DADIANNAO; DIANNAO
AB Traditional computing hardware is working to meet the extensive computational load presented by the rapidly growing Machine Learning (ML) and Artificial Intelligence algorithms such as Deep Neural Networks and Big Data. In order to get hardware solutions to meet the low-latency and high-throughput computational needs of these algorithms, Non-Von Neumann computing architectures such as In-memory Computing (IMC) have been extensively researched and experimented with over the last five years. This study analyses and reviews works designed to accelerate Machine Learning task. We investigate different architectural aspects and directions and provide our comparative evaluations. We further discuss IMC research's challenges and limitations and present possible directions.
C1 [Snasel, Vaclav; Kong, Lingping] VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, Ostrava, Czech Republic.
   [Tran Khanh Dang; Pham, Phuong N. H.] Ho Chi Minh City Univ Food Ind HUFI, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Kueng, Josef] Johannes Kepler Univ Linz, Linz, Austria.
RP Snásel, V; Kong, LP (corresponding author), VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, Ostrava, Czech Republic.
EM vaclav.snasel@vsb.cz; khanh@hufi.edu.vn; phuongpnh@hufi.edu.vn;
   josef.kueng@jku.at; lingping.kong@vsb.cz
CR Advanced Micro Devices, 2022, AMD RAD GRAPH CARDS
   Agrawal A, 2018, IEEE T CIRCUITS-I, V65, P4219, DOI 10.1109/TCSI.2018.2848999
   Angizi S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240799
   [Anonymous], 2022, GOOGLECLOUD TPU
   author. Graphcore ipu, 2022, US
   author. Nvidia gpu, 2022, US
   Boutros A, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242898
   Bradski G, 2000, DR DOBBS J, V25, P120
   Capra M, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040100
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Y., 2022, P IEEECVF C COMPUTER, P5270
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chmielewski L, 2021, LECT NOTES COMPUT SC, V12809, P96, DOI 10.1007/978-3-030-81645-2_7
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dazzi M, 2021, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.674154
   Dietterich TG, 1997, AI MAG, V18, P97
   Faggin F., 1990, VLSI IMPLEMENTATION
   Freund K., 2022, MACHINE LEARNING LAN
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Gokmen T, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00103
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hashiyana V., 2017, 2017 1 AFRICA WEEK C, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Honghoon Jang, 2008, 2008 Digital Image Computing: Techniques and Applications, P155, DOI 10.1109/DICTA.2008.82
   Hoschek W, 2001, LECT NOTES COMPUT SC, V1971, P77
   Huang G. B., 2008, WORKSHOP FACES INREA, P1
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Jawandhiya P., 2018, INT J ARTIF INTELL A, V9, P63, DOI [10.5121/ijaia.2018.9105, DOI 10.5121/IJAIA.2018.9105]
   Jesan J.P., 2003, HUMAN BRAIN NEURAL N
   Jia XY, 2018, Arxiv, DOI arXiv:1807.11205
   Jung S, 2007, IEEE T IND ELECTRON, V54, P265, DOI 10.1109/TIE.2006.888791
   Kabakus AT, 2017, J KING SAUD UNIV-COM, V29, P520, DOI 10.1016/j.jksuci.2016.06.007
   Kerbl B., 2022, CUDA APPL TASKBASED
   Khan AA, 2021, EAI ENDORSED TRANS S, V8, DOI 10.4108/eai.21-4-2021.169418
   Khan AI, 2020, PROCEDIA COMPUT SCI, V167, P1444, DOI 10.1016/j.procs.2020.03.355
   Kim JW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062143
   Korchagin P.A., 2018, INT C AVIAMECHANICAL, P416
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2018, DES AUT TEST EUROPE, P815, DOI 10.23919/DATE.2018.8342118
   Lim B, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0209
   Lin H, 2020, ADV NEURAL INFORM PR, V33, P1796
   Lin TY, 2021, Arxiv, DOI [arXiv:2106.04554, DOI 10.1016/J.AIOPEN.2022.10.001]
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Longa A., 2022, PYG TORCH GEOMETRIC
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Lynham J, 2014, MAR POLICY, V44, P42, DOI 10.1016/j.marpol.2013.08.007
   Makrani HM, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P727, DOI 10.1145/3287624.3288756
   Mao HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P669, DOI [10.1109/MICRO.2018.00060, 10.1109/MICR0.2018.00060]
   Merolla P, 2011, IEEE CUST INTEGR CIR
   Mijwel M. M, 2018, ARTIFICIAL NEURAL NE
   Miyashita D, 2016, Arxiv, DOI arXiv:1603.01025
   Nandakumar SR, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00406
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Nvidia, 2022, CUD TOOLK
   O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, DOI 10.48550/ARXIV.1511.08458]
   Osman A.A.M., 2017, RECENT PROGR PARALLE
   Peng XC, 2021, IEEE T COMPUT AID D, V40, P2306, DOI 10.1109/TCAD.2020.3043731
   Qiao XM, 2018, DES AUT CON, DOI 10.1145/3195970.3195998
   Raposo G, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7908, DOI 10.1109/ICASSP39728.2021.9413919
   Rashed Muhammad Rashedul Haq, 2022, 2022 27th Asia and South Pacific Design Automation Conference (ASP-DAC), P690, DOI 10.1109/ASP-DAC52403.2022.9712569
   Rege A., INTRO MODERN GPU ARC
   Reuben J, 2020, J LOW POWER ELECT AP, V10, DOI 10.3390/jlpea10030028
   Ríos C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau5759
   Ruizhe Zhao, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P645, DOI 10.1109/ISVLSI.2017.127
   Sahin S, 2006, LECT NOTES COMPUT SC, V4234, P1105
   Saikia J, 2019, I SYMPOS LOW POWER E
   Salami B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P724, DOI [10.1109/MICR0.2018.00064, 10.1109/MICRO.2018.00064]
   Salkuti S.R., 2020, INT J ELECT COMPUT E, V10, P2088, DOI [10.11591/ijece.v10i2.pp1179-1186, DOI 10.11591/IJECE.V10I2.PP1179-1186]
   Sebastian A., 2019, 2019 Symposium on VLSI Technology, pT168, DOI 10.23919/VLSIT.2019.8776518
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Silicon Graphics Khronos Group. Opengl, 2022, US
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Song MC, 2018, INT S HIGH PERF COMP, P66, DOI 10.1109/HPCA.2018.00016
   Sun X, 2019, ADV NEUR IN, V32
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tarditi D, 2006, ACM SIGPLAN NOTICES, V41, P325, DOI 10.1145/1168918.1168898
   Touvron H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P32, DOI 10.1109/ICCV48922.2021.00010
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Wang C, 2020, IEEE T PARALL DISTR, V31, P2346, DOI 10.1109/TPDS.2020.2990924
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang W, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.4.040901
   Wang Y., 2020, SHORT COURSE, V3
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yan BA, 2019, ADV INTELL SYST-GER, V1, DOI 10.1002/aisy.201900068
   Yann L., 2022, MNIST DATASET
   Zanotti T, 2020, IEEE J EM SEL TOP C, V10, P478, DOI 10.1109/JETCAS.2020.3030542
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang CX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P793, DOI 10.1145/3292500.3330961
   Zhang Y., 2018, ENERGY INF, V1, P1, DOI DOI 10.1186/S42162-018-0007-5
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 96
TC 0
Z9 0
U1 1
U2 3
PY 2022
VL 1688
BP 19
EP 33
DI 10.1007/978-981-19-8069-5_2
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Industrial
DA 2023-11-11
ER

PT C
AU Solis, AI
   Nava, P
AF Solis, Angel, I
   Nava, Patricia
BE Blowers, M
   Hall, RD
   Dasari, VR
TI Domain Specific Architectures, Hardware Acceleration for Machine/Deep
   Learning
SO DISRUPTIVE TECHNOLOGIES IN INFORMATION SCIENCES II
SE Proceedings of SPIE
DT Proceedings Paper
CT Conference on SPIE Disruptive Technologies in Information Sciences II
CY APR 15-16, 2019
CL Baltimore, MD
DE Domain Specific Architectures; Machine Learning; Deep Learning; Computer
   Architecture; Accelerators; Convolutional Neural Networks; Recurrent
   Neural Networks; Soft Computing
AB This article aims to provide the reader with a clear understanding of a subdiscipline in artificial intelligence, Deep Neural Networks. In addition to this, we cover a set of proposed Domain Specific Architectures, Accelerators, that are optimized for these types of computations. In optimizing these computations, we are able to reduce data transfers by keeping data at the processing unit in their individual register files thus increasing energy efficiency per computation.
C1 [Solis, Angel, I; Nava, Patricia] UTEP, Dept Elect & Comp Engn, El Paso, TX 79902 USA.
RP Solis, AI (corresponding author), UTEP, Dept Elect & Comp Engn, El Paso, TX 79902 USA.
CR [Anonymous], 2012, COMPUTER ARCHITECTUR
   [Anonymous], 2016, COMPL VIS NETW IND V
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Hennessy J., 2017, COMPUTER ARCHITECTUR
   Niu X., SYST CHIP SOC BAS HA, DOI [10.25148/etd.fi13042902, DOI 10.25148/ETD.FI13042902]
   Reagen B., 2017, DEEP LEARNING COMPUT
   Salvo B. D., 2018, 2018 IEEE INT SOL ST, DOI [10.1109/isscc.2018.8310165, DOI 10.1109/ISSCC.2018.8310165]
   Siddique M. N. H., 2001, INT JOINT C NEUR NET, V4, P2673, DOI DOI 10.1109/IJCNN.2001.938792
   Sze V, 2017, IEEE CUST INTEGR CIR
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Takamaeda-Yamazaki S., 2017, 2017 AS PAC SIGN INF, DOI [10.1109/apsipa.2017.8282183, DOI 10.1109/APSIPA.2017.8282183]
NR 11
TC 3
Z9 3
U1 0
U2 3
PY 2019
VL 11013
AR 1101307
DI 10.1117/12.2519554
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Reis, D
   Laguna, AF
   Niemier, M
   Hu, XS
AF Reis, Dayane
   Laguna, Ann Franchesca
   Niemier, Michael
   Hu, Xiaobo Sharon
GP IEEE
TI In-Memory Computing Accelerators for Emerging Learning Paradigms
SO 2023 28TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, ASP-DAC
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 28th Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 16-19, 2023
CL Miraikan Natl Museum Emerging Sci & Informat, Tokyo, JAPAN
HO Miraikan Natl Museum Emerging Sci & Informat
DE Computing-in-memory; Emerging technologies; Machine Learning
AB Over the past decades, emerging, data-driven machine learning (ML) paradigms have increased in popularity, and revolutionized many application domains. To date, a substantial effort has been devoted to devising mechanisms for facilitating the deployment and near ubiquitous use of these memory intensive ML models. This review paper presents the use of in-memory computing (IMC) accelerators for emerging ML paradigms from a bottom-up perspective through the choice of devices, the design of circuits/architectures, to the application-level results.
C1 [Reis, Dayane] Univ S Florida, Tampa, FL 33620 USA.
   [Laguna, Ann Franchesca] De La Salle Univ, Manila, Philippines.
   [Niemier, Michael; Hu, Xiaobo Sharon] Univ Notre Dame, Notre Dame, IN 46556 USA.
RP Reis, D (corresponding author), Univ S Florida, Tampa, FL 33620 USA.
EM dayane3@usf.edu; ann.laguna@dlsu.edu.ph; mniemier@nd.edu; shu@nd.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   [Anonymous], 2017, TVLSI
   Bhatia S, 2021, PSYCHOL REV
   Cheng CH, 2014, IEEE ELECTR DEVICE L, V35, P138, DOI 10.1109/LED.2013.2290117
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Dünkel S, 2017, INT EL DEVICES MEET
   Fedus William, 2021, SWITCH TRANSFORMERS
   Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209
   Huang QR, 2022, IEEE DES TEST, V39, P56, DOI 10.1109/MDAT.2021.3063336
   Isaac RD, 2000, IBM J RES DEV, V44, P369, DOI 10.1147/rd.443.0369
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Kang W, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2703863
   Kazemi A, 2022, IEEE T COMPUT, V71, P2565, DOI [10.1109/TC.2021.3136576, 10.23919/DATE51398.2021.9474025]
   Laguna A. F., 2022, FRONTIERS ELECT, V3
   Laguna AF, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1839, DOI 10.23919/DATE51398.2021.9474146
   Li M, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P463, DOI 10.1145/3489517.3530478
   Li SC, 2016, DES AUT CON, DOI [10.1145/2897937.2898064, 10.1109/ICAUMS.2016.8479697]
   Marcus Mitchell P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Moore G. E., 1965, CRAMMING MORE COMPON
   Naumov Maxim, 2019, ABS190600091 CORR
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Pan Y., 2021, 2021 28th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS)
   Rae Jack W, 2019, ARXIV191105507
   Ranjan A, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317935
   Reis D., 2021, ASP DAC
   Reis D, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P306, DOI 10.23919/DATE51398.2021.9474261
   Reis D, 2020, DES AUT TEST EUROPE, P127, DOI 10.23919/DATE48585.2020.9116292
   Reis D, 2018, I SYMPOS LOW POWER E, P134, DOI 10.1145/3218603.3218640
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen ZJ, 2020, NANOMATERIALS-BASEL, V10, DOI 10.3390/nano10081437
   Vaswani A., 2017, P 31 INT C NEURAL IN
   Weste N.E.H., 2015, CMOS VLSI DESIGN CIR
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xunzhao Yin, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P437, DOI 10.1109/ISVLSI.2019.00085
   Yin XZ, 2019, IEEE T CIRCUITS-II, V66, P1577, DOI 10.1109/TCSII.2018.2889225
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang XY, 2019, PR IEEE COMP DESIGN, P541, DOI 10.1109/ICCD46524.2019.00080
NR 37
TC 1
Z9 1
U1 0
U2 0
PY 2023
BP 606
EP 611
DI 10.1145/3566097.3568356
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Rescic, M
   Seviour, R
   Blokland, W
AF Rescic, Miha
   Seviour, Rebecca
   Blokland, Willem
TI Predicting particle accelerator failures using binary classifiers
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Particle accelerator; Accelerator reliability; Machine learning; Binary
   classifier; Failure prediction
ID NEURAL-NETWORKS; RELIABILITY
AB Particle accelerator failures lead to unscheduled downtime and lower reliability. Although simple to mitigate while they are actually happening such failures are difficult to predict or identify beforehand. In this work we propose using machine learning approaches to predict machine failures via beam current measurements before they actual occur. To demonstrate this technique in this paper we examine beam pulses from the Oakridge Spallation Neutron Source (SNS). By evaluating a pulse against a set of common classification techniques we show that accelerator failure can be identified prior to actually failing with almost 80% accuracy. We also show that tuning classifier parameters and using pulse properties for refining datasets can further lead to almost 92% accuracy in classification of bad pulses. Most importantly, in the paper we establish there is information about the failure encoded in the pulses prior to it, so we also present a list of feasible next steps for increasing pulse classification accuracy.
C1 [Rescic, Miha; Seviour, Rebecca] Univ Huddersfield, Huddersfield HD1 3DH, W Yorkshire, England.
   [Blokland, Willem] Neutron Sci Directorate, One Bethel Valley Rd, Oak Ridge, TN 37831 USA.
RP Rescic, M (corresponding author), Univ Huddersfield, Huddersfield HD1 3DH, W Yorkshire, England.
EM miha.rescic@hud.ac.uk; R.Seviour2@hud.ac.uk; blokland@ornl.gov
CR Adelmann Andreas, 2018, MACHINE LEARNING APP
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2012, LEARNING FROM DATA
   [Anonymous], 2001, IEEE COMP SOC C COMP
   [Anonymous], 2003, TECHNOMETRICS
   [Anonymous], 1951, JOSEPH
   [Anonymous], MACH LEARN
   [Anonymous], 2010, BAGS FEATURES SPATIA
   [Anonymous], 2013, WORLD SCI
   [Anonymous], DISCRIMINATIVELY TRA, DOI DOI 10.1242/jeb.010272
   Bargalló E, 2014, FUSION ENG DES, V89, P2425, DOI 10.1016/j.fusengdes.2013.12.004
   Bauer G.S., 2000, P 15 M INT COLL ADV, P103
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bhatia N., 2010, INT J COMPUT SCI INF, V8, P302, DOI DOI 10.1016/J.PMCJ.2015.02.001
   Blokland W., 2013, P INT BEAM INSTR C S
   Breiman L., 2017, CLASSIFICATION REGRE, DOI 10.1201/9781315139470
   Bruce P., 2018, PRACTICAL STAT DATA
   Burgazzi L, 2007, RELIAB ENG SYST SAFE, V92, P449, DOI 10.1016/j.ress.2005.12.008
   Campisi I. E., 2007, 2007 IEEE Particle Accelerator Conference, P2502, DOI 10.1109/PAC.2007.4441297
   Clark R, 2016, IEEE DECIS CONTR P, P879, DOI 10.1109/CDC.2016.7798378
   Corneliusen A., 1989, COMPUTATION CONTROL
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P327
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A.L., 2015, P IPAC 2015 MAY 3 8, P1217
   Edelen Auralee, 2018, MACHINE LEARNING APP
   Empresarios Agrupados Empresarios Agrupados Ea, 2013, P 39 ANN M SPAN NUCL
   Everingham M., PASCAL VISUAL OBJECT
   Faber MH, 2003, RELIAB ENG SYST SAFE, V80, P173, DOI 10.1016/S0951-8320(03)00027-9
   Fol E., 2018, P IPAC 2018, P12
   Fol E., 2018, MACHINE LEARNING APP
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Galambos John, 2013, PROC PAC2013, P1443
   Galambos John, 2007, CARE HHH APD EVENT B
   Galambos John, 2010, P 46 ICFA ADV BEAM D
   Groeschel F., 2007, P 5 INT WORKSH UT RE
   Hastie T., 2017, ELEMENTS STAT LEARNI
   Henderson S., 2010, ACCELERATOR TARGET T
   Higo T., 1987, Proceedings of the 1987 IEEE Particle Accelerator Conference: Accelerator Engineering and Technology (Cat. No.87CH2387-9), P701
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Kim S-H., 2014, P 16 INT C RF SUP SE, P83
   Laverty M., 2016, P LINAC2016 E LANS M, P485
   Lee M., 1991, ACCELERATOR FEEDBACK, V1991, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   MARON ME, 1961, J ACM, V8, P404, DOI 10.1145/321075.321084
   Mitchell T.M., 1997, MACH LEARN, V1
   Modarres M., 2011, TECHNOMETRICS, P565
   Nuclear Energy Agency, 2002, NEA ACC DRIV SYST AD
   Omohundro Stephen M., 1989, INT COMPUTER SCI I T
   Phinney N., 2004, 9 EUR PART ACC C 5 9, P857
   Pichoff N., 2000, P 7 EUROPEAN PARTICL, P2049
   Pierini P., 2003, PDS XADS DELIVERABLE
   Pierini Paolo, 2004, UTILISATION RELIABIL
   Pradlwarter HL, 2005, COMPUT METHOD APPL M, V194, P1597, DOI 10.1016/j.cma.2004.05.029
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rezaeizadeh Amin, P FEL2014 BAS SWITZ, P824
   Roberts L., 1963, MACHINE PERCEPTION 3
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Sanchezgonzalez Alvaro, 2018, MACHINE LEARNING APP, P8
   Suhring S, 2003, PROCEEDINGS OF THE 2003 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P625, DOI 10.1109/PAC.2003.1288994
   Tajima T., 2008, P EP, P3717
   Tang William, 2015, MACHINE LEARNING STU
   Tapia C, 2011, FUSION ENG DES, V86, P2722, DOI 10.1016/j.fusengdes.2011.02.099
   Vesely W.E., 1981, FAULT TREE HDB, P209
   WALKER SH, 1967, BIOMETRIKA, V54, P167, DOI 10.2307/2333860
   Chen Y, 2017, IEEE SYST J, V11, P1060, DOI 10.1109/JSYST.2015.2445919
   Zagar K., 2013, P INT PARTICLE ACCEL, P873
NR 74
TC 15
Z9 15
U1 2
U2 8
PD MAR 1
PY 2020
VL 955
AR 163240
DI 10.1016/j.nima.2019.163240
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Liu, DF
   Chen, TS
   Liu, SL
   Zhou, JH
   Zhou, SY
   Teman, O
   Feng, XB
   Zhou, XH
   Chen, YJ
AF Liu, Daofu
   Chen, Tianshi
   Liu, Shaoli
   Zhou, Jinhong
   Zhou, Shengyuan
   Teman, Olivier
   Feng, Xiaobing
   Zhou, Xuehai
   Chen, Yunji
TI PuDianNao: A Polyvalent Machine Learning Accelerator
SO ACM SIGPLAN NOTICES
DT Article; Proceedings Paper
CT 20th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY MAR 14-18, 2015
CL Istanbul, TURKEY
AB Machine Learning (ML) techniques are pervasive tools in various emerging commercial applications, but have to be accommodated by powerful computer systems to process very large data. Although general-purpose CPUs and GPUs have provided straightforward solutions, their energy-efficiencies are limited due to their excessive supports for flexibility. Hardware accelerators may achieve better energy-efficiencies, but each accelerator often accommodates only a single ML technique (family). According to the famous No-Free-Lunch theorem in the ML domain, however, an ML technique performs well on a dataset may perform poorly on another dataset, which implies that such accelerator may sometimes lead to poor learning accuracy. Even if regardless of the learning accuracy, such accelerator can still become inapplicable simply because the concrete ML task is altered, or the user chooses another ML technique.
   In this study, we present an ML accelerator called PuDianNao, which accommodates seven representative ML techniques, including k-means, k-nearest neighbors, naive bayes, support vector machine, linear regression, classification tree, and deep neural network. Benefited from our thorough analysis on computational primitives and locality properties of different ML techniques, PuDianNao can perform up to 1 0 5 6 GOP/s (e.g., additions and multiplications) in an area of 3 : 5 1 mm 2, and consumes 596 mW only. Compared with the NVIDIA K20M GPU (28nm process), PuDianNao (65nm process) is 1.20x faster, and can reduce the energy by 128.41x.
C1 [Liu, Daofu; Chen, Tianshi; Liu, Shaoli; Zhou, Shengyuan; Feng, Xiaobing] ICT, SKLCA, Beijing, Peoples R China.
   [Zhou, Jinhong; Zhou, Xuehai] USTC, Hefei, Peoples R China.
   [Teman, Olivier] Inria, Villers, France.
   [Chen, Yunji] ICT, SKLCA, CAS Ctr Excellence Brain Sci, Beijing, Peoples R China.
RP Chen, TS (corresponding author), Chinese Acad Sci, State Key Lab Comp Architecture, Inst Comp Technol, Beijing, Peoples R China.
EM chentianshi@ict.ac.cn
CR Al Maashri A, 2012, DES AUT CON, P579
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2014, CHINESE GEN PRACTICE, DOI DOI 10.3969/J.ISSN.1674-4748.2014.21.005
   [Anonymous], 2009, CLUSTER 09, DOI DOI 10.1109/CLUSTR.2009.5289193
   [Anonymous], INT S COMP ARCH
   Breiman L, 1983, CART CLASSIFICATION, P156
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Chan E., 2013, ALGORITHMIC TRADING, V625
   Chen M., 2014, BIG DATA RELATED TEC
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Collobert R., 2008, P 25 ICML, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   da S AG, 2003, 16TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN, SBCCI 2003, PROCEEDINGS, P99
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Edwards A. L., 1976, INTRO LINEAR REGRESS
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Garcia Vincent, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563100
   Heemskerk Jan NH, 1995, NEUROCOMPUTERS BRAIN
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hussain H. M., 2011, Proceedings of the 2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), P248, DOI 10.1109/AHS.2011.5963944
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Majumdar A, 2011, IEEE EMBED SYST LETT, V3, P42, DOI 10.1109/LES.2010.2100802
   Manolakos Elias S, 2010, CIRC SYST ISCAS P 20, P4133
   Maruyama T, 2006, INT C PATT RECOG, P816
   Papadonikolakis M, 2010, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2010.39
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Schmidhuber J., 2011, P 22 INT JOINT C ART
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Yeh YJ, 2007, LECT NOTES COMPUT SC, V4522, P512
   Zhang Tong, 2004, ICML
NR 40
TC 155
Z9 167
U1 1
U2 71
PD APR
PY 2015
VL 50
IS 4
BP 369
EP 381
DI 10.1145/2694344.2694358
WC Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Huang, S
   Xie, ZC
   Han, J
   Zeng, XY
AF Huang, Shan
   Xie, Zhicheng
   Han, Jun
   Zeng, Xiaoyang
BE Jiang, YL
   Tang, TA
   Huang, R
TI A Flexible Low-Power Machine Learning Accelerator for Healthcare
   Applications
SO 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED
   CIRCUIT TECHNOLOGY (ICSICT)
DT Proceedings Paper
CT 13th IEEE International Conference on Solid-State and Integrated-Circuit
   Technology (ICSICT)
CY OCT 25-28, 2016
CL Hangzhou, PEOPLES R CHINA
AB A flexible machine learning accelerator with low power consumption is presented in this paper. Linear classifier, naive Bayes (NB) classifier and support vector machine (SVM) classifier with three kernel functions (linear, polynomial and radial basis function (RBF)) are realized in this design using the same architecture. A modified coordinate rotation digital computer (CORDIC) unit with expanded convergence range is employed to calculate exponential functions. The supply voltage is decreased to help reduce the power consumption. Re-characterized libraries for TSMC 65 nm LP technology under near-threshold supply voltages are generated for the implementation of the proposed accelerator. At the supply voltage of 0.6 V and the clock frequency of 10 MHz, the accelerator consumes 0.26 mu J for each classification using SVM with RBF function. Using linear classifier, the power consumption is further reduced to 0.41 nJ per classification.
C1 [Huang, Shan; Xie, Zhicheng; Han, Jun; Zeng, Xiaoyang] Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
RP Huang, S (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
EM shuang14@fudan.edu.cn
CR Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Shoeb A., 2010, P 27 INT C MACH LEAR, P975, DOI [10.5555/3104322.3104446, DOI 10.5555/3104322.3104446]
   Walther J.S., 1971, P SPRING JOINT COMP, P379, DOI [10.1145/1478786.1478840, DOI 10.1145/1478786.1478840]
NR 5
TC 4
Z9 4
U1 0
U2 1
PY 2016
BP 613
EP 615
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Schueler, E
   Zhao, W
   Patil, I
   Han, B
   Yang, Y
   Xing, L
AF Schueler, E.
   Zhao, W.
   Patil, I.
   Han, B.
   Yang, Y.
   Xing, L.
TI Machine Learning Modeling of Beam Data of Multiple Linear Accelerators
   (LINACs) From Different Institutions and Its Practical Application in
   Fast and Robust LINAC Commissioning
SO MEDICAL PHYSICS
DT Meeting Abstract
CT Annual Meeting of the American-Association-of-Physicists-in-Medicine
   (AAPM)
CY JUL 14-18, 2019
CL San Antonio, TX
C1 [Schueler, E.; Zhao, W.; Patil, I.; Han, B.; Yang, Y.; Xing, L.] Stanford Univ, Sch Med, Stanford, CA 94305 USA.
NR 0
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2019
VL 46
IS 6
MA MO-I345-Ge
BP E263
EP E263
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Shalloo, RJ
   Dann, SJD
   Gruse, JN
   Underwood, CID
   Antoine, AF
   Arran, C
   Backhouse, M
   Baird, CD
   Balcazar, MD
   Bourgeois, N
   Cardarelli, JA
   Hatfield, P
   Kang, J
   Krushelnick, K
   Mangles, SPD
   Murphy, CD
   Lu, N
   Osterhoff, J
   Poder, K
   Rajeev, PP
   Ridgers, CP
   Rozario, S
   Selwood, MP
   Shahani, AJ
   Symes, DR
   Thomas, AGR
   Thornton, C
   Najmudin, Z
   Streeter, MJV
AF Shalloo, R. J.
   Dann, S. J. D.
   Gruse, J. -N.
   Underwood, C. I. D.
   Antoine, A. F.
   Arran, C.
   Backhouse, M.
   Baird, C. D.
   Balcazar, M. D.
   Bourgeois, N.
   Cardarelli, J. A.
   Hatfield, P.
   Kang, J.
   Krushelnick, K.
   Mangles, S. P. D.
   Murphy, C. D.
   Lu, N.
   Osterhoff, J.
   Poder, K.
   Rajeev, P. P.
   Ridgers, C. P.
   Rozario, S.
   Selwood, M. P.
   Shahani, A. J.
   Symes, D. R.
   Thomas, A. G. R.
   Thornton, C.
   Najmudin, Z.
   Streeter, M. J. V.
TI Automation and control of laser wakefield accelerators using Bayesian
   optimization
SO NATURE COMMUNICATIONS
DT Article
AB Laser wakefield accelerators promise to revolutionize many areas of accelerator science. However, one of the greatest challenges to their widespread adoption is the difficulty in control and optimization of the accelerator outputs due to coupling between input parameters and the dynamic evolution of the accelerating structure. Here, we use machine learning techniques to automate a 100 MeV-scale accelerator, which optimized its outputs by simultaneously varying up to six parameters including the spectral and spatial phase of the laser and the plasma density and length. Most notably, the model built by the algorithm enabled optimization of the laser evolution that might otherwise have been missed in single-variable scans. Subtle tuning of the laser pulse shape caused an 80% increase in electron beam charge, despite the pulse length changing by just 1%. Laser wakefield accelerators are compact sources of ultra-relativistic electrons which are highly sensitive to many control parameters. Here the authors present an automated machine learning based method for the efficient multi-dimensional optimization of these plasma-based particle accelerators.
C1 [Shalloo, R. J.; Gruse, J. -N.; Backhouse, M.; Mangles, S. P. D.; Rozario, S.; Najmudin, Z.; Streeter, M. J. V.] Imperial Coll London, John Adams Inst Accelerator Sci, London SW7 2AZ, England.
   [Dann, S. J. D.; Baird, C. D.; Bourgeois, N.; Rajeev, P. P.; Symes, D. R.; Thornton, C.] STFC Rutherford Appleton Lab, Cent Laser Facil, Didcot OX11 0QX, Oxon, England.
   [Underwood, C. I. D.; Arran, C.; Baird, C. D.; Murphy, C. D.; Ridgers, C. P.; Selwood, M. P.] Univ York, York Plasma Inst, Dept Phys, York YO10 5DD, N Yorkshire, England.
   [Antoine, A. F.; Balcazar, M. D.; Cardarelli, J. A.; Krushelnick, K.; Thomas, A. G. R.] Univ Michigan, Ctr Ultrafast Opt Sci, Ann Arbor, MI 48109 USA.
   [Hatfield, P.] Univ Oxford, Clarendon Lab, Parks Rd, Oxford OX1 3PU, England.
   [Kang, J.] Univ Michigan, Dept Chem Engn, Ann Arbor, MI 48109 USA.
   [Lu, N.; Shahani, A. J.] Univ Michigan, Dept Mat Sci & Engn, Ann Arbor, MI 48109 USA.
   [Osterhoff, J.; Poder, K.] Deutsch Elektronen Synchrotron DESY, Notkestr 85, D-22607 Hamburg, Germany.
RP Shalloo, RJ (corresponding author), Imperial Coll London, John Adams Inst Accelerator Sci, London SW7 2AZ, England.
EM r.shalloo@imperial.ac.uk
CR Albert F, 2016, PLASMA PHYS CONTR F, V58, DOI 10.1088/0741-3335/58/10/103001
   Cros B., 2019, ARXIV190108436
   Dann SJD, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.041303
   Danson CN, 2019, HIGH POWER LASER SCI, V7, DOI 10.1017/hpl.2019.36
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edwards RD, 2002, APPL PHYS LETT, V80, P2129, DOI 10.1063/1.1464221
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Esarey E, 2004, AIP CONF PROC, V737, P578
   Gaffney JA, 2019, PHYS PLASMAS, V26, DOI 10.1063/1.5108667
   Glendinning AG, 2001, PHYS MED BIOL, V46, P517, DOI 10.1088/0031-9155/46/2/317
   Glinec Y, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.025003
   Gonsalves AJ, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.084801
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   Hooker SM, 2013, NAT PHOTONICS, V7, P775, DOI [10.1038/nphoton.2013.234, 10.1038/NPHOTON.2013.234]
   Huang D, 2006, J GLOBAL OPTIM, V34, P441, DOI 10.1007/s10898-005-2454-3
   Jacquemot S., 2019, XRAY LASERS COHERENT, V11111
   Kirschner J, 2019, PR MACH LEARN RES, V97
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kneip S, 2010, NAT PHYS, V6, P980, DOI 10.1038/NPHYS1789
   Leemans WP, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.174802
   Lehe R, 2016, COMPUT PHYS COMMUN, V203, P66, DOI 10.1016/j.cpc.2016.02.007
   Leroux V, 2020, OPT EXPRESS, V28, P8257, DOI 10.1364/OE.386112
   Lu W, 2006, PHYS PLASMAS, V13, DOI 10.1063/1.2203364
   Mangles S. P. D, 2016, CAS CERN ACCELERATOR, P289
   McGuffey C, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.025004
   Mockus J., 1982, System Modeling and Optimization. Proceedings of the 10th IFIP Conference, P473, DOI 10.1007/BFb0006170
   Pak A, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.025003
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rowlands-Rees TP, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.105005
   Rus B, 2011, PROC SPIE, V8080, DOI 10.1117/12.890392
   Sarri G, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7747
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Steinke S, 2016, NATURE, V530, P190, DOI 10.1038/nature16525
   Streeter MJV, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.254801
   The EuPraxia Consortium, 2020, TECHNICAL REPORT
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
NR 37
TC 64
Z9 67
U1 8
U2 39
PD DEC 11
PY 2020
VL 11
IS 1
AR 6355
DI 10.1038/s41467-020-20245-6
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Li, XF
   Wang, YX
AF Li, Xianfeng
   Wang, Yuanxun
GP IEEE Comp Soc
TI A Versatile Acceleration Framework for Machine Learning Algorithms
SO 2019 IEEE INTL CONF ON PARALLEL & DISTRIBUTED PROCESSING WITH
   APPLICATIONS, BIG DATA & CLOUD COMPUTING, SUSTAINABLE COMPUTING &
   COMMUNICATIONS, SOCIAL COMPUTING & NETWORKING
   (ISPA/BDCLOUD/SOCIALCOM/SUSTAINCOM 2019)
SE IEEE International Symposium on Parallel and Distributed Processing with
   Applications
DT Proceedings Paper
CT IEEE Int Conf on Parallel and Distributed Processing with Applications,
   Big Data and Cloud Computing, Sustainable Computing and Communications,
   Social Computing and Networking (ISPA/BDCloud/SocialCom/SustainCom)
CY DEC 16-18, 2019
CL Xiamen, PEOPLES R CHINA
DE machine learning; accelerator; co-design; data level parallelism;
   reconfigurable
AB Current Machine Learning (ML) accelerators are based on custom designs targeted to specific algorithms, like the NPU coprocessor for neural networks. We propose a Versatile Acceleration Framework based on a key concept called Performance Semantics, which is an abstraction on data-level parallel behaviors for execution kernels nested in loops. It includes a Versatile Accelerator Pipeline and a software library of common Performance Semantics. The ML programmers only need to invoke the library functions in their algorithms and get accelerated transparently. We implement our framework on FPGA with an embedded ARM CPU, and test it with a set of popular ML algorithms. The results show that our framework can successfully cover the computation kernels in these ML algorithms, and achieves enormous performance speedup ranging from 15x to 40x over ARM CPU and 2.x to 12.x over x86 CPU.
C1 [Li, Xianfeng; Wang, Yuanxun] Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen, Peoples R China.
RP Li, XF (corresponding author), Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen, Peoples R China.
EM lixianfeng.sz@pku.edu.cn; wangyuanxun@pku.edu.cn
CR Akhlaghi Vahideh., 2018, 2018 ACM IEEE 45 ANN
   [Anonymous], 26 ACM SIGDA INT S F
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Groléat T, 2014, IEEE T NETW SERV MAN, V11, P278, DOI 10.1109/TNSM.2014.2346075
   Guo KY, 2017, IEEE MICRO, V37, P18, DOI 10.1109/MM.2017.39
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Li Qin, 2019, P AS S PAC DES AUT C
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Park E., 2018, ISCA
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Rouhani Bita Darvish, 2018, 2018 ACM SIGDA INT S
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tao L., 2016, TOC, V66, P1
   Wang S, 2018, C LSTM ENABLING EFFI
   Yang Yifan., 2018, SYNETGY ALGORITHM HA
   Yazdanbakhsh A, 2018, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2018.00019
   Yazdanbakhsh A, 2018, CONF PROC INT SYMP C, P650, DOI 10.1109/ISCA.2018.00060
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 493
EP 500
DI 10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00076
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Huang, HT
   Ni, LB
   Yu, H
AF Huang, Hantao
   Ni, Leibin
   Yu, Hao
BE Jiang, YL
   Tang, TA
   Huang, R
TI A 3D Multi-layer CMOS-RRAM Accelerator for Multi-layer Machine Learning
   (Invited)
SO 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED
   CIRCUIT TECHNOLOGY (ICSICT)
DT Proceedings Paper
CT 13th IEEE International Conference on Solid-State and Integrated-Circuit
   Technology (ICSICT)
CY OCT 25-28, 2016
CL Hangzhou, PEOPLES R CHINA
AB Fast machine learning is required for future real-time data analytics. This paper introduces a 3D multi-layer CMOS-RRAM accelerator for learning on neural network. Given input of buffered data hold on the layer of a RRAM memory, intensive matrix-vector multiplication can be firstly accelerated on the layer of a digitized RRAM-crossbar. The remaining algorithmic operations such as feature extraction and classifier training can be accelerated on the layer of CMOS ASIC with consideration of parallelism and pipeline. Experiment results have shown that such a 3D accelerator can significantly reduce training time with acceptable accuracy. Compared to 3D-CMOS-ASIC implementation, it can achieve 1.28x smaller area, 2.05x faster runtime and 12.4x energy reduction.
C1 [Huang, Hantao; Ni, Leibin; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM haoyu@ntu.edu.sg
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], IEEE ISSCC
   [Anonymous], IEEE ASP DAC
   [Anonymous], IEEE ASP DAC
   [Anonymous], IEEE DATE
   [Anonymous], 2015, MORE MOORE TECHNOLOG
   Chen YC, 2012, IEEE INT FERRO
   Coates A., 2011, AISTATS
   Franz Peter, 2015, 2015 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT). Proceedings, P1, DOI 10.1109/ISGT.2015.7131798
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kim DH, 2013, IEEE T VLSI SYST, V21, P862, DOI 10.1109/TVLSI.2012.2201760
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Lee H., 2008, IEEE EL DEV M
   Müller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022
NR 17
TC 1
Z9 1
U1 0
U2 2
PY 2016
BP 186
EP 188
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xu, HY
   Liu, DF
   Merkel, C
   Zuzak, M
AF Xu, Hongye
   Liu, Dongfang
   Merkel, Cory
   Zuzak, Michael
GP ACM
TI Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning
   Accelerators
SO PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2023, GLSVLSI 2023
DT Proceedings Paper
CT 33rd Great Lakes Symposium on VLSI (GLSVLSI)
CY JUN 05-07, 2023
CL Knoxville, TN
DE Logic Locking; Neural Trojan; Untrusted Foundry Problem; Machine
   Learning Accelerator
AB Logic locking has been proposed to safeguard intellectual property (IP) during chip fabrication. Logic locking techniques protect hardware IP by making a subset of combinational modules in a design dependent on a secret key that is withheld from untrusted parties. If an incorrect secret key is used, a set of deterministic errors is produced in locked modules, restricting unauthorized use. A common target for logic locking is neural accelerators, especially as machine-learning-as-a-service becomes more prevalent. In this work, we explore how logic locking can be used to compromise the security of a neural accelerator it protects. Specifically, we show how the deterministic errors caused by incorrect keys can be harnessed to produce neural-trojan-style backdoors. To do so, we first outline a motivational attack scenario where a carefully chosen incorrect key, which we call a trojan key, produces misclassifications for an attacker-specified input class in a locked accelerator. We then develop a theoretically-robust attack methodology to automatically identify trojan keys. To evaluate this attack, we launch it on several locked accelerators. In our largest benchmark accelerator, our attack identified a trojan key that caused a 74% decrease in classification accuracy for attacker-specified trigger inputs, while degrading accuracy by only 1.7% for other inputs on average.
C1 [Xu, Hongye; Liu, Dongfang; Merkel, Cory; Zuzak, Michael] Rochester Inst Technol, Rochester, NY 14623 USA.
RP Xu, HY (corresponding author), Rochester Inst Technol, Rochester, NY 14623 USA.
EM hx5239@rit.edu; dongfang.liu@rit.edu; cemeec@rit.edu; mjzeec@rit.edu
CR Chakraborty A, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218651
   Chakraborty A, 2020, IEEE T COMPUT AID D, V39, P1952, DOI 10.1109/TCAD.2019.2944586
   Clements Joseph, 2022, AAAI C ARTIFICIAL IN
   El Massad M, 2017, Arxiv, DOI arXiv:1703.10187
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Kamali H. M., 2022, ADV LOGIC LOCKING PR
   Liu K, 2018, LECT NOTES COMPUT SC, V11050, P273, DOI 10.1007/978-3-030-00470-5_13
   Liu Yingqi, 2019, ACM SIGSAC C COMPUTE
   Liu YT, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3446215
   Liu YT, 2020, INT SYM QUAL ELECT, P33, DOI [10.1109/isqed48828.2020.9137011, 10.1109/ISQED48828.2020.9137011]
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Rostami M, 2014, P IEEE, V102, P1283, DOI 10.1109/JPROC.2014.2335155
   Shakya B., 2020, IACR T CRYPTOGRAPHIC, P175
   Shamsi K, 2019, IEEE T INF FOREN SEC, V14, P347, DOI 10.1109/TIFS.2018.2850319
   Shinde PP, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Subramanyan P, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P137, DOI 10.1109/HST.2015.7140252
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie Yang, 2018, IEEE T COMPUTERAIDED
   Yan MJ, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2003
   Yasin M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1601, DOI 10.1145/3133956.3133985
   Yasin M, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P236, DOI 10.1109/HST.2016.7495588
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhou HT, 2019, IEEE-RAS INT C HUMAN, P359, DOI [10.1109/humanoids43949.2019.9035069, 10.1109/iccad45719.2019.8942076, 10.1109/Humanoids43949.2019.9035069]
   Zuzak M, 2021, DES AUT CON, P235, DOI 10.1109/DAC18074.2021.9586179
   Zuzak M, 2021, IEEE T COMPUT AID D, V40, P1531, DOI 10.1109/TCAD.2020.3025135
NR 27
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 351
EP 356
DI 10.1145/3583781.3590242
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ni, LB
   Huang, HT
   Yu, H
AF Ni, Leibin
   Huang, Hantao
   Yu, Hao
GP IEEE
TI A Memristor Network with Coupled Oscillator and Crossbar towards L2-norm
   based Machine Learning
SO PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL SYMPOSIUM ON NANOSCALE
   ARCHITECTURES (NANOARCH)
SE IEEE International Symposium on Nanoscale Architectures
DT Proceedings Paper
CT IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)
CY JUL 18-20, 2016
CL Beijing, PEOPLES R CHINA
AB This paper introduces a memristor-network based accelerator for L2-norm based machine learning. A coupled-memristor-oscillator network is developed for a L2-norm calculation; and a binary-memristor-crossbar network is developed to accelerate matrixvector multiplication. As such, one can map gradient-descent (of L2-norm) based on-line machine learning on the proposed memristor-network that is composed of coupled-oscillator (to sample L2-norm) and binary-crossbar (to digitize L2-norm). Experiment results have shown that such a memristor-network based accelerator can achieve significant power reduction and runtime speed-up for both training and testing compared to the conventional CMOS-CPU based implementation.
C1 [Ni, Leibin; Huang, Hantao; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM haoyu@ntu.edu.sg
CR Akinaga  H., 2010, P IEEE
   [Anonymous], 2013, MACHINE LEARNING ART
   Chiarulli DM, 2015, IEEE COMP SOC ANN, P125, DOI 10.1109/ISVLSI.2015.77
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jackson TC, 2015, IEEE J EM SEL TOP C, V5, P230, DOI 10.1109/JETCAS.2015.2433551
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lee H. Y., 2008, EL DEV M
   Lichman M., 2013, UCI MACHINE LEARNING
   Maffezzoni P, 2015, ELECTRON LETT, V51, P819, DOI 10.1049/el.2015.0025
   Ni L., 2016, DES AUT C AS S PAC A
   Shang Y, 2012, IEEE T CIRCUITS-I, V59, P1906, DOI 10.1109/TCSI.2011.2180441
   Sharma AA, 2015, IEEE T ELECTRON DEV, V62, P3857, DOI 10.1109/TED.2015.2475623
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang Y, 2016, IEEE T MOBILE COMPUT, V15, P1965, DOI 10.1109/TMC.2015.2483501
   Yogendra K., 2016, DES AUT C AS S PAC A
NR 16
TC 6
Z9 6
U1 0
U2 4
PY 2016
BP 179
EP 184
DI 10.1145/2950067.2950083
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Wang, Y
   Xu, J
   Han, YH
   Li, HW
   Li, XW
AF Wang, Ying
   Xu, Jie
   Han, Yinhe
   Li, Huawei
   Li, Xiaowei
GP ACM
TI DeepBurning: Automatic Generation of FPGA-based Learning Accelerators
   for the Neural Network Family
SO 2016 ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 53rd ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 05-09, 2016
CL Austin, TX
AB Recent advances in Neural Networks (NN) arc enabling more and more innovative applications. As an energy-efficient hardware solution, machine learning accelerators for CNNs or traditional ANNs are also gaining popularity in the area of embedded vision, robotics and cyberphysics. However, the design parameters of NN models vary significantly from application to application. Hence, it's hard to provide one general and highly-efficient hardware solution to accommodate all of them, and it is also impractical for the domain-specific developers to customize their own hardware targeting on a specific NN model. To deal with this dilemma, this study proposes a design automation tool, DeepBurning, allowing the application developers to build from scratch learning accelerators that targets their specific NN models with custom configurations and optimized performance. DeepBurning includes a RTL-level accelerator generator and a coordinated compiler that generates the control flow and data layout under the user-specified constraints. The results can be used to implement FPGA-based NN accelerator or help generate chip design for early design stage. In general, DeepBurning supports a large family of NN models, and greatly simplifies the design flow of NN accelerators for the machine learning or Al application developers. The evaluation shows that the generated learning accelerators burnt to our FPGA board exhibit great power efficiency compared to state-of-the-art FPGA-based solutions.
C1 [Wang, Ying; Xu, Jie; Han, Yinhe; Li, Huawei; Li, Xiaowei] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
RP Wang, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
EM wangying2009@ict.ac.cn; xujie@ict.ac.cn; yinhes@ict.ac.cn;
   lihuawei@ict.ac.cn; lxw@ict.ac.cn
CR [Anonymous], 2014, P ASPLOS
   [Anonymous], P FPGA
   Beigel R., 1990, IEEE T COMPUTERS
   Esmaeilzadeh, 2012, P MICRO
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jia Y, 2014, ACM P MULT
   Krizhevsky A., 2012, ADV COND MATTER PHYS, DOI DOI 10.1145/3065386
   Ouyang W., 2015, P CVPR
   Pan Y., 2015, JOINTLY MODELING EMB
   Peemen M., 2013, P ICCD
   Vapnik V., 2015, YAND C MACH LEARN PR
NR 11
TC 141
Z9 154
U1 1
U2 15
PY 2016
DI 10.1145/2897937.2898003
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Rothmann, M
   Porrmann, M
AF Rothmann, Marc
   Porrmann, Mario
BE Pericas, M
   Pnevmatikatos, D
   Trancoso, PPM
   Sourdis, I
TI FAQ: A Flexible Accelerator for Q-Learning with Configurable Environment
SO 2022 IEEE 33RD INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 33rd International Conference on Application-specific Systems,
   Architectures and Processors (ASAP)
CY JUL 12-14, 2022
CL Gothenburg, SWEDEN
DE Domain-specific architectures; Reconfigurable hardware; Reinforcement
   Learning; Machine Learning
AB Reinforcement Learning is an area of machine learning that is concerned with optimizing the behavior of an agent in an environment by maximizing cumulative rewards. This can be done with classical reinforcement learning algorithms such as Q-Learning and SARSA. This paper presents FAQ, a flexible FPGA-based accelerator for the Q-Learning algorithm. The architecture of the accelerator can be configured in multiple ways, like adjusting the bit width of Q-values or changing the number of pipeline stages. The evaluation shows that FAQ achieves 249% higher throughput than state-of-the-art FPGA implementations while decreasing DSP and BRAM utilization. Additionally, a software-configurable environment was implemented, and the whole system was tested on an Ultra96-V2 development board utilizing the PYNQ framework. Compared to a CPU implementation, FAQ is more than 13 times faster, including communication overhead caused by transferring the environment onto the FPGA and reading the resulting Q-table.
C1 [Rothmann, Marc; Porrmann, Mario] Osnabrueck Univ, Comp Engn Grp, Osnabruck, Germany.
RP Rothmann, M (corresponding author), Osnabrueck Univ, Comp Engn Grp, Osnabruck, Germany.
EM mrothmann@uni-osnabrueck.de; mporrmann@uni-osnabrueck.de
CR Bernstein A., 2018, REINFORCEMENT LEARNI, P258
   Cho H, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P499, DOI 10.1145/3297858.3304058
   Gankidi P. R, 2016, THESIS ARIZONA STATE
   Gankidi P. R., 2017, AEROSP CONF PROC, P1
   Guo C, 2019, IEEE INT CONF ASAP, P91, DOI 10.1109/ASAP.2019.00-24
   Nguyen H, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P590, DOI 10.1109/IRC.2019.00120
   Li MJ, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEMS (ICISS 2019), P232, DOI 10.1145/3322645.3322693
   Meng Y, 2020, IEEE SYM PARA DISTR, P107, DOI 10.1109/IPDPSW50202.2020.00024
   Meng Y, 2020, ANN IEEE SYM FIELD P, P19, DOI 10.1109/FCCM48280.2020.00012
   Prabha VL, 2007, EURASIP J EMBED SYST, DOI 10.1155/2007/65478
   Rothmann M, 2022, IEEE ACCESS, V10, P13753, DOI 10.1109/ACCESS.2022.3146518
   Rummery Gavin Adrian, 1994, ON LINE Q LEARNING U
   Shao SJ, 2018, IEEE INT CONF ASAP, P135
   Shaozhen Song, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092353
   Silva LM, 2018, IEEE IJCNN
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Spanò S, 2019, IEEE ACCESS, V7, P186340, DOI 10.1109/ACCESS.2019.2961174
   Su Jiang, 2017, ACM SIGARCH COMPUTER, V44, P68, DOI 10.1145/3039902.3039915
   Sutton R. S., 2015, REINFORCEMENT LEARNI, V2nd
   Watanabe H, 2021, 2021 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P96, DOI 10.1109/IPDPSW52791.2021.00022
   Watkins C.J.C.H., 1989, THESIS U CAMBRIDGE
   Xilinx, PYNQ FRAM
NR 22
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 106
EP 114
DI 10.1109/ASAP54787.2022.00026
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Marino, R
   Quintero, S
   Lanza-Gutierrez, JM
   Riesgo, T
   Holgado, M
   Portilla, J
   de la Torre, E
AF Marino, Rodrigo
   Quintero, Sergio
   Lanza-Gutierrez, Jose M.
   Riesgo, Teresa
   Holgado, Miguel
   Portilla, Jorge
   de la Torre, Eduardo
GP IEEE
TI Hardware Accelerator for Ethanol Detection in Water Media based on
   Machine Learning Techniques
SO 2019 XXXIV CONFERENCE ON DESIGN OF CIRCUITS AND INTEGRATED SYSTEMS
   (DCIS)
SE Conference on Design of Circuits and Integrated Systems DCIS
DT Proceedings Paper
CT 34th Conference on Design of Circuits and Integrated Systems (DCIS)
CY NOV 20-22, 2019
CL Bilbao, SPAIN
DE Smart Farming; Optical Sensing; Machine Learning; Feature Extraction;
   SoPC
ID NEAR-INFRARED SPECTROSCOPY; RESONANT NANOPILLARS; PREDICTION; ARRAYS;
   REGRESSION
AB In the last years, the Industry 4.0 paradigm is gaining relevance in the agro-food industry, leading to Smart Farming. One of the applications in the Smart Farming domain is the advanced chemical analysis in process monitoring using distributed, low-cost embedded systems. Optical sensing technology is used in conjunction with machine learning techniques for this advanced analysis. From the embedded system perspective, it might be required to propose a method for the implementation of machine learning techniques in heterogeneous platforms. This paper focuses on implementing Machine Learning techniques in a System on Programmable Chip, based on an FPGA and ARM processors. As a use case, we mimic water pollution by ethanol. Thus, the application might determine the percentage of ethanol of the water during run-time. As a result, this paper provides a methodology for implementing a machine learning technique for ethanol prediction using an FPGA, and the study of its parameters as resource utilization and accelerator latency for the architecture proposed.
C1 [Marino, Rodrigo; Riesgo, Teresa; Portilla, Jorge; de la Torre, Eduardo] Univ Politecn Madrid, Ctr Elect Ind, Madrid, Spain.
   [Quintero, Sergio; Holgado, Miguel] Univ Politecn Madrid, Ctr Tecnol Biomed, Madrid, Spain.
   [Lanza-Gutierrez, Jose M.] Univ Carlos III, Dept Tecnol Elect, Madrid, Spain.
RP Marino, R (corresponding author), Univ Politecn Madrid, Ctr Elect Ind, Madrid, Spain.
EM teresa.riesgo@upm.es; miguel.holgado@upm.es; jm.lanza@ing.uc3m.es
CR Canalejas-Tejero V, 2018, OPT MATER EXPRESS, V8, P1082, DOI 10.1364/OME.8.001082
   Chou JS, 2018, IEEE T IND INFORM, V14, P3132, DOI 10.1109/TII.2018.2794389
   Estelles-Lopez L, 2017, FOOD RES INT, V99, P206, DOI 10.1016/j.foodres.2017.05.013
   Fernández F, 2017, SENSOR ACTUAT B-CHEM, V244, P323, DOI 10.1016/j.snb.2016.12.140
   Han J, 2012, MOR KAUF D, P1
   Hernández AL, 2018, SENSOR ACTUAT B-CHEM, V259, P956, DOI 10.1016/j.snb.2017.11.029
   Hernández AL, 2016, OPT LETT, V41, P5430, DOI 10.1364/OL.41.005430
   Hernandez AL, 2015, OPT LETT, V40, P2370, DOI 10.1364/OL.40.002370
   Lambrou TP, 2014, IEEE SENS J, V14, DOI 10.1109/JSEN.2014.2316414
   Lu YY, 2017, J AM HEART ASSOC, V6, DOI 10.1161/JAHA.116.004168
   Morellos A, 2016, BIOSYST ENG, V152, P104, DOI 10.1016/j.biosystemseng.2016.04.018
   Mu KX, 2018, CHEMOMETR INTELL LAB, V179, P46, DOI 10.1016/j.chemolab.2018.06.003
   Pilloni V, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10030024
   Puiu A, 2015, SENSORS-BASEL, V15, P14415, DOI 10.3390/s150614415
   Quintero S, 2019, IEEE ACCESS, V7, P129778, DOI 10.1109/ACCESS.2019.2939576
   Skou PB, 2017, APPL SPECTROSC, V71, P410, DOI 10.1177/0003702816654165
   Sundmaeker H., 2016, DIGITISING IND INTER, P129
   Wolfert S, 2017, AGR SYST, V153, P69, DOI 10.1016/j.agsy.2017.01.023
   Zulkifli SN, 2018, SENSOR ACTUAT B-CHEM, V255, P2657, DOI 10.1016/j.snb.2017.09.078
NR 19
TC 1
Z9 1
U1 1
U2 2
PY 2019
DI 10.1109/dcis201949030.2019.8959937
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Cui, XW
   Feng, WC
AF Cui, Xuewen
   Feng, Wu-chun
GP Assoc Comp Machinery
TI Iterative Machine Learning (IterML) for Effective Parameter Pruning and
   Tuning in Accelerators
SO CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON
   COMPUTING FRONTIERS
DT Proceedings Paper
CT 16th ACM International Conference on Computing Frontiers (CF)
CY APR 30-MAY 02, 2019
CL Alghero, ITALY
DE GPU; performance; thread block; machine learning; random forest;
   classification and regression trees (CART); support vector machine
   (SVM); multi-layer perceptron (MLP); k-nearest neighbor (KNN)
ID MODEL; PERFORMANCE
AB With the rise of accelerators (e.g., GPUs, FPGAs, and APUs) in computing systems, the parallel computing community needs better tools and mechanisms with which to productively extract performance. While modern compilers provide flags to activate different optimizations to improve performance, the effectiveness of such automated optimization depends on the algorithm and its mapping to the underlying accelerator architecture. Currently, however, extracting the best performance from an algorithm on an accelerator requires significant expertise and manual effort to exploit both spatial and temporal sharing of computing resources in order to improve overall performance. In particular, maximizing the performance on an algorithm on an accelerator requires extensive hyperparameter (e.g., thread-block size) selection and tuning. Given the myriad of hyperparameter dimensions to optimize across, the search space of optimizations is generally extremely large, making it infeasible to exhaustively evaluate each optimization configuration.
   This paper proposes an approach that uses statistical analysis with iterative machine learning (IterML) to prune and tune hyper parameters to achieve better performance. During each iteration, we leverage machine-learning (ML) models to provide pruning and tuning guidance for the subsequent iterations. We evaluate our IterML approach on the selection of the GPU thread-block size across many benchmarks running on an NVIDIA P100 or V100 GPU. The experimental results show that our IterML approach can significantly reduce (i.e., improve) the search effort by 40% to 80%.
C1 [Cui, Xuewen; Feng, Wu-chun] Virginia Tech, Blacksburg, VA 24061 USA.
RP Cui, XW (corresponding author), Virginia Tech, Blacksburg, VA 24061 USA.
EM xuewenc@vt.edu; wfeng@vt.edu
CR [Anonymous], 1994, TOP500 SUPERCOMPUTER
   Choi JW, 2010, ACM SIGPLAN NOTICES, V45, P115, DOI 10.1145/1837853.1693471
   Cui XW, 2017, INT PARALL DISTRIB P, P575, DOI 10.1109/IPDPS.2017.96
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Hou KX, 2017, ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2017, P107, DOI 10.1145/3075564.3075583
   Hou KX, 2018, INT PARALL DISTRIB P, P276, DOI 10.1109/IPDPS.2018.00037
   Hou K, 2017, IEEE SYM PARA DISTR, P713, DOI 10.1109/IPDPSW.2017.155
   Jia WH, 2013, INT CONFER PARA, P257, DOI 10.1109/PACT.2013.6618822
   Johnson N, 2013, EPCC OPENACC BENCHMA
   Joseph PJ, 2006, INT S HIGH PERF COMP, P99, DOI 10.1109/HPCA.2006.1598116
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lee RB, 2018, INT CON DISTR COMP S, P1270, DOI 10.1109/ICDCS.2018.00126
   Li WQ, 2015, IEEE ACM INT SYMP, P1092, DOI 10.1109/CCGrid.2015.105
   Li Yan, 2017, P INT C HIGH PERF CO, V42
   Li YN, 2009, LECT NOTES COMPUT SC, V5544, P884
   Mittal Sparsh, 2015, ACM Computing Surveys, V47, DOI 10.1145/2636342
   Tran NP, 2017, CLUSTER COMPUT, V20, P2133, DOI 10.1007/s10586-017-1003-4
   Pouchet L.-N., 2012, POLYBENCH POLYHEDRAL
   Ryoo S, 2008, INT SYM CODE GENER, P195
NR 19
TC 3
Z9 3
U1 0
U2 2
PY 2019
BP 16
EP 23
DI 10.1145/3310273.3321563
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Zhou, SY
   Guo, Q
   Du, ZD
   Liu, DF
   Chen, TS
   Li, L
   Liu, SL
   Zhou, JH
   Temam, O
   Feng, XB
   Zhou, XH
   Chen, YJ
AF Zhou, Shengyuan
   Guo, Qi
   Du, Zidong
   Liu, Daofu
   Chen, Tianshi
   Li, Ling
   Liu, Shaoli
   Zhou, Jinhong
   Temam, Olivier
   Feng, Xiaobing
   Zhou, Xuehai
   Chen, Yunji
TI ParaML: A Polyvalent Multicore Accelerator for Machine Learning
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Neural networks; Machine learning; Testing; Support vector machines;
   Linear regression; Computers; Computer architecture; Accelerator;
   machine learning (ML) techniques; multicore accelerator
AB In recent years, machine learning (ML) techniques are proven to be powerful tools in various emerging applications. Traditionally, ML techniques are processed on general-purpose CPUs and GPUs, but their energy efficiencies are limited due to their excessive support for flexibility. As an efficient alternative to CPUs/GPUs, hardware accelerators are still limited as they often accommodate only a single ML technique (family). However, different problems may require different ML techniques, which implies that such accelerators may achieve poor learning accuracy or even be ineffective. In this paper, we present a polyvalent accelerator architecture integrated with multiple processing cores, called ParaML, which accommodates ten representative ML techniques, including k-means, k-nearest neighbors (k-NN), naive Bayes (NB), support vector machine (SVM), linear regression (LR), classification tree (CT), deep neural network (DNN), learning vector quantization (LVQ), parzen window (PW), and principal component analysis (PCA). Benefited from our thorough analysis on computational primitives and locality properties of different ML techniques, the single-core ParaML can perform up to 1056 GOP/s (e.g., additions and multiplications) in an area of 3.51 mm(2) and consumes 596 mW only, estimated by ICC and PrimeTime PX with post-synthesis netlist, respectively. Compared with the NVIDIA K20M GPU (28-nm process), the single-core ParaML (65-nm process) is 1.21x faster, and can reduce the energy by 137.93x. We also compare the single-core ParaML with other accelerators. Compared with PRINS, single-core ParaML achieves 72.09x and 2.57x energy benefit for k-NN and k-means, respectively, and speeds up each query in k-NN by 44.76x. Compared with EIE, the single-core ParaML achieves 5.02x speedup and 4.97x energy benefit with 11.62x less area when evaluating with dense DNN. Compared with TPU, the single-core ParaML achieves 2.45x better power efficiency (5647 Gop/W versus 2300 Gop/W) with 321.36x less area. Compared to the single-core version, the 8-core ParaML will further improve the speedup up to 3.98x with an area of 13.44 mm(2) and a power of 2036 mW.
C1 [Zhou, Shengyuan; Guo, Qi; Du, Zidong; Liu, Daofu; Chen, Tianshi; Liu, Shaoli; Zhou, Jinhong; Chen, Yunji] Chinese Acad Sci, Inst Comp Technol, Intelligent Processor Res Ctr, Beijing 100190, Peoples R China.
   [Zhou, Shengyuan; Chen, Yunji] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China.
   [Guo, Qi; Du, Zidong; Liu, Daofu; Chen, Tianshi; Liu, Shaoli; Zhou, Jinhong] Cambricon Technol Corp Ltd, Beijing 100191, Peoples R China.
   [Chen, Tianshi; Chen, Yunji] CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China.
   [Li, Ling] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
   [Temam, Olivier] Inria Scalay, F-91120 Palaiseau, France.
   [Feng, Xiaobing] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Zhou, Xuehai] Univ Sci & Technol China, Hefei 230026, Peoples R China.
RP Guo, Q (corresponding author), Chinese Acad Sci, Inst Comp Technol, Intelligent Processor Res Ctr, Beijing 100190, Peoples R China.
EM zhousy@ict.ac.cn; guoqi@ict.ac.cn; duzidong@cambricon.com;
   liudaofu@cambricon.com; chentianshi@ict.ac.cn; liling@ict.ac.cn;
   liushaoli@cambricon.com; zhoujinhong@cambricon.com;
   olivier.temam@inria.fr; fxb@ict.ac.cn; xhzhou@ustc.edu.cn; cyj@ict.ac.cn
CR Al Maashri A, 2012, DES AUT CON, P579
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Chan E., 2013, ALGORITHMIC TRADING, V625
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen M., 2014, BIG DATA RELATED TEC
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Coutinho B, 2009, INT SYM COMP ARCHIT, P11, DOI 10.1109/SBAC-PAD.2009.26
   da S AG, 2003, 16TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN, SBCCI 2003, PROCEEDINGS, P99
   Edwards A. L., 1976, INTRO LINEAR REGRESS
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Garcia Vincent, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563100
   Golub G. H., 1983, MATRIX COMPUTATIONS
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Heemskerk Jan NH, 1995, NEUROCOMPUTERS BRAIN
   Hussain H. M., 2011, Proceedings of the 2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), P248, DOI 10.1109/AHS.2011.5963944
   Hussain Z., 2008, THESIS
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaplan R, 2018, IEEE T NANOTECHNOL, V17, P889, DOI 10.1109/TNANO.2018.2799872
   Kohonen, 1995, HDB BRAIN THEORY NEU, P175, DOI DOI 10.1007/978-3-642-97610-0_6
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Majumdar A, 2011, IEEE EMBED SYST LETT, V3, P42, DOI 10.1109/LES.2010.2100802
   Manolakos E. S., 2010, 2010 IEEE International Symposium on Circuits and Systems. ISCAS 2010, P4133, DOI 10.1109/ISCAS.2010.5537602
   Maruyama T, 2006, INT C PATT RECOG, P816
   Papadonikolakis M, 2010, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2010.39
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saif H, 2012, P 2 WORKSH MAK SENS, P2
   Schmidhuber J., 2011, P 22 INT JOINT C ART
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Temam O, 2010, CONF PROC INT SYMP C, P349, DOI 10.1145/1816038.1816008
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Witten DM, 2010, J AM STAT ASSOC, V105, P713, DOI 10.1198/jasa.2010.tm09415
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Yeh Y.-J., 2007, P SCAND C IM AN
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
NR 47
TC 3
Z9 3
U1 0
U2 10
PD SEPT
PY 2020
VL 39
IS 9
BP 1764
EP 1777
DI 10.1109/TCAD.2019.2927523
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Schram, M
   Rajput, K
   Somayaji, NK
   Li, P
   St John, J
   Sharma, H
AF Schram, Malachi
   Rajput, Kishansingh
   Somayaji, N. S. Karthik
   Li, Peng
   St John, Jason
   Sharma, Himanshu
TI Uncertainty aware machine-learning-based surrogate models for particle
   accelerators: Study at the Fermilab Booster Accelerator Complex
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
ID NEURAL-NETWORKS; QUANTIFICATION
AB Standard deep learning methods, such as Ensemble Models, Bayesian Neural Networks, and Quantile Regression Models provide estimates of prediction uncertainties for data-driven deep learning models. However, they can be limited in their applications due to their heavy memory, inference cost, and ability to properly capture out-of-distribution uncertainties. Additionally, some of these models require post-training calibration that limits their ability to be used for continuous learning applications. In this paper, we present a new approach to provide prediction with calibrated uncertainties that includes out-of-distribution contributions and compare it to standard methods on the Fermi National Accelerator Laboratory (FNAL) Booster accelerator complex.
C1 [Schram, Malachi; Rajput, Kishansingh] Thomas Jefferson Natl Accelerator Lab, Newport News, VA 23606 USA.
   [Somayaji, N. S. Karthik; Li, Peng] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [St John, Jason] Fermilab Natl Accelerator Lab, Batavia, IL 60510 USA.
   [Sharma, Himanshu] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
RP Schram, M (corresponding author), Thomas Jefferson Natl Accelerator Lab, Newport News, VA 23606 USA.
EM schram@jlab.org
CR Abdar M, 2021, INFORM FUSION, V76, P243, DOI 10.1016/j.inffus.2021.05.008
   Adelmann A, 2019, SIAM-ASA J UNCERTAIN, V7, P383, DOI 10.1137/16M1061928
   Amundson J, 2014, COMPUT SCI ENG, V16, P32, DOI 10.1109/MCSE.2014.76
   Blokland W, 2021, Arxiv, DOI arXiv:2110.12006
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Chung Y., 2021, ARXIV
   Cortes Corinna, 2009, COMMUN ACM, V22
   Davies A, 2018, WIRED GUIDE SELF DRI
   DeepMind, 2018, SAF 1 AUT DAT CTR CO
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Gal Y, 2016, PR MACH LEARN RES, V48
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Hirlaender S., 2020, ARXIV
   Kafkes D., 2021, ARXIV
   Kafkes D, 2021, DATA, V6, DOI 10.3390/data6040042
   Kendall A., 2017, ADV NEURAL INFORM PR, V30, P5574
   Knight Will, 2018, THIS FACTORY ROBOT L
   Koenker R, 2005, ECONOMETRIC SOC MONO, DOI [DOI 10.1017/CBO9780511754098, 10.1017/CBO9780511754098]
   Langston Jennifer, 2018, IS BUILDING BETTER G
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li SC, 2021, INFORMATION, V12, DOI 10.3390/info12030121
   Liu J, 2020, ADV NEURAL INFORM PR, V33, P7498
   Minorsky N., 1922, J AM SOC NAVAL ENG, V34, P280, DOI [DOI 10.1111/J.1559-3584.1922.TB04958.X, 10.1111/j.1559-3584.1922.tb04958.x]
   Mishra AA, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.114601
   Powers T., 2019, P 19 INT C RF SUP SR, P763, DOI 10.18429/JACoWSRF2019-WETEB3
   Rahimi A., 2007, ADV NEURAL INFORM PR, V20
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rescic M, 2022, NUCL INSTRUM METH A, V1025, DOI 10.1016/j.nima.2021.166064
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Sanchez-Gonzalez A, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15461
   Scheinker A, 2021, J INSTRUM, V16, DOI 10.1088/1748-0221/16/10/P10008
   Scheinker A., 2020, LAUR1932526
   Scheinker A., 2023, J PHYS C SER, V2420
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   St John J, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.104601
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
   Wilson A. G., 2015, P 19 INT C ART INT S, V51
   ZIEGLER JG, 1993, J DYN SYST-T ASME, V115, P220, DOI 10.1115/1.2899060
NR 43
TC 0
Z9 0
U1 3
U2 3
PD APR 21
PY 2023
VL 26
IS 4
AR 044602
DI 10.1103/PhysRevAccelBeams.26.044602
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Appel, S
   Geithner, W
   Reimann, S
   Sapinski, M
   Singh, R
   Vilsmeier, D
AF Appel, Sabrina
   Geithner, Wolfgang
   Reimann, Stephan
   Sapinski, Mariusz
   Singh, Rahul
   Vilsmeier, Dominik
TI Application of nature-inspired optimization algorithms and machine
   learning for heavy-ion synchrotrons
SO INTERNATIONAL JOURNAL OF MODERN PHYSICS A
DT Article; Proceedings Paper
CT 10th Conference on Charged Particle Optics (CPO) / 13th International
   Conference on Computational Accelerator Physics (/ICAP)
CY OCT 17-21, 2018
CL Key West, FL
DE Automated optimization; nature-inspired optimization methods; machine
   learning; signal reconstruction
ID INJECTION OPTIMIZATION
AB The application of machine learning and nature-inspired optimization methods, like for example genetic algorithms (GA) and particle swarm optimization (PSO) can be found in various scientific/technical areas. In recent years, these approaches are finding application in accelerator physics to a greater extent. In this paper, nature-inspired optimization as well as the machine learning will be shortly introduced and their application to the accelerator facility at GSI/FAIR will be presented. For the heavy-ion synchrotron SIS18 at GSI, the multi-objective GA/PSO optimization resulted in a significant improvement of multi-turn injection performance and subsequent transmission for intense beams. An automated injection optimization with genetic algorithms at the CRYRING@ESR ion storage ring has been performed. The usage of machine learning for a beam diagnostic application, where reconstruction of space-charge distorted beam profiles from ionization profile monitors is performed, will also be shown. First results and the experience gained will be presented.
C1 [Appel, Sabrina; Geithner, Wolfgang; Reimann, Stephan; Sapinski, Mariusz; Singh, Rahul] GSI Helmoltzzentrum Schwerionenforsch GmbH, Darmstadt, Germany.
   [Vilsmeier, Dominik] Goethe Univ Frankfurt, Frankfurt, Germany.
RP Appel, S (corresponding author), GSI Helmoltzzentrum Schwerionenforsch GmbH, Darmstadt, Germany.
EM s.appel@gsi.de; w.geithner@gsi.de; s.reimann@gsi.de; m.sapinski@gsi.de;
   r.singh@gsi.de; d.vilsmeier@gsi.de
CR Appel S, 2017, NUCL INSTRUM METH A, V866, P36, DOI 10.1016/j.nima.2017.05.041
   Appel S, 2017, NUCL INSTRUM METH A, V852, P73, DOI 10.1016/j.nima.2016.11.069
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Geithner W, 2017, HYPERFINE INTERACT, V238, DOI 10.1007/s10751-016-1383-5
   Geithner W, 2018, P IPAC 18 VANC CAN, P4712, DOI DOI 10.18429/JACOW-IPAC2018-THPML028
   Geron A., HANDS ON MACHINE LEA
   Gorda O, 2015, PHYS SCRIPTA, VT166, DOI 10.1088/0031-8949/2015/T166/014043
   KLEFFNER C, 2018, P LINAC2018, P00787
   Konak A, 2006, RELIAB ENG SYST SAFE, V91, P992, DOI 10.1016/j.ress.2005.11.018
   Levasseur  S., 2018, P 9 INT PART ACC C I, P2361
   Mustafin E, 2003, NUCL INSTRUM METH A, V510, P199, DOI 10.1016/S0168-9002(03)01811-4
   Pang X, 2014, NUCL INSTRUM METH A, V741, P124, DOI 10.1016/j.nima.2013.12.042
   Sapinski  M., 2018, P 61 ICFA ADV BEAM D, P410
   Shishlo A, 2015, PROCEDIA COMPUT SCI, V51, P1272, DOI 10.1016/j.procs.2015.05.312
   Spiller P.J, 2008, P EPAC08 11 PART ACC, P3608
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 25
TC 0
Z9 0
U1 0
U2 5
PD DEC 30
PY 2019
VL 34
IS 36
SI SI
AR 1942019
DI 10.1142/S0217751X19420193
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Taylor, B
   Zheng, QL
   Li, ZR
   Li, SY
   Chen, YR
AF Taylor, Brady
   Zheng, Qilin
   Li, Ziru
   Li, Shiyu
   Chen, Yiran
TI Processing-in-Memory Technology for Machine Learning: From Basic to ASIC
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Processing-in-memory; machine learning accelerator; analogcomputation;
   dataflow optimization
ID UNIT-MACRO; COMPUTATION; SRAM; ACCELERATOR
AB Due to the need for computing models that can process large quantities of data efficiently and with high throughput in many state-of-the-art machine learning algorithms, the processing-in-memory (PIM) paradigm is emerging as a potential replacement for standard digital architectures on these workloads. In this tutorial, we review the progress of PIM technology in recent years, at both the circuit and architecture level. We further present an analysis of when and how PIM technology surpasses the performance of conventional architectures. Finally, we outline our vision for the future of PIM technology.
C1 [Taylor, Brady; Zheng, Qilin; Li, Ziru; Li, Shiyu; Chen, Yiran] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27707 USA.
RP Taylor, B (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27707 USA.
EM brady.g.taylor@duke.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Chen F, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317936
   Chen ZY, 2021, IEEE J SOLID-ST CIRC, V56, P1924, DOI 10.1109/JSSC.2021.3056447
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chih YD, 2021, ISSCC DIG TECH PAP I, V64, P252, DOI 10.1109/ISSCC42613.2021.9365766
   Chiu YC, 2020, IEEE J SOLID-ST CIRC, V55, P2790, DOI 10.1109/JSSC.2020.3005754
   Dhar A, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P102, DOI 10.1109/MICRO50266.2020.00021
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Gupta S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240811
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu M, 2012, IEEE IJCNN
   Hua QL, 2019, ADV SCI, V6, DOI 10.1002/advs.201900024
   Jiang HQ, 2019, PUBLIC HEALTH NUTR, V22, P1138, DOI 10.1017/S1368980018003506
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim H, 2019, PROC EUR SOLID-STATE, P345, DOI 10.1109/esscirc.2019.8902824
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Lee S, 2021, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA52012.2021.00013
   Li BX, 2013, I SYMPOS LOW POWER E, P242, DOI 10.1109/ISLPED.2013.6629302
   Li ZR, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218578
   Liu BY, 2014, ICCAD-IEEE ACM INT, P63, DOI 10.1109/ICCAD.2014.7001330
   Liu CC, 2015, DES AUT CON, DOI 10.1145/2744769.2744783
   Liu CC, 2016, IEEE COMP SOC ANN, P110, DOI 10.1109/ISVLSI.2016.46
   Merced-Grafals EJ, 2016, NANOTECHNOLOGY, V27, DOI 10.1088/0957-4484/27/36/365202
   Papistas I. A., 2021, 2021 IEEE CUST INT C, P1, DOI DOI 10.1109/CICC51472.2021.9431575
   Park J, 2022, IEEE J SOLID-ST CIRC, V57, P965, DOI 10.1109/JSSC.2021.3103603
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shirinzadeh S, 2018, IEEE T COMPUT AID D, V37, P1422, DOI 10.1109/TCAD.2017.2750064
   Si X, 2021, IEEE J SOLID-ST CIRC, V56, P2817, DOI 10.1109/JSSC.2021.3073254
   Si X, 2020, IEEE J SOLID-ST CIRC, V55, P189, DOI 10.1109/JSSC.2019.2952773
   Song LH, 2019, CCF T HIGH PERFORM C, V1, P196, DOI 10.1007/s42514-019-00014-8
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Ueyoshi K., 2022, 2022 IEEE INT SOLID, V1
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Wu P.-C., 2022, IEEE INT SOLID STATE, V65, P1
   Yan Bonan, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P188, DOI 10.1109/ISSCC42614.2022.9731545
   Yan B., 2020, P 39 INT C COMP AID, P1
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yan BN, 2016, IEEE INT SYMP CIRC S, P1390, DOI 10.1109/ISCAS.2016.7527509
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Zhang Grace Li, 2020, GLSVLSI '20. Proceedings of the 2020 Great Lakes Symposium on VLSI, P33, DOI 10.1145/3386263.3407579
   Zheng QL, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415666
   Zheng QL, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218590
   Zhou JT, 2014, IEEE T ELECTRON DEV, V61, P1369, DOI 10.1109/TED.2014.2310200
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 48
TC 0
Z9 0
U1 4
U2 24
PD JUN
PY 2022
VL 69
IS 6
BP 2598
EP 2603
DI 10.1109/TCSII.2022.3168404
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kuo, CY
   Lee, CC
   Lee, YL
   Liou, SC
   Lee, JC
   Su, ECY
   Chen, YW
AF Kuo, Chao-Yang
   Lee, Cheng-Chun
   Lee, Yuh-Lin
   Liou, Shueh-Chun
   Lee, Jia-Cheng
   Su, Emily Chia-Yu
   Chen, Yi-Wei
TI Visual light perceptions caused by medical linear accelerator: Findings
   of machine-learning algorithms in a prospective questionnaire-based
   case-control study (vol 16, e0247597, 2021)
SO PLOS ONE
DT Correction
CR Kuo CY, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247597
NR 1
TC 0
Z9 0
U1 0
U2 0
PD MAY 27
PY 2021
VL 16
IS 5
AR e0252634
DI 10.1371/journal.pone.0252634
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU El-Ghety, HS
   Emam, I
   Ali, AM
AF El-Ghety, Hamed S.
   Emam, Ismail
   Ali, AbdelMagid M.
TI Performance Evaluation of Different Supervised Machine Learning
   Algorithms in Predicting Linear Accelerator Multileaf Collimator
   Positioning's Accuracy Problem
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
DT Article
DE Linear accelerators; logistic regression; performance evaluation;
   prediction methods; supervised learning
AB Oncology is one of the businesses that employs Machine Learning to automate quality assurance tests so that errors and defects can be reduced, avoided, or eliminated as much as possible during tumor therapy using a Linear Accelerator with MultiLeaf Collimator (Linac MLC). The majority of Machine Learning applications have used supervised learning algorithms rather than unsupervised learning algorithms. However, in most cases, there is a clear bias in deciding which supervised machine learning algorithm to use. And prediction findings may be less accurate as a result of this bias. As a result, in this study, an evidence is presented for a novel application of Logistic Regression technique to predict Linac MLC positioning accuracy, which achieved 98.68 percent prediction accuracy with robust and consistent performance across several sets of Linac data. this evidence was obtained by comparing the performance of various supervised machine learning algorithms (i.e. Logistic Regression, Decision Tree, Support Vector Machine, Random Forest, Naive Bayes, and K-Nearest Neighbor) in the prediction of Linac MLC's positioning accuracy problem using leaves' positioning displacement datasets with labelled results as training and test datasets. For each method, two parameters were used to evaluate performance: prediction accuracy and the receiver operating characteristics curve. Based on that evaluation, the right selection sequence was proposed for supervised Machine Learning algorithms in order to achieve near-optimal prediction performance for Linac MLC's leaf positioning accuracy problem. As a result, the selection bias, as well as the negative side effects (i.e. ineffective preventive maintenance plan for Linac MLC to avoid and solve causes of inaccurate leaf displacement such as motor fatigue and stuck problems) could have occurred were successfully avoided.
C1 [El-Ghety, Hamed S.; Ali, AbdelMagid M.] Aswan Univ, Fac Engn, Elect Engn Dept, Aswan, Egypt.
   [Emam, Ismail] Shams Univ, Fac Med, Oncol Dept, Cairo, Egypt.
RP El-Ghety, HS (corresponding author), Aswan Univ, Fac Engn, Elect Engn Dept, Aswan, Egypt.
CR [Anonymous], MACH LEARN
   [Anonymous], ELEKTA USER MANUALS
   [Anonymous], 2013, MACHINE LEARNING ART
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Dean JA, 2016, RADIOTHER ONCOL, V120, P21, DOI 10.1016/j.radonc.2016.05.015
   El Naqa I, 2015, MACHINE LEARNING RAD, P39
   El Naqa I, 2009, PHYS MED BIOL, V54, pS9, DOI 10.1088/0031-9155/54/18/S02
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Han Jiawei, 2010, DATA MINING CONCEPTS, P291
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1, DOI 10.1002/9781118548387
   Lee Suk, 2017, RADIOTHERAPY, P175
   Mohamed A. E., 2017, INT J APPL SCI TECHN, V7
   Novakovic J.D., 2017, THEORY APPL MATH COM, V7, P39, DOI DOI 10.1007/978-3-319-58747-9_1
   Rish I., 2001, J U COMPUT SCI, V3, P41, DOI DOI 10.1002/9781118721957.CH4
   Rokach L, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P149, DOI 10.1007/978-0-387-09823-4_9
NR 15
TC 0
Z9 0
U1 2
U2 4
PD APR
PY 2022
VL 13
IS 4
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Edelen, AL
   Biedron, SG
   Chase, BE
   Edstrom, D 
   Milton, SV
   Stabile, P
AF Edelen, A. L.
   Biedron, S. G.
   Chase, B. E.
   Edstrom, D., Jr.
   Milton, S. V.
   Stabile, P.
TI Neural Networks for Modeling and Control of Particle Accelerators
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article; Proceedings Paper
CT International Particle Accelerator Conference
CY MAY 03-08, 2015
CL Richmond, VA
DE Adaptive control; artificial intelligence; control systems; machine
   learning; neural networks; particle accelerators; predictive control
ID PREDICTIVE CONTROL; GENETIC ALGORITHM; CONTROL-SYSTEMS; OPTIMIZATION;
   IDENTIFICATION; INSTABILITIES; SEEKING
AB Particle accelerators are host to myriad nonlinear and complex physical phenomena. They often involve a multitude of interacting systems, are subject to tight performance demands, and should be able to run for extended periods of time with minimal interruptions. Often times, traditional control techniques cannot fully meet these requirements. One promising avenue is to introduce machine learning and sophisticated control techniques inspired by artificial intelligence, particularly in light of recent theoretical and practical advances in these fields. Within machine learning and artificial intelligence, neural networks are particularly well-suited to modeling, control, and diagnostic analysis of complex, nonlinear, and time-varying systems, as well as systems with large parameter spaces. Consequently, the use of neural network-based modeling and control techniques could be of significant benefit to particle accelerators. For the same reasons, particle accelerators are also ideal test-beds for these techniques. Many early attempts to apply neural networks to particle accelerators yielded mixed results due to the relative immaturity of the technology for such tasks. The purpose of this paper is to re-introduce neural networks to the particle accelerator community and report on some work in neural network control that is being conducted as part of a dedicated collaboration between Fermilab and Colorado State University (CSU). We describe some of the challenges of particle accelerator control, highlight recent advances in neural network techniques, discuss some promising avenues for incorporating neural networks into particle accelerator control systems, and describe a neural network-based control system that is being developed for resonance control of an RF electron gun at the Fermilab Accelerator Science and Technology (FAST) facility, including initial experimental results from a benchmark controller.
C1 [Edelen, A. L.; Biedron, S. G.; Milton, S. V.] Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO 80523 USA.
   [Biedron, S. G.] Univ Ljubljana, Fac Elect & Comp Engn, Trzaska 25, SI-1000 Ljubljana, Slovenia.
   [Chase, B. E.; Edstrom, D., Jr.; Stabile, P.] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Stabile, P.] ADAM, CERN Spin Off, CH-1211 Geneva 23, Switzerland.
RP Edelen, AL (corresponding author), Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO 80523 USA.
EM auralee.morin@colostate.edu
CR Åkesson BM, 2006, J PROCESS CONTR, V16, P937, DOI 10.1016/j.jprocont.2006.06.001
   Åkesson BM, 2005, COMPUT CHEM ENG, V29, P323, DOI 10.1016/j.compchemeng.2004.09.023
   Al Seyab RK, 2008, J PROCESS CONTR, V18, P568, DOI 10.1016/j.jprocont.2007.10.012
   Anderson C., 2015, P IJCNN
   [Anonymous], STABLE ADAPTIVE CONT
   Arena P, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P77
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Ball NM, 2010, INT J MOD PHYS D, V19, P1049, DOI 10.1142/S0218271810017160
   Battiti R., 2009, P MIC JUL
   Bayer J., 2009, P INT C ART NEUR NET, P755
   Bengio Y, 2006, ADV NEURAL INFORM PR, P19, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bhat PC, 2011, ANNU REV NUCL PART S, V61, P281, DOI [10.1146/annurev.nucl.012809.10442, 10.1146/annurev.nucl.012809.104427]
   Biegler L. T., 1994, COMP CHEM ENG, V18
   Biswas R, 2013, PHYS REV D, V88, DOI 10.1103/PhysRevD.88.062003
   BOZOKI E, 1994, AIP CONF PROC, P103, DOI 10.1063/1.46759
   Campbell S. R., 1999, P SPIE APPL SCI NEUR, P3812
   Chen L, 2007, LECT NOTES COMPUT SC, V4491, P138
   Chen M, 2010, IEEE T NEURAL NETWOR, V21, P796, DOI 10.1109/TNN.2010.2042611
   Chow TT, 2002, ENERG BUILDINGS, V34, P103, DOI 10.1016/S0378-7788(01)00085-8
   Church M., 2012, BEAMSDOC4212 FERM
   Church M., 2013, FERMILABTM2568
   Cook DF, 2000, ENG APPL ARTIF INTEL, V13, P391, DOI 10.1016/S0952-1976(00)00021-X
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Diamond A, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00491
   Dormido-Canto S, 2013, NUCL FUSION, V53, DOI 10.1088/0029-5515/53/11/113001
   Draeger A., 1995, IEEE Control Systems Magazine, V15, P61, DOI 10.1109/37.466261
   Dreyfus G., 2005, NEURAL NETWORKS METH, DOI 10.1007/3-540-28847-3
   Farabet C., 2011, SCALING MACHINE LEAR, P399
   Gauci J, 2010, NEURAL COMPUT, V22, P1860, DOI 10.1162/neco.2010.06-09-1042
   Ge S. S., 2002, STABLE ADAPTIVE NEUR
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1162/089976600300015015, 10.1049/cp:19991218]
   Gosavi A, 2009, INFORMS J COMPUT, V21, P178, DOI 10.1287/ijoc.1080.0305
   Graff P., 2013, P IEEE 13 INT C DAT
   Graff P, 2014, MON NOT R ASTRON SOC, V441, P1741, DOI 10.1093/mnras/stu642
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A., 2006, P 23 INT C MACHINE L, V148, P369, DOI DOI 10.1145/1143844.1143891
   Grune L, 2011, COMMUN CONTROL ENG, P1
   Hasler J, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00118
   Haykin S., 2004, NEURAL NETWORKS COMP, V2, P41
   Hedjar R, 2013, INT J INNOV COMPUT I, V9, P1245
   Higo T., 1987, Proceedings of the 1987 IEEE Particle Accelerator Conference: Accelerator Engineering and Technology (Cat. No.87CH2387-9), P701
   Hinton G. E., COGNIT SCI, V38, P1078
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hitaka Y., 2004, P EUR PART ACC C, P2664
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI 10.1109/9780470544037.ch14
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   HOWELL JA, 1990, NUCL INSTRUM METH A, V293, P517, DOI 10.1016/0168-9002(90)91492-T
   Huang H, 2012, PROCEDIA ENGINEER, V49, P142, DOI 10.1016/j.proeng.2012.10.122
   Huang XB, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.084001
   Huang XB, 2013, NUCL INSTRUM METH A, V726, P77, DOI 10.1016/j.nima.2013.05.046
   HUNT KJ, 1992, AUTOMATICA, V28, P1083, DOI 10.1016/0005-1098(92)90053-I
   Hussain MA, 1999, ARTIF INTELL ENG, V13, P55, DOI 10.1016/S0954-1810(98)00011-9
   Jennings NR, 1996, IEEE INTELL SYST APP, V11, P64, DOI 10.1109/64.546585
   KIJIMA Y, 1992, EPAC 1992 - THIRD EUROPEAN PARTICLE ACCELERATOR CONFERENCE, VOL 2, P1155
   Kim K. H., 2000, P EUR PART ACC C, P1906
   Klein W, 1998, PROCEEDINGS OF THE 1997 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-3, P2535, DOI 10.1109/PAC.1997.751265
   Klein W. B., 1997, P ASS ADV ART INT C, P1019
   Klein W. B., 1997, P EUR PART ACC C, P2422
   Klein WB, 1999, J INTELL FUZZY SYST, V7, P1
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lawrynczuk M., 2013, STUDIES SYSTEMS DECI, V3
   Lawrynczuk M, 2007, INT J AP MAT COM-POL, V17, P217, DOI 10.2478/v10006-007-0020-5
   Lawrynczuk M, 2011, LECT NOTES COMPUT SC, V6593, P31, DOI 10.1007/978-3-642-20282-7_4
   LIU GP, 2001, ADV IND CON, pR11
   Lu CH, 2008, IEEE T IND ELECTRON, V55, P1366, DOI 10.1109/TIE.2007.896492
   Lu CH, 2007, J PROCESS CONTR, V17, P83, DOI 10.1016/j.jprocont.2006.08.003
   Martens J., 2011, P 28 INT C MACH LEAR, P1033, DOI DOI 10.1145/346152.346166
   Mayne DQ, 2014, AUTOMATICA, V50, P2967, DOI 10.1016/j.automatica.2014.10.128
   Mayne DQ, 2000, AUTOMATICA, V36, P789, DOI 10.1016/S0005-1098(99)00214-9
   MEAD WC, 1994, NUCL INSTRUM METH A, V352, P309, DOI 10.1016/0168-9002(94)91530-X
   MEAD WC, 1992, NUCL INSTRUM METH B, V72, P271, DOI 10.1016/0168-583X(92)95243-K
   Meier E, 2011, NUCL INSTRUM METH A, V632, P1, DOI 10.1016/j.nima.2010.12.203
   Meier E, 2009, NUCL INSTRUM METH A, V610, P629, DOI 10.1016/j.nima.2009.09.048
   Meier E, 2009, NUCL INSTRUM METH A, V609, P79, DOI 10.1016/j.nima.2009.08.028
   Meneghini O, 2014, PHYS PLASMAS, V21, DOI 10.1063/1.4885343
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   MILLER WT, 1996, NEURAL NETWORKS CONT
   Murari A, 2013, NUCL INSTRUM METH A, V720, P2, DOI 10.1016/j.nima.2013.03.039
   Murari A, 2012, IEEE MEDITERR ELECT, P932, DOI 10.1109/MELCON.2012.6196580
   Murari A, 2012, IEEE T PLASMA SCI, V40, P1386, DOI 10.1109/TPS.2012.2187682
   NGUYEN D, 1991, CONFERENCE RECORD OF THE 1991 IEEE PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P1437, DOI 10.1109/PAC.1991.164660
   Norgaard M., 2000, ADV TK CONT SIGN PRO
   Pascanu R., 2013, P ICML JUN
   Pérez-Ortiz JA, 2003, NEURAL NETWORKS, V16, P241, DOI 10.1016/S0893-6080(02)00219-8
   Perriollat F., 1997, IEEE EXPERT INTELL S, V11, P80
   Pieck M., 2008, P 42 INT LIN ACC C
   Piot P., 2014, P IPAC
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Rybarcyk L., COMPUT PHYS COMMUN, V185, P3
   Safranek J., 2014, NUCL INSTRUM METHO A, V757
   Scheinker A., 2012, THESIS U CALIFORNIA
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Scheinker A, 2014, NUCL INSTRUM METH A, V756, P30, DOI 10.1016/j.nima.2014.04.026
   Scheinker A, 2014, IEEE T CONTR SYST T, V22, P34, DOI 10.1109/TCST.2013.2240387
   Scheinker A, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.102803
   Scheinker A, 2013, IEEE T AUTOMAT CONTR, V58, P1107, DOI 10.1109/TAC.2012.2225514
   Schirmer D., 2006, P 10 EUR PART ACC C, P1948
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   SCHULTZ DE, 1990, NUCL INSTRUM METH A, V293, P486, DOI 10.1016/0168-9002(90)91487-V
   Shen CY, 2007, J MATER PROCESS TECH, V183, P412, DOI 10.1016/j.jmatprotec.2006.10.036
   Skarek P, 1996, EXPERT SYST APPL, V11, P481, DOI 10.1016/S0957-4174(96)00064-4
   Srinivasan K., 2002, 2002 7th International Conference on Control, Automation, Robotics and Vision (IEEE Cat. No.02EX649), P1626
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stabile P., 2013, P PAC
   Sungil Kwon, 2007, 2007 IEEE Particle Accelerator Conference, P2379, DOI 10.1109/PAC.2007.4441256
   Sutskever I., 2012, THESIS U TORONTO TOR
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tian K, 2014, PHYS REV SPEC TOP-AC, V17, DOI 10.1103/PhysRevSTAB.17.020703
   Vaezipour A., 2012, APPL MATH, V3, P1572, DOI DOI 10.4236/AM.2012.330217
   Vagliasindi G, 2009, IEEE T PLASMA SCI, V37, P146, DOI 10.1109/TPS.2008.2005985
   Vega J, 2013, FUSION ENG DES, V88, P1228, DOI 10.1016/j.fusengdes.2013.03.003
   Way M. J., 2012, LEARNING DATA MINING
   Werbos PJ, 1990, NEURAL NETWORKS CONT, P67
   Weygand D. P., 1987, Proceedings of the 1987 IEEE Particle Accelerator Conference: Accelerator Engineering and Technology (Cat. No.87CH2387-9), P564
   Whiteson S, 2012, ADAPT LEARN OPTIM, V12, P325
   Whiteson S, 2009, ENG APPL ARTIF INTEL, V22, P1203, DOI 10.1016/j.engappai.2009.05.004
   Yadav RP, 2012, INT J AUTOM COMPUT, V9, P561, DOI 10.1007/s11633-012-0680-y
   Yadav R. P., 2012, ELIXIR COMP SCI ENG, V44, P7405
   Yadav R. P., 2013, INT J ADV SCI TECHNO, V52, P11
   Zamarreño JM, 1999, ENG APPL ARTIF INTEL, V12, P149, DOI 10.1016/S0952-1976(98)00055-4
NR 125
TC 51
Z9 52
U1 2
U2 40
PD APR
PY 2016
VL 63
IS 2
SI SI
BP 878
EP 897
DI 10.1109/TNS.2016.2543203
PN 2
WC Engineering, Electrical & Electronic; Nuclear Science & Technology
DA 2023-11-11
ER

PT J
AU Yamanokuchi, T
   Ando, S
   Kinoshita, K
   Bahadori, A
   Kashiwao, T
AF Yamanokuchi, Tomoya
   Ando, Shin
   Kinoshita, Koji
   Bahadori, Alireza
   Kashiwao, Tomoaki
TI Prediction of accelerator operation using machine learning
SO IEEJ TRANSACTIONS ON ELECTRICAL AND ELECTRONIC ENGINEERING
DT Article
DE neural network; radial basis function network; support vector
   regression; random forest
AB This paper reports the regression analysis of the horizontal motion of a car driver's foot from a brake pedal to an accelerator pedal using machine learning methods, namely, neural network (NN), radial basis function network (RBFN), random forest (RF), and support vector regression (SVR) models, in order to predict the timing of when the driver steps on the accelerator from an web camera movie. The approximation performances of these models are compared based on root mean squared error (RMSE) and the estimated timing when the driver's foot reaches the accelerator pedal. From the results, the RF model could approximate the driver's foot motion most precisely. (c) 2018 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc.
C1 [Yamanokuchi, Tomoya; Kashiwao, Tomoaki] Niihama Coll, Natl Inst Technol, Dept Elect & Control Engn, 7-1 Yagumo Cho, Niihama, Ehime 7928580, Japan.
   [Ando, Shin; Kinoshita, Koji] Ehime Univ, Grad Sch Sci & Engn, Elect & Informat Engn, 3 Bunkyo Cho, Matsuyama, Ehime 7908577, Japan.
   [Bahadori, Alireza] Southern Cross Univ, Sch Environm Sci & Engn, POB 157, Lismore, NSW 2480, Australia.
RP Kashiwao, T (corresponding author), Niihama Coll, Natl Inst Technol, Dept Elect & Control Engn, 7-1 Yagumo Cho, Niihama, Ehime 7928580, Japan.
EM kashiwao@ect.niihama-nct.ac.jp
CR Ando S, 2015, DETECTION SHOE POSIT, P190
   Haberland H., 2012, INT J SOCIOL LANG, V2012, P1, DOI [https://doi.org/10.1515/ijsl-2012-0036, DOI 10.1515/IJSL-2012-0036]
   Kashiwao T, 2017, APPL SOFT COMPUT, V56, P317, DOI 10.1016/j.asoc.2017.03.015
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Takeuchi I, 2015, SUPPORT VECTOR MACHI
   Yamanokuchi T, 2016, SICE SHIK BRANCH ANN
NR 6
TC 4
Z9 4
U1 2
U2 13
PD APR
PY 2018
VL 13
IS 4
BP 656
EP 657
DI 10.1002/tee.22614
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Shahshahani, M
   Sabri, M
   Khabbazan, B
   Bhatia, D
AF Shahshahani, Masoud
   Sabri, Mohammad
   Khabbazan, Bahareh
   Bhatia, Dinesh
GP IEEE
TI An Automated Tool for Implementing Deep Neural Networks on FPGA
SO 2021 34TH INTERNATIONAL CONFERENCE ON VLSI DESIGN AND 2021 20TH
   INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS (VLSID & ES 2021)
SE International Conference on VLSI Design
DT Proceedings Paper
CT 34th International Conference on VLSI Design / 20th International
   Conference on Embedded Systems (VLSID)
CY FEB 20-24, 2021
CL ELECTR NETWORK
DE FPGAs; Accelerators; Deep Neural Networks
AB FPGA based Deep Neural Networks provide the advantage of high performance, highly parallel implementation with very low energy requirements. A designer must consider various configuration choices, processing components, data-flow types, local memory hierarchy, and fixed-data-precision for a DNN implementation. An exploration tool is essential for building a reconfigurable, fast, and efficient DNN hardware accelerator. We present a methodology to automatically create an optimized FPGA-based hardware accelerator given DNNs from standard machine learning frameworks. We generate a HighLevel-Synthesis (HLS) code depending on the user preferences with a set of optimization pragmas. For a faster and costeffective hardware accelerator, the tool employs a softwaremodel to estimate the execution time and hardware utilization using trained machine-learning models. The model evaluation results show that our framework performance speed-up compares well with the state-of-the-art accelerators using Xilinx FPGA platforms.
C1 [Shahshahani, Masoud; Bhatia, Dinesh] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
   [Sabri, Mohammad] Iran Univ Technol, Sch Elect Engn, Tehran, Iran.
   [Khabbazan, Bahareh] Univ Tehran, Coll Engn, Tehran, Iran.
RP Shahshahani, M (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
EM masoud.shahshahani@utdallas.edu; Mohammad.sabri@ut.ac.ir;
   b_khabbazan@alumni.iust.ac.ir; dinesh@utdallas.edu
CR [Anonymous], 2016, FPGA
   [Anonymous], 2016, DAC
   [Anonymous], 2018, ICCAD
   [Anonymous], 2015, FPGA
   Ghaffari A., 2020, CNN2GATE DESIGNING G
   Hailesellasie MT, 2019, IEEE ACCESS, V7, P47509, DOI 10.1109/ACCESS.2019.2907865
   Ma Y., 2018, VLSI J, V1
   Meeuws R., 2011, IC SAMOS
   Mirzakuchaki S, 2019, DSD
   Mu J., 2018, FPL
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Qiu J, 2017, I C FIELD PROG LOGIC
   Shahshahani M., 2020, IEEE DCAS
   VENIERIS SI, 2017, I C FIELD PROG LOGIC, DOI DOI 10.23919/FPL.2017.8056828
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Xu P., 2020, FPGA
   Yan MY, 2019, IEEE T SUSTAIN ENERG, V10, P1227, DOI 10.1109/TSTE.2018.2864296
NR 17
TC 4
Z9 4
U1 0
U2 1
PY 2021
BP 322
EP 327
DI 10.1109/VLSID51830.2021.00060
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chen, J
   Lange, T
   Andjelkovic, M
   Simevski, A
   Krstic, M
AF Chen, J.
   Lange, T.
   Andjelkovic, M.
   Simevski, A.
   Krstic, M.
BE Dilillo, L
   Psarakis, M
   Siddiqua, T
TI Hardware Accelerator Design with Supervised Machine Learning for Solar
   Particle Event Prediction
SO 2020 33RD IEEE INTERNATIONAL SYMPOSIUM ON DEFECT AND FAULT TOLERANCE IN
   VLSI AND NANOTECHNOLOGY SYSTEMS (DFT)
SE IEEE International Symposium on Defect and Fault Tolerance in VLSI
   Systems
DT Proceedings Paper
CT 33rd IEEE International Symposium on Defect and Fault Tolerance in VLSI
   and Nanotechnology Systems (DFT)
CY OCT 19-21, 2020
CL ELECTR NETWORK
DE solar particle event; machine learning; single event upset; hardware
   accelerator
ID SPACE
AB The intensity of cosmic radiation can differ over five orders of magnitude within a few hours or days during Solar Particle Events (SPEs), thus increasing the probability of Single-Event Upsets (SEUs) in space applications for several orders of magnitude. Therefore, it is vital to employ the early detection of the SEU rate changes in order to ensure timely activation of the radiation hardening measures. In this paper, a hardware accelerator for forecasting the SPEs by the prediction of inflight SEU variation is proposed. An embedded on-chip SRAM is used as the real-time particle detector. The dedicated hardware accelerator implements a supervised machine learning model to forecast the SRAM SEUs one hour in advance with fine-grained hourly tracking of SEU variations during SPEs as well as under normal conditions. The whole design is intended for a highly dependable and self-adaptive multiprocessing system employed in space applications. Therefore, the target system can drive the appropriate radiation hardening mechanisms before the onset of high radiation levels.
C1 [Chen, J.; Andjelkovic, M.; Simevski, A.; Krstic, M.] IHP Leibniz Inst Innovat Mikroelekt, Frankfurt, Germany.
   [Lange, T.] iROC, Grenoble, France.
   [Krstic, M.] Univ Potsdam, Potsdam, Germany.
   [Lange, T.] Politecn Torino, Turin, Italy.
RP Chen, J (corresponding author), IHP Leibniz Inst Innovat Mikroelekt, Frankfurt, Germany.
EM chen@ihp-microelectronics.com; lange@ihp-microelectronics.com;
   andjelkovic@ihp-microelectronics.com; simevski@ihp-microelectronics.com;
   krstic@ihp-microelectronics.com
CR Bain H.M., 2018, P SOARS
   Barth JL, 2003, IEEE T NUCL SCI, V50, P466, DOI 10.1109/TNS.2003.813131
   Camporeale E, 2019, SPACE WEATHER, V17, P1166, DOI 10.1029/2018SW002061
   Chen J., 2020, P ESREF
   Chen J., 2019, P 22 EUR C DIG SYST
   Engell AJ, 2017, SPACE WEATHER, V15, P1321, DOI 10.1002/2017SW001660
   Gupta V, 2017, THESIS U MONTPELLIER
   Hansen DL, 2007, IEEE T NUCL SCI, V54, P2525, DOI 10.1109/TNS.2007.908787
   Hazucha P, 2000, IEEE T NUCL SCI, V47, P2586, DOI 10.1109/23.903813
   Hoyos SE, 2004, IEEE T NUCL SCI, V51, P2927, DOI 10.1109/TNS.2004.835072
   Petersen E., 2011, SINGLE EVENT EFFECTS
   Petrovic V, 2015, IEEE INT SYMP DESIGN, P203, DOI 10.1109/DDECS.2015.65
   Simevski A, 2020, IEEE INT ON LINE, DOI 10.1109/iolts50870.2020.9159716
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tylka AJ, 1997, IEEE T NUCL SCI, V44, P2150, DOI 10.1109/23.659030
   Yearby KH, 2014, SPACE WEATHER, V12, P24, DOI 10.1002/2013SW000985
NR 16
TC 1
Z9 1
U1 0
U2 0
PY 2020
DI 10.1109/dft50435.2020.9250856
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Edelen, JP
   Hall, CC
AF Edelen, Jonathan P.
   Hall, Christopher C.
TI Autoencoder Based Analysis of RF Parameters in the Fermilab Low Energy
   Linac
SO INFORMATION
DT Article
DE autoencoder; anomaly detection; linear accelerator; machine learning;
   root cause analysis
ID ANOMALY DETECTION; NEURAL-NETWORKS; SPACE
AB Machine learning (ML) has the potential for significant impact on the modeling, operation, and control of particle accelerators due to its ability to model nonlinear behavior, interpolate on complicated surfaces, and adapt to system changes over time. Anomaly detection in particular has been highlighted as an area where ML can significantly impact the operation of accelerators. These algorithms work by identifying subtle behaviors of key variables prior to negative events. Efforts to apply ML to anomaly detection have largely focused on subsystems such as RF cavities, superconducting magnets, and losses in rings. However, dedicated efforts to understand how to apply ML for anomaly detection in linear accelerators have been limited. In this paper the use of autoencoders is explored to identify anomalous behavior in measured data from the Fermilab low-energy linear accelerator.
C1 [Edelen, Jonathan P.; Hall, Christopher C.] RadiaSoft LLC, Boulder, CO 80301 USA.
   [Edelen, Jonathan P.] 6525 Gunpk Dr,Suites 370-411, Boulder, CO 80301 USA.
RP Edelen, JP (corresponding author), RadiaSoft LLC, Boulder, CO 80301 USA.; Edelen, JP (corresponding author), 6525 Gunpk Dr,Suites 370-411, Boulder, CO 80301 USA.
EM jedelen@radiasoft.net; chall@radiasoft.net
CR Butler T.A., 2008, P LINAC08 VICT BC CA
   Cauteruccio F, 2021, FUTURE GENER COMP SY, V114, P322, DOI 10.1016/j.future.2020.08.010
   Cauteruccio F, 2019, INFORM FUSION, V52, P13, DOI 10.1016/j.inffus.2018.11.010
   Dewitte T., 2019, P 17 INT C ACC LARG
   Doolittle L., 2007, P AS PART ACC C IND
   Edelen A., 2018, ARXIV181103172
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A.L., 2016, P 2016 N AM PART ACC
   Edelen A.L., 2017, P 2017 DEEP LEARN PH
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Edelen J.P., OPTIMAL CONTROL RAPI
   Edelen J.P., 2018, ARXIV180308211
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Fol E., 2019, P 10 INT PART ACC C, DOI [10.18429/JACoW-IPAC2019-WEPGW081, DOI 10.18429/JACOW-IPAC2019-WEPGW081]
   KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209
   Nawaz A, 2018, IFAC PAPERSONLINE, V51, P1379, DOI 10.1016/j.ifacol.2018.09.554
   Nawaz A., 2018, PROC 9 INT PARTICLE, P2502, DOI [10.18429/JACoW-IPAC2018-WEPMF058, DOI 10.18429/JACOW-IPAC2018-WEPMF058]
   Nawaz AS, 2016, CONF CONTR FAULT-TOL, P196, DOI 10.1109/SYSTOL.2016.7739750
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Soma T., 2017, P 14 ANN M PART ACC, P1427
   Valentino G, 2017, J PHYS CONF SER, V874, DOI 10.1088/1742-6596/874/1/012002
   Webber R.C., 2000, P 9 WORKSH BEAM INST
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
NR 23
TC 2
Z9 2
U1 2
U2 4
PD JUN
PY 2021
VL 12
IS 6
AR 238
DI 10.3390/info12060238
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Nurvitadhi, E
   Mishra, A
   Wang, Y
   Venkatesh, G
   Marr, D
AF Nurvitadhi, Eriko
   Mishra, Asit
   Wang, Yu
   Venkatesh, Ganesh
   Marr, Debbie
GP IEEE
TI Hardware Accelerator for Analytics of Sparse Data
SO PROCEEDINGS OF THE 2016 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 14-18, 2016
CL Dresden, GERMANY
DE Hardware accelerator; analytics; machine learning
AB Rapid growth of Internet led to web applications that produce large unstructured sparse datasets (e.g., texts, ratings). Machine learning (ML) algorithms are the basis for many important analytics workloads that extract knowledge from these datasets. This paper characterizes such workloads on a high-end server for real-world datasets and shows that a set of sparse matrix operations dominates runtime. Further, they run inefficiently due to low compute-per-byte and challenging thread scaling behavior. As such, we propose a hardware accelerator to perform these operations with extreme efficiency. Simulations and RTL synthesis to 14nm ASIC demonstrate significant performance and performance/Watt improvements over conventional processors, with only a small area overhead.
C1 [Nurvitadhi, Eriko; Mishra, Asit; Wang, Yu; Venkatesh, Ganesh; Marr, Debbie] Intel Corp, Hillsboro, OR 97124 USA.
RP Nurvitadhi, E (corresponding author), Intel Corp, Hillsboro, OR 97124 USA.
CR Bottou L. A., 2010, COMPUTATIONAL STAT
   Chang Chih-Chung, 2011, ACM T INTELLIGENT SY, V2, P27
   Chen T., 2014, P 19 INT C ARCH SUPP
   Chen YJ, 2014, IEEE MTT S INT MICR
   Conti F., 2015, DES AUT TEST EUR C E
   Dorrance R., 2014, INT S FIELD PROGR GA
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Lin C.-J., 2008, J MACHINE LEARNING R
   Liu D., 2015, ARCH SUPPORT PROGRAM
   Ma J., 2009, INT C MACH LEARN
   McMahan H. B., 2013, KNOWLEDGE DISCOVERY
   Ning X., 2012, C REC SYST
   Nurvitadhi E., 2015, COMPILERS ARCHITECTU
   Papadonikolakis M., 2010, FIELD PROGRAMMABLE C
   Pedram A., 2011, APPL SPECIFIC SYSTEM
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Sculley D., 2010, ACM INT C WORLD WID
   University of California Irvine, MACH LEARN REP
   Winterstein F, 2013, I C FIELD PROG LOGIC
   Zhang Y., 2009, INT C FIELD PROGR TE
   Zhuo L., 2005, INT S FIELD PROGR GA
NR 21
TC 11
Z9 13
U1 0
U2 0
PY 2016
BP 1616
EP 1621
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Valdes, G
   Morin, O
   Pouliot, J
   Chuang, C
AF Valdes, G.
   Morin, O.
   Pouliot, J.
   Chuang, C.
TI Automated Quality Assurance for XML Controlled Linacs
SO MEDICAL PHYSICS
DT Meeting Abstract
DE Linear accelerators; Medical image quality; Machine learning;
   Stereoscopy; Medical physicists; Quality assurance; Image guided
   radiation therapy; Cone beam computed tomography
NR 0
TC 0
Z9 0
U1 0
U2 1
PD JUN
PY 2014
VL 41
IS 6
MA SU-E-T-48
DI 10.1118/1.4888378
PN 11
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Dadu, V
   Weng, J
   Liu, SH
   Nowatzki, T
AF Dadu, Vidushi
   Weng, Jian
   Liu, Sihao
   Nowatzki, Tony
TI Towards General-Purpose Acceleration: Finding Structure in Irregularity
SO IEEE MICRO
DT Article
DE Hardware; Machine learning algorithms; Databases; Computer architecture;
   Throughput; Computational modeling; Approximation algorithms
AB Programmable hardware accelerators (e.g., vector processors, GPUs) have been extremely successful at targeting algorithms with regular control and memory patterns to achieve order-of-magnitude performance and energy efficiency improvements. However, they perform far under the peak on important irregular algorithms, like those from graph processing, database querying, genomics, advanced machine learning, and others. This work posits that the primary culprit is specific forms of irregular control flow and memory access. By capturing the problematic behavior at a domain-agnostic level, we propose an accelerator that is sufficiently general, matches domain-specific accelerator performance, and significantly outperforms traditional CPUs and GPUs.
C1 [Dadu, Vidushi; Weng, Jian; Liu, Sihao; Nowatzki, Tony] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.
RP Dadu, V (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.
EM vidushi.dadu@cs.ucla.edu; jian.weng@cs.ucla.edu; sihao@cs.ucla.edu;
   tjn@cs.ucla.edu
CR [Anonymous], [No title captured]
   Gómez-Luna J, 2013, IEEE T PARALL DISTR, V24, P2273, DOI 10.1109/TPDS.2012.319
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Ham TJ, 2016, INT SYMP MICROARCH
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Mishra AK, 2017, ASIA S PACIF DES AUT, P635, DOI 10.1109/ASPDAC.2017.7858395
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Nowatzki T, 2016, INT S HIGH PERF COMP, P27, DOI 10.1109/HPCA.2016.7446051
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Wu LS, 2014, ACM SIGPLAN NOTICES, V49, P255, DOI 10.1145/2541940.2541961
NR 12
TC 1
Z9 1
U1 0
U2 3
PD MAY-JUN
PY 2020
VL 40
IS 3
BP 37
EP 46
DI 10.1109/MM.2020.2986199
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Picca, P
   Furfaro, R
AF Picca, Paolo
   Furfaro, Roberto
TI Application of Extreme Learning Machines to inverse neutron kinetics
SO ANNALS OF NUCLEAR ENERGY
DT Article
DE Inverse neutron kinetics; Accelerator-driven system; Artificial Neural
   Network; Extreme Learning Machines
ID ACCELERATOR-DRIVEN SYSTEMS
AB The paper presents the application of Extreme Leaning Machines (ELMs) for inverse reactor kinetic applications. ELMs were proposed by Huang and co-workers (2004, 2006a,b, 2015), which showed their enhances capabilities in terms of training speed and generalization with respect to classical Artificial Neural Networks (ANNs). ELMs are here implemented for reactivity determination as an alternative to ANNs (e.g. Picca et al. (2008)) and Gaussian Processes (Picca and Furfaro, 2012). After a review of the main features of ELMs, their application to inverse kinetic problems is proposed. The ELMs performance is tested on a typical accelerator drive system configuration (Yalina reactor) and the inversion is carried out on an accurate kinetic model (multi-group transport). (C) 2016 Published by Elsevier Ltd.
C1 [Picca, Paolo; Furfaro, Roberto] Univ Arizona, Dept Syst & Ind Engn, POB 210020, Tucson, AZ 85721 USA.
RP Furfaro, R (corresponding author), Univ Arizona, Dept Syst & Ind Engn, POB 210020, Tucson, AZ 85721 USA.
EM ppicca@email.arizona.edu; robertof@email.arizona.edu
CR AKCASU Z, 1971, MATH METHODS NUCL RE
   [Anonymous], 2010, HDB NUCL ENG
   Bartlett PL, 1997, ADV NEUR IN, V9, P134
   Dulla S, 2011, PROG NUCL ENERG, V53, P32, DOI 10.1016/j.pnucene.2010.09.008
   Eriksson M, 2005, NUCL SCI ENG, V149, P298, DOI 10.13182/NSE03-103
   Feynman RP., 1956, J NUCL ENERGY, V3, P64, DOI DOI 10.1016/0891-3919(56)90042-0
   GOZANI T, 1962, NUKLEONIKA, V4, P348
   Hagan MT., 1996, NEURAL NETWORK DESIG
   HENRY AF, 1958, NUCL SCI ENG, V3, P52, DOI 10.13182/NSE58-1
   HUANG GB, 2004, 2004 INT JOINT C NEU
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2015, COGN COMPUT, V7, P263, DOI 10.1007/s12559-015-9333-0
   Kiyavitskaya H., 2007, YALINA BOOSTER BENCH
   OECD/NEA, 2002, ACC DRIV SYST ADS FA
   ORNDOFF JD, 1957, NUCL SCI ENG, V2, P450, DOI 10.13182/NSE57-A25409
   Picca P., 2009, JOINT INT TOP M MATH
   Picca P., 2008, ANS WINT M REN
   Picca P., 2010, PHYSOR 2010
   Picca P, 2012, ANN NUCL ENERGY, V47, P146, DOI 10.1016/j.anucene.2012.03.023
   Salvatores M., 1996, P 2 INT C ACC DRIV T, V1, P513
   SIMMONS BE, 1958, NUCL SCI ENG, V3, P595, DOI 10.13182/NSE3-595-608
   Sjostrand N.G., 1956, P UN INT C PEAC US A
   Soule R, 2004, NUCL SCI ENG, V148, P124, DOI 10.13182/NSE01-13C
   WILLIAMS M.M.R., 1974, RANDOM PROCESSES NUC
NR 25
TC 2
Z9 2
U1 0
U2 12
PD FEB
PY 2017
VL 100
BP 1
EP 8
DI 10.1016/j.anucene.2016.08.031
PN 2
WC Nuclear Science & Technology
DA 2023-11-11
ER

PT J
AU Ngo, D
   Lee, S
   Lee, GD
   Kang, B
AF Ngo, Dat
   Lee, Seungmin
   Lee, Gi-Dong
   Kang, Bongsoon
TI Single-Image Visibility Restoration: A Machine Learning Approach and Its
   4K-Capable Hardware Accelerator
SO SENSORS
DT Article
DE haze removal; machine learning; supervised learning; hardware
   accelerator; field programmable gate array
ID DARK-CHANNEL-PRIOR; HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT;
   QUALITY ASSESSMENT
AB In recent years, machine vision algorithms have played an influential role as core technologies in several practical applications, such as surveillance, autonomous driving, and object recognition/localization. However, as almost all such algorithms are applicable to clear weather conditions, their performance is severely affected by any atmospheric turbidity. Several image visibility restoration algorithms have been proposed to address this issue, and they have proven to be a highly efficient solution. This paper proposes a novel method to recover clear images from degraded ones. To this end, the proposed algorithm uses a supervised machine learning-based technique to estimate the pixel-wise extinction coefficients of the transmission medium and a novel compensation scheme to rectify the post-dehazing false enlargement of white objects. Also, a corresponding hardware accelerator implemented on a Field Programmable Gate Array chip is in order for facilitating real-time processing, a critical requirement of practical camera-based systems. Experimental results on both synthetic and real image datasets verified the proposed method's superiority over existing benchmark approaches. Furthermore, the hardware synthesis results revealed that the accelerator exhibits a processing rate of nearly 271.67 Mpixel/s, enabling it to process 4K videos at 30.7 frames per second in real time.
C1 [Ngo, Dat; Lee, Seungmin; Lee, Gi-Dong; Kang, Bongsoon] Dong A Univ, Dept Elect Engn, Busan 49315, South Korea.
RP Kang, B (corresponding author), Dong A Univ, Dept Elect Engn, Busan 49315, South Korea.
EM datngo@donga.ac.kr; 1672885@donga.ac.kr; gdlee@dau.ac.kr;
   bongsoon@dau.ac.kr
CR Ancuti C.O., 2018, ARXIV180405091CS
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen XQ, 2019, J NAVIGATION, V72, P176, DOI 10.1017/S0373463318000504
   Cho H, 2015, J SEMICOND TECH SCI, V15, P60, DOI 10.5573/JSTS.2015.15.1.060
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dat Ngo, 2019, 2019 International Conference on Electronics, Information, and Communication (ICEIC), DOI 10.23919/ELINFOCOM.2019.8706413
   Ngo D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185170
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   FRIES RW, 1979, IEEE T ACOUST SPEECH, V27, P625, DOI 10.1109/TASSP.1979.1163324
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   *IEEE, 2006, 13642005 IEEE
   Jack K., 2005, VIDEO DEMYSTIFIED, V4th ed., P394, DOI [10.1016/B978-075067822-3/50010-5, DOI 10.1016/B978-075067822-3/50010-5]
   Kaufman HJ, 1993, IEEE T CIRC SYST VID, V3, P2, DOI 10.1109/76.180686
   Kim GJ, 2018, IEICE T FUND ELECTR, VE101A, P1999, DOI 10.1587/transfun.E101.A.1999
   Knuth D.E., 1998, ART COMPUTER PROGRAM, V3
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Lee Z, 2016, J ATMOS SCI, V73, P4573, DOI 10.1175/JAS-D-16-0102.1
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Ngo D, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Ngo D, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142233
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173443
   Ngo Dat, 2018, [Journal of IKEEE, 전기전자학회논문지], V22, P948, DOI 10.7471/ikeee.2018.22.4.948
   Ngo Dat, 2018, [Journal of IKEEE, 전기전자학회논문지], V22, P585, DOI 10.7471/ikeee.2018.22.3.585
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Park D, 2014, IEEE IMAGE PROC, P4037, DOI 10.1109/ICIP.2014.7025820
   Park Y, 2017, IEEE GLOB CONF SIG, P779, DOI 10.1109/GlobalSIP.2017.8309066
   Park Y, 2018, IEEE ACCESS, V6, P10003, DOI 10.1109/ACCESS.2018.2806378
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Sengee N, 2010, IEEE T CONSUM ELECTR, V56, P2727, DOI 10.1109/TCE.2010.5681162
   Tan SF, 2019, IEEE ACCESS, V7, P70842, DOI 10.1109/ACCESS.2019.2918557
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tufail Z, 2018, IEEE ACCESS, V6, P32576, DOI 10.1109/ACCESS.2018.2843261
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
NR 52
TC 13
Z9 13
U1 1
U2 9
PD OCT
PY 2020
VL 20
IS 20
AR 5795
DI 10.3390/s20205795
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT C
AU Shankar, S
   Reuther, A
AF Shankar, Sadasivan
   Reuther, Albert
GP IEEE
TI Trends in Energy Estimates for Computing in AI/Machine Learning
   Accelerators, Supercomputers, and Compute-Intensive Applications
SO 2022 IEEE HIGH PERFORMANCE EXTREME COMPUTING VIRTUAL CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Virtual Conference (HPEC)
CY SEP 19-23, 2022
CL ELECTR NETWORK
DE Moore's law; Energy Efficiency in computing; Energy per Instruction;
   Energy per Bit; Instructions per Second; Bit Utilization; Specialized
   Architectures; Energy for Machine Learning Application; Co-design;
   Energy as a design attribute
AB We examine the computational energy requirements of different systems driven by the geometrical scaling law (known as Moore's law or Dennard Scaling for geometry) and increasing use of Artificial Intelligence/ Machine Learning (AI/ML) over the last decade. With more scientific and technology applications based on data-driven discovery, machine learning methods, especially deep neural networks, have become widely used. In order to enable such applications, both hardware accelerators and advanced Al/ML methods have led to the introduction of new architectures, system designs, algorithms, and software. Our analysis of energy trends indicates three important observations: 1) Energy efficiency due to geometrical scaling is slowing down; 2) The energy efficiency at the bit-level does not translate into efficiency at the instruction-level, or at the system-level for a variety of systems, especially for large-scale AI/ML accelerators or supercomputers; 3) At the application level, general-purpose Al/ML methods can be computationally energy intensive, off-setting the gains in energy from geometrical scaling and special purpose accelerators. Further, our analysis provides specific pointers for integrating energy efficiency with performance analysis for enabling high-performance and sustainable computing in the future.
C1 [Shankar, Sadasivan] SLAC Natl Lab, Menlo Pk, CA USA.
   [Shankar, Sadasivan] Stanford Univ, Mat Sci & Engn, Stanford, CA USA.
   [Reuther, Albert] Lincoln Lab Supercomputing Ctr LLSC, Lexington, MA USA.
RP Shankar, S (corresponding author), SLAC Natl Lab, Menlo Pk, CA USA.; Shankar, S (corresponding author), Stanford Univ, Mat Sci & Engn, Stanford, CA USA.
EM sshankar@slac.stanford.edu; reuther@LL.mit.edu
CR [Anonymous], 2013, SAND20134744
   [Anonymous], 2022, 59 EDITION TOP500
   [Anonymous], 2007, PATTERN RECOGN, V16
   Barrett RF, 2010, CONCURR COMP-PRACT E, V22, P573, DOI 10.1002/cpe.1476
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Flach P., 2012, MACHINE LEARNING ART
   Gibney E, 2022, NATURE, V607, P648, DOI 10.1038/d41586-022-01983-7
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Hoffmann J, 2022, Arxiv, DOI [arXiv:2203.15556, DOI 10.48550/ARXIV.2203.15556]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Moore GE, 2003, ISSCC DIG TECH PAP I, V46, P20
   Myszczynska MA, 2020, NAT REV NEUROL, V16, P440, DOI 10.1038/s41582-020-0377-8
   Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181
   Patterson D, 2022, COMPUTER, V55, P18, DOI 10.1109/MC.2022.3148714
   Reuther A, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622867
   Rogers T., 2021, ACM SIGARCH
   Schmidt J, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0221-0
   Semiconductor Research Corporation, 2021, DEC PLAN SEM
   Sevilla J., 2021, PARAMETER COUNTS MAC
   Sevilla J, 2022, Arxiv, DOI [arXiv:2202.05924, 10.48550/ARXIV.2202.05924, DOI 10.48550/ARXIV.2202.05924]
   Shankar S, 2022, NAT MACH INTELL, V4, P314, DOI 10.1038/s42256-022-00481-9
   Shanmugam S., 2021, 2021 INNOVATIONS POW, P1
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Tachet des Combes R., 2022, 2022 ACM C FAIRNESS, P1877
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   Zhou YQ, 2021, Arxiv, DOI arXiv:2102.08619
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/HPEC55821.2022.9926296
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Mishra, AK
   Nurvitadhi, E
   Venkatesh, G
   Pearce, J
   Marr, D
AF Mishra, Asit K.
   Nurvitadhi, Eriko
   Venkatesh, Ganesh
   Pearce, Jonathan
   Marr, Debbie
GP IEEE
TI Fine-Grained Accelerators for Sparse Machine Learning Workloads
SO 2017 22ND ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 22nd Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 16-19, 2017
CL Tokyo, JAPAN
AB Text analytics applications using machine learning techniques have grown in importance with ever increasing amount of data being generated from web-scale applications, social media and digital repositories. Apart from being large in size, these generated data are often unstructured and are heavily sparse in nature. The performance of these applications on current systems is hampered by hard to predict branches and low compute-per-byte ratio. This paper proposes a set of fine-grained accelerators that improve the performance and energy-envelope of these applications by an order of magnitude.
C1 [Mishra, Asit K.; Nurvitadhi, Eriko; Venkatesh, Ganesh; Pearce, Jonathan; Marr, Debbie] Intel Corp, Santa Clara, CA 95051 USA.
RP Mishra, AK (corresponding author), Intel Corp, Santa Clara, CA 95051 USA.
EM asit.k.mishra@intel.com; eriko.nurvitadhi@intel.com;
   ganesh.venkatesh@intel.com; jonathan.d.pearce@intel.com;
   debbie.marr@intel.com
CR [Anonymous], 2013, HPEC
   [Anonymous], 2014, MICRO
   [Anonymous], FPGA
   [Anonymous], 2010, WWW
   [Anonymous], 2014, FPGA
   Bell Nathan, 2008, NVR2008004
   Carlson Trevor E., 2011, SC, V11
   Chang C.-C., 2011, ACM T IST
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Francesco Conti, 2015, DATE
   Gilbert J. R., SIAM J MATRIX ANAL A, V13
   Haidar A., INT J HIGH PERFORM C, V28
   Li S., 2009, MICRO
   Mittal S, 2014, SUSTAINABLE COMPUTIN
   Ning Xia, 2012, RECSYS
   Nurvitadhi E., 2016, DATE
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Williams S., 2007, SC
NR 18
TC 12
Z9 12
U1 0
U2 0
PY 2017
BP 635
EP 640
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Sinha, M
   Bhattacharyya, P
   Rout, SS
   Prakriya, NB
   Deb, S
AF Sinha, Mitali
   Bhattacharyya, Pramit
   Rout, Sidhartha Sankar
   Prakriya, Neha Bhairavi
   Deb, Sujay
TI Securing an Accelerator-Rich System From Flooding-Based
   Denial-of-Service Attacks
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Accelerator-rich SoC; flooding attack; denial-of-service; machine
   learning
AB Increasing demand for high performance and energy efficiency along with time-to-market pressures have led to a growing number of third-party accelerators in modern System-on-Chips (SoCs). However, the third-party accelerators may introduce vulnerabilities due to malicious intent or elusive design bugs that escape through verification processes. These vulnerabilities can be exploited by various attackers which can corrupt the entire system. Flooding is one such attack that is triggered by a malicious third-party accelerator to obstruct on-chip network communication by injecting useless packets leading to Denial-of-Service. To secure accelerator-rich SoCs from flooding attacks, we propose a two-step attack detection framework that leverages machine learning (ML) models to detect an attack scenario. The ML-based solution along with hierarchical feature data aggregation and feature packet prioritization provides an accurate attack detection with minimal performance overheads. Experimental evaluations with real accelerator benchmarks show the effectiveness of our framework achieving a detection accuracy of up to 97 percent across various ML classifiers.
C1 [Sinha, Mitali; Bhattacharyya, Pramit] Indraprastha Inst Informat Technol, Dept Comp Sci & Engn, New Delhi 110020, India.
   [Rout, Sidhartha Sankar; Prakriya, Neha Bhairavi; Deb, Sujay] Indraprastha Inst Informat Technol, Dept Elect & Commun Engn, New Delhi 110020, India.
RP Sinha, M (corresponding author), Indraprastha Inst Informat Technol, Dept Comp Sci & Engn, New Delhi 110020, India.
EM mitalis@iiitd.ac.in
CR [Anonymous], 2015, P 9 INT S NETWORKS O
   [Anonymous], 2008, P 6 IEEEACMIFIP INT
   [Anonymous], 2012, P ACM IEEE INT S LOW
   [Anonymous], 2001, NETWORK CALCULUS THE
   Attia KM, 2017, AIN SHAMS ENG J, V8, P445, DOI 10.1016/j.asej.2015.08.010
   Benini L, 2002, COMPUTER, V35, P70, DOI 10.1109/2.976921
   Bermak A, 2003, IEEE T NEURAL NETWOR, V14, P1097, DOI 10.1109/TNN.2003.816362
   Boraten T, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P45, DOI 10.1145/2902961.2903032
   Catania V, 2015, IEEE INT CONF ASAP, P162, DOI 10.1109/ASAP.2015.7245728
   Charles S, 2019, DES AUT TEST EUROPE, P1160, DOI [10.23919/DATE.2019.8715009, 10.23919/date.2019.8715009]
   Cong J, 2014, DES AUT CON, DOI 10.1145/2593069.2596667
   Dabin Fang, 2013, 2013 IEEE Eighth International Conference on Networking, Architecture and Storage (NAS), P178, DOI 10.1109/NAS.2013.29
   Das S, 2019, P IEEE S SECUR PRIV, P20, DOI 10.1109/SP.2019.00021
   Demme John, 2013, SIGARCH COMPUT ARCHI, P559, DOI [10.1145/2485922.2485970, DOI 10.1145/2508148.2485970]
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Huang YW, 2018, IEEE T INF FOREN SEC, V13, P2746, DOI 10.1109/TIFS.2018.2833059
   Iskandar V, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P230, DOI 10.1109/ICCES.2018.8639212
   *ITRS, 2007, SYST DRIV
   Jyothi V, 2016, I CONF VLSI DESIGN, P587, DOI 10.1109/VLSID.2016.115
   Lyons MJ, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086727
   Olson LE, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P470, DOI 10.1145/2830772.2830819
   Olson LE, 2016, IEEE COMPUT ARCHIT L, V15, P50, DOI 10.1109/LCA.2015.2445337
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Piccolboni L, 2018, IEEE T COMPUT AID D, V37, P2685, DOI 10.1109/TCAD.2018.2857321
   Pilato C, 2019, IEEE T COMPUT AID D, V38, P798, DOI 10.1109/TCAD.2018.2834421
   Qian ZL, 2014, ASIA S PACIF DES AUT, P323, DOI 10.1109/ASPDAC.2014.6742910
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Reddy BK, 2018, IEEE T MULTI-SCALE C, V4, P369, DOI 10.1109/TMSCS.2017.2755619
   Rohl T, 2015, PROC 9 INT WORKSHOP, P17
   Shao Y. S., 2015, HPCA SENSORS CLOUD A, P1
   Shao YS, 2016, INT SYMP MICROARCH
   Sinha M, 2018, IEEE INT CONF ASAP, P101
   Weaver Vincent M., 2013, IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS 2013), P215
   Xu Wenyuan, 2005, P 6 ACM INT S MOB AD, P46, DOI DOI 10.1145/1062689.1062697
   Xu ZX, 2017, DES AUT TEST EUROPE, P169, DOI 10.23919/DATE.2017.7926977
NR 35
TC 1
Z9 1
U1 0
U2 2
PD APR-JUN
PY 2022
VL 10
IS 2
BP 855
EP 869
DI 10.1109/TETC.2021.3049826
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT J
AU Wang, C
   Gong, L
   Li, X
   Yu, Q
   Wang, AL
   Hung, PT
   Zhou, XH
AF Wang, Chao
   Gong, Lei
   Li, Xi
   Yu, Qi
   Wang, Aili
   Hung, Patrick
   Zhou, Xuehai
TI SOLAR: Services-Oriented Deep Learning Architectures-Deep Learning as a
   Service
SO IEEE TRANSACTIONS ON SERVICES COMPUTING
DT Article
DE Machine learning; Hardware; Service-oriented architecture; Computer
   architecture; Field programmable gate arrays; Training;
   Services-oriented architecture; deep learning; neural network;
   accelerator
AB Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data size have posed significant challenge to construct a flexible and high performance implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. To leverage the trade-offs between the metrics among performance, power, energy, and efficiency, we present a multitarget design space exploration. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.
C1 [Wang, Chao; Gong, Lei; Li, Xi; Yu, Qi; Wang, Aili; Zhou, Xuehai] Univ Sci & Technol China, Hefei 230027, Anhui, Peoples R China.
   [Hung, Patrick] Univ Ontario Inst Technol, Business & Informat Technol, Oshawa, ON L1H 7K4, Canada.
RP Li, X (corresponding author), Univ Sci & Technol China, Hefei 230027, Anhui, Peoples R China.
EM saintwc@mail.ustc.edu.cn; leigong0203@mail.ustc.edu.cn;
   wangal@ustc.edu.cn; llxx@ustc.edu.cn; yuiq20123@mail.ustc.edu.cn;
   patrick.hung@uoit.ca; xhzhou@ustc.edu.cn
CR Achbany Youssef, 2008, IEEE Transactions on Services Computing, V1, P141, DOI 10.1109/TSC.2008.12
   Alam M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, VOLS 1 AND 2, P343, DOI 10.1109/ICWS.2009.139
   [Anonymous], 2005, SERVICE ORIENTED ARC
   [Anonymous], 2009, P ACMSIGDA INT S FIE
   Bellens P, 2009, SCI PROGRAMMING-NETH, V17, P77, DOI [10.3233/SPR-2009-0272, 10.1155/2009/561672]
   Chao Wang, 2011, 2011 Proceedings of IEEE International Conference on Services Computing (SCC 2011), P709, DOI 10.1109/SCC.2011.26
   Chao Wang, 2011, 2011 IEEE 9th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P107, DOI 10.1109/ISPA.2011.40
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Deng D. Y., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P137, DOI 10.1109/MICRO.2010.17
   Gupta G, 2011, INT SYMP MICROARCH, P59
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Hayashi A, 2011, LECT NOTES COMPUT SC, V6548, P184, DOI 10.1007/978-3-642-19595-2_13
   Jenista JC, 2011, ACM SIGPLAN NOTICES, V46, P57, DOI 10.1145/2038037.1941563
   Jia Zhang, 2011, 2011 Proceedings of IEEE International Conference on Services Computing (SCC 2011), P48, DOI 10.1109/SCC.2011.120
   Kotha Aparna, 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P547, DOI 10.1109/MICRO.2010.27
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Ma S, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P413, DOI 10.1145/2024723.2000113
   Mehrara M, 2011, INT S HIGH PERF COMP, P87, DOI 10.1109/HPCA.2011.5749719
   Mladen B., 2008, DISTRIBUTED SIMULTAN, P201
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Planas J, 2009, INT J HIGH PERFORM C, V23, P284, DOI 10.1177/1094342009106195
   Stantchev V, 2011, IEEE T SERV COMPUT, V4, P85, DOI 10.1109/TSC.2010.15
   Suh JH, 2009, CONF PROC INT SYMP C, P46, DOI 10.1145/1555815.1555763
   TOMASULO RM, 1967, IBM J RES DEV, V11, P25, DOI 10.1147/rd.111.0025
   Wang C, 2017, IEEE T PARALL DISTR, V28, P2993, DOI 10.1109/TPDS.2017.2701828
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang C, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS), P662, DOI 10.1109/ICWS.2016.91
   Wang C, 2012, J SUPERCOMPUT, V62, P1404, DOI 10.1007/s11227-012-0810-x
   Wentzlaff David, 2009, Operating Systems Review, V43, P76, DOI 10.1145/1531793.1531805
   Yazdanbakhsh A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P482, DOI 10.1145/2830772.2830810
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou JH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P1146
NR 35
TC 7
Z9 7
U1 3
U2 15
PD JAN 1
PY 2021
VL 14
IS 1
BP 262
EP 273
DI 10.1109/TSC.2017.2777478
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Chakraborty, I
   Roy, S
   Sridharan, S
   Ali, M
   Ankit, A
   Jain, S
   Raghunathan, A
AF Chakraborty, Indranil
   Roy, Sourjya
   Sridharan, Shrihari
   Ali, Mustafa
   Ankit, Aayush
   Jain, Shubham
   Raghunathan, Anand
GP IEEE
TI Design Tools for Resistive Crossbar based Machine Learning Accelerators
SO 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   CIRCUITS AND SYSTEMS (AICAS)
DT Proceedings Paper
CT IEEE 3rd International Conference on Artificial Intelligence Circuits
   and Systems (AICAS)
CY JUN 06-09, 2021
CL ELECTR NETWORK
AB Resistive crossbar based accelerators for Machine Learning (ML) have attracted great interest as they offer the prospect of high density on-chip storage as well as efficient in-memory matrix-vector multiplication (MVM) operations. Despite their promises, they present several design challenges, such as high write costs, overhead of analog-to-digital and digital-to-analog converters and other peripheral circuits, and accuracy degradation due to the the analog nature of in-memory computing coupled with device and circuit level non-idealities. The unique characteristics of crossbar-based accelerators pose unique challenges for design automation. We outline a design flow for crossbar-based accelerators, and elaborate on some key tools involved in such a flow. Specifically, we discuss architectural estimation of metrics such as power, performance and area, and functional simulation to evaluate algorithmic accuracy considering the impact of non-idealities.
C1 [Chakraborty, Indranil; Roy, Sourjya; Sridharan, Shrihari; Ali, Mustafa; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Ankit, Aayush] Microsoft Corp, Mountain View, CA 94043 USA.
   [Jain, Shubham] IBM Res, Yorktown Hts, NY 10598 USA.
RP Chakraborty, I (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
CR Ankit A, 2020, IEEE T COMPUT, V69, P1128, DOI 10.1109/TC.2020.2998456
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit A, 2017, ICCAD-IEEE ACM INT, P533, DOI 10.1109/ICCAD.2017.8203823
   Chakraborty I, 2020, APPL PHYS REV, V7, DOI 10.1063/1.5113536
   Chakraborty I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218688
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain S, 2021, IEEE T COMPUT AID D, V40, P326, DOI 10.1109/TCAD.2020.3000185
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Long Y, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218737
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Raghunathan A., 2021, TXSIM MODELING TRAIN
   Rasch MJ, 2020, IEEE DES TEST, V37, P19, DOI 10.1109/MDAT.2019.2952341
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Vlasov Y., 2016, FRONT NEUROSCI-SWITZ, V10
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2021
DI 10.1109/AICAS51828.2021.9458433
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kodithuwakku, J
   Arachchi, DD
   Rajasekera, J
AF Kodithuwakku, Janith
   Arachchi, Dilki Dandeniya
   Rajasekera, Jay
TI An Emotion and Attention Recognition System to Classify the Level of
   Engagement to a Video Conversation by Participants in Real Time Using
   Machine Learning Models and Utilizing a Neural Accelerator Chip
SO ALGORITHMS
DT Article
DE artificial intelligence (AI); convolutional neural network (CNN); facial
   emotion recognition (FER); support vector machine (SVM)
AB It is not an easy task for organizers to observe the engagement level of a video meeting audience. This research was conducted to build an intelligent system to enhance the experience of video conversations such as virtual meetings and online classrooms using convolutional neural network (CNN)- and support vector machine (SVM)-based machine learning models to classify the emotional states and the attention level of the participants to a video conversation. This application visualizes their attention and emotion analytics in a meaningful manner. This proposed system provides an artificial intelligence (AI)-powered analytics system with optimized machine learning models to monitor the audience and prepare insightful reports on the basis of participants' facial features throughout the video conversation. One of the main objectives of this research is to utilize the neural accelerator chip to enhance emotion and attention detection tasks. A custom CNN developed by Gyrfalcon Technology Inc (GTI) named GnetDet was used in this system to run the trained model on their GTI Lightspeeur 2803 neural accelerator chip.
C1 [Kodithuwakku, Janith; Arachchi, Dilki Dandeniya; Rajasekera, Jay] Tokyo Int Univ, Digital Business & Innovat, Saitama 3501197, Japan.
RP Kodithuwakku, J; Rajasekera, J (corresponding author), Tokyo Int Univ, Digital Business & Innovat, Saitama 3501197, Japan.
EM mjpkodithuwakku@gmail.com; dadmahindika@gmail.com; jrr@tiu.ac.jp
CR [Anonymous], 2009, AFF COMP INT INT WOR, P1, DOI DOI 10.1109/ACII.2009.5349489
   [Anonymous], 1978, APA PSYCTESTS, DOI DOI 10.1037/T27734-000
   Ardakani A, 2020, IEEE T COMPUT, V69, P138, DOI 10.1109/TC.2019.2941875
   Bradski G., 2008, LEARNING OPENCV COMP
   Chen LY, 2012, IERI PROC, V2, P781, DOI 10.1016/j.ieri.2012.06.171
   Chiang HS, 2018, J MED BIOL ENG, V38, P847, DOI 10.1007/s40846-017-0344-z
   Cordel MO, 2019, PROC CVPR IEEE, P4021, DOI 10.1109/CVPR.2019.00415
   Correia AP, 2020, DISTANCE EDUC, V41, P429, DOI 10.1080/01587919.2020.1821607
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Dlib, 2022, WEB DLIB DOC
   Ekman P., 1999, HDB COGNITION EMOTIO, V98, P16, DOI [DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   GTI, 2022, WEB GYRF TECHN INC O
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kramer O, 2016, STUD BIG DATA, V20, P45, DOI 10.1007/978-3-319-33383-0_5
   Li Y., 2011, P 2011 INT WORKSH UB, P33, DOI [DOI 10.1145/2030092.2030099, 10.1145/2030092.2030099]
   Liu SS, 2019, P IEEE, V107, P1697, DOI 10.1109/JPROC.2019.2915983
   Liu X, 2022, IEEE T COMPUT SOC SY, V9, P252, DOI 10.1109/TCSS.2021.3059318
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   OpenCV, 2022, WEB OPENCV DOC
   PyImageSearch, 2022, WEBARTICLE PYIMAGESE
   Rahayu D., 2020, J ELT RES, V5, P68
   Sarsenov A., 2017, P 2017 IEEE 11 INT C, P1
   Scikit-learn, 2022, WEB SUPP VECT MACH S
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Wu SW, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P40, DOI 10.1145/3340555.3353739
   Xia L, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION (ICICTA), P256, DOI 10.1109/ICICTA.2014.69
   Yu W., 2016, P 33 INT C MACH LEAR
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zoom, 2022, WEB NAT SDKS ZOOM SO
NR 31
TC 3
Z9 3
U1 2
U2 8
PD MAY
PY 2022
VL 15
IS 5
AR 150
DI 10.3390/a15050150
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Tzanos, G
   Kachris, C
   Soudris, D
AF Tzanos, Georgios
   Kachris, Christoforos
   Soudris, Dimitrios
GP IEEE
TI Hardware Acceleration on Gaussian Naive Bayes Machine Learning Algorithm
SO 2019 8TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS
   TECHNOLOGIES (MOCAST)
DT Proceedings Paper
CT 8th International Conference on Modern Circuit and System Technologies
   (MOCAST)
CY MAY 13-15, 2019
CL Thessaloniki, GREECE
AB Naive Bayes is one of the most effective and efficient classification algorithms and its classifiers still tend to perform very well under unrealistic assumptions. Especially for small sample sizes, naive Bayes classifiers can outperform the more powerful classifiers. Therefore the acceleration of such an algorithm becomes a great asset in machine learning applications. The SDSoC environment provides a framework for developing and delivering hardware accelerated embedded processor applications using standard programming languages. A Hardware Acceleration project has been implemented on the all-programmable MPSoC and it has been evaluated on a typical machine learning application based on Naive Bayes. The Naive Bayes kernel has been developed as accelerator in both training and prediction part. The performance evaluation shows that the heterogeneous accelerator-based MPSoC can achieve up to 16.8x system speedup compared with an embedded ARM processor in the training part and 14x speedup in the prediction part. The accelerator had been also integrated with Python using the Pynq-Z1 device.
C1 [Tzanos, Georgios; Soudris, Dimitrios] NTUA, Dept Elect & Comp Engn, Athens, Greece.
   [Kachris, Christoforos] NTUA, ICCS, Athens, Greece.
   [Kachris, Christoforos] DUTH, Komotini, Greece.
RP Tzanos, G (corresponding author), NTUA, Dept Elect & Comp Engn, Athens, Greece.
EM grg.tzan@gmail.com; kachris@microlab.ntua.gr; dsoudris@microlab.ntua.gr
CR [Anonymous], IET COMPUTERS DIGITA
   [Anonymous], P 2017 2 INT C MULT
   [Anonymous], PHILOS T
   [Anonymous], CVPR 2011 WORKSH COL
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chen YP, 2016, CACS INT AUTOMAT CON, P7, DOI 10.1109/CACS.2016.7973875
   Nguyen D, 2006, IEEE T SYST MAN CY B, V36, P902, DOI 10.1109/TSMCB.2005.862728
NR 7
TC 8
Z9 8
U1 0
U2 0
PY 2019
DI 10.1109/mocast.2019.8741875
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ankit, A
   El Hajj, I
   Chalamalasetti, SR
   Ndu, G
   Foltin, M
   Williams, RS
   Faraboschi, P
   Hwu, WM
   Strachan, JP
   Roy, K
   Milojicic, DS
AF Ankit, Aayush
   El Hajj, Izzat
   Chalamalasetti, Sai Rahul
   Ndu, Geoffrey
   Foltin, Martin
   Williams, R. Stanley
   Faraboschi, Paolo
   Hwu, Wen-mei
   Strachan, John Paul
   Roy, Kaushik
   Milojicic, Dejan S.
GP ACM
TI PUMA: A Programmable Ultra-efficient Memristor-based Accelerator for
   Machine Learning Inference
SO TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR
   PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV)
DT Proceedings Paper
CT 24th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY APR 13-17, 2019
CL Brown Univ, Providence, RI
HO Brown Univ
DE memristors; accelerators; machine learning; neural networks
ID MEMORY; SCALE; COPROCESSOR
AB Memristor crossbars are circuits capable of performing analog matrix-vector multiplications, overcoming the fundamental energy efficiency limitations of digital logic. They have been shown to be effective in special-purpose accelerators for a limited set of neural network applications.
   We present the Programmable Ultra-efficient Memristor-based Accelerator (PUMA) which enhances memristor crossbars with general purpose execution units to enable the acceleration of a wide variety of Machine Learning (ML) inference workloads. PUMA's microarchitecture techniques exposed through a specialized Instruction Set Architecture (ISA) retain the efficiency of in-memory computing and analog circuitry, without compromising programmability.
   We also present the PUMA compiler which translates high-level code to PUMA ISA. The compiler partitions the computational graph and optimizes instruction scheduling and register allocation to generate code for large and complex workloads to run on thousands of spatial cores.
   We have developed a detailed architecture simulator that incorporates the functionality, timing, and power models of PUMA's components to evaluate performance and energy consumption. A PUMA accelerator running at 1 GHz can reach area and power efficiency of 577 GOPS/s/mm(2) and 837 GOPS/s/W, respectively. Our evaluation of diverse ML applications from image recognition, machine translation, and language modelling (5M-800M synapses) shows that PUMA achieves up to 2,446x energy and 66x latency improvement for inference compared to state-of-the-art GPUs. Compared to an application-specific memristor-based accelerator, PUMA incurs small energy overheads at similar inference latency and added programmability.
C1 [Ankit, Aayush; Roy, Kaushik] Purdue Univ, W Lafayette, IN 47907 USA.
   [Ankit, Aayush; Chalamalasetti, Sai Rahul; Ndu, Geoffrey; Foltin, Martin; Williams, R. Stanley; Faraboschi, Paolo; Strachan, John Paul; Milojicic, Dejan S.] Hewlett Packard Enterprise, San Jose, CA 95002 USA.
   [El Hajj, Izzat] Amer Univ Beirut, Beirut, Lebanon.
   [El Hajj, Izzat; Hwu, Wen-mei] Univ Illinois, Champaign, IL USA.
RP Ankit, A (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.; Ankit, A (corresponding author), Hewlett Packard Enterprise, San Jose, CA 95002 USA.
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alwani M., 2016, MICROPAGE, P1
   Ambrosi Joao, 2018, REB COMP ICRC 2018 I
   Ankit A, 2017, DES AUT CON, DOI 10.1145/3061639.3062311
   Ankit A, 2017, ICCAD-IEEE ACM INT, P533, DOI 10.1109/ICCAD.2017.8203823
   [Anonymous], 2017, NATURE NANOTECHNOLOG
   [Anonymous], 2016, MICRO
   [Anonymous], 1996, APPL LINEAR STAT MOD
   [Anonymous], 2018, TSMC ANN REPORT 2017
   [Anonymous], 2016, 2016 53 ACM EDAC IEE
   [Anonymous], 2016, P 43 INT S COMP ARCH
   [Anonymous], J NANOMATERIALS, DOI DOI 10.1155/2016/5639129
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2017, P 50 ANN IEEE ACM IN
   [Anonymous], 2002, LOGISTIC REGRESSION
   [Anonymous], 2013, BOOKSIM 2 0 USERS GU
   [Anonymous], 2017, IEEE T COMPUTER AIDE
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2016, MATH PROBL ENG, DOI DOI 10.1155/2016/3763512
   [Anonymous], 2017, ARXIV170309039
   [Anonymous], 2016, MICRO
   [Anonymous], 2020, COMMUN ACM, DOI DOI 10.1145/3422622
   Bhandari K, 2016, ACM SIGPLAN NOTICES, V51, P677, DOI 10.1145/3022671.2984019
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Cavigelli Lukas, 2015, P 25 GREAT LAK S VLS, P6
   Chakrabarti DR, 2014, ACM SIGPLAN NOTICES, V49, P433, DOI [10.1145/2660193.2660224, 10.1145/2714064.2660224]
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen GY, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P191, DOI 10.1145/3123939.3124543
   Chen TS, 2014, IEEE DECIS CONTR P, P265, DOI 10.1109/CDC.2014.7039392
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Coburn J, 2011, ACM SIGPLAN NOTICES, V46, P105, DOI [10.1145/1961295.1950380, 10.1145/1961296.1950380]
   Cohen Nachshon, 2018, P ACM PROGRAM LANG, V2, DOI DOI 10.1145/3276523
   Collobert R, BIGLEARN NIPS WORKSH
   Condit Jeremy, 2009, P ACM SIGOPS 22 S OP
   Debnath B., 2016, ACM SIGOPS OPERATING, V49, P18
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   El Hajj I, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133869
   El Hajj I, 2016, ACM SIGPLAN NOTICES, V51, P353, DOI 10.1145/2954679.2872366
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Feinberg B., 2018, 2018 IEEE INT S HIGH
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Guo K, 2017, ARXIV171208934
   Guo XN, 2017, IEEE INFOCOM SER
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hayakawa Y, 2015, S VLSI TECH
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Izraelevitz Joseph, 2016, Distributed Computing. 30th International Symposium, DISC 2016. Proceedings: LNCS 9888, P313, DOI 10.1007/978-3-662-53426-7_23
   Ji Yu, 2018, P 23 INT C ARCH SUPP, P448
   Joshi A, 2017, INT S HIGH PERF COMP, P361, DOI 10.1109/HPCA.2017.50
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kahng A. B., 2012, TECHNICAL REPORT
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim K, 2016, DES AUT CON, DOI 10.1145/2897937.2898011
   Kim Y, 2015, ACM J EMERG TECH COM, V11, DOI 10.1145/2700234
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lee D, 2013, IEEE T VLSI SYST, V21, P1583, DOI 10.1109/TVLSI.2012.2217514
   Liu D, 2015, PROCEEDINGS OF 2015 INTERNATIONAL SYMPOSIUM - COLLEGE FOREIGN LANGUAGES EDUCATION REFORM AND INNOVATION, P369
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Liu XF, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/950262
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Muralimanohar N, 2009, TECHNICAL REPORT
   Murmann Boris, 2015, IEEE Solid-State Circuits Magazine, V7, P58, DOI 10.1109/MSSC.2015.2442393
   Murmann Boris, 2011, ADC PERFORMANCE SURV
   Murray Sean, 2016, P 49 ANN IEEE ACM IN, P1
   Nalli S, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P135, DOI 10.1145/3037697.3037730
   Ogleari MA, 2018, INT S HIGH PERF COMP, P336, DOI 10.1109/HPCA.2018.00037
   Oukid I, 2017, PROC VLDB ENDOW, V10, P1166, DOI 10.14778/3137628.3137629
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park Seongwook, 2015, SOL STAT CIRC C ISSC
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Ren A, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P405, DOI 10.1145/3037697.3037746
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Roth Ron M, 2017, ARXIV170806892
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sengupta A, 2016, IEEE T BIOMED CIRC S, V10, P1152, DOI 10.1109/TBCAS.2016.2525823
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Song MC, 2018, INT S HIGH PERF COMP, P66, DOI 10.1109/HPCA.2018.00016
   Tanaka T, 1998, PHYS REV E, V58, P2302, DOI 10.1103/PhysRevE.58.2302
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Volos H, 2011, ACM SIGPLAN NOTICES, V46, P91, DOI [10.1145/1961296.1950379, 10.1145/1961295.1950379]
   Wang Q, 2016, ACM J EMERG TECH COM, V12, DOI 10.1145/2894756
   Wang QS, 2017, IEEE IND ELEC, P2600, DOI 10.1109/IECON.2017.8216437
   Wang YinQian, 2017, The Proceedings of the Fourteenth China Pig Industry Development Conference in 2016, Tianjin, China, 1 - 2 September, 2016, P33
   Wang YX, 2017, P INT COMP SOFTW APP, P85, DOI 10.1109/COMPSAC.2017.12
   Waser R, 2009, ADV MATER, V21, P2632, DOI 10.1002/adma.200900375
   Yang Jun, 2015, 13 USENIX C FILE STO, P167
   Yazdani Reza, 2016, P INT S MICROARCHITE, P1, DOI DOI 10.1109/MICRO.2016.7783750
   Yu Ji, 2018, ACM SIGPLAN Notices, V53, P448, DOI 10.1145/3296957.3173205
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang JX, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/4350965
   Zhuo Wang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3884, DOI 10.1109/ICASSP.2014.6854329
NR 116
TC 204
Z9 210
U1 2
U2 12
PY 2019
BP 715
EP 731
DI 10.1145/3297858.3304049
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Xu, D
   Özgüler, AB
   Di Guglielmo, G
AF Xu, David
   Ozguler, A. Baris
   Di Guglielmo, Giuseppe
GP IEEE
TI Neural network accelerator for quantum control
SO 2022 IEEE/ACM THIRD INTERNATIONAL WORKSHOP ON QUANTUM COMPUTING SOFTWARE
   (QCS)
DT Proceedings Paper
CT IEEE/ACM 3rd International Workshop on Quantum Computing Software (QCS)
CY NOV 13-18, 2022
CL Dallas, TX
DE hls4ml; machine learning; neural networks; quantum control; FPGA;
   low-power; low-latency
AB Efficient quantum control is necessary for practical quantum computing implementations with current technologies. Conventional algorithms for determining optimal control parameters are computationally expensive, largely excluding them from use outside of the simulation. Existing hardware solutions structured as lookup tables are imprecise and costly. By designing a machine learning model to approximate the results of traditional tools, a more efficient method can be produced. Such a model can then be synthesized into a hardware accelerator for use in quantum systems. In this study, we demonstrate a machine learning algorithm for predicting optimal pulse parameters. This algorithm is lightweight enough to fit on a low-resource FPGA and perform inference with a latency of 175 ns and pipeline interval of 5 ns with > 0.99 gate fidelity. In the long term, such an accelerator could be used near quantum computing hardware where traditional computers cannot operate, enabling quantum control at a reasonable cost at low latencies without incurring large data bandwidths outside of the cryogenic environment.
C1 [Xu, David] Columbia Univ, New York, NY USA.
   [Ozguler, A. Baris; Di Guglielmo, Giuseppe] Fermilab Natl Accelerator Lab, Batavia, IL 60510 USA.
RP Özgüler, AB (corresponding author), Fermilab Natl Accelerator Lab, Batavia, IL 60510 USA.
EM dx2199@columbia.edu; aozguler@fnal.gov; gdg@fnal.gov
CR Alam MS, 2022, Arxiv, DOI arXiv:2204.08605
   Petersson NA, 2020, Arxiv, DOI arXiv:2001.01013
   Ball H, 2021, QUANTUM SCI TECHNOL, V6, DOI 10.1088/2058-9565/abdca6
   Borras H, 2022, Arxiv, DOI arXiv:2206.11791
   Butko A, 2020, 2020 INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC 2020), P66, DOI 10.1109/ICRC2020.2020.00011
   Coelho CN Jr, 2021, Arxiv, DOI arXiv:2006.10159
   Deiana AM, 2022, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.787421
   Elsken T, 2019, J MACH LEARN RES, V20
   Fahim F, 2021, Arxiv, DOI arXiv:2103.05579
   Farhi E, 2014, Arxiv, DOI [arXiv:1411.4028, DOI 10.48550/ARXIV.1411.4028]
   Fellous-Asiani M, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.040335
   github, ML4QUANTUM
   Gunther S., 2021, QUANDARY OPESOURCE C
   Jin HF, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1946, DOI 10.1145/3292500.3330648
   Johansson JR, 2012, COMPUT PHYS COMMUN, V183, P1760, DOI 10.1016/j.cpc.2012.02.021
   Koolstra G, 2022, PHYS REV X, V12, DOI 10.1103/PhysRevX.12.031017
   Liang ZD, 2022, Arxiv, DOI arXiv:2203.17267
   LLNL, JUQBOXJL
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Overwater Ramon W. J., 2022, IEEE Transactions on Quantum Engineering, V3, DOI 10.1109/TQE.2022.3174017
   Özgüler AB, 2022, Arxiv, DOI arXiv:2207.14006
   Ozguler AB, 2022, Arxiv, DOI arXiv:2201.07787
   Koch CP, 2022, Arxiv, DOI arXiv:2205.12110
   Pedersen LH, 2007, PHYS LETT A, V367, P47, DOI 10.1016/j.physleta.2007.02.069
   Petersson N, 2021, Arxiv, DOI arXiv:2106.14310
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Stefanazzi L, 2022, REV SCI INSTRUM, V93, DOI 10.1063/5.0076249
   Xue X, 2021, NATURE, V593, P205, DOI 10.1038/s41586-021-03469-4
NR 28
TC 0
Z9 0
U1 3
U2 3
PY 2022
BP 43
EP 49
DI 10.1109/QCS56647.2022.00010
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Ni, LB
   Huang, HT
   Yu, H
AF Ni, Leibin
   Huang, Hantao
   Yu, Hao
GP IEEE
TI On-line Machine Learning Accelerator on Digital RRAM-Crossbar
SO 2016 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 22-25, 2016
CL Montreal, CANADA
ID CLASSIFICATION; CLASSIFIERS
AB On-line machine learning has become the need for future data analytics. This work will show an l(2) norm based hardware solver for on-line machine learning that can significantly reduce training time when compared to the traditional gradient-based solution using backward propagation. We will show that the intensive matrix-vector multiplication in l(2) norm solution can be mapped onto a distributed in-memory accelerator using the recent resistive switching random access memory (RRAM) device. A digitized matrix-vector multiplication accelerator will be developed based on the distributed RRAM-crossbar. Such a distributed RRAM-crossbar architecture can utilize the reformulated l(2) norm solver with a scalable and energy-efficient solution for real-time training and testing in image recognition. Experiment results have shown that significant speedup can be achieved for matrix-vector multiplication in the l(2) norm solver such that the overall training and testing time can be reduced respectively. In addition, large energy saving can be also achieved when compared to the traditional CMOS-based out-of-memory computing architecture.
C1 [Ni, Leibin; Huang, Hantao; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM haoyu@ntu.edu.sg
CR Akinaga  H., 2010, P IEEE
   Chua KS, 2003, PATTERN RECOGN LETT, V24, P75, DOI 10.1016/S0167-8655(02)00190-3
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G. B., 2008, WORKSHOP FACES INREA, P1
   Huang GB, 2000, IEEE T NEURAL NETWOR, V11, P799, DOI 10.1109/72.846750
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kim Y., 2012, SOC C SOCC
   Lee H., 2008, EL DEC M IEEE
   Lu W., 2011, DES AUT C AS S PAC A
   Müller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022
   Ni L., 2016, DES AUT C AS S PAC A
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wang Y, 2016, IEEE T MOBILE COMPUT, V15, P1965, DOI 10.1109/TMC.2015.2483501
NR 17
TC 9
Z9 9
U1 0
U2 2
PY 2016
BP 113
EP 116
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zhang, Z
   Song, MH
   Huang, XBA
AF Zhang, Zhe
   Song, Minghao
   Huang, Xiaobiao
TI Online accelerator optimization with a machine learning-based stochastic
   algorithm
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
DT Article
DE online optimization; Gaussian process; evolutionary algorithm
AB Online optimization is critical for realizing the design performance of accelerators. Highly efficient stochastic optimization algorithms are needed for many online accelerator optimization problems in order to find the global optimum in the non-linear, coupled parameter space. In this study, we propose to use the multi-generation Gaussian process optimizer for online accelerator optimization and demonstrate that the algorithm is significantly more efficient than other stochastic algorithms that are commonly used in the accelerator community.
C1 [Zhang, Zhe; Song, Minghao; Huang, Xiaobiao] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Song, Minghao] IIT, Dept Phys, Chicago, IL 60616 USA.
RP Huang, XBA (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM xiahuang@slac.stanford.edu
CR [Anonymous], 2013, 22 INT C COMPUTER CO, DOI DOI 10.1109/ICCCN.2013.6614105
   Auer P., 2002, J MACHINE LEARNING R, V3, P397, DOI [10.1162/153244303321897663, DOI 10.4271/610369]
   Bazarov IV, 2005, PHYS REV SPEC TOP-AC, V8, DOI 10.1103/PhysRevSTAB.8.034202
   Bergan WF, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.054601
   Borland M., 2009, P 23 PART ACC C VANC, P3850
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 1995, Complex Systems, V9, P115
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   GPy, 2012, GPY GAUSS PROC FRAM
   Huang X., 2016, P NAPAC2016 CHIC IL
   Huang X., 2019, BEAM BASED CORRECTIO
   Huang X., 2019, ARXIV190700250
   Huang XB, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.104601
   Huang XB, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.084001
   Huang XB, 2014, NUCL INSTRUM METH A, V757, P48, DOI 10.1016/j.nima.2014.04.078
   Huang XB, 2013, NUCL INSTRUM METH A, V726, P77, DOI 10.1016/j.nima.2013.05.046
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Liuzzo S., 2016, P IPAC2016 BUS KOR
   Martin I., 2016, P IPAC2016 BUS KOR
   MCKAY MD, 1979, TECHNOMETRICS, V21, P239, DOI 10.2307/1268522
   Olsson DK., 2018, P IPAC2018
   Pulampong T., 2017, ONLINE OPTIMIZATION
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Smaluk V., 2019, P IPAC2019 MELB AUST
   Song MH, 2020, NUCL INSTRUM METH A, V976, DOI 10.1016/j.nima.2020.164273
   Tian K, 2014, PHYS REV SPEC TOP-AC, V17, DOI 10.1103/PhysRevSTAB.17.020703
   Wu J., 2017, P FEL 2017 SANT FE N
   Yang X, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39208-z
   Zhou G., 2016, P IPAC2016 BUS KOR
NR 29
TC 4
Z9 4
U1 4
U2 10
PD MAR
PY 2021
VL 2
IS 1
AR 015014
DI 10.1088/2632-2153/abc81e
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Tumeo, A
   Minutoli, M
   Castellana, VG
   Manzano, J
   Amatya, V
   Brooks, D
   Wei, GY
AF Tumeo, Antonino
   Minutoli, Marco
   Castellana, Vito Giovanni
   Manzano, Joseph
   Amatya, Vinay
   Brooks, David
   Wei, Gu-Yeon
GP IEEE
TI Invited: Software Defined Accelerators From Learning Tools Environment
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
DE High-Level Synthesis; Agile Hardware Development; Extreme
   Specialization; Machine Learning
ID OPTIMIZATION
AB Next generation systems, such as edge devices, will need to provide efficient processing of machine learning (ML) algorithms along several metrics, including energy, performance, area, and latency. However, the quickly evolving field of ML makes it extremely difficult to generate accelerators able to support a wide variety of algorithms. At the same time, designing accelerators in hardware description languages (HDLs) by hand is hard and time consuming, and does not allow quick exploration of the design space. In this paper we present the Software Defined Accelerators From Learning Tools Environment (SODALITE), an automated open source high-level ML framework-to-verilog compiler targeting ML Application-Specific Integrated Circuits (ASICs) chiplets. The SODALITE approach will implement optimal designs by seamlessly combining custom components generated through high-level synthesis (HLS) with templated and fully tunable Intellectual Properties (IPs) and macros, integrated in an extendable resource library. Through a closed loop design space exploration engine, developers will be able to quickly explore their hardware designs along different dimensions.
C1 [Tumeo, Antonino; Minutoli, Marco; Castellana, Vito Giovanni; Manzano, Joseph; Amatya, Vinay] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
   [Brooks, David; Wei, Gu-Yeon] Harvard Univ, Cambridge, MA 02138 USA.
RP Tumeo, A (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99352 USA.
EM antonino.tumeo@pnnl.gov; marco.minutoli@pnnl.gov;
   vitogiovanni.castellana@pnnl.gov; joseph.manzano@pnnl.gov;
   vinay.amatya@pnnl.gov; dbrooks@eecs.harvard.edu; guyeon@eecs.harvard.edu
CR A. S. Foundation, 2018, AP MXNET INC
   [Anonymous], 2018, ARXIV
   [Anonymous], 2019, OPEN NEURAL NETWORK
   Castellana VG, 2014, DES AUT TEST EUROPE
   Ceriani M., 2010, P GEN EV COMP C, P1267
   Chen T., 2018, CORR
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   DARPA, RES TEAMS SEL LOW BA
   Ferrandi F, 2007, IC-SAMOS: 2007 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION, PROCEEDINGS, P145, DOI 10.1109/ICSAMOS.2007.4285745
   Ferrandi F, 2010, ASIA S PACIF DES AUT, P790
   Ferrandi F, 2010, IEEE T COMPUT AID D, V29, P911, DOI 10.1109/TCAD.2010.2048354
   G. Inc, 2019, XLA IS COMP OPT TENS
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lattner C., 2020, MLIR COMPILER INFRAS
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Minutoli M., 2016, ICCAD 2016 IEEE ACM, P129
   Pilato C, 2008, J SYST ARCHITECT, V54, P1046, DOI 10.1016/j.sysarc.2008.04.010
   Plana LA, 2011, ACM J EMERG TECH COM, V7, DOI 10.1145/2043643.2043647
   Ragan-Kelley J, 2018, COMMUN ACM, V61, P106, DOI 10.1145/3150211
   Sharma H, 2016, INT SYMP MICROARCH
   T. K. Group, 2019, KERAS
   Tumeo A., 2009, CODES ISSS09 7 IEEE, P443
NR 23
TC 0
Z9 0
U1 0
U2 0
PY 2020
AR 65.2
DI 10.1109/dac18072.2020.9218489
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Li, Z
   Wang, YQ
   Zhi, T
   Chen, TS
AF Li, Zhen
   Wang, Yuqing
   Zhi, Tian
   Chen, Tianshi
TI A survey of neural network accelerators
SO FRONTIERS OF COMPUTER SCIENCE
DT Review
DE neural networks; accelerators; FPGAs; ASICs; DianNao series
ID LEARNING ALGORITHM; FAULT-TOLERANCE; MODEL; IMPLEMENTATION;
   ARCHITECTURE; RECOGNITION; COPROCESSOR; PERFORMANCE; PROCESSOR; SYSTEM
AB Machine-learning techniques have recently been proved to be successful in various domains, especially in emerging commercial applications. As a set of machine-learning techniques, artificial neural networks (ANNs), requiring considerable amount of computation and memory, are one of the most popular algorithms and have been applied in a broad range of applications such as speech recognition, face identification, natural language processing, ect. Conventionally, as a straightforward way, conventional CPUs and GPUs are energy-inefficient due to their excessive effort for flexibility. According to the aforementioned situation, in recent years, many researchers have proposed a number of neural network accelerators to achieve high performance and low power consumption. Thus, the main purpose of this literature is to briefly review recent related works, as well as the DianNao-family accelerators. In summary, this review can serve as a reference for hardware researchers in the area of neural networks.
C1 [Li, Zhen; Zhi, Tian; Chen, Tianshi] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Wang, Yuqing] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
RP Chen, TS (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
EM chentianshi@ict.ac.cn
CR Afifi A, 2009, 2009 EUROPEAN CONFERENCE ON CIRCUIT THEORY AND DESIGN, VOLS 1 AND 2, P563, DOI 10.1109/ECCTD.2009.5275035
   Al Maashri A, 2012, DES AUT CON, P579
   [Anonymous], 1974, NEW TOOLS PREDICTION
   [Anonymous], 2014, CVPR WARKSHOPS
   [Anonymous], 2015, P 2015 52 ACM EDAC I
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   [Anonymous], 2013, P 40 ANN INT S COMPU
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2009, CLUSTER 09, DOI DOI 10.1109/CLUSTR.2009.5289193
   [Anonymous], P IEEE DES AUT C
   Azoff E. M., 1994, NEURAL NETWORK TIME
   Back AD, 1991, NEURAL COMPUT, V3, P375, DOI 10.1162/neco.1991.3.3.375
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Cardells-Tormo F, 2005, IEEE WRK SIG PRO SYS, P209, DOI 10.1109/SIPS.2005.1579866
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chandra P, 2003, IEEE IJCNN, P489
   Chang SW, 2006, TENCON IEEE REGION, P128
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Ciresan D.C., 2011, P INT JOINT C ART IN
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Coates A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4287, DOI 10.1109/IROS.2009.5354084
   Dawwd SA, 2013, IEEE I C ELECT CIRC, P221, DOI 10.1109/ICECS.2013.6815394
   Dawwd Shefa A., 2009, IDT 09, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Dias F. M., 2008, INT J CIRCUITS SYSTE, P329
   Ding SF, 2013, ARTIF INTELL REV, V39, P251, DOI 10.1007/s10462-011-9270-6
   Draper BA, 2003, IEEE T IMAGE PROCESS, V12, P1543, DOI 10.1109/TIP.2003.819226
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Esmaeilzadeh H, 2006, P IEEE INT S CIRC SY
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farabet Clement, 2011, COMP VIS PATT REC WO
   FRASCONI P, 1992, NEURAL COMPUT, V4, P120, DOI 10.1162/neco.1992.4.1.120
   George D, 2005, IEEE IJCNN, P1812
   Hameed Alnaish RA., 2014, ADV ARTIF NEURAL SYS, V17, P2014
   Harmon FG, 2005, NEURAL NETWORKS, V18, P772, DOI 10.1016/j.neunet.2005.06.030
   Hashmi A, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P1, DOI 10.1145/2024723.2000066
   Hebb D.O., 2005, ORG BEHAV NEUROPSYCH
   Hecht V., 1991, 1991 IEEE International Sympoisum on Circuits and Systems (Cat. No.91CH3006-4), P1897, DOI 10.1109/ISCAS.1991.176778
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu M, 2013, IEEE SYM COMPUT INT, P80, DOI 10.1109/CISDA.2013.6595431
   Iwata A., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P171, DOI 10.1109/IJCNN.1989.118695
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaastra I, 1996, NEUROCOMPUTING, V10, P215, DOI 10.1016/0925-2312(95)00039-9
   KAMP W, 1990, IEEE J SOLID-ST CIRC, V25, P735, DOI 10.1109/4.102668
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   Krizhevsky A, 2014, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Le Q., 2011, P INT C MACH LEARN
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   LEE SY, 1987, IEEE T PATTERN ANAL, V9, P590, DOI 10.1109/TPAMI.1987.4767947
   Liu D, 2015, PROCEEDINGS OF 2015 INTERNATIONAL SYMPOSIUM - COLLEGE FOREIGN LANGUAGES EDUCATION REFORM AND INNOVATION, P369
   McCulloch W. S., 1943, B MATH BIOPHYS, V5, P115, DOI [10.1007/BF02478259, DOI 10.1007/BF02478259]
   Merolla P., 2011, IEEE CUST INT CIRC C, P1, DOI DOI 10.1109/CICC.2011.6055294
   Mishra AK, 2006, ECOL MODEL, V198, P127, DOI 10.1016/j.ecolmodel.2006.04.017
   Muller M., 2010, EE TIM DES ARM VIRT, V26, p[70, 285]
   Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013
   Ordonez-Cardenas E., 2008, P 18 ACM GREAT LAK S, P333
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pereira LAM, 2014, COMP MED SY, P14, DOI 10.1109/CBMS.2014.25
   Pham PH, 2012, MIDWEST SYMP CIRCUIT, P1044, DOI 10.1109/MWSCAS.2012.6292202
   Pokrajac D, 2001, P ASAE ANN M
   PROTZEL PW, 1993, IEEE T NEURAL NETWOR, V4, P600, DOI 10.1109/72.238315
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rice KL, 2009, J SUPERCOMPUT, V47, P21, DOI 10.1007/s11227-008-0195-z
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Schemmel J, 2008, IEEE IJCNN, P431, DOI 10.1109/IJCNN.2008.4633828
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P82, DOI 10.1007/978-3-642-15825-4_9
   Siegelmann H. T., 2012, NEURAL NETWORKS ANAL
   SIEGELMANN HT, 1994, THEOR COMPUT SCI, V131, P331, DOI 10.1016/0304-3975(94)90178-3
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Stearns C C, 1988, P IEEE CUST INT CIRC
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C., 2014, P 2 INT C LEARN REPR
   TAM KY, 1991, OMEGA-INT J MANAGE S, V19, P429, DOI 10.1016/0305-0483(91)90060-7
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Vanhoucke V., 2011, IMPROVING SPEED NEUR
   West D, 2005, COMPUT OPER RES, V32, P2543, DOI 10.1016/j.cor.2004.03.017
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Zhang C, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P161, DOI 10.1109/SPAWDA.2015.7364463
   Zissis D, 2015, APPL SOFT COMPUT, V35, P652, DOI 10.1016/j.asoc.2015.07.002
NR 93
TC 23
Z9 31
U1 0
U2 82
PD OCT
PY 2017
VL 11
IS 5
BP 746
EP 761
DI 10.1007/s11704-016-6159-1
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Chen, YJ
   Chen, TS
   Xu, ZW
   Sun, NH
   Temam, O
AF Chen, Yunji
   Chen, Tianshi
   Xu, Zhiwei
   Sun, Ninghui
   Temam, Olivier
TI DianNao Family: Energy-Efficient Hardware Accelerators for Machine
   Learning
SO COMMUNICATIONS OF THE ACM
DT Article
AB Machine Learning (ML) tasks are becoming pervasive in a broad range of applications, and in a broad range of systems (from embedded systems to data centers). As computer architectures evolve toward heterogeneous multi-cores composed of a mix of cores and hardware accelerators, designing hardware accelerators for ML techniques can simultaneously achieve high efficiency and broad application scope.
   While efficient computational primitives are important for a hardware accelerator, inefficient memory transfers can potentially void the throughput, energy, or cost advantages of accelerators, that is, an Amdahl's law effect, and thus, they should become a first-order concern, just like in processors, rather than an element factored in accelerator design on a second step. In this article, we introduce a series of hardware accelerators (i.e., the DianNao family) designed for ML (especially neural networks), with a special emphasis on the impact of memory on accelerator design, performance, and energy. We show that, on a number of representative neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip DaDianNao system (a member of the DianNao family).
C1 [Chen, Yunji; Chen, Tianshi; Xu, Zhiwei; Sun, Ninghui] Chinese Acad Sci, ICT, Beijing, Peoples R China.
   [Temam, Olivier] Inria Saclay, Palaiseau, France.
RP Chen, YJ (corresponding author), Chinese Acad Sci, ICT, Beijing, Peoples R China.
EM cyj@ict.ac.cn; chentianshi@ict.ac.cn; zxu@ict.ac.cn; snh@ict.ac.cn;
   olivier.temam@inria.fr
CR Al Maashri A, 2012, DES AUT CON, P579
   [Anonymous], INT S VLSI CIRC VLSI
   [Anonymous], 2009, ENG MECH
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], INT S WORKL CHAR
   [Anonymous], INT S COMP ARCH
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chan E, 2013, ALGORITHMIC TRADING
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   da S AG, 2003, 16TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN, SBCCI 2003, PROCEEDINGS, P99
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hinton G, 2012, ARXIV
   Hussain H. M., 2011, Proceedings of the 2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), P248, DOI 10.1109/AHS.2011.5963944
   Keckler S., 2011, INT S MICR SAO PAOL
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Larkin D, 2006, LECT NOTES COMPUT SC, V4234, P1178
   Le Le Q.V. Q.V., 2012, ICML, P507
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Majumdar A, 2011, IEEE EMBED SYST LETT, V3, P42, DOI 10.1109/LES.2010.2100802
   Manolakos E. S., 2010, 2010 IEEE International Symposium on Circuits and Systems. ISCAS 2010, P4133, DOI 10.1109/ISCAS.2010.5537602
   Maruyama T, 2006, INT C PATT RECOG, P816
   Muller M., 2010, EE TIM DES ARM VIRT, V26, p[70, 285]
   Papadonikolakis M, 2010, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2010.39
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI DOI 10.1145/2485922.2485925
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sermanet P., 2012, PATTERN RECOGNITION
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
   Swanson S, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P291
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Vanhoucke V., 2011, DEEP LEARN UNS FEAT, V1
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Yeh YJ, 2007, LECT NOTES COMPUT SC, V4522, P512
NR 45
TC 105
Z9 146
U1 4
U2 89
PD NOV
PY 2016
VL 59
IS 11
BP 105
EP 112
DI 10.1145/2996864
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Zhu, HS
   Lo, D
   Cheng, LQ
   Govindaraju, R
   Ranganathan, P
   Erez, M
AF Zhu, Haishan
   Lo, David
   Cheng, Liqun
   Govindaraju, Rama
   Ranganathan, Parthasarathy
   Erez, Mattan
GP IEEE
TI Kelp: QoS for Accelerated Machine Learning Systems
SO 2019 25TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 25th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 16-20, 2019
CL Washington, DC
AB Development and deployment of machine learning (ML) accelerators inWarehouse Scale Computers (WSCs) demand significant capital investments and engineering efforts. However, even though heavy computation can be offloaded to the accelerators, applications often depend on the host system for various supporting tasks. As a result, contention on host resources, such as memory bandwidth, can significantly discount the performance and efficiency gains of accelerators. The impact of performance interference is further amplified in distributed learning, which has become increasingly common as model sizes continue to grow.
   In this work, we study the performance of four production machine learning workloads on three accelerator platforms. Our experiments show that these workloads are highly sensitive to host memory bandwidth contention, which can cause 40% average performance degradation when left unmanaged. To tackle this problem, we design and implement Kelp, a software runtime that isolates high priority accelerated ML tasks from memory resource interference. We evaluate Kelp with both production and artificial aggressor workloads, and compare its effectiveness with previously proposed solutions. Our evaluation shows that Kelp is effective in mitigating performance degradation of the accelerated tasks, and improves performance by 24% on average. Compared to previous work, Kelp reduces performance degradation of ML tasks by 7% and improves system efficiency by 17%. Our results further expose opportunities in future architecture designs.
C1 [Zhu, Haishan] Microsoft, Redmond, WA USA.
   [Zhu, Haishan; Lo, David; Cheng, Liqun; Govindaraju, Rama; Ranganathan, Parthasarathy] Google, Mountain View, CA USA.
   [Zhu, Haishan; Erez, Mattan] Univ Texas Austin, Austin, TX 78712 USA.
RP Zhu, HS (corresponding author), Microsoft, Redmond, WA USA.; Zhu, HS (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.
EM haishanz@utexas.edu; davidlo@google.com; liquncheng@google.com;
   govindaraju@google.com; parthas@google.com; mattan.erez@utexas.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Albericio J., 2016, COMP ARCH ISCA 2016
   Amazon, 2017, AM EC2 PRIC
   [Anonymous], P 44 ANN IEEE ACM IN
   [Anonymous], FIELD PROGR LOG APPL
   [Anonymous], 2017, INT 64 IA 32 ARCH SO
   [Anonymous], 2009, INTR INT QUICKPATH I
   [Anonymous], 2011, SCALING MACHINE LEAR
   Canziani A., 2016, ARXIV
   Cavigelli L., 2015, P 25 ED GREAT LAK S
   Chen  Q., 2017, P 22 INT C ARCH SUPP
   Chen Q, 2016, ACM SIGPLAN NOTICES, V51, P681, DOI 10.1145/2954679.2872368
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Collobert R., 2011, BIGLEARN
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Dean J., 2017, GOOGLE CLOUD TPUS
   Dean J, 2013, COMMUN ACM, V56, P74, DOI 10.1145/2408776.2408794
   Ebrahimi  E., 2011, ACM SIGARCH COMPUTER
   Gianelli  S., 2017, BAIDU DEPLOYS XILINX
   Google, 2017, DISTR TENS
   Google, 2017, HIGH PERF MOD
   Google, 2017, GOOGL CLOUD PLATF PR
   Guadarrama  S., TENSORFLOW SLIM
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hsu C. - H., 2015, IEEE 21 INT S HIGH P
   Intel, 2017, INT XEON PROC SCAL F
   Intel, 2015, INT XEON PROC E5 E7
   Intel, 2017, INT PROGR ACC CARD A
   Jeong M. K., 2012, P 49 ANN DES AUT C
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kambadur M, 2012, INT CONF HIGH PERFOR
   Kanev S., 2015, ACM IEEE 42 ANN INT
   Kasture  H., 2014, ACM SIGARCH COMPUTER
   Khazraee  M., 2017, P 22 INT C ARCH SUPP
   Koehn  P., 2003, P 2003 C N AM CHAPT, V1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leverich J., 2014, P 9 EUR C COMP SYST, P1
   Lo D, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P450, DOI 10.1145/2749469.2749475
   Magaki  I., 2016, P 43 INT S COMP ARCH
   Mulnix D, 2017, INTEL XEON PROCESSOR
   Mulnix  D., 2016, INTEL XEON PROCESSOR
   Muralidhara S. P., 2011, P 44 ANN IEEE ACM IN
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Ovtcharov K, 2016, IEEE HOT CHIP SYMP
   Putnam Andrew, 2014, COMP ARCH ISCA 2014
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Srinath  S., 2007, 2007 IEEE 13 INT S H
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Szegedy C., 2017, P 31 AAAI C ART INT, DOI DOI 10.1609/AAAI.V31I1.11231
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Usui  H., 2015, ARXIV150507502
   Verma AK, 2015, PARKINSONS DIS-US, V2015, DOI 10.1155/2015/598028
   Viswanathan  V., 2014, DISCLOUSURE HARDWARE
   Yang H., 2013, ACM SIGARCH COMPUTER
   Yun H., 2013, REAL TIM EMB TECHN A
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang  X., 2013, P 8 ACM EUR C COMP S
   Zhou  Y., 2016, P 43 INT S COMP ARCH
   Zhu HS, 2016, ACM SIGPLAN NOTICES, V51, P33, DOI 10.1145/2954679.2872394
NR 64
TC 12
Z9 12
U1 0
U2 3
PY 2019
BP 172
EP 184
DI 10.1109/HPCA.2019.00036
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Dong, B
   Wang, Z
   Chen, WX
   Chen, C
   Yang, YK
   Yu, ZB
AF Dong, Bo
   Wang, Zheng
   Chen, Wenxuan
   Chen, Chao
   Yang, Yongkui
   Yu, Zhibin
GP IEEE
TI OR-ML: Enhancing Reliability for Machine Learning Accelerator with
   Opportunistic Redundancy
SO PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2021)
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY FEB 01-05, 2021
CL ELECTR NETWORK
DE Fault tolerance; machine learning accelerator; opportunistic redundancy
ID NEURAL-NETWORKS
AB Reliability plays a central role in deep sub-micron and nanometre IC fabrication technology and has recently been reported to be one of the key issues affecting the inference phase of neural networks. State-of-the-art machine learning (ML) accelerators exploit massively computing parallelism observed in neural networks to achieve high energy efficiency. The topology of ML engines' computing fabric, which constitutes large arrays of processing elements (PEs), has been increasing dramatically to incorporate the huge size and heterogeneity of the rapid evolving ML algorithm. However, it is commonly observed that activations of zero value lead to reduced PE utilization. In this work, we present a novel and low-cost approach to enhance the reliability of generic ML accelerators by Opportunistically exploring the chances of runtime Redundancy provided by neighbouring PEs, named as OR-ML. In contrast to conventional redundancy techniques, the proposed technique introduces no additional computing resources, therefore significantly reduces the implementation overhead and achieves obvious level of protection. The design prototype is evaluated using emulated fault injection on FPGA, executing mainstream neural networks for objection classification and detection.
C1 [Dong, Bo; Wang, Zheng; Chen, Wenxuan; Chen, Chao; Yang, Yongkui; Yu, Zhibin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Dong, Bo; Chen, Wenxuan] Xidian Univ, Sch Microelect, Xian, Peoples R China.
RP Wang, Z (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM zheng.wang@siat.ac.cn
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Esmaeilzadeh H, 2013, IEEE MICRO, V33, P16, DOI 10.1109/MM.2013.28
   Kelly O., 2013, US
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Redmon J., 2013, DARKNET OPEN SOURCE
   Reinhardt SK, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P25, DOI [10.1145/342001.339652, 10.1109/ISCA.2000.854375]
   Salami B, 2018, INT SYM COMP ARCHIT, P322, DOI [10.1109/CAHPC.2018.8645906, 10.1109/SBAC-PAD.2018.00059]
   Slayman C., 2010, 2010 IEEE International Integrated Reliability Workshop Final Report (IIRW 2010), P25, DOI 10.1109/IIRW.2010.5706479
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Torres-Huitzil C, 2017, IEEE ACCESS, V5, P17322, DOI 10.1109/ACCESS.2017.2742698
   Wang Z, 2020, J SEMICOND, V41, DOI 10.1088/1674-4926/41/2/022401
NR 13
TC 1
Z9 1
U1 1
U2 5
PY 2021
BP 739
EP 742
DI 10.23919/DATE51398.2021.9474016
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Srivastava, P
   Kang, MG
   Gonugondla, SK
   Lim, S
   Choi, J
   Adve, V
   Kim, NS
   Shanbhag, N
AF Srivastava, Prakalp
   Kang, Mingu
   Gonugondla, Sujan K.
   Lim, Sungmin
   Choi, Jungwook
   Adve, Vikram
   Kim, Nam Sung
   Shanbhag, Naresh
GP IEEE
TI PROMISE: An End-to-End Design of a Programmable Mixed-Signal Accelerator
   for Machine-Learning Algorithms
SO 2018 ACM/IEEE 45TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 45th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 01-06, 2018
CL Los Angeles, CA
DE deep in-memory computing; analog ISA; programmable machine learning
   accelerator
AB Analog/mixed-signal machine learning (ML) accelerators exploit the unique computing capability of analog/mixed-signal circuits and inherent error tolerance of ML algorithms to obtain higher energy efficiencies than digital ML accelerators. Unfortunately, these analog/mixed-signal ML accelerators lack programmability, and even instruction set interfaces, to support diverse ML algorithms or to enable essential software control over the energy-vs-accuracy trade-offs. We propose PROMISE, the first end-to-end design of a PROgrammable MIxed-Signal accElerator from Instruction Set Architecture (ISA) to high-level language compiler for acceleration of diverse ML algorithms. We first identify prevalent operations in widely-used ML algorithms and key constraints in supporting these operations for a programmable mixed-signal accelerator. Second, based on that analysis, we propose an ISA with a PROMISE architecture built with silicon validated components for mixed-signal operations. Third, we develop a compiler that can take a ML algorithm described in a high-level programming language (Julia) and generate PROMISE code, with an IR design that is both language neutral and abstracts away unnecessary hardware details. Fourth, we show how the compiler can map an application-level error tolerance specification for neural network applications down to low-level hardware parameters (swing voltages for each application Task) to minimize energy consumption. Our experiments show that PROMISE can accelerate diverse ML algorithms with energy efficiency competitive even with fixed-function digital ASICs for specific ML algorithms, and the compiler optimization achieves significant additional energy savings even for only 1% extra errors.
C1 [Srivastava, Prakalp; Gonugondla, Sujan K.; Lim, Sungmin; Adve, Vikram; Kim, Nam Sung; Shanbhag, Naresh] Univ Illinois, Champaign, IL 61820 USA.
   [Kang, Mingu; Choi, Jungwook] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY USA.
RP Srivastava, P (corresponding author), Univ Illinois, Champaign, IL 61820 USA.
EM psrivas2@illinois.edu; mingu.kang@ibm.com; gonugon2@illinois.edu;
   sungmin3@illinois.edu; choij@us.ibm.com; vadve@illinois.edu;
   nskim@illinois.edu; shanbhag@illinois.edu
CR Abadi Martin, 2016, arXiv
   Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   AHO AV, 1986, COMPILERS PRINCIPLES
   [Anonymous], 2016, CORR
   [Anonymous], FPL
   Bezanson J., 2017, SIAM REV
   Bornholt J, 2014, ACM SIGPLAN NOTICES, V49, P51, DOI 10.1145/2541940.2541958
   Brunelli R., 1993, IEEE T PATTERN ANAL
   Buhler F. N., 2017, S VLSI CIRC
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Center for Biological and Computational Learning MIT, 2001, CBCL FAC DAT 1
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Chi P., 2016, P INT S COMP ARCH IS
   Chollet F., 2015, KERAS
   Collobert R., 2011, BIGLEARN
   Corinna Cortes., 1995, MACH LEARN, V20, P273, DOI DOI 10.1023/A:1022627411411
   Cytron R., 1991, TOPLAS
   Ernst D., 2003, MICRO
   Genov R., 2003, IEEE T NEURAL NETWOR
   Gonugondla S. K., 2018, ISSCC
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hameed R., 2010, ACM SIGARCH COMPUTER
   Huang Y., 2017, MICRO
   Innes M. J., 2015, FLUX JULIA MACHINE L
   ITRS, ITRS ROADMAP
   Joshi S., 2017, ISSCC
   Kang M., 2015, ICASSP
   Kang M., 2016, IEEE T BIOMEDICAL CI
   Kang M., 2018, JSSC
   Kaul Himanshu, 2016, ISSCC
   Kim K. I., 2002, IEEE SIGNAL PROCESSI
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lecun Yann, 2015, NATURE
   Lee E. H., 2016, ISSCC
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Mellinger D. K., 2011, J ACOUSTICAL SOC AM
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Misailovic S, 2014, ACM SIGPLAN NOTICES, V49, P309, DOI [10.1145/10.1145/2660193.2660231, 10.1145/2714064.2660231]
   Murmann B., AS C SIGN SYST COMP
   Python Core Team, 2015, PYTHON DYNAMIC OPEN
   Rieutort-Louis W., 2015, ISSCC
   Sakr C., 2018, ICASSP
   Sakr C., 2017, ICML
   Sampaio A, 2015, TERRORIZING LATINA/O IMMIGRANTS: RACE, GENDER, AND IMMIGRATION POLITICS IN THE AGE OF SECURITY, P15
   Sampson A., 2011, PLDI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   The Apache Software Foundation (ASF), 2015, MXNET JL
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Zhang J., 2017, JSSC
NR 56
TC 35
Z9 36
U1 0
U2 2
PY 2018
BP 43
EP 56
DI 10.1109/ISCA.2018.00015
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Huang, HT
   Ni, LB
   Wang, YH
   Yu, H
   Wang, ZW
   Cai, YM
   Huang, R
AF Huang, Hantao
   Ni, Leibin
   Wang, Yuhao
   Yu, Hao
   Wang, Zongwei
   Cai, Yimao
   Huang, Ru
GP IEEE
TI A 3D Multi-layer CMOS-RRAM Accelerator for Neural Network
SO 2016 IEEE INTERNATIONAL 3D SYSTEMS INTEGRATION CONFERENCE (3DIC)
SE IEEE International 3D Systems Integration Conference
DT Proceedings Paper
CT IEEE International 3D Systems Integration Conference (3DIC)
CY NOV 08-11, 2016
CL San Francisco, CA
ID MACHINE
AB Incremental machine learning is required for future real-time data analytics. This paper introduces a 3D multi layer CMOS-RRAM accelerator for an incremental least-squares based learning on neural network. Given input of buffered data hold on the layer of a RRAM memory, intensive matrix-vector multiplication can be firstly accelerated on the layer of a digitized RRAM-crossbar. The remaining incremental least-squares algorithmic operations for feature extraction and classifier training can be accelerated on the layer of CMOS ASIC, using an incremental Cholesky factorization accelerator realized with consideration of parallelism and pipeline. Experiment results have shown that such a 3D accelerator can significantly reduce training time with acceptable accuracy. Compared to 3D-CMOS-ASIC implementation, it can achieve 1.28x smaller area, 2.05x faster runtime and 12.4x energy reduction. Compared to GPU implementation, our work shows 3.07x speed-up and 162.86x energy-saving.
C1 [Huang, Hantao; Ni, Leibin; Wang, Yuhao; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Wang, Zongwei; Cai, Yimao; Huang, Ru] Peking Univ, Inst Microelect, Beijing 100871, Peoples R China.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM haoyu@ntu.edu.sg
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], IEEE ISSCC
   [Anonymous], IEEE ASP DAC
   [Anonymous], IEEE ASP DAC
   [Anonymous], IEEE DATE
   [Anonymous], 2015, MORE MOORE TECHNOLOG
   [Anonymous], BREAKTHR NONV MEM TE
   Chen Y.-C., 2012, IEEE FPL
   Coates A., 2011, AISTATS
   Franzon P., 2015, IEEE CICC
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kim DH, 2013, IEEE T VLSI SYST, V21, P862, DOI 10.1109/TVLSI.2012.2201760
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Lee H., 2008, IEEE EL DEV M
   Lichman M., 2013, UCI MACHINE LEARNING
   Müller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022
   Wang Y., 2012, IEEE 3DIC
   Wang YH, 2015, IEEE T NANOTECHNOL, V14, P998, DOI 10.1109/TNANO.2015.2447531
   Yu S., 2013, EEE VLSIT
NR 22
TC 2
Z9 2
U1 0
U2 2
PY 2016
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Scheinker, A
AF Scheinker, Alexander
TI Adaptive Machine Learning for Robust Diagnostics and Control of
   Time-Varying Particle Accelerator Components and Beams
SO INFORMATION
DT Article
DE machine learning; adaptive control; time-varying systems
AB Machine learning (ML) is growing in popularity for various particle accelerator applications including anomaly detection such as faulty beam position monitor or RF fault identification, for non-invasive diagnostics, and for creating surrogate models. ML methods such as neural networks (NN) are useful because they can learn input-output relationships in large complex systems based on large data sets. Once they are trained, methods such as NNs give instant predictions of complex phenomenon, which makes their use as surrogate models especially appealing for speeding up large parameter space searches which otherwise require computationally expensive simulations. However, quickly time varying systems are challenging for ML-based approaches because the actual system dynamics quickly drifts away from the description provided by any fixed data set, degrading the predictive power of any ML method, and limits their applicability for real time feedback control of quickly time-varying accelerator components and beams. In contrast to ML methods, adaptive model-independent feedback algorithms are by design robust to un-modeled changes and disturbances in dynamic systems, but are usually local in nature and susceptible to local extrema. In this work, we propose that the combination of adaptive feedback and machine learning, adaptive machine learning (AML), is a way to combine the global feature learning power of ML methods such as deep neural networks with the robustness of model-independent control. We present an overview of several ML and adaptive control methods, their strengths and limitations, and an overview of AML approaches.
C1 [Scheinker, Alexander] Los Alamos Natl Lab, Los Alamos, NM 87545 USA.
RP Scheinker, A (corresponding author), Los Alamos Natl Lab, Los Alamos, NM 87545 USA.
EM ascheink@lanl.gov
CR Adelmann A, 2019, SIAM-ASA J UNCERTAIN, V7, P383, DOI 10.1137/16M1061928
   Agapov I, 2014, NUCL INSTRUM METH A, V768, P151, DOI 10.1016/j.nima.2014.09.057
   [Anonymous], 1951, REPRESENTATION EVENT
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   BELLMAN R, 1956, P NATL ACAD SCI USA, V42, P767, DOI 10.1073/pnas.42.10.767
   Bruchon N, 2019, 2019 23RD INTERNATIONAL CONFERENCE ON MECHATRONICS TECHNOLOGY (ICMT 2019), DOI 10.1109/icmect.2019.8932150
   Bruchon N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050781
   Dalesio L.R., 1991, EPICS ARCHITECTURE
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Fol E., 2019, P 2019 INT PART ACC
   Fol E., 2019, P 10 INT PART ACC C, V2668
   Hanuka A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82473-0
   Hao Y., 2019, ARXIV190211157
   Hastie Trevor, 2001, ELEMENTS STAT LEARNI
   Hirlaender S., 2020, ARXIV201209737
   Kain V, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.124801
   Kapchinskij I., 1959, P 2 INT C HIGH EN AC
   Khalil H. K, 2002, NONLINEAR SYSTEMS, V115
   Kirk D.E., 2004, IEEE T AUTOMAT CONTR, DOI DOI 10.1109/TAC.1972.1100008
   Kranjcevic M, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.014601
   Lewis FL, 2012, OPTIMAL CONTROL
   Li Y., 2019, ARXIV190405683
   Li YJ, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.012804
   Li YJ, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.054601
   McIntire M., 2016, P 7 INT PART ACC C B
   MUDGETT DR, 1985, IEEE T AUTOMAT CONTR, V30, P549, DOI 10.1109/TAC.1985.1104006
   NUSSBAUM RD, 1983, SYST CONTROL LETT, V3, P243, DOI 10.1016/0167-6911(83)90021-X
   O'Shea FH, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.122802
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Scheinker A, 2017, SPRBRIEF ELECT, P1, DOI 10.1007/978-3-319-50790-3
   Scheinker A., 2021, ARXIV210210510
   Scheinker A., 2012, THESIS U CALIFORNIA
   Scheinker A, 2020, AIP ADV, V10, DOI 10.1063/5.0003423
   Scheinker A, 2021, INT J ADAPT CONTROL, V35, P1143, DOI 10.1002/acs.3097
   Scheinker A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082802
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2018, INT J ROBUST NONLIN, V28, P568, DOI 10.1002/rnc.3886
   Scheinker A, 2016, AUTOMATICA, V69, P250, DOI 10.1016/j.automatica.2016.02.023
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Scheinker A, 2013, IEEE T AUTOMAT CONTR, V58, P1107, DOI 10.1109/TAC.2012.2225514
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   WU MY, 1984, INT J SYST SCI, V15, P137, DOI 10.1080/00207728408926550
   WU MY, 1974, IEEE T AUTOMAT CONTR, VAC19, P162, DOI 10.1109/TAC.1974.1100529
   Zhu J., 2021, ARXIV210110437
NR 48
TC 5
Z9 5
U1 0
U2 5
PD APR
PY 2021
VL 12
IS 4
AR 161
DI 10.3390/info12040161
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT J
AU Inayat, K
   Chung, J
AF Inayat, Kashif
   Chung, Jaeyong
TI Hybrid Accumulator Factored Systolic Array for Machine Learning
   Acceleration
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Systolic arrays; Delays; Adders; Power demand; Computer architecture;
   Tensors; System-on-chip; Accelerator; factorization; Gemmini; machine
   learning; systolic array
ID DEEP NEURAL-NETWORKS
AB Deep learning applications have become ubiquitous in today's era and it has led to vast development in machine learning (ML) accelerators. Systolic arrays have been a primary part of ML accelerator architecture. To fully leverage the systolic arrays, it is required to explore the computer arithmetic data-path components and their tradeoffs in accelerators. We present a novel factored systolic array (FSA) architecture, in which the carry propagation adder (CPA) and carry-save adder (CSA) perform hybrid accumulation on least significant bit (LSB) bits and most significant bits (MSB) bits, respectively, inside each processing element. In addition, a small CPA to complete accumulation for MSB bits along with rounding logic for each column of the array is placed, which not only reduces the area, delay, and power but also balances the combinational and sequential area tradeoffs. We demonstrate the hybrid accumulator with partial CPA factoring in ``Gemmini,'' an open-source practical systolic array accelerator and factoring technique does not change the functionality of the base design. We implemented three baselines, original Gemmini and two variants of it, and show that the proposed approach leads to overall significant reduction in area within the range 12.8%-50.2% and in power within the range 18.6%-41% with improved or similar delay in comparison to the baselines.
C1 [Inayat, Kashif; Chung, Jaeyong] Incheon Natl Univ, Dept Elect Engn, Incheon 22012, South Korea.
RP Chung, J (corresponding author), Incheon Natl Univ, Dept Elect Engn, Incheon 22012, South Korea.
EM jychung@inu.ac.kr
CR Amid A., 2020, EE 290 2 HARDWARE MA
   [Anonymous], 2019, GOYA INFERENCE PLATF
   [Anonymous], 2018, ACC DNNS XIL ALV ACC
   Asgari B, 2019, IEEE MICRO, V39, P46, DOI 10.1109/MM.2019.2930057
   Bewick G. W., 1994, THESIS STANFORD U ST
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Daneshtalab M., 2020, HARDWARE ARCHITECTUR
   Ercegovac M.D., 2004, DIGITAL ARITHMETIC
   Farshchi F, 2019, 2019 2ND WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2 2019), P21, DOI 10.1109/EMC249363.2019.00012
   FOSTER MJ, 1980, COMPUTER, V13, P26, DOI 10.1109/MC.1980.1653338
   Garland J, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3233300
   Genc H., ARXIV191109925
   Hamming R.R., 1997, ART DOING SCI ENG LE
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hanif M. A., 2019, P MACH LEARN COMP AI, P647
   Hweesoo Kim, 2021, IEEE Computer Architecture Letters, V20, P34, DOI 10.1109/LCA.2021.3054371
   Inayat K, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060652
   Ivanyi A, 2007, ALGORITHMS INFORM
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kai H., 1979, COMPUTER ARITHMETIC
   Khan Shoab Ahmed, 2011, DIGITAL DESIGN SIGNA
   Kung H, 1983, CMUCS84100
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Kung H.T., 1982, PROC 4 REAL TIME SIG, V298, P19
   Kung H. T., 1979, INTRO VLSI SYSTEMS
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Liu ZG, 2020, IEEE COMPUT ARCHIT L, V19, P34, DOI 10.1109/LCA.2020.2979965
   Lu H, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240855
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Lym S., 2020, ARXIV200413027
   Manasi SD, 2021, ASIA S PACIF DES AUT, P235, DOI 10.1145/3394885.3431539
   Montagne E, 2019, P SPRING SIM C SPRIN, P1
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Parhi KK, 2020, IEEE OPEN J CIRCUITS, V1, P185, DOI 10.1109/OJCAS.2020.3032092
   Parmar Y, 2020, IEEE T CIRCUITS-II, V67, P370, DOI 10.1109/TCSII.2019.2907974
   Ryu S, 2019, IEEE T VLSI SYST, V27, P138, DOI 10.1109/TVLSI.2018.2873716
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samajdar Ananda, 2018, SCALE SIM SYSTOLIC C
   Shao Y S, 2015, SYNTHESIS LECT COMPU, V4, P1, DOI DOI 10.2200/S00677ED1
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Sze Vivienne, 2020, SYNTHESIS LECT COMPU, DOI DOI 10.2200/S01004ED1V01Y202004CAC050
   Yin C, 2017, INT C PAR DISTRIB SY, P180, DOI 10.1109/ICPADS.2017.00034
NR 45
TC 4
Z9 4
U1 0
U2 2
PD JUL
PY 2022
VL 30
IS 7
BP 881
EP 892
DI 10.1109/TVLSI.2022.3170233
EA MAY 2022
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Choudhury, R
   Ahamed, SR
   Guha, P
AF Choudhury, Rituparna
   Ahamed, Shaik Rafi
   Guha, Prithwijit
TI Training Accelerator for Two Means Decision Tree
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Decision tree (DT); field-programmable gate array (FPGA); machine
   learning (ML); training accelerator; two means DT (TMDT)
ID IMPLEMENTATION
AB Decision trees (DTs) are profusely used in machine learning (ML) applications on account of their fast execution and high interpretability. As DT training is time-consuming, in this brief, we proposed a hardware training accelerator to speedup the training process. The proposed training accelerator is implemented on the field-programmable gate array (FPGA) having a maximum operating frequency of 62 MHz. The proposed architecture uses a combination of parallel execution for training time reduction and pipelined execution to minimize resource consumption. For a given design, the proposed hardware implementation is found to be at least 14x faster than the C-based software implementation. Moreover, the proposed architecture can be easily retrained for the next set of data using a single RESET signal. This on-the-go training makes the hardware versatile for any kind of application.
C1 [Choudhury, Rituparna; Ahamed, Shaik Rafi; Guha, Prithwijit] IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
RP Choudhury, R (corresponding author), IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM ritup176102101@iitg.ac.in; rafiahamed@iitg.ac.in; pguha@iitg.ac.in
CR Behnke S, 1998, IEEE T NEURAL NETWOR, V9, P1352, DOI 10.1109/72.728387
   Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   Dua D, 2020, UCI MACHINE LEARNING
   Godbole A, 2018, P 24 NAT C COMM NCC, P1
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Ruggieri S, 2002, IEEE T KNOWL DATA EN, V14, P438, DOI 10.1109/69.991727
   Saegusa T, 2007, J REAL-TIME IMAGE PR, V2, P309, DOI 10.1007/s11554-007-0055-8
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Tong D, 2017, IEEE T PARALL DISTR, V28, P3046, DOI 10.1109/TPDS.2017.2714661
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Winterstein F, 2013, I C FIELD PROG LOGIC
NR 12
TC 2
Z9 2
U1 0
U2 2
PD JUL
PY 2021
VL 29
IS 7
BP 1465
EP 1469
DI 10.1109/TVLSI.2021.3076081
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Abu Talib, M
   Majzoub, S
   Nasir, Q
   Jamal, D
AF Abu Talib, Manar
   Majzoub, Sohaib
   Nasir, Qassim
   Jamal, Dina
TI A systematic literature review on hardware implementation of artificial
   intelligence algorithms
SO JOURNAL OF SUPERCOMPUTING
DT Review
DE Hardware accelerators; Artificial intelligence; Machine learning; AI on
   hardware; Real-time AI
ID FOREGROUND OBJECT SEGMENTATION; DEEP NEURAL-NETWORKS; REAL-TIME; FACE
   DETECTION; FPGA; ACCELERATOR; CLASSIFICATION; ARCHITECTURE; CNN
AB Artificial intelligence (AI) and machine learning (ML) tools play a significant role in the recent evolution of smart systems. AI solutions are pushing towards a significant shift in many fields such as healthcare, autonomous airplanes and vehicles, security, marketing customer profiling and other diverse areas. One of the main challenges hindering the AI potential is the demand for high-performance computation resources. Recently, hardware accelerators are developed in order to provide the needed computational power for the AI and ML tools. In the literature, hardware accelerators are built using FPGAs, GPUs and ASICs to accelerate computationally intensive tasks. These accelerators provide high-performance hardware while preserving the required accuracy. In this work, we present a systematic literature review that focuses on exploring the available hardware accelerators for the AI and ML tools. More than 169 different research papers published between the years 2009 and 2019 are studied and analysed.
C1 [Abu Talib, Manar; Majzoub, Sohaib; Nasir, Qassim; Jamal, Dina] Univ Sharjah, Sharjah, U Arab Emirates.
RP Nasir, Q (corresponding author), Univ Sharjah, Sharjah, U Arab Emirates.
EM nasir@sharjah.ac.ae
CR Abdelouahab K, 2017, IEEE EMBED SYST LETT, V9, P113, DOI 10.1109/LES.2017.2743247
   Ali U, 2009, 2009 5TH SOUTHERN CONFERENCE ON PROGRAMMABLE LOGIC, PROCEEDINGS, P33, DOI 10.1109/SPL.2009.4914888
   [Anonymous], P INT C FPT 12 14 DE
   [Anonymous], 2016, MICRO
   [Anonymous], 2010, 2010 IEEE INT S PARA
   [Anonymous], 2018, DLA COMPILER FPGA OV
   [Anonymous], 2016, CORR
   [Anonymous], 2019, NVIDIA GEFORCE GT 73
   [Anonymous], 2012, P 2012 C DES ARCH SI
   [Anonymous], 2011, GPU COMPUTING GEMS E, DOI DOI 10.1016/B978-0-12-384988-5.00033-4
   Art P, 2011, ARTIFICIAL NEURAL NE, P450
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Baji T., 2018, IEEE 2 EL DEV TECHN, P7
   Barbosa JPF, 2015, J SYST ARCHITECT, V61, P639, DOI 10.1016/j.sysarc.2015.09.005
   Bauer S., 2009, P MPC WORKSHOP, P49
   Bauer S., 2010, IEEE COMP SOC C COMP
   Berjón D, 2013, IEEE T CONSUM ELECTR, V59, P361, DOI 10.1109/TCE.2013.6531118
   Bishnoi L, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P106, DOI 10.1109/CONFLUENCE.2018.8442729
   Bottleson J, 2016, IEEE INT PAR DISTR P
   Bouris D, 2010, ANN IEEE SYM FIELD P, P3, DOI 10.1109/FCCM.2010.11
   Budgen D., 2006, 28th International Conference on Software Engineering Proceedings, P1051, DOI 10.1145/1134285.1134500
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Cengil E, 2017, 2017 INTERNATIONAL ARTIFICIAL INTELLIGENCE AND DATA PROCESSING SYMPOSIUM (IDAP)
   Chen Y, 2014, DADIANNAO MACHINE LE
   Cheng KT, 2011, 2011 INTERNATIONAL SYMPOSIUM ON VLSI DESIGN, AUTOMATION AND TEST (VLSI-DAT), P54
   Cho JY, 2009, BMC INFECT DIS, V9, DOI 10.1186/1471-2334-9-171
   Coates A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4287, DOI 10.1109/IROS.2009.5354084
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Nguyen D, 2017, DES AUT TEST EUROPE, P890, DOI 10.23919/DATE.2017.7927113
   Duarte RP, 2018, LITE CNN HIGH PERFOR
   Duffany J.L, 2010, 2010 2 INT C SOFTW T, V1
   Dwith CYN, 2012, 2012 13TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS, AND TECHNOLOGIES (PDCAT 2012), P755, DOI 10.1109/PDCAT.2012.107
   England WE, 2018, MSYSTEMS, V3, DOI 10.1128/mSystems.00075-18
   Fabian Nasse, 2009, P 13 INT C COMP AN I, P83
   Farabet Clement, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P878, DOI 10.1109/ICCVW.2009.5457611
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farah NICLA, 2014, NEW CLASSIFICATION A, P491
   Faraone J, 2018, I C FIELD PROG LOGIC, P97, DOI 10.1109/FPL.2018.00025
   Farrugia N, 2009, IEEE T CIRC SYST VID, V19, P597, DOI 10.1109/TCSVT.2009.2014013
   Feng G, 2016, ENERGY EFFICIENT HIG, P4
   Fraley JB, 2017, IEEE SOUTHEASTCON
   Gao CJ, 2008, I C FIELD PROG LOGIC, P372
   Geng T, 2018, I C FIELD PROG LOGIC, P394, DOI 10.1109/FPL.2018.00074
   Georganas E, 2018, SC18 INT C HIGH PERF, P830
   GONG J, 2018, IEEE WCNC
   Gong L, 2017, WORK IN PROGR POWER
   Gong L, 2018, IEEE T COMPUT AID D, V37, P2601, DOI 10.1109/TCAD.2018.2857078
   Gu QY, 2013, IEEE T CIRC SYST VID, V23, P30, DOI 10.1109/TCSVT.2012.2202195
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Guo JX, 2017, ANN IEEE SYM FIELD P, P31, DOI 10.1109/FCCM.2017.13
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Guzhva A, 2009, LECT NOTES COMPUT SC, V5768, P373, DOI 10.1007/978-3-642-04274-4_39
   Hahnle M, 2013, IEEE COMPUT SOC CONF, P629, DOI 10.1109/CVPRW.2013.95
   He C, 2009, INT J PHOTOENERGY, V2009, DOI 10.1155/2009/634369
   Hefenbrock D, 2010, ANN IEEE SYM FIELD P, P11, DOI 10.1109/FCCM.2010.12
   Herout A, 2011, J REAL-TIME IMAGE PR, V6, P159, DOI 10.1007/s11554-010-0179-0
   Hikawa H, 2015, IEEE T CIRC SYST VID, V25, P153, DOI 10.1109/TCSVT.2014.2335831
   Hiromoto M., 2009, IEEE 12 INT C COMP V
   Hu YW, 2018, INT PARALL DISTRIB P, P244, DOI 10.1109/IPDPS.2018.00034
   Hwang WJ, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P582, DOI 10.1109/TSP.2017.8076054
   Jain V, 2016, PROCEDIA COMPUT SCI, V87, P156, DOI 10.1016/j.procs.2016.05.142
   Jawandhiya P., 2018, INT J ARTIF INTELL A, V9, P63, DOI [10.5121/ijaia.2018.9105, DOI 10.5121/IJAIA.2018.9105]
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Jin L, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P1622, DOI 10.1109/IPDPSW.2014.194
   Kim JH, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P268, DOI 10.1109/SOCC.2017.8226056
   Kim L, 2017, DEEPX DEEP LEARNING, P1
   Knag P, 2015, IEEE J SOLID-ST CIRC, V50, P1070, DOI 10.1109/JSSC.2014.2386892
   Komorkiewicz M, 2012, 2012 22 INT C FIELD
   Kong J, 2010, INT C INT CONTR INF
   Kryjak T, 2013, FED CONF COMPUT SCI, P591
   Kryjak T, 2014, J REAL-TIME IMAGE PR, V9, P61, DOI 10.1007/s11554-012-0290-5
   Kurth T, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126916
   Kyrkou C, 2011, IEEE T VLSI SYST, V19, P1034, DOI 10.1109/TVLSI.2010.2048224
   Lacey G, 2016, DEEP LEARNING FPGAS
   Lescano G, 2017, J COMPUT SCI TECHNOL, V17, P68
   Li BX, 2014, IEEE IJCNN, P4062, DOI 10.1109/IJCNN.2014.6889433
   Li E, 2012, 2012 IEEE INT MULT E
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Lifan Yao, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P30, DOI 10.1109/FPT.2009.5377651
   Serato JHL, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P287, DOI 10.1109/ICASI.2018.8394589
   Liu S, 2011, CHIN CONT DECIS CONF, P111, DOI 10.1109/CCDC.2011.5968156
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Lozano OM, 2008, INT CONF ACOUST SPEE, P713, DOI 10.1109/ICASSP.2008.4517709
   Lucas SM, 2009, IEEE T COMP INTEL AI, V1, P1, DOI 10.1109/TCIAIG.2009.2021433
   Luo G, 2016, ENERGY EFFICIENT CNN, P326
   Ma XY, 2015, IEEE T CIRC SYST VID, V25, P1051, DOI 10.1109/TCSVT.2014.2360030
   Ma Y, 2018, PERSPECT ASIAN TOUR, P201, DOI 10.1007/978-981-10-7980-1_11
   Ma Y, 2020, IEEE T COMPUT AID D, V39, P424, DOI 10.1109/TCAD.2018.2884972
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Masek J, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P808, DOI 10.1109/TSP.2013.6614050
   Mathuriya A., 2018, SC18, P819, DOI [10. 1109/SC.2018.00068, DOI 10.1109/SC.2018.00068]
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Nakano H, 2017, 2017 INTERNATIONAL WORKSHOP ON ANTENNA TECHNOLOGY: SMALL ANTENNAS, INNOVATIVE STRUCTURES, AND APPLICATIONS (IWAT), P1, DOI 10.1109/IWAT.2017.7915280
   Nurvitadhi E., 2017, P ACM INT S FIELD PR
   Nurvitadhi E, 2018, I C FIELD PROG LOGIC, P106, DOI 10.1109/FPL.2018.00027
   Oh C, 2015, IEEE INT CON MULTI
   Oh C, 2018, IEICE T INF SYST, VE101D, P2878, DOI 10.1587/transinf.2018PAP0004
   Oro D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P530, DOI 10.1109/ICCVW.2011.6130288
   Oro D, 2012, 41 INT C PAR PROC
   Ouerhani Y., 2010, IEEE INT C IM SYST T, P80
   Pan Jia, 2010, 24 AAAI C ART INT
   Park J, 2016, NEURAL ACCELERATION, P482
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Parker DS, 1989, P 5 INT C DAT ENG
   Pau L. F., 1991, IEEE Transactions on Knowledge and Data Engineering, V3, P137, DOI 10.1109/69.87994
   Pertsau D, 2013, IEEE 7 INT C INT DAT
   Possa PR, 2014, IEEE T COMPUT, V63, P2376, DOI 10.1109/TC.2013.130
   Potluri S, 2011, STUD COMPUT INTELL, V391, P255
   Qiao Y, 2011, SEISMOL RES LETT, V82, P2010
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rabhi S, 2019, PROCEEDINGS OF THE WORKSHOP ON ACM RECOMMENDER SYSTEMS CHALLENGE (RECSYS CHALLENGE 2019), DOI 10.1145/3359555.3359564
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Rao Qing, 2018, P 1 INT WORKSH SOFTW
   Rigos S, 2012, MED C EMB COMP MECO, P17
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Samragh M., 2017, 2017 IEEE 25 ANN INT
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Schutzer D., 1983, Proceedings of the 1983 IEEE Military Communications Conference, P786
   Sharma B, 2009, 16TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING (HIPC), PROCEEDINGS, P368, DOI 10.1109/HIPC.2009.5433189
   Sharma H., 2016, WORKSH COGN ARCH
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shimoda M, 2018, INT C FIELD PROGR TE, V2018, P291
   Strigl D, 2010, EUROMICRO WORKSHOP P, P317, DOI 10.1109/PDP.2010.43
   Sun F, 2017, IEEE INT SYMP PARAL, P622, DOI 10.1109/ISPA/IUCC.2017.00099
   Sváb J, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR PRACTICAL ROBOT APPLICATIONS (TEPRA 2009), P35, DOI 10.1109/TEPRA.2009.5339646
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tijtgat N, 2017, IEEE INT CONF COMP V, P2110, DOI 10.1109/ICCVW.2017.247
   Ullah I, 2016, BMC INFECT DIS, V16, DOI 10.1186/s12879-016-1745-2
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vasumathi B, 2012, ENG APPL ARTIF INTEL, V25, P476, DOI 10.1016/j.engappai.2011.12.005
   Venieris SI, 2017, LATENCY DRIVEN DESIG
   Venieris SI, 2018, F CNN X TOOLFLOW MAP
   Venieris SI, 2016, IEEE 24 ANN INT S FI
   Viebke A, 2019, J SUPERCOMPUT, V75, P197, DOI 10.1007/s11227-017-1994-x
   Vrudhula S, 2016, THROUGHPUT OPTIMIZED, P16
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang NJ, 2012, I S INTELL SIG PROC
   Wang T., 2018, ARXIV PREPRINT ARXIV
   Wang Y, 2016, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-319-26389-2
   Wang Y, 2016, IEEE INT SYMP CIRC S, P129, DOI 10.1109/ISCAS.2016.7527187
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Xian A, 2017, HARDWARE ACCELERATOR
   Yan B, 2017, NANOMED NANOTOXICOL, P1, DOI 10.1007/978-981-10-5864-6
   Yao XF, 2017, INT CONF ENTERP SYST, P311, DOI 10.1109/ES.2017.58
   Yonekawa H, 2017, IEEE SYM PARA DISTR, P98, DOI 10.1109/IPDPSW.2017.95
   Yu JC, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P227, DOI 10.1109/FPT.2017.8280147
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zeng H, 2018, INT C REC COMP FPGAS, V2018, P1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang TT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P133, DOI 10.1109/CBS.2018.8612238
   Zhang Xiaoci, 2016, COMMUN COMPUT PHYS, P484
   Zhao J, 2013, IEEE HIGH PERF EXTR
   Zhao MH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020350
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhao RZ, 2018, I C FIELD PROG LOGIC, P147, DOI 10.1109/FPL.2018.00033
   Zhou W, 2011, 2011 IEEE 9 INT C AS
   Zhou YT, 2015, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2015.45
   Zhuang HL, 2012, IEEE T IND ELECTRON, V59, P3299, DOI 10.1109/TIE.2011.2165451
NR 169
TC 42
Z9 44
U1 15
U2 112
PD FEB
PY 2021
VL 77
IS 2
BP 1897
EP 1938
DI 10.1007/s11227-020-03325-8
EA MAY 2020
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Huang, HT
   Ni, LB
   Yu, H
AF Huang, Hantao
   Ni, Leibin
   Yu, Hao
BE Alioto, M
   Li, H
   Schlichtmann, U
   Sridhar, R
   Becker, J
TI LTNN: An Energy-efficient Machine Learning Accelerator on 3D CMOS-RRAM
   for Layer-wise Tensorized Neural Network
SO 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC)
DT Proceedings Paper
CT 30th IEEE International System-on-Chip Conference (SOCC)
CY SEP 05-08, 2017
CL Munich, GERMANY
AB An energy efficient machine learning requires an effective construction of neural network during training. This paper introduces a tensorized formulation of neural network during training such that weight matrix can be significantly compressed. The tensorized neural network can be further naturally mapped to a 3D CMOS-RRAM based accelerator with significant bandwidth boosting from vertical I/O connections. As such, high throughput and low power can be achieved simultaneously. Simulation results using the benchmark MNIST show that the proposed accelerator has 1.294x speed-up, 2.393x energy-efficiency and 7.59 x area saving compared to 3D CMOS-ASIC implementation. Moreover, our proposed accelerator can achieve 370.64 COPS throughput and 1055.95 GOPS/W energy efficiency, which is equivalent to 7.661 TOPS/VV for uncompressed neural network. In addition, 142x model compression can be achieved by tensorization with acceptable accuracy loss.
C1 [Huang, Hantao; Ni, Leibin; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM haoyu@ntu.edu.sg
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], 2014, THE CIFAR 10 DATASET
   [Anonymous], IEEE VLSIT
   [Anonymous], IEEE ISSCC
   [Anonymous], IEEE ASP DAC
   [Anonymous], IEEE ASP DAC
   [Anonymous], IEEE DATE
   [Anonymous], 2015, MORE MOORE TECHNOLOG
   [Anonymous], BREAKTHR NONV MEM TE
   [Anonymous], 2013, ARXIV13124461
   [Anonymous], ARXIV E PRINTS
   [Anonymous], ARXIV160202505
   [Anonymous], 2016, ARXIV160907061
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chen K, 2012, DES AUT TEST EUROPE, P33
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Fei W, 2012, IEEE T VLSI SYST, V20, P1012, DOI 10.1109/TVLSI.2011.2136443
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Han S., 2015, ARXIV151000149
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Lee H. Y., 2008, IEEE IEDM, P1
   Oseledets IV, 2012, SIAM J SCI COMPUT, V34, pA2718, DOI 10.1137/110833142
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Poremba M, 2015, DES AUT TEST EUROPE, P1543
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 27
TC 3
Z9 3
U1 0
U2 4
PY 2017
BP 280
EP 285
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Vassal, A
   Ghribi, A
   Millet, F
   Bonne, F
   Bonnay, P
   Bernaudin, PE
AF Vassal, Adrien
   Ghribi, Adnan
   Millet, Francois
   Bonne, Francois
   Bonnay, Patrick
   Bernaudin, Pierre-Emmanuel
TI SPIRAL2 Cryomodule Models: A Gateway to Process Control and Machine
   Learning
SO FRONTIERS IN PHYSICS
DT Article
DE machine learning; cryogenics; modeling; accelerators; thermodynamics;
   control
AB From simple physical systems to full production lines, numerical models could be used to minimize downtime and to optimize performances. In this article, the system of interest is the SPIRAL2 heavy ion accelerator cryogenic system. This article illustrates three different applications based on a SPIRAL2 cryostat model: optimal controller synthesis, virtual sensor synthesis, and anomaly detection. The two first applications have been deployed on the system. Experimental results are used to illustrate the benefits of such applications. The third application is a case study based on data generated from a thermodynamic twin model.
C1 [Vassal, Adrien; Millet, Francois; Bonne, Francois; Bonnay, Patrick; Bernaudin, Pierre-Emmanuel] Commissariat Energie Atom & Energies Appropriees C, Paris, France.
   [Vassal, Adrien; Ghribi, Adnan; Bernaudin, Pierre-Emmanuel] Grand Accelelerateur Natl Ions Lourds GANIL, Caen, France.
   [Ghribi, Adnan] Ctr Natl Rech Sci CNRS, Paris, France.
RP Ghribi, A (corresponding author), Grand Accelelerateur Natl Ions Lourds GANIL, Caen, France.; Ghribi, A (corresponding author), Ctr Natl Rech Sci CNRS, Paris, France.
EM adnan.ghribi@ganil.fr
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Bernaudin P., 2004, EPAC, V6, P1276
   Bonne F, 2020, IOP CONF SER-MAT SCI, V755, DOI 10.1088/1757-899X/755/1/012076
   Bonne F., 2014, THESIS HAL OPEN SCI
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]
   Ding X., 2010, IPAC 2010 1 INT PART, P3789
   Ferdinand R., 2008, P LINAC 2008
   Ghribi A, 2017, CRYOGENICS, V85, P44, DOI 10.1016/j.cryogenics.2017.05.003
   Ghribi A., 2017, IOP C SER MAT SCI EN, V171, P012115, DOI [10.1088/1757-899X/171/1/012115, DOI 10.1088/1757-899X/171/1/012115]
   Ghribi A, 2020, CRYOGENICS, V110, DOI 10.1016/j.cryogenics.2020.103126
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   ISA, 2012, 750101 ISA ANSI
   Kalman R.E., 1960, T ASME J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   LUENBERGER DG, 1971, IEEE T AUTOMAT CONTR, VAC16, P596, DOI 10.1109/TAC.1971.1099826
   Matworks, 2019, CONTROL SYSTEM TOOLB
   McGee L.A., 1985, DISCOVERY KALMAN FIL
   Olry G, 2006, PHYSICA C, V441, P197, DOI 10.1016/j.physc.2006.03.030
   Padamsee H., 2009, RF SUPERCONDUCTIVITY
   Paszke A, 2019, ADV NEUR IN, V32
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Shung KP., 2018, ACCURACY PRECISION R
   The MathWorks I., 2018, MATLAB STAT MACHINE
   Torres L, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8030173
   Vassal A, 2019, IOP CONF SER-MAT SCI, V502, DOI 10.1088/1757-899X/502/1/012111
   Vassal A., 2018, PROCEDE DETERMINATIO
   Vassal A., 2018, P 29 LIN ACC C LINAC, P366
   Vassal A., 2019, THESIS
   WIPF SL, 1968, J APPL PHYS, V39, P2538, DOI 10.1063/1.1656612
NR 31
TC 0
Z9 0
U1 2
U2 2
PD SEP 8
PY 2022
VL 10
AR 875464
DI 10.3389/fphy.2022.875464
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Mittal, S
AF Mittal, Sparsh
TI A Survey of ReRAM-Based Architectures for Processing-In-Memory and
   Neural Networks
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION
DT Article
DE review; memristor; resistive memory; artificial intelligence; machine
   learning; deep learning; hardware architecture; processing-in-memory;
   non-volatile memory; emerging memory technology
ID LIFETIME; SYSTEMS; CACHE
AB As data movement operations and power-budget become key bottlenecks in the design of computing systems, the interest in unconventional approaches such as processing-in-memory (PIM), machine learning (ML), and especially neural network (NN)-based accelerators has grown significantly. Resistive random access memory (ReRAM) is a promising technology for efficiently architecting PIM- and NN-based accelerators due to its capabilities to work as both: High-density/low-energy storage and in-memory computation/search engine. In this paper, we present a survey of techniques for designing ReRAM-based PIM and NN architectures. By classifying the techniques based on key parameters, we underscore their similarities and differences. This paper will be valuable for computer architects, chip designers and researchers in the area of machine learning.
C1 [Mittal, Sparsh] IIT Hyderabad, Dept Comp Sci & Engn, Hyderabad 502285, Telangana, India.
RP Mittal, S (corresponding author), IIT Hyderabad, Dept Comp Sci & Engn, Hyderabad 502285, Telangana, India.
EM sparsh@iith.ac.in
CR Abu Lebdeh M, 2017, IEEE T CIRCUITS-I, V64, P2427, DOI 10.1109/TCSI.2017.2706299
   Ankit A., ARXIV170807949
   Ankit A, 2017, DES AUT CON, DOI 10.1145/3061639.3062311
   [Anonymous], 2016, P 35 INT C COMPUTER
   [Anonymous], 2017, IEEE T CONTROL NETW
   [Anonymous], 2016, 2016 IEEE 2ND ANNUAL
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Bhattacharjee D., 2016, VER LARG SCAL INT VL, P1, DOI DOI 10.1109/VLSISOC.2016.7753568
   Cai RZ, 2016, IEEE COMP SOC ANN, P643, DOI 10.1109/ISVLSI.2016.124
   Chang KC, 2015, NANOSCALE RES LETT, V10, DOI 10.1186/s11671-015-0740-7
   Chang YF, 2017, IEEE T ELECTRON DEV, V64, P2977, DOI 10.1109/TED.2017.2699679
   Chang YF, 2016, SCI REP-UK, V6, DOI 10.1038/srep21268
   Chang YF, 2014, J APPL PHYS, V116, DOI 10.1063/1.4891242
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen YC, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aaa1b9
   Chenchen Liu, 2017, 2017 54th ACM/EDAC/IEEE Design Automation Conference (DAC), DOI 10.1145/3061639.3062310
   Cheng M, 2017, DES AUT CON, DOI 10.1145/3061639.3062326
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Gao LG, 2016, IEEE ELECTR DEVICE L, V37, P870, DOI 10.1109/LED.2016.2573140
   Ghosh-Dastidar S, 2009, INT J NEURAL SYST, V19, P295, DOI 10.1142/S0129065709002002
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   Nguyen HAD, 2017, IEEE T VLSI SYST, V25, P2206, DOI 10.1109/TVLSI.2017.2690571
   Hsieh CC, 2017, IEEE ELECTR DEVICE L, V38, P871, DOI 10.1109/LED.2017.2710955
   Hsieh CC, 2016, APPL PHYS LETT, V109, DOI 10.1063/1.4971188
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Huang HT, 2018, IEEE T NANOTECHNOL, V17, P645, DOI 10.1109/TNANO.2017.2732698
   Huangfu WQ, 2017, ASIA S PACIF DES AUT, P794, DOI 10.1109/ASPDAC.2017.7858421
   Imani M, 2018, IEEE EMBED SYST LETT, V10, P14, DOI 10.1109/LES.2017.2746742
   Imani M, 2017, DES AUT CON, DOI 10.1145/3061639.3062337
   Imani M, 2017, ASIA S PACIF DES AUT, P757, DOI 10.1109/ASPDAC.2017.7858415
   Kadetotad D, 2015, IEEE J EM SEL TOP C, V5, P194, DOI 10.1109/JETCAS.2015.2426495
   Kim S, 2017, ACS APPL MATER INTER, V9, P40420, DOI 10.1021/acsami.7b11191
   Kim S, 2017, PHYS CHEM CHEM PHYS, V19, P18988, DOI 10.1039/c7cp03120c
   Li BL, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2446203
   Li B, 2017, MATERIALS IN ENVIRONMENTAL ENGINEERING, P247, DOI 10.1515/9783110516623-025
   Li BX, 2015, IEEE T COMPUT AID D, V34, P1905, DOI 10.1109/TCAD.2015.2445741
   Li BX, 2014, ASIA S PACIF DES AUT, P361, DOI 10.1109/ASPDAC.2014.6742916
   Li S., 2016, SPRINGERPLUS, V5, P1, DOI DOI 10.1155/2016/3203728
   Li Z, 2017, ADVANCED ENGINEERING AND TECHNOLOGY III, P3
   Liu B, 2015, INT J ANTENN PROPAG, V2015, DOI 10.1155/2015/319894
   Liu X., 2014, PROC 18 HIGH PERFORM, P1
   Liu XJ, 2015, INT J APPL MECH, V7, DOI 10.1142/S1758825115400074
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mittal Sparsh, 2017, Journal of Low Power Electronics and Applications, V7, DOI 10.3390/jlpea7030023
   Mittal Sparsh, 2016, International Journal of Computer Aided Engineering and Technology, V8, P424
   Mittal Sparsh, 2016, Journal of Low Power Electronics and Applications, V6, DOI 10.3390/jlpea6010001
   Mittal S, 2014, 2014 3RD INTERNATIONAL CONFERENCE ON ECO-FRIENDLY COMPUTING AND COMMUNICATION SYSTEMS (ICECCS 2014), P9, DOI 10.1109/Eco-friendly.2014.77
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mittal S, 2017, COMPUTERS, V6, DOI 10.3390/computers6010008
   Mittal S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/2994550
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1852, DOI 10.1109/TPDS.2015.2461155
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2871167
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1537, DOI 10.1109/TPDS.2015.2442980
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1226, DOI 10.1109/TPDS.2015.2426179
   Mittal S, 2016, IEEE T VLSI SYST, V24, P103, DOI 10.1109/TVLSI.2015.2389113
   Mittal S, 2015, IEEE COMPUT ARCHIT L, V14, P115, DOI 10.1109/LCA.2014.2355193
   Mittal S, 2015, IEEE T PARALL DISTR, V26, P1524, DOI 10.1109/TPDS.2014.2324563
   Mittal S, 2014, SUSTAIN COMPUT-INFOR, V4, P33, DOI 10.1016/j.suscom.2013.11.001
   Narayanan S., 2017, P INT JOINT C NEUR N
   Ni L., 2017, P IEEE ACM INT S LOW, P1
   Ni LB, 2016, ASIA S PACIF DES AUT, P280, DOI 10.1109/ASPDAC.2016.7428024
   Nielsen M., NEURAL NETWORKS DEEP
   Pandiyan D, 2014, I S WORKL CHAR PROC, P171, DOI 10.1109/IISWC.2014.6983056
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song L., ARXIV170806248
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sun Y, 2017, PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON NANOSCALE COMPUTING AND COMMUNICATION (ACM NANOCOM 2017), DOI 10.1145/3109453.3109461
   Sze V., ARXIV170309039
   Taha TM, 2013, IEEE IJCNN
   Tang S., 2017, NONVOLATILE MEMORY S, P1
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Vetter JS, 2015, COMPUT SCI ENG, V17, P73, DOI 10.1109/MCSE.2015.4
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Wang Y., 2015, P 25 EDITION GREAT L
   Woods W, 2017, IEEE INT SYMP NANO, P103, DOI 10.1109/NANOARCH.2017.8053729
   Xia LX, 2017, DES AUT CON, DOI 10.1145/3061639.3062248
   Xia L, 2015, INTERNATIONAL SYMPOSIUM 2015: EXERCISE AND HEALTH, P58
   Yantir HE, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126526
   Yavits L., 2017, NEAR DATA PROCESSING
   Yu S., P IEEE INT EL DEV M
   Zha Y, 2017, IEEE COMPUT ARCHIT L, V16, P123, DOI 10.1109/LCA.2017.2672558
   Zhou F, 2015, APPL PHYS LETT, V107, DOI 10.1063/1.4934835
   Zidan MA, 2018, IEEE T MULTI-SCALE C, V4, P698, DOI 10.1109/TMSCS.2017.2721160
NR 85
TC 97
Z9 103
U1 2
U2 10
PD MAR
PY 2019
VL 1
IS 1
BP 75
EP 114
DI 10.3390/make1010005
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Safaei, A
   Wu, QMJ
   Yang, YM
   Akilan, T
AF Safaei, Amin
   Wu, Q. M. Jonathan
   Yang, Yimin
   Akilan, Thangarajah
GP IEEE
TI System-on-a-chip (SoC)-based Hardware Acceleration for Extreme Learning
   Machine
SO 2017 24TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND
   SYSTEMS (ICECS)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 24th IEEE International Conference on Electronics, Circuits and Systems
   (ICECS)
CY DEC 05-08, 2017
CL Batumi, GEORGIA
DE Extreme learning machine; system on chip field-programmable gate array
   (SoC FPGA); hardware (HW) neural networks (NNs)
AB Extreme learning machine (ELM) is a popular class of supervised models in machine learning that is used in a wide range of applications, such as image object classification, video content analysis (VCA) and human action recognition. However, ELM classification is a computationally demanding task, and the existing hardware implementations are not efficient for embedded systems. This work addresses the implementation of extreme learning machine (ELM) in a system on a chip field-programmable gate-array (SoC FPGA)-based customized architecture to efficiently utilize hardware accelerator. The optimization process consists of parallelism extraction, algorithm tuning and deep pipelining.
C1 [Safaei, Amin; Wu, Q. M. Jonathan; Yang, Yimin; Akilan, Thangarajah] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON, Canada.
RP Safaei, A (corresponding author), Univ Windsor, Dept Elect & Comp Engn, Windsor, ON, Canada.
EM safaeia@uwindsor.ca; jwu@uwindsor.ca; eyyang@uwindsor.ca;
   thangara@uwindsor.ca
CR Bjorck A., 1967, BIT, V7, P1, DOI [10.1007/BF01934122, DOI 10.1007/BF01934122]
   Fowers J, 2012, FPGA 12: PROCEEDINGS OF THE 2012 ACM-SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P47
   Frances-Villora JV, 2016, COMPUT ELECTR ENG, V51, P139, DOI 10.1016/j.compeleceng.2016.02.007
   Gentle J. E., 2007, MATRIX ALGEBRA THEOR, P172
   Hadfield S., 2016, INT J COMPUT VISION, V121, P1
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Li S., 2017, NEUROCOMPUTING
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Safaei A., 2017, 2017 IEEE INT C SYST
   Safaei A., 2017, J FRANKLIN I
   Safaei A, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P531, DOI 10.1109/HPCSim.2016.7568380
   Safaei A, 2016, IEEE INT SYMP CIRC S, P2571, DOI 10.1109/ISCAS.2016.7539118
   van Heeswijk M, 2011, NEUROCOMPUTING, V74, P2430, DOI 10.1016/j.neucom.2010.11.034
   Xilinx, 2017, EXP ALL PROGR SOC PO
NR 14
TC 3
Z9 3
U1 0
U2 2
PY 2017
BP 470
EP 473
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Russo, M
   Russo, GV
   Petta, C
   Randazzo, N
AF Russo, M
   Russo, GV
   Petta, C
   Randazzo, N
GP IEEE
TI An accelerator card for fuzzy learning
SO 1ST INTERNATIONAL SYMPOSIUM ON NEURO-FUZZY SYSTEMS - AT'96, CONFERENCE
   REPORT
DT Proceedings Paper
CT 1st International Symposium on Neuro-Fuzzy Systems (AT 96)
CY AUG 29-31, 1996
CL ECOLE POLYTECH FED LAUSANNE, LAUSANNE, SWITZERLAND
HO ECOLE POLYTECH FED LAUSANNE
DE fuzzy logic; genetic algorithms; machine learning
AB In this paper we present a fuzzy multiprocessor card which is capable of significantly increasing the performance, in terms of time, of a generic fuzzy inference learning algorithm based on techniques that do not use the derivative of the function to be learned, such as genetic algorithms.
RP Russo, M (corresponding author), UNIV CATANIA,FAC INGN,IST INFORMAT & TELECOM,VIALE ANDREA DORIA 6,I-95125 CATANIA,ITALY.
NR 0
TC 0
Z9 0
U1 0
U2 1
PY 1996
BP 39
EP 46
DI 10.1109/ISNFS.1996.603819
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Hwang, R
   Kim, T
   Kwon, Y
   Rhu, M
AF Hwang, Ranggi
   Kim, Taehun
   Kwon, Youngeun
   Rhu, Minsoo
GP IEEE
TI Centaur: A Chiplet-based, Hybrid Sparse-Dense Accelerator for
   Personalized Recommendations
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
DE Accelerator; processor architecture; FPGA; machine learning; neural
   network; deep learning
AB Personalized recommendations are the backbone machine learning (ML) algorithm that powers several important application domains (e.g., ads, e-commerce, etc) serviced from cloud datacenters. Sparse embedding layers are a crucial building block in designing recommendations yet little attention has been paid in properly accelerating this important ML algorithm. This paper first provides a detailed workload characterization on personalized recommendations and identifies two significant performance limiters: memory-intensive embedding layers and compute-intensive multi-layer perceptron (MLP) layers. We then present Centaur, a chiplet-based hybrid sparse-dense accelerator that addresses both the memory throughput challenges of embedding layers and the compute limitations of MLP layers. We implement and demonstrate our proposal on an Intel HARPv2, a package-integrated CPU+FPGA device, which shows a 1.7-17.2x performance speedup and 1.7-19.5x energy-efficiency improvement than conventional approaches.
C1 [Hwang, Ranggi; Kim, Taehun; Kwon, Youngeun; Rhu, Minsoo] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
RP Hwang, R (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
EM ranggi.hwang@kaist.ac.kr; taehun.kim@kaist.ac.kr; yekwon@kaist.ac.kr;
   mrhu@kaist.ac.kr
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M, 2016, INT SYMP MICROARCH
   Amodei D., 2015, DEEP SPEECH 2 ENDTOE
   [Anonymous], 2018, DEEP LEARNING INFERE
   [Anonymous], 2017, SPARS OP
   [Anonymous], 2018, IEEE MICRO
   [Anonymous], 2016, P INT S HIGHP COMP A
   [Anonymous], 2016, P INT S MICR MICRO
   [Anonymous], 2019, DEEP LEARNING RECOMM
   [Anonymous], 2019, P S PRINC PRACT PAR
   [Anonymous], P INT S HIGH PERF CO
   [Anonymous], 2018, P INT S FIELD PROGR
   [Anonymous], P INT S COMP ARCH IS
   [Anonymous], 2018, P INT S HIGH COMP AR
   [Anonymous], 2019, INTEL FOV 3D PACK TE
   [Anonymous], 2018, P INT S HIGHP COMP A
   [Anonymous], 2017, HOT CHIPS S HIGH PER
   [Anonymous], 2015, P INT S FIELD PROGR
   [Anonymous], 2017, NVIDIA DGX1V DEEP LE
   [Anonymous], 2016, INT SYMP MICROARCH
   [Anonymous], 2017, P INT S MICR MICRO
   [Anonymous], 2020, P INT S COMP ARCH IS
   [Anonymous], 2018, IEEE COMPUTER ARCHIT
   [Anonymous], 2016, FLOAT IP COR US GUID
   [Anonymous], 2017, CLOUD TPUS ML ACCELE
   [Anonymous], P INT S FIELD PROGR
   [Anonymous], 2019, I S WORLD WIREL MOBI
   [Anonymous], 2017, HARDW ACC RES PROGR
   [Anonymous], 2019, P INT S MICR MICRO
   [Anonymous], 2019, P INT S COMP ARCH IS
   [Anonymous], 2019, P INT S HIGHP COMP A
   [Anonymous], 2018, COMPETITIVE ANAL SYS
   [Anonymous], 2018, P INT S MICR MICRO
   [Anonymous], P INT S COMP ARCH IS
   [Anonymous], 2018, NVIDIA TESLA V100
   [Anonymous], 2016, P INT S COMP ARCH IS
   [Anonymous], 2018, MICRO
   [Anonymous], 2019, C SYST MACH LEARN SY
   [Anonymous], 2017, P INT S COMP ARCH IS
   Arunkumar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P320, DOI 10.1145/3079856.3080231
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, IEEE MTT S INT MICR
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Choi Y, 2020, P INT C ARCH SUPP PR
   Choi Y, 2020, INT J CONTEMP HOSP M, V32, P977, DOI 10.1108/IJCHM-03-2019-0265
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Gao CH, 2018, ISBDAI '18: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON BIG DATA AND ARTIFICIAL INTELLIGENCE, P1, DOI 10.1145/3305275.3305276
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Intel, 2020, INT VTUNE PROF
   Intel, 2019, INT AG FPGAS SOCS
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Kwon Y, 2019, IEEE MICRO, V39, P82, DOI 10.1109/MM.2019.2929165
   Lee K., 2019, P C N AM CHAPT ASS C, P4171, DOI DOI 10.18653/V1/N19-1423
   Mahajan R, 2016, ELEC COMP C, P557, DOI 10.1109/ECTC.2016.201
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Nethercote N, 2007, PLDI'07: PROCEEDINGS OF THE 2007 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P89, DOI 10.1145/1250734.1250746
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E., 2018, P INT S COMP ARCH IS
   Sharma H, 2016, INT SYMP MICROARCH
   Wang JZ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P839, DOI 10.1145/3219819.3219869
   Whatmough P., 2017, HOT CHIPS S HIGH PER
   Wu C.-J, 2019, DEEP LEARNING ITS NO
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
NR 67
TC 32
Z9 33
U1 2
U2 12
PY 2020
BP 968
EP 981
DI 10.1109/ISCA45697.2020.00083
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Kachris, C
   Koromilas, E
   Stamelos, I
   Soudris, D
AF Kachris, Christoforos
   Koromilas, Elias
   Stamelos, Ioannis
   Soudris, Dimitrios
BE Patt, Y
   Nandy, SK
TI SPynq: Acceleration of Machine Learning Applications over Spark on Pynq
SO INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES,
   MODELING, AND SIMULATION (SAMOS 2017)
DT Proceedings Paper
CT 17th Annual International Conference on Embedded Computer Systems -
   Architectures, Modeling, and Simulation (SAMOS)
CY JUL 16-20, 2017
CL Samos, GREECE
AB Spark is one of the most widely used frameworks for data analytics that offers fast development of applications like machine learning and graph computations in distributed systems. In this paper, we present SPynq: A framework for the efficient utilization of hardware accelerators over the Spark framework on heterogeneous MPSoC FPGAs, such as Zynq. Spark has been mapped to the Pynq platform and the proposed framework allows the seamlessly utilization of the programmable logic for the hardware acceleration of computational intensive Spark kernels. We have also developed the required libraries in Spark that hides the accelerator's details to minimize the design effort to utilize the accelerators.
   A cluster of 4 nodes (workers) based on the all-programmable MPSoCs has been implemented and the proposed platform is evaluated in a typical machine learning application based on logistic regression. The logistic regression kernel has been developed as an accelerator and incorporated to the Spark. The developed system is compared to a high-performance Xeon cluster that is typically used in cloud computing. The performance evaluation shows that the heterogeneous accelerator-based MpSoC can achieve up to 2.3x system speedup compared with a Xeon system (with 90% accuracy) and 20x better energy-efficiency. For embedded application, the proposed system can achieve up to 40x speedup compared to the software only implementation on low-power embedded processors and 30x lower energy consumption.
C1 [Kachris, Christoforos] NTUA, Inst Commun & Comp Syst ICCS, Athens, Greece.
   [Koromilas, Elias; Stamelos, Ioannis; Soudris, Dimitrios] Natl Tech Univ Athens, Dept Elect & Comp Engn, Athens, Greece.
RP Kachris, C (corresponding author), NTUA, Inst Commun & Comp Syst ICCS, Athens, Greece.
CR [Anonymous], 2016, XILINX RECONFIGURABL
   Apache, SPARK
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Cong J, 2016, DES AUT CON, DOI 10.1145/2897937.2905012
   Das T., 2012, P 9 USENIX C NETWORK, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Esmaeilzadeh H, 2013, COMMUN ACM, V56, P93, DOI 10.1145/2408776.2408797
   Esmaeilzadeh H, 2012, IEEE MICRO, V32, P122, DOI 10.1109/MM.2012.17
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Martin C, 2014, POSTDENNARD SCALING
NR 9
TC 3
Z9 3
U1 1
U2 1
PY 2017
BP 70
EP 77
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ohba, M
   Shindo, S
   Miwa, S
   Tsumura, T
   Yamaki, H
   Honda, H
AF Ohba, Momoka
   Shindo, Satoshi
   Miwa, Shinobu
   Tsumura, Tomoaki
   Yamaki, Hayato
   Honda, Hiroki
GP IEEE
TI Initial Study of Reconfigurable Neural Network Accelerators
SO 2016 FOURTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR)
SE International Symposium on Computing and Networking
DT Proceedings Paper
CT 4th International Symposium on Computing and Networking (CANDAR)
CY NOV 22-25, 2016
CL Hiroshima, JAPAN
AB Neural Networks or NNs are widely used for many machine learning applications such as image processing and speech recognition. Since general-purpose processors such as CPUs and GPUs are energy inefficient for computing NNs, application-specific hardware accelerators for NNs (a.k.a. Neural Network Accelerators or NNAs) have been proposed to improve the energy efficiency. However, the existing NNAs are too customized for computing specific NNs, and do not allow to change neuron models or learning algorithms. This limitation prevents machine-learning researchers from exploiting NNAs, so we are developing a general-purpose NNA including reconfigurable logic, which is called a reconfigurable NNA or RNNA. The RNNA is highly tuned for the NN computation but allows end users to customize the hardware to compute desired NNs. This paper introduces the RNNA architecture, and reports the performance analysis of the RNNA with an in-house cycle-level simulator.
C1 [Ohba, Momoka; Miwa, Shinobu; Yamaki, Hayato; Honda, Hiroki] Univ Electron & Commun, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.
   [Shindo, Satoshi; Tsumura, Tomoaki] Nagoya Inst Technol, Showa Ku, Gokiso Cho, Nagoya, Aichi 4668555, Japan.
RP Ohba, M (corresponding author), Univ Electron & Commun, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.
EM ohba@hpc.is.uec.ac.jp; miwa@hpc.is.uec.ac.jp; yamaki@hpc.is.uec.ac.jp;
   honda@hpc.is.uec.ac.jp
CR [Anonymous], P 22 ACM INT C MULTI
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
NR 3
TC 1
Z9 1
U1 0
U2 0
PY 2016
BP 707
EP 709
DI 10.1109/CANDAR.2016.106
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Liu, LY
   Khalid, MAS
AF Liu, Liyuan
   Khalid, Mohammed A. S.
GP IEEE
TI Acceleration of k-Nearest Neighbor Algorithm on FPGA using Intel SDK for
   OpenCL
SO 2018 IEEE 61ST INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT 61st IEEE International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY AUG 05-08, 2018
CL Windsor, CANADA
DE FPGAs; high level synthesis; machine learning algorithms
AB Field Programmable Gate Arrays (FPGAs) have been widely used for accelerating machine learning algorithms. However, the high design cost and time for implementing FPGA-based accelerators using traditional HDL-based design methodologies has discouraged users from designing FPGA-based accelerators. In recent years, a new CAD tool called Intel FPGA SDK for OpenCL (IFSO) allowed fast and efficient design of FPGA-based hardware accelerators from high level specification such as OpenCL. Even software engineers with basic hardware design knowledge could design FPGA-based accelerators. In this paper, IFSO has been used to explore acceleration of k-Nearest-Neighbor (kNN) algorithm using FPGAs. kNN is a popular algorithm used in machine learning. Bitonic sorting algorithm was used within the kNN algorithm to check if this provides any performance improvements. The experimental results obtained from FPGA-based acceleration were compared with the state of the art CPU implementation. The optimized algorithm was implemented on two different FPGAs (Intel Stratix A7 and Intel Arria 10 GX). Experimental results show that the FPGA-based accelerators provided similar or better execution time (up to 80X faster) and better power efficiency (83% reduction in power consumption) than traditional platforms such as a workstation based on two Intel Xeon processors E5-2620 Series (each with 6 cores and running at 2.4 GHz).
C1 [Liu, Liyuan; Khalid, Mohammed A. S.] Univ Windsor, Dept Elect & Comp Engn, Res Ctr Integrated Microsyst RCIM, Windsor, ON, Canada.
RP Liu, LY (corresponding author), Univ Windsor, Dept Elect & Comp Engn, Res Ctr Integrated Microsyst RCIM, Windsor, ON, Canada.
EM liu181@uwindsor.ca; mkhalid@uwindsor.ca
CR Botsinis P., 2013, IEEE ACCESS
   Gaster Benedict R., 2012, HETEROGENEOUS COMPUT, P12
   Han J., 2012, BRIT LIB CATALOGUING, P423
   Hussain H. M., 2012, Proceedings of the 2012 NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2012), P205, DOI 10.1109/AHS.2012.6268651
   Infoworld Staff, WHAT IS BIG DAT EV Y
   *INT CORP, INT FPGA SDK OPENCL
   Intel Corporation, SYST ACC FPGA US ALT
   Intel Corporation, 2015, ALT SDK OPENCL PROGR
   Luo P., 2006, FLEX EFF INF HANDL B, P177
   Peng H., 2016, SOC DES C ISOCC IEEE
   Pu Y., 2015, FIELD PROGR CUST COM
   Song X., 2014, 11 INT C INF TECHN N
   Stamoulias I., 2013, ACM T EMBED COMPUT S, V13
   Tang Qingyun, 2016, THESIS, P75
NR 14
TC 3
Z9 3
U1 0
U2 0
PY 2018
BP 1070
EP 1073
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Diamantopoulos, D
   Ringlein, B
   Purandare, M
   Singh, G
   Hagleitner, C
AF Diamantopoulos, Dionysios
   Ringlein, Burkhard
   Purandare, Mitra
   Singh, Gagandeep
   Hagleitner, Christoph
BE Mentens, N
   Sousa, L
   Trancoso, P
   Pericas, M
   Sourdis, I
TI Agile Autotuning of a Transprecision Tensor Accelerator Overlay for TVM
   Compiler Stack
SO 2020 30TH INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 30th International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 31-SEP 04, 2020
CL ELECTR NETWORK
DE Neural Networks; Machine Learning; Autotuning; FPGA; Transprecision
   Computing; Tensor Accelerator
ID NEURAL-NETWORK
AB Specialized accelerators for tensor-operations, such as blocked-matrix operations and multi-dimensional convolutions, have emerged as powerful architecture choices for high-performance Deep-Learning computing. The rapid development of frameworks, models, and precision options challenges the adaptability of such tensor-accelerators since the adaptation to new requirements incurs significant engineering costs. Programmable tensor accelerators offer a promising alternative by allowing reconfiguration of a virtual architecture that overlays on top of the physical FPGA configurable fabric. We propose an overlay (tau-VTA) and an optimization method guided by agile-inspired auto-tuning techniques. We achieve higher performance of up to 2.5x and faster convergence of up to 8.1x.
C1 [Diamantopoulos, Dionysios; Ringlein, Burkhard; Purandare, Mitra; Singh, Gagandeep; Hagleitner, Christoph] IBM Res Europe, Zurich, Switzerland.
   [Singh, Gagandeep] Eindhoven Univ Technol, Eindhoven, Netherlands.
RP Diamantopoulos, D (corresponding author), IBM Res Europe, Zurich, Switzerland.
EM did@zurich.ibm.com; ngl@zurich.ibm.com; mpu@zurich.ibm.com;
   g.singh@tue.nl; hle@zurich.ibm.com
CR [Anonymous], 2018, P 12 USENIX C OPERAT
   [Anonymous], 2018, ABS180204730 CORR
   [Anonymous], 2016, KDD16 P 22 ACM, DOI DOI 10.1145/2939672.2939785
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Chen T., 2018, SER NIPS 18, P3393
   Cong J., CORR
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Faraone J, 2017, LECT NOTES COMPUT SC, V10635, P393, DOI 10.1007/978-3-319-70096-0_41
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Han, 2016, 4 INT C LEARNING REP
   Han S., 2015, P 28 INT C NEUR INF, V1, P1135
   Iandola F. N., 2016, ARXIV
   Lee Y, 2016, IEEE MICRO, V36, P8, DOI 10.1109/MM.2016.11
   Li M., 2020, ARXIV200203794
   Li Z, 2017, FRONT COMPUT SCI-CHI, V11, P746, DOI 10.1007/s11704-016-6159-1
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Roesch J, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P58, DOI 10.1145/3211346.3211348
   Schafer B. Carrion, 2019, IEEE T COMPUT AID D, P1
   Sood A., 2019, ARXIV190106261
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Ulusel O, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2567661
   Wang E., 2020, IEEE T IND INFORM, P1, DOI DOI 10.1109/TII.2020.3028616
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
NR 30
TC 0
Z9 0
U1 0
U2 5
PY 2020
BP 310
EP 316
DI 10.1109/FPL50879.2020.00058
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Emma, C
   Edelen, A
   Hogan, MJ
   O'Shea, B
   White, G
   Yakimenko, V
AF Emma, C.
   Edelen, A.
   Hogan, M. J.
   O'Shea, B.
   White, G.
   Yakimenko, V
TI Machine learning-based longitudinal phase space prediction of particle
   accelerators
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB We report on the application of machine learning (ML) methods for predicting the longitudinal phase space (LPS) distribution of particle accelerators. Our approach consists of training a ML-based virtual diagnostic to predict the LPS using only nondestructive linac and e-beam measurements as inputs. We validate this approach with a simulation study for the FACET-II linac and with an experimental demonstration conducted at LCLS. At LCLS, the e-beam LPS images are obtained with a transverse deflecting cavity and used as training data for our ML model. In both the FACET-11 and LCLS cases we find good agreement between the predicted and simulated/measured LPS profiles, an important step towards showing the feasibility of implementing such a virtual diagnostic on particle accelerators in the future.
C1 [Emma, C.; Edelen, A.; Hogan, M. J.; O'Shea, B.; White, G.; Yakimenko, V] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
RP Emma, C (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM cemma@slac.stanford.edu
CR Barber SK, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.104801
   Behrens C, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4762
   Edelen A., 2018, P INT PART ACC C VAN
   Edelen A., 2016, P N AM PART ACC C CH
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Joshi C, 2018, PLASMA PHYS CONTR F, V60, DOI 10.1088/1361-6587/aaa2e3
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Loos H., 2007, 12619 SLACPUB
   Neumann C. P., 2000, PHYS REV SPEC TOP-AC, V3
   Sanchez-Gonzalez A, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15461
   Scheinker A, 2017, SPRBRIEF ELECT, P1, DOI 10.1007/978-3-319-50790-3
   Scheinker A., 2018, P INT PART ACC C VAN
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Tennenbaum P., 2005, P 21 PART ACC C KNOX, P4197
   Weingartner R, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.111302
   Yakimenko V., 2016, P 7 INT PART ACC C J
NR 17
TC 49
Z9 52
U1 0
U2 11
PD NOV 16
PY 2018
VL 21
IS 11
AR 112802
DI 10.1103/PhysRevAccelBeams.21.112802
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Hwu, WM
   Patel, S
AF Hwu, Wen-mei
   Patel, Sanjay
TI Accelerator Architectures-A Ten-Year Retrospective
SO IEEE MICRO
DT Article
AB This article is a ten-year retrospective of the rise of the accelerators since the authors coedited a 2008 IEEE MICRO special issue on Accelerator Architectures. It identifies the most prominent applications using the accelerators to date: high-performance computing, crypto currencies, and machine learning. For the two most popular types of accelerators, GPUs and FPGAs, the article gives a concise overview of the important trends in their compute throughput, memory bandwidth, and system interconnect. The article also articulates the importance of education for growing the adoption of accelerators. It concludes by identifying emerging types of accelerators and making a few predictions for the coming decade.
C1 [Hwu, Wen-mei] Univ Illinois, Champaign, IL 61820 USA.
   [Patel, Sanjay] Univ Illinois, Elect & Comp Engn, Champaign, IL USA.
RP Hwu, WM (corresponding author), Univ Illinois, Champaign, IL 61820 USA.
CR [Anonymous], 2018, TENS PROC UN
   [Anonymous], 2018, NVLINK
   [Anonymous], 2018, TOP 500 LIST
   [Anonymous], 2018, APPLE A11
   [Anonymous], 2018, GREEN 500 LIST
   Firestone Daniel, 2018, P NSDI
   Hwu, 2017, IEEE INT C REB COMP
   Intel, HARDW ACC RES PROGR
   Jon Peddie, GPU MARK DECL SEAS Q
   NVIDIA, 2018, NVIDIA GPU DIR TECHN
   Zhang X., 2018, P 37 INT C COMP AID
NR 11
TC 6
Z9 7
U1 0
U2 3
PD NOV-DEC
PY 2018
VL 38
IS 6
BP 56
EP 62
DI 10.1109/MM.2018.2877839
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Awal, A
   Hetzel, J
   Gebel, R
   Kamerdzhiev, V
   Pretz, J
AF Awal, A.
   Hetzel, J.
   Gebel, R.
   Kamerdzhiev, V.
   Pretz, J.
TI Optimization of the injection beam line at the Cooler Synchrotron COSY
   using Bayesian Optimization
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Accelerator Applications; Accelerator modelling and simulations
   (multi-particle dynamics; single-particle dynamics); Analysis and
   statistical methods
AB The complex non-linear processes in multi-dimensional parameter spaces, that are typical for an accelerator, are a natural application for machine learning algorithms. This paper reports on the use of Bayesian optimization for the optimization of the Injection Beam Line (IBL) of the Cooler Synchrotron storage ring COSY at the Forschungszentrum Julich, Germany. Bayesian optimization is a machine learning method that optimizes a continuous objective function using limited observations. The IBL is composed of 15 quadrupoles and 28 steerers. The goal is to increase the beam intensity inside the storage ring. The results showed the effectiveness of the Bayesian optimization in achieving better/faster results compared to manual optimization.
C1 [Awal, A.; Pretz, J.] Rhein Westfal TH Aachen, Phys Inst B 3, Otto Blumenthal Str, D-52056 Aachen, Germany.
   [Awal, A.; Hetzel, J.; Gebel, R.; Kamerdzhiev, V.] GSI Helmholtzzentrum Schwerionenforsch, Planckstr 1, D-64291 Darmstadt, Germany.
   [Pretz, J.] Forschungszentrum Julich GmbH, Inst Kernphys, Wilhelm Johnen Str, D-52428 Julich, Germany.
RP Pretz, J (corresponding author), Rhein Westfal TH Aachen, Phys Inst B 3, Otto Blumenthal Str, D-52056 Aachen, Germany.; Pretz, J (corresponding author), Forschungszentrum Julich GmbH, Inst Kernphys, Wilhelm Johnen Str, D-52428 Julich, Germany.
EM pretz@physik.rwth-aachen.de
CR Miskovich SA, 2022, Arxiv, DOI arXiv:2209.04587
   Bechstedt U, 1996, NUCL INSTRUM METH B, V113, P26, DOI 10.1016/0168-583X(95)01352-0
   Brochu E, 2010, Arxiv, DOI [arXiv:1012.2599, DOI 10.48550/ARXIV.1012.2599]
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A., 2018, FERMILABPUB19017AD
   EPICS, ABOUT US
   Heidelberg Ion-Beam Therapy Center (HIT), CPYM CYTH BIND MAD X
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147
   Madx, MAD X METH ACC DES V
   Maier R, 1997, NUCL PHYS A, V626, p395C
   Nogueira F., BAYESIAN OPTIMIZATIO
   Pedregosa F., 2012, J MACH LEARNING RES, V12, P2825, DOI DOI 10.48550/ARXIV.1201.0490
   Pousa AF, 2022, Arxiv, DOI arXiv:2212.12551
   PyEpics, PYEPICS EP CHANN ACC
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
NR 16
TC 0
Z9 0
U1 2
U2 2
PD APR
PY 2023
VL 18
IS 4
AR P04010
DI 10.1088/1748-0221/18/04/P04010
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Zhang, D
   Huda, S
   Songhori, E
   Prabhu, K
   Le, Q
   Goldie, A
   Mirhoseini, A
AF Zhang, Dan
   Huda, Safeen
   Songhori, Ebrahim
   Prabhu, Kartik
   Quoc Le
   Goldie, Anna
   Mirhoseini, Azalia
BE Falsafi, B
   Ferdman, M
   Lu, S
   Weinisch, T
TI A Full-Stack Search Technique for Domain Optimized Deep Learning
   Accelerators
SO ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON
   ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 27th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY FEB 28-MAR 04, 2022
CL Lausanne, SWITZERLAND
DE machine learning; tensor processing unit; hardware-software code-sign;
   design space exploration; operation fusion
ID PERFORMANCE; SCALE
AB The rapidly-changing deep learning landscape presents a unique opportunity for building inference accelerators optimized for specific datacenter-scale workloads. We propose Full-stack Accelerator Search Technique (FAST), a hardware accelerator search framework that defines a broad optimization environment covering key design decisions within the hardware-software stack, including hardware data-path, software scheduling, and compiler passes such as operation fusion and tensor padding. In this paper, we analyze bottlenecks in state-of-the-art vision and natural language processing (NLP) models, including EfficientNet [91] and BERT [19], and use FAST to design accelerators capable of addressing these bottlenecks. FAST-generated accelerators optimized for single workloads improve Perf/TDP by 3.7x on average across all benchmarks compared to TPU-v3. AFAST-generated accelerator optimized for serving a suite of workloads improves Perf/TDP by 2.4x on average compared to TPU-v3. Our return on investment analysis shows that FAST-generated accelerators can potentially be practical for moderate-sized datacenter deployments.
C1 [Zhang, Dan; Songhori, Ebrahim; Quoc Le; Goldie, Anna; Mirhoseini, Azalia] Google Brain, Mountain View, CA 94043 USA.
   [Huda, Safeen] Google, Sunnyvale, CA USA.
   [Prabhu, Kartik] Stanford Univ, Stanford, CA 94305 USA.
RP Zhang, D (corresponding author), Google Brain, Mountain View, CA 94043 USA.
EM dazh@google.com; safeen@google.com; esonghori@google.com;
   kprabhu7@stanford.edu; qvl@google.com; agoldie@google.com;
   azalia@google.com
CR Abdelfattah M. S., 2020, ARXIV200205022
   Abdolrashidi Amirali, 2019, WORKSHOP ML SYSTEMS
   Alwani M., 2016, MICROPAGE, P1
   [Anonymous], 2011, CUDA EXAMPLE INTRO G
   [Anonymous], 2020, ELECT POWER MONTHLY
   [Anonymous], 2021, SOFTWARE ENG SALARIE
   [Anonymous], 2017, 2017 IEEEACM INT S L
   [Anonymous], 2021, DEV GUIDE NVIDIA DEE
   Bannon Pete, 2021, COMPUTE REDUNDANCY S
   Barroso L A, 2019, DATACENTER COMPUTER, DOI DOI 10.2200/S00874ED3V01Y201809CAC046
   Batra Gaurav, 2018, ARTIFICIALINTELLIGE
   Boehm M, 2018, PROC VLDB ENDOW, V11, P1755, DOI 10.14778/3229863.3229865
   Brown Tom B., 2020, ARXIV
   Cai Han, 2019, ARXIV181200332 CSLG
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Choquette J, 2021, IEEE MICRO, V41, P29, DOI 10.1109/MM.2021.3061394
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Dave S, 2020, INT CONF ACOUST SPEE, P1544, DOI [10.1109/ICASSP40776.2020.9054275, 10.1109/icassp40776.2020.9054275]
   Devlin Jacob, 2019, ARXIV181004805 CSCL
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fedus William, 2021, J MACHINE LEARNING R, DOI DOI 10.48550/ARXIV.2101.03961
   Friedlob G.T., 1996, UNDERSTANDING RETURN
   Gamrath G., 2020, SCIP OPTIMIZATION SU
   Gelbart MA, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P250
   Golovin D, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1487, DOI 10.1145/3097983.3098043
   Golovin Daniel, 2017, 10 NIPSWORKSHOP OPTI
   Google, 2018, XLA OPTIMIZING COMPI
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde Kartik, 2021, P 26 ACM INT C ARCH, P943, DOI 10.1145/3445814.3446762
   Howard A. G., 2017, ARXIV
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Iandola F. N., 2016, ARXIV
   Jiang WW, 2020, IEEE T COMPUT AID D, V39, P4805, DOI 10.1109/TCAD.2020.2986127
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi Norman P, 2017, P 44 ANN INT S COMPU
   Kanter David, 2021, MLPERF INFERENCE RUL
   Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Kaufman Samuel J., 2020, ML SYSTEMS WORKSHOP
   Khailany Brucek, 2019, MACHINE LEARNING ASS
   Kung S. Y., 1988, 1988 IEEE International Symposium on Circuits and Systems. Proceedings (Cat. No.88CH2458-8), P313, DOI 10.1109/ISCAS.1988.14929
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Lan Z, 2019, ALBERT LITE BERT SEL, DOI DOI 10.48550/ARXIV.1909.11942
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lee Y, 2016, IEEE MICRO, V36, P8, DOI 10.1109/MM.2016.11
   Lepikhin D., 2021, 9 INT C LEARNING REP
   Li R, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P928, DOI 10.1145/3445814.3446759
   Li S, 2021, PROC CVPR IEEE, P8081, DOI 10.1109/CVPR46437.2021.00799
   Li Yuhong, 2020, P 57 ACMEDACIEEE DES, DOI [10.5555/3437539.3437669, DOI 10.5555/3437539.3437669]
   Liang SW, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415645
   Lin Wei, 2018, ARXIV PREPRINT ARXIV
   Lin Yujun, 2019, NEURIPS ML SYSTEMSWO
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luong M.-Th., 2020, CORR
   Ma CH, 2019, IEEE ACCESS, V7, P121685, DOI 10.1109/ACCESS.2019.2936215
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Magaki I, 2016, CONF PROC INT SYMP C, P178, DOI 10.1109/ISCA.2016.25
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Mei LY, 2021, IEEE T COMPUT, V70, P1160, DOI 10.1109/TC.2021.3059962
   Milakov Maxim, 2018, ARXIV180502867 CSPF
   Nayak Pandu, 2019, UNDERSTANDING SEARCH
   Nilsson P, 2014, 2014 NORCHIP
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Park Jongsoo, 2018, ABS181109886 CORR
   Patterson D., 2021, ARXIV PREPRINT ARXIV
   Prabhakar R, 2018, IEEE MICRO, V38, P20, DOI 10.1109/MM.2018.032271058
   Putnam A, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P5, DOI 10.1145/3060403.3066860
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qin SY, 2019, IEEE I CONF COMP VIS, P4703, DOI 10.1109/ICCV.2019.00480
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Radford A., 2019, OPENAI BLOG
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Ranganathan P, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P600, DOI 10.1145/3445814.3446723
   Roesch Jared, 2019, ARXIV190408368 CSLG
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shahan Zachary., 2020, TESLA AUTOPILOT INNO
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shaolin Xie, 2018, ACM SIGOPS Operating Systems Review, V52, P96, DOI 10.1145/3273982.3273991
   Sharma H, 2016, INT SYMP MICROARCH
   Shi Zhan, 2020, ARXIV201002075 CSLG
   Smith Ryan., 2020, NVIDIA AMPERE UNLEAS
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Supermicro, 2021, DAT CTR ENV STAT GRE
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkatesan R., 2019, P IEEE ACM INT C COM, P1
   Vulimiri Ashish, 2013, ARXIV PREPRINT ARXIV
   Wei XC, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317875
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wu Z., 2015, P 12 USENIX S NETW S, P543
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Yang L, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218676
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yazdanbakhsh Amir, 2021, ARXIV210201723 CSLG
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang D, 2018, ACM SIGPLAN NOTICES, V53, P593, DOI [10.1145/3173162.3173197, 10.1145/3296957.3173197]
   Zhang XF, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415609
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhang XY, 2019, IEEE COMP SOC ANN, P25, DOI 10.1109/ISVLSI.2019.00014
   Zhao J, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P427, DOI 10.1109/MICRO50266.2020.00044
   Zhou Y., 2020, ADV NEURAL INFORM PR, V33, P13844
   Zhou Yanqi, 2021, ARXIV PREPRINT ARXIV
NR 111
TC 5
Z9 5
U1 0
U2 1
PY 2022
BP 27
EP 42
DI 10.1145/3503222.3507767
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Inayat, K
   Muslim, FB
   Iqbal, J
   Mohsan, SAH
   Alkahtani, HK
   Mostafa, SM
AF Inayat, Kashif
   Muslim, Fahad Bin
   Iqbal, Javed
   Mohsan, Syed Agha Hassnain
   Alkahtani, Hend Khalid
   Mostafa, Samih M.
TI Power-Intent Systolic Array Using Modified Parallel Multiplier for
   Machine Learning Acceleration
SO SENSORS
DT Article
DE machine learning; deep learning; accelerators; power-intent; systolic
   arrays
ID ENERGY
AB Systolic arrays are an integral part of many modern machine learning (ML) accelerators due to their efficiency in performing matrix multiplication that is a key primitive in modern ML models. Current state-of-the-art in systolic array-based accelerators mainly target area and delay optimizations with power optimization being considered as a secondary target. Very few accelerator designs directly target power optimizations and that too using very complex algorithmic modifications that in turn result in a compromise in the area or delay performance. We present a novel Power-Intent Systolic Array (PI-SA) that is based on the fine-grained power gating of the multiplication and accumulation (MAC) block multiplier inside the processing element of the systolic array, which reduces the design power consumption quite significantly, but with an additional delay cost. To offset the delay cost, we introduce a modified decomposition multiplier to obtain smaller reduction tree and to further improve area and delay, we also replace the carry propagation adder with a carry save adder inside each sub-multiplier. Comparison of the proposed design with the baseline Gemmini naive systolic array design and its variant, i.e., a conventional systolic array design, exhibits a delay reduction of up to 6%, an area improvement of up to 32% and a power reduction of up to 57% for varying accumulator bit-widths.
C1 [Inayat, Kashif] Incheon Natl Univ, Dept Elect Engn, Incheon 22012, South Korea.
   [Muslim, Fahad Bin] GIK Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi 23460, Pakistan.
   [Iqbal, Javed] Univ Engn & Appl Sci, Dept Comp Syst Engn, Swat 19201, Pakistan.
   [Mohsan, Syed Agha Hassnain] Zhejiang Univ, Ocean Coll, Opt Commun Lab, Zheda Rd 1, Zhoushan 316021, Peoples R China.
   [Alkahtani, Hend Khalid] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Syst, POB 84428, Riyadh 11671, Saudi Arabia.
   [Mostafa, Samih M.] South Valley Univ, Fac Comp & Informat, Comp Sci Dept, Qena 83523, Egypt.
RP Iqbal, J (corresponding author), Univ Engn & Appl Sci, Dept Comp Syst Engn, Swat 19201, Pakistan.
EM javed@ueas.edu.pk
CR Ahmad H, 2019, Arxiv, DOI arXiv:1901.04986
   Amid A., 2020, EE 290 2 HARDWARE MA
   Tran AT, 2021, NEUROCOMPUTING, V422, P245, DOI 10.1016/j.neucom.2020.10.014
   [Anonymous], 2013, ASIC LOW POWER PRIME
   [Anonymous], 2016, WACV
   Bannon P., 2019, P IEEE HOT CHIPS 31, P1
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Carver S, 2012, IEEE DES TEST COMPUT, V29, P62, DOI 10.1109/MDT.2012.2183574
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Del Barrio AA, 2019, IEEE T CIRCUITS-I, V66, P742, DOI 10.1109/TCSI.2018.2866172
   Ercegovac M.D., 2004, DIGITAL ARITHMETIC
   Farshchi F, 2019, 2019 2ND WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2 2019), P21, DOI 10.1109/EMC249363.2019.00012
   Genc H., 2021, P 58 ANN DES AUT C D
   Guo C, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218732
   Inayat K, 2022, IEEE T VLSI SYST, V30, P881, DOI 10.1109/TVLSI.2022.3170233
   Inayat K, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060652
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kai H., 1979, COMPUTER ARITHMETIC
   Lebaka M.R., 2020, P DESIGN VERIFICATIO
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Liu SL, 2022, IEEE T NEUR NET LEAR, V33, P3974, DOI 10.1109/TNNLS.2021.3055240
   Loukadakis M., 2018, P 11 INT WORKSH PROG
   Mei LY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P6, DOI [10.1109/aicas.2019.8771481, 10.1109/AICAS.2019.8771481]
   Moons B, 2017, DES AUT TEST EUROPE, P488, DOI 10.23919/DATE.2017.7927038
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Nayak A, 2020, DES AUT TEST EUROPE, P846, DOI 10.23919/DATE48585.2020.9116477
   Ryu S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317784
   Seshadri K, 2022, Arxiv, DOI arXiv:2102.10423
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Solangi US, 2021, IEEE ACCESS, V9, P96700, DOI 10.1109/ACCESS.2021.3094741
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Ullah I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218585
   Vila M.D.M., 2022, HDB ARTIFICIAL INTEL, P215
   Xin He, 2020, ICS '20: Proceedings of the 34th ACM International Conference on Supercomputing, DOI 10.1145/3392717.3392751
   Yin C, 2017, INT C PAR DISTRIB SY, P180, DOI 10.1109/ICPADS.2017.00034
   Yuzuguler A.C., 2022, ARXIV, DOI [10.1145/3572917, DOI 10.1145/3572917]
   Zhang S, 2021, ASIA S PACIF DES AUT, P229, DOI 10.1145/3394885.3431531
   Zhu S, 2022, IEEE INTERNET THINGS, V9, P7525, DOI 10.1109/JIOT.2022.3143722
NR 39
TC 0
Z9 0
U1 2
U2 2
PD APR 26
PY 2023
VL 23
IS 9
AR 4297
DI 10.3390/s23094297
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT J
AU Ozen, E
   Orailoglu, A
AF Ozen, Elbruz
   Orailoglu, Alex
TI Architecting Decentralization and Customizability in DNN Accelerators
   for Hardware Defect Adaptation
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article; Proceedings Paper
CT ACM/IEEE Int Conf on Hardware/Software Codesign and Syst Synthesis / Int
   Conf on Compilers, Architectures, and Synthesis for Embedded Syst / Int
   Conf on Embedded Software part of the Embedded Syst Week
CY OCT 08-15, 2021
CL ELECTR NETWORK
DE Hardware; Neural networks; Deep learning; Training; Reliability;
   Systolic arrays; Circuit faults; Deep learning hardware; fault
   tolerance; semiconductor defects; semiconductor yield improvement
ID FAULT TOLERANCE
AB The efficiency of machine intelligence techniques has improved noticeably in the embedded application domains thanks to the dedicated hardware accelerators for deep neural networks (DNNs). Despite the economic criticality of yield and reliability problems in advanced semiconductor nodes, these concerns have attracted limited attention in the context of embedded machine intelligence devices. The micro-architectural features of deep learning accelerators, when paired with the algorithmic characteristics of DNNs, unlock novel opportunities to tackle semiconductor reliability problems in embedded deep learning devices. While the fine-grained bypassing of the faulty processing elements reins the computational impact of hardware defects, a one-time training of DNNs with Hardware-Aware Dropout/Dropconnect techniques boosts model decentralization and facilitates accurate neural network inference in the degraded computational fabrics. Furthermore, on-device calibration methods can improve resilience even further without necessitating expensive defect compensation methods such as device-specific training. Our work confirms the potential for improving the yield, reliability, and operational lifetime of embedded machine intelligence devices through a highly practical co-design of DNNs and configurable hardware architectures.
C1 [Ozen, Elbruz; Orailoglu, Alex] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Ozen, E (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM elozen@eng.ucsd.edu; alex@cs.ucsd.edu
CR ABRAHAM JA, 1987, COMPUTER, V20, P65, DOI 10.1109/MC.1987.1663621
   Batra G., 2019, ARTIF INTELL
   Burel S., 2021, PROC IOLTS, P1
   Bushnell M., 2004, ESSENTIALS ELECT TES, V17
   Chaudhuri A, 2020, INT TEST CONF P, DOI 10.1109/ITC44778.2020.9325272
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen ZM, 2023, IEEE T PATTERN ANAL, V45, P6969, DOI 10.1109/TPAMI.2021.3063496
   Choi W, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317908
   Devlin J., 2018, PREPRINT
   Gebregiorgis A, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000110
   Genc Hasan, 2021, 2021 58th ACM/IEEE Design Automation Conference (DAC), P769, DOI 10.1109/DAC18074.2021.9586216
   Hanif MA, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0164
   Hari SKS, 2022, IEEE T DEPEND SECURE, V19, P2546, DOI 10.1109/TDSC.2021.3063083
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YZ, 2019, INT CONF ACOUST SPEE, P6381, DOI 10.1109/ICASSP.2019.8682336
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hochschild Peter H., 2021, P WORKSH HOT TOP OP, P9, DOI 10.1145/3458336.3465297
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Hubara I, 2016, ADV NEUR IN, V29
   ieee, INT ROADMAP DEVICES
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KIM JH, 1989, IEEE T COMPUT, V38, P515, DOI 10.1109/12.21144
   Koren I., 2020, FAULT TOLERANT SYSTE, DOI DOI 10.1016/C2018-0-02160-X
   Kundu S, 2021, IEEE T VLSI SYST, V29, P485, DOI 10.1109/TVLSI.2020.3048829
   Hoang LH, 2020, DES AUT TEST EUROPE, P1241, DOI 10.23919/DATE48585.2020.9116571
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Liu C, 2022, IEEE T COMPUT AID D, V41, P3400, DOI 10.1109/TCAD.2021.3124763
   Liu CF, 2017, DES AUT CON, DOI [10.1145/3061639.3062334, 10.1109/ICCSN.2017.8230067]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Meng FR, 2021, ASIA S PACIF DES AUT, P722, DOI 10.1145/3394885.3431519
   nytimes, TINY CHIPS BIG HEADA
   Ozen Elbruz, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P169, DOI 10.1109/ASP-DAC47756.2020.9045662
   Ozen E, 2023, IEEE DES TEST, V40, P59, DOI 10.1109/MDAT.2022.3156016
   Ozen E, 2023, IEEE T COMPUT AID D, V42, P1147, DOI 10.1109/TCAD.2022.3191561
   Ozen E, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3477007
   Ozen E, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415680
   Ozen E, 2020, J ELECTRON TEST, V36, P703, DOI 10.1007/s10836-020-05920-2
   Ozen E, 2020, IEEE T COMPUT AID D, V39, P3250, DOI 10.1109/TCAD.2020.3012209
   Ozen E, 2019, ASIAN TEST SYMPOSIUM, P7, DOI 10.1109/ATS47505.2019.000-8
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Sadi M, 2022, IEEE T COMPUT AID D, V41, P104, DOI 10.1109/TCAD.2021.3051841
   Sakai Y, 2019, IEEE J EM SEL TOP C, V9, P658, DOI 10.1109/JETCAS.2019.2952642
   Sakai Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P76, DOI [10.1109/aicas.2019.8771533, 10.1109/AICAS.2019.8771533]
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samajdar Ananda, 2018, ARXIV
   Schorn C, 2018, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE.2018.8342151
   semiengineering, AGING PROBLEMS 5NM B
   Sharma H, 2016, INT SYMP MICROARCH
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strojwas Andrzej J., 2019, 2019 Electron Devices Technology and Manufacturing Conference (EDTM), P179, DOI 10.1109/EDTM.2019.8731146
   Sze Vivienne, 2020, SYNTHESIS LECT COMPU, DOI DOI 10.2200/S01004ED1V01Y202004CAC050
   Wan L., 2013, P 30 INT C MACH LEAR, V28, P1058
   Yang XD, 2021, CAN J CHEM ENG, V99, pS616, DOI [10.13196/j.cims.2021.08.014, 10.1002/cjce.23958, 10.1109/ICCSI53130.2021.9736224]
   Yuan G, 2021, INT SYM QUAL ELECT, P135, DOI 10.1109/ISQED51717.2021.9424332
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang J, 2018, IEEE VLSI TEST SYMP
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
NR 61
TC 1
Z9 1
U1 1
U2 2
PD NOV
PY 2022
VL 41
IS 11
BP 3934
EP 3945
DI 10.1109/TCAD.2022.3197540
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Huang, HT
   Ni, LB
   Wang, KW
   Wang, YG
   Yu, H
AF Huang, Hantao
   Ni, Leibin
   Wang, Kanwen
   Wang, Yuangang
   Yu, Hao
TI A Highly Parallel and Energy Efficient Three-Dimensional Multilayer
   CMOS-RRAM Accelerator for Tensorized Neural Network
SO IEEE TRANSACTIONS ON NANOTECHNOLOGY
DT Article
DE RRAM computing; tensorized neural network (TNN); three-dimensional (3-D)
   accelerator
ID MACHINE; MEMORY
AB It is a grand challenge to develop highly parallel yet energy-efficient machine learning hardware accelerator. This paper introduces a three-dimensional (3-D) multilayer CMOS-RRAM accelerator for a tensorized neural network. Highly parallel matrix-vector multiplication can be performed with low power in the proposed 3-D multilayer CMOS-RRAM accelerator. The adoption of tensorization can significantly compress the weight matrix of a neural network using much fewer parameters. Simulation results using the benchmark MNIST show that the proposed accelerator has 1.283x speed-up, 4.276x energy-saving, and 9.339x area-saving compared to the 3-D CMOS-ASIC implementation; and 6.37x speed-up and 2612x energy-saving compared to 2-D CPU implementation. In addition, 14.85x model compression can be achieved by tensorization with acceptable accuracy loss.
C1 [Huang, Hantao; Ni, Leibin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
   [Yu, Hao] Southern Univ Sci & Technol, Shenzhen 518055, Peoples R China.
   [Wang, Kanwen; Wang, Yuangang] Huawei Technol Co Ltd, Data Ctr Technol Lab, Labs 2012, Hangzhou 310012, Zhejiang, Peoples R China.
RP Huang, HT (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
EM HHUANG013@E.NTU.EDU.SG; NILE0001@e.ntu.edu.sg; wangkanwen@huawei.com;
   wangyuangang@huawei.com; yuh3@sustc.edu.cn
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], BREAKTHR NONV MEM TE
   [Anonymous], 2013, INTERSPEECH, DOI DOI 10.21437/INTERSPEECH.2013-552
   [Anonymous], P DES AUT TEST EUR C
   [Anonymous], 2015, MORE MOORE TECHNOLOG
   [Anonymous], CORR
   [Anonymous], P IEEE S VLSI TECHN
   [Anonymous], 2015, PROC 20 ASIA S PACIF
   [Anonymous], 1986, CMUCS86126
   Bengio Y, 2006, ADV NEURAL INFORM PR, P19, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Chen K, 2012, DES AUT TEST EUROPE, P33
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cichocki A., 2014, CORR
   Erhan D., 2009, J MACHINE LEARNING R, V5, P153, DOI DOI 10.1145/3301282
   Fei W, 2012, IEEE T VLSI SYST, V20, P1012, DOI 10.1109/TVLSI.2011.2136443
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Hagan M.T., 1996, NEURAL NETWORK DESIG, V20
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Holtz S, 2012, SIAM J SCI COMPUT, V34, pA683, DOI 10.1137/100818893
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   LeCun Y., 2009, THEMNIST DATABASE HA
   Lichman M., 2013, UCI MACHINE LEARNING
   Müller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022
   Nakkiran P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1473
   Ni LB, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/2996192
   Novikov A., 2015, ADV NEURAL INFORM PR, P442, DOI DOI 10.5555/2969239.2969289
   Oseledets IV, 2012, SIAM J SCI COMPUT, V34, pA2718, DOI 10.1137/110833142
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Poremba M, 2015, DES AUT TEST EUROPE, P1543
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Wang YH, 2017, IEEE T BIOMED CIRC S, V11, P255, DOI 10.1109/TBCAS.2016.2597310
   Wang YH, 2015, IEEE T NANOTECHNOL, V14, P998, DOI 10.1109/TNANO.2015.2447531
   Wang YH, 2014, IEEE T VLSI SYST, V22, P957, DOI 10.1109/TVLSI.2013.2265754
   Wang Y, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION 2010, VOL 11, P1
   Yi-Chung Chen, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P367, DOI 10.1109/FPL.2012.6339206
   Young Yang Liauw, 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P406, DOI 10.1109/ISSCC.2012.6177067
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 40
TC 24
Z9 28
U1 2
U2 30
PD JUL
PY 2018
VL 17
IS 4
BP 645
EP 656
DI 10.1109/TNANO.2017.2732698
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Materials Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT C
AU Rombouts, MPG
   Calabretta, N
AF Rombouts, M. P. G.
   Calabretta, N.
GP IEEE
TI On the Performance of a Fast Optically Switched Network for
   Machine-Learning Accelerator Clusters
SO 2023 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION, OFC
DT Proceedings Paper
CT Optical Fiber Communications Conference and Exhibition (OFC)
CY MAR 05-09, 2023
CL San Diego, CA
AB We investigate the viability of optically switched network for ML accelerator clusters and compare it to a leaf-spine network with 256/1024 GPUs. Results show almost ideal throughput, sub-mu s latency and zero packet-loss for (i)0.6 traffic-load. (c) 2022 The Author(s)
C1 [Rombouts, M. P. G.; Calabretta, N.] Eindhoven Univ Technol, POB 513, NL-5600 MB Eindhoven, Netherlands.
RP Rombouts, MPG (corresponding author), Eindhoven Univ Technol, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM m.p.g.rombouts@tue.nl
CR [Anonymous], OMNET DISCRETE EVENT
   [Anonymous], 2022, NVIDIA H100 TENSOR C
   Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]
   Fedus W., 2022, SWITCH TRANSFORMERS, P39
   Hosseini K., 2021, 8 TBPS COPACKAGED FP, P3
   Li A, 2020, IEEE T PARALL DISTR, V31, P94, DOI 10.1109/TPDS.2019.2928289
   Ren YH, 2019, PROCEEDINGS OF 2019 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2019), P103, DOI 10.1109/PMBS49563.2019.00017
   Sevilla J, 2022, Arxiv, DOI [arXiv:2202.05924, 10.48550/ARXIV.2202.05924, DOI 10.48550/ARXIV.2202.05924]
   Shalf J, 2019, 2019 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC)
   Wheeler B, 2019, MICROPROCESSOR REPOR
   Yan FL, 2017, J OPT COMMUN NETW, V9, P291, DOI 10.1364/JOCN.9.000291
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Engineering, Electrical & Electronic; Optics; Telecommunications
DA 2023-11-11
ER

PT C
AU Seshadri, K
   Akin, B
   Laudon, J
   Narayanaswami, R
   Yazdanbakhsh, A
AF Seshadri, Kiran
   Akin, Berkin
   Laudon, James
   Narayanaswami, Ravi
   Yazdanbakhsh, Amir
GP IEEE Comp Soc
TI An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON WORKLOAD CHARACTERIZATION (IISWC
   2022)
SE International Symposium on Workload Characterization Proceedings
DT Proceedings Paper
CT IEEE International Symposium on Workload Characterization (IISWC)
CY NOV 06-08, 2022
CL Austin, TX
AB Edge TPUs are a domain of accelerators for low-power, edge devices and are widely used in various Google products such as Coral and Pixel devices. In this paper, we first discuss the major microarchitectural details of Edge TPUs. Then, we extensively evaluate three classes of Edge TPUs, covering different computing ecosystems, across 423K unique convolutional neural networks. Building upon this extensive study, we discuss critical and interpretable microarchitectural insights about the studied classes of Edge TPUs. Mainly, we discuss how Edge TPU accelerators perform across convolutional neural networks with different structures. Finally, we present a learned machine learning model with high accuracy to estimate the major performance metrics of accelerators. These learned models enable significantly faster (in the order of milliseconds) evaluations of accelerators as an alternative to time-consuming cycle-accurate simulators and establish an exciting opportunity for rapid hardware/software co-design.
C1 [Seshadri, Kiran; Akin, Berkin] Google, Mountain View, CA 94043 USA.
   [Narayanaswami, Ravi] Cruise, San Francisco, CA USA.
   [Laudon, James; Yazdanbakhsh, Amir] Google Res, Brain Team, Mountain View, CA USA.
RP Seshadri, K (corresponding author), Google, Mountain View, CA 94043 USA.
EM kiranks@utexas.edu; bakin@google.com; jlaudon@google.com;
   ravi.narayanaswami@getcruise.com; ayazdan@google.com
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Adve VS, 2004, ACM T COMPUT SYST, V22, P94, DOI 10.1145/966785.966788
   [Anonymous], 2021, EETIME
   [Anonymous], 2001, LNCS, DOI DOI 10.1007/3-540-45449-7_32
   [Anonymous], 2021, FACEBOOK
   Apple, 2021, M1 PROC
   Ba J. L., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1607.06450
   Biagio A. D., 2019, LLVM MACHINE CODE AN
   Blanco V., 2004, PARALLEL COMPUT
   Chang Jianlong, 2019, ADV NEURAL INFORM PR
   Chen XE, 2009, INT S HIGH PERF COMP, P329, DOI 10.1109/HPCA.2009.4798270
   Cheng HP, 2020, Arxiv, DOI arXiv:2007.04452
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cloud.google, EDGE TP
   Coral.ai, RUN INFERENCE EDGE
   Coral.ai, EDGE TPU COMPILE
   coronavirus, US
   DeepMind, 2021, SONNET
   Dubach C., 2007, CF
   Fahringer T., 1993, ICS
   Google, 2021, ML MOB EDG DEV TENSO
   googleblog.com, INTRO NEXT GENERATIO
   Hamilton WL., 2017, ADV NEURAL INFORM PR, V2017, P1025, DOI DOI 10.48550/ARXIV.1706.02216
   Hartleb F., 1992, P 6 INT C MODELLING
   Hegde K, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P943, DOI 10.1145/3445814.3446762
   Hu Hanzhang, 2019, NEURIPS
   Huang L., 2010, ADV NEURAL INFORM PR
   I. Corporation, 2019, INT ARCH COD AN
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaufman S., 2021, MLSYS
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kumar Ananya, 2022, ICLR
   Laukemann J, 2019, PROCEEDINGS OF 2019 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2019), P1, DOI 10.1109/PMBS49563.2019.00006
   Laukemann J, 2018, PROCEEDINGS OF 2018 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2018), P121, DOI [10.1109/PMBS.2018.00016, 10.1109/PMBS.2018.8641578]
   Li X., 2007, SCI COMPUT PROGRAM
   Mendis C, 2019, PR MACH LEARN RES, V97
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]
   Park C. Y., 1993, REAL-TIME SYST
   Patel A, 2011, DES AUT CON, P1050
   Rugina R, 1998, FIRST MERGED INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM & SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, P654, DOI 10.1109/IPPS.1998.669996
   Sanchez D., 2013, ISCA
   Seshia SA, 2012, ACM T EMBED COMPUT S, V11, DOI 10.1145/2331147.2331165
   Seshia SA, 2011, LECT NOTES COMPUT SC, V6605, P388, DOI 10.1007/978-3-642-19835-9_34
   Shaw Albert, 2019, NEURIPS
   Shi Z., 2019, ARXIV
   Sykora O., 2022, IISWC
   Taha TM, 2008, IEEE T COMPUT, V57, P389, DOI 10.1109/TC.2007.70817
   Battaglia PW, 2018, Arxiv, DOI [arXiv:1806.01261, DOI 10.48550/ARXIV.1806.01261]
   Wei Wen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P660, DOI 10.1007/978-3-030-58526-6_39
   White C, 2020, Arxiv, DOI [arXiv:1910.11858, DOI 10.1609/AAAI.V35I12.17233]
   Yazdanbakhsh A, 2021, Arxiv, DOI arXiv:2102.01723
   Ying C., 2019, ICML
   Zhou Y., 2022, P MACHINE LEARNING S, V4, P141
NR 55
TC 2
Z9 2
U1 1
U2 1
PY 2022
BP 79
EP 91
DI 10.1109/IISWC55918.2022.00017
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kang, JY
   Zhou, MX
   Bhansali, A
   Xu, WH
   Thomas, A
   Rosing, T
AF Kang, Jaeyoung
   Zhou, Minxuan
   Bhansali, Abhinav
   Xu, Weihong
   Thomas, Anthony
   Rosing, Tajana
GP IEEE
TI RelHD: A Graph-based Learning on FeFET with Hyperdimensional Computing
SO 2022 IEEE 40TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2022)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT IEEE 40th International Conference on Computer Design (ICCD)
CY OCT 23-26, 2022
CL Olympic Valley, CA
DE Hyperdimensional Computing; Graph-based Machine Learning;
   Processing-in-memory; FeFET
AB Advances in graph neural network (GNN)-based algorithms enable machine learning on relational data. GNNs are computationally demanding since they rely upon back-propagation over the graph data that has sparse and irregular characteristics. In this paper, we propose a lightweight graph-based machine learning framework based on hyperdimensional computing (HDC) called RelHD. It maps the features of each node into a high-dimensional space and embeds relationships between nodes. Using lightweight HDC operations, RelHD enables both training and inference on graph data without back-propagation. Furthermore, we design a scalable processing in-memory (PIM) architecture based on the emerging FeFET technology to accelerate the proposed algorithm. Our strategy optimizes data allocation and operation scheduling that maximizes the accelerator performance by addressing the sparseness and irregularity of the graph. Experimental results show that RelHD offers comparable accuracy to the popular GNN-based algorithms while being up to 32x faster on GPU. Also, our FeFET-based accelerator achieves 33x of speedup and 59287x energy efficiency improvement on average over the GPU. It is 10x faster and 986x more energy efficient on average compared to the state-of-the-art in-memory processing-based GNN accelerator.
C1 [Kang, Jaeyoung; Zhou, Minxuan; Bhansali, Abhinav; Xu, Weihong; Thomas, Anthony; Rosing, Tajana] Univ Calif San Diego, San Diego, CA 92103 USA.
RP Kang, JY (corresponding author), Univ Calif San Diego, San Diego, CA 92103 USA.
EM j5kang@ucsd.edu; miz087@ucsd.edu; abhansali@ucsd.edu; wexu@ucsd.edu;
   ahthomas@ucsd.edu; tajana@ucsd.edu
NR 0
TC 0
Z9 0
U1 1
U2 2
PY 2022
BP 553
EP 560
DI 10.1109/ICCD56317.2022.00087
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Mittal, S
   Vaishay, S
AF Mittal, Sparsh
   Vaishay, Shraiysh
TI A survey of techniques for optimizing deep learning on GPUs
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Review
DE Review; GPU; Hardware architecture for deep learning; Accelerator;
   Distributed training; Parameter server; Allreduce; Pruning; Tiling
AB The rise of deep-learning (DL) has been fuelled by the improvements in accelerators. Due to its unique features, the GPU continues to remain the most widely used accelerator for DL applications. In this paper, we present a survey of architecture and system-level techniques for optimizing DL applications on GPUs. We review techniques for both inference and training and for both single GPU and distributed system with multiple GPUs. We bring out the similarities and differences of different works and highlight their key attributes. This survey will be useful for both novice and experts in the field of machine learning, processor architecture and high-performance computing.
C1 [Mittal, Sparsh; Vaishay, Shraiysh] IIT Hyderabad, Dept Comp Sci & Engn, Hyderabad, India.
RP Mittal, S (corresponding author), IIT Hyderabad, Dept Comp Sci & Engn, Hyderabad, India.
EM sparsh@iith.ac.in; cs17btech11050@iith.ac.in
CR [Anonymous], ARXIV180210280V1
   [Anonymous], ACM COMPUTING SURVEY
   [Anonymous], ARXIV14100759V1
   [Anonymous], ARXIV190106773V1
   [Anonymous], NVIDIAS GOT CUNNING
   [Anonymous], PERFORMANCE EVALUATI
   [Anonymous], P INT C SUP
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], ARXIV180406826V1
   [Anonymous], ARXIV14127580V1
   [Anonymous], 2017, P MACH LEARN HPC ENV
   [Anonymous], P 11 EUR C COMP SYST
   [Anonymous], ARXIV171104325V1
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], 2017, P INT C HIGH PERF CO
   [Anonymous], MASSIVELY DISTRIBUTE
   [Anonymous], ARXIV190110008V1
   [Anonymous], 2018, J HARDW SYST SECUR
   [Anonymous], ARXIV190101965V1
   [Anonymous], GPU POWERING FUTURE
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-41321-1_2
   [Anonymous], ARXIV150106633V1
   [Anonymous], TECHNICAL REPORT
   [Anonymous], ARXIV190206855V1
   [Anonymous], AI CHIPS BIG DATA MA
   [Anonymous], ARXIV180711205V1
   [Anonymous], ARXIV180209941V1
   [Anonymous], ARXIV151206216V1
   [Anonymous], 2016, P 49 ANN IEEEACM INT
   [Anonymous], HIGH PERF COMP S
   [Anonymous], INT C SUP
   [Anonymous], 2017, INT WORKSH PERF MOD
   [Anonymous], ARXIV1901058030V1
   [Anonymous], ARXIV180705358V1
   [Anonymous], USENIX ATC
   [Anonymous], 2016, ACM COMPUT SURV, DOI DOI 10.1145/2893356
   [Anonymous], 2016, IEEE T PARALLEL DIST
   [Anonymous], 2016, P INT C HIGH PERFORM
   [Anonymous], ARXIV E PRINTS
   [Anonymous], ARXIV190401691V1
   [Anonymous], 2019, M&SOM-MANUF SERV OP, DOI DOI 10.1287/msom.2017.0667
   [Anonymous], ARXIV190300045V1
   Awan AA, 2018, INT C HIGH PERFORM, P143, DOI 10.1109/HiPC.2018.00024
   Awan AA, 2017, ACM SIGPLAN NOTICES, V52, P193, DOI [10.1145/3155284.3018769, 10.1145/3018743.3018769]
   Campos V, 2017, IEEE ACM INT SYMP, P677, DOI 10.1109/CCGRID.2017.110
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen XM, 2018, DES AUT TEST EUROPE, P13, DOI 10.23919/DATE.2018.8341972
   Dong S, 2018, PROCEEDINGS OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '18), P96, DOI 10.1145/3184407.3184423
   Harlap A., 2018, ARXIV180603377
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Hill P, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P786, DOI 10.1145/3123939.3123970
   Holmes C., 2019, P 14 EUROSYS C MAR, P41
   Hu ZH, 2017, CHINA PERSPECTIVE, P110
   Iandola FN, 2016, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR.2016.284
   Jin T, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P835, DOI 10.1145/3297858.3304038
   Le T, 2018, 2018 IEEE 3RD INTERNATIONAL VERIFICATION AND SECURITY WORKSHOP (IVSW), P56, DOI 10.1109/IVSW.2018.8494891
   Li C, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P633, DOI 10.1109/SC.2016.53
   Li SG, 2015, IEEE I C EMBED SOFTW, P316, DOI 10.1109/HPCC-CSS-ICESS.2015.94
   Li XQ, 2016, PROC INT CONF PARAL, P67, DOI 10.1109/ICPP.2016.15
   Li XH, 2019, PROCEEDINGS OF THE 24TH SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '19), P229, DOI 10.1145/3293883.3295734
   Lu XY, 2018, IEEE T MULTI-SCALE C, V4, P635, DOI 10.1109/TMSCS.2018.2845886
   Meng C, 2017, P ML SYST WORKSH NIP
   Mittal S, 2019, J SYST ARCHITECT, V98, P135, DOI 10.1016/j.sysarc.2019.07.006
   Mittal S, 2019, J SYST ARCHITECT, V97, P428, DOI 10.1016/j.sysarc.2019.01.011
   Mittal S, 2019, J SYST ARCHITECT, V97, P373, DOI 10.1016/j.sysarc.2018.11.001
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2636342
   Oyama Y, 2018, IEEE INT C CL COMP, P402, DOI 10.1109/CLUSTER.2018.00058
   Park H, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2968476
   Shen MH, 2018, PR IEEE COMP DESIGN, P595, DOI 10.1109/ICCD.2018.00095
   Song MC, 2017, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2017.52
   Song MC, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P315, DOI 10.1145/2967938.2967944
   Umesh S, 2019, J SYST ARCHITECT, V97, P349, DOI 10.1016/j.sysarc.2018.11.005
   van Werkhovena B, 2014, FUTURE GENER COMP SY, V30, P14, DOI 10.1016/j.future.2013.09.003
   Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491
   Xu RG, 2018, PROCEEDINGS OF 2018 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2018), P23, DOI [10.1109/PMBS.2018.00006, 10.1109/PMBS.2018.8641600]
   You R, 2018, ASIAN AND PACIFIC COASTS 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON APAC 2017, P1
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhu MH, 2018, IEEE T VLSI SYST, V26, P831, DOI 10.1109/TVLSI.2018.2791442
NR 79
TC 113
Z9 115
U1 5
U2 46
PD OCT
PY 2019
VL 99
AR 101635
DI 10.1016/j.sysarc.2019.101635
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Wang, C
   Li, X
   Yu, Q
   Wang, AL
   Hung, P
   Zhou, XH
AF Wang, Chao
   Li, Xi
   Yu, Qi
   Wang, Aili
   Hung, Patrick
   Zhou, Xuehai
BE ReiffMarganiec, S
TI SOLAR: Services-oriented Learning Architectures
SO 2016 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS)
DT Proceedings Paper
CT IEEE 23rd International Conference on Web Services (ICWS)
CY JUN 27-JUL 02, 2016
CL San Francisco, CA
DE Services-oriented Architecture; Deep Learning; neural network;
   accelerator
AB Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data sizes have posed significant challenge to construct a flexible and high efficient implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA based approaches. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.
C1 [Wang, Chao; Li, Xi; Yu, Qi; Wang, Aili; Zhou, Xuehai] Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
   [Hung, Patrick] Univ Ontario Inst Technol, Business & Informat Technol, Oshawa, ON, Canada.
RP Wang, C (corresponding author), Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
EM cswang@ustc.edu.cn; llxx@ustc.edu.cn; yuiq@mail.ustc.edu.cn;
   wangal@ustc.edu.cn; patrick.hung@uoit.ca; xhzhou@ustc.edu.cn
CR Aili Wang, 2013, 2013 IEEE Ninth World Congress on Services (SERVICES), P67, DOI 10.1109/SERVICES.2013.26
   Chao Wang, 2012, 2012 IEEE International Conference on Services Computing (SCC), P668, DOI 10.1109/SCC.2012.72
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Wang C., IEEE T SERVICES COMP
   Wang C, 2015, IEEE ACM T COMPUT BI, V12, P166, DOI 10.1109/TCBB.2014.2351800
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang J., 2011, SCC
NR 9
TC 8
Z9 8
U1 0
U2 3
PY 2016
BP 662
EP 665
DI 10.1109/ICWS.2016.91
WC Computer Science, Interdisciplinary Applications; Engineering,
   Multidisciplinary
DA 2023-11-11
ER

PT C
AU Wang, F
   Chen, GY
   Zhang, WF
   Rompf, T
AF Wang, Fei
   Chen, Guoyang
   Zhang, Weifeng
   Rompf, Tiark
BE Baru, C
   Huan, J
   Khan, L
   Hu, XH
   Ak, R
   Tian, Y
   Barga, R
   Zaniolo, C
   Lee, K
   Ye, YF
TI Parallel Training via Computation Graph Transformation
SO 2019 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
DT Proceedings Paper
CT IEEE International Conference on Big Data (Big Data)
CY DEC 09-12, 2019
CL Los Angeles, CA
DE Parallel Training; Graph Transformation; Machine Learning Frameworks
AB Parallel training can speed up the convergence of machine learning models via splitting the workload into multiple accelerators by the wide array of possible parallel paradigms (e.g., data parallelism. model parallelism, attribute parallelism, and pipelining parallelism). However, most machine learning frameworks lack sufficient support for these flexible and sometimes complex parallel training schemes (e.g., TensorFlow does not provide convenient APIs for any paradigm other than data parallelism), and the engineering effort to support all parallelisms in all machine learning frameworks seems gigantic.
   In this paper, we demonstrate that most parallel training designs/paradigms can be abstracted as a computation graph transformation problem, so that they are realized via computation graph duplication, splitting, augmentation, and assignment to different accelerators, which are then connected by send/recv channels for tensor communications. Furthermore, conducting such computation graph transformations in a portable IR allows the engineering efforts of parallel training to be widely applied across machine learning frameworks.
   We propose an extensible parallel training search space which describes parallel training schemes in a declarative fashion. We then implement a computation graph transformation compiler that can instantiate the parallel schemes into explicit execution plans, which are readily executable on modern machine learning frameworks (such as TensorFlow). We maximize code reuse by handling parallel configurations and computation graph transformations in extended ONNX, which can be ported to machine learning frameworks by adapting their existing ONNX frontend/backend implementations. Our design reflects a few good themes in machine learning frameworks, including code reuse via powerful IR (as in MLIR) and separation of declaration and realization (as in Halide/TVM).
C1 [Wang, Fei; Rompf, Tiark] Purdue Univ, W Lafayette, IN 47907 USA.
   [Chen, Guoyang; Zhang, Weifeng] Alibaba Grp, Sunnyvale, CA USA.
RP Wang, F (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM wang603@purdue.edu; g.chen@alibaba-inc.com; weifeng.z@alibaba-inc.com;
   tiark@purdue.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2016, XGBOOST SCALABLE TRE
   [Anonymous], 2014, CORR
   [Anonymous], 2018, CORR
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Bauer Michael, 2012, P INT C HIGH PERFORM, P66
   Chen T., 2015, MXNET FLEXIBLE EFFIC
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Huang Y., 2018, CORR
   Jayarajan A., 2019, CORR
   Jia ZH, 2018, PR MACH LEARN RES, V80
   Kingma D. P., 2015, ICLR POSTER
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Paszke Adam, 2017, AUTOMATIC DIFFERENTI
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Roesch J., 2018, CORR
   Wang F., 2018, CORR
NR 18
TC 1
Z9 1
U1 0
U2 1
PY 2019
BP 3430
EP 3439
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Kaiser, J
   Stein, O
   Eichler, A
AF Kaiser, Jan
   Stein, Oliver
   Eichler, Annika
BE Chaudhuri, K
   Jegelka, S
   Song, L
   Szepesvari, C
   Niu, G
   Sabato, S
TI Learning-based Optimisation of Particle Accelerators Under Partial
   ObservabilityWithout Real-World Training
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 162
SE Proceedings of Machine Learning Research
DT Proceedings Paper
CT 38th International Conference on Machine Learning (ICML)
CY JUL 17-23, 2022
CL Baltimore, MD
AB In recent work, it has been shown that reinforcement learning (RL) is capable of solving a variety of problems at sometimes super-human performance levels. But despite continued advances in the field, applying RL to complex real-world control and optimisation problems has proven difficult. In this contribution, we demonstrate how to successfully apply RL to the optimisation of a highly complex real-world machine - specifically a linear particle accelerator - in an only partially observable setting and without requiring training on the real machine. Our method outperforms conventional optimisation algorithms in both the achieved result and time taken as well as already achieving close to human-level performance. We expect that such automation of machine optimisation will push the limits of operability, increase machine availability and lead to a paradigm shift in how such machines are operated, ultimately facilitating advances in a variety of fields, such as science and medicine among many others.
C1 [Kaiser, Jan; Stein, Oliver; Eichler, Annika] Deutsch Elektronen Synchrotron DESY, Notkestr 85, D-22607 Hamburg, Germany.
RP Kaiser, J (corresponding author), Deutsch Elektronen Synchrotron DESY, Notkestr 85, D-22607 Hamburg, Germany.
EM jan.kaiser@desy.de
CR Akkaya I, 2019, ARXIV191007113
   Badia AP, 2020, PR MACH LEARN RES, V119
   Biewald L., 2020, EXPT TRACKING WEIGHT
   Brockman G., 2016, ARXIV160601540, P1
   Bruchon N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050781
   Degrave J, 2022, NATURE, V602, P414, DOI 10.1038/s41586-021-04301-9
   Dulac-Arnold G., 2019, P 36 INT C MACHINE L
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Eichler A., 2021, P 12 INT PARTICLE AC
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Head Tim, 2021, Zenodo, DOI 10.5281/ZENODO.1157319
   Irpan A, 2018, DEEP REINFORCEMENT L
   Ivanov A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.074601
   John J. St., 2021, PHYS REV ACCEL BEAMS, V24
   Kain V, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.124801
   Kirschner J, 2019, PR MACH LEARN RES, V97
   Lillicrap Timothy P., 2015, 4 INT C LEARNING REP
   McIntire M., 2016, P 7 INT PARTICLE ACC
   Mockus J., 1982, System Modeling and Optimization. Proceedings of the 10th IFIP Conference, P473, DOI 10.1007/BFb0006170
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Pang X., 2020, WORKSHOP MACHINE LEA
   Panofski Eva, 2021, Instruments, V5, DOI 10.3390/instruments5030028
   POWELL MJD, 1993, MATH APPL, V275, P51
   Raffin A., 2019, STABLE BASELINES3
   Schulman J., 2017, ARXIV, DOI DOI 10.1016/J.JDEVECO.2016.04.001
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Stein O., 2022, P 13 INT PARTICLE AC
   Tobin J, 2017, Arxiv, DOI [arXiv:1703.06907, DOI 10.48550/ARXIV.1703.06907]
   Virtanen P, 2020, NAT METHODS, V17, P352, DOI 10.1038/s41592-020-0772-5
   Zagorodnov I., 2016, P 7 INT PARTICLE ACC
NR 32
TC 1
Z9 1
U1 3
U2 3
PY 2022
BP 10575
EP 10585
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Forkel, B
   Kallwies, J
   Wuensche, HJ
AF Forkel, Bianca
   Kallwies, Jan
   Wuensche, Hans-Joachim
GP IEEE
TI Efficient On-chip Acceleration of Machine Learning Models for Detection
   of RF Signal Modulation
SO 2021 32ND IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV)
SE IEEE Intelligent Vehicles Symposium
DT Proceedings Paper
CT 32nd IEEE Intelligent Vehicles Symposium (IV)
CY JUL 11-17, 2021
CL ELECTR NETWORK
DE radio frequency; machine learning; convolution neural network (CNN);
   quantization; accelerator
ID RADIO
AB This paper presents a design methodology for efficient on-chip acceleration of deep neural network (DNN) for classification of signal modulation in Radio Frequency signals. A low complexity DNN model with ternary weights is developed to reduce computational demand. A digital chip architecture with complex multiply-and-accumulate (MAC) engines are presented to accelerate the DNN model. Simulation results in 28nm CMOS show that the low-complexity DNN model coupled with the on-chip accelerator increases allowable instantaneous bandwidth of the RF signals with minimal impact on the classification accuracy.
C1 [Forkel, Bianca; Kallwies, Jan; Wuensche, Hans-Joachim] Georgia Inst Technol, Atlanta, GA 30332 USA.
RP Forkel, B (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM jwoo66@gatech.edu; kjung62@gatech.edu; saibal@ece.gatech.edu
CR Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380
   Kulin M, 2018, IEEE ACCESS, V6, P18484, DOI 10.1109/ACCESS.2018.2818794
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   O'Shea TJ, 2016, COMM COM INF SC, V629, P213, DOI 10.1007/978-3-319-44188-7_16
   O'Shea TJ, 2018, IEEE J-STSP, V12, P168, DOI 10.1109/JSTSP.2018.2797022
   OShea T.J., 2016, P GNU RAD C, V1
   Shi Y, 2019, IEEE INT SYMP DYNAM, P207, DOI [10.1109/dyspan.2019.8935684, 10.1109/jurse.2019.8808986]
   Tang ZL, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7070122
   Tridgell S, 2020, IEEE SYM PARA DISTR, P82, DOI 10.1109/IPDPSW50202.2020.00021
   West N.E., 2017, P IEEE INT S DYN SPE, P1, DOI [DOI 10.1109/DYSPAN.2017.7920754, 10.1109/DySPAN.2017.7920754]
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 74
EP +
DI 10.1109/IV48863.2021.9575141
WC Computer Science, Artificial Intelligence; Transportation Science &
   Technology
DA 2023-11-11
ER

PT C
AU Wyatt, MR
   Yamamoto, V
   Tosi, Z
   Karlin, I
   Van Essen, B
AF Wyatt, Michael R., II
   Yamamoto, Valen
   Tosi, Zoe
   Karlin, Ian
   Van Essen, Brian
GP IEEE Comp Soc
TI Is Disaggregation possible for HPC Cognitive Simulation?
SO PROCEEDINGS OF THE WORKSHOP ON MACHINE LEARNING IN HIGH PERFORMANCE
   COMPUTING ENVIRONMENTS (MLHPC 2021)
DT Proceedings Paper
CT 7th IEEE/ACM Workshop on Machine Learning in High Performance Computing
   Environments (MLHPC)
CY NOV 14-19, 2021
CL St Louis, MO
DE deep learning; cognitive simulation; surrogate models; accelerator
   performance
AB Cognitive simulation (CogSim) is an important and emerging workflow for HPC scientific exploration and scientific machine learning (SciML). One challenging workload for CogSim is the replacement of one component in a complex physical simulation with a fast, learned, surrogate model that is "inside" of the computational loop. The execution of this in-the-loop inference is particularly challenging because it requires frequent inference across multiple possible target models, can be on the simulation's critical path (latency bound), is subject to requests from multiple MPI ranks, and typically contains a small number of samples per request. In this paper we explore the use of large, dedicated Deep Learning / AI accelerators that are disaggregated from compute nodes for this CogSim workload. We compare the trade-offs of using these accelerators versus the node-local GPU accelerators on leadership-class HPC systems.
C1 [Wyatt, Michael R., II; Yamamoto, Valen; Tosi, Zoe; Van Essen, Brian] Lawrence Livermore Natl Lab, Tenter Appl Sci Comp, Livermore, CA 94550 USA.
   [Karlin, Ian] Intel Corp, Santa Clara, CA 95051 USA.
RP Wyatt, MR (corresponding author), Lawrence Livermore Natl Lab, Tenter Appl Sci Comp, Livermore, CA 94550 USA.
EM wyatt5@llnl.gov; yamamoto6@llnl.gov; tosi1@llnl.gov;
   ian.karlin@intel.com; vanessen1@llnl.gov
CR Anirudh R, 2020, P NATL ACAD SCI USA, V117, P9741, DOI 10.1073/pnas.1916634117
   Dong S, 2018, PROCEEDINGS OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '18), P96, DOI 10.1145/3184407.3184423
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Gregg C, 2011, INT SYM PERFORM ANAL, P134, DOI 10.1109/ISPASS.2011.5762730
   Holmes C, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303949
   Humbird KD, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0041907
   Kluth G, 2020, PHYS PLASMAS, V27, DOI 10.1063/5.0006784
   Kondratyuk N, 2021, INT J HIGH PERFORM C, V35, P312, DOI 10.1177/10943420211008288
   Langer SH, 2015, LECT NOTES COMPUT SC, V8969, P173, DOI 10.1007/978-3-319-17353-5_15
   Marinak MM, 1996, PHYS PLASMAS, V3, P2070, DOI 10.1063/1.872004
   Mittal S, 2019, J SYST ARCHITECT, V99, DOI 10.1016/j.sysarc.2019.101635
   Paszke A, 2019, ADV NEUR IN, V32
   Sun LN, 2020, COMPUT METHOD APPL M, V361, DOI 10.1016/j.cma.2019.112732
   Vanholder H., 2016, EFFICIENT INFERENCE
   Xu RG, 2018, PROCEEDINGS OF 2018 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2018), P23, DOI [10.1109/PMBS.2018.00006, 10.1109/PMBS.2018.8641600]
   Zlateski A, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P854, DOI 10.1109/SC.2016.72
NR 16
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 94
EP 105
DI 10.1109/MLHPC54614.2021.00014
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Woo, J
   Jung, K
   Mukhopadhyay, S
AF Woo, Jongseok
   Jung, Kuchul
   Mukhopadhyay, Saibal
GP IEEE
TI Efficient On-chip Acceleration of Machine Learning Models for Detection
   of RF Signal Modulation
SO 2021 IEEE MTT-S INTERNATIONAL MICROWAVE SYMPOSIUM (IMS)
SE IEEE MTT-S International Microwave Symposium
DT Proceedings Paper
CT IEEE MTT-S International Microwave Symposium (IMS)
CY JUN 07-25, 2021
CL ELECTR NETWORK
DE radio frequency; machine learning; convolution neural network (CNN);
   quantization; accelerator
ID RADIO
AB This paper presents a design methodology for efficient on-chip acceleration of deep neural network (DNN) for classification of signal modulation in Radio Frequency signals. A low complexity DNN model with ternary weights is developed to reduce computational demand. A digital chip architecture with complex multiply-and-accumulate (MAC) engines are presented to accelerate the DNN model. Simulation results in 28nm CMOS show that the low-complexity DNN model coupled with the on-chip accelerator increases allowable instantaneous bandwidth of the RF signals with minimal impact on the classification accuracy.
C1 [Woo, Jongseok; Jung, Kuchul; Mukhopadhyay, Saibal] Georgia Inst Technol, Atlanta, GA 30332 USA.
RP Woo, J (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM jwoo66@gatech.edu; kjung62@gatech.edu; saibal@ece.gatech.edu
CR Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380
   Kulin M., 2018, IEEE ACCESS
   Li FF, 2016, Arxiv, DOI arXiv:1605.04711
   O'Shea TJ, 2016, COMM COM INF SC, V629, P213, DOI 10.1007/978-3-319-44188-7_16
   O'Shea TJ, 2018, IEEE J-STSP, V12, P168, DOI 10.1109/JSTSP.2018.2797022
   Oshea T. J., 2016, P GNU RADIO C, V1, P19
   Shi Y, 2019, IEEE INT SYMP DYNAM, P207, DOI [10.1109/dyspan.2019.8935684, 10.1109/jurse.2019.8808986]
   Tang ZL, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7070122
   Tridgell S, 2020, IEEE SYM PARA DISTR, P82, DOI 10.1109/IPDPSW50202.2020.00021
   West N.E., 2017, P IEEE INT S DYN SPE, P1, DOI [DOI 10.1109/DYSPAN.2017.7920754, 10.1109/DySPAN.2017.7920754]
NR 10
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 74
EP 77
DI 10.1109/IMS19712.2021.9574932
WC Engineering, Electrical & Electronic; Optics; Physics, Applied;
   Telecommunications
DA 2023-11-11
ER

PT C
AU Zeng, ZQ
   Sapatnekar, SS
AF Zeng, Ziqing
   Sapatnekar, Sachin S.
BE IEEE
TI Energy-efficient Hardware Acceleration of Shallow Machine Learning
   Applications
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
AB ML accelerators have largely focused on building general platforms for deep neural networks (DNNs), but less so on shallow machine learning (SML) algorithms. This paper proposes Axiline, a compact, configurable, template-based generator for SML hardware acceleration. Axiline identifies computational kernels as templates that are common to these algorithms and builds a pipelined accelerator for efficient execution. The dataflow graphs of individual ML instances, with different data dimensions, are mapped to the pipeline stages and then optimized by customized algorithms. The approach generates energy-efficient hardware for training and inference of various ML algorithms, as demonstrated with post-layout FPGA and ASIC results.
C1 [Zeng, Ziqing; Sapatnekar, Sachin S.] Univ Minnesota, Minneapolis, MN 55455 USA.
RP Zeng, ZQ (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
CR Afifi S, 2020, NEURAL COMPUT APPL, V32, P1777, DOI 10.1007/s00521-018-3656-1
   Ago Yuki, 2013, 2013 IEEE 7th International Symposium on Embedded Multicore/Manycore System-on-Chip (MCSoC), P91, DOI 10.1109/MCSoC.2013.30
   Ahmad MW, 2017, ENERG BUILDINGS, V147, P77, DOI 10.1016/j.enbuild.2017.04.038
   [Anonymous], 2021, TABLA
   Ayupov A, 2018, IEEE T COMPUT AID D, V37, P420, DOI 10.1109/TCAD.2017.2706562
   Corazao MR, 1996, IEEE T COMPUT AID D, V15, P877, DOI 10.1109/43.511568
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Elgawi Osman, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P164, DOI 10.1109/ISVLSI.2019.00038
   Esmaeilzadeh H, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643449
   Feng X., 2012, P 2012 ACM SIGMOD IN, P325, DOI 10.1145/2213836.2213874
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Huang SJ, 2018, CANCER GENOM PROTEOM, V15, P41, DOI 10.21873/cgp.20063
   Kinzer S, 2021, INT S HIGH PERF COMP, P54, DOI 10.1109/HPCA51647.2021.00015
   Koide T, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P651, DOI 10.1109/APCCAS.2014.7032865
   Kuang W, 2020, IEEE T CIRC SYST VID, V30, P1481, DOI 10.1109/TCSVT.2019.2903547
   Linty N, 2019, IEEE T AERO ELEC SYS, V55, P303, DOI 10.1109/TAES.2018.2850385
   Lu A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P139, DOI 10.1109/ICFPT51103.2020.00027
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Minut M., 2020, 2020 IEEE ACM INT C, P1, DOI [10.1109/EHB50910.2020.9280178, DOI 10.1109/EHB50910.2020.9280178]
   Pullini A, 2019, IEEE J SOLID-ST CIRC, V54, P1970, DOI 10.1109/JSSC.2019.2912307
   Qasaimeh M, 2015, IEEE T COMPUT IMAG, V1, P56, DOI 10.1109/TCI.2015.2424077
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tabanelli Enrico, 2021, ARXIV
   UCI Machine Learning Repository, 2017, GEO MAGN FIELD WLAN
   Zhang JJ, 2021, IEEE INT CONF ASAP, P218, DOI 10.1109/ASAP52443.2021.00040
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT J
AU Banerjee, S
   Deb, AK
   Rajan, RN
   Kishore, NK
AF Banerjee, Srutarshi
   Deb, A. K.
   Rajan, Rehim N.
   Kishore, N. K.
TI Classification of electrical discharges in DC Accelerators
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Classification; Electrical discharges; Fuzzy Logic; High voltage (HV);
   LSSVM; Neural; Network
ID DYNAMITRON ACCELERATORS
AB Controlled electrical discharge aids in conditioning of the system while uncontrolled discharges damage its electronic components. DC Accelerator being a high voltage system is no exception. It is useful to classify electrical discharges according to the severity. Experimental prototypes of the accelerator discharges are developed. Photomultiplier Tubes (PMTS) are used to detect the signals from these discharges. Time and Frequency domain characteristics of the detected discharges are used to extract features. Machine Learning approaches like Fuzzy Logic, Neural Network and Least Squares Support Vector Machine (LSSVM) are employed to classify the discharges. This aids in detecting the severity of the discharges. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Banerjee, Srutarshi; Rajan, Rehim N.] Bhabha Atom Res Ctr, Accelerator & Pulse Power Div, Mumbai 400085, Maharashtra, India.
   [Deb, A. K.; Kishore, N. K.] Indian Inst Technol, Dept Elect Engn, Kharagpur 721302, W Bengal, India.
RP Banerjee, S (corresponding author), Bhabha Atom Res Ctr, Accelerator & Pulse Power Div, Mumbai 400085, Maharashtra, India.
EM sruban.stephens@gmail.com
CR [Anonymous], 1998, PHOT TUB CONSTR OP C
   [Anonymous], 1999, PHOT TUB 1P28 DAT
   Banerjee Srutarshi, 2013, P 2013 IEEE 1 INT C
   Chang C. S., 2004, AUPEC 2004, P120
   CLELAND MR, 1993, NUCL INSTRUM METH B, V79, P861, DOI 10.1016/0168-583X(93)95486-O
   Contin A, 2002, IEEE T DIELECT EL IN, V9, P335, DOI 10.1109/TDEI.2002.1007695
   Deb AK, 2007, IEEE T NEURAL NETWOR, V18, P1016, DOI 10.1109/TNN.2007.899255
   EARWAKER LG, 1977, REV PHYS APPL, V12, P1419, DOI 10.1051/rphysap:0197700120100141900
   Evagorou D, 2010, IET SCI MEAS TECHNOL, V4, P177, DOI 10.1049/iet-smt.2009.0023
   Fernández A, 2010, FUZZY SET SYST, V161, P3064, DOI 10.1016/j.fss.2010.05.016
   Galloway RA, 2004, RADIAT PHYS CHEM, V71, P283, DOI 10.1016/j.radphyschem.2004.03.060
   HANLEY PR, 1969, IEEE T NUCL SCI, VNS16, P90, DOI 10.1109/TNS.1969.4325184
   Hirata A, 2006, IEEE T POWER DELIVER, V21, P526, DOI 10.1109/TPWRD.2005.848439
   Hunter J. A., 2010, P IEEE 2010 INT S EL, P18
   JAK Tony van Gestel Suykens, 2004, MACH LEARN, P5
   Kaehler Steven D., 1998, FUZZY LOGIC TUTORIAL
   Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255
   Kuffel E., 2000, HIGH VOLTAGE ENG FUN
   LANGSDORF A, 1983, IEEE T NUCL SCI, V30, P1453, DOI 10.1109/TNS.1983.4332558
   Matsuyama S, 2009, NUCL INSTRUM METH B, V267, P2060, DOI 10.1016/j.nimb.2009.03.028
   Rajan R. N., 2011, STATIC ELECT GUN POW
   Rajan Rehim N., 2014, P INT S DISCH EL INS
   Schneider J., 1997, CROSS VALIDATION
   Sharma D. K., 2011, PERFORMANCE 3 MV VOL
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   THOMPSON CC, 1989, NUCL INSTRUM METH B, V40-1, P1137, DOI 10.1016/0168-583X(89)90557-0
   THOMPSON CC, 1969, IEEE T NUCL SCI, VNS16, P124, DOI 10.1109/TNS.1969.4325195
   Thompson Jr Chester C., 1973, U. S. Patent, Patent No. [3,754,149, 3754149]
   Weston J., 1999, P ESANN99 BRUSS BELG
   Yan WZ, 2005, P SOC PHOTO-OPT INS, V5768, P166, DOI 10.1117/12.599819
NR 30
TC 1
Z9 1
U1 1
U2 7
PD AUG 11
PY 2016
VL 827
BP 131
EP 136
DI 10.1016/j.nima.2016.04.099
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Reuther, A
   Michaleas, P
   Jones, M
   Gadepally, V
   Samsi, S
   Kepner, J
AF Reuther, Albert
   Michaleas, Peter
   Jones, Michael
   Gadepally, Vijay
   Samsi, Siddharth
   Kepner, Jeremy
GP IEEE
TI AI and ML Accelerator Survey and Trends
SO 2022 IEEE HIGH PERFORMANCE EXTREME COMPUTING VIRTUAL CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Virtual Conference (HPEC)
CY SEP 19-23, 2022
CL ELECTR NETWORK
DE Machine learning; GPU; TPU; dataflow; accelerator; embedded inference;
   computational performance
ID NEURAL-NETWORKS; ARCHITECTURES; HARDWARE
AB This paper updates the survey of AI accelerators and processors from past three years. This paper collects and summarizes the current commercial accelerators that have been publicly announced with peak performance and power consumption numbers. The performance and power values are plotted on a scatter graph, and a number of dimensions and observations from the trends on this plot are again discussed and analyzed. Two new trends plots based on accelerator release dates are included in this year's paper, along with the additional trends of some neuromorphic, photonic, and memristor-based inference accelerators.
C1 [Reuther, Albert; Michaleas, Peter; Jones, Michael; Gadepally, Vijay; Samsi, Siddharth; Kepner, Jeremy] Lincoln Lab Supercomputing Ctr, Lexington, MA USA.
RP Reuther, A (corresponding author), Lincoln Lab Supercomputing Ctr, Lexington, MA USA.
EM reuther@ll.mit.edu; pmichaleas@ll.mit.edu; michael.jones@ll.mit.edu;
   vijayg@ll.mit.edu; Sid@ll.mit.edu; Kepner@ll.mit.edu
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Alcorn P., 2017, NVIDIA INFUSES DGX 1
   [Anonymous], 2020, DELL DSS8440 GRAPHC
   [Anonymous], 2018, AIWARE3 HARDWARE IP
   [Anonymous], 2021, OPTICAL CHIP SOLVES
   [Anonymous], 2019, NVIDIA TESLA V100 TE
   [Anonymous], 2017, TAK DEEP LOOK AMD RA
   [Anonymous], 2019, CORNAMI ACHIEVES UNP
   [Anonymous], 2020, GAP APPL PROCESSORS
   Barnell M, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286246
   Belletti F., 2019, P 2020 SIAM C PARALL, P12
   Burt J, 2022, CHIP MAKERS PRESS ST
   Campa C., 2020, DEFINING INNOVATION
   Canziani A, 2016, ARXIV
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Choi C. Q., 2022, PHOTONIC CHIP PERFOR
   Clarke P., 2020, NXP KALRAY DEMO COOL
   Clarke P, 2018, INDO US STARTUP PREP
   Clarke P, 2019, GLOBALFOUNDRIES AIDS
   Clay M, 2022, PROC SPIE, V12102, DOI 10.1117/12.2622390
   cpu-world, 2020, INTEL XEON PLATINUM
   Cutress I., 2019, PREFERRED NETWORKS 5
   Cutress I., 2018, CAMBRICON MAKER HAUW
   Cutress I, 2018, NVIDIAS DGX 2 16 TES
   Schuman CD, 2017, Arxiv, DOI arXiv:1705.06963
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Davies M, 2021, P IEEE, V109, P911, DOI 10.1109/JPROC.2021.3067593
   De Gelas J, 2019, INTELS XEON CASCADE
   Demler M., 2020, TI JACINTO ACCELERAT
   Demler M., 2020, BLAIZE IGNITES EDGE
   Duckett C, 2018, BAIDU CREATES KUNLUN
   Dupont de Dinechin B., 2019, 17 IEEE INT NEW CIRC
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Evangelist C., 2020, DEEP DIVE AMAZON INF
   Fick D., 2018, MYTHIC HOT CHIPS 201
   Firu D, 2019, QUADRIC EDGE SUPERCO
   Franklin, 2017, NVIDIA JETSON TX2 DE
   Freund K., 2019, NOVUMIND EARLY ENTRA
   Freund K, 2021, ESPERANTO LAUNCHES A
   Funk B, 2022, NVIDIA JETSON AGX OR
   Gadepally V, 2019, Arxiv, DOI arXiv:1905.03592
   google, 2019, EDGE TPU
   Gwennap L., 2020, UNTETHER DELIVERS AT
   Gwennap L, 2019, HABANA WINS CIGAR AI
   Gwennap L, 2019, KENDRYTE EMBEDS AI S
   Gwennap Linley, 2020, MICROPROCESSOR REPOR
   Hamilton J, 2018, AWS INFERENTIA MACHI
   Hemsoth N, 2018, INTEL FPGA ARCHITECT
   Hemsoth N, 2020, GROQ SHARES RECIPE T
   Hemsoth N, 2018, MYTHIC APPROACH DEEP
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hill B, 2022, NVIDIA UNVEILS AMPER
   Hilson G, 2022, STARTUP TACHYUM OFFE
   Hock A, 2019, INTRO CEREBRAS CS 1
   horizon, 2020, HORIZON ROBOTICS JOU
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   hpcwire, 2020, SOLIDRUN GYRFALCON D
   Hruska J, 2017, NEW MOVIDIUS MYRIAD
   Hu RL, 2022, INT J HIGH PERFORM C, V36, P510, DOI 10.1177/10943420221102873
   Huawei, 2020, ASC 910 AI PROC
   Huawei, 2020, ASC 310 AI PROC
   James CD, 2017, BIOL INSPIR COGN ARC, V19, P49, DOI 10.1016/j.bica.2016.11.002
   Jani A., 2021, MAXIM SHOWCASES EFFI
   Jia Z, 2019, Arxiv, DOI arXiv:1912.03413
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2018, COMMUN ACM, V61, P50, DOI 10.1145/3154484
   Khan Saif, 2020, AI CHIPS WHAT THEY A
   Kilgariff E., 2018, NVIDIA TURING ARCHIT
   Krashinsky Ronny., 2020, NVIDIA AMPERE ARCHIT
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kundu I, 2020, ARXIV
   Lacey D, 2017, PRELIMINARY IPU BENC
   Langroudi HF, 2019, PROC SPIE, V11139, DOI 10.1117/12.2529407
   Launay J, 2020, Arxiv, DOI arXiv:2006.01475
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Leiserson CE, 2020, SCIENCE, V368, P1079, DOI 10.1126/science.aam9744
   Levy M., 2021, INNATERAS SPIKING NE
   Lewis AGMGM, 2021, Arxiv, DOI arXiv:2112.09017
   Liao, 2001, NEURAL NETWORKS HARD
   LINDSEY CS, 1995, P SOC PHOTO-OPT INS, V2492, P1194, DOI 10.1117/12.205116
   Louw T, 2021, 3 WORKSHOP ACCELERAT
   Lu T., 2020, IEEE ACCESS, V9
   Lu TJ, 2021, I S BIOMED IMAGING, P783, DOI 10.1109/ISBI48211.2021.9434068
   Lu TJ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286192
   Lunden I, 2020, GRAPHCORE UNVEILS NE
   Martin D., 2022, SAMSUNG OTHERS TEST
   McGrath D, 2018, TECH HEAVYWEIGHTS BA
   McGrath D, 2019, QUALCOMM TARGETS AI
   McGregor J., 2020, PERCEIVE EXITS STEAL
   Medina E, 2020, IEEE MICRO, V40, P17, DOI 10.1109/MM.2020.2975185
   Mehta V, 2020, LINL SPRING PROC C L
   Merritt R., 2019, STARTUP ACCELERATES
   Merritt R, 2018, BAIDU ACCELERATOR RI
   Merritt R, 2018, STARTUP ROLLS AI CHI
   Merritt R., 2019, SAMSUNG TOSHIBA DETA
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Morgan T. P., 2022, INTEL PITS NEW GAUDI
   Morgan T. P., 2017, DRILLING MICROSOFTS
   Morgan T. P., 2021, NVIDIA ROUNDS OUT AM
   Noune Badreddine, 2022, ARXIV
   nvidia, 2022, JETSON AGX ORIN NEXT
   nvidia, NVIDIA TESLA P100
   Orchard G, 2021, IEEE WRK SIG PRO SYS, P254, DOI 10.1109/SiPS52927.2021.00053
   Ostrovskii V, 2022, NANOMATERIALS-BASEL, V12, DOI 10.3390/nano12010063
   Ouyang J, 2021, ISSCC DIG TECH PAP I, V64, P50, DOI 10.1109/ISSCC42613.2021.9366056
   Peckham O, 2022, GOOGLE CLOUDS NEW TP
   Peckham O., 2021, ENTER DOJO TESLA REV
   Peckham O, 2022, INTELS HABANA LABS U
   Peng T, 2019, ALIBABAS NEW AI CHIP
   Prabhakar Raghu, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P350, DOI 10.1109/ISSCC42614.2022.9731612
   Prabhakar R., 2021, HOT CHIPS, P1, DOI DOI 10.1109/HCS52781.2021.9567250
   projects.preferred, 2020, MN CORE
   R. F. Service, 2022, MICR MIM HUM BRAIN C
   Reuther A, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622867
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Reuther A, 2019, IEEE HIGH PERF EXTR
   rock- chips, 2018, ROCKCHIP RELEASED IT
   Rocki K., 2020, ARXIV
   Rogers T., 2021, ACAD ATTEMPT CLEAR F
   Roos G, 2019, FPGA ACCELERATION CA
   Rueckert U., 2020, NANOCHIPS 2030 ON CH, P181
   Schneider D, 2019, NEURAL NET BASED LIG
   Schor D, 2020, ARM ETHOS IS UBIQUIT
   Schor D, 2017, 2048 CORE PEZY SC2 S
   Sharma P., 2021, ARXIV
   Shilov A., 2021, VIA SHUTTERS CENTAUR
   Shilov A., 2022, TACHYUM TEASES 128 C
   Smith R, 2018, AMD ANNOUNCES RADEON
   Smith R, 2022, NVIDIA HOPPER GPU AR
   Smith R., 2019, NVIDIA GIVES JETSON
   Smith R, 2018, 16GB NVIDIA TESLA V1
   Sunny FP, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3459009
   Sze V., 2020, EFFICIENT PROCESSING
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Teich P., 2018, TEARING APART GOOGLE
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Thompson NC, 2021, COMMUN ACM, V64, P64, DOI 10.1145/3430936
   ti, 2021, TDA4VM JAC PROC ADAS
   Toon N, 2020, INTRO 2 GENERATION I
   Trader T., 2021, CEREBRAS DOUBLES AI
   Turley J, 2020, GAP9 ML EDGE EEJOURN
   Tyson M, 2022, GRAPHCORE BOW IPU IN
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Viale A, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533738
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Ward-Foxton S, 2019, DETAILS HAILO AI EDG
   Ward-Foxton S., 2020, SAMBANOVA EMERGES ST
   Ward-Foxton S, 2022, AXELERA DEMOS AI TES
   Ward-Foxton S., 2020, KNERONS NEXT GEN EDG
   Ward-Foxton S., 2021, INNATERA UNVEILS NEU
   Ward-Foxton S, 2021, KNERON ATTRACTS STRA
   Ward-Foxton S., 2021, MYTHIC RESIZES ITS A
   Ward-Foxton S, 2020, MAXIM DEBUTS HOMEGRO
   Ward-Foxton S., 2020, GRAPHCORE TAKES NVID
   Ward-Foxton S, 2019, GYRFALCON UNVEILS 4
   Ward-Foxton S, OPTICAL COMPUTE PROM
   Ward-Foxton S, 2020, QUALCOMM CLOUD AI 10
   Ward-Foxton S., 2021, TIS 1 AUTOMOTIVE SOC
   Wheeler B, 2019, BITMAIN SOC BRINGS A
   wikichip, 2020, FSD CHIP TESLA
   Wilson J, 2020, MULTIPLY FOURIER TRA
   Wu Y, 2018, CHINESE AI CHIP MAKE
   Yang K., 2019, INT C HIGH PERFORMAN
   Yoshida J, 2018, NOVUMINDS AI CHIP SP
NR 167
TC 3
Z9 3
U1 5
U2 5
PY 2022
DI 10.1109/HPEC55821.2022.9926331
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Noskova, ES
   Zakharov, IE
   Shkandybin, YN
   Rykovanov, SG
AF Noskova, E. S.
   Zakharov, I. E.
   Shkandybin, Y. N.
   Rykovanov, S. G.
TI Towards energy-efficient neural network calculations
SO COMPUTER OPTICS
DT Article
DE NVDLA; FPGA; inference; deep learning accelerators
ID MACHINE
AB Nowadays, the problem of creating high-performance and energy-efficient hardware for Artificial Intelligence tasks is very acute. The most popular solution to this problem is the use of Deep Learning Accelerators, such as GPUs and Tensor Processing Units to run neural networks. Recently, NVIDIA has announced the NVDLA project, which allows one to design neural network accelerators based on an open-source code. This work describes a full cycle of creating a prototype NVDLA accelerator, as well as testing the resulting solution by running the resnet-50 neural network on it. Finally, an assessment of the performance and power efficiency of the prototype NVDLA accelerator when compared to the GPU and CPU is provided, the results of which show the superiority of NVDLA in many characteristics.
C1 [Noskova, E. S.; Zakharov, I. E.; Shkandybin, Y. N.; Rykovanov, S. G.] Skolkovo Inst Sci & Technol, Bolshoi Blvd 30,Bldg 1, Moscow 121205, Russia.
RP Noskova, ES (corresponding author), Skolkovo Inst Sci & Technol, Bolshoi Blvd 30,Bldg 1, Moscow 121205, Russia.
EM elizaveta.noskova@skoltech.ru; i.zacharov@skoltech.ru;
   y.shkandybin@skoltech.ru; s.rykovanov@skoltech.ru
CR Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Delbergue G., 2016, P 8 EUR C EMB REAL T, P1
   Farshchi F, 2019, 2019 2ND WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2 2019), P21, DOI 10.1109/EMC249363.2019.00012
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo K, 2017, ARXIV171208934
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Merenda M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092533
   MISHRA A, 2018, P INT C LEARN REPR, P1, DOI DOI 10.1109/ICACAT.2018.8933665
   Panarin O., 2020, RUSSIAN DIGITAL LIB, V23, P835
   Park Ji Ho, 2018, BAM BOTTLENECK ATTEN
   Shaw DE, 2008, COMMUN ACM, V51, P91, DOI 10.1145/1364782.1364802
   Singer G., 2018, DEEP LEARNING IS COM
   Tan ZX, 2010, CONF PROC INT SYMP C, P290, DOI 10.1145/1816038.1815999
   TechPowerUp, NVIDIA GEFORCE RTX 2
   TechPowerUp, NVIDIA GEFORCE GTX 1
   Zacharov I, 2019, OPEN ENG, V9, P512, DOI 10.1515/eng-2019-0059
   [Захаров Игорь Евгеньевич Zacharov Igor Evgenjevich], 2021, [Программные системы: теория и приложения, Program Systems: Theory and Applications, Programmnye sistemy: teoriya i prilozheniya], V12, P73, DOI 10.25209/2079-3316-2021-12-2-73-103
NR 19
TC 0
Z9 0
U1 0
U2 3
PD JAN-FEB
PY 2022
VL 46
IS 1
BP 160
EP 166
DI 10.18287/2412-6179-CO-914
WC Optics
DA 2023-11-11
ER

PT J
AU Zheng, N
   Mazumder, P
AF Zheng, Nan
   Mazumder, Pinaki
TI A Scalable Low-Power Reconfigurable Accelerator for Action-Dependent
   Heuristic Dynamic Programming
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Adaptive dynamic programming; neural networks; low-power accelerators;
   action-dependent heuristic dynamic programming; machine learning
ID FEEDBACK-CONTROL; ARCHITECTURE; DESIGN
AB Adaptive dynamic programming (ADP) is an effective algorithm that has been successfully deployed in various control tasks. For many emerging applications where power consumption is a major design consideration, the conventional way of implementing ADP as software executing on a general-purpose processor is not sufficient. This paper proposes a scalable and low-power hardware architecture for implementing one of the most popular forms of ADP called action-dependent heuristic dynamic programming. Different from most machine-learning accelerators that mainly focus on the inference operation, the proposed architecture is also designed for energy-efficient learning, considering the highly iterative and interactive nature of the ADP algorithm. In addition, a virtual update technique is proposed to speed up the computation and to improve the energy efficiency of the accelerators. Two design examples are presented to demonstrate the proposed algorithm and architecture. Compared with the software approach running on a general-purpose processor, the accelerator operating at 175 MHz achieves 270 times improvement in computational time while consuming merely 25 mW power. Furthermore, it is demonstrated that the proposed virtual update algorithm can effectively boost the energy efficiency of the accelerator. Improvements up to 1.64 times are observed in the benchmark tasks employed.
C1 [Zheng, Nan; Mazumder, Pinaki] Univ Michigan, Dept Elect Engn Comp Sci, Ann Arbor, MI 48104 USA.
RP Zheng, N (corresponding author), Univ Michigan, Dept Elect Engn Comp Sci, Ann Arbor, MI 48104 USA.
EM zhengn@umich.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2007, PATTERN RECOGN, V16
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Ferrari S, 2004, J GUID CONTROL DYNAM, V27, P777, DOI 10.2514/1.12597
   Ferrari S, 2008, IEEE T SYST MAN CY B, V38, P982, DOI 10.1109/TSMCB.2008.924140
   Han DC, 2002, IEEE T CONTR SYST T, V10, P481, DOI 10.1109/TCST.2002.1014669
   He HB, 2012, NEUROCOMPUTING, V78, P3, DOI 10.1016/j.neucom.2011.05.031
   Iyer MS, 2001, IEEE T NEURAL NETWOR, V12, P1433, DOI 10.1109/72.963778
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kung J, 2015, I SYMPOS LOW POWER E, P85, DOI 10.1109/ISLPED.2015.7273495
   Larkin D, 2006, LECT NOTES COMPUT SC, V3973, P1319
   Lewis FL, 2012, IEEE CONTR SYST MAG, V32, P76, DOI 10.1109/MCS.2012.2214134
   Lewis FL, 2009, IEEE CIRC SYST MAG, V9, P32, DOI 10.1109/MCAS.2009.933854
   Lin CK, 2005, IEEE T SYST MAN CY B, V35, P197, DOI 10.1109/TSMCB.2004.842246
   Liu DR, 2001, IEEE IJCNN, P990, DOI 10.1109/IJCNN.2001.939495
   Liu F, 2012, NEURAL NETWORKS, V32, P229, DOI 10.1016/j.neunet.2012.02.005
   Mazumder P, 2016, INTEGRATION, V54, P109, DOI 10.1016/j.vlsi.2016.01.002
   Mu CX, 2017, IEEE T NEUR NET LEAR, V28, P584, DOI 10.1109/TNNLS.2016.2516948
   Ni Z., 2013, IEEE T NEUR NET LEAR, V26, P1834
   Ni Z, 2013, IEEE T NEUR NET LEAR, V24, P913, DOI 10.1109/TNNLS.2013.2247627
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pérez-Arancibia NO, 2011, BIOINSPIR BIOMIM, V6, DOI 10.1088/1748-3182/6/3/036009
   Prokhorov DV, 1997, IEEE T NEURAL NETWOR, V8, P997, DOI 10.1109/72.623201
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Savich A, 2012, MICROPROCESS MICROSY, V36, P138, DOI 10.1016/j.micpro.2010.12.001
   Si J, 2001, IEEE T NEURAL NETWOR, V12, P264, DOI 10.1109/72.914523
   Sokolov Y, 2015, AUTOMATICA, V59, P9, DOI 10.1016/j.automatica.2015.06.001
   Sun YW, 2012, COMPUT BIOL MED, V42, P751, DOI 10.1016/j.compbiomed.2012.04.007
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang D, 2017, IEEE T CYBERNETICS, V47, P3429, DOI 10.1109/TCYB.2017.2712188
   Wang FY, 2009, IEEE COMPUT INTELL M, V4, P39, DOI 10.1109/MCI.2009.932261
   Wei QL, 2017, IEEE T IND ELECTRON, V64, P4110, DOI 10.1109/TIE.2017.2650872
   Wood RJ, 2008, IEEE T ROBOT, V24, P341, DOI 10.1109/TRO.2008.916997
   Zheng N., 2018, P 31 INT C VLSI DES
NR 38
TC 2
Z9 2
U1 2
U2 6
PD JUN
PY 2018
VL 65
IS 6
BP 1897
EP 1908
DI 10.1109/TCSI.2017.2771437
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU de Abreu, BA
   Paim, G
   Grellert, M
   Bampi, S
AF de Abreu, Brunno Alves
   Paim, Guilherme
   Grellert, Mateus
   Bampi, Sergio
TI C2PAx: Complexity-Aware Constant Parameter Approximation for
   Energy-Efficient Tree-Based Machine Learning Accelerators
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Radio frequency; Proposals; Integrated circuit modeling; Brain modeling;
   Random forests; Very large scale integration; Power dissipation;
   Approximate computing; machine learning; random forests; decision trees;
   VLSI design; hardware accelerators
ID DECISION
AB Tree-based machine learning models, like random forests and decision trees, are low-complexity solutions that provide an efficient prediction for a wide range of applications. These models are particularly interesting for energy-constrained platforms since they can be implemented with simple logical operations. Tree-based accelerators are also intrinsically resilient to errors, and this can be leveraged to boost energy efficiency with approximate computing techniques. The key operations in these models are comparisons to constants, making comparators excellent candidates for approximation. This paper presents a technique to approximate comparisons to constants called C2PAx, which is capable of reducing the area and energy of tree-based accelerators. The method consists in finding alternative constants that reduce circuit area while keeping an efficient prediction performance. It is also shown that the selection of the constant parameters directly influences both hardware complexity and model performance, demanding cross-layer optimization. For that, we extend an existing framework that generates VLSI tree-based accelerators, inserting our approximation proposal that allows selecting the constant parameters that maximize energy efficiency at the cost of minor accuracy drops. Simulation results demonstrate that C2PAx outperforms the Don't Care logic approximation technique when accuracy and energy are jointly considered. C2PAx trades accuracy for significant reductions in the VLSI area, power, delay, and energy consumption compared to precise models.
C1 [de Abreu, Brunno Alves; Paim, Guilherme; Bampi, Sergio] Univ Fed Rio Grande do Sul UFRGS, Inst Informat INF, Grad Program Microelect PGMICRO, BR-91501970 Porto Alegre, RS, Brazil.
   [Grellert, Mateus] Univ Fed Santa Catarina UFSC, Grad Program Comp Sci PPGCC, BR-88040900 Florianopolis, SC, Brazil.
RP Paim, G (corresponding author), Univ Fed Rio Grande do Sul UFRGS, Inst Informat INF, Grad Program Microelect PGMICRO, BR-91501970 Porto Alegre, RS, Brazil.
EM baabreu@inf.ufrgs.br; gppaim@inf.ufrgs.br; mateus.grellert@ufsc.br;
   bampi@inf.ufrgs.br
CR Abreu B.A., 2020, 2020 IEEE INT S CIRC, P1
   Abreu B, 2022, ENG APPL ARTIF INTEL, V109, DOI 10.1016/j.engappai.2021.104638
   Amato Flora, 2013, Algorithms and Architectures for Parallel Processing. 13th International Conference, ICA3PP 2013. Proceedings: LNCS 8286, P125, DOI 10.1007/978-3-319-03889-6_14
   Amato F, 2014, STUD COMPUT INTELL, V511, P289, DOI 10.1007/978-3-319-01571-2_34
   Barbareschi M, 2021, KNOWL INF SYST, V63, P1577, DOI 10.1007/s10115-021-01565-5
   Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Chang SY, 2019, IEEE T CIRCUITS-I, V66, P3504, DOI 10.1109/TCSI.2019.2927839
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Ikeda Taiga, 2020, Applied Reconfigurable Computing Architectures, Tools, and Applications. 16th International Symposium, ARC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 120830), P345, DOI 10.1007/978-3-030-44534-8_26
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P189, DOI 10.1109/TCSI.2018.2856245
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Paim G, 2020, IEEE T CIRC SYST VID, V30, P3814, DOI 10.1109/TCSVT.2019.2945763
   Paim G, 2019, IEEE T CIRCUITS-I, V66, P680, DOI 10.1109/TCSI.2018.2868513
   Pashaeifar M, 2019, IEEE T CIRCUITS-I, V66, P327, DOI 10.1109/TCSI.2018.2856757
   Salamat S, 2017, INT SYM QUAL ELECT, P419, DOI 10.1109/ISQED.2017.7918352
   Sayed R, 2020, IEEE ACCESS, V8, P192155, DOI 10.1109/ACCESS.2020.3032658
   Seidel HB, 2021, IEEE T CIRCUITS-I, V68, P1814, DOI 10.1109/TCSI.2021.3057584
   Shoaran M, 2018, IEEE J EM SEL TOP C, V8, P693, DOI 10.1109/JETCAS.2018.2844733
   Stanley-Marbell P., 2021, ACM COMPUT SURV, V53, P1
   Strollo AGM, 2020, IEEE T CIRCUITS-I, V67, P3021, DOI 10.1109/TCSI.2020.2988353
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Tong D, 2017, IEEE T PARALL DISTR, V28, P3046, DOI 10.1109/TPDS.2017.2714661
   Torres RLS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON RFID (RFID), P191, DOI 10.1109/RFID.2013.6548154
   Tsai KL, 2021, IEEE T CIRCUITS-I, V68, P3328, DOI 10.1109/TCSI.2021.3085572
   Ugulino Wallace, 2012, Advances in Artificial Intelligence - SBIA 2012. Proceedings 21th Brazilian Symposium on Artificial Intelligence, P52, DOI 10.1007/978-3-642-34459-6_6
   Velloso Eduardo, 2013, P 4 AUGMENTED HUMAN, P116, DOI DOI 10.1145/2459236.2459256
   Yang Y, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY (CYBERC), P380, DOI 10.1109/CyberC.2014.72
   Zervakis G, 2021, ASIA S PACIF DES AUT, P189, DOI 10.1145/3394885.3431632
NR 30
TC 6
Z9 6
U1 0
U2 1
PD JUL
PY 2022
VL 69
IS 7
BP 2683
EP 2693
DI 10.1109/TCSI.2022.3169028
EA APR 2022
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ipatov, DE
   Zverev, AV
AF Ipatov, Dmitry E.
   Zverev, Alexey, V
GP IEEE
TI Development of Neuromorphic Accelerator
SO 2019 20TH INTERNATIONAL CONFERENCE OF YOUNG SPECIALISTS ON
   MICRO/NANOTECHNOLOGIES AND ELECTRON DEVICES (EDM 2019)
SE International Conference and Seminar of Young Specialists on
   Micro-Nanotechnologies and Electron Devices
DT Proceedings Paper
CT 20th International Conference of Young Specialists on
   Micro/Nanotechnologies and Electron Devices (EDM)
CY JUN 29-JUL 03, 2019
CL Erlagol, RUSSIA
DE Neuromorphic; neuromorphic architecture; neural networks; accelerator;
   machine learning
AB The paper shows the design of a neuromorphic accelerator, as well as unified design solutions for creating a scalable modular system of neuromorphic accelerators. The neuromorphic accelerator based on the FPGA was developed. It allows simulating up to 131 thousand neurons with 67 million synaptic connections.
   The neuromorphic cross-connection board, which is the universal platform for working with the neuromorphic accelerators and neural networks that they stimulate, was developed. One cross connection board allows placing up to 16 neuromorphic accelerators, which makes a simulation of up to 2 million neurons with a total number of synaptic connections of up to 1 billion possible.
   An energy consumption analysis was made for every developed device.
C1 [Ipatov, Dmitry E.] AV Rzhanov Inst Semicond Phys SB RAS, Novosibirsk, Russia.
   [Zverev, Alexey, V] Motiv NT LLC, Moscow, Russia.
RP Ipatov, DE (corresponding author), AV Rzhanov Inst Semicond Phys SB RAS, Novosibirsk, Russia.
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   [Anonymous], 2014, 6029731082014 IEC
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Furber SB, 2013, IEEE T COMPUT, V62, P2454, DOI 10.1109/TC.2012.142
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Herculano-Houzel S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017514
   Marblestone AH, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00137
   Mead C., 1989, ANALOG VLSI NEURAL S, P63
   Qiao N, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00141
   Snijders C, 2012, INT J INTERNET SCI, V7, P1
   Xilinx Inc, 2016, 7 SER FPGAS MEM RES
NR 13
TC 0
Z9 0
U1 2
U2 4
PY 2019
BP 720
EP 725
DI 10.1109/edm.2019.8823487
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Physics, Applied
DA 2023-11-11
ER

PT C
AU Scherer, M
   Di Mauro, A
   Rutishauser, G
   Fischer, T
   Benini, L
AF Scherer, Moritz
   Di Mauro, Alfio
   Rutishauser, Georg
   Fischer, Tim
   Benini, Luca
GP IEEE
TI A 1036 TOp/s/W, 12.2 mW, 2.72 μJ/Inference All Digital TNN Accelerator
   in 22 nm FDX Technology for TinyML Applications
SO IEEE SYMPOSIUM ON LOW-POWER AND HIGH-SPEED CHIPS AND SYSTEMS (2022 IEEE
   COOL CHIPS 25)
SE Proceedings for IEEE COOL CHIPS
DT Proceedings Paper
CT 25th IEEE Symposium in Low-Power and High-Speed Chips (COOL CHIPS)
CY APR 20-22, 2022
CL Univ Tokyo, Tokyo, JAPAN
HO Univ Tokyo
DE VLSI; IoT; TinyML; Machine Learning; TNN; RISC-V; SoC
AB Tiny Machine Learning (TinyML) applications impose mu J/Inference constraints, with maximum power consumption of a few tens of mW. It is extremely challenging to meet these requirement at a reasonable accuracy level. In this work, we address this challenge with a flexible, fully digital Ternary Neural Network (TNN) accelerator in a RISC-V-based SoC. The design achieves 2.72 mu J/Inference, 12.2 mW, 3200 Inferences/sec at 0.5 V for a non-trivial 9-layer, 96 channels-per-layer network with CIFAR-10 accuracy of 86 %. The peak energy efficiency is 1036 TOp/s/W, outperforming the state-of-the-art in silicon-proven TinyML accelerators by 1.67x.
C1 [Scherer, Moritz; Di Mauro, Alfio; Rutishauser, Georg; Fischer, Tim; Benini, Luca] Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn, Bologna, Italy.
RP Scherer, M (corresponding author), Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, Zurich, Switzerland.
EM scheremo@iis.ee.ethz.ch; adimauro@iis.ee.ethz.ch; georgr@iis.ee.ethz.ch;
   fischeti@iis.ee.ethz.ch; lbenini@iis.ee.ethz.ch
CR Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Knag P. C., 2020, 2020 IEEE S VLSI CIR, P1
   Moons B, 2018, IEEE CUST INTEGR CIR
   Pullini Antonio, 2017 27 INT S POWER
   Scherer M, 2022, IEEE T COMPUT AID D, V41, P1020, DOI 10.1109/TCAD.2021.3075420
NR 5
TC 1
Z9 1
U1 0
U2 2
PY 2022
DI 10.1109/COOLCHIPS54332.2022.9772668
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Kim, M
   Mohanty, A
   Kadetotad, D
   Wei, LN
   He, XF
   Cao, Y
   Seo, JS
AF Kim, Minkyu
   Mohanty, Abinash
   Kadetotad, Deepak
   Wei, Luning
   He, Xiaofei
   Cao, Yu
   Seo, Jae-Sun
TI A Real-Time 17-Scale Object Detection Accelerator With Adaptive
   2000-Stage Classification in 65 nm CMOS
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Object detection; machine learning; classification; real-time;
   low-power; special-purpose accelerator
AB Machine learning has become ubiquitous in applications including object detection, image/video classification, and natural language processing. While machine learning algorithms have been successfully used in many practical applications, accurate, fast, and low-power hardware implementations of such algorithms is still a challenging task, especially for mobile systems such as Internet of Things (IoT), autonomous vehicles, and smart drones. This paper presents an energy-efficient programmable ASIC accelerator for object detection. Our ASIC accelerator supports multi-class (e.g., face, traffic sign, car license plate, and pedestrian) that are programmable, many-object (up to 50) in one image with different sizes (17-scale support with 6 down-/11 up-scaling), and high accuracy (AP of 0.87/0.81/0.72/0.76 for FDDB/AFW/BTSD/ Caltech datasets). We designed an integral channel detector with 2,000 classifiers for rigid boosted templates, where the number of stages used for classification can be adaptively controlled depending on the content of the search window. This can be implemented with a more modular hardware, compared to support vector machine (SVM) and deformable parts model (DPM) designs. By jointly optimizing the algorithm and the efficient hardware architecture, the prototype chip implemented in 65nm CMOS demonstrates real-time object detection of 20-50 frames/s with low power consumption of 22.5-181.7 mW (0.54-1.75 nJ/pixel) at 0.58-1.1 V supply.
C1 [Kim, Minkyu; Mohanty, Abinash; Kadetotad, Deepak; Cao, Yu; Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
   [Wei, Luning; He, Xiaofei] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
RP Kim, M (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
EM mkim152@asu.edu
CR Advani S, 2015, IEEE SYM EMBED SYST, P103, DOI 10.1109/ESTIMedia.2015.7351774
   [Anonymous], 2010, FDDB BENCHMARK FACE
   [Anonymous], 2006, P 23 INT C MACH LEAR, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]
   [Anonymous], P IEEE S VLSI CIRC V
   [Anonymous], IEEE T CIRCUITS SYST
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dollar P., 2009, P BMVC, DOI DOI 10.5244/C.23.91
   Dongsuk Jeon, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC48, DOI 10.1109/VLSIC.2015.7231322
   Everingham M., PASCAL VISUAL OBJECT
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Kim M, 2017, ASIA S PACIF DES AUT, P21, DOI 10.1109/ASPDAC.2017.7858282
   Koestinger Martin, 2011, P IEEE INT C COMP VI, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Lee KJ, 2016, ISSCC DIG TECH PAP I, V59, P256, DOI 10.1109/ISSCC.2016.7418004
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Suleiman A, 2017, 2017 IEEE INT S CIRC, P1, DOI DOI 10.1109/ISCAS.2017.8050341
   Suleiman A, 2017, IEEE J SOLID-ST CIRC, V52, P844, DOI 10.1109/JSSC.2017.2648820
   Suleiman A, 2016, J SIGNAL PROCESS SYS, V84, P325, DOI 10.1007/s11265-015-1080-7
   Takagi K, 2014, J SIGNAL PROCESS SYS, V76, P261, DOI 10.1007/s11265-014-0870-7
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 27
TC 5
Z9 5
U1 0
U2 9
PD OCT
PY 2019
VL 66
IS 10
BP 3843
EP 3853
DI 10.1109/TCSI.2019.2921714
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Jalali, B
   Mahjoubfar, A
   Solli, D
   Asghari, M
   Jiang, YS
   Chen, CL
AF Jalali, Bahram
   Mahjoubfar, Ata
   Solli, Daniel
   Asghari, Mohamad
   Jiang, Yunshan
   Chen, Claire L.
BE Lakshminarayan, V
   Bhattacharya, I
TI Silicon Photonics Coprocessors for Energy Efficient Computing
SO 2015 2ND INTERNATIONAL CONFERENCE ON OPTO-ELECTRONICS AND APPLIED OPTICS
   (IEM OPTRONIX)
DT Proceedings Paper
CT 2nd International Conference on Opto-Electronics and Applied Optics (IEM
   OPTRONIX 2015)
CY OCT 15-17, 2015
CL University of British Columbia, Vancouver, CANADA
HO University of British Columbia
DE natural computing; analog computing; physical computing; complex dynamic
   systems; intelligent dynamic systems; analog optical co-processor;
   silicon photonics; photonic hardware accelerator; optical learning
   machines; photonic deep learning
AB We introduce three types of analog optical accelerators for enhancing the performance of electronic computing. These include (1) physical computing using complex optical dynamics in silicon for acceleration of scientific computing, (2) spectrotemporal processing and sparse coding using dispersion basis functions and (3) photonic computing primitives for performing nonlinear mathematical operations.
C1 [Jalali, Bahram; Mahjoubfar, Ata; Solli, Daniel; Asghari, Mohamad; Jiang, Yunshan; Chen, Claire L.] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90024 USA.
RP Jalali, B (corresponding author), Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90024 USA.
EM jalali@ucla.edu
CR Asghari MH, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/687819
   Borlaug D, 2009, IEEE PHOTONICS J, V1, P33, DOI 10.1109/JPHOT.2009.2025517
   Chan J, 2014, APPL PHYS LETT, V105, DOI 10.1063/1.4902986
   Chen C. L., 2015, PLOS ONE
   DeVore PTS, 2013, J OPTICS-UK, V15, DOI 10.1088/2040-8978/15/6/064001
   Jalali B, 1998, IEEE J SEL TOP QUANT, V4, P938, DOI 10.1109/2944.736081
   Jalali B., 2015, INF SCI SYST CISS 20, P1
   Jalali B, 2006, J LIGHTWAVE TECHNOL, V24, P4600, DOI 10.1109/JLT.2006.885782
   Jalali B, 2015, P IEEE, V103, P1071, DOI 10.1109/JPROC.2015.2418538
   Jalali B, 2014, OPTICA, V1, P23, DOI 10.1364/OPTICA.1.000023
   Mahjoubfar A., 2015, IN SCI SYST CISS 201, P1
   Solli DR, 2007, NATURE, V450, P1054, DOI 10.1038/nature06402
NR 12
TC 0
Z9 0
U1 0
U2 3
PY 2015
WC Engineering, Electrical & Electronic; Optics
DA 2023-11-11
ER

PT C
AU Milo, V
   Zambelli, C
   Olivo, P
   Pérez, E
   Ossorio, OG
   Wenger, C
   Ielmini, D
AF Milo, V.
   Zambelli, C.
   Olivo, P.
   Perez, E.
   Ossorio, O. G.
   Wenger, Ch.
   Ielmini, D.
GP IEEE
TI Low-energy inference machine with multilevel HfO<sub>2</sub> RRAM arrays
SO 49TH EUROPEAN SOLID-STATE DEVICE RESEARCH CONFERENCE (ESSDERC 2019)
SE Proceedings of the European Solid-State Device Research Conference
DT Proceedings Paper
CT 49th European Solid-State Device Research Conference (ESSDERC)
CY SEP 23-26, 2019
CL Cracow, POLAND
DE resistive switching memory (RRAM); artificial intelligence; machine
   learning; in-memory computing; neural network; backpropagation; energy
   efficiency
AB Recently, artificial intelligence reached impressive milestones in many machine learning tasks such as the recognition of faces, objects, and speech. These achievements have been mostly demonstrated in software running on high-performance computers, such as the graphics processing unit (GPU) or the tensor processing unit (TPU). Novel hardware with inmemory processing is however more promising in view of the reduced latency and the improved energy efficiency. In this scenario, emerging memory technologies such as phase change memory (PCM) and resistive switching memory (RRAM), have been proposed for hardware accelerators of both learning and inference tasks. In this work, a multilevel 4kbit RRAM array is used to implement a 2-layer feedforward neural network trained with the MNIST dataset. The performance of the network in the inference mode is compared with recently proposed implementations using the same image dataset demonstrating the higher energy efficiency of our hardware, thanks to low current operation and an innovative multilevel programming scheme. These results support RRAM technology for in-memory hardware accelerators of machine learning.
C1 [Milo, V.; Ielmini, D.] Politecn Milan, Dipartimento Elettron Informa & Bioingn, I-20133 Milan, Italy.
   [Zambelli, C.; Olivo, P.] Univ Ferrara, Dipartimento Ingn, I-44121 Ferrara, Italy.
   [Perez, E.; Wenger, Ch.] IHPLeibniz Inst Innovat Mikroelekt, Technol Pk 25, D-15236 Frankfurt, Germany.
   [Ossorio, O. G.] Univ Valladolid, Dept Elect & Elect, Paseo Belen 15, Valladolid 47011, Spain.
   [Wenger, Ch.] Brandenburg Med Sch Theodor, Fehrbelliner Str 38, D-16816 Neuruppin, Germany.
RP Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informa & Bioingn, I-20133 Milan, Italy.
EM daniele.ielmini@polimi.it
CR [Anonymous], 2013, PROC 30 INT C MACH L
   Burr G. W., 2014, IEDM, DOI 10.1109/IEDM.2014.7047135
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Ielmini D, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/6/063002
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Perez E., T ELECT DEVICE UNPUB
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zambelli C, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MICROELECTRONIC TEST STRUCTURES (ICMTS), P27, DOI 10.1109/ICMTS.2014.6841463
NR 12
TC 5
Z9 5
U1 0
U2 1
PY 2019
BP 174
EP 177
DI 10.1109/essderc.2019.8901818
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Van der Veken, FF
   Azzopardi, G
   Blanc, F
   Coyle, L
   Fol, E
   Giovannozzi, M
   Pieloni, T
   Redaelli, S
   Rivkin, L
   Salvachua, B
   Schenk, M
   Garcia, RT
   Valentino, G
AF Van der Veken, F. F.
   Azzopardi, G.
   Blanc, F.
   Coyle, L.
   Fol, E.
   Giovannozzi, M.
   Pieloni, T.
   Redaelli, S.
   Rivkin, L.
   Salvachua, B.
   Schenk, M.
   Garcia, R. Tomas
   Valentino, G.
BE Lowette, S
TI Application of machine learning techniques at the CERN Large Hadron
   Collider
SO EUROPEAN PHYSICAL SOCIETY CONFERENCE ON HIGH ENERGY PHYSICS, EPS-HEP2019
DT Proceedings Paper
CT European-Physical-Society Conference on High Energy Physics (EPS-HEP)
CY JUL 10-17, 2019
CL Ghent, BELGIUM
AB Machine learning techniques have been used extensively in several domains of Science and Engineering for decades. These powerful tools have been applied also to the domain of high-energy physics, in the analysis of the data from particle collisions, for years already. Accelerator physics, however, has not started exploiting machine learning until very recently. Several activities are flourishing in this domain, in view of providing new insights to beam dynamics in circular accelerators, in different laboratories worldwide. This is, for instance, the case for the CERN Large Hadron Collider, where since a few years exploratory studies are being carried out. A broad range of topics have been addressed, such as anomaly detection of beam position monitors, analysis of optimal correction tools for linear optics, optimisation of the collimation system, lifetime and performance optimisation, and detection of hidden correlations in the huge data set of beam dynamics observables collected during the LHC Run 2. Furthermore, very recently, machine learning techniques are being scrutinised for the advanced analysis of numerical simulations data, in view of improving our models of dynamic aperture evolution.
C1 [Van der Veken, F. F.; Azzopardi, G.; Coyle, L.; Fol, E.; Giovannozzi, M.; Pieloni, T.; Redaelli, S.; Salvachua, B.; Schenk, M.; Garcia, R. Tomas; Valentino, G.] CERN, Beams Dept, CH-1211 Meyrin, Switzerland.
   [Van der Veken, F. F.; Azzopardi, G.; Valentino, G.] Univ Malta, MSD2080, Msida, Malta.
   [Blanc, F.; Coyle, L.; Pieloni, T.; Rivkin, L.; Schenk, M.] Ecole Polytechn Federale Lausanne, CH-1015 Lausanne, Switzerland.
   [Fol, E.] Goethe Univ Frankfurt, D-60323 Frankfurt, Germany.
   [Rivkin, L.] Paul Scherrer Inst, CH-5232 Villigen, Switzerland.
RP Van der Veken, FF (corresponding author), CERN, Beams Dept, CH-1211 Meyrin, Switzerland.; Van der Veken, FF (corresponding author), Univ Malta, MSD2080, Msida, Malta.
EM frederik.van.der.veken@cern.ch
CR Aiba M, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.081002
   Assmann R. W., 2004, P 9 EUR PART ACC C E, P1825
   Azzopardi G, 2019, P 17 INT C ACC LARG
   Azzopardi G., 2019, P 10 INT PART ACC C, P1208
   Azzopardi G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.093001
   Azzopardi G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.083002
   Azzopardi G, 2019, NUCL INSTRUM METH A, V934, P10, DOI 10.1016/j.nima.2019.04.057
   Bazzani A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.104003
   Bozoki E., 1994, P 4 EUR PART ACC C E, P1589
   Bruning O. S., 2004, LHC DESIGN REPORT, DOI DOI 10.5170/CERN-2004-003-V-1
   Calaga R, 2004, PHYS REV SPEC TOP-AC, V7, DOI 10.1103/PhysRevSTAB.7.042801
   Deniau L, MAD METHODICAL ACCEL
   Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507
   Fol E., 2019, P 39 INT FREE EL LAS
   Fol E., 2019, P 10 INT PART ACC C, P2668
   Fol E., 2019, P 10 INT PARTICLE AC, P3990, DOI DOI 10.18429/JACOW-IPAC2019-THPRB077
   Giovannozzi M, 2018, NUCL INSTRUM METH A, V908, P1, DOI 10.1016/j.nima.2018.08.019
   Giovannozzi M, 2018, NUCL INSTRUM METH A, V905, P171, DOI 10.1016/j.nima.2018.07.063
   Ke G., 2017, ADV NEURAL INFORM PR, V30, P3146, DOI DOI 10.5555/3294996.3295074
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Meier E., 2012, P 3 INT PART ACC C I, P2837
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Persson T, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.061002
   Van der Veken F. F., 2018, P 61 ICFA ADV BEAM D, P260
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2020
AR 006
WC Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Lubana, ES
   Dick, RP
   Aggarwal, V
   Pradhan, PM
AF Lubana, Ekdeep Singh
   Dick, Robert P.
   Aggarwal, Vinayak
   Pradhan, Pyari Mohan
GP IEEE
TI MINIMALISTIC IMAGE SIGNAL PROCESSING FOR DEEP LEARNING APPLICATIONS
SO 2019 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP)
SE IEEE International Conference on Image Processing ICIP
DT Proceedings Paper
CT 26th IEEE International Conference on Image Processing (ICIP)
CY SEP 22-25, 2019
CL Taipei, TAIWAN
DE Deep learning accelerators; Image signal processor; RAW images;
   Covariate shift
ID ENERGY
AB In-sensor energy-efficient deep learning accelerators have the potential to enable the use of deep neural networks in embedded vision applications. However, their negative impact on accuracy has been severely underestimated. The inference pipeline used in prior in-sensor deep learning accelerators bypasses the image signal processor (ISP), thereby disrupting the conventional vision pipeline and undermining accuracy of machine learning algorithms trained on conventional, post-ISP datasets. For example, the detection accuracy of an off-the-shelf Faster RCNN algorithm in a vehicle detection scenario reduces by 60%. To make in-sensor accelerators practical, we describe energy-efficient operations that yield most of the benefits of an ISP and reduce covariate shift between the training (ISP processed images) and target (RAW images) distributions. For the vehicle detection problem, our approach improves accuracy by 25-60%. Relative to the conventional ISP pipeline, energy consumption and response time improve by 30% and 34%, respectively.
C1 [Lubana, Ekdeep Singh; Dick, Robert P.] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Lubana, Ekdeep Singh; Aggarwal, Vinayak; Pradhan, Pyari Mohan] Indian Inst Technol, Roorkee, Uttar Pradesh, India.
RP Lubana, ES (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.; Lubana, ES (corresponding author), Indian Inst Technol, Roorkee, Uttar Pradesh, India.
CR Adobe Systems Incorporated, 1998, TECH REP
   Amir MF, 2018, IEEE SENS J, V18, P4187, DOI 10.1109/JSEN.2018.2817632
   Buckler M, 2017, IEEE I CONF COMP VIS, P975, DOI 10.1109/ICCV.2017.111
   Cheng H., 2008, P SPIE SENSORS CAMER, V6816, P1
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gonzalez R. C., 2006, DIGITAL IMAGE PROCES, V3rd
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Kim D., 2017, SENSORS, V17
   Lee K, 2017, SYMP VLSI CIRCUITS, pC294, DOI 10.23919/VLSIC.2017.8008514
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Lubana ES, 2018, IEEE T COMPUT AID D, V37, P2371, DOI 10.1109/TCAD.2018.2858340
   Omid-Zohoor A, 2018, IEEE T CIRC SYST VID, V28, P1102, DOI 10.1109/TCSVT.2017.2653187
NR 12
TC 6
Z9 6
U1 0
U2 2
PY 2019
BP 4165
EP 4169
DI 10.1109/icip.2019.8803645
WC Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT C
AU Unver, HO
   Sener, B
AF Unver, Hakki Ozgur
   Sener, Batihan
BE Longo, F
   Affenzeller, M
   Padovano, A
TI Exploring the Potential of Transfer Learning for Chatter Detection
SO 3RD INTERNATIONAL CONFERENCE ON INDUSTRY 4.0 AND SMART MANUFACTURING
SE Procedia Computer Science
DT Proceedings Paper
CT 3rd International Conference on Industry 4.0 and Smart Manufacturing
   (ISM)
CY NOV 17-19, 2021
CL Upper Austria Univ Appl Sci, Hagenberg Campus, Linz, AUSTRIA
HO Upper Austria Univ Appl Sci, Hagenberg Campus
DE Transfer Learning; Chatter; Machining; Machine Learning
AB Chatter detection and avoidance are indispensable for many industries that rely on the machining process. The physics-based analytical models and recently successful machine learning methods can provide solutions using data from a unique setting. When the primary conditions of machining alter, new data needs to be collected, and analysis/training should be revised. Unfortunately, data collection is time-consuming and expensive for all machine learning applications. Therefore, broader applications of these methods are usually hindered at high production rate machining shops. Transfer learning aims to attenuate this critical barrier of machine learning implementations by transferring knowledge generated from a source domain to a different but related domain. As the concept has immense potential as an accelerator for machine learning applications, it has many prospects in Industry 4.0 framework. This article provides an introduction to transfer learning and briefly overviews its categorizations. Afterward, its potential for chatter detection is explored, and potential strategies are exemplified. Recent studies in the literature within the strategies are briefly presented as well. (C) 2022 The Authors. Published by Elsevier B.V.
C1 [Unver, Hakki Ozgur; Sener, Batihan] TOBB Univ Econ & Technol, Dept Mech Engn, Ankara, Turkey.
RP Unver, HO (corresponding author), TOBB Univ Econ & Technol, Dept Mech Engn, Ankara, Turkey.
EM hounver@etu.edu.tr
CR Altintas Y, 2020, J MANUF SCI E-T ASME, V142, DOI 10.1115/1.4047391
   [Anonymous], 1983, CIRP ANN-MANUF TECHN, DOI DOI 10.1016/S0007-8506(07)63411-8
   Arrazola PJ, 2013, CIRP ANN-MANUF TECHN, V62, P695, DOI 10.1016/j.cirp.2013.05.006
   Budak E, 2006, INT J MACH TOOL MANU, V46, P1489, DOI 10.1016/j.ijmachtools.2005.09.010
   Budak E, 2009, CIRP ANN-MANUF TECHN, V58, P347, DOI 10.1016/j.cirp.2009.03.044
   BudakE Tunc LT, 2012, CIRP ANN, V61, P339
   Cao HR, 2017, INT J ADV MANUF TECH, V92, P4387, DOI 10.1007/s00170-017-0476-x
   Cao HR, 2015, INT J MACH TOOL MANU, V92, P52, DOI 10.1016/j.ijmachtools.2015.03.002
   Cao HR, 2013, INT J MACH TOOL MANU, V69, P11, DOI 10.1016/j.ijmachtools.2013.02.007
   Chen GS, 2018, INT J ADV MANUF TECH, V95, P775, DOI 10.1007/s00170-017-1242-9
   Chen Y, 2019, PRECIS ENG, V56, P235, DOI 10.1016/j.precisioneng.2018.12.004
   Chen Y, 2019, INT J ADV MANUF TECH, V102, P1433, DOI 10.1007/s00170-018-3190-4
   Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009
   Choi T, 2003, J MANUF SCI E-T ASME, V125, P21, DOI 10.1115/1.1531113
   Navas CFE, 2021, PROCEDIA COMPUT SCI, V180, P69, DOI 10.1016/j.procs.2021.01.130
   Feng J, 2018, INT J MACH TOOL MANU, V134, P1, DOI 10.1016/j.ijmachtools.2018.06.001
   Fu Y, 2019, J INTELL MANUF, V30, P995, DOI 10.1007/s10845-017-1302-x
   Fu Y, 2016, MECH SYST SIGNAL PR, V75, P668, DOI 10.1016/j.ymssp.2016.01.003
   GoldmanCV BaltaxeM, PROCEDIA COMPUTER SC, V180, P259
   Lamraoui M, 2015, J VIB CONTROL, V21, P1251, DOI 10.1177/1077546313493919
   Lee DG., 1988, CIRP ANN-MANUF TECHN, V37, P365, DOI [10.1016/S0007-8506(07)61655-2, DOI 10.1016/S0007-8506(07)61655-2]
   Liu CF, 2018, MECH SYST SIGNAL PR, V105, P169, DOI 10.1016/j.ymssp.2017.11.046
   Liu CQ, 2018, J INTELL MANUF, V29, P1739, DOI 10.1007/s10845-016-1209-y
   Oleaga I, 2018, MEASUREMENT, V128, P34, DOI 10.1016/j.measurement.2018.06.028
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Postel M, 2020, INT J ADV MANUF TECH, V107, P4123, DOI 10.1007/s00170-020-05322-w
   Tlusty G, 1999, MANUFACTURING PROCES
   Tunç LT, 2012, INT J MACH TOOL MANU, V57, P10, DOI 10.1016/j.ijmachtools.2012.01.009
   Yao ZH, 2010, J MATER PROCESS TECH, V210, P713, DOI 10.1016/j.jmatprotec.2009.11.007
   Yesilli MC, 2020, CIRP J MANUF SCI TEC, V28, P118, DOI 10.1016/j.cirpj.2019.11.003
   Yesilyurt I, 2007, INT J PROD RES, V45, P1013, DOI 10.1080/00207540600677781
NR 31
TC 4
Z9 4
U1 5
U2 13
PY 2022
VL 200
BP 151
EP 159
DI 10.1016/j.procs.2022.01.214
EA MAR 2022
WC Computer Science, Theory & Methods; Engineering, Industrial;
   Engineering, Manufacturing
DA 2023-11-11
ER

PT C
AU Wang, KN
   Zhu, YX
   Chen, CZ
AF Wang, Kainan
   Zhu, Yingxuan
   Chen, C-Z
BE Claeys, C
   Liang, S
   Lin, Q
   Huang, R
   Wu, H
   Song, P
   Lai, K
   Zhang, Y
   Zang, B
   Qu, X
   Lung, HL
   Yu, W
TI Perceptron Algorithm and Its Verilog Design
SO 2020 CHINA SEMICONDUCTOR TECHNOLOGY INTERNATIONAL CONFERENCE 2020 (CSTIC
   2020)
DT Proceedings Paper
CT China Semiconductor Technology International Conference (CSTIC)
CY JUN 29-JUL 17, 2020
CL ELECTR NETWORK
DE Perceptron; Verilog; hardware design; machine learning; ANN; CNN
ID ACCELERATOR
AB In artificial neural network (ANN), the basic perceptron algorithm plays a significant role in supervised machine learning due to its simple structure. Though it cannot solve some non-linear problems like XOR, however, this feature offers a possibility to build perceptron on a hardware design. Due to high efficiency and defect tolerant, researchers have proposed some ANN accelerators with complicated memory units and specific registers. In this work, we focus on a simplest perceptron and accomplish its hardware design using Verilog HDL. The design module includes one core for learning and four memory units for storing the training data. The study shows that the proximate floating-point simulation of the simple perceptron design can replace the defect-tolerant registers and the simple memory units, thus to make the accelerator a tiny scale, it also demonstrates that the accuracy rate on test set achieved at 98% and the total area cost is only 0.0078 mm(2).
C1 [Wang, Kainan; Zhu, Yingxuan] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.
   [Wang, Kainan; Zhu, Yingxuan; Chen, C-Z] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
   [Chen, C-Z] EtownIP Microelect, Beijing 100176, Peoples R China.
RP Wang, KN (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.; Wang, KN (corresponding author), Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
EM wangkainan@iie.ac.cn
CR [Anonymous], 2013, PROC 30 INT C MACH L
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Holler M., 1990, FLOATING GATE SYNAPS
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   MAUDUIT N, 1992, IEEE T NEURAL NETWOR, V3, P414, DOI 10.1109/72.129414
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/cstic49141.2020.9282536
WC Computer Science, Hardware & Architecture; Engineering, Manufacturing;
   Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Materials Science, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Syafalni, I
   Firdaus, MI
   Ilmy, AMR
   Sutisna, N
   Adiono, T
AF Syafalni, Infall
   Firdaus, Mohamad Imam
   Ilmy, Andi M. Riyadhus
   Sutisna, Nana
   Adiono, Trio
GP IEEE
TI MazeCov-Q: An Efficient Maze-Based Reinforcement Learning Accelerator
   for Coverage
SO 2023 IEEE SYMPOSIUM IN LOW-POWER AND HIGH-SPEED CHIPS, COOL CHIPS
SE Proceedings for IEEE COOL CHIPS
DT Proceedings Paper
CT 26th IEEE International Symposium on Low-Power and High-Speed Chips
   (COOL CHIPS)
CY APR 19-21, 2023
CL Univ Tokyo, Tokyo, JAPAN
HO Univ Tokyo
AB Reinforcement learning (RL) is an unsupervised machine learning that does not requires pre-assigned labeled data to learn. It is implemented in many areas such as robotics, games, finances, health, transportation, and energy applications. In this paper, we present an application of reinforcement learning accelerator for finding coverage area and its implementation in a mobile robot called MazeCov-Q (Maze-Based Coverage Q-Learning). We define a novel state that is divided into two conditions. The conditions are directions and visit counters for the Q-value calculation. The experimental results show that our MazeCov-Q achieves more than 74% path efficiency on average. Moreover, our coverage-based Q-learning accelerator (MazeCov-Q) achieves 48.3 Mps and 169.05 Mps for 50 Mhz Pynq Z1 and 175 MHz ZCU104 boards, respectively. This research is useful for surveillance, resource allocation, environmental monitoring, and autonomous navigation.
C1 [Syafalni, Infall; Sutisna, Nana; Adiono, Trio] Bandung Inst Technol, Sch Elect Engn & Informat, Bandung, Indonesia.
   [Syafalni, Infall; Firdaus, Mohamad Imam; Ilmy, Andi M. Riyadhus; Sutisna, Nana; Adiono, Trio] Bandung Inst Technol, Univ Ctr Excellence Microelect, Bandung, Indonesia.
RP Syafalni, I (corresponding author), Bandung Inst Technol, Univ Ctr Excellence Microelect, Bandung, Indonesia.
EM infall@ieee.org
CR Hassan M, 2020, IEEE T ROBOT, V36, P284, DOI 10.1109/TRO.2019.2946891
   Meng Y, 2020, IEEE SYM PARA DISTR, P107, DOI 10.1109/IPDPSW50202.2020.00024
   Piardi L, 2019, AIP CONF PROC, V2116, DOI 10.1063/1.5114220
   Rothmann M, 2022, IEEE INT CONF ASAP, P106, DOI 10.1109/ASAP54787.2022.00026
   Roughgarden T., 2022, ALGORITHMS ILLUMIN 4
   Samir M, 2021, IEEE T MOBILE COMPUT, V20, P2835, DOI 10.1109/TMC.2020.2991326
   Senthurbavan K., 2020, 2020 AUSTRALASIAN C
   Song Y, 2012, INT J CONTROL AUTOM, V10, P166, DOI 10.1007/s12555-012-0119-9
   Sutisna N, 2023, IEEE ACCESS, V11, P144, DOI 10.1109/ACCESS.2022.3232853
   Syafalni I., 2022, 2022 INT S ELECT SMA, P1, DOI [10.1109/ISESD56103.2022.9980709, DOI 10.1109/ISESD56103.2022.9980709]
   Syafalni I., 2022, 2022 8 INT C WIRELES, P1, DOI [10.1109/ICWT55831.2022.9935386, DOI 10.1109/ICWT55831.2022.9935386]
   Wu SG, 2023, IEEE T IND INFORM, V19, P121, DOI 10.1109/TII.2022.3160629
   Xiao J, 2020, IEEE ACCESS, V8, P33511, DOI 10.1109/ACCESS.2020.2967225
   Zhang MY, 2023, IEEE ACCESS, V11, P29673, DOI 10.1109/ACCESS.2023.3255007
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/COOLCHIPS57690.2023.10122120
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Hussain, SU
   Rouhani, BD
   Ghasemzadeh, M
   Koushanfar, F
AF Hussain, Siam U.
   Rouhani, Bita Darvish
   Ghasemzadeh, Mohammad
   Koushanfar, Farinaz
GP IEEE
TI MAXelerator: FPGA Accelerator for Privacy Preserving Multiply-Accumulate
   (MAC) on Cloud Servers
SO 2018 55TH ACM/ESDA/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 55th ACM/ESDA/IEEE Design Automation Conference (DAC)
CY JUN 24-28, 2018
CL San Francisco, CA
DE Garbled Circuit; Privacy-preserving computation; Data mining; Secure
   machine learning; Deep learning
AB This paper presents MAXelerator, the first hardware accelerator for privacy-preserving machine learning (ML) on cloud servers. Cloud-based ML is being increasingly employed in various data sensitive scenarios. While it enhances both efficiency and quality of the service, it also raises concern about privacy of the users' data. We create a practical privacy-preserving solution for matrix-based ML on cloud servers. We show that for the majority of the ML applications, the privacy-sensitive computation boils down to either matrix multiplication, which is a repetition of Multiply-Accumulate (MAC) or the MAC itself We design an FPGA architecture for privacy-preserving MAC to accelerate the ML computation based on the well known Secure Function Evaluation protocol named Yao's Garbled Circuit. MAXelerator demonstrates up to 57x improvement in throughput per core compared to the fastest existing GC framework. We corroborate the effectiveness of the accelerator with real-world case studies in privacy-sensitive scenarios.
C1 [Hussain, Siam U.; Rouhani, Bita Darvish; Ghasemzadeh, Mohammad; Koushanfar, Farinaz] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
RP Hussain, SU (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM siamumar@ucsd.edu; bita@ucsd.edu; mghasemzadeh@ucsd.edu;
   farinaz@ucsd.edu
CR [Anonymous], J MACHINE LEARNING R
   [Anonymous], PORTFOLIO RISK ANAL
   [Anonymous], INT J RECONFIG COMPU
   Bellare M., 2013, S S P
   Brant A., 2012, FIELD PROGRAMMABLE C
   Deng L., 2014, FDN TRENDS SIGNAL PR, V7
   Fang X., 2017, FPGA
   Fowlkes C., 2004, T PATTERN ANAL MACHI
   Husted N., 2013, COMP SEC APPL C 2007
   Ishai Y., 2003, CRYPTO, V2729
   Jones N., 2014, NATURE, V505
   Kerschbaum F., 2014, INT C APPL CRYPT NET
   Kirk Jeremy, 2016, IBM JOIN FORCES BUIL
   Kolesnikov V., 2008, AUTOMATA LANGUAGES P
   Krcmar H., 2014, TRUSTED CLOUD COMPUT
   Naor M., 2005, J CRYPTOLOGY, V18
   Naor M., 1999, C EL COMM
   Nikolaenko V., 2013, S S P
   Nikolaenko V., 2013, C COMP COMM SEC
   Pu S., 2011, IACR CRYPTOLOGY EPRI
   Rouhani B. D., 2017, DAC
   Rouhani B. D., 2016, TRETS, V10
   Song Z., 2017, ARXIV170907776
   Songhori E. M., 2015, S S P
   Songhori E. M., 2016, DES AUT C
   Varela J. A., 2017, INT WORKSH OPENCL
   Wang X. S., 2014, CCS
   Wang X. S., 2016, ESORICS
   Yao Andrew Chi-Chih, 1986, ANN S FDN COMP SCI
   Zahur S., 2015, 2 HALVES MAKE WHOLE
NR 30
TC 3
Z9 3
U1 0
U2 2
PY 2018
DI 10.1145/3195970.3196074
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Santos, ACF
   Fonseca, P
   Coelho, LFS
AF Santos, A. C. F.
   Fonseca, P.
   Coelho, L. F. S.
BE McDaniel, FD
   Doyle, BL
TI Can Accelerators Accelerate Learning?
SO APPLICATION OF ACCELERATORS IN RESEARCH AND INDUSTRY
SE AIP Conference Proceedings
DT Proceedings Paper
CT 20th International Conference on Application of Accelerators in Research
   and Industry
CY AUG 10-15, 2008
CL Ft Worth, TX
DE accelerators; teaching
AB The 'Young Talented' education program developed by the Brazilian State Funding Agency (FAPERJ) [1] makes it possible for high-schools students from public high schools to perform activities in scientific laboratories. In the Atomic and Molecular Physics Laboratory at Federal University of Rio de Janeiro (UFRJ), the students are confronted with modem research tools like the 1.7 MV ion accelerator. Being a user-friendly machine, the accelerator is easily manageable by the students, who can perform simple hands-on activities, stimulating interest in physics, and getting the students close to modem laboratory techniques.
C1 [Santos, A. C. F.; Fonseca, P.; Coelho, L. F. S.] Univ Fed Rio de Janeiro, Inst Fis, BR-21941972 Rio De Janeiro, RJ, Brazil.
RP Santos, ACF (corresponding author), Univ Fed Rio de Janeiro, Inst Fis, Caixa Postal 68528, BR-21941972 Rio De Janeiro, RJ, Brazil.
CR DAHL DA, 1995, SIMION 3D VERSION 7
   JOHANSSON KE, 2006, PHYS EDUC, V41, P251
   MANOS H, 1989, AM J PHYS, V57, P139, DOI 10.1119/1.16111
   Santos ACF, 2007, NUCL INSTRUM METH B, V261, P264, DOI 10.1016/j.nimb.2007.03.091
   Sinflorio D. A., 2006, Physics Education, V41, P539, DOI 10.1088/0031-9120/41/6/008
NR 5
TC 0
Z9 0
U1 0
U2 1
PY 2009
VL 1099
BP 211
EP 213
WC Physics, Applied; Spectroscopy
DA 2023-11-11
ER

PT C
AU Cheng, SY
   Chung, CP
   Lai, R
   Lee, JK
AF Cheng, Sheng-Yuan
   Chung, Chun-Ping
   Lai, Robert
   Lee, Jenq-Kuen
GP ACM
TI Application Showcases for TVM with NeuroPilot on Mobile Devices
SO 51ST INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING WORKSHOPS
   PROCEEDINGS, ICPP 2022
SE International Conference on Parallel Processing Workshops
DT Proceedings Paper
CT 51st International Conference on Parallel Processing (ICPP)
CY AUG 29-SEP 01, 2022
CL ELECTR NETWORK
DE TVM; NeuroPilot; Relay IR; Deep Learning; Inference; Pipeline
AB With the increasing demand for machine learning inference on mobile devices, more platforms are emerging to provide AI inferences on mobile devices. One of the popular ones is TVM, which is an end-to-end AI compiler. The major drawback is TVM doesn't support all manufacturer-supplied accelerators. On the other hand, an AI solution for MediaTek's platform, NeuroPilot, offers inference on mobile devices with high performance. Nevertheless, NeuroPilot does not support all of the common machine learning frameworks. Therefore, we want to take advantage of both sides. This way, the solution could accept a variety of machine learning frameworks, including Tensorflow, Pytorch, ONNX, and MxNet and utilize the AI accelerator from MediaTek. We adopt the TVM BYOC flow to implement the solution. In order to illustrate the ability to accept different machine learning frameworks for different tasks, we used three different models to build an application showcase in this work: the face anti-spoofing model from PyTorch, the emotion detection model from Keras, and the object detection model from Tflite. Since these models have dependencies while running inference, we propose a prototype of pipeline algorithm to improve the inference performance of the application showcase.
C1 [Cheng, Sheng-Yuan; Chung, Chun-Ping; Lee, Jenq-Kuen] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Lai, Robert] Mediatek Inc, Hsinchu, Taiwan.
RP Cheng, SY (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM sycheng@pllab.cs.nthu.edu.tw; cpchung@pllab.cs.nthu.edu.tw;
   Robert.Lai@mediatek.com; jklee@cs.nthu.edu.tw
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Chang YM, 2021, J SUPERCOMPUT, V77, P10065, DOI 10.1007/s11227-021-03625-7
   Chen TL, 2021, J SUPERCOMPUT, V77, P8622, DOI 10.1007/s11227-021-03631-9
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TC, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P167, DOI [10.1109/AICAS.2019.8771536, 10.1109/aicas.2019.8771536]
   Demidovskij A, 2019, IEEE INT CONF COMP V, P783, DOI 10.1109/ICCVW.2019.00104
   George Anjith, 2019, 2019 INT C BIOM ICB, P1
   Huang HR, 2021, INT PARALL DISTRIB P, P1035, DOI 10.1109/IPDPS49936.2021.00112
   Hubara I, 2018, J MACH LEARN RES, V18
   keras team, HOM KER DOC
   Lai Ming-Yi, 2020, 49 INT C PAR PROC IC, P1
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Liu PF, 2019, 2019 SEVENTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING WORKSHOPS (CANDARW 2019), P141, DOI 10.1109/CANDARW.2019.00033
   ONNX, ONNX HOM ONNX
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Redmon J., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.02767
   Roesch J, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P58, DOI 10.1145/3211346.3211348
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2022
AR 11
DI 10.1145/3547276.3548514
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Chen, TB
   Yin, SY
   Ouyang, P
   Tu, FB
   Liu, LB
   Wei, SJ
AF Chen, Tianbao
   Yin, Shouyi
   Ouyang, Peng
   Tu, Fengbin
   Liu, Leibo
   Wei, Shaojun
GP IEEE
TI A Novel Hardware Accelerator Guideline for ANN with High Performance
SO 2016 5TH INTERNATIONAL SYMPOSIUM ON NEXT-GENERATION ELECTRONICS (ISNE)
SE International Symposium on Next-Generation Electronics
DT Proceedings Paper
CT 5th International Symposium on Next-Generation Electronics (ISNE)
CY MAY 03-06, 2016
CL Natl Tsing Hua Univ, Hsinchu, TAIWAN
HO Natl Tsing Hua Univ
DE ANN; Hardware Accelerator; Design guideline
AB Artificial Neural Network (ANN) is widely used in machine learning and artificial intelligence areas. But ANN requires a long running time and induces a high power consumption when running on a GPU or CPU which may hinder its application in embedded system. This paper proposes a hardware accelerator design guideline for ANN with arbitrary scales and depths. We take full consideration of the hardware scale, performance and power consumption.
C1 [Chen, Tianbao; Yin, Shouyi; Ouyang, Peng; Tu, Fengbin; Liu, Leibo; Wei, Shaojun] Tsinghua Univ, Inst Microelect, Room 3-330,Bldg Fit, Beijing, Peoples R China.
RP Chen, TB (corresponding author), Tsinghua Univ, Inst Microelect, Room 3-330,Bldg Fit, Beijing, Peoples R China.
EM ctb13@mails.tsinghua.edu.cn
CR [Anonymous], 2014, TENCON 2014 2014 IEE
   Domingos P. O., 2005, Proceedings. 2005 International Conference on Field Programmable Logic and Applications (IEEE Cat. No.05EX1155), P89
   Esmaeilzadeh H., MICR MICRO 2012 45 A, V33, P16
   Lingbo Kou, 2014, 2014 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P214, DOI 10.1109/ISVLSI.2014.73
   Pietras M., 2014, PROC 24 INT C FIELD, P1
NR 5
TC 0
Z9 0
U1 1
U2 4
PY 2016
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lawson, J
AF Lawson, John
GP IEEE Computer Soc
TI Towards automated kernel selection in machine learning systems: A SYCL
   case study
SO 2020 IEEE 34TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2020)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 34th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 18-22, 2020
CL ELECTR NETWORK
DE Auto-tuning; SYCL; GPGPU; Machine learning
AB Automated tuning of compute kernels is a popular area of research, mainly focused on finding optimal kernel parameters for a problem with fixed input sizes. This approach is good for deploying machine learning models, where the network topology is constant, but machine learning research often involves changing network topologies and hyperparameters. Traditional kernel auto-tuning has limited impact in this case; a more general selection of kernels is required for libraries to accelerate machine learning research.
   In this paper we present initial results using machine learning to select kernels in a case study deploying high performance SYCL kernels in libraries that target a range of heterogeneous devices from desktop GPUs to embedded accelerators. The techniques investigated apply more generally and could similarly be integrated with other heterogeneous programming systems. By combining auto-tuning and machine learning these kernel selection processes can be deployed with little developer effort to achieve high performance on new hardware.
C1 [Lawson, John] Codeplay Software Ltd, Edinburgh, Midlothian, Scotland.
RP Lawson, J (corresponding author), Codeplay Software Ltd, Edinburgh, Midlothian, Scotland.
EM john@codeplay.com
CR [Anonymous], 2012, 2012 INNOVATIVE PARA, DOI DOI 10.1109/INPAR.2012.6339587
   [Anonymous], SINGL SOURC HET PROG
   Burns R, 2019, PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19), DOI 10.1145/3318170.3318183
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Codeplay Software Ltd, HET SYST EXP
   Falch TL, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P1231, DOI 10.1109/IPDPSW.2015.85
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Li YN, 2009, LECT NOTES COMPUT SC, V5544, P884
   Mametjanov A, 2012, IEEE INT C CL COMP, P266, DOI 10.1109/CLUSTER.2012.46
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Nugteren C, 2018, IWOCL'18: PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL, P22, DOI 10.1145/3204919.3204924
   Nugteren C, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P195, DOI 10.1109/MCSoC.2015.10
   Nukada A, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   van Werkhoven B, 2019, FUTURE GENER COMP SY, V90, P347, DOI 10.1016/j.future.2018.08.004
   van Werkhovena B, 2014, FUTURE GENER COMP SY, V30, P14, DOI 10.1016/j.future.2013.09.003
   Zhang Y., 2012, INORGCHEM IND, V44, P12
NR 21
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 475
EP 478
DI 10.1109/IPDPSW50202.2020.00086
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Masadeh, M
   Elderhalli, Y
   Hasan, O
   Tahar, S
AF Masadeh, Mahmoud
   Elderhalli, Yassmeen
   Hasan, Osman
   Tahar, Sofiene
TI A Quality-assured Approximate Hardware Accelerators-based on Machine
   Learning and Dynamic Partial Reconfiguration
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Approximate computing; approximate hardware accelerator; decision tree;
   input-aware approximation; dynamic partial reconfiguration; adaptive
   design; FPGA
ID DESIGN
AB Machine learning is widely used these days to extract meaningful information out of the Zettabytes of sensors data collected daily. All applications require analyzing and understanding the data to identify trends, e.g., surveillance, exhibit some error tolerance. Approximate computing has emerged as an energy-efficient design paradigm aiming to take advantage of the intrinsic error resilience in a wide set of error-tolerant applications. Thus, inexact results could reduce power consumption, delay, area, and execution time. To increase the energy-efficiency of machine learning on FPGA, we consider approximation at the hardware level, e.g., approximate multipliers. However, errors in approximate computing heavily depend on the application, the applied inputs, and user preferences. However, dynamic partial reconfiguration has been introduced, as a key differentiating capability in recent FPGAs, to significantly reduce design area, power consumption, and reconfiguration time by adaptively changing a selective part of the FPGA design without interrupting the remaining system. Thus, integrating "Dynamic Partial Reconfiguration" (DPR) with "Approximate Computing" (AC) will significantly ameliorate the efficiency of FPGA-based design approximation. In this article, we propose hardware-efficient quality-controlled approximate accelerators, which are suitable to be implemented in FPGA-based machine learning algorithms as well as any error-resilient applications. Experimental results using three case studies of image blending, audio blending, and image filtering applications demonstrate that the proposed adaptive approximate accelerator satisfies the required quality with an accuracy of 81.82%, 80.4%, and 89.4%, respectively. On average, the partial bitstream was found to be 28.6x smaller than the full bitstream.
C1 [Masadeh, Mahmoud; Elderhalli, Yassmeen; Hasan, Osman; Tahar, Sofiene] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
   [Masadeh, Mahmoud] Yarmouk Univ, Comp Engn Dept, Irbid 21163, Jordan.
RP Masadeh, M (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.; Masadeh, M (corresponding author), Yarmouk Univ, Comp Engn Dept, Irbid 21163, Jordan.
CR Agrawal A., 2016, P IEEE INT C REB COM, P1, DOI DOI 10.1109/ICRC.2016.7738674
   Akbari O, 2017, IEEE T VLSI SYST, V25, P1352, DOI 10.1109/TVLSI.2016.2643003
   Alaghi A, 2018, IEEE SPECTRUM, V55, P46, DOI 10.1109/MSPEC.2018.8302387
   Almurib HAF, 2016, DES AUT TEST EUROPE, P660
   [Anonymous], 2020, IEEE INT SYSTEMS C S, P1
   [Anonymous], 2019, R PROJECT STAT COMPU
   [Anonymous], 2013, PARTIAL RECONFIGURAT
   [Anonymous], 2020, VIVADO DESIGN SUITE
   [Anonymous], 2020, BBC SOUND EFFECTS
   [Anonymous], 2020, AXI HWICAP V3 0 LOGI
   [Anonymous], 2020, 7 SERIES FPGAS DATA
   [Anonymous], 2019, VC707 EVALUATION BOA
   [Anonymous], 2019, XILINX PARTIAL RECON
   [Anonymous], 2019, VIVADO DESIGN SUITE
   Ashok P, 2019, LECT NOTES COMPUT SC, V11785, P147, DOI 10.1007/978-3-030-30281-8_9
   Baek W, 2010, PLDI '10: PROCEEDINGS OF THE 2010 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P198, DOI 10.1145/1806596.1806620
   Barni M., 2006, DOCUMENT IMAGE COMPR
   Breiman L., 1984, BIOMETRICS, P357
   Chan WTJ, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P47, DOI 10.1109/ICCD.2013.6657024
   Chang IJ, 2011, IEEE T CIRC SYST VID, V21, P101, DOI 10.1109/TCSVT.2011.2105550
   Chen X, 2017, IEEE WORKS SIG POW, DOI 10.1109/ULTSYM.2017.8092497
   Chu P., 2008, FPGA PROTOTYPING VHD
   Dede G, 2010, DIGIT SIGNAL PROCESS, V20, P763, DOI 10.1016/j.dsp.2009.10.004
   Frady EP, 2019, P NATL ACAD SCI USA, V116, P18050, DOI 10.1073/pnas.1902653116
   Gao MZ, 2020, IEEE T COMPUT AID D, V39, P335, DOI 10.1109/TCAD.2018.2889662
   Garcia S, 2015, INTEL SYST REF LIBR, V72, P1, DOI 10.1007/978-3-319-10247-4
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grigorian B, 2015, INT S HIGH PERF COMP, P615, DOI 10.1109/HPCA.2015.7056067
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Herbordt MC, 2007, COMPUTER, V40, P50, DOI 10.1109/MC.2007.79
   Hoang RV, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00019
   Jiang H., 2015, P GREAT LAK S VLSI U, P343
   Karunaratne G, 2020, NAT ELECTRON, V3, P327, DOI 10.1038/s41928-020-0410-3
   Khudia DS, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P554, DOI 10.1145/2749469.2750371
   Khudia DS, 2016, IEEE DES TEST, V33, P43, DOI 10.1109/MDAT.2015.2501306
   Kim M., 2016, ARXIVCSLG160106071
   Kim M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P701, DOI 10.1109/ICASSP.2018.8461824
   Kleyko D., 2017, ABS170600280 CORR
   Kleyko D, 2021, IEEE T NEUR NET LEAR, V32, P3777, DOI 10.1109/TNNLS.2020.3015971
   Koch D., 2012, PARTIAL RECONFIGURAT
   Krill B, 2010, SIGNAL PROCESS-IMAGE, V25, P377, DOI 10.1016/j.image.2010.04.005
   Laurenzano MA, 2016, ACM SIGPLAN NOTICES, V51, P161, DOI [10.1145/2980983.2908087, 10.1145/2908080.2908087]
   Lee VT, 2017, DES AUT TEST EUROPE, P13, DOI 10.23919/DATE.2017.7926951
   Masadeh M., 2019, ABS190801343 CORR
   Masadeh M, 2020, INT SYSTEMS C SYSCON, P1
   Masadeh M, 2021, IEEE T VLSI SYST, V29, P800, DOI 10.1109/TVLSI.2021.3056243
   Masadeh M, 2019, IEEE ACCESS, V7, P147129, DOI 10.1109/ACCESS.2019.2946513
   Masadeh M, 2019, DES AUT TEST EUROPE, P1575, DOI [10.23919/date.2019.8714957, 10.23919/DATE.2019.8714957]
   Masadeh M, 2018, PR GR LAK SYMP VLSI, P415, DOI 10.1145/3194554.3194626
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mohapatra D, 2011, DES AUT TEST EUROPE, P950
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Nakahara H, 2015, I C FIELD PROG LOGIC
   Nguyen M, 2019, I C FIELD PROG LOGIC, P129, DOI 10.1109/FPL.2019.00029
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A., 2020, MODELING SHAPE SCENE
   Orlandic M., 2018, J REAL-TIME IMAGE PR, V16, P1
   [庞素琳 PANG Su-lin], 2009, [系统工程理论与实践, Systems Engineering-Theory & Practice], V29, P94, DOI 10.1016/S1874-8651(10)60092-0
   Papadimitriou K, 2011, ACM T RECONFIG TECHN, V4, DOI 10.1145/2068716.2068722
   Pirkl J., 2017, SCOPES, P89
   Quan W, 2016, J SYST ARCHITECT, V62, P12, DOI 10.1016/j.sysarc.2015.11.004
   Raha A, 2016, IEEE T VLSI SYST, V24, P846, DOI 10.1109/TVLSI.2015.2424212
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Shalev-Schwartz Ben-David S., 2014, UNDERSTANDING MACHIN
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Solomon C., 2011, FUNDAMENTALS DIGITAL
   The MathWorks Inc, 2018, MATLAB HDL COD TOOLB
   The MathWorks Inc., 2018, MATLAB CLASS LEARN T
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3195996
   Venkataramani S, 2015, DES AUT CON, DOI 10.1145/2744769.2744904
   Vipin K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3193827
   Wang T, 2016, I SYMPOS LOW POWER E, P156, DOI 10.1145/2934583.2934608
   Wright CD, 2013, ADV FUNCT MATER, V23, P2248, DOI 10.1002/adfm.201202383
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
   Xu S, 2019, IEEE T VLSI SYST, V27, P778, DOI 10.1109/TVLSI.2018.2884848
   Xu SY, 2017, PR IEEE COMP DESIGN, P113, DOI 10.1109/ICCD.2017.25
NR 79
TC 2
Z9 2
U1 3
U2 7
PD OCT
PY 2021
VL 17
IS 4
AR 57
DI 10.1145/3462329
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Kumar, A
   Talawar, B
AF Kumar, Anil
   Talawar, Basavaraj
TI Knowledgeable network-on-chip accelerator for fast and accurate
   simulations using supervised learning algorithms and multiprocessing
SO INTERNATIONAL JOURNAL OF INTELLIGENT ENGINEERING INFORMATICS
DT Article
DE NoC; network-on-chip; Floorplan; performance modelling; simulation;
   machine learning; prediction; regression; decision tree; Booksim;
   performance evaluation; power; area; router; traffic pattern
ID DESIGN; NOC
AB In a multi-processor system-on-chip (MPSoC) environment, networkson-chip (NoC) is becoming the de-facto scaling communication technique. One of the most significant techniques used in NoC for analysing and testing new architectures is simulations. Simulation is one of the main tools used in NoC for analysing and testing new architectures. To achieve the best performance vs. cost tradeoff, simulators have become an essential tool. Software simulators are too slow for evaluating large-scale NoCs. To overcome this problem we propose an NoC Accelerator named knowledgeable network-on-chip accelerator (KNoC) which can be used to analyse various NoC architectures. The proposed accelerator is built using machine learning (ML) algorithms and multiprocessing to predict the design parameters of NoCs with a fixed and accurate delay between nodes of large-scale architectures. The KNoC results were compared to the widely used cycle-accurate Booksim simulator. KNoC showed an error rate of less than 6% and an overall speedup of up to 12 Kx.
C1 [Kumar, Anil; Talawar, Basavaraj] Natl Inst Technol Karnataka Surathkal, Dept Comp Sci & Engn, Mangalore 575025, India.
RP Kumar, A (corresponding author), Natl Inst Technol Karnataka Surathkal, Dept Comp Sci & Engn, Mangalore 575025, India.
EM anilkumar.cs14f05@nitk.edu.in; basavaraj@nitk.edu.in
CR Aarti, 2019, INT J INTELL ENG INF, V7, P231
   Agarwal N, 2009, INT SYM PERFORM ANAL, P33, DOI 10.1109/ISPASS.2009.4919636
   Angepat H., 2014, SYNTHESIS LECT COMPU, V9, P1, DOI 10.2200/S00586ED1V01Y201407CAC029
   [Anonymous], 2010, P 3 INT WORKSH NETW, DOI DOI 10.1145/1921249.1921254
   Arora I, 2018, INT J INTELL ENG INF, V6, P356, DOI 10.1504/IJIEI.2018.091870
   Boraten T., 2016, INT SYMP MICROARCH, P1, DOI 10.1109/MICRO.2016.7783734
   Borkar S, 2007, DES AUT CON, P746, DOI 10.1109/DAC.2007.375263
   Carloni LP, 2010, IEEE T VLSI SYST, V18, P679, DOI 10.1109/TVLSI.2009.2014772
   Catania V, 2015, IEEE INT CONF ASAP, P162, DOI 10.1109/ASAP.2015.7245728
   Chen Sun, 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P201, DOI 10.1109/NOCS.2012.31
   Clark M, 2018, DES AUT CON, DOI 10.1145/3195970.3196068
   Dally WJ, 2001, DES AUT CON, P684, DOI 10.1109/DAC.2001.935594
   DiTomaso D, 2017, DES AUT TEST EUROPE, P1354, DOI 10.23919/DATE.2017.7927203
   Ebrahimi M., 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P19, DOI 10.1109/NOCS.2012.10
   Farahnakian F, 2014, MICROPROCESS MICROSY, V38, P64, DOI 10.1016/j.micpro.2013.11.008
   Farahnakian F, 2012, 2012 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS (SAMOS): ARCHITECTURES, MODELING AND SIMULATION, P236, DOI 10.1109/SAMOS.2012.6404180
   FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176
   Fettes Q, 2019, IEEE T COMPUT, V68, P375, DOI 10.1109/TC.2018.2875476
   Halavar B., 2018, 2018 IEEE INT C ELEC, P1
   Hemani A., 2000, P IEEE NORCHIP C, P166
   Jain L., 2007, WORKSH DIAGN SERV NE, P16
   Jeong K, 2009, 2009 INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC 2009), P53, DOI 10.1109/SOCDC.2009.5423853
   Jeong K, 2010, IEEE EMBED SYST LETT, V2, P62, DOI 10.1109/LES.2010.2051413
   Jiang N., 2013, INT S PERFORMANCE AN, P86, DOI 10.1109/ISPASS.2013.6557149
   Jin YH, 2012, IEEE T PARALL DISTR, V23, P242, DOI 10.1109/TPDS.2011.164
   Kahng Andrew B., 2010, 2010 15th Asia and South Pacific Design Automation Conference (ASP-DAC 2010), P241, DOI 10.1109/ASPDAC.2010.5419887
   Kahng AB, 2012, IEEE T VLSI SYST, V20, P191, DOI 10.1109/TVLSI.2010.2091686
   Kim RG, 2018, COMPUTER, V51, P66, DOI 10.1109/MC.2018.3011040
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kumar A, 2018, WIRELESS PERS COMMUN, V102, P2211, DOI 10.1007/s11277-018-5376-3
   Kumari A, 2019, INT J INTELL ENG INF, V7, P457, DOI 10.1504/IJIEI.2019.103626
   Kurian G, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P477, DOI 10.1145/1854273.1854332
   Leung L.F., 2007, THESIS
   Lewis R.J., 2000, ANN M SOC AC EM MED
   Loh WY, 2002, STAT SINICA, V12, P361
   McKerns MM, 2012, Arxiv, DOI arXiv:1202.1056
   Mahmoud H, 2018, INT J INTELL ENG INF, V6, P509, DOI 10.1504/IJIEI.2018.10017812
   Mirza-Aghatabar M, 2007, DSD 2007: 10TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN ARCHITECTURES, METHODS AND TOOLS, PROCEEDINGS, P19, DOI 10.1109/DSD.2007.4341445
   Nagwanshi KK, 2020, INT J INTELL ENG INF, V8, P117
   nocs.stanford, BOOKSIM2 0
   Pande PP, 2005, IEEE T COMPUT, V54, P1025, DOI 10.1109/TC.2005.134
   Pinto A., 2007, METHODOLOGY OPEN SOF
   Puente V, 2002, 10TH EUROMICRO WORKSHOP ON PARALLEL, DISTRIBUTED AND NETWORK-BASED PROCESSING, PROCEEDINGS, P15, DOI 10.1109/EMPDP.2002.994207
   Qian ZL, 2016, IEEE T COMPUT AID D, V35, P471, DOI 10.1109/TCAD.2015.2474393
   Qian ZL, 2013, DES AUT TEST EUROPE, P354
   Sanchez Daniel, 2013, INT S COMPUTER ARCHI, P475, DOI DOI 10.1145/2485922.2485963
   Sharma S, 2019, INT J INTELL ENG INF, V7, P180
   Singh S., 2014, INT J ADV INF SCI TE, V27, P97
   Taylor MB, 2002, IEEE MICRO, V22, P25, DOI 10.1109/MM.2002.997877
   Van Chu T., 2015, THESIS TOKYO I TECHN
   Van Chu T, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3151758
   Van Winkle S, 2018, INT S HIGH PERF COMP, P480, DOI 10.1109/HPCA.2018.00048
   Vangal SR, 2008, IEEE J SOLID-ST CIRC, V43, P29, DOI 10.1109/JSSC.2007.910957
   Wang K, 2020, ENERG SOURCE PART A, V42, P2199, DOI 10.1080/15567036.2019.1607933
   Wang K, 2019, DES AUT TEST EUROPE, P1166, DOI [10.23919/date.2019.8714869, 10.23919/DATE.2019.8714869]
   Whelihan D, 2003, NOCSIM SIMULATOR
   Won JY, 2014, INT S HIGH PERF COMP, P308, DOI 10.1109/HPCA.2014.6835941
   Xiao Y, 2019, IEEE T VLSI SYST, V27, P1416, DOI 10.1109/TVLSI.2019.2897650
   Zheng H, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317768
NR 59
TC 1
Z9 1
U1 0
U2 0
PY 2022
VL 10
IS 2
BP 160
EP 182
DI 10.1504/IJIEI.2022.10050882
WC Computer Science, Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Jin, K
   Hu, YM
   Lu, W
   Zhang, SK
AF Jin, Kai
   Hu, Yimin
   Lu, Wei
   Zhang, Shukui
BE Jiang, S
   Digonnet, MJ
TI Laser Beam Control Using Machine Learning Technology for Particle
   Accelerator
SO OPTICAL COMPONENTS AND MATERIALS XIX
SE Proceedings of SPIE
DT Proceedings Paper
CT Conference on Optical Components and Materials XIX at SPIE OPTO
   Conference
CY JAN 22-FEB 28, 2022
CL ELECTR NETWORK
DE Pockels Cell; Accelerator; Neural Network; auto-alignment; machine
   learning
AB The Pockels Cells play important role in generating helicity-flipping polarized laser beam to be used in high energy electron beam accelerator facility. Due to exceptional requirements for ultra-stable electron beam in modern nuclear physics experiment, the operation of Pockels Cells which are key components to generate stable electron beam becomes critical. However, since the operation of Pockels Cell, which usually work in pair, involves beam alignments up to 12 degrees of freedom, it requires extremely complicated controls to maintain the stable output beam through whole operation time of accelerator. In this paper, we combined the machine learning method with the Pockels Cells control system, automatically collected data of Pockels cells optical properties such as polarization extinction ratio (PER), beam position, optical intensity asymmetry, etc., at different orientation angles and physical potions, and built an artificial neural network which can determine the optimal position of Pockels Cells. The trained artificial neural network can predict the PER, intensity asymmetry, beam position difference with a mean agreement around 95%, which makes it possible to find the optimal yaw/pitch/roll angles and physical positions of the Pockels cells in a short time. This technology can also be translated to alignments of devices in other laser systems such as high energy ultrafast oscillators and amplifiers.
C1 [Jin, Kai; Hu, Yimin; Lu, Wei] Raytum Photon, Sterling, VA 20166 USA.
   [Zhang, Shukui] Thomas Jefferson Natl Accelerator Facil, Newport News, VA 23606 USA.
RP Lu, W (corresponding author), Raytum Photon, Sterling, VA 20166 USA.
EM wei.lu@raytum-photonics.com
CR Baumeister T, 2018, J OPT SOC AM B, V35, P617, DOI 10.1364/JOSAB.35.000617
   Fu X, 2014, OPT EXPRESS, V22, P8585, DOI 10.1364/OE.22.008585
   Humensky Thomas Brian, 2003, THESIS PRINCETON U
   Kokhanovskiy A, 2019, OPT LETT, V44, P3410, DOI 10.1364/OL.44.003410
   Pu GQ, 2019, OPTICA, V6, P362, DOI 10.1364/OPTICA.6.000362
   Silwa Rupesh, 2012, THESIS U VIRGINIA
NR 6
TC 0
Z9 0
U1 1
U2 3
PY 2022
VL 11997
AR 119970M
DI 10.1117/12.2608311
WC Optics
DA 2023-11-11
ER

PT C
AU Tang, TQ
   Li, S
   Nai, LF
   Jouppi, N
   Xie, Y
AF Tang, Tianqi
   Li, Sheng
   Nai, Lifeng
   Jouppi, Norm
   Xie, Yuan
GP IEEE Comp Soc
TI NeuroMeter: An Integrated Power, Area, and Timing Modeling Framework for
   Machine Learning Accelerators
SO 2021 27TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2021)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 27th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 27-MAR 03, 2021
CL ELECTR NETWORK
DE accelerator; hardware modeling; deep learning
ID ARCHITECTURES; PERFORMANCE
AB As Machine Learning (ML) becomes pervasive in the era of artificial intelligence, ML specific tools and frameworks are required for architectural research. This paper introduces NeuroMeter, an integrated power, area, and timing modeling framework for ML accelerators. NeuroMeter models the detailed architecture of ML accelerators and generates a fast and accurate estimation on power, area, and chip timing. Meanwhile, it also enables the runtime analysis of system-level performance and efficiency when the runtime activity factors are provided. NeuroMeter's micro-architecture model includes fundamental components of ML accelerators, including systolic array based tensor units (TU), reduction trees (RT), and 1D vector units (VU). NeuroMeter has accurate modeling results, with the average power and area estimation errors below 10% and 17% respectively when validated against TPU-v1, TPU-v2, and Eyeriss.
   Leveraging the NeuroMeter's new capabilities on architecting manycore ML accelerators, this paper presents the first in-depth study on the design space and tradeoffs of "Brawny and Wimpy" inference accelerators in datacenter scenarios with the insights that are otherwise difficult to discover without NeuroMeter. Our study shows that brawny designs with 64x64 systolic arrays are the most performant and efficient for inference tasks in the 28nm datacenter architectural space with a 500mm(2) die area budget. Our study also reveals important tradeoffs between performance and efficiency. For datacenter accelerators with low batch inference, a small (similar to 16%) sacrifice of system performance (in achieved Tera Operations per Second, aka TOPS) can lead to more than a 2x efficiency improvement (in achieved TOPS/TCO). To showcase NeuroMeter's capability to model a wide range of diverse ML accelerator architectures, we also conduct a follow-on mini-case study on implications of sparsity on different ML accelerators, demonstrating wimpier accelerator architectures benefit more readily from sparsity processing despite their lower achievable raw energy efficiency.
C1 [Tang, Tianqi; Xie, Yuan] UC Santa Barbara, Santa Barbara, CA 93106 USA.
   [Li, Sheng; Nai, Lifeng; Jouppi, Norm] Google, Mountain View, CA 94043 USA.
RP Tang, TQ (corresponding author), UC Santa Barbara, Santa Barbara, CA 93106 USA.
EM tianqi_taug@ucsb.edu; lsheng@google.com; lnai@google.com;
   jouppi@google.com; yuanxie@ece.ucsb.edu
CR [Anonymous], TF SINI TENSORFLOW P
   [Anonymous], 2019, ALLEN SCH DISTINGUIS
   [Anonymous], 2007, NVDLA DEEP LEARNING
   Azad A, 2017, INT PARALL DISTRIB P, P688, DOI 10.1109/IPDPS.2017.76
   Bachrach J, 2012, DES AUT CON, P1212
   Barroso Luiz., 2009, DATACENTER COMPUTER
   Bhanushali K., 2015, P 2015 S INT S PHYS, P165
   Borkar S, 2003, DES AUT CON, P338
   Brooks D, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P83, DOI [10.1145/342001.339657, 10.1109/ISCA.2000.854380]
   Chen S, 2017, I S WORKL CHAR PROC, P125, DOI 10.1109/IISWC.2017.8167770
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Choquette J, 2018, IEEE MICRO, V38, P42, DOI 10.1109/MM.2018.022071134
   Cong Jason, 2018, IEEE ACM INT C COMPU, P1
   Dean J, 2020, ISSCC DIG TECH PAP I, P8, DOI 10.1109/ISSCC19947.2020.9063049
   Delimitrou C, 2018, COMMUN ACM, V61, P65, DOI 10.1145/3232559
   ELMORE WC, 1948, J APPL PHYS, V19, P55, DOI 10.1063/1.1697872
   Greathouse JL, 2014, INT CONF HIGH PERFOR, P769, DOI 10.1109/SC.2014.68
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hennessy J. L., 2011, COMPUTER ARCHITECTUR
   Hetherington T., 2013, ACM SIGARCH COMPUTER, V4l, P487
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Ke I.., 2018, P INT S LOW POW EL D, P1
   Kumar R, 2005, CONF PROC INT SYMP C, P408, DOI 10.1109/ISCA.2005.34
   Kumar R, 2005, COMPUTER, V38, P32, DOI 10.1109/MC.2005.379
   Kung HT, 2019, IEEE INT CONF ASAP, P42, DOI 10.1109/ASAP.2019.00-31
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Liang XY, 2013, J PARALLEL DISTR COM, V73, P1351, DOI 10.1016/j.jpdc.2013.06.001
   Meisner D., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P109, DOI 10.1109/ISLPED.2011.5993621
   Miyashita T, 2007, INT EL DEVICES MEET, P251, DOI 10.1109/IEDM.2007.4418915
   Muralimanohar N., 2009, HP LAB, V27, P28
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Park I., 2016, ARXIV PREPRINT ARXIV
   Patterson D, 2019, ALLEN SCH DISTINGUIS
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Samajdar A., 2018, ARXIV PREPRINT ARXIV
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Song WJ, 2016, I SYMPOS LOW POWER E, P284, DOI 10.1145/2934583.2934637
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wu Yannan, 2019, ACCELERGY ARCHITECTU
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 51
TC 4
Z9 4
U1 0
U2 1
PY 2021
BP 841
EP 853
DI 10.1109/HPCA51647.2021.00075
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ng, SSH
   Chiu, HN
   Retallick, J
   Walus, K
AF Ng, Samuel S. H.
   Chiu, Hsi Nien
   Retallick, Jacob
   Walus, Konrad
GP IEEE
TI A Blueprint for Machine Learning Accelerators Using Silicon Dangling
   Bonds
SO 2023 IEEE 23RD INTERNATIONAL CONFERENCE ON NANOTECHNOLOGY, NANO
SE IEEE International Conference on Nanotechnology
DT Proceedings Paper
CT IEEE 23rd International Conference on Nanotechnology (NANO)
CY JUL 02-05, 2023
CL Jeju, SOUTH KOREA
ID QUANTUM-DOT; CLOCKING
AB As we approach the limit of transistor scaling, an appealing alternative in the form of quantum dots made of silicon dangling bonds (SiDBs) has been experimentally demonstrated to be capable of realizing sub-30 nm(2) logic gates. The introduction of SiQAD, a calibrated computer-aided design tool for the design and simulation of SiDBs, has further enabled the rapid exploration of this novel design space outside of experimental laboratories. Motivated by these advances and by identifying recent demands in machine learning acceleration, this paper proposes an architecture for an SiDB inference accelerator. Area and power estimates are made based on existing logic components and power models, the results are compared against Google's TPUv1. At the same clock rate, the proposed SiDB inference accelerator offers up to 10x improvement in area efficiency and orders of magnitude improvement in power efficiency, showing tremendous promise for further research into this novel platform technology.
C1 [Ng, Samuel S. H.; Chiu, Hsi Nien; Retallick, Jacob; Walus, Konrad] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
RP Ng, SSH (corresponding author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
EM samueln@ece.ubc.ca; nathanchiu@ece.ubc.ca; jret@ece.ubc.ca;
   konradw@ece.ubc.ca
CR Achal R, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05171-y
   Bahar AN, 2020, IEEE T NANOTECHNOL, V19, P807, DOI 10.1109/TNANO.2020.3036629
   Barthel C, 2010, PHYS REV B, V81, DOI 10.1103/PhysRevB.81.161308
   Bennett CH, 2003, STUD HIST PHILOS M P, V34B, P501, DOI 10.1016/S1355-2198(03)00039-X
   Bohloul S, 2017, NANO LETT, V17, P322, DOI 10.1021/acs.nanolett.6b04125
   Chiu H. N., 2020, THESIS U BRIT COLUMB
   Chiu HN, 2020, IEEE CONF NANOTECH, P134, DOI [10.1109/NANO47656.2020.9183710, 10.1109/nano47656.2020.9183710]
   Dadda L., 1965, ALTA FREQ, V34, P349
   Fuechsle M, 2012, NAT NANOTECHNOL, V7, P242, DOI [10.1038/nnano.2012.21, 10.1038/NNANO.2012.21]
   Gong Y., 2014, ARXIV14126115
   Gupta S, 2015, I C DEPEND SYS NETWO, P37, DOI 10.1109/DSN.2015.52
   Haider MB, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.046805
   Hennessy K, 2001, J VAC SCI TECHNOL B, V19, P1752, DOI 10.1116/1.1394729
   Huff T, 2018, NAT ELECTRON, V1, P636, DOI 10.1038/s41928-018-0180-3
   Huff TR, 2017, ACS NANO, V11, P8636, DOI 10.1021/acsnano.7b04238
   Jacob Benoit, 2017, QUANTIZATION TRAININ, P5
   Jouppi N. P., 2017, INDATACENTER PERFORM
   Labidi H, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/7/073023
   Lent C. S., 1993, Nanotechnology, V4, P49, DOI 10.1088/0957-4484/4/1/004
   Lent CS, 2006, NANOTECHNOLOGY, V17, P4240, DOI 10.1088/0957-4484/17/16/040
   Lent CS, 1997, P IEEE, V85, P541, DOI 10.1109/5.573740
   Livadaru L, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/8/083018
   Lupoiu R., 2022, AUTOMATED ATOMIC SIL
   Ng S. S. H., 2020, THESIS U BRIT COLUMB
   Ng SSH, 2020, IEEE T NANOTECHNOL, V19, P137, DOI 10.1109/TNANO.2020.2966162
   NORTHRUP JE, 1989, PHYS REV B, V40, P5875, DOI 10.1103/PhysRevB.40.5875
   NVIDIA Corporation, NVID ADA GPU ARCH
   Prager AA, 2009, IEEE NANOTECHNOL MAT, P54, DOI 10.1109/NMDC.2009.5167548
   Rashidi M, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.166801
   Rashidi M, 2017, ACS NANO, V11, P11732, DOI 10.1021/acsnano.7b07068
   Seong-Wan Kim, 2010, Proceedings 2010 10th IEEE International Conference on Nanotechnology and Joint Symposium with Nano Korea 2010 KINTEX (IEEE-NANO 2010), P953, DOI 10.1109/NANO.2010.5697997
   Shaterzadeh-Yazdi Z, 2014, PHYS REV B, V89, DOI 10.1103/PhysRevB.89.035315
   Sicard E., 2017, INTRO 7 NM FINFET TE
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Taucer M, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.256801
   Vieira M. D., 2022, IEEE DES TEST
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Walter M., 2022, P 59 ACMIEEE DESIGN, P6
   Yan Y, 2008, INT FED INFO PROC, V276, P427
   Zhang R, 2015, IEEE T COMP PACK MAN, V5, P762, DOI 10.1109/TCPMT.2015.2426791
NR 40
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 280
EP 285
DI 10.1109/NANO58406.2023.10231158
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Materials Science, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Vohra, M
   Fasciani, S
AF Vohra, Manohar
   Fasciani, Stefano
GP IEEE
TI PYNQ-Torch: a framework to develop PyTorch accelerators on the PYNQ
   platform
SO 2019 IEEE 19TH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND
   INFORMATION TECHNOLOGY (ISSPIT 2019)
SE IEEE International Symposium on Signal Processing and Information
   Technology
DT Proceedings Paper
CT 19th IEEE International Symposium on Signal Processing and Information
   Technology (ISSPIT)
CY DEC 10-12, 2019
CL Ajman, U ARAB EMIRATES
DE Reconfigurable architectures; accelerator architectures; machine
   learning; artificial neural networks
AB Artificial intelligence based on deep learning has gained popularity in a broad range of applications. Software libraries and frameworks for deep learning provide developers with tools for fast deployment, hiding the algorithmic complexity for training and inference of large neural networks. These frameworks allow mitigating the computational complexity of such algorithms by interfacing parallel computing libraries for specific graphic processing units, which are not available on all platforms, especially if embedded. The framework we propose in this paper enables fast prototyping of custom hardware accelerators for deep learning. In particular we describe how to design, evaluate and deploy accelerators for PyTorch applications written in Python and running on PYNQ compatible platforms, which are based on Xilinx Zynq Systems on Chips. This approach does not require traditional ASIC-style design tools, but rather it simplifies the interfacing between hardware and software components of the neural network, which includes support for deployment on embedded platforms. As an example, we use the framework to design hardware accelerators for a computationally demanding sound synthesis algorithm based on a recurrent neural network.
C1 [Vohra, Manohar] Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai, U Arab Emirates.
   [Fasciani, Stefano] Univ Oslo, Dept Musicol, Oslo, Norway.
RP Vohra, M (corresponding author), Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai, U Arab Emirates.
EM mv800@uowmail.edu.au; stefano.fasciani@imv.uio.no
CR [Anonymous], 2019, PYNQ PYTHON PRODUCTI
   [Anonymous], 2019, PYNQ TORCH
   [Anonymous], 754 2008 IEEE STAND
   Canavan D., 2018, 2018 29 IR SIGN SYST, P1
   CUDA, 2019, CUDA ZON
   Finnerty A., 2017, REDUCE POWER COST CO
   Hou XY, 2018, 2018 18TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P79, DOI 10.1109/ISCIT.2018.8587934
   Kachris C, 2017, INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION (SAMOS 2017), P70, DOI 10.1109/SAMOS.2017.8344613
   Kachris C, 2017, I C FIELD PROG LOGIC
   Kern R., 2019, LINE BY LINE PROFILI
   Liu YH, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON ELECTRICAL MATERIALS AND POWER EQUIPMENT (ICEMPE), P296, DOI 10.1109/ICEMPE.2017.7982088
   Mehri S., 2016, SAMPLERNN UNCONDITIO
   Python Documentation, 2018, PYTHON PROFILERS PYT
   Pytorch, 2019, PYTORCH
   Stornaiuolo L, 2018, IEEE COMP SOC ANN, P587, DOI 10.1109/ISVLSI.2018.00112
   XIlinx,, 2018, VIVADO DESIGN SUITE
   Xilinx, 2011, AXI REF GUID, V13, P82
NR 17
TC 0
Z9 0
U1 0
U2 4
PY 2019
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Park, J
   Sharma, H
   Mahajan, D
   Kim, JK
   Olds, P
   Esmaeilzadeh, H
AF Park, Jongse
   Sharma, Hardik
   Mahajan, Divya
   Kim, Joon Kyung
   Olds, Preston
   Esmaeilzadeh, Hadi
GP ACM
TI Scale-Out Acceleration for Machine Learning
SO 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
DT Proceedings Paper
CT 50th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 14-18, 2017
CL Cambridge, MA
DE Accelerator; scale-out; distributed; cloud; machine learning
AB The growing scale and complexity of Machine Learning (ML) algorithms has resulted in prevalent use of distributed general-purpose systems. In a rather disjoint effort, the community is focusing mostly on high performance single-node accelerators for learning. This work bridges these two paradigms and offers CoSMIC, a full computing stack constituting language, compiler, system software, template architecture, and circuit generators, that enable programmable acceleration of learning at scale. CoSMIC enables programmers to exploit scale-out acceleration using FPGAs and Programmable ASICs (P-ASICs) from a high-level and mathematical Domain-Specific Language (DSL). Nonetheless, CoSMIC does not require programmers to delve into the onerous task of system software development or hardware design. CoSMIC achieves three conflicting objectives of efficiency, automation, and programmability, by integrating a novel multi-threaded template accelerator architecture and a cohesive stack that generates the hardware and software code from its high-level DSL. CoSMIC can accelerate a wide range of learning algorithms that are most commonly trained using parallel variants of gradient descent. The key is to distribute partial gradient calculations of the learning algorithms across the accelerator-augmented nodes of the scale-out system. Additionally, CoSMIC leverages the parallelizability of the algorithms to offer multi-threaded acceleration within each node. Multi-threading allows CoSMIC to efficiently exploit the numerous resources that are becoming available on modern FPGAs/P-ASICs by striking a balance between multi-threaded parallelism and single-threaded performance. CoSMIC takes advantage of algorithmic properties of ML to offer a specialized system software that optimizes task allocation, role-assignment, thread management, and internode communication. We evaluate the versatility and efficiency of CoSMIC for 10 different machine learning applications from various domains. On average, a 16-node CoSMIC with UltraScale+ FPGAs offers 18.8x speedup over a 16-node Spark system with Xeon processors while the programmer only writes 22-55 lines of code. CoSMIC offers higher scalability compared to the state-of-the-art Spark; scaling from 4 to 16 nodes with CoSMIC yields 2.7x improvements whereas Spark offers 1.8x. These results confirm that the full-stack approach of CoSMIC takes an effective and vital step towards enabling scale-out acceleration for machine learning.
C1 [Park, Jongse; Sharma, Hardik; Mahajan, Divya; Kim, Joon Kyung; Olds, Preston; Esmaeilzadeh, Hadi] Georgia Inst Technol, Alternat Comp Technol ACT Lab, Atlanta, GA 30332 USA.
   [Esmaeilzadeh, Hadi] Univ Calif San Diego, Alternat Comp Technol ACT Lab, La Jolla, CA 92093 USA.
RP Park, J (corresponding author), Georgia Inst Technol, Alternat Comp Technol ACT Lab, Atlanta, GA 30332 USA.
EM jspark@gatech.edu; hsharma@gatech.edu; divya_mahajan@gatech.edu;
   jkkim@gatech.edu; prestonolds@gatech.edu; hadi@eng.ucsd.edu
CR [Anonymous], 2016, MICRO
   [Anonymous], THESIS
   [Anonymous], ASPLOS
   [Anonymous], 2014, ASPLOS
   [Anonymous], 1992, HIGH LEVEL SYNTHESIS
   [Anonymous], 2016, MICRO
   [Anonymous], ASPLOS
   [Anonymous], 2014, MICRO
   [Anonymous], 2016, MICRO
   [Anonymous], 2017, SNICKERDOODLE AFFORD
   [Anonymous], 2016, ISCA
   [Anonymous], 12 INT WORKSH IM AN
   [Anonymous], 2017, AMAZON EC2 F1 INSTAN
   [Anonymous], CORR
   [Anonymous], 2011, CVPRW
   [Anonymous], 2016, ISCA
   [Anonymous], 2012, INT S MICR MICRO
   [Anonymous], 2016, ARXIV160304467CS
   [Anonymous], 2016, HPCA
   [Anonymous], 2016, MICRO
   [Anonymous], 2016, MICRO
   [Anonymous], ARXIV14085093
   [Anonymous], 2017, P 44 ANN INT S COMP
   [Anonymous], 2013, ICML
   [Anonymous], 2016, ISCA
   Bordawekar Rajesh, ACCELERATING SPARK W
   Boyd S., 2014, CONVEX OPTIMIZATION
   Byrd Richard H., 2012, MATH PROGRAMMING, V134
   Cadambi S., 2009, FCCM
   Cantador Ivan, 2011, HETREC
   Caulfield A. M., 2016, MICRO
   Chen J., 2016, ICLR WORKSH TRACK
   Chen Zhang, 2015, FPGA
   Chung E. S., 2013, ISCA
   Chung Eric, 2017, HOT CHIPS, V29
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Cotter A., 2011, NIPS
   Das Dipankar, 2016, ARXIV160206709CS
   Dean J., 2004, OSDI, P1
   Dekel O, 2012, J MACH LEARN RES, V13, P165
   Dhanya S, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-015-1631-1
   Diamantopoulos D, 2015, SAMOS
   Donninger Chrilly, 2004, IPDPS
   DuBois D., 2008, FCCM
   Farabet C., 2011, MACHINE LEARNING VER
   Feng Xixuan, SIGMOD
   Filho A. Gda. S., 2003, SBCCI
   Grouplens, 2017, MOV DAT
   Hussain H. M., 2011, AHS
   Intel Altera, 2017, ARR 10 ARCH
   Ji Yu, 2016, MICRO
   Kesler D., 2011, SASP
   Langford J., 2009, NIPS
   LeCun Yann, 2010, MNIST HANDWRITTEN DI
   Li Mu, 2014, KDD
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Majumdar A, 2011, IEEE EMBED SYST LETT, V3, P42, DOI 10.1109/LES.2010.2100802
   Mann G., 2009, NIPS
   Manolakos E.S., 2010, ISCAS
   Maruyama Tsutomu, 2006, ICPR
   Moreau T., 2015, HPCA
   Morris G.R., 2006, FCCM
   Muhuan Huang, 2016, SOCC
   Ouaiss I., 1999, LECT NOTES COMPUTER, V1385, P31
   Papadonikolakis M., 2010, FCCM
   Putnam A., 2014, ISCA
   Putnam Andrew R., 2008, FPGA
   Roldao A, 2010, ACM T RECONFIG TECHN, V3, DOI 10.1145/1661438.1661439
   Segal MR, 2003, J COMPUTATIONAL BIOL, V10
   Seide F, 2014, ICASSP
   Shaoyi Cheng, 2016, OLAF
   Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
   Sujeeth AK, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584665
   Walters JP, 2007, J VLSI SIG PROC SYST, V48, P223, DOI 10.1007/s11265-007-0062-9
   Wang ZK, 2016, IEEE T PARALL DISTR, V27, P3547, DOI 10.1109/TPDS.2016.2537805
   Weston J., 2000, NIPS
   Zhou Bin, 2008, J BUSINESS EC STAT, V14
   Zidong Du, 2015, ISCA
   Zinkevich M., 2010, P ANN C NEUR INF PRO, V4, P4
NR 80
TC 17
Z9 17
U1 0
U2 4
PY 2017
BP 367
EP 381
DI 10.1145/3123939.3123979
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kornaros, G
AF Kornaros, Georgios
TI Hardware-Assisted Machine Learning in Resource-Constrained IoT
   Environments for Security: Review and Future Prospective
SO IEEE ACCESS
DT Review
DE Internet of Things; Security; Machine learning; Hardware; Malware;
   Microprogramming; Cryptography; AI-based IoT security; hardware-based
   machine learning; IoT intrusion detection; trusted embedded devices
ID NETWORK INTRUSION DETECTION; DEEP NEURAL-NETWORKS; ANOMALY DETECTION;
   TROJAN DETECTION; DETECTION FRAMEWORK; ATTACK DETECTION; ON-CHIP;
   INTERNET; THINGS; ACCELERATOR
AB As the Internet of Things (IoT) technology advances, billions of multidisciplinary smart devices act in concert, rarely requiring human intervention, posing significant challenges in supporting trusted computing and user privacy, as well as protecting against attacks such as spoofing, denial of service (DoS), jamming, and eavesdropping. To tackle attacks on the IoT and cyber-physical ecosystem, many intrusion detection and security approaches have been presented in the literature. Machine learning (ML) based intrusion and anomaly detection has lately gained traction due to its capacity to cope with encrypted and rapidly developing threat techniques. This work investigates into machine learning (ML) and deep learning (DL) methodologies for IoT device security and examine the benefits, drawbacks, and potential. To protect an IoT infrastructure, various solutions look into hardware-based methods for ML-based IoT authentication, access control, secure offloading, and malware detection schemes. This review aims to illuminate the value of various approaches for addressing IoT security in a truly effective, flexible, and seamless manner, as well as to provide answers to questions about tradeoffs in integrating accelerators and customizing embedded device architectures for effective use of ML-based methods.
C1 [Kornaros, Georgios] Hellen Meditteranean Univ, Dept Elect & Comp Engn, Iraklion 71410, Greece.
RP Kornaros, G (corresponding author), Hellen Meditteranean Univ, Dept Elect & Comp Engn, Iraklion 71410, Greece.
EM kornaros@hmu.gr
CR Al-Garadi MA, 2020, IEEE COMMUN SURV TUT, V22, P1646, DOI 10.1109/COMST.2020.2988293
   Amacher J., 2019, IFIP INT C DISTRIBUT, P133
   Andrea I, 2015, 2015 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P180, DOI 10.1109/ISCC.2015.7405513
   ARM, 2020, ARM IS POW INN ART I
   ARM, 2018, TRUST BAS SYST ARCH
   ARM, 2020, LAT NPU ADDS ARMS AI
   Azimi I, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126501
   Azmoodeh A, 2019, IEEE T SUST COMPUT, V4, P88, DOI 10.1109/TSUSC.2018.2809665
   Azmoodeh A, 2018, J AMB INTEL HUM COMP, V9, P1141, DOI 10.1007/s12652-017-0558-5
   Bao C, 2015, INT SYM QUAL ELECT, P47
   Bayerl SP, 2020, DES AUT TEST EUROPE, P460, DOI 10.23919/DATE48585.2020.9116560
   Bhattacharya S, 2015, LECT NOTES COMPUT SC, V9293, P248, DOI 10.1007/978-3-662-48324-4_13
   Bochie K, 2021, J NETW COMPUT APPL, V194, DOI 10.1016/j.jnca.2021.103213
   Bout E, 2022, IEEE COMMUN SURV TUT, V24, P248, DOI 10.1109/COMST.2021.3127267
   BrainChip, 2021, AK NEUR PROC SOC
   Brasser F, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23448
   Burrello A., 2021, PROC IEEE INT C OMNI, P1
   Burrello A, 2021, IEEE T COMPUT, V70, P1253, DOI 10.1109/TC.2021.3066883
   Butun I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205729
   Canedo Janice, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P219, DOI 10.1109/PST.2016.7906930
   Canizo M, 2019, NEUROCOMPUTING, V363, P246, DOI 10.1016/j.neucom.2019.07.034
   Carlini N., 2017, AISEC CCS, P3
   Chaabouni N, 2019, IEEE COMMUN SURV TUT, V21, P2671, DOI 10.1109/COMST.2019.2896380
   Chakraborty A, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218651
   Chang XP, 2021, IEEE T CIRCUITS-I, V68, P1706, DOI 10.1109/TCSI.2020.3048260
   Chen K., 2018, J HARDWARE SYSTEMS S, V2, P97, DOI DOI 10.1007/S41635-017-0029-7
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen T, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0027-x
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Cheng YL, 2021, IEEE INTERNET THINGS, V8, P144, DOI 10.1109/JIOT.2020.3000771
   Cho S, 2020, IEEE ACCESS, V8, P135223, DOI 10.1109/ACCESS.2020.3011265
   Chockaiah Nikhila Shri, 2021, Proceedings of International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications. ICMISC 2020. Advances in Intelligent Systems and Computing (AISC 1245), P415, DOI 10.1007/978-981-15-7234-0_37
   Chowdhury AB, 2023, IEEE T COMPUT AID D, V42, P384, DOI 10.1109/TCAD.2022.3159749
   Christophides V, 2018, P 1 INT WORKSH SEC P, P42
   COLLYER M, 2020, POLITICS DIS INTEGRA, P1, DOI DOI 10.1007/978-3-030-25089-8_1
   Das A, 2008, IEEE T INF FOREN SEC, V3, P118, DOI 10.1109/TIFS.2007.916288
   Das S, 2016, IEEE T INF FOREN SEC, V11, P289, DOI 10.1109/TIFS.2015.2491300
   de Araujo PF, 2021, IEEE INTERNET THINGS, V8, P6247, DOI 10.1109/JIOT.2020.3024800
   Deng SG, 2020, IEEE T IND INFORM, V16, P6103, DOI 10.1109/TII.2020.2974875
   Deokar B., 2012, INT J COMPUTER APPL, V45, P28, DOI DOI 10.1109/ICMIC48233.2019.9068567
   Diro A, 2018, IEEE COMMUN MAG, V56, P124, DOI 10.1109/MCOM.2018.1701270
   Donassolo B, 2019, CONSUM COMM NETWORK, DOI 10.1109/ccnc.2019.8651835
   Drumond Mario, 2018, P 32 INT C NEURAL IN, P451
   Duddu V, 2018, DEFENCE SCI J, V68, P356, DOI 10.14429/dsj.68.12371
   Elnawawy M, 2020, IEEE ACCESS, V8, P175637, DOI 10.1109/ACCESS.2020.3026831
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Fan Mo, 2020, MobiSys '20: Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services, P161, DOI 10.1145/3386901.3388946
   Fang LM, 2021, IEEE T IND INFORM, V17, P4260, DOI 10.1109/TII.2020.3011444
   Franca A. L. P. D., 2014, PROC IEEE COMPUT SOC, P456
   Fremantle P., 2016, SECURITY SURVEY MIDD, P1, DOI [10.1049/pbse002-_ch1, DOI 10.1049/PBSE002-_CH1]
   Gao J., 2020, ARXIV PREPRINT ARXIV
   Gholami Amir, 2021, ARXIV210313630
   Granjal J, 2015, IEEE COMMUN SURV TUT, V17, P1294, DOI 10.1109/COMST.2015.2388550
   Greenwaves Technologies, ULTR LOW POW GAP PRO
   Guo HQ, 2019, IEEE INT CONF ASAP, P136, DOI 10.1109/ASAP.2019.00-16
   Guo WB, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P364, DOI 10.1145/3243734.3243792
   HaddadPajouh H, 2018, FUTURE GENER COMP SY, V85, P88, DOI 10.1016/j.future.2018.03.007
   Han Y, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1095, DOI 10.1145/3133956.3134081
   Hasegawa K, 2017, IEEE INT SYMP CIRC S, P2154
   Hassan MM, 2021, IEEE T IND INFORM, V17, P2860, DOI 10.1109/TII.2020.3015026
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hou YM, 2019, IEEE T COMPUT AID D, V38, P1820, DOI 10.1109/TCAD.2018.2864246
   Howard A. G., 2017, ARXIV
   Huang Z, 2020, IEEE ACCESS, V8, P10796, DOI 10.1109/ACCESS.2020.2965016
   Humayed A, 2017, IEEE INTERNET THINGS, V4, P1802, DOI 10.1109/JIOT.2017.2703172
   Hussain F, 2020, IEEE COMMUN SURV TUT, V22, P1686, DOI 10.1109/COMST.2020.2986444
   Hwang D, 2023, IEEE T MOBILE COMPUT, V22, P708, DOI 10.1109/TMC.2021.3086143
   Iandola F. N., 2016, SQUEEZENET ALEXNET L
   Iwase T, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P185, DOI 10.1109/GCCE.2015.7398569
   Javaheripi M, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415671
   Jin Y, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HARDWARE-ORIENTED SECURITY AND TRUST, P51, DOI 10.1109/HST.2008.4559049
   Kadiyala SP, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3403943
   Khalid F, 2020, IEEE T COMPUT AID D, V39, P3748, DOI 10.1109/TCAD.2020.3012236
   Khan MN, 2021, IEEE INTERNET THINGS, V8, P4132, DOI 10.1109/JIOT.2020.3026493
   Khraisat A, 2021, CYBERSECURITY, V4, DOI 10.1186/s42400-021-00077-7
   Kocher P. C., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P104
   Kornaros G., 2018, SOLUTIONS CYBER PHYS, P301, DOI 10.4018/978-1-5225-2845-6.ch012
   Kornaros G, 2018, IEEE MICRO, V38, P63, DOI 10.1109/MM.2018.053631143
   Kornaros G, 2013, ACM T DES AUTOMAT EL, V18, DOI 10.1145/2442087.2442088
   Krishnamurthy P, 2020, IEEE T INF FOREN SEC, V15, P666, DOI 10.1109/TIFS.2019.2923577
   Krupa, 2021, ARXIV210305579
   Kulkarni A, 2016, ACM J EMERG TECH COM, V13, DOI 10.1145/2827699
   Kulow A, 2021, IEEE T INF FOREN SEC, V16, P3254, DOI 10.1109/TIFS.2021.3074884
   Kumar R, 2020, PROCEDIA COMPUT SCI, V167, P373, DOI 10.1016/j.procs.2020.03.240
   Lahti S, 2019, IEEE T COMPUT AID D, V38, P898, DOI 10.1109/TCAD.2018.2834439
   Lai L., 2018, CMSIS NN EFFICIENT N
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Lee S, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P138, DOI 10.1145/3356250.3360030
   Li XS, 2017, IEEE DATA MINING, P277, DOI 10.1109/ICDM.2017.37
   Liakos K. G., 2019, P IEEE PANH C EL TEL, P1
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Liu Y., 2014, PROC 51 ANN DESIGN A, P1, DOI [10.1145/2593069.2593147, DOI 10.1145/2593069.2593147]
   Liu Y, 2021, IEEE INTERNET THINGS, V8, P6348, DOI 10.1109/JIOT.2020.3011726
   Lodhi FK, 2016, IEEE INT SYMP CIRC S, P1702, DOI 10.1109/ISCAS.2016.7538895
   Luo Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453155
   Maene P, 2018, IEEE T COMPUT, V67, P361, DOI 10.1109/TC.2017.2647955
   Mantovani P, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415753
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Martinez I, 2021, IEEE INTERNET THINGS, V8, P2494, DOI 10.1109/JIOT.2020.3022699
   Matsubara K, 2019, SYMP VLSI CIRCUITS, pC202, DOI 10.23919/VLSIC.2019.8778078
   Merenda M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092533
   Meynard O, 2011, LECT NOTES COMPUT SC, V6584, P471, DOI 10.1007/978-3-642-21518-6_33
   Mitchell R, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2542049
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moratelli C, 2016, P IEEE RAP SYST PROT, P2, DOI 10.1145/2990299.2990301
   Munir M, 2019, IEEE ACCESS, V7, P1991, DOI 10.1109/ACCESS.2018.2886457
   Mutlu O, 2021, INTELLIGENT ARCHITEC
   Mutlu O., 2020, ARXIV PREPRINT ARXIV
   Nasahl P, 2021, ASIA CCS'21: PROCEEDINGS OF THE 2021 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P200, DOI 10.1145/3433210.3453684
   Nepes AI, NM500 USERTS MAN VER
   Novac PE, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092984
   NVIDIA, NVID DRIV HARDW
   Nwakanma CI, 2021, ICT EXPRESS, V7, P152, DOI 10.1016/j.icte.2021.05.003
   Nyman T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317836
   Olowononi FO, 2021, IEEE COMMUN SURV TUT, V23, P524, DOI 10.1109/COMST.2020.3036778
   Ozsoy M, 2015, INT S HIGH PERF COMP, P651, DOI 10.1109/HPCA.2015.7056070
   Pachauri G, 2015, PROCEDIA COMPUT SCI, V70, P325, DOI 10.1016/j.procs.2015.10.026
   Pan ZX, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1775, DOI 10.23919/DATE51398.2021.9474050
   Papp D, 2015, ANN CONF PRIV SECUR, P145, DOI 10.1109/PST.2015.7232966
   Patel N, 2017, DES AUT CON, DOI [10.1145/3061639.3062202, 10.1109/PESGM.2017.8274502]
   PCI Security Standards Council, 2018, PAYM CARD IND PCI DA
   Pontarelli S, 2013, IEEE T COMPUT, V62, P2322, DOI 10.1109/TC.2012.105
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Qiu H, 2021, IEEE INTERNET THINGS, V8, P10327, DOI 10.1109/JIOT.2020.3048038
   Qualcomm Technologies, 2017, POINT AUTH ARMV8 3
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Renesas, 2022, E AI SOL
   Renju Liu, 2021, IoTDI '21: Proceedings of the International Conference on Internet-of-Things Design and Implementation, P67, DOI 10.1145/3450268.3453524
   Roman R, 2018, FUTURE GENER COMP SY, V78, P680, DOI 10.1016/j.future.2016.11.009
   Rosenberg I, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453158
   Rostami M, 2014, P IEEE, V102, P1283, DOI 10.1109/JPROC.2014.2335155
   Rusci Manuele, 2020, ARXIV PREPRINT ARXIV
   Sadeghi AR, 2015, DES AUT CON, DOI 10.1145/2744769.2747942
   Samy A, 2020, IEEE ACCESS, V8, P74571, DOI 10.1109/ACCESS.2020.2988854
   Sayadi H, 2021, CRYPTOGRAPHY-BASEL, V5, DOI 10.3390/cryptography5040028
   Sayadi H, 2018, DES AUT CON
   Sengupta A, 2017, IEEE T COMPUT AID D, V36, P655, DOI 10.1109/TCAD.2016.2597232
   Serebryany K, 2019, USENIX MAGAZINE, V44
   Sharma R, 2021, INTEGRATION, V79, P1, DOI 10.1016/j.vlsi.2021.03.001
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shin D, 2018, IEEE MICRO, V38, P85, DOI 10.1109/MM.2018.053631145
   Sidhu S, 2019, J SENS ACTUAR NETW, V8, DOI 10.3390/jsan8030042
   Sisejkovic D, 2020, PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS FOR EMBEDDED SYSTEMS (SCOPES 2020), P62, DOI 10.1145/3378678.3391886
   Snow KZ, 2013, P IEEE S SECUR PRIV, P574, DOI 10.1109/SP.2013.45
   Soylu T., 2017, P RECONFIG 17 CANC M, P1
   STM, 2021, 10 CUBE AI AI AI EXP
   STM, 2021, STM32U575 585 ARM BA
   STM, 2021, FP AI NANOEDG1 ART I
   STM Life.Augmented, 2022, LSM6DSOX MACH LEARN
   Stouffer K., 2015, NIST SPECIAL PUBLICA, DOI [10.6028/NIST.SP.800-82r2, DOI 10.6028/NIST.SP.800-82R2]
   Sun Z., 2020, ARXIV201105905
   Suresh M, 2011, COMM COM INF SC, V196, P441
   Tahsien SM, 2020, J NETW COMPUT APPL, V161, DOI 10.1016/j.jnca.2020.102630
   Tang Adrian, 2014, Research in Attacks, Intrusions and Defenses. 17th International Symposium (RAID 2014). Proceedings: LNCS 8688, P109, DOI 10.1007/978-3-319-11379-1_6
   Tange K, 2020, IEEE COMMUN SURV TUT, V22, P2489, DOI 10.1109/COMST.2020.3011208
   Nguyen TT, 2023, IEEE T NEUR NET LEAR, V34, P3779, DOI 10.1109/TNNLS.2021.3121870
   Theissler A, 2017, KNOWL-BASED SYST, V123, P163, DOI 10.1016/j.knosys.2017.02.023
   Tramer Florian, 2019, 7 INT C LEARN REPR I
   Trouli GI, 2020, IEEE DES TEST, V37, P91, DOI 10.1109/MDAT.2020.2974914
   Vashist A, 2019, IEEE T VLSI SYST, V27, P2781, DOI 10.1109/TVLSI.2019.2928960
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Viegas E, 2017, IEEE T COMPUT, V66, P163, DOI 10.1109/TC.2016.2560839
   Wang H, 2020, PR IEEE COMP DESIGN, P648, DOI 10.1109/ICCD50377.2020.00111
   Wang XY, 2016, IEEE T COMPUT AID D, V35, P485, DOI 10.1109/TCAD.2015.2474374
   Whitnall C, 2019, LECT NOTES COMPUT SC, V11923, P256, DOI 10.1007/978-3-030-34618-8_9
   Woodruff J, 2014, CONF PROC INT SYMP C, P457, DOI 10.1109/ISCA.2014.6853201
   Xiao L, 2018, IEEE SIGNAL PROC MAG, V35, P41, DOI 10.1109/MSP.2018.2825478
   Xu DW, 2020, IEEE T COMPUT, V69, P1172, DOI 10.1109/TC.2020.3001033
   Xu Q, 2021, ASIA S PACIF DES AUT, P449, DOI 10.1145/3394885.3431639
   Yang K, 2020, IEEE J SEL AREA COMM, V38, P955, DOI 10.1109/JSAC.2020.2980921
   Yang MM, 2018, IEEE ACCESS, V6, P17119, DOI 10.1109/ACCESS.2018.2817523
   Yao F., 2020, DEEPHAMMER DEPLETING
   Zhang XX, 2011, 2011 24TH INTERNATIONAL VACUUM NANOELECTRONICS CONFERENCE (IVNC), P67, DOI 10.1109/HST.2011.5954998
   Zhao H, 2020, IEEE T DEPEND SECURE, V17, P716, DOI 10.1109/TDSC.2018.2864733
   Zhao SJ, 2019, PROCEEDINGS OF THE 22ND INTERNATIONAL SYMPOSIUM ON RESEARCH IN ATTACKS, INTRUSIONS AND DEFENSES, P105
   Zhou BY, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P457, DOI 10.1145/3196494.3196515
   Zhou LW, 2021, IEEE J EM SEL TOP C, V11, P292, DOI 10.1109/JETCAS.2021.3077442
   Zhou LW, 2020, IEEE T COMPUT, V69, P1668, DOI 10.1109/TC.2020.3000237
   Zolanvari M, 2019, IEEE INTERNET THINGS, V6, P6822, DOI 10.1109/JIOT.2019.2912022
NR 181
TC 7
Z9 7
U1 11
U2 29
PY 2022
VL 10
BP 58603
EP 58622
DI 10.1109/ACCESS.2022.3179047
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Jamma, D
   Ahmed, O
   Areibi, S
   Grewal, G
AF Jamma, Dunia
   Ahmed, Omar
   Areibi, Shawki
   Grewal, Gary
GP IEEE
TI Hardware Accelerators for the K-Nearest Neighbor Algorithm using High
   Level Synthesis
SO 2017 29TH INTERNATIONAL CONFERENCE ON MICROELECTRONICS (ICM)
SE International Conference on Microelectronics-ICM
DT Proceedings Paper
CT 29th International Conference on Microelectronics (ICM)
CY DEC 10-13, 2017
CL Beirut, LEBANON
AB Supervised machine-learning algorithms require relatively large amounts of runtime to perform training and/or classification. Therefore, a need exists to accelerate their runtime, especially for real-time applications. In this paper, we propose and compare several hardware accelerators for the K-Nearest Neighbor (K-NN) classification algorithm. The accelerators are developed using Xilinx Vivado High-Level Synthesis (HLS) and represent examples of semi-tightly coupled architectures. Our experimental results, based on standard benchmarks, show speedups ranging from 48x-168x.
C1 [Jamma, Dunia; Ahmed, Omar; Areibi, Shawki] Univ Guelph, Sch Engn, Guelph, ON, Canada.
   [Grewal, Gary] Univ Guelph, Sch Comp Sci, Guelph, ON, Canada.
RP Jamma, D (corresponding author), Univ Guelph, Sch Engn, Guelph, ON, Canada.
EM djamma@uoguelph.ca; oahmed@uoguelph.ca; sareibi@uoguelph.ca;
   ggrewal@uoguelph.ca
CR [Anonymous], AD HARDW SYST 2012 N
   CARUANA R, 2006, ICML 06, P161
   Jamma D., 2016, THESIS
   Jamma D, 2016, INT C MICROELECTRON, P57, DOI 10.1109/ICM.2016.7847907
   Kiang MY, 2003, DECIS SUPPORT SYST, V35, P441, DOI 10.1016/S0167-9236(02)00110-0
   KOTSIANTIS SB, 2007, C EM ART INT APPL, V160, P3
   Lichman M., 2013, UCI MACHINE LEARNING
   Lucas SM, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P1867, DOI 10.1109/IJCNN.1998.687142
   Manolakos E S, 2010, PAR DISTR PROC WORKS, P1
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
NR 10
TC 3
Z9 3
U1 0
U2 1
PY 2017
BP 330
EP 333
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Sheppard, R
   Baribeau, C
   Pedersen, T
   Boland, M
   Bertwistle, D
AF Sheppard, Ryan
   Baribeau, Cameron
   Pedersen, Tor
   Boland, Mark
   Bertwistle, Drew
TI A neural network model of a quasiperiodic elliptically polarizing
   undulator in universal mode
SO JOURNAL OF SYNCHROTRON RADIATION
DT Article
DE undulator; neural network; synchrotron radiation; extreme ultraviolet
ID CODE
AB Machine learning has recently been applied and deployed at several light source facilities in the domain of accelerator physics. Here, an approach based on machine learning to produce a fast-executing model is introduced that predicts the polarization and energy of the radiated light produced at an insertion device. This paper demonstrates how a machine learning model can be trained on simulated data and later calibrated to a smaller, limited measured data set, a technique referred to as transfer learning. This result will enable users to efficiently determine the insertion device settings for achieving arbitrary beam characteristics.
C1 [Sheppard, Ryan; Baribeau, Cameron; Pedersen, Tor; Boland, Mark; Bertwistle, Drew] Canadian Light Source, 44 Innovat Blvd, Saskatoon, SK, Canada.
   [Sheppard, Ryan] McGill Univ, 817 Sherbrooke St West, Montreal, PQ, Canada.
   [Boland, Mark; Bertwistle, Drew] Univ Saskatchewan, Dept Phys & Engn Phys, 116 Sci Pl, Saskatoon, SK, Canada.
RP Bertwistle, D (corresponding author), Canadian Light Source, 44 Innovat Blvd, Saskatoon, SK, Canada.; Bertwistle, D (corresponding author), Univ Saskatchewan, Dept Phys & Engn Phys, 116 Sci Pl, Saskatoon, SK, Canada.
EM drew.bertwistle@lightsource.ca
CR Abadi M, 2016, Arxiv, DOI [arXiv:1605.08695, DOI 10.48550/ARXIV.1605.08695]
   [Anonymous], 1998, P EPAC98
   [Anonymous], 2002, SCI ENG GUIDE DIGITA
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Chavanne J., 1998, P 6 EUR PART ACC C E, P2213
   Chubar O, 1998, J SYNCHROTRON RADIAT, V5, P481, DOI 10.1107/S0909049597013502
   Day RP, 2019, NPJ QUANTUM MATER, V4, DOI 10.1038/s41535-019-0194-8
   Edelen A., 2010, P 9 INT PART ACC C I
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Elleaume P., 1997, P 1997 PART ACC C PA, p9P027
   Hu BH, 2020, IEEE INT POWER ELEC, P197, DOI 10.1109/IPEMC-ECCEAsia48364.2020.9368103
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Marcouille O, 2007, AIP CONF PROC, V879, P311
   Scheinker A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082802
   Sigrist M, 2018, CALCULATING PHOTON P
   Sigrist M. J., 2019, P 10 INT PART ACC C, P1687
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Wavemetrics, 2018, IG PRO
   Wurtz W. A., 2014, P 5 INT PART ACC C I, P1995
NR 21
TC 1
Z9 1
U1 0
U2 0
PD NOV
PY 2022
VL 29
BP 1368
EP 1375
DI 10.1107/S1600577522008554
PN 6
WC Instruments & Instrumentation; Optics; Physics, Applied
DA 2023-11-11
ER

PT C
AU Read, J
   Li, WT
   Yu, SM
AF Read, James
   Li, Wantong
   Yu, Shimeng
GP IEEE
TI A Method for Reverse Engineering Neural Network Parameters from
   Compute-in-Memory Accelerators
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
DE compute-in-memory; weight stealing; reverse engineering; machine
   learning accelerators
AB Recent work has shown that on-chip memory read-out is possible through Photonic Emission Analysis (PEA), a semi-invasive Side-Channel Attack (SCA) that can reveal SRAM cell values. These attacks are of significant concern to machine learning hardware accelerators that store neural network parameters in on-chip memory as the parameters (weights and biases) take significant engineering time and money to train. Inference-only, compute-in-memory (CIM) accelerators based on emerging non-volatile memory (eNVM) devices appear to be resistant to such attacks, as eNVM cells do not emit photons during the read operation or in the off state. Despite this intrinsic security, this work will show that these accelerators are still vulnerable to reverse engineering, as PEA can be used on the peripheral circuitry that buffer the input and output to the eNVM memory array. With this information alone, the weights and biases of the network can be discovered with 99% accuracy, even in the presence of significant noise. Experiments are simulated based on results gathered from a RRAM-based, 1T1R CIM macro implemented on TSMC 40nm process.
C1 [Read, James; Li, Wantong; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Ensan SS, 2021, IEEE T VLSI SYST, V29, P2040, DOI 10.1109/TVLSI.2021.3110744
   Faraj M, 2021, CRYPTOGR COMMUN, V13, P363, DOI 10.1007/s12095-020-00469-5
   Helfmeier C, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE-ORIENTED SECURITY AND TRUST (HOST), P1, DOI 10.1109/HST.2013.6581556
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Li W, 2021, IEEE EUROPEAN SOLID
   Lu AN, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.659060
   Schlösser A, 2013, J CRYPTOGR ENG, V3, P3, DOI 10.1007/s13389-013-0053-7
   Stellari F., 2021, INT S TESTING FAILUR
   Stellari F, 2016, IEEE VLSI TEST SYMP
   Strubell E, 2019, Arxiv, DOI [arXiv:1906.02243, DOI 10.48550/ARXIV.1906.02243]
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
   Yu SM, 2021, IEEE T CIRCUITS-I, V68, P2753, DOI 10.1109/TCSI.2021.3072200
NR 15
TC 0
Z9 0
U1 1
U2 4
PY 2022
BP 302
EP 307
DI 10.1109/ISVLSI54635.2022.00066
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Peserico, N
   Ma, XX
   Shastri, B
   Sorger, VJ
AF Peserico, Nicola
   Ma, Xiaoxuan
   Shastri, Bahvin
   Sorger, Volker J.
BE Volpe, G
   Pereira, JB
   Brunner, D
   Ozcan, A
TI Photonic Tensor Core for Machine Learning: a review
SO EMERGING TOPICS IN ARTIFICIAL INTELLIGENCE (ETAI) 2022
SE Proceedings of SPIE
DT Proceedings Paper
CT Emerging Topics in Artificial Intelligence (ETAI)
CY AUG 21-25, 2022
CL San Diego, CA
DE Photonic Tensor Core; Machine Learning; Neural Network; Silicon
   Photonics
AB Photonic Tensor Core circuits have been widely explored as possible hardware accelerators for the next generation of Machine Learning applications, due to the large bandwidth, low latency, and energy saving that light has. Many architectures have been presented, especially exploiting photonic integrated circuits. However, most of the proposed solutions lack some features, such as integration, scalability, or energy saving. In this paper, we review the major achievements in recent years, showing how high integration can lead to better performance, but it could also limit the scalability of the overall system.
C1 [Peserico, Nicola; Ma, Xiaoxuan; Sorger, Volker J.] George Washington Univ, 800 22nd St NE, Washington, DC 20052 USA.
   [Shastri, Bahvin] Queens Univ, Kingston, ON, Canada.
RP Sorger, VJ (corresponding author), George Washington Univ, 800 22nd St NE, Washington, DC 20052 USA.
EM sorger@gwu.edu
CR Amin R, 2019, APL MATER, V7, DOI 10.1063/1.5109039
   Amin R, 2021, APL PHOTONICS, V6, DOI 10.1063/5.0062830
   Amin R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80381-3
   Amin R, 2020, J LIGHTWAVE TECHNOL, V38, P282, DOI 10.1109/JLT.2019.2956719
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Annoni A, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2017.110
   Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Bandyopadhyay S., 2022, SINGLE CHIP PHOTONIC
   Banerjee S., 2022, IEEE DESIGN TEST PP, P2168
   Brückerhoff-Plückelmann F, 2022, NANOPHOTONICS-BERLIN, V11, P4063, DOI 10.1515/nanoph-2021-0752
   Demirkiran C., 2021, ELECTROPHOTONIC SYST, P9
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Feldmann J., NATURE
   Feng C., 2021, COMPACT BUTTERFLY ST
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   Gui YL, 2022, NANOPHOTONICS-BERLIN, V11, P4001, DOI 10.1515/nanoph-2021-0796
   Guo K., 2017, SURVEY FPGA BASED NE
   Guo Z., IEEE J SEL TOP QUANT, V28
   Huang CR, 2021, NAT ELECTRON, V4, P837, DOI 10.1038/s41928-021-00661-2
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Khaddam-Aljameh R., IEEE J SOLID-ST CIRC, V1
   Ma X., 2022, PLOS ONE
   Ma X., 2022, OPTICAL FIBER COMMUN
   Marquez BA, 2021, J PHYS-PHOTONICS, V3, DOI 10.1088/2515-7647/abe3d9
   Meng J., 2022, ELECT PROGRAMMABLE L
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Miller DAB, 2015, OPTICA, V2, P747, DOI 10.1364/OPTICA.2.000747
   Miller DAB, 2013, PHOTONICS RES, V1, P1, DOI 10.1364/PRJ.1.000001
   Miller DAB, 2009, P IEEE, V97, P1166, DOI 10.1109/JPROC.2009.2014298
   Miscuglio M, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0001942
   Miscuglio M, 2019, APL MATER, V7, DOI 10.1063/1.5109689
   Onen M, 2022, SCIENCE, V377, P539, DOI 10.1126/science.abp8064
   Peserico N, 2022, OPT MATER EXPRESS, V12, P1347, DOI 10.1364/OME.451802
   Ramey C., 2020, 2020 IEEE HOT CHIPS
   Sarwat SG, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn3243
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Strigl D, 2010, EUROMICRO WORKSHOP P, P317, DOI 10.1109/PDP.2010.43
   Sun S., CLEAR HOLISTIC FIGUR
   Tait AN, 2018, OPT EXPRESS, V26, P26422, DOI 10.1364/OE.26.026422
   Yang L, 2012, OPT EXPRESS, V20, P13560, DOI 10.1364/OE.20.013560
   Youngblood N., 2022, NAT COMMUN
   Zhang H., OPTICAL NEURAL CHIP
   Zhang H, 2022, Arxiv, DOI arXiv:2203.02285
   Zhang WP, 2022, OPTICA, V9, P579, DOI 10.1364/OPTICA.446100
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou HL, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2943347
NR 47
TC 0
Z9 0
U1 3
U2 6
PY 2022
VL 12204
AR 1220407
DI 10.1117/12.2633916
WC Computer Science, Artificial Intelligence; Neurosciences; Optics
DA 2023-11-11
ER

PT J
AU Romaszkan, W
   Li, TM
   Gupta, P
AF Romaszkan, Wojciech
   Li, Tianmu
   Gupta, Puneet
TI SASCHA-Sparsity-Aware Stochastic Computing Hardware Architecture for
   Neural Network Acceleration
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article; Proceedings Paper
CT ACM/IEEE Int Conf on Hardware/Software Codesign and Syst Synthesis / Int
   Conf on Compilers, Architectures, and Synthesis for Embedded Syst / Int
   Conf on Embedded Software part of the Embedded Syst Week
CY OCT 08-15, 2021
CL ELECTR NETWORK
DE Accelerators; machine learning; stochastic computing (SC)
ID PERFORMANCE; INFERENCE
AB Stochastic computing (SC) has recently emerged as a promising method for efficient machine learning acceleration. Its high compute density, affinity with dense linear algebra primitives, and approximation properties have an uncanny level of synergy with the deep neural network computational requirements. However, there is a conspicuous lack of works trying to integrate SC hardware with sparsity awareness, which has brought significant performance improvements to conventional architectures. In this work, we identify why common sparsity-exploiting techniques are not easily applicable to SC accelerators and propose a new architecture-SASCHA-sparsity-aware SC hardware architecture for the neural network acceleration that addresses those issues. SASCHA encompasses a set of techniques that make utilizing sparsity in inference practical for different types of SC computation. At 90% weight sparsity, SASCHA can be up to 6.5x faster and 5.5x more energy-efficient than comparable dense SC accelerators with a similar area without sacrificing the dense network throughput. SASCHA also outperforms sparse fixed-point accelerators by up to 4x in terms of latency. To the best of our knowledge, SASCHA is the first SC accelerator architecture oriented around sparsity.
C1 [Romaszkan, Wojciech; Li, Tianmu; Gupta, Puneet] Univ Calif Los Angeles, Elect & Comp Engn Dept, Los Angeles, CA 90095 USA.
RP Romaszkan, W (corresponding author), Univ Calif Los Angeles, Elect & Comp Engn Dept, Los Angeles, CA 90095 USA.
EM wromaszkan@ucla.edu; litianmu1995@ucla.edu; puneetg@ucla.edu
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2014, LEARNING SEMANTIC IM
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng Y, 2020, Arxiv, DOI arXiv:1710.09282
   Chin Ting-Wu, 2020, COMPUTER VISION ECCV, P3
   Chippa VK, 2014, I SYMPOS LOW POWER E, P39, DOI 10.1145/2627369.2627645
   Choquette J, 2021, ISSCC DIG TECH PAP I, V64, P48, DOI 10.1109/ISSCC42613.2021.9365803
   Cota EG, 2015, DES AUT CON, DOI 10.1145/2744769.2744794
   Deng CH, 2021, CONF PROC INT SYMP C, P1110, DOI 10.1109/ISCA52012.2021.00090
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Finucane ML, 2000, J BEHAV DECIS MAKING, V13, P1, DOI 10.1002/(SICI)1099-0771(200001/03)13:1<1::AID-BDM333>3.0.CO;2-S
   Gaines B. R., 1969, ADV INFORM SYSTEMS S, V2, P37
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Gong ZXW, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P796, DOI 10.1109/MICRO50266.2020.00070
   Han S, 2015, ADV NEUR IN, V28
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hojabr R, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317911
   Kim YG, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P1082, DOI 10.1109/MICRO50266.2020.00090
   Lai LZ, 2018, Arxiv, DOI arXiv:1801.06601
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Li SC, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P696, DOI [10.1109/MICRO.2018.00062, 10.1109/MICR0.2018.00062]
   Li T., 2021, PROC DESIGN AUTOM TE, P1
   Li Z, 2019, IEEE T COMPUT AID D, V38, P1543, DOI 10.1109/TCAD.2018.2852752
   Mahmoud M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P781, DOI 10.1109/MICRO50266.2020.00069
   Mishra A, 2021, Arxiv, DOI arXiv:2104.08378
   Muralimanohar N., 2009, HP LAB
   Najafi MH, 2019, IEEE T VLSI SYST, V27, P2925, DOI 10.1109/TVLSI.2019.2929354
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park JS, 2021, ISSCC DIG TECH PAP I, V64, P152, DOI 10.1109/ISSCC42613.2021.9365928
   Ren A, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P405, DOI 10.1145/3037697.3037746
   Romaszkan W, 2020, DES AUT TEST EUROPE, P768, DOI 10.23919/DATE48585.2020.9116289
   Sehwag V, 2018, IEEE T CIRCUITS-II, V65, P231, DOI 10.1109/TCSII.2017.2708128
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Sim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062290
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P766, DOI 10.1109/MICRO50266.2020.00068
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Vasudevan A, 2017, IEEE INT CONF ASAP, P19, DOI 10.1109/ASAP.2017.7995254
   Wang SQ, 2020, IEEE DES TEST, V37, P50, DOI 10.1109/MDAT.2020.2968258
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
   Wu D, 2020, ANN I S COM, P377, DOI 10.1109/ISCA45697.2020.00040
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhong GW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3301278
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 51
TC 0
Z9 0
U1 0
U2 4
PD NOV
PY 2022
VL 41
IS 11
BP 4169
EP 4180
DI 10.1109/TCAD.2022.3197503
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Darbani, P
   Rohbani, N
   Beitollahi, H
   Lotfi-Kamran, P
AF Darbani, Paria
   Rohbani, Nezam
   Beitollahi, Hakem
   Lotfi-Kamran, Pejman
TI RASHT: A Partially Reconfigurable Architecture for Efficient
   Implementation of CNNs
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Computer architecture; Convolutional neural networks; Arrays; Resource
   management; System-on-chip; Computational modeling; Very large scale
   integration; Array accelerator; convolutional neural network (CNN);
   image processing and computer vision; machine learning (ML);
   reconfigurable hardware
AB Convolutional neural networks (CNNs) are widely used in machine learning (ML) applications such as image processing. CNN requires heavy computations to provide significant accuracy for many ML tasks. Therefore, the efficient implementations of CNNs to improve performance using limited resources without accuracy reduction is a challenge for ML systems. One of the architectures for the efficient execution of CNNs is the array-based accelerator, that consists of an array of similar processing elements (PEs). The array accelerators are popular as high-performance architecture using the features of parallel computing and data reuse. These accelerators are optimized for a set of CNN layers, not for individual layers. Using the same accelerator dimension size to compute all CNN layers with varying shapes and sizes leads to the resource underutilization problem. We propose a flexible and scalable architecture for array-based accelerator that increases resource utilization by resizing PEs to better match the different shapes of CNN layers. The low-cost partial reconfiguration improves resource utilization and performance, resulting in a 23.2% reduction in computational times of GoogLeNet compared to the state-of-the-art accelerators. The proposed architecture decreases the on-chip memory access rate by 26.5% with no accuracy loss.
C1 [Darbani, Paria; Beitollahi, Hakem] Iran Univ Sci & Technol, Sch Comp Engn, Tehran 1311416846, Iran.
   [Rohbani, Nezam; Lotfi-Kamran, Pejman] Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran 193955531, Iran.
RP Beitollahi, H (corresponding author), Iran Univ Sci & Technol, Sch Comp Engn, Tehran 1311416846, Iran.
EM paria_darbani@cmps2.iust.ac.ir; rohbani@ipm.ir; beitollahi@iust.ac.ir;
   plotfi@ipm.ir
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ansari A, 2017, CONF REC ASILOMAR C, P1337, DOI 10.1109/ACSSC.2017.8335571
   Azizimazreah A, 2022, IEEE T COMPUT, V71, P534, DOI 10.1109/TC.2020.3048624
   Chen KC, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352376
   Chen XM, 2020, INT S HIGH PERF COMP, P529, DOI 10.1109/HPCA47549.2020.00050
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chopade A., 2019, 2019 INT C COMP COMM, P1
   Dave S., 2020, ARXIV200700864
   Delmas A., 2017, ARXIV170600504
   Delmas A., 2018, CORR
   Ding X., 2019, PROC INT C MACH LEAR, P1607
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gschwend D., 2020, ARXIV200506892
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isakedo, 2020, DNNSIM
   Jang JW, 2021, CONF PROC INT SYMP C, P15, DOI 10.1109/ISCA52012.2021.00011
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lascorz AD, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P28, DOI 10.1145/3352460.3358295
   Liu BS, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P733, DOI 10.1145/3287624.3287638
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Qiu KN, 2020, INT S HIGH PERF COMP, P315, DOI 10.1109/HPCA47549.2020.00034
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siu K, 2018, I S WORKL CHAR PROC, P111, DOI 10.1109/IISWC.2018.8573527
   Sze Vivienne, 2020, SYNTHESIS LECT COMPU, DOI DOI 10.2200/S01004ED1V01Y202004CAC050
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Venkataramani S, 2021, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA52012.2021.00021
   Wechsler Ofri, 2019, 2019 IEEE Hot Chips 31 Symposium (HCS), DOI 10.1109/HOTCHIPS.2019.8875671
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 39
TC 2
Z9 2
U1 0
U2 8
PD JUL
PY 2022
VL 30
IS 7
BP 860
EP 868
DI 10.1109/TVLSI.2022.3167449
EA APR 2022
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Dhilleswararao, P
   Boppu, S
   Manikandan, MS
   Cenkeramaddi, LR
AF Dhilleswararao, Pudi
   Boppu, Srinivas
   Manikandan, M. Sabarimalai
   Cenkeramaddi, Linga Reddy
TI Efficient Hardware Architectures for Accelerating Deep Neural Networks:
   Survey
SO IEEE ACCESS
DT Article
DE Machine learning; field programmable gate array (FPGA); deep neural
   networks (DNN); deep learning (DL); application specific integrated
   circuits (ASIC); artificial intelligence (AI); central processing unit
   (CPU); graphics processing unit (GPU); hardware accelerators
ID FPGA IMPLEMENTATION; PERFORMANCE; DESIGN; CNN; THROUGHPUT; DADIANNAO;
   MACHINE; SPARSE
AB In the modern-day era of technology, a paradigm shift has been witnessed in the areas involving applications of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL). Specifically, Deep Neural Networks (DNNs) have emerged as a popular field of interest in most AI applications such as computer vision, image and video processing, robotics, etc. In the context of developed digital technologies and the availability of authentic data and data handling infrastructure, DNNs have been a credible choice for solving more complex real-life problems. The performance and accuracy of a DNN is a way better than human intelligence in certain situations. However, it is noteworthy that the DNN is computationally too cumbersome in terms of the resources and time to handle these computations. Furthermore, general-purpose architectures like CPUs have issues in handling such computationally intensive algorithms. Therefore, a lot of interest and efforts have been invested by the research fraternity in specialized hardware architectures such as Graphics Processing Unit (GPU), Field Programmable Gate Array (FPGA), Application Specific Integrated Circuit (ASIC), and Coarse Grained Reconfigurable Array (CGRA) in the context of effective implementation of computationally intensive algorithms. This paper brings forward the various research works on the development and deployment of DNNs using the aforementioned specialized hardware architectures and embedded AI accelerators. The review discusses the detailed description of the specialized hardware-based accelerators used in the training and/or inference of DNN. A comparative study based on factors like power, area, and throughput, is also made on the various accelerators discussed. Finally, future research and development directions, such as future trends in DNN implementation on specialized hardware accelerators, are discussed. This review article is intended to guide hardware architects to accelerate and improve the effectiveness of deep learning research.
C1 [Dhilleswararao, Pudi; Boppu, Srinivas] Indian Inst Technol Bhubaneswar, Sch Elect Sci, Bhubaneswar 752050, India.
   [Manikandan, M. Sabarimalai] Indian Inst Technol Bhubaneswar, Sch Elect Sci, Bhubaneswar 678557, India.
   [Cenkeramaddi, Linga Reddy] Univ Agder, Dept ICT, N-4879 Grimstad, Norway.
RP Cenkeramaddi, LR (corresponding author), Univ Agder, Dept ICT, N-4879 Grimstad, Norway.
EM linga.cenkeramaddi@uia.no
CR Abu Talib M, 2021, J SUPERCOMPUT, V77, P1897, DOI 10.1007/s11227-020-03325-8
   Advanced AI Embedded Systems, ADV AI EMBEDDED SYST
   Alwani M, 2016, INT SYMP MICROARCH
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], NVIDIA TESLA T4 SPEC
   [Anonymous], 2021, ETHOS ARM WIKICHIP
   [Anonymous], SILICON LABS BG24 MG
   [Anonymous], ULTRA96 V2
   [Anonymous], 2019, LEARN MORE LINARO MA
   [Anonymous], FAST TRACK EMBEDDED
   [Anonymous], VITIS
   [Anonymous], MAX78000 ARTIFICIAL
   [Anonymous], 2022, PHOTOS RASPBERRY PI
   [Anonymous], 2018, BEGINNERS GUIDE UNDE
   [Anonymous], 2018, CONVOLUTIONAL NEURAL
   [Anonymous], MYRIAD 2 MA2X5X VIS
   [Anonymous], JETSON NANODEVELOPER
   [Anonymous], INTEL MOVIDIUS MYRIA
   [Anonymous], VITIS UNIFIED SOFTWA
   [Anonymous], 2022, EDGE TPU COMPILER
   [Anonymous], XILINX KRIA ADAPTIVE
   [Anonymous], 2020, NVIDIA A100 TENSOR C
   [Anonymous], GLUON AI COPROCESSOR
   [Anonymous], MAIXDUINO
   [Anonymous], ACCELERATE FAST MATH
   [Anonymous], 2022, CORAL PRODUCTS
   [Anonymous], 2021, HIGH PERFORMING AI S
   [Anonymous], 2022, DEPLOY AI POWERED AU
   [Anonymous], KENDRYTE K210
   [Anonymous], HIGH LEVEL SYNTHESIS
   [Anonymous], XILINX VITIS MODEL Z
   [Anonymous], EDGE TPU DEV BOARD
   [Anonymous], PYNQ Z2
   [Anonymous], BITMAIN NEURAL NETWO
   [Anonymous], DPU CONVOLUTIONAL NE
   [Anonymous], 2021, ETHOS U55 ARM DEV
   [Anonymous], 2021, JETSON XAVIER NX
   Argal A, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P176, DOI 10.1109/CCWC.2018.8301732
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Benkrid K, 2002, THIRD INTERNATIONAL WORKSHOP ON DIGITAL AND COMPUTATIONAL VIDEO, PROCEEDINGS, P85, DOI 10.1109/DCV.2002.1218747
   Bergeron M., REAL TIME FACE RECOG
   Bhosale Y.H., 2022, 2022 8 INT C ADV COM, V1, P1398, DOI DOI 10.1109/ICACCS54159.2022.9785113
   Bhosale YH, 2022, PROC INT C IOT BLOCK, P1, DOI DOI 10.1109/ICIBT52874.2022.9807725
   Bhosale YH, 2023, NEURAL PROCESS LETT, V55, P3551, DOI 10.1007/s11063-022-11023-0
   Bishnoi L., 2018, PROC 8 INT C CLOUD C, P1
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Bouguezzi S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182272
   Boutros A, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242898
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Cardells-Tormo F., 2005, Proceedings. 2005 International Conference on Field Programmable Logic and Applications (IEEE Cat. No.05EX1155), P578
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chang JW, 2018, ASIA S PACIF DES AUT, P343, DOI 10.1109/ASPDAC.2018.8297347
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen ZH, 2014, MRS BULL, V39, P719, DOI 10.1557/mrs.2014.164
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   Chicco D., 2014, P 5 ACM C BIOINF COM, P533, DOI [DOI 10.1145/2649387.2649442, 10.1145/2649387.2649442, 10.1145/2649387]
   Chiu PS, 2020, IEEE ACCESS, V8, P62032, DOI 10.1109/ACCESS.2020.2984383
   Choi YK, 2010, IEEE T CIRCUITS-I, V57, P2119, DOI 10.1109/TCSI.2010.2041501
   Choquette J, 2021, IEEE MICRO, V41, P29, DOI 10.1109/MM.2021.3061394
   Clevert DA, 2016, Arxiv, DOI [arXiv:1511.07289, DOI 10.48550/ARXIV.1511.07289]
   Cloutier J., 1996, Proceedings of the Fifth International Conference on Microelectronics for Neural Networks and Fuzzy Systems. MicroNeuro'96, P330, DOI 10.1109/MNNFS.1996.493811
   Collobert R, BIGLEARN NIPS WORKSH
   Cong Hao, 2019, 2019 IEEE International Workshop on Signal Processing Systems (SiPS), P121, DOI 10.1109/SiPS47522.2019.9020540
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Courbariaux M, 2016, Arxiv, DOI [arXiv:1602.02830, DOI 10.48550/ARXIV.1602.02830]
   Crocioni G, 2020, IEEE ACCESS, V8, P122135, DOI 10.1109/ACCESS.2020.3007046
   Danopoulos D., 2018, PROC 7 INT C MODERN, P1
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Denil M., 2013, ADV NEURAL INFORM PR, V26, P2148, DOI DOI 10.5555/2999792.2999852
   Dong YM, 2020, NATL SCI REV, V7, P1092, DOI 10.1093/nsr/nwaa007
   Du L., 2018, MACH LEARN, DOI 10.1109/eGRID.2018.8598696
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   El-Maksoud A. J. A., 2021, IEEE ACCESS, V9
   Fan HX, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P17, DOI 10.1109/FPT.2018.00014
   Fan XT, 2018, IEEE T VLSI SYST, V26, P1098, DOI 10.1109/TVLSI.2018.2797600
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Feng XY, 2019, J MED INTERNET RES, V21, DOI 10.2196/12957
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Gainaru A, 2011, LECT NOTES COMPUT SC, V6804, P102, DOI 10.1007/978-3-642-21916-0_12
   Gartenberg C, 2020, VERGE
   Ghaffari A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122200
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gowda KMV, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101653
   Grigorescu S, 2020, Arxiv, DOI arXiv:1910.07738
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Guowei Zhang, 2021, ASPLOS 2021: Proceedings of the 26th International Conference on Architectural Support for Programming Languages and Operating Systems, P687, DOI 10.1145/3445814.3446702
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gustavson F. G., 1978, ACM Transactions on Mathematical Software, V4, P250, DOI 10.1145/355791.355796
   Guzhva A, 2009, LECT NOTES COMPUT SC, V5768, P373, DOI 10.1007/978-3-642-04274-4_39
   Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hannig F, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584660
   Hardesty L., 2013, RES BUILD ALL OPTICA
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hefenbrock D, 2010, ANN IEEE SYM FIELD P, P11, DOI 10.1109/FCCM.2010.12
   Heidorn C., 2019, J COMPUTERS, V14, P541, DOI DOI 10.17706/JCP.14.8.541-556
   Howard A., 2020, INTRO NEXT GENERATIO
   Hu H., 2022, J PHYS C SOLID STATE, V2171
   Hussein AS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010105
   Huynh T. V., 2022, INT J COMPUT DIGIT S, V11, P441, DOI DOI 10.12785/IJCDS/110136
   Im D, 2019, IEEE INT SYMP CIRC S
   Irmak H., 2021, 29 IEEE C SIGN PROC, P1, DOI DOI 10.1109/SIU53274.2021.9477823
   Irmak H, 2021, J LOW POWER ELECT AP, V11, DOI 10.3390/jlpea11030032
   Jafri SMAH, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P506, DOI 10.1109/HPCSim.2014.6903727
   Jia Y., 2014, CAFFE CONVOLUTIONAL
   Jin Wang, 2021, 2021 11th International Conference on Information Science and Technology (ICIST), P571, DOI 10.1109/ICIST52614.2021.9440554
   Jinsu Lee, 2021, IEEE Open Journal of the Solid-State Circuits Society, V1, P115, DOI 10.1109/OJSSCS.2021.3119554
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Justus D, 2018, IEEE INT CONF BIG DA, P3873, DOI 10.1109/BigData.2018.8622396
   Kalapothas S, 2022, INFORMATION, V13, DOI 10.3390/info13060279
   Kavitha M., 2022, FAKE NEWS DETECTION, P181
   Khan H, 2022, PHYTOCHEM REV, V21, P385, DOI 10.1007/s11101-021-09771-3
   Kim JY, 2021, ADV COMPUT, V122, P135, DOI 10.1016/bs.adcom.2020.11.002
   Kim Y, 2018, 2018 IEEE 3RD INTERNATIONAL WORKSHOPS ON FOUNDATIONS AND APPLICATIONS OF SELF* SYSTEMS (FAS*W), P37, DOI 10.1109/FAS-W.2018.00023
   Klock J. P., 2021, PROC 11 BRAZILIAN S, P1
   Kojima A, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P414, DOI 10.1109/FPT.2018.00087
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Lee J, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1408
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   Lewin DI, 2002, COMPUT SCI ENG, V4, P5, DOI [10.1109/5992.976430, 10.1109/5992.998634]
   Li BX, 2014, IEEE IJCNN, P4062, DOI 10.1109/IJCNN.2014.6889433
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Luong M.T., 2015, P 2015 C EMP METH NA, P1412, DOI DOI 10.18653/V1/D15-1166
   Lv P, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2020), P1894, DOI 10.1109/ICMCCE51767.2020.00415
   Maas AL, 2013, RECTIFIER NONLINEARI, DOI DOI 10.1016/0010-0277(84)90022-2
   Machupalli R, 2022, MICROPROCESS MICROSY, V89, DOI 10.1016/j.micpro.2022.104441
   Mathieu M, 2014, Arxiv, DOI [arXiv:1312.5851, 10.48550/ARXIV.1312.5851]
   Mei BF, 2003, LECT NOTES COMPUT SC, V2778, P61
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Mohan Puranjay, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2021. Lecture Notes in Electrical Engineering (LNEE 756), P657, DOI 10.1007/978-981-16-0749-3_52
   Monk S., 2016, PROGRAMMING RASPBERR
   Moolayil J. J., 2020, MEDIUM MAY
   Moolchandani D, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101887
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Nair V., 2010, ICML, P807
   Nikhil R, 2004, Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, Proceedings, P69
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   NVIDIA, 2017, NVIDIA TESLA V100 GP
   Nyamukuru MT, 2020, 2020 IEEE SECOND WORKSHOP ON MACHINE LEARNING ON EDGE IN SENSOR SYSTEMS (SENSYS-ML 2020), P19, DOI 10.1109/SenSysML50931.2020.00011
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park SW, 2015, IEEE T BIOMED CIRC S, V9, P838, DOI 10.1109/TBCAS.2015.2504563
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pham PH, 2012, MIDWEST SYMP CIRCUIT, P1044, DOI 10.1109/MWSCAS.2012.6292202
   Pietras M., 2014, PROC 24 INT C FIELD, P1
   Posewsky T., 2016, PROC INT C RECONFIGU, P1
   Posewsky T, 2018, MICROPROCESS MICROSY, V60, P151, DOI 10.1016/j.micpro.2018.04.004
   Prakash S, 2022, Arxiv, DOI arXiv:2201.01863
   Qadeer W, 2015, COMMUN ACM, V58, P85, DOI 10.1145/2735841
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Reuther A, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622867
   Rhu M, 2016, 2016 49 ANN IEEEACM, P1, DOI [DOI 10.1109/MICRO.2016.7783721, 10.1109/MICRO.2016.7783721]
   Ridnik T., 2021, ARXIV, DOI [10.48550/arXiv.2003.13630, DOI 10.48550/ARXIV.2003.13630]
   Saglam S, 2019, 2019 INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT), DOI 10.1109/isaect47714.2019.9069724
   Saha S., 2018, COMPREHENSIVE GUIDE
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sati V., 2020, P INT S AMB INT, P177
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Selvathi D, 2016, INTELL DECIS TECHNOL, V10, P341, DOI 10.3233/IDT-160261
   Service Robert, 2017, DNA COULD STORE ALL, DOI [10.1126/science.aal0852, DOI 10.1126/SCIENCE.AAL0852]
   Seshadri K, 2022, Arxiv, DOI arXiv:2102.10423
   Sharma H, 2016, INT SYMP MICROARCH
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Shi RB, 2013, APPL PHYS LETT, V102, DOI 10.1063/1.4795332
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shulaker MM, 2017, NATURE, V547, P74, DOI 10.1038/nature22994
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith GW, 2017, ARTS, V6, DOI 10.3390/arts6020005
   Srinivas S, 2016, FRONT ROBOT AI, V2, DOI 10.3389/frobt.2015.00036
   Sriram V., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P273, DOI 10.1109/FPT.2010.5681487
   Strigl D, 2010, EUROMICRO WORKSHOP P, P317, DOI 10.1109/PDP.2010.43
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sun J.(, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Svedin Martin, 2021, HEART '21: Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies, DOI 10.1145/3468044.3468053
   Syu DF, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P485, DOI 10.1109/GCCE.2015.7398519
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tanomoto M, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P73, DOI 10.1109/MCSoC.2015.41
   Texas Instruments, 2015, AM5729 SIT PROC
   TinyML Foundation, US
   Tkachenko Y, 2015, Arxiv, DOI arXiv:1504.01840
   Ngyen T, 2015, 23RD EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED, AND NETWORK-BASED PROCESSING (PDP 2015), P751, DOI 10.1109/PDP.2015.60
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vanderbauwhede W., 2013, HIGH PERFORMANCE COM
   Vasudevan A, 2017, IEEE INT CONF ASAP, P19, DOI 10.1109/ASAP.2017.7995254
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   vivalnk, US
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang T, 2019, Arxiv, DOI arXiv:1901.04988
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wong W. G., 2018, MORE DETAILS EMERGE
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Xiao H, 2021, IEICE T INF SYST, VE104D, P772, DOI 10.1587/transinf.2020EDL8153
   Xiong SY, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04347-6
   Yazdanbakhsh A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P482, DOI 10.1145/2830772.2830810
   Yin X, 2019, PEER PEER NETW APPL, V12, P310, DOI 10.1007/s12083-017-0615-z
   Zanc R, 2019, INT C INTELL COMP CO, P459, DOI [10.1109/ICCP48234.2019.8959715, 10.1109/iccp48234.2019.8959715]
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang JF, 2019, SYMP VLSI CIRCUITS, pC306, DOI 10.23919/VLSIC.2019.8778193
   Zhang L., PROC IEEE INT PARALL, P1056
   Zhang XY, 2013, PLOS ONE, V8, DOI [10.1371/journal.pone.0053931, 10.1371/journal.pone.0057805, 10.1371/journal.pone.0053995]
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI [10.1109/TNNLS.2018.2876865, 10.1109/biocas.2019.8918995]
   Zhu J, 2020, IEEE ACCESS, V8, P83224, DOI 10.1109/ACCESS.2020.2988311
   Zhu JY, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103645
NR 229
TC 2
Z9 2
U1 8
U2 13
PY 2022
VL 10
BP 131788
EP 131828
DI 10.1109/ACCESS.2022.3229767
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Page, A
   Attaran, N
   Shea, C
   Homayoun, H
   Mohsenin, T
AF Page, Adam
   Attaran, Nasrin
   Shea, Colin
   Homayoun, Houman
   Mohsenin, Tinoosh
GP IEEE
TI Low-Power Manycore Accelerator for Personalized Biomedical Applications
SO 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI)
DT Proceedings Paper
CT 26th ACM Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 18-20, 2016
CL Boston Univ, Dept  Elect & Comp Engn, Boston, MA
HO Boston Univ, Dept  Elect & Comp Engn
DE Low power; biomedical; manycore; accelerator; digital signal processing;
   machine learning; FPGA; embedded processors
ID PROCESSOR
AB Wearable personal health monitoring systems can offer a cost effective solution for human healthcare. These systems must provide both highly accurate, secured and quick processing and delivery of vast amount of data. In addition, wearable biomedical devices are used in inpatient, outpatient, and at home e-Patient care that must constantly monitor the patient's biomedical and physiological signals 24/7. These biomedical applications require sampling and processing multiple streams of physiological signals with strict power and area footprint. The processing typically consists of feature extraction, data fusion, and classification stages that require a large number of digital signal processing and machine learning kernels. In response to these requirements, in this paper, a low-power, domain-specific manycore accelerator named Power Efficient Nano Clusters (PENC) is proposed to map and execute the kernels of these applications. Experimental results show that the manycore is able to reduce energy consumption by up to 80% and 14% for DSP and machine learning kernels, respectively, when optimally parallelized. The performance of the proposed PENC manycore when acting as a coprocessor to an Intel Atom processor is compared with existing commercial off-the-shelf embedded processing platforms including Intel Atom, Xilinx Artix-7 FPGA, and NVIDIA TK1 ARM-A15 with GPU SoC. The results show that the PENC manycore architecture reduces the energy by as much as 10X while outperforming all off-the-shelf embedded processing platforms across all studied machine learning classifiers.
C1 [Page, Adam; Attaran, Nasrin; Shea, Colin; Mohsenin, Tinoosh] Univ Maryland, Dept Comp Sci Elect Engn, Baltimore, MD USA.
   [Homayoun, Houman] George Mason Univ Fairfax, Dept Elect Comp Engn, Fairfax, VA USA.
RP Page, A (corresponding author), Univ Maryland, Dept Comp Sci Elect Engn, Baltimore, MD USA.
EM apage2@umbc.edu; attar1@umbc.edu; cshea3@umbc.edu; hhomayou@gmu.edu;
   tinoosh@umbc.edu
CR [Anonymous], CIRC SYST ISCAS 2016
   [Anonymous], IEEE BIOM CIRC SYST
   [Anonymous], 2012, PROC IEEE S VLSI CIR, DOI DOI 10.1109/VLSIC.2012.6243837
   Bisasky J, 2013, INT SYM QUAL ELECT, P368, DOI 10.1109/ISQED.2013.6523637
   Bisasky J, 2012, IEEE INT SYMP CIRC S, P564, DOI 10.1109/ISCAS.2012.6272092
   Ghasemzadeh H, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2501626.2501636
   김철수, 2014, [Transactions of KSAE, 한국자동차공학회 논문집], V22, P1, DOI 10.7467/KSAE.2014.22.7.001
   Kulkarni A., 2016, ACM J EMERGING TECHN
   Kulkarni A., 2016, CIRC SYST ISCAS 2016
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Otto P, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P479, DOI 10.1109/ICCD.2015.7357153
   Page A., 2015, ENG MED BIOL SOC EMB
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Tavana MK, 2014, I SYMPOS LOW POWER E, P275, DOI 10.1145/2627369.2627654
   Venkat A, 2014, CONF PROC INT SYMP C, P121, DOI 10.1109/ISCA.2014.6853218
   Viseh S, 2015, IEEE T CIRCUITS-II, V62, P174, DOI 10.1109/TCSII.2014.2387683
   Yoo J, 2013, IEEE J SOLID-ST CIRC, V48, P214, DOI 10.1109/JSSC.2012.2221220
NR 17
TC 12
Z9 12
U1 0
U2 4
PY 2016
BP 63
EP 68
DI 10.1145/2902961.2902986
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Hanif, MA
   Khalid, F
   Shafique, M
AF Hanif, Muhammad Abdullah
   Khalid, Faiq
   Shafique, Muhammad
GP ACM
TI CANN: Curable Approximations for High-Performance Deep Neural Network
   Accelerators
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
DE Approximate Computing; Neural Network; MAC; DNN; High-Performance;
   Accelerator; Energy Efficiency; Power Efficiency
AB Approximate Computing (AC) has emerged as a means for improving the performance, area and power-/energy-efficiency of a digital design at the cost of output quality degradation. Applications like machine learning (e.g., using DNNs-deep neural networks) are highly computationally intensive and, therefore, can significantly benefit from AC and specialized accelerators. However, the accuracy loss introduced because of approximations in the DNN accelerator hardware can result in undesirable results. This paper presents a novel method to design high-performance DNN accelerators where approximation error(s) from one stage/part of the design is "completely" compensated in the subsequent stage/part while offering significant efficiency gains. Towards this, the paper also presents a case-study for improving the performance of systolic array-based hardware architectures, which are commonly used for accelerating state-of-the-art deep learning algorithms.
C1 [Hanif, Muhammad Abdullah; Khalid, Faiq; Shafique, Muhammad] Tech Univ Wien TU Wien, Vienna, Austria.
RP Hanif, MA (corresponding author), Tech Univ Wien TU Wien, Vienna, Austria.
EM muhammad.hanif@tuwien.ac.at; faiq.khalid@tuwien.ac.at;
   muhammad.shafique@tuwien.ac.at
CR [Anonymous], 2014, PROC DESIGN AUTOM TE
   [Anonymous], 2016, P 53 ANN DES AUT C A
   BAUGH CR, 1973, IEEE T COMPUT, VC 22, P1045, DOI 10.1109/T-C.1973.223648
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   El-Harouni W, 2017, DES AUT TEST EUROPE, P1384, DOI 10.23919/DATE.2017.7927209
   Hanif MA, 2018, J LOW POWER ELECTRON, V14, P520, DOI 10.1166/jolpe.2018.1575
   He X, 2018, I SYMPOS LOW POWER E, P110, DOI 10.1145/3218603.3218643
   Jacob Benoit, 2017, ABS171205877 CORR
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Mazahir S, 2018, IEEE DES TEST, V35, P65, DOI 10.1109/MDAT.2017.2772874
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Venkataramani S, 2012, DES AUT CON, P796
NR 19
TC 21
Z9 21
U1 0
U2 2
PY 2019
DI 10.1145/3316781.3317787
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Tuli, S
   Li, CH
   Sharma, R
   Jha, NK
AF Tuli, Shikhar
   Li, Chia-Hao
   Sharma, Ritvik
   Jha, Niraj K.
TI CODEBench: A Neural Architecture and Hardware Accelerator Co-Design
   Framework
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Active learning; application-specific integrated circuits;
   hardware-software co-design; machine learning; Neural Architecture
   Search; neural network accelerators
ID SPACE EXPLORATION; OPTIMIZATION; PERFORMANCE; NETWORKS; MODEL
AB Recently, automated co-design of machine learning (ML) models and accelerator architectures has attracted significant attention from both the industry and academia. However, most co-design frameworks either explore a limited search space or employ suboptimal exploration techniques for simultaneous design decision investigations of the ML model and the accelerator. Furthermore, training the ML model and simulating the accelerator performance is computationally expensive. To address these limitations, this work proposes a novel neural architecture and hardware accelerator co-design framework, called CODEBench. It comprises two new benchmarking sub-frameworks, CNNBench and AccelBench, which explore expanded design spaces of convolutional neural networks (CNNs) and CNN accelerators. CNNBench leverages an advanced search technique, Bayesian Optimization using Second-order Gradients and Heteroscedastic Surrogate Model for Neural Architecture Search, to efficiently train a neural heteroscedastic surrogate model to converge to an optimal CNN architecture by employing second-order gradients. AccelBench performs cycle-accurate simulations for diverse accelerator architectures in a vast design space. With the proposed co-design method, called Bayesian Optimization using Second-order Gradients and Heteroscedastic Surrogate Model for Co-Design of CNNs and Accelerators, our best CNN-accelerator pair achieves 1.4% higher accuracy on the CIFAR-10 dataset compared to the state-of-the-art pair while enabling 59.1% lower latency and 60.8% lower energy consumption. On the ImageNet dataset, it achieves 3.7% higher Top1 accuracy at 43.8% lower latency and 11.2% lower energy consumption. CODEBench outperforms the state-of-the-art framework, i.e., Auto-NBA, by achieving 1.5% higher accuracy and 34.7x higher throughput while enabling 11.0x lower energy-delay product and 4.0x lower chip area on CIFAR-10.
C1 [Tuli, Shikhar; Li, Chia-Hao; Sharma, Ritvik; Jha, Niraj K.] Princeton Univ, Dept Elect & Comp Engn, Princeton, NJ 08544 USA.
RP Tuli, S (corresponding author), Princeton Univ, Dept Elect & Comp Engn, Princeton, NJ 08544 USA.
EM stuli@princeton.edu; chli@princeton.edu; rsharma3@stanford.edu;
   jha@princeton.edu
CR Abdelfattah MS, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218596
   Abu-Aisheh Zeina, 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P271
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Benmeziane H., 2021, P IJCAI AUG, P4322, DOI [10.24963/ijcai.2021/592, DOI 10.24963/IJCAI.2021/592]
   Cai H., 2020, P INT C LEARN REPR, P1
   Cai H, 2019, P INT C LEARNING REP
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng HP, 2021, AAAI CONF ARTIF INTE, V35, P7090
   Choi J, 2018, Arxiv, DOI arXiv:1805.06085
   Choi K, 2021, DES AUT CON, P337, DOI 10.1109/DAC18074.2021.9586121
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai XL, 2019, IEEE T COMPUT, V68, P1487, DOI 10.1109/TC.2019.2914438
   Dai XL, 2019, PROC CVPR IEEE, P11390, DOI 10.1109/CVPR.2019.01166
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Dang DC, 2021, AAAI CONF ARTIF INTE, V35, P12275
   Elsken T, 2019, P INT C LEARNING REP
   Elsken T, 2019, J MACH LEARN RES, V20
   Fu YG, 2021, PR MACH LEARN RES, V139
   Gal Y, 2016, PR MACH LEARN RES, V48
   Github, 2022, CHAIDNNV2 HLS BAS DN
   Guler A, 2018, IEEE T VLSI SYST, V26, P1868, DOI 10.1109/TVLSI.2018.2832607
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang WW, 2020, IEEE T COMPUT AID D, V39, P4805, DOI 10.1109/TCAD.2020.2986127
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Chaojian, 2021, P INT C LEARNING REP
   Li L., 2020, P MACHINE LEARNING S, V2, P230, DOI DOI 10.1038/S41586-020-2867-7
   Li Y., 2020, P DAC, P1
   Lin J., 2020, ADV NEURAL INFORM PR, V33, P11711
   Lin M, 2014, Arxiv, DOI arXiv:1312.4400
   Lin YJ, 2021, DES AUT CON, P1051, DOI 10.1109/DAC18074.2021.9586250
   Liu H., 2018, ARXIV180609055
   Loshchilov I., 2018, P 7 INT C LEARNING R, P1, DOI 10.48550/arXiv.1711.05101
   Narain S, 2022, IEEE T COMPUT AID D, V41, P2970, DOI 10.1109/TCAD.2021.3118963
   Nvdla, 2022, NVIDIA DEEP LEARN AC
   Poremba M, 2015, IEEE COMPUT ARCHIT L, V14, P140, DOI 10.1109/LCA.2015.2402435
   Ramachandran P, 2017, Arxiv, DOI [arXiv:1710.05941, DOI 10.48550/ARXIV.1710.05941]
   Reagen B, 2017, I SYMPOS LOW POWER E
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schor David, 2018, HOT CHIPS 30 NVIDIA
   Shafaei A, 2014, IEEE COMP SOC ANN, P291, DOI 10.1109/ISVLSI.2014.94
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Siems Julien, 2022, P INT C LEARNING REP
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snoek J., 2012, PROC INT C NEURAL IN, V25, P2951
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Sun HB, 2022, DES AUT TEST EUROPE, P867, DOI 10.23919/DATE54114.2022.9774605
   Synopsys, 2022, SYN DES COMP
   Sze V., 2020, EFFICIENT PROCESSING
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tuli S., 2020, P INT C NEUR SYST, P1
   Tuli Shikhar, 2022, ARXIV
   Tuli S, 2022, IEEE T PARALL DISTR, V33, P101, DOI 10.1109/TPDS.2021.3087349
   Vaidya M, 2022, INT SYM CODE GENER, P325, DOI 10.1109/CGO53902.2022.9741281
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2016, ADV NEUR IN, V29
   White C, 2021, AAAI CONF ARTIF INTE, V35, P10293
   White Colin, 2020, ARXIV
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Xia WH, 2022, IEEE T EMERG TOP COM, V10, P962, DOI 10.1109/TETC.2021.3056031
   Xu K., 2018, INT C LEARN REPR ICL, DOI DOI 10.48550/ARXIV.1810.00826
   Xuefei Ning, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P189, DOI 10.1007/978-3-030-58601-0_12
   Yang L, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218676
   Yao ZW, 2021, AAAI CONF ARTIF INTE, V35, P10665
   Ying CS, 2018, Arxiv, DOI arXiv:1811.06992
   Ying Chris, 2019, 36 INT C MACH LEARN, P7105
   Yu Y, 2022, IEEE T EMERG TOP COM, V10, P237, DOI 10.1109/TETC.2020.3003328
   Yu Y, 2021, IEEE T COMPUT, V70, P45, DOI 10.1109/TC.2020.2983694
   Yu Y, 2018, IEEE T NANOTECHNOL, V17, P620, DOI 10.1109/TNANO.2017.2731871
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang MH, 2019, ADV NEUR IN, V32
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhou Yanqi, 2021, NAHAS NEURAL ARCHITE
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 92
TC 0
Z9 0
U1 0
U2 0
PD MAY
PY 2023
VL 22
IS 3
AR 51
DI 10.1145/3575798
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Jun, SW
   Nguyen, HT
   Gadepally, V
   Arvind
AF Jun, Sang-Woo
   Nguyen, Huy T.
   Gadepally, Vijay
   Arvind
GP IEEE
TI In-Storage Embedded Accelerator for Sparse Pattern Processing
SO 2016 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 13-15, 2016
CL Waltham, MA
AB We present a novel architecture for sparse pattern processing, using flash storage with embedded accelerators. Sparse pattern processing on large data sets is the essence of applications such as document search, natural language processing, bioinformatics, subgraph matching, machine learning, and graph processing. One slice of our prototype accelerator is capable of handling up to 1TB of data, and experiments show that it can outperform C/C++ software solutions on a 16-core system at a fraction of the power and cost; an optimized version of the accelerator can match the performance of a 48-core server.
C1 [Nguyen, Huy T.; Gadepally, Vijay] MIT, Lincoln Lab, Cambridge, MA 02139 USA.
   [Jun, Sang-Woo; Gadepally, Vijay; Arvind] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
RP Jun, SW (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
EM wjun@csail.mit.edu; hnguyen@ll.mit.edu; vijayg@ll.mit.edu;
   arvind@csail.mit.edu
CR ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999
   [Anonymous], HIGH PERF EXTR COMP
   [Anonymous], 2006, PROC 23 INT C MACH L
   [Anonymous], 2000, INT C MACH LEARN
   [Anonymous], 2014, SIAM WORKSH EX APPL
   [Anonymous], 1999, TECH REP
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P45, DOI 10.1093/nar/28.1.45
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dreher Patrick, 2016, PAR DISTR PROC S WOR
   Eggert J, 2004, IEEE IJCNN, P2529
   Elmore A, 2015, PROC VLDB ENDOW, V8, P1909
   Gadepally V, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P822, DOI 10.1109/IPDPSW.2015.19
   Gavin Brendan, 2016, PAR DISTR PROC S WOR
   Hauswald Johann, 2015, P 20 INT C ARCH SUPP
   Jun SW, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P1, DOI 10.1145/2749469.2750412
   Lichman M., 2013, UCI MACHINE LEARNING
   Mimno D, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P500
   Nguyen Huy, 2005, HIGH PERF EMB COMP W
   Steinbach M., 2000, P KDD WORKSH TEXT MI
   Sun Z, 2012, PROC VLDB ENDOW, V5, P788, DOI 10.14778/2311906.2311907
   Zaharia M., 2010, P 2 USENIX C HOT TOP
NR 22
TC 1
Z9 1
U1 0
U2 1
PY 2016
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chai, YJ
   Ko, GG
   Ting, WTM
   Bailey, L
   Brooks, D
   Wei, GY
AF Chai, Yuji
   Ko, Glenn G.
   Ting, Wei-Te Mark
   Bailey, Luke
   Brooks, David
   Wei, Gu-Yeon
GP IEEE Comp Soc
TI CoopMC: Algorithm-Architecture Co-Optimization for Markov Chain Monte
   Carlo Accelerators
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE Algorithm-Architecture Co-Design; Hardware Accelerator; Bayesian Machine
   Learning; Markov Chain Monte Carlo
AB Bayesian machine learning is useful for applications that may make high-risk decisions with limited, noisy, or unlabeled data, as it provides great data efficiency and uncertainty estimation. Building on previous efforts, this work presents CoopMC, an algorithm-architecture co-optimization for developing more efficient MCMC-based Bayesian inference accelerators. CoopMC utilizes dynamic normalization (DyNorm), LUT-based exponential kernels (TableExp), and log-domain kernel fusion (LogFusion) to reduce computational precision and shrink ALU area by 7.5x without noticeable reduction in model performance. Also, a Tree-based Gibbs sampler (TreeSampler) improves hardware runtime from O(N) to O(log(N)), an 8.7x speedup, and yields 1.9x better area efficiency than the existing state-of-the-art Gibbs sampling architecture. These methods have been tested on 10 diverse workloads using 3 different types of Bayesian models, demonstrating applicability to many Bayesian algorithms. In an end-to-end case study, these optimizations achieve a 33% logic area reduction, 62% power reduction, and 1.53x speedup over previous state-of-the-art end-to-end MCMC accelerators.
C1 [Chai, Yuji; Ko, Glenn G.; Ting, Wei-Te Mark; Bailey, Luke; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Cambridge, MA 02138 USA.
   [Chai, Yuji; Ko, Glenn G.; Ting, Wei-Te Mark; Bailey, Luke] Stochastic Inc, Atlanta, GA 30318 USA.
RP Chai, YJ (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.; Chai, YJ (corresponding author), Stochastic Inc, Atlanta, GA 30318 USA.
EM yuc927@g.harvard.edu
CR [Anonymous], 2012, BAYESIAN PARADIGM LI, P6, DOI [10.1002/9781119202141.ch2, DOI 10.1002/9781119202141.CH2]
   Banerjee SS, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P515, DOI 10.1145/3297858.3304019
   Berihuete A, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9030228
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Farquhar S, 2020, PR MACH LEARN RES, V108, P1352
   Foulds J, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P446
   Gal Y, 2016, PR MACH LEARN RES, V48
   Goudie R. J., 2017, J STAT SOFTW, V95
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hoffman MD, 2013, J MACH LEARN RES, V14, P1303
   Hong L, 2017, N AM ACTUAR J, V21, P228, DOI 10.1080/10920277.2016.1247720
   Hooker S., 2020, ARXIV200906489, Vabs
   Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175
   Khan M. E., 2018, PR MACH LEARN RES
   Ko G., 2020, P IEEE HOT CHIPS 32, P1, DOI [10.1109/HCS49909.2020.9220686, DOI 10.1109/HCS49909.2020.9220686]
   Ko G. G., 2020, 2020 IEEE S VLSI CIR, P1
   Ko GG, 2019, I C FIELD PROG LOGIC, P159, DOI 10.1109/FPL.2019.00033
   Ko GG, 2019, ANN IEEE SYM FIELD P, P334, DOI 10.1109/FCCM.2019.00075
   Korb K., 2010, BAYESIAN ARTIFICIAL, P491
   Korb KB, 2010, BAYESIAN ARTIFICIAL, VSecond, DOI DOI 10.1201/B10391
   Kucukelbir A, 2017, J MACH LEARN RES, V18, P1
   LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157
   Lesaffre E., 2020, BAYESIAN METHODS PHA
   Lunn DJ, 2000, STAT COMPUT, V10, P325, DOI 10.1023/A:1008929526011
   Manevski D, 2020, MATH BIOSCI, V329, DOI 10.1016/j.mbs.2020.108466
   Nielsen T.D., 2007, BAYESIAN NETWORKS DE, DOI [https://doi.org/10.1007/978-0-387-68282-2, DOI 10.1007/978-0-387-68282-2]
   Osawa K, 2019, ADV NEUR IN, V32
   Qin HT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107281
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rouhani BD, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P1, DOI 10.1145/3174243.3174259
   Scutari M, 2015, CH CRC TEXT STAT SCI, P1
   Shah N, 2021, ISSCC DIG TECH PAP I, V64, P150, DOI 10.1109/ISSCC42613.2021.9366061
   de Oliveira ACS, 2020, INFECT DIS MODEL, V5, P699, DOI 10.1016/j.idm.2020.09.005
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Tambe T, 2021, ISSCC DIG TECH PAP I, V64, P158, DOI 10.1109/ISSCC42613.2021.9366062
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Wang YE, 2019, INT SYM PERFORM ANAL, P177, DOI 10.1109/ISPASS.2019.00031
   Xie XL, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P195, DOI 10.1145/3307681.3325407
   Yao LM, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P937
   Yuan JH, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1351, DOI 10.1145/2736277.2741115
   Zhang XY, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P959, DOI 10.1145/3445814.3446697
NR 41
TC 2
Z9 2
U1 0
U2 2
PY 2022
BP 38
EP 52
DI 10.1109/HPCA53966.2022.00012
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Mohsin, MA
   Perera, DG
AF Mohsin, Mokhles A.
   Perera, Darshika G.
GP Assoc Comp Machinery
TI An FPGA-Based Hardware Accelerator for K-Nearest Neighbor Classification
   for Machine Learning on Mobile Devices
SO HEART 2018: PROCEEDINGS OF THE 9TH INTERNATIONAL SYMPOSIUM ON
   HIGHLY-EFFICIENT ACCELERATORS AND RECONFIGURABLE TECHNOLOGIES
DT Proceedings Paper
CT 9th International Symposium on Highly Efficient Accelerators and
   Reconfigurable Technologies (HEART)
CY JUN 20-22, 2018
CL Univ Toronto, Toronto, CANADA
HO Univ Toronto
AB Machine learning has become one of the cornerstones of information technology. Many machine learning algorithms have found their way into mobile devices, which have stringent requirements. Also, machine learning algorithms, such as classification and clustering, are becoming complex, requiring high processing power, thus affecting the speedup. In this paper, we introduce unique, novel, and efficient hardware architecture to accelerate the K-nearest neighbor classifier on mobile devices, considering constraints associated with these devices. We evaluate the efficiency of our hardware architecture, in terms of speedup, space, and accuracy. Our design is generic, parameterized, and scalable. Our hardware design achieves 127 times speedup compared to its software counter-part, and can also achieve 100% classification accuracy.
C1 [Mohsin, Mokhles A.; Perera, Darshika G.] Univ Colorado, Dept Elect & Comp Engn, Colorado Springs, CO 80933 USA.
RP Perera, DG (corresponding author), Univ Colorado, Dept Elect & Comp Engn, Colorado Springs, CO 80933 USA.
EM darshika.perera@uccs.edu
CR Amanpreet S, 2016, P INT C COMP SUST GL
   Hussain H., 2012, P 22 INT C FIELD PRO
   Kotsiantis SB, 2007, FRONT ARTIF INTEL AP, V160, P3
   Larose D.T., 2005, DISCOVERING KNOWLEDG
   Li ZH, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P600, DOI 10.1109/ICSICT.2016.7998989
   Perera D. G., 2011, 2011 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing, P100, DOI 10.1109/3PGCIC.2011.25
   Pu Y, 2015, P IEEE 23 INT S FIEL
   Satyanarayana N., 2009, P INT MULT ENG COMP
   Stamoulias I, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514641.2514649
NR 9
TC 7
Z9 7
U1 0
U2 1
PY 2018
DI 10.1145/3241793.3241810
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Hassanpour, M
   Riera, M
   González, A
AF Hassanpour, Mehdi
   Riera, Marc
   Gonzalez, Antonio
TI A Survey of Near-Data Processing Architectures for Neural Networks
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION
DT Article
DE machine learning; deep neural networks; near-data processing;
   near-memory-processing; processing-in-memory; conventional memory
   technology; emerging memory technology; hardware architecture
AB Data-intensive workloads and applications, such as machine learning (ML), are fundamentally limited by traditional computing systems based on the von-Neumann architecture. As data movement operations and energy consumption become key bottlenecks in the design of computing systems, the interest in unconventional approaches such as Near-Data Processing (NDP), machine learning, and especially neural network (NN)-based accelerators has grown significantly. Emerging memory technologies, such as ReRAM and 3D-stacked, are promising for efficiently architecting NDP-based accelerators for NN due to their capabilities to work as both high-density/low-energy storage and in/near-memory computation/search engine. In this paper, we present a survey of techniques for designing NDP architectures for NN. By classifying the techniques based on the memory technology employed, we underscore their similarities and differences. Finally, we discuss open challenges and future perspectives that need to be explored in order to improve and extend the adoption of NDP architectures for future computing platforms. This paper will be valuable for computer architects, chip designers, and researchers in the area of machine learning.
C1 [Hassanpour, Mehdi; Riera, Marc; Gonzalez, Antonio] Univ Politecn Catalunya UPC, Dept Comp Architecture, Barcelona 08034, Spain.
RP Riera, M (corresponding author), Univ Politecn Catalunya UPC, Dept Comp Architecture, Barcelona 08034, Spain.
EM mehdi@ac.upc.edu; mriera@ac.upc.edu; antonio@ac.upc.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], 2012, COMPUTER ARCHITECTUR
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Bojarski Mariusz, 2016, arXiv
   Burger D, 1996, 23RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, PROCEEDINGS, P78, DOI 10.1145/232974.232983
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P., 2015, PROCESSING IN MEMORY
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Dally W.J, 2015, LECT SLIDES
   Davis WR, 2005, IEEE DES TEST COMPUT, V22, P498, DOI 10.1109/MDT.2005.136
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Do Jaeyoung, 2013, P 2013 ACM SIGMOD IN, P1221
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Han Song, 2015, C NEUR INF PROC SYST
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   Hybrid Memory Cube Consortium, 2014, HYBRID MEMORY CUBE S
   Imani M, 2020, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA47549.2020.00011
   Jaeger H., 2002, TUTORIAL TRAINING RE
   Jiménez DA, 2001, HPCA: SEVENTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTING ARCHITECTURE, PROCEEDINGS, P197, DOI 10.1109/HPCA.2001.903263
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Këpuska V, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P99, DOI 10.1109/CCWC.2018.8301638
   Kestor G, 2013, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2013.6704670
   Kim D, 2018, IEEE T COMPUT AID D, V37, P2360, DOI 10.1109/TCAD.2018.2858358
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li SC, 2016, DES AUT CON, DOI [10.1145/2897937.2898064, 10.1109/ICAUMS.2016.8479697]
   Lopez G., 2017, INT C APPL HUMAN FAC
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mittal S, 2019, MACH LEARN KNOW EXTR, V1, P75, DOI 10.3390/make1010005
   Pan Y, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2018.2848625
   Pandiyan D, 2014, I S WORKL CHAR PROC, P171, DOI 10.1109/IISWC.2014.6983056
   Rosenblatt F., 1962, PRINCIPLES NEURODYNA
   Rosenfeld P., 2012, UMDSCA20121001
   Ruan ZY, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P379
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seshadri S., 2014, 11 USENIX S OPERATIN
   Seshadri Vivek, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P185, DOI 10.1145/2540708.2540725
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Siegl P, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P295, DOI 10.1145/2989081.2989087
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Song Y.H., 2014, P FLASH MEM SUMM 201
   STONE HS, 1970, IEEE T COMPUT, VC 19, P73, DOI 10.1109/TC.1970.5008902
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   VONNEUMANN J, 1993, IEEE ANN HIST COMPUT, V15, P28
   Wang XW, 2019, INT S HIGH PERF COMP, P81, DOI 10.1109/HPCA.2019.00029
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
NR 60
TC 1
Z9 1
U1 0
U2 4
PD MAR
PY 2022
VL 4
IS 1
BP 66
EP 102
DI 10.3390/make4010004
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Li, ZY
   Wang, ZH
   Xu, L
   Dong, Q
   Liu, BW
   Su, CI
   Chu, WT
   Tsou, G
   Chih, YD
   Chang, TYJ
   Sylvester, D
   Kim, HS
   Blaauw, D
AF Li, Ziyun
   Wang, Zhehong
   Xu, Li
   Dong, Qing
   Liu, Bowen
   Su, Chin-I
   Chu, Wen-Ting
   Tsou, George
   Chih, Yu-Der
   Chang, Tsung-Yung Jonathan
   Sylvester, Dennis
   Kim, Hun-Seok
   Blaauw, David
TI RRAM-DNN: An RRAM and Model-Compression Empowered All-Weights-On-Chip
   DNN Accelerator
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Random access memory; Computer architecture; System-on-chip; Nonvolatile
   memory; Computational modeling; Bandwidth; Arrays; Deep learning; deep
   neural network (DNN) ASIC; machine learning (ML) hardware; mobile; model
   compression; non-volatile memory; resistive random access memory (RRAM)
ID MACRO; SCHEME; READ
AB This article presents an energy-efficient deep neural network (DNN) accelerator with non-volatile embedded resistive random access memory (RRAM) for mobile machine learning (ML) applications. This DNN accelerator implements weight pruning, non-linear quantization, and Huffman encoding to store all weights on RRAM, enabling single-chip processing for large neural network models without external memory. A four-core parallel and programmable architecture adapts to various neural network configurations with high utilization. We introduce a customized RRAM macro with a dynamic clamping offset-canceling sense amplifier (DCOCSA) that achieves sub-microampere input offset. The on-chip decompression and memory error-resilient scheme enables 16 million (M) 8-bit (decompressed) weights on a single-chip using 24 Mb RRAM. The proposed RRAM-DNN is the first digital DNN accelerator featuring 24 Mb RRAM as all-on-chip weight storage to eliminate energy-consuming off-chip memory accesses. The fabricated design performs the complete inference process of the ResNet-18 model while consuming 127.9 mW power in TSMC-22 nm ULL CMOS. The RRAM-DNN accelerator achieves peak performance of 123 GOPs with 8-bit precision, exhibiting measured energy efficiency of 0.96 TOPs/W.
C1 [Li, Ziyun; Wang, Zhehong; Xu, Li; Liu, Bowen; Sylvester, Dennis; Kim, Hun-Seok; Blaauw, David] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
   [Dong, Qing] TSMC, San Jose, CA 95134 USA.
   [Su, Chin-I; Chu, Wen-Ting; Tsou, George; Chih, Yu-Der; Chang, Tsung-Yung Jonathan] TSMC, Hsinchu 30086, Taiwan.
RP Wang, ZH (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
EM liziyun@umich.edu; zhehongw@umich.edu
CR [Anonymous], 1957, PERCEPTRON PERCEIVIN
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Chang MF, 2015, IEEE J SOLID-ST CIRC, V50, P2786, DOI 10.1109/JSSC.2015.2472601
   Chang MF, 2015, IEEE J SOLID-ST CIRC, V50, P2188, DOI 10.1109/JSSC.2015.2424972
   Chen A, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chou CC, 2018, ISSCC DIG TECH PAP I, P478
   De Sandre Guido, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P268, DOI 10.1109/ISSCC.2010.5433911
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denton Emily L, 2014, ADV NEURAL INFORM PR, DOI DOI 10.5555/2968826.2968968
   Dong Q, 2019, IEEE J SOLID-ST CIRC, V54, P231, DOI 10.1109/JSSC.2018.2872584
   Han S., 2015, ARXIV151000149
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Kim Y.-D., 2015, ARXIV151106530
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Li Z., 2019, THESIS U MICHIGAN AN
   Li ZY, 2019, ISSCC DIG TECH PAP I, V62, P134, DOI [10.1109/ISSCC.2019.8662397, 10.1109/isscc.2019.8662397]
   Lo CP, 2019, IEEE J SOLID-ST CIRC, V54, P584, DOI 10.1109/JSSC.2018.2873588
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Redmon J., 2016, ARXIV160207360, P779
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Seung Ryul Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P71, DOI 10.1109/VLSIT.2012.6242466
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   Wang Z., 2020, 2020 IEEE 91 VEHICUL, P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9128938
   Wei LQ, 2019, ISSCC DIG TECH PAP I, V62, P214, DOI 10.1109/ISSCC.2019.8662444
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Wu TF, 2019, ISSCC DIG TECH PAP I, V62, P226, DOI 10.1109/ISSCC.2019.8662402
   Xue CX, 2020, IEEE J SOLID-ST CIRC, V55, P203, DOI 10.1109/JSSC.2019.2951363
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Zhang JF, 2019, SYMP VLSI CIRCUITS, pC306, DOI 10.23919/VLSIC.2019.8778193
   Zisserman A., 2014, 14091556 ARXIV
NR 38
TC 13
Z9 13
U1 3
U2 26
PD APR
PY 2021
VL 56
IS 4
BP 1105
EP 1115
DI 10.1109/JSSC.2020.3045369
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Morabito, R
   Chiang, M
AF Morabito, Roberto
   Chiang, Mung
GP IEEE COMP SOC
TI Demo: Discover, Provision, and Orchestration of Machine Learning
   Inference Services in Heterogeneous Edge
SO 2021 IEEE 41ST INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS 2021)
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 41st IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY JUL 07-10, 2021
CL ELECTR NETWORK
DE Distributed Machine Learning; Machine Learning Inference; Edge
   Computing; Internet of Things
AB In recent years, the research community started to extensively study how edge computing can enhance the provisioning of a seamless and performing Machine Learning (ML) experience. Boosting the performance of ML inference at the edge became a driving factor especially for enabling those use-cases in which proximity to the data sources, near real-time requirements, and need of a reduced network latency represent a determining factor. The growing demand of edge-based ML services has been also boosted by an increasing market release of small-form factor inference accelerators devices that feature, however, heterogeneous and not fully interoperable software and hardware characteristics. A key aspect that has not yet been fully investigated is how to discover and efficiently optimize the provision of ML inference services in distributed edge systems featuring heterogeneous edge inference accelerators not neglecting also that the limited devices computation capabilities may imply the need of orchestrating the inference execution provisioning among the different system's devices. The main goal of this demo is to showcase how ML inference services can be agnostically discovered, provisioned, and orchestrated in a cluster of heterogeneous and distributed edge nodes.
C1 [Morabito, Roberto] Princeton Univ, Sch Elect Engn, Princeton, NJ 08544 USA.
   [Morabito, Roberto] Ericsson Res, Plano, TX 75024 USA.
   [Chiang, Mung] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Morabito, R (corresponding author), Princeton Univ, Sch Elect Engn, Princeton, NJ 08544 USA.; Morabito, R (corresponding author), Ericsson Res, Plano, TX 75024 USA.
EM roberto.morabito@princeton.edu; chiang@purdue.edu
CR Antonini M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL WORKSHOP ON CHALLENGES IN ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR INTERNET OF THINGS (AICHALLENGEIOT '19), P49, DOI 10.1145/3363347.3363363
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Chen X, 2018, IEEE NETWORK, V32, P61, DOI 10.1109/MNET.2018.1700145
   Howard A. G., 2017, ARXIV
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Sanchez-Iborra R, 2020, IEEE CIRC SYST MAG, V20, P4, DOI 10.1109/MCAS.2020.3005467
   Wood T, 2019, COMPUTER NERIVORKS, V53, P2933
   Zhou Z, 2019, P IEEE, V107, P1738, DOI 10.1109/JPROC.2019.2918951
NR 8
TC 1
Z9 1
U1 0
U2 1
PY 2021
BP 1116
EP 1119
DI 10.1109/ICDCS51616.2021.00115
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT J
AU Edelen, A
   Neveu, N
   Frey, M
   Huber, Y
   Mayes, C
   Adelmann, A
AF Edelen, Auralee
   Neveu, Nicole
   Frey, Matthias
   Huber, Yannick
   Mayes, Christopher
   Adelmann, Andreas
TI Machine learning for orders of magnitude speedup in multiobjective
   optimization of particle accelerator systems
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
ID GENETIC ALGORITHM
AB High-fidelity physics simulations are powerful tools in the design and optimization of charged particle accelerators. However, the computational burden of these simulations often limits their use in practice for design optimization and experiment planning. It also precludes their use as on-line models tied directly to accelerator operation. We introduce an approach based on machine learning to create nonlinear, fast-executing surrogate models that are informed by a sparse sampling of the physics simulation. The models are O(10(6))-O(10(7)) times more computationally efficient to execute. We also demonstrate that these models can be reliably used with multiobjective optimization to obtain orders-of-magnitude speedup in initial design studies and experiment planning. For example, we required 132 times fewer simulation evaluations to obtain an equivalent solution for our main test case, and initial studies suggest that between 330-550 times fewer simulation evaluations are needed when using an iterative retraining process. Our approach enables new ways for high-fidelity particle accelerator simulations to be used, at comparatively little computational cost.
C1 [Edelen, Auralee; Neveu, Nicole; Mayes, Christopher] SLAC Natl Lab, Menlo Pk, CA 94025 USA.
   [Frey, Matthias; Huber, Yannick; Adelmann, Andreas] Paul Scherrer Inst, CH-5232 Villigen, Switzerland.
RP Edelen, A (corresponding author), SLAC Natl Lab, Menlo Pk, CA 94025 USA.
EM edelen@slac.stanford.edu; andreas.adelmann@psi.ch
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adelmann A, 2019, SIAM-ASA J UNCERTAIN, V7, P383, DOI 10.1137/16M1061928
   Adelmann A, 2016, COMPUT PHYS COMMUN, V207, P83, DOI 10.1016/j.cpc.2016.05.013
   Allen CK, 2002, PHYS REV SPEC TOP-AC, V5, DOI 10.1103/PhysRevSTAB.5.124202
   Alonso JR, 2019, NAT REV PHYS, V1, P533, DOI 10.1038/s42254-019-0095-6
   [Anonymous], 1 ICFA MACH LEAN WOR
   [Anonymous], INT C ART INT STAT A
   [Anonymous], P PAC VANC CA
   [Anonymous], 2015, DEEP LEARNING PYTHON
   [Anonymous], P IPAC 2015 RICHM VA
   [Anonymous], P IPAC 2018 VANC CAN
   [Anonymous], DEEP KERNEL LEARNING
   [Anonymous], 2014, UNCERTAINTY QUANTIFI
   [Anonymous], ICML
   [Anonymous], P IPAC 2016 BUS KOR
   [Anonymous], P INT COMP ACC PHYS
   [Anonymous], P IPAC 2017 COP DENM
   [Anonymous], P 4 INT PART ACC C I
   [Anonymous], THESIS
   [Anonymous], ARXIV190905963
   [Anonymous], ONLINE STORAGE RING
   [Anonymous], P 3 INT PART ACC C N
   [Anonymous], NEURIPS DEEP LEARN P
   [Anonymous], 2016, ICML
   [Anonymous], 2000, LS287 ARG NAT LAB
   [Anonymous], ADV PROT LIN ONL MOD
   [Anonymous], 2019, MACH LEARN PHYS SCI
   [Anonymous], UAI 16 P 32 C UNC AR
   [Anonymous], INTERNAL REPORT
   [Anonymous], 2019, NEURIPS MACHINE LEAR
   [Anonymous], P INT FREE EL LAS C
   [Anonymous], ARXIV190506654
   [Anonymous], P NAPAC 2016 CHIC IL
   [Anonymous], P 9 INT PART ACC C I
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], P NAPAC 2016
   [Anonymous], P PART ACC C DALL TX
   B??ck T., 1996, EVOLUTION STRATEGIES, DOI DOI 10.1093/OSO/9780195099713.001.0001
   Bazarov IV, 2005, PHYS REV SPEC TOP-AC, V8, DOI 10.1103/PhysRevSTAB.8.034202
   Bungau A, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.141802
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Debusschere B., 2017, HDB UNCERTAINTY QUAN, P1807
   Debusschere BJ, 2004, SIAM J SCI COMPUT, V26, P698, DOI 10.1137/S1064827503427741
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Gai W, 2012, J PLASMA PHYS, V78, P339, DOI 10.1017/S0022377812000037
   Gulliford C, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.073401
   Ha G, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.121301
   Halbach K., 1976, Particle Accelerators, V7, P213
   Hofler A, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.010101
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Lehe R, 2016, COMPUT PHYS COMMUN, V203, P66, DOI 10.1016/j.cpc.2016.02.007
   Li YP, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P4220, DOI 10.1109/WCICA.2010.5553934
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI DOI 10.1016/S0079-7421(08)60536-8
   McIntire M, 2016, UAI
   MEISS JD, 1992, REV MOD PHYS, V64, P795, DOI 10.1103/RevModPhys.64.795
   Mitchell M., 1996, INTRO GENETIC ALGORI
   Neal R. M., 2012, BAYESIAN LEARNING NE
   Neveu N, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.054602
   Pang X, 2014, NUCL INSTRUM METH A, V741, P124, DOI 10.1016/j.nima.2013.12.042
   Rasmussen C. E., 2006, GAUSSIAN PROCESSES M, DOI DOI 10.1142/S0129065704001899
   Ryne R, 2005, J PHYS CONF SER, V16, P210, DOI 10.1088/1742-6596/16/1/028
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Sobol IM, 2001, MATH COMPUT SIMULAT, V55, P271, DOI 10.1016/S0378-4754(00)00270-6
   Sudret B, 2008, RELIAB ENG SYST SAFE, V93, P964, DOI 10.1016/j.ress.2007.04.002
   Vapnik V, 1998, ADAPTIVE LEARNING SY
   Vay JL, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.130405
   Vay JL, 2013, J COMPUT PHYS, V243, P260, DOI 10.1016/j.jcp.2013.03.010
   WARREN JL, 1985, IEEE T NUCL SCI, V32, P2870, DOI 10.1109/TNS.1985.4334210
   Yang JJ, 2013, NUCL INSTRUM METH A, V704, P84, DOI 10.1016/j.nima.2012.12.050
NR 76
TC 49
Z9 52
U1 0
U2 12
PD APR 8
PY 2020
VL 23
IS 4
AR 044601
DI 10.1103/PhysRevAccelBeams.23.044601
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Chen, RQ
   Wu, TY
   Zheng, YC
   Ling, M
AF Chen, Ruiqi
   Wu, Tianyu
   Zheng, Yuchen
   Ling, Ming
TI MLoF: Machine Learning Accelerators for the Low-Cost FPGA Platforms
SO APPLIED SCIENCES-BASEL
DT Article
DE Internet of Things; machine learning; embedded system; FPGA; hardware
   accelerator
ID NETWORKS; IMPLEMENTATION; CLASSIFICATION; IOT
AB In Internet of Things (IoT) scenarios, it is challenging to deploy Machine Learning (ML) algorithms on low-cost Field Programmable Gate Arrays (FPGAs) in a real-time, cost-efficient, and high-performance way. This paper introduces Machine Learning on FPGA (MLoF), a series of ML IP cores implemented on the low-cost FPGA platforms, aiming at helping more IoT developers to achieve comprehensive performance in various tasks. With Verilog, we deploy and accelerate Artificial Neural Networks (ANNs), Decision Trees (DTs), K-Nearest Neighbors (k-NNs), and Support Vector Machines (SVMs) on 10 different FPGA development boards from seven producers. Additionally, we analyze and evaluate our design with six datasets, and compare the best-performing FPGAs with traditional SoC-based systems including NVIDIA Jetson Nano, Raspberry Pi 3B+, and STM32L476 Nucle. The results show that Lattice's ICE40UP5 achieves the best overall performance with low power consumption, on which MLoF averagely reduces power by 891% and increases performance by 9 times. Moreover, its cost, power, Latency Production (CPLP) outperforms SoC-based systems by 25 times, which demonstrates the significance of MLoF in endpoint deployment of ML algorithms. Furthermore, we make all of the code open-source in order to promote future research.
C1 [Chen, Ruiqi; Wu, Tianyu] Nanjing Renmian Integrated Circuit Co Ltd, VeriMake Innovat Lab, Nanjing 210088, Peoples R China.
   [Wu, Tianyu] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.
   [Zheng, Yuchen] Univ North Carolina Chapel Hill, Dept Comp Sci, Chapel Hill, NC 27514 USA.
   [Ling, Ming] Southeast Univ, Natl ASIC Syst Engn Technol Res Ctr, Nanjing 210096, Peoples R China.
RP Ling, M (corresponding author), Southeast Univ, Natl ASIC Syst Engn Technol Res Ctr, Nanjing 210096, Peoples R China.
EM rickychen@verimake.com; twu15@ece.ubc.ca; felix02@email.unc.edu;
   trio@seu.edu.cn
CR AKIMA H, 1970, J ACM, V17, P589, DOI 10.1145/321607.321609
   Arzamasov V., 2018, P 2018 IEEE INT C CO, P1, DOI DOI 10.1109/SMARTGRIDCOMM.2018.8587498
   Attaran N, 2018, IEEE T CIRCUITS-II, V65, P2032, DOI 10.1109/TCSII.2018.2799821
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Batista GC, 2020, MICROELECTRON J, V105, DOI 10.1016/j.mejo.2020.104907
   Brandalero M, 2020, 2020 INTERNATIONAL CONFERENCE ON OMNI-LAYER INTELLIGENT SYSTEMS (IEEE COINS 2020), P208, DOI 10.1109/coins49042.2020.9191672
   Chen H, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101739
   Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016
   Crocioni G, 2020, IEEE ACCESS, V8, P122135, DOI 10.1109/ACCESS.2020.3007046
   Dellamonica J, 2011, CRIT CARE, V15, DOI 10.1186/cc10587
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Faraji SR, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180836
   Garofalo A, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0155
   Ge F, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050497
   Gong ZQ, 2019, IEEE ACCESS, V7, P64323, DOI 10.1109/ACCESS.2019.2917620
   Hu YF, 2006, DES AUT CON, P574, DOI 10.1109/DAC.2006.229293
   Intelligent Automation Inc, DEEPIP FNN
   Jindal Mansi, 2019, 2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P430, DOI 10.1109/ICCCIS48478.2019.8974551
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   KBV, 2021, PRAX
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lai L., 2018, CMSIS NN EFFICIENT N
   Lang R, 2018, IEEE POTENTIALS, V37, P6, DOI 10.1109/MPOT.2017.2716778
   Li H, 2018, IEEE NETWORK, V32, P96, DOI 10.1109/MNET.2018.1700202
   Meshram V., 2020, INT J ADV SCI TECHNO, V29, P5319
   Noronha DH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P110, DOI 10.1145/3289602.3293922
   Qian B, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3398020
   Ramachandran S, 2007, DIGITAL VLSI SYSTEMS, P255
   Roukhami M, 2019, IEEE ACCESS, V7, P102217, DOI 10.1109/ACCESS.2019.2931392
   Sakr F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092638
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Schäfer B, 2016, EUR PHYS J-SPEC TOP, V225, P569, DOI 10.1140/epjst/e2015-50136-y
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Slater WS, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286222
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
NR 37
TC 3
Z9 4
U1 5
U2 19
PD JAN
PY 2022
VL 12
IS 1
AR 89
DI 10.3390/app12010089
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT C
AU Hu, ZB
   Li, SR
   Schwartz, RLT
   Solyanik-Gorgone, M
   Nouri, BM
   Miscuglio, M
   Gupta, P
   Dalir, H
   Sorger, VJ
AF Hu, Zibu
   Li, Shurui
   Schwartz, Russell L. T.
   Solyanik-Gorgone, Maria
   Nouri, Behrouz Movahhed
   Miscuglio, Mario
   Gupta, Puneet
   Dalir, Hamed
   Sorger, Volker J.
BE Volpe, G
   Pereira, JB
   Brunner, D
   Ozcan, A
TI Batch Processing and Data Streaming Fourier-based Convolutional Neural
   Network Accelerator
SO EMERGING TOPICS IN ARTIFICIAL INTELLIGENCE (ETAI) 2022
SE Proceedings of SPIE
DT Proceedings Paper
CT Emerging Topics in Artificial Intelligence (ETAI)
CY AUG 21-25, 2022
CL San Diego, CA
DE convolution; accelerator; neural network; parallelization; diffraction;
   digital micromirror device
AB Decision-making through artificial neural networks with minimal latency is critical for numerous applications such as navigation, tracking, and real-time machine action systems. This requires machine learning hardware to process multidimensional data at high throughput. Unfortunately, handling convolution operations, the primary computational tool for data classification tasks, obeys challenging runtime complexity scaling laws. However, homomorphically implementing the convolution theorem in a Fourier optics display light processor can achieve a non-iterative O(1) runtime complexity for data inputs beyond 1,000 x 1,000 large matrices. Following this approach, here we demonstrate data streaming multi-kernel image batching using a Fourier Convolutional Neural Network (FCNN) accelerator. We show image batch processing of large-scale matrices as 2 million dot product multiplications performed by a digital light processing module in the Fourier domain. Furthermore, we further parallelize this optical FCNN system by exploiting multiple spatially parallel diffraction orders, achieving a 98x throughput improvement over state-of-the-art FCNN accelerators. A comprehensive discussion of the practical challenges associated with working at the edge of system capabilities highlights the problem of crosstalk and resolution scaling laws in the Fourier domain. Accelerating convolution by exploiting massive parallelism in display technology brings non-Van Neumann-based machine learning acceleration.
C1 [Hu, Zibu; Schwartz, Russell L. T.; Solyanik-Gorgone, Maria; Nouri, Behrouz Movahhed; Miscuglio, Mario; Dalir, Hamed; Sorger, Volker J.] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [Nouri, Behrouz Movahhed; Dalir, Hamed; Sorger, Volker J.] Upper Marlboro, Optelligence LLC, 10703 Marlboro Pike, Upper Marlboro, MD 20772 USA.
   [Li, Shurui; Gupta, Puneet] Univ Calif Los Angeles, Dept Elect & Comp Engn, Los Angeles, CA 90095 USA.
RP Sorger, VJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.; Sorger, VJ (corresponding author), Upper Marlboro, Optelligence LLC, 10703 Marlboro Pike, Upper Marlboro, MD 20772 USA.
EM sorger@gwu.edu
CR Alam MZ, 2018, NAT PHOTONICS, V12, P79, DOI 10.1038/s41566-017-0089-9
   Amin R, 2019, APL MATER, V7, DOI 10.1063/1.5109039
   Bhatt D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202470
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Chellapilla Kumar, 2005, CEAS
   George Jonathan K., 2021, SCI REP-UK, V11, P1
   Gu ZY, 2022, OPT EXPRESS, V30, P19416, DOI 10.1364/OE.456003
   Hu Z., 2021, PHOTONICS SWITCHING
   Hu Z., 2022, 3D IMAGE ACQUISITION
   Hu Zibo, 2019, FRONTIERS OPTICS
   Huang C, 2022, ADV PHYS-X, V7, DOI 10.1080/23746149.2021.1981155
   Huang C, 2019, IEEE PHOTONIC TECH L, V31, P1834, DOI 10.1109/LPT.2019.2948903
   Jha A, 2021, 2021 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Jiachi Ye, 2020, OPTICAL SOC AM
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li SR, 2021, Arxiv, DOI arXiv:2011.07391
   Li XQ, 2016, PROC INT CONF PARAL, P67, DOI 10.1109/ICPP.2016.15
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Ma X., 2022, HIGH DENSITY INTEGRA, DOI 10.21203/rs.3.rs-1833027/v1
   Ma Xiaoxuan, 2019, FRONTIERS OPTICS
   Maiti R, 2020, NAT PHOTONICS, V14, P578, DOI 10.1038/s41566-020-0647-4
   Meng JW, 2021, ADV PHOTON RES, V2, DOI 10.1002/adpr.202000033
   Mengu Deniz, 2021, B AM PHYS SOC
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Miscuglio M, 2020, OPTICA, V7, P1812, DOI 10.1364/OPTICA.408659
   Miscuglio M, 2018, OPT MATER EXPRESS, V8, P3851, DOI 10.1364/OME.8.003851
   Nahmias MA, 2018, OPT PHOTONICS NEWS, V29, P34
   Peserico Nicola, 2022, PROC SPIE, VIII
   Saponara S, 2021, J REAL-TIME IMAGE PR, V18, P889, DOI 10.1007/s11554-020-01044-0
   Shalf J, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0061
   Solyanik-Gorgone M, 2020, Arxiv, DOI arXiv:2011.08314
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Veli M, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20268-z
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Wright LG, 2022, NATURE, V601, P549, DOI 10.1038/s41586-021-04223-6
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yan T, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.023901
   Yang L, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P89, DOI [10.1109/ICCCBDA.2019.8725756, 10.1109/icccbda.2019.8725756]
   Zhao D, 2018, INT J COMPUT COMMUN, V13, P429, DOI 10.15837/ijccc.2018.3.3236
   Zhou TK, 2020, PHOTONICS RES, V8, P940, DOI 10.1364/PRJ.389553
   Zhu HH, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28702-0
NR 42
TC 1
Z9 1
U1 1
U2 5
PY 2022
VL 12204
AR 1220409
DI 10.1117/12.2633917
WC Computer Science, Artificial Intelligence; Neurosciences; Optics
DA 2023-11-11
ER

PT J
AU Trouli, GI
   Kornaros, G
AF Trouli, Georgia-Irene
   Kornaros, George
TI Automotive Virtual In-sensor Analytics for Securing Vehicular
   Communication
SO IEEE DESIGN & TEST
DT Article
DE Security; Sensor systems; Automotive engineering; Software; Sensor
   fusion; Hardware; secure vehicle communication; automotive in-sensor
   analytics; hardware classifier; virtual sensing; real-time CAN-bus
   analyzer; FPGA k-NN accelerator; machine learning-based virtual sensor
ID INTRUSION DETECTION
AB Editor's note: In this article, the authors design and demonstrate a CAN vehicle network gateway that employs machine learning to achieve real-time analysis of messages, to protect against cyber-attacks.--udeep Pasricha, Colorado State University
C1 [Trouli, Georgia-Irene; Kornaros, George] Hellen Mediterranean Univ, Iraklion, Greece.
RP Kornaros, G (corresponding author), Hellen Mediterranean Univ, Dept Elect & Comp Engn, Iraklion 71004, Greece.
EM kornaros@hmu.gr
CR Alippi C, 2012, LECT NOTES COMPUT SC, V7664, P664, DOI 10.1007/978-3-642-34481-7_81
   [Anonymous], 2017, 54 ACMEDACIEEE DESIG
   [Anonymous], P 17 ACM SIGKDD INT
   Bass T, 2000, COMMUN ACM, V43, P99, DOI 10.1145/332051.332079
   Cheng DB, 2014, LECT NOTES ARTIF INT, V8933, P499, DOI 10.1007/978-3-319-14717-8_39
   Coppola R, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2971482
   Hassani M., 2010, P 4 INT WORKSH KNOWL, P87
   Kangara M. G. M., 2016, Proceedings - International Fertiliser Society, P1
   Kornaros G., 2018, SOLUTIONS CYBER PHYS, P301, DOI 10.4018/978-1-5225-2845-6.ch012
   Kornilov G. P., 2019, 2019 IEEE INT C COMM, P1
   Lu N, 2014, IEEE INTERNET THINGS, V1, P289, DOI 10.1109/JIOT.2014.2327587
   Nakamura EF, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1267070.1267073
   Pham ND, 2010, INT J COMMUN SYST, V23, P1311, DOI 10.1002/dac.1104
   Sarma S., 2012, P ARM MONTR QC CAN, V4, P1
   Whitworth Jeff, 2014, ACM SIGMETRICS Performance Evaluation Review, V41, P82
   Wu WF, 2018, IEEE ACCESS, V6, P45233, DOI 10.1109/ACCESS.2018.2865169
NR 16
TC 2
Z9 2
U1 1
U2 5
PD JUN
PY 2020
VL 37
IS 3
BP 91
EP 98
DI 10.1109/MDAT.2020.2974914
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Giovannozzi, M
   Maclean, E
   Montanari, CE
   Valentino, G
   Van der Veken, FE
AF Giovannozzi, Massimo
   Maclean, Ewen
   Montanari, Carlo Emilio
   Valentino, Gianluca
   Van der Veken, Frederik E.
TI Machine Learning Applied to the Analysis of Nonlinear Beam Dynamics
   Simulations for the CERN Large Hadron Collider and Its Luminosity
   Upgrade
SO INFORMATION
DT Article
DE machine learning; CERN Large Hadron Collider; CERN High-Luminosity Large
   Hadron Collider; nonlinear beam dynamics; dynamic aperture
ID LHC
AB A Machine Learning approach to scientific problems has been in use in Science and Engineering for decades. High-energy physics provided a natural domain of application of Machine Learning, profiting from these powerful tools for the advanced analysis of data from particle colliders. However, Machine Learning has been applied to Accelerator Physics only recently, with several laboratories worldwide deploying intense efforts in this domain. At CERN, Machine Learning techniques have been applied to beam dynamics studies related to the Large Hadron Collider and its luminosity upgrade, in domains including beam measurements and machine performance optimization. In this paper, the recent applications of Machine Learning to the analyses of numerical simulations of nonlinear beam dynamics are presented and discussed in detail. The key concept of dynamic aperture provides a number of topics that have been selected to probe Machine Learning. Indeed, the research presented here aims to devise efficient algorithms to identify outliers and to improve the quality of the fitted models expressing the time evolution of the dynamic aperture.
C1 [Giovannozzi, Massimo; Maclean, Ewen; Montanari, Carlo Emilio; Van der Veken, Frederik E.] CERN, Beams Dept, Esplanade Particules 1, CH-1211 Geneva 23, Switzerland.
   [Montanari, Carlo Emilio] Univ Bologna, Dipartimento Fis & Astron, Via Irnerio 46, I-40126 Bologna, Italy.
   [Valentino, Gianluca; Van der Veken, Frederik E.] Univ Malta, Fac ICT, Dept Commun & Comp Engn, MSD-2080 Msida, Malta.
RP Giovannozzi, M (corresponding author), CERN, Beams Dept, Esplanade Particules 1, CH-1211 Geneva 23, Switzerland.
EM massimo.giovannozzi@cern.ch; ewen.hamish.maclean@cern.ch;
   carlo.emilio.montanari@cern.ch; gianluca.valentino@um.edu.mt;
   frederik.van.der.veken@cern.ch
CR Apollinari G., 2017, TECH REP CERN2017 00, DOI [10.23731/CYRM-2017-004, DOI 10.23731/CYRM-2017-004]
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Barranco J, 2017, OPEN ENG, V7, P379, DOI 10.1515/eng-2017-0042
   Bazzani A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.104003
   Bestmann P, 2007, IEEE PART ACC CONF, P25
   Bonaccorso G., 2019, HANDS ON UNSUPERVISE
   Bonetta R, 2020, PROTEINS, V88, P397, DOI 10.1002/prot.25832
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bozoki E., 1994, P 4 EUR PART ACC C E, P1589
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Bruning O. S., 2004, LHC DESIGN REPORT, DOI DOI 10.5170/CERN-2004-003-V-1
   Chalup SK, 2007, IEEE T SYST MAN CY C, V37, P297, DOI 10.1109/TSMCC.2006.886964
   Dal Pozzolo A, 2018, IEEE T NEUR NET LEAR, V29, P3784, DOI 10.1109/TNNLS.2017.2736643
   Edelen A., 2018, ARXIV181103172
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507
   Fartoukh S, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.111002
   Giovannozzi M, 2018, NUCL INSTRUM METH A, V908, P1, DOI 10.1016/j.nima.2018.08.019
   Giovannozzi M, 2018, NUCL INSTRUM METH A, V905, P171, DOI 10.1016/j.nima.2018.07.063
   Giovannozzi M, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.024001
   Giovannozzi M, 1997, INT J MOD PHYS C, V8, P155, DOI 10.1142/S0129183197000163
   Hussein S, 2019, IEEE T MED IMAGING, V38, P1777, DOI 10.1109/TMI.2019.2894349
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Li YJ, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.054601
   Maclean EH, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.034002
   Meier E., 2012, P 3 INT PART ACC C I, P2837
   Minh DL, 2018, IEEE ACCESS, V6, P55392, DOI 10.1109/ACCESS.2018.2868970
   Mitchell T.M., 1997, MACH LEARN, V1
   Nekhoroshev N, 1977, RUSS MATH SURVEYS, V32, P1, DOI DOI 10.1070/RM1977V032N06ABEH003859
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Su J, 2018, IEEE T VEH TECHNOL, V67, P5650, DOI 10.1109/TVT.2018.2819806
   Todesco E, 1996, PHYS REV E, V53, P4067, DOI 10.1103/PhysRevE.53.4067
   Vert J.-P., 2004, KERNEL METHODS COMPU, V47, P35
   Vilsmeier D, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.052801
   Wan JY, 2019, NUCL INSTRUM METH A, V946, DOI 10.1016/j.nima.2019.162683
   Xu XY, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.032805
NR 39
TC 3
Z9 3
U1 0
U2 1
PD FEB
PY 2021
VL 12
IS 2
AR 53
DI 10.3390/info12020053
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Rajabalipanah, M
   Ghasemi, SM
   Nosrati, N
   Basharkhah, K
   Yousefzadeh, S
   Navabi, Z
AF Rajabalipanah, Maryam
   Ghasemi, Seyedeh Maryam
   Nosrati, Nooshin
   Basharkhah, Katayoon
   Yousefzadeh, Saba
   Navabi, Zainalabedin
BE Dilillo, L
   Psarakis, M
   Siddiqua, T
TI Reducing DFT hardware overhead by use of a test microprogram in a
   microprogrammed hardware accelerator
SO 2020 33RD IEEE INTERNATIONAL SYMPOSIUM ON DEFECT AND FAULT TOLERANCE IN
   VLSI AND NANOTECHNOLOGY SYSTEMS (DFT)
SE IEEE International Symposium on Defect and Fault Tolerance in VLSI
   Systems
DT Proceedings Paper
CT 33rd IEEE International Symposium on Defect and Fault Tolerance in VLSI
   and Nanotechnology Systems (DFT)
CY OCT 19-21, 2020
CL ELECTR NETWORK
DE Microprogram testing; Microprogrammed Accelerator testing; Test
   Mechanisms; Online Test; Offline Test
AB Because of heavy repeated computations and concurrency in the execution of many machine learning applications, embedded hardware architectures based on reconfigurable accelerators have emerged as a convenient and efficient means of hardware implementation. The reloadable microinstructions in a microprogrammed architecture provide an opportunity for self-testing of the accelerator by a test microprogram. This paper describes a mechanism of testing microprogrammed accelerators of an embedded system. We utilize the accelerator microinstructions to test the datapath and controller of our existing home-grown accelerator, called iMPAC. For prototyping, this architecture is implemented on an FPGA and its testing is compared with a hard-wired controller utilizing scan and other standard test techniques.
C1 [Rajabalipanah, Maryam; Ghasemi, Seyedeh Maryam; Nosrati, Nooshin; Basharkhah, Katayoon; Yousefzadeh, Saba; Navabi, Zainalabedin] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
RP Rajabalipanah, M (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
EM m.rajabalipanah@ut.ac.ir; s_ma_ghasemy@ut.ac.ir;
   nosrati.nooshin@ut.ac.ir; basharkhah.kt96@ut.ac.ir;
   saba.yousefzadeh@ut.ac.ir; navabi@ut.ac.ir
CR Akbari O, 2018, DES AUT TEST EUROPE, P413, DOI 10.23919/DATE.2018.8342045
   Barkalov A., 2010, EWDTS, P73
   Bauer L, 2013, IEEE T COMPUT, V62, P1494, DOI 10.1109/TC.2013.53
   Bushnell M., 2004, SSBM, V17
   Cheong M, 2018, INT SOC DESIGN CONF, P11, DOI 10.1109/ISOCC.2018.8649896
   Duran J., 1983, MICRO 16. Proceedings of the 16th Annual Microprogramming Workshop, P55
   Geurkov V, 2016, IEEE ACCESS, V4, P2479, DOI 10.1109/ACCESS.2016.2571278
   Motaman S, 2019, IEEE J EM SEL TOP C, V9, P562, DOI 10.1109/JETCAS.2019.2933678
   Navabi Z., 2011, DIGITAL SYSTEM TEST
   Prabhakar R, 2018, IEEE MICRO, V38, P20, DOI 10.1109/MM.2018.032271058
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Yousefzadeh S., 2020, DDECS, P1
   Youssef S.B.H., 2019, IEEE WCNC, P1, DOI DOI 10.1109/wcnc.2019.8885479
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/dft50435.2020.9250763
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ober, M
   Hofmann, JA
   Sommer, L
   Weber, L
   Koch, A
AF Ober, Micha
   Hofmann, Jaco A.
   Sommer, Lukas
   Weber, Lukas
   Koch, Andreas
GP IEEE
TI High-Throughput Multi-Threaded Sum-Product Network Inference in the
   Reconfigurable Cloud
SO PROCEEDINGS OF H2RC 2019: 2019 FIFTH IEEE/ACM INTERNATIONAL WORKSHOP ON
   HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC)
DT Proceedings Paper
CT 5th IEEE/ACM International Workshop on Heterogeneous High-performance
   Reconfigurable Computing (H2RC)
CY NOV 17, 2019
CL Denver, CO
DE FPGA; SPN; Machine Learning; Graphical Models; Deep Models; Cloud
AB Large cloud providers have started to make powerful FPGAs available as part of their public cloud offers. One promising application area for this kind of instances is the acceleration of machine learning tasks.
   This work presents an accelerator architecture that uses multiple accelerator cores for the inference in so-called Sum-Product Networks and complements it with a host software interface that overlaps data-transfer and actual computation.
   The evaluation shows that, the proposed architecture deployed to Amazon AWS F1 instances is able to outperform a 12-core Xeon processor by a factor of up to 1.9x and a Nvidia Tesla V100 GPU by a factor of up to 6.6x.
C1 [Ober, Micha; Hofmann, Jaco A.; Sommer, Lukas; Weber, Lukas; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
RP Ober, M (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM ober@esa.tu-darmstadt.de; hofmann@esa.tu-darmstadt.de;
   sommer@esa.tu-darmstadt.de; weber@esa.tu-darmstadt.de;
   koch@esa.tu-darmstadt.de
CR [Anonymous], MICROSOFT FPGA WINS
   Chung E., 2017, HOT CHIPS 29
   de Dinechin F., 2011, IEEE DESIGN TEST COM
   Dua D, 2020, UCI MACHINE LEARNING
   Jouppi N. P., 2017, 44 ANN INT S COMP AR
   Korinth J., 2019, APPL RECONFIGURABLE
   Molina A., 2018, MIXED SUM PRODUCT NE
   Peharz R., 2015, P AISTATS
   Poon H., 2011, P UAI
   Pronobis A., 2017, ICAPS 2017 WORKSH PL
   Ratajczak M., 2018, SUM PRODUCT NETWORKS
   Sommer L., 2018, ICML 2018 WORKSH TRA
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
NR 13
TC 3
Z9 3
U1 0
U2 0
PY 2019
BP 26
EP 33
DI 10.1109/H2RC49586.2019.00009
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Dünner, C
   Parnell, T
   Jaggi, M
AF Dunner, Celestine
   Parnell, Thomas
   Jaggi, Martin
BE Guyon, I
   Luxburg, UV
   Bengio, S
   Wallach, H
   Fergus, R
   Vishwanathan, S
   Garnett, R
TI Efficient Use of Limited-Memory Accelerators for Linear Learning on
   Heterogeneous Systems
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 30 (NIPS 2017)
SE Advances in Neural Information Processing Systems
DT Proceedings Paper
CT 31st Annual Conference on Neural Information Processing Systems (NIPS)
CY DEC 04-09, 2017
CL Long Beach, CA
AB We propose a generic algorithmic building block to accelerate training of machine learning models on heterogeneous compute systems. Our scheme allows to efficiently employ compute accelerators such as GPUs and FPGAs for the training of large-scale machine learning models, when the training data exceeds their memory capacity. Also, it provides adaptivity to any system's memory hierarchy in terms of size and processing speed. Our technique is built upon novel theoretical insights regarding primal-dual coordinate methods, and uses duality gap information to dynamically decide which part of the data should be made available for fast processing. To illustrate the power of our approach we demonstrate its performance for training of generalized linear models on a large-scale dataset exceeding the memory size of a modern GPU, showing an order-of-magnitude speedup over existing approaches.
C1 [Dunner, Celestine; Parnell, Thomas] IBM Res Zurich, Zurich, Switzerland.
   [Jaggi, Martin] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
RP Dünner, C (corresponding author), IBM Res Zurich, Zurich, Switzerland.
EM cdu@zurich.ibm.com; tpa@zurich.ibm.com; martin.jaggi@epfl.ch
CR Bauschke HH, 2011, CMS BOOKS MATH, P1, DOI 10.1007/978-1-4419-9467-7
   Chang K. -W., 2011, P 17 ACM SIGKDD INT, P699
   Csiba Dominik, 2015, ICML 2015 P 32 INT C
   Dunner Celestine, 2016, P 33 INT C INT C MAC, P783
   Fercoq O, 2016, SIAM REV, V58, P739, DOI 10.1137/16M1085905
   Heinze C, 2016, JMLR WORKSH CONF PRO, V51, P875
   Matsushima S., 2012, P INT C KNOWL DISC D, P177
   Nutini J, 2015, PR MACH LEARN RES, V37, P1632
   Osokin A, 2016, PR MACH LEARN RES, V48
   Parnell T., 2017, P 6 INT WORKSH PAR D
   Perekrestenko D, 2017, PR MACH LEARN RES, V54, P869
   Qu Z, 2016, OPTIM METHOD SOFTW, V31, P829, DOI 10.1080/10556788.2016.1190360
   Shalev-Shwartz S, 2013, J MACH LEARN RES, V14, P567
   Smith V., 2016, COCOA GEN FRAMEWORK
   Yen Ian En-Hsu, 2015, ADV NEURAL INFORM PR, V28, P3582
   Yu H, 2012, ACM T KNOWL DISCOV D, P1
   Zhao PL, 2015, PR MACH LEARN RES, V37, P1
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2017
VL 30
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT J
AU Fol, E
   Tomás, R
   Franchetti, G
AF Fol, E.
   Tomas, R.
   Franchetti, G.
TI Supervised learning-based reconstruction of magnet errors in circular
   accelerators
SO EUROPEAN PHYSICAL JOURNAL PLUS
DT Article
AB Magnetic field errors and misalignments cause optics perturbations, which can lead to machine safety issues and performance degradation. The correlation between magnetic errors and deviations of the measured optics functions from design can be used in order to build supervised learning models able to predict magnetic errors directly from a selection of measured optics observables. Extending the knowledge of errors in individual magnets offers potential improvements of beam control by including this information into optics models and corrections computation. Besides, we also present a technique for denoising and reconstruction of measurements data, based on autoencoder neural networks and linear regression. We investigate the usefulness of supervised machine learning algorithms for beam optics studies in a circular accelerator such as the LHC, for which the presented method has been applied in simulated environment, as well as on experimental data.
C1 [Fol, E.] CERN, CH-1211 Geneva 23, Switzerland.
   [Fol, E.; Tomas, R.; Franchetti, G.] Goethe Univ Frankfurt, D-60438 Frankfurt, Germany.
   [Franchetti, G.] GSI Helmholtzzentrum Schwerionenforsch, D-64291 Darmstadt, Germany.
RP Fol, E (corresponding author), CERN, CH-1211 Geneva 23, Switzerland.; Fol, E (corresponding author), Goethe Univ Frankfurt, D-60438 Frankfurt, Germany.
EM elena.fol@cern.ch
CR Aiba, 2009, PHYS REV ST ACCEL BE, V12, P81002, DOI [10.1103/PhysRevSTAB.12.081002, DOI 10.1103/PHYSREVSTAB.12.081002]
   [Anonymous], 2008, 1123 LHC
   [Anonymous], 2007, NOTES REGULARIZED LE
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   BOZOKI E, 1994, AIP CONF PROC, P103, DOI 10.1063/1.46759
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Calaga R., 2007, IEEE PART ACC C PAC, V2007, P3693
   Carlier F, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.011005
   Carlier F., 2019, P 10 INT PARTICLE AC, P508, DOI [10.18429/JACoW-IPAC2019-MOPMP033, DOI 10.18429/JACOW-IPAC2019-MOPMP033]
   Coello de Portugal J., 2017, LIN CORR 113 HILUMI
   Coello de Portugal J., 2020, PHYS REV ACCEL BEAMS, V23
   Edelen A., 2018, ARXIV181103172
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Fartoukh, 2020, CERNACC20200028
   Cardona JF, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.111004
   Fol, 2017, THESIS U APPL SCI KA
   Fol E., 2019, P 10 INT PARTICLE AC, P3990, DOI DOI 10.18429/JACOW-IPAC2019-THPRB077
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   King DB, 2015, ACS SYM SER, V1214, P1
   LAI TL, 1979, J MULTIVARIATE ANAL, V9, P343, DOI 10.1016/0047-259X(79)90093-9
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Li YJ, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.012804
   Meier E., 2012, P 3 INT PART ACC C I, P2837
   Mitchell T.M., 1997, MACH LEARN, V1
   Persson T, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.061002
   Scheinker A., 2020, ARXIV200105461
   Tomás R, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.091001
   Tomas R., P 6 INT PART ACC C I, P419
   Tomas R., P 39 FREE EL LAS C F, P311, DOI [10.18429/JACoW-FEL2019-WEB03, DOI 10.18429/JACOW-FEL2019-WEB03]
   Tomas R., 2018, CERNACCNOTE20180056
   Tomás R, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.054801
NR 31
TC 7
Z9 7
U1 0
U2 0
PD APR 7
PY 2021
VL 136
IS 4
AR 365
DI 10.1140/epjp/s13360-021-01348-5
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Kwon, H
   Kwon, Y
   Han, J
AF Kwon, Hyunjeong
   Kwon, Youngsu
   Han, Jinho
GP IEEE
TI Backward Graph Construction and Lowering in DL Compiler for Model
   Training on AI Accelerators
SO 2022 19TH INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC)
SE International SoC Design Conference
DT Proceedings Paper
CT 19th International SoC Design Conference (ISOCC) - SoC Technology
   Towards a New Era of Innovation
CY OCT 19-22, 2022
CL Gangwon Do, SOUTH KOREA
DE AI accelerator; compiler; deep learning; training
AB A deep learning (DL) compiler is required to acceler ate model inference and training on AI accelerators. In this work, we propose a novel approach to constructing a backward graph from a PyTorch model, and lowering it to machine codes. The backward graph is constructed using information from PyTorch's autograd engine. The newly proposed lexer and parser convert the generated graph into an abstract syntax tree (AST). The AST is converted to GIR, an intermediate representation within the MLIR framework. IR lowering is then applied to the GIR, producing an LLVM IR for the LLVM backend. Among operators, those that can be accelerated using a DL accelerator are processed by the accelerator. This is achieved through the LLVM IR call function, which calls the accelerator's backend. In the experiment, the proposed compiler estimated the training loss with an average error of 1.46% within 6.7 seconds while processing 100 epochs.
C1 [Kwon, Hyunjeong; Kwon, Youngsu; Han, Jinho] ETRI, AI SoC Res Div, Daejeon, South Korea.
RP Kwon, H (corresponding author), ETRI, AI SoC Res Div, Daejeon, South Korea.
EM kwonhj@etri.re.kr; yskwon@etri.re.kr; soc@etrise.kr
CR Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Facebook, 2020, PYT XLA
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Rotem N, 2019, Arxiv, DOI arXiv:1805.00907
NR 4
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 91
EP 92
DI 10.1109/ISOCC56007.2022.10031488
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lee, K
AF Lee, Kyuho
GP IEEE
TI Trends of Modern Processors for AI Acceleration
SO 18TH INTERNATIONAL SOC DESIGN CONFERENCE 2021 (ISOCC 2021)
SE International SoC Design Conference
DT Proceedings Paper
CT 18th International SoC Design Conference (ISOCC)
CY OCT 06-09, 2021
CL Jeju, SOUTH KOREA
DE Artificial Intelligence; System-on-Chip; Machine Learning; AI SoC
AB As Machine Learning and Artificial Intelligence (AI) technology are playing the key role in the 4th industrial revolution, tremendous amounts of researches are actively conducted to blend the technologies into our daily lives with practical applications, such as autonomous vehicles, robots, drones, AI speaker, smart phone, intelligent surveillance, etc. Most of current works rely on GPU that is not a practical solution to embedded systems and mobile platforms due to its large form factor and power consumption. Instead, low-power hardware accelerators are essential for feasible implementation and they have been investigated recently with different aspects and architectures. In this talk, the technological challenges and trends in the latest AI accelerators are reviewed.
C1 [Lee, Kyuho] Ulsan Natl Inst Sci & Technol UNIST, Dept Elect Engn, Artificial Intelligence Grad Sch, Ulsan, South Korea.
RP Lee, K (corresponding author), Ulsan Natl Inst Sci & Technol UNIST, Dept Elect Engn, Artificial Intelligence Grad Sch, Ulsan, South Korea.
EM kyuho.jsn.lee@unist.ac.kr
NR 0
TC 2
Z9 2
U1 0
U2 2
PY 2021
BP 227
EP 227
DI 10.1109/ISOCC53507.2021.9613902
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Wu, RD
   Liu, B
   Fu, P
   Li, JB
   Feng, S
AF Wu, Ruidong
   Liu, Bing
   Fu, Ping
   Li, Junbao
   Feng, Shou
TI An Accelerator Architecture of Changeable-Dimension Matrix Computing
   Method for SVM
SO ELECTRONICS
DT Article
DE changeable-dimension matrix computing; field programmable gate array
   (FPGA); support vector machine (SVM); ZYNQ
ID NEURAL-NETWORK; CLASSIFICATION; ALGORITHM; SYSTEM; SET
AB Matrix multiplication is a critical time-consuming processing step in many machine learning applications. Due to the diversity of practical applications, the matrix dimensions are generally not fixed. However, most matrix calculation methods, based on field programmable gate array (FPGA) currently use fixed matrix dimensions, which limit the flexibility of machine learning algorithms in a FPGA. The bottleneck lies in the limited FPGA resources. Therefore, this paper proposes an accelerator architecture for matrix computing method with changeable dimensions. Multi-matrix synchronous calculation concept allows matrix data to be processed continuously, which improves the parallel computing characteristics of FPGA and optimizes the computational efficiency. This paper tests matrix multiplication using support vector machine (SVM) algorithm to verify the performance of proposed architecture on the ZYNQ platform. The experimental results show that, compared to the software processing method, the proposed architecture increases the performance by 21.18 times with 9947 dimensions. The dimension is changeable with a maximum value of 2,097,151, without changing hardware design. This method is also applicable to matrix multiplication processing with other machine learning algorithms.
C1 [Wu, Ruidong; Liu, Bing; Fu, Ping; Li, Junbao; Feng, Shou] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
RP Liu, B (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM 17B901027@stu.hit.edu.cn; liubing66@hit.edu.cn; fuping@hit.edu.cn;
   lijunbao@hit.edu.cn; fengshou@hit.edu.cn
CR Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745
   Antos A, 2003, J MACH LEARN RES, V3, P73, DOI 10.1162/153244303768966111
   Ardakani A, 2018, IEEE T CIRCUITS-I, V65, P1349, DOI 10.1109/TCSI.2017.2757036
   Bauer S, 2010, IEEE COMPUTER SOC, P61, DOI [10.1109/CVPRW.2010.5543772, DOI 10.1109/CVPRW.2010.5543772]
   Bharatiraja C, 2018, IEEE J EM SEL TOP P, V6, P233, DOI 10.1109/JESTPE.2017.2723518
   Bilal M, 2017, IEEE T CIRC SYST VID, V27, P2260, DOI 10.1109/TCSVT.2016.2581660
   Cao YQ, 2015, INT J COMPUT VISION, V113, P54, DOI 10.1007/s11263-014-0788-3
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Dominguez-Morales JP, 2018, IEEE T BIOMED CIRC S, V12, P24, DOI 10.1109/TBCAS.2017.2751545
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Guyon I, 2007, PATTERN RECOGN LETT, V28, P1438, DOI 10.1016/j.patrec.2007.02.014
   Ilas ME, 2018, COMPUTERS, V7, DOI 10.3390/computers7010018
   Jin RC, 2018, IET CIRC DEVICE SYST, V12, P295, DOI 10.1049/iet-cds.2017.0468
   Joachims Thorsten, 2000, THESIS
   Kao WC, 2004, NEURAL COMPUT, V16, P1689, DOI 10.1162/089976604774201640
   Keerthi SS, 2005, J MACH LEARN RES, V6, P341
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kyrkou C, 2016, IEEE T NEUR NET LEAR, V27, P99, DOI 10.1109/TNNLS.2015.2428738
   Kyrkou C, 2012, IEEE T COMPUT, V61, P831, DOI 10.1109/TC.2011.113
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu X, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061883
   Luo JH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041174
   Müller J, 2018, IEEE T CIRCUITS-II, V65, P1084, DOI 10.1109/TCSII.2016.2621773
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qasaimeh M, 2015, IEEE T COMPUT IMAG, V1, P56, DOI 10.1109/TCI.2015.2424077
   Ribeiro EG, 2018, MEASUREMENT, V128, P276, DOI 10.1016/j.measurement.2018.06.059
   Ricci S, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7120434
   Tao Xiao, 2015, Algorithms and Architectures for Parallel Processing. 15th International Conference, ICA3PP 2015. Proceedings: LNCS 9528, P64, DOI 10.1007/978-3-319-27119-4_5
   Venkateshan S, 2015, IEEE T VLSI SYST, V23, P2221, DOI 10.1109/TVLSI.2014.2361254
   Wang BK, 2018, J INTELL FUZZY SYST, V34, P3535, DOI 10.3233/JIFS-169532
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Wang QX, 2016, IEEE T CIRCUITS-I, V63, P401, DOI 10.1109/TCSI.2016.2515398
   Xu JW, 2018, MICROPROCESS MICROSY, V60, P196, DOI 10.1016/j.micpro.2018.03.007
NR 36
TC 5
Z9 5
U1 0
U2 10
PD FEB
PY 2019
VL 8
IS 2
AR 143
DI 10.3390/electronics8020143
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Yu, Y
   Li, YM
   Che, S
   Jha, NK
   Zhang, WF
AF Yu, Ye
   Li, Yingmin
   Che, Shuai
   Jha, Niraj K.
   Zhang, Weifeng
TI Software-Defined Design Space Exploration for an Efficient DNN
   Accelerator Architecture
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Kernel; Hardware; System-on-chip; Parallel processing; Microsoft
   Windows; Space exploration; Optimization; Application-driven framework;
   deep learning; design space exploration; hardware acceleration; machine
   learning; neural network
AB Deep neural networks (DNNs) have been shown to outperform conventional machine learning algorithms across a wide range of applications, e.g., image recognition, object detection, robotics, and natural language processing. However, the high computational complexity of DNNs often necessitates extremely fast and efficient hardware. The problem gets worse as the size of neural networks grows exponentially. As a result, customized hardware accelerators have been developed to accelerate DNN processing without sacrificing model accuracy. However, previous accelerator design studies have not fully considered the characteristics of the target applications, which may lead to sub-optimal architecture designs. On the other hand, new DNN models have been developed for better accuracy, but their compatibility with the underlying hardware accelerator is often overlooked. In this article, we propose an application-driven framework for architectural design space exploration of DNN accelerators. This framework is based on a hardware analytical model of individual DNN operations. It models the accelerator design task as a multi-dimensional optimization problem. We demonstrate that it can be efficaciously used in application-driven accelerator architecture design: we use the framework to optimize the accelerator configurations for eight representative DNNs and select the configuration with the highest geometric mean performance. The geometric mean performance improvement of the selected DNN configuration relative to the architectural configuration optimized only for each individual DNN ranges from 12.0 to 117.9 percent. Given a target DNN, the framework can generate efficient accelerator design solutions with optimized performance and area. Furthermore, we explore the opportunity to use the framework for accelerator configuration optimization under simultaneous diverse DNN applications. The framework is also capable of improving neural network models to best fit the underlying hardware resources. We demonstrate that it can be used to analyze the relationship between the operations of the target DNNs and the corresponding accelerator configurations, based on which the DNNs can be tuned for better processing efficiency on the given accelerator without sacrificing accuracy.
C1 [Yu, Ye; Jha, Niraj K.] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
   [Li, Yingmin; Che, Shuai; Zhang, Weifeng] Alibaba Grp, Sunnyvale, CA 94085 USA.
RP Yu, Y (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM yeyu@princeton.edu; yingmin.li@alibaba-inc.com;
   shuai.che@alibaba-inc.com; jha@princeton.edu; weifeng.z@alibaba-inc.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M., 2016, MICROPAGE, P1
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng H.-T., 2016, P 1 WORKSH DEEP LEAR, P7, DOI DOI 10.1145/2988450.2988454
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Goldberg D.E, 1989, GENETIC ALGORITHMS S, V27, P27
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2016, P IEEE C COMPUTER VI
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Ke I.., 2018, P INT S LOW POW EL D, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma YL, 2016, ACTA OTO-LARYNGOL, V136, P800, DOI 10.3109/00016489.2016.1164893
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma H., 2016, P IEEE ACM INT S MIC, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Venkataramani S, 2017, INT CONFER PARA, P146, DOI 10.1109/PACT.2017.39
   Wang SH, 2017, DES AUT TEST EUROPE, P1032, DOI 10.23919/DATE.2017.7927142
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Zaremba Wojciech, 2014, ARXIV14092329
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
   Zhang XB, 2019, DEMENTIA-LONDON, V18, P2620, DOI 10.1177/1471301217753775
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu JY, 2018, DES AUT TEST EUROPE, P241, DOI 10.23919/DATE.2018.8342010
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 48
TC 8
Z9 8
U1 2
U2 9
PD JAN 1
PY 2021
VL 70
IS 1
BP 45
EP 56
DI 10.1109/TC.2020.2983694
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU He, L
   Luo, Y
   Cao, Y
AF He, Lu
   Luo, Yan
   Cao, Yu
GP IEEE
TI Accelerator of Stacked Convolutional Independent Subspace Analysis for
   Deep Learning-based Action Recognition
SO 2014 IEEE 22ND ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2014)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 22nd IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines ((FCCM)
CY MAY 11-13, 2014
CL Boston, MA
DE Deep Learning; Independent Subspace Analysis; Accelerator
AB Action recognition has been a research challenge in multimedia computing and machine vision. Recent advances in deep learning combined with stacked convolutional Independent Subspace Analysis (ISA) has achieved a better performance superior to all previously published results on several public available data sets. Unfortunately, one major issue in large-scale deployment of this new deep learning-based approach is the unacceptable latency of training with highdimension data. In this paper, we propose a new hardware accelerator that can reduce the training time substantially for deep learning-based action recognition. Specifically, our proposed approach focuses on accelerating the convolutional stacked ISA algorithm, the core components of the deep learning-based action recognition algorithms. We design parallel pipelines, data parallelisms and look-up table to speed up the algorithm. With an embedded heterogeneous platform consisting of a general purpose processor and a FPGA, we are able to achieve up to 10X speedup for stacked ISA training compared to a software-only implementation.
C1 [He, Lu; Luo, Yan] Univ Massachusetts, Elect & Comp Engn, Lowell, MA 01854 USA.
   [Cao, Yu] Univ Massachusetts, Comp Sci, Lowell, MA USA.
RP He, L (corresponding author), Univ Massachusetts, Elect & Comp Engn, Lowell, MA 01854 USA.
EM Lu_He@student.uml.edu; Yan_Luo@uml.edu; ycao@cs.uml.edu
CR Le Quoc V., 2011, COMP VIS PATT REC CV
NR 1
TC 1
Z9 1
U1 0
U2 1
PY 2014
BP 104
EP 104
DI 10.1109/FCCM.2014.37
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Barham, P
   Isard, M
AF Barham, Paul
   Isard, Michael
GP ACM
TI Machine Learning Systems are Stuck in a Rut
SO PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS
   '19)
DT Proceedings Paper
CT Workshop on Hot Topics in Operating Systems (HotOS)
CY MAY 13-15, 2019
CL Bertinoro, ITALY
AB In this paper we argue that systems for numerical computing are stuck in a local basin of performance and programmability. Systems researchers are doing an excellent job improving the performance of 5-year-old benchmarks, but gradually making it harder to explore innovative machine learning research ideas.
   We explain how the evolution of hardware accelerators favors compiler back ends that hyper-optimize large monolithic kernels, show how this reliance on high-performance but inflexible kernels reinforces the dominant style of programming model, and argue these programming abstractions lack expressiveness, maintainability, and modularity; all of which hinders research progress.
   We conclude by noting promising directions in the field, and advocate steps to advance progress towards high-performance general purpose numerical computing systems on modern accelerators.
C1 [Barham, Paul; Isard, Michael] Google Brain, Mountain View, CA 94043 USA.
RP Barham, P (corresponding author), Google Brain, Mountain View, CA 94043 USA.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], ABS160406174 CORR
   [Anonymous], 2018, ABS181102084 CORR
   [Anonymous], 2014, ABS14111607 CORR
   [Anonymous], ACM T GRAPHICS SIGGR
   [Anonymous], 2018, SC18 INT C HIGH PERF
   [Anonymous], P C SYST MACH LEARN
   [Anonymous], 2018, ICLR
   [Anonymous], ABS170604972 CORR
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Han S., 2015, ARXIV151000149
   He K., 2016, INDIAN J CHEM B
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Vasilache N., 2018, CORR ABS180204730 18
NR 15
TC 22
Z9 22
U1 0
U2 1
PY 2019
BP 177
EP 183
DI 10.1145/3317550.3321441
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Chaudhuri, A
   Talukdar, J
   Chakrabarty, K
AF Chaudhuri, Arjun
   Talukdar, Jonti
   Chakrabarty, Krishnendu
GP IEEE
TI Machine Learning for Testing Machine-Learning Hardware: A Virtuous Cycle
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
AB The ubiquitous application of deep neural networks (DNN) has led to a rise in demand for AI accelerators. DNN-specific functional criticality analysis identifies faults that cause measurable and significant deviations from acceptable requirements such as the inferencing accuracy. This paper examines the problem of classifying structural faults in the processing elements (PEs) of systolic-array accelerators. We first present a two-tier machine-learning (ML) based method to assess the functional criticality of faults. While supervised learning techniques can be used to accurately estimate fault criticality, it requires a considerable amount of ground truth for model training. We therefore describe a neural-twin framework for analyzing fault criticality with a negligible amount of ground-truth data. We further describe a topological and probabilistic framework to estimate the expected number of PE's primary outputs (POs) flipping in the presence of defects and use the PO-flip count as a surrogate for determining fault criticality. We demonstrate that the combination of PO-flip count and neural twin-enabled sensitivity analysis of internal nets can be used as additional features in existing ML-based criticality classifiers.
C1 [Chaudhuri, Arjun; Talukdar, Jonti; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
RP Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
CR [Anonymous], GOOGLE EDGE TPU CORA
   [Anonymous], SYSTEM ARCHITECTURE
   Chaudhuri A., 2021, DATE
   Chaudhuri A., 2022, ISVLSI
   Chaudhuri A, 2021, INT TEST CONF P, P73, DOI 10.1109/ITC50571.2021.00015
   Chaudhuri A, 2020, INT TEST CONF P, DOI 10.1109/ITC44778.2020.9325272
   Chaudhuri A, 2020, ASIAN TEST SYMPOSIUM, P18, DOI [10.1109/ATS49688.2020.9301581, 10.1109/ats49688.2020.9301581]
   Chauhan A, 2023, INORG NANO-MET CHEM, V53, P460, DOI 10.1080/24701556.2021.2025078
   Chen CY, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1074, DOI 10.23919/DATE51398.2021.9473989
   Gebregiorgis A, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000110
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kundu S., 2021, TVLSI
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Sadi M., 2021, IEEE T COMPUT AID D
   Zhang J, 2018, IEEE VLSI TEST SYMP
NR 16
TC 0
Z9 0
U1 1
U2 1
PY 2022
DI 10.1145/3508352.3561121
WC Computer Science, Theory & Methods; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chandra, M
AF Chandra, Mahesh
TI On the Implementation of Fixed-Point Exponential Function for Machine
   Learning and Signal- Processing Accelerators
SO IEEE DESIGN & TEST
DT Article
DE Table lookup; Hardware; Taylor series; Arithmetic; Adders; Optimization;
   Neural networks; Digital integrated circuit; natural exponential;
   activation function; Gaussian function
AB Editor's notes: The natural exponential function appears in a broad range of conventional and emerging applications, including the activation functions used in deep learning applications. This article presents an optimized implementation of exponential function for variable precision fixed-point negative inputs. Hence, this design can boost the performance and energy efficiency of a vast amount of hardware accelerators and systems. -Umit Ogras, Arizona State University
C1 [Chandra, Mahesh] NXP Semicond India Ltd, Noida 201301, India.
RP Chandra, M (corresponding author), NXP Semicond India Ltd, Noida 201301, India.
EM mahesh.chandra_1@nxp.com
CR Kim J, 2020, INT SYM QUAL ELECT, P358, DOI [10.1109/ISQED48828.2020.9137012, 10.1109/isqed48828.2020.9137012]
   Nilsson P, 2014, 2014 NORCHIP
   Nwankpa C, 2018, ARXIV181103378
   Partzsch J, 2017, IEEE INT SYMP CIRC S
   Pouyan P., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P709, DOI 10.1109/ECCTD.2011.6043642
   Sudha J, 2012, PROCEDIA ENGINEER, V30, P519, DOI 10.1016/j.proeng.2012.01.893
   Tang P. T. P., 1991, Proceedings. 10th IEEE Symposium on Computer Arithmetic (Cat. No.91CH3015-5), P232, DOI 10.1109/ARITH.1991.145565
   Volder J. E., 1959, IRE T ELECT COMPUT, VEC-8, P330, DOI [10.1109/TEC.1959.5222693, DOI 10.1109/TEC.1959.5222693]
   Wu D, 2019, I SYMPOS LOW POWER E
NR 9
TC 0
Z9 0
U1 3
U2 4
PD AUG
PY 2022
VL 39
IS 4
BP 64
EP 70
DI 10.1109/MDAT.2021.3133373
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Chen, CY
   Murmann, B
   Seo, JS
   Yoo, HJ
AF Chen, Chia-Yu
   Murmann, Boris
   Seo, Jae-Sun
   Yoo, Hoi-Jun
TI Custom Sub-Systems and Circuits for Deep Learning: Guest Editorial
   Overview
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Editorial Material
DE Deep learning; machine learning; accelerators; computer architectures;
   integrated circuit designs; neural network hardware; in-memory
   computing; data-flow architectures; reduced-precision; approximate
   computing; distributed learning
AB This survey paper summarizes recent progress of deep learning circuits and systems technologies and contains four topics: hardware-centric deep learning algorithms, digital architectures, analog architectures, and system demonstrations. We present an overview of these four areas and introduce key contributions of papers in this special issue.
C1 [Chen, Chia-Yu] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Murmann, Boris] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
   [Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85251 USA.
   [Yoo, Hoi-Jun] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
RP Chen, CY (corresponding author), IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
CR Agrawal K, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P1, DOI 10.1109/MLDS.2017.21
   [Anonymous], 2016, ARXIV161007501
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P IEEE ACM INT S MIC
   [Anonymous], 2016, ARXIV160704381
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], 2016, ARXIV161105162
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2016, ARXIV160907061
   [Anonymous], 2015, P 16 ANN C INT SPEEC
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Chen CY, 2018, DES AUT TEST EUROPE, P821, DOI 10.23919/DATE.2018.8342119
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng CY, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2018), P1, DOI 10.1145/3192975.3193009
   Durant L., 2017, INSIDE VOLTA WORLDS
   Gupta S, 2016, IEEE DATA MINING, P171, DOI [10.1109/ICDM.2016.0028, 10.1109/ICDM.2016.122]
   Injoon Hong, 2015, 2015 IEEE International Solid-State Circuits Conference (ISSCC). Digest of Technical Papers, P1, DOI 10.1109/ISSCC.2015.7063058
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lian X., 2017, ADV NEURAL INFORM PR, P5330
   Lita Yang, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P689, DOI 10.1109/ISVLSI.2017.117
   Ma YW, 2017, IEEE T IND ELECTRON, V64, P8821, DOI 10.1109/TIE.2017.2694347
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Molchanov P., 2016, 5 INT C LEARNING REP
   van den Berg E, 2017, INT CONF ACOUST SPEE, P2287, DOI 10.1109/ICASSP.2017.7952564
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wen Wei, 2017, NIPS, P1509
   Zhang JT, 2016, SYMP VLSI CIRCUITS
   Zhou S., 2016, DOREFANET TRAINING L
NR 31
TC 2
Z9 2
U1 0
U2 12
PD JUN
PY 2019
VL 9
IS 2
BP 247
EP 252
DI 10.1109/JETCAS.2019.2918317
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kundu, S
   Banerjee, S
   Raha, A
   Basu, K
AF Kundu, Shamik
   Banerjee, Suvadeep
   Raha, Arnab
   Basu, Kanad
GP IEEE
TI Special Session: Effective In-field Testing of Deep Neural Network
   Hardware Accelerators
SO 2022 IEEE 40TH VLSI TEST SYMPOSIUM (VTS)
SE IEEE VLSI Test Symposium
DT Proceedings Paper
CT 40th IEEE VLSI Test Symposium (VTS)
CY APR 25-27, 2022
CL ELECTR NETWORK
DE Machine learning; Deep Neural Network accelerator; Functional Safety;
   Reliability
AB Ongoing research to obtain high performance Deep Neural Network (DNN) executions have led to the development of customized purpose-built deep learning inference accelerators. DNN accelerators are susceptible to faults, due to high-energy particles, process variations, temperature and structural deformities manifesting as latent defects. These faults can introduce misclassification, thereby jeopardizing the Functional Safety (FuSa) of the accelerator in mission mode, which can eventuate to disastrous consequences, including loss of human lives. In this paper, we explore the impact of such faults on the FuSa of a DNN accelerator by varying the network parameters, position and characteristics of the injected fault across multiple exhaustive datasets. Furthermore, we analyze the efficiency of a software-based self test scheme to detect FuSa violations in the accelerator in mission mode, that employs functional test patterns, akin to instances in the application dataset. The test patterns, selected from the dataset of the DNN, furnish up to 100% coverage with cardinality as low as 0.1% of the entire test dataset.
C1 [Kundu, Shamik; Basu, Kanad] Univ Texas Dallas, Elect & Comp Engn, Richardson, TX 75083 USA.
   [Banerjee, Suvadeep; Raha, Arnab] Intel Corp, Santa Clara, CA USA.
RP Kundu, S (corresponding author), Univ Texas Dallas, Elect & Comp Engn, Richardson, TX 75083 USA.
EM shamik.kundu@utdallas.edu; suvadeep.banerjee@intel.com;
   arnab.raha@intel.com; kanad.basu@utdallas.edu
CR Bettola S, 1998, IEEE T COMPUT, V47, P357, DOI 10.1109/12.660173
   Birch John, 2013, Computer Safety, Reliability and Security. 32nd International Conference, SAFECOMP 2013. Proceedings: LNCS 8153, P154, DOI 10.1007/978-3-642-40793-2_15
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen ZT, 2021, Arxiv, DOI arXiv:2003.13874
   Gebregiorgis A, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000110
   Jones J, FUNCTIONAL SAFETY IT
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kundu S, 2021, IEEE T VLSI SYST, V29, P485, DOI 10.1109/TVLSI.2020.3048829
   Park SK, 2015, IEEE INT MEM WORKSH, P1
   Piuri V, 2001, J PARALLEL DISTR COM, V61, P18, DOI 10.1006/jpdc.2000.1663
   Reda, 2019, APPROXIMATE CIRCUITS
   Shin D, 2011, DES AUT TEST EUROPE, P1566
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Vu TH, 2019, IEEE ACCESS, V7, P90436, DOI 10.1109/ACCESS.2019.2925085
   Zhang J, 2018, IEEE VLSI TEST SYMP
NR 15
TC 0
Z9 0
U1 0
U2 1
PY 2022
DI 10.1109/VTS52500.2021.9794227
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Rescic, M
   Seviour, R
   Blokland, W
AF Rescic, Miha
   Seviour, Rebecca
   Blokland, Willem
TI Improvements of pre-emptive identification of particle accelerator
   failures using binary classifiers and dimensionality reduction
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Machine learning; Particle accelerator; Failure prediction; Reliability
AB In this paper we look at the properties of the Spallation Neutron Source (SNS) Differential Beam Current Monitor (DCM) data and various methods of data transformation to improve pre-emptive detection of machine trips. Foundation of the approach is the analysis of new underlying data and understanding various properties with the goal of faster classification, higher precision and higher recall with the aim to reduce false positives as low as required. The result of the research presented in this paper are a binary classifier capable of predicting accelerator failures with millisecond classification time, 96% precision, 58% true positive and 0% false positive rate and optimization techniques enabling real-time implementations.
C1 [Rescic, Miha; Seviour, Rebecca] Univ Huddersfield, Huddersfield HD1 3DH, England.
   [Blokland, Willem] Neutron Sci Directorate, One Bethel Valley Rd, Oak Ridge, TN 37831 USA.
   [Rescic, Miha] Syrengatan 22, Malmo, Sweden.
RP Rescic, M (corresponding author), Univ Huddersfield, Huddersfield HD1 3DH, England.; Rescic, M (corresponding author), Syrengatan 22, Malmo, Sweden.
EM miha.rescic@hud.ac.uk; R.Seviour2@hud.ac.uk; blokland@ornl.gov
CR [Anonymous], 2021, PICKLE PYTHON OBJECT
   [Anonymous], 2021, PYTHON PROGRAMMING L
   Bargalló E, 2014, FUSION ENG DES, V89, P2425, DOI 10.1016/j.fusengdes.2013.12.004
   Bauer G.S., 2000, P 15 M INT COLL ADV, P103
   Blokland W., 2019, IBIC2019
   Blokland W., 2021, P IPAC 2021 MAY 24 2
   Campisi I. E., 2007, 2007 IEEE Particle Accelerator Conference, P2502, DOI 10.1109/PAC.2007.4441297
   Corneliusen A., 1989, ACC CONTR INT C ACC
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A.L., 2015, P IPAC 2015 MAY 3 8, P1217
   Fol E, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.102805
   Galambos J., 2010, P 46 ICFA ADV BEAM D
   Galambos J., 2007, CARE HHH APD EVENT B
   Galambos John, 2013, PROC PAC2013, P1443
   Groeschel F., 2007, P 5 INT WORKSH UT RE
   Henderson S., 2010, ACCELERATOR TARGET T
   Himel T, 2007, IEEE PART ACC CONF, P4352
   Kesselman M, 2000, AIP CONF PROC, V546, P464
   Kim S-H., 2014, P 16 INT C RF SUP SE, P83
   Laverty M., 2016, P LINAC2016 E LANS M, P485
   Lee M., 1991, C 1991 IEEE PART ACC, P1437
   McKerns M., 2010, PATHOS FRAMEWORK HET
   McKerns M., 2011, P 10 PYTH SCI C SCIP, P76, DOI [10.25080/majora-ebaa42b7-00d, DOI 10.25080/MAJORA-EBAA42B7-00D]
   Nuclear Energy Agency, 2002, NEA ACC DRIV SYST AD
   Phinney N., 2004, 9 EUR PART ACC C 5 9, P857
   Pierini P., 2004, UTILISATION RELIABIL
   Pierini P., 2003, PDS XADS DELIVERABLE
   Pitigoi A.E., 2013, 39 ANN M SPAN NUCL S
   pyRiemann Python package, 2021, PYRIEMANN BIOSIGNALS
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Rezaeizadeh A., 2014, P FEL2014 BAS SWITZ, P824
   Scikit-learn, 2021, MACHINE LEARNING PYT
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
NR 33
TC 3
Z9 3
U1 1
U2 4
PD FEB 11
PY 2022
VL 1025
AR 166064
DI 10.1016/j.nima.2021.166064
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Kim, DE
   Ankit, A
   Wang, C
   Roy, K
AF Kim, Dong Eun
   Ankit, Aayush
   Wang, Cheng
   Roy, Kaushik
TI SAMBA: Sparsity Aware In-Memory Computing Based Machine Learning
   Accelerator
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Computer architecture; Optimization; Load management; Convolution;
   In-memory computing; Hardware; Energy consumption; Accelerator;
   in-memory computing; neural networks; sparsity
ID COPROCESSOR
AB Machine Learning (ML) inference is typically dominated by highly data-intensive Matrix Vector Multiplication (MVM) computations that may be constrained by memory bottleneck due to massive data movement between processor and memory. Although analog in-memory computing (IMC) ML accelerators have been proposed to execute MVM with high efficiency, the latency and energy of such computing systems can be dominated by the large latency and energy costs from analog-to-digital converters (ADCs). Leveraging sparsity in ML workloads, reconfigurable ADCs can save MVM energy and latency by reducing the required ADC bit precision. However, such improvement in latency can be hindered by non-uniform sparsity of the weight matrices mapped into hardware. Moreover, data movement between MVM processing cores may become another factor that delays the overall system-level performance. To address these issues, we propose SAMBA, Sparsity Aware IMC Based Machine Learning Accelerator. First, we propose load balancing during mapping of weight matrices into physical crossbars to eliminate non-uniformity in the sparsity of mapped matrices. Second, we propose optimizations in arranging and scheduling the tiled MVM hardware to minimize the overhead of data movement across multiple processing cores. Our evaluations show that the proposed load balancing technique can achieve performance improvement. The proposed optimizations can further improve both performance and energy-efficiency regardless of sparsity condition. With the combination of load balancing and data movement optimization in conjunction with reconfigurable ADCs, our proposed approach provides up to 2.38x speed-up and 1.54x energy-efficiency over stateof- art analog IMC based ML accelerators for ImageNet datasets on Resnet-50 architecture.
C1 [Kim, Dong Eun; Roy, Kaushik] Purdue Univ, Dept Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Ankit, Aayush] Microsoft, San Jose, CA 95112 USA.
   [Wang, Cheng] Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA.
RP Kim, DE (corresponding author), Purdue Univ, Dept Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM kim2976@purdue.edu; aankit@purdue.edu; wang4700@purdue.edu;
   kaushik@purdue.edu
CR Ali M, 2021, IEEE SOLID-ST CIRC L, V4, P129, DOI 10.1109/LSSC.2021.3093354
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit A, 2017, DES AUT CON, DOI 10.1145/3061639.3062311
   Ankit A, 2017, ICCAD-IEEE ACM INT, P533, DOI 10.1109/ICCAD.2017.8203823
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen ZY, 2021, ISSCC DIG TECH PAP I, V64, P240, DOI 10.1109/ISSCC42613.2021.9366045
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   LeCun Y., 1995, HDB BRAIN THEORY NEU, P276, DOI 10.5555/303568.303704
   Lin JL, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P639, DOI 10.1145/3287624.3287715
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Murmann B., 2020, ADC PERFORMANCE SURV
   Park J, 2018, Arxiv, DOI arXiv:1811.09886
   Park SK, 2015, IEEE INT MEM WORKSH, P1
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharma T, 2021, I SYMPOS LOW POWER E, DOI 10.1109/ISLPED52811.2021.9502492
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sriram V., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P273, DOI 10.1109/FPT.2010.5681487
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang PQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196116
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhu MC, 2017, Arxiv, DOI [arXiv:1710.01878, DOI 10.48550/ARXIV.1710.01878]
NR 36
TC 1
Z9 1
U1 9
U2 9
PD SEPT 1
PY 2023
VL 72
IS 9
BP 2615
EP 2627
DI 10.1109/TC.2023.3257513
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Mannocci, P
   Ielmini, D
AF Mannocci, Piergiulio
   Ielmini, Daniele
TI A Generalized Block-Matrix Circuit for Closed-Loop Analog In-Memory
   Computing
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE Hardware accelerator; in-memory computing (IMC); linear algebra; linear
   regression; machine learning; resistive memory
AB Matrix-based computing is ubiquitous in an increasing number of present-day machine learning applications such as neural networks, regression, and 5G communications. Conventional systems based on von-Neumann architecture are limited by the energy and latency bottleneck induced by the physical separation of the processing and memory units. In-memory computing (IMC) is a novel paradigm where computation is performed directly within the memory, thus eliminating the need for constant data transfer. IMC has shown exceptional throughput and energy efficiency when coupled with crosspoint arrays of resistive memory devices in open-loop matrix-vector-multiplication and closed-loop inverse-matrix-vector multiplication (IMVM) accelerators. However, each application results in a different circuit topology, thus complicating the development of reconfigurable, general-purpose IMC systems. In this article, we present a generalized closed-loop IMVM circuit capable of performing any linear matrix operation by proper memory remapping. We derive closed-form equations for the ideal input-output transfer functions, static error, and dynamic behavior, introducing a novel continuous-time analytical model allowing for orders-of-magnitude simulation speedup with respect to SPICE-based solvers. The proposed circuit represents an ideal candidate for general-purpose accelerators of machine learning.
C1 [Mannocci, Piergiulio; Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
   [Mannocci, Piergiulio; Ielmini, Daniele] IU NET, I-20133 Milan, Italy.
RP Mannocci, P (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.; Mannocci, P (corresponding author), IU NET, I-20133 Milan, Italy.
EM piergiulio.mannocci@polimi.it; daniele.ielmini@polimi.it
CR Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Feinberg B, 2021, INT S HIGH PERF COMP, P761, DOI 10.1109/HPCA51647.2021.00069
   HANSEN PC, 1988, J COMPUT APPL MATH, V23, P117, DOI 10.1016/0377-0427(88)90336-6
   Horn R., 2012, MATRIX ANAL, DOI [DOI 10.1017/CBO9780511810817, 10.1017/CBO9780511810817]
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hurwitz A., 1895, MATH ANN, V46, P273, DOI DOI 10.1007/BF01446812
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Kushel OY, 2019, SIAM REV, V61, P643, DOI 10.1137/18M119241X
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Mannocci P, 2022, IEEE J EM SEL TOP C, V12, P952, DOI 10.1109/JETCAS.2022.3221284
   Mannocci P, 2022, IEEE NANOTECHNOL MAG, V16, P4, DOI 10.1109/MNANO.2022.3141515
   Mannocci P, 2021, IEEE T CIRCUITS-I, V68, P4889, DOI 10.1109/TCSI.2021.3122278
   Pedretti G, 2021, IEEE T ELECTRON DEV, V68, P4379, DOI 10.1109/TED.2021.3095430
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Sun Z, 2021, IEEE T CIRCUITS-II, V68, P2785, DOI 10.1109/TCSII.2021.3068764
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P2945, DOI 10.1109/TED.2020.2992435
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 22
TC 1
Z9 1
U1 0
U2 0
PD JUN
PY 2023
VL 9
IS 1
BP 47
EP 55
DI 10.1109/JXCDC.2023.3265803
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Schelten, N
   Steinert, F
   Knapheide, J
   Schulte, A
   Stabernack, B
AF Schelten, Niklas
   Steinert, Fritjof
   Knapheide, Justin
   Schulte, Anton
   Stabernack, Benno
TI A High-Throughput, Resource-Efficient Implementation of the RoCEv2
   Remote DMA Protocol and its Application
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; Network-attached Accelerator; RDMA; RoCEv2; machine learning;
   high-performance computing; data center
AB The use of application-specific accelerators in data centers has been the state of the art for at least a decade, starting with the availability of General Purpose GPUs achieving higher performance either overall or per watt. In most cases, these accelerators are coupled via PCIe interfaces to the corresponding hosts, which leads to disadvantages in interoperability, scalability and power consumption. As a viable alternative to PCIe-attached FPGA accelerators this paper proposes standalone FPGAs as Network-attached Accelerators (NAAs). To enable reliable communication for decoupled FPGAs we present an RDMA over Converged Ethernet v2 (RoCEv2) communication stack for high-speed and low-latency data transfer integrated into a hardware framework.
   For NAAs to be used instead of PCIe coupled FPGAs the framework must provide similar throughput and latency with low resource usage. We show that our RoCEv2 stack is capable of achieving 100 Gb/s throughput with latencies of less than 4 mu s while using about 10% of the available resources on a mid-range FPGA. To evaluate the energy efficiency of our NAA architecture, we built a demonstrator with 8 NAAs for machine learning based image classification. Based on our measurements, network-attached FPGAs are a great alternative to the more energy-demanding PCIe-attached FPGA accelerators.
C1 [Schelten, Niklas] Heinrich Hertz Inst HHI, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Berlin, Germany.
   [Steinert, Fritjof; Knapheide, Justin; Schulte, Anton; Stabernack, Benno] Fraunhofer Inst Telecommun HHI, Einsteinufer 37, D-10587 Berlin, Germany.
   [Steinert, Fritjof; Knapheide, Justin; Stabernack, Benno] Univ Potsdam, Neuen Palais 10, D-14469 Potsdam, Germany.
RP Schelten, N (corresponding author), Heinrich Hertz Inst HHI, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Berlin, Germany.
EM mail@niklas-schelten.de; fritjof.steinert@hhi-extern.fraunhofer.de;
   justin.knapheide@uni-potsdam.de; mail@anton-schulte.de;
   benno.stabernack@hhi.fraunhofer.de
CR Abel F, 2017, 2017 IEEE 25TH ANNUAL SYMPOSIUM ON HIGH-PERFORMANCE INTERCONNECTS (HOTI), P29, DOI 10.1109/HOTI.2017.13
   [Anonymous], 2018, 80232018 IEEE, P1, DOI [10.1109/IEEESTD.2018.8457469, DOI 10.1109/IEEESTD.2018.8457469]
   [Anonymous], 2021, LIN RDMA
   [Anonymous], 2017, IEEE STAND ETH AM 10
   [Anonymous], 2021, NVIDIA VOLT UNV GV10
   ARM, AMBA R AXI TAND ACE
   Caulfield AM, 2016, INT SYMP MICROARCH
   ETH Zurich, SCAL NETW STACK SUPP
   HITEK Systems, WWW
   InfiniBandT Trade Association, 2014, ANN 17 ROCEV2
   InfiniBandT Trade Association, 2015, ARCH SPEC, V1
   InfiniBandT Trade Association, 2010, ANN 16 ROCE
   Intel, 2018, INT ARR 10 DEV OV
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Knapheide J, 2020, I C FIELD PROG LOGIC, P277, DOI 10.1109/FPL50879.2020.00053
   Lockwood JW, 2016, IEEE MICRO, V36, P18, DOI 10.1109/MM.2016.55
   Mansour W, 2019, IEEE T NUCL SCI, V66, P1138, DOI 10.1109/TNS.2019.2904118
   Mellanox Technologies, CONNECTX 4 CARD
   Mellanox Technologies, MELL TECHN SX1012 12
   Ringlein B, 2019, I C FIELD PROG LOGIC, P293, DOI 10.1109/FPL.2019.00054
   Ruiz M, 2019, I C FIELD PROG LOGIC, P286, DOI 10.1109/FPL.2019.00053
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2019, Arxiv, DOI [arXiv:1801.04381, 10.48550/ARXIV.1801.04381, DOI 10.48550/ARXIV.1801.04381]
   Schelten N, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P241, DOI 10.1109/ICFPT51103.2020.00042
   Sidler D, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387519
   Steinert F, 2022, J SIGNAL PROCESS SYS, V94, P693, DOI 10.1007/s11265-021-01727-2
   Steinert F, 2021, I C FIELD PROG LOGIC, P386, DOI 10.1109/FPL53798.2021.00077
   Steinert F, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P149, DOI 10.1109/DSD51259.2020.00033
   Tarafdar N, 2018, IEEE MICRO, V38, P18, DOI 10.1109/MM.2018.2877290
   University of Toronto, WWW
   Weerasinghe J, 2016, INT CONF CLOUD COMP, P9, DOI [10.1109/CloudCom.2016.0018, 10.1109/CloudCom.2016.15]
   Xilinx, 2021, EMB RDMA EN NIC V3
   Xilinx, 2018, XIL EMB TARG RDMA EN
   Xilinx, 2015, ULTRASCALE FPGAS PRO
   Zang DW, 2015, INT C PAR DISTRIB SY, P465, DOI 10.1109/ICPADS.2015.65
NR 35
TC 0
Z9 0
U1 4
U2 6
PD MAR
PY 2023
VL 16
IS 1
DI 10.1145/3543176
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Taht, K
   Balasubramonian, R
AF Taht, Karl
   Balasubramonian, Rajeev
GP IEEE
TI Introspective Computing
SO 2017 26TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND
   COMPILATION TECHNIQUES (PACT)
SE International Conference on Parallel Architectures and Compilation
   Techniques
DT Proceedings Paper
CT 26th International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY SEP 09-13, 2017
CL Portland, OR
DE phase detection; machine learning; tuning
AB We live in an advent of specialized tasks ranging from graphics, to networking and graph processing, to machine learning and more. While hardware accelerators cater to mainstream demands, general purpose units will always be challenged to run new software. Introspective Computing focuses on building a feedback mechanism to tune dynamic hardware features in real-time. Unlike most prior work, our study is done completely on a real system using hardware resources tunable in most modern Intel processors.
C1 [Taht, Karl; Balasubramonian, Rajeev] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
RP Taht, K (corresponding author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
EM taht@cs.utah.edu; rajeev@cs.utah.edu
CR Dhodapkar AS, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P217
NR 1
TC 0
Z9 0
U1 0
U2 0
PY 2017
BP 371
EP 371
DI 10.1109/PACT.2017.49
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Tunheim, SA
   Jiao, L
   Shafik, R
   Yakovlev, A
   Granmo, OC
AF Tunheim, Svein Anders
   Jiao, Lei
   Shafik, Rishad
   Yakovlev, Alex
   Granmo, Ole-Christoffer
GP IEEE
TI A Convolutional Tsetlin Machine-based Field Programmable Gate Array
   Accelerator for Image Classification
SO 2022 INTERNATIONAL SYMPOSIUM ON THE TSETLIN MACHINE (ISTM 2022)
DT Proceedings Paper
CT 1st International Symposium on the Tsetlin Machine (ISTM)
CY JUN 20-21, 2022
CL Grimstad, NORWAY
AB This paper presents a Field Programmable Gate Array (FPGA) implementation of an image classification accelerator based on the Convolutional Tsetlin Machine (CTM). The work is a concept design, and the solution demonstrates recognition of two classes in 4x4 images with a 2x2 convolution window. More specifically, there are two sub-Tsetlin Machines (TMs), one per class. A single sub-TM employs 40 clauses, each controlled by 20 Tsetlin Automata. The accelerator features random patch selection, in parallel for all clauses, based on reservoir sampling. The design is implemented in a Xilinx Zync XC7Z020 FPGA. With an operating clock speed of 30 MHz, the accelerator is capable of inferring at the rate of 3.3 million images per second with an additional power consumption of 20 mW from idle mode. The average test accuracy is 96.7% when trained on data with 10% noise. A training session with 100 epochs and 8192 examples takes 1.5 seconds. Due to the limited hardware resources required, the CTM accelerator represents a promising concept for online learning in energy-frugal systems. The solution can be scaled to multi-class systems and larger images.
C1 [Tunheim, Svein Anders; Jiao, Lei; Granmo, Ole-Christoffer] Univ Agder, Ctr Artificial Intelligence Res, Grimstad, Norway.
   [Shafik, Rishad; Yakovlev, Alex] Newcastle Univ, Microsyst Grp, Sch Engn, Newcastle, England.
RP Tunheim, SA (corresponding author), Univ Agder, Ctr Artificial Intelligence Res, Grimstad, Norway.
EM svein.a.tunheim@uia.no; lei.jiao@uia.no
CR Abeyrathna K. D., 2021, INT C MACHINE LEARNI, P10
   Bakar A., 2022, HOTMOBILE 22
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Granmo OC, 2021, Arxiv, DOI arXiv:1804.01508
   Granmo OC, 2019, Arxiv, DOI arXiv:1905.09688
   Haykin S., 2001, COMMUNICATION SYSTEM
   Knag PC, 2021, IEEE J SOLID-ST CIRC, V56, P1082, DOI 10.1109/JSSC.2020.3038616
   Di Mauro A, 2020, IEEE T CIRCUITS-I, V67, P3905, DOI 10.1109/TCSI.2020.3012576
   Miyashita D, 2017, IEEE J SOLID-ST CIRC, V52, P2679, DOI 10.1109/JSSC.2017.2712626
   Rahman T., 2022, FRONTIERS CONTROL EN, DOI [10.3389/fcteg.2021.778118/abstract, DOI 10.3389/FCTEG.2021.778118/ABSTRACT]
   SARWATE DV, 1980, P IEEE, V68, P593, DOI 10.1109/PROC.1980.11697
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165
   Wheeldon A, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0593
   Yadav RK, 2021, AAAI CONF ARTIF INTE, V35, P14203
   Zhang XJ, 2022, IEEE T PATTERN ANAL, V44, P4239, DOI 10.1109/TPAMI.2021.3059299
NR 17
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 21
EP 28
DI 10.1109/ISTM54910.2022.00013
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Chen, TB
   Yin, SY
   Wei, SJ
AF Chen, Tianbao
   Yin, Shouyi
   Wei, Shaojun
BE Xu, M
   Zhang, K
TI A Fast and Low Power Hardware Accelerator for ANN Working at Near
   Threshold Voltage
SO PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN
   MECHANICAL ENGINEERING AND INDUSTRIAL INFORMATICS (AMEII 2016)
SE AER-Advances in Engineering Research
DT Proceedings Paper
CT 2nd International Conference on Advances in Mechanical Engineering and
   Industrial Informatics (AMEII)
CY APR 09-10, 2016
CL Hangzhou, PEOPLES R CHINA
DE ANN; Hardware accelerator; NTV
AB Artificial neural network (ANN) are widely applied in machine learning and artificial intelligence. But ANN usually requires large data throughputs and induces high power consumptions. This paper proposes an accelerator design guideline for ANN with full consideration of the hardware scale, performance and power consumption. We apply multiple clocks in our design to get a high data throughput and introduce the near threshold voltage (NTV) to get a lower power consumption. We further optimize the multiplication operation in critical path obtaining a higher performance.
C1 [Chen, Tianbao; Yin, Shouyi; Wei, Shaojun] Tsinghua Univ, Room 3-330,Bldg FIT, Beijing 100084, Peoples R China.
RP Chen, TB (corresponding author), Tsinghua Univ, Room 3-330,Bldg FIT, Beijing 100084, Peoples R China.
EM ctb13@mails.tsinghua.edu.cn; yinsy@tsinghua.edu.cn; wsj@tsinghua.edu.cn
CR [Anonymous], 2006, FPGA IMPLEMENTATIONS
   [Anonymous], 2014, TENCON 2014 2014 IEE
   Domingos P. O., 2005, Proceedings. 2005 International Conference on Field Programmable Logic and Applications (IEEE Cat. No.05EX1155), P89
   Esmaeilzadeh H., MICR MICRO 2012 45 A, V33, P16
   Lingbo Kou, 2014, 2014 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P214, DOI 10.1109/ISVLSI.2014.73
   Pietras M., 2014, PROC 24 INT C FIELD, P1
   Wey IC, 2014, INT SOC DESIGN CONF, P138, DOI 10.1109/ISOCC.2014.7087666
NR 7
TC 0
Z9 0
U1 0
U2 0
PY 2016
VL 73
BP 683
EP 687
WC Automation & Control Systems; Engineering, Multidisciplinary;
   Engineering, Manufacturing; Engineering, Mechanical
DA 2023-11-11
ER

PT C
AU Lopes, ASB
   Pereira, MM
AF Bezerra Lopes, Alba Sandyra
   Pereira, Monica Magalhaes
GP IEEE
TI A Machine Learning Approach to Accelerating DSE of Reconfigurable
   Accelerator Systems
SO 33RD SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN (SBCCI 2020)
DT Proceedings Paper
CT 33rd Symposium on Integrated Circuits and Systems Design (SBCCI)
CY AUG 24-28, 2020
CL ELECTR NETWORK
DE design space exploration; reconfigurable accelerators; CGRA; machine
   learning
ID DESIGN SPACE EXPLORATION; EFFICIENT; PERFORMANCE
AB Reconfigurable hardware accelerators (RAs) have become a frequent choice in embedded systems design to meet the performance demand of current embedded applications. However, answering when the combination of general purpose processors (GPPs) and RAs can provide the expected performance at the additional area and energy cost demands an extensive design space exploration. In this scenario when varying microarchitectural characteristics of both GPPs and RAs, one can easily reach million combinations. Evaluating one of these solutions through hardware synthesis is an extremely costly task. And even the use of high-level simulation tools as alternative does not allow simulating all solutions and meeting time-to-market. In this work, we propose the use of predictive models based on machine learning algorithms to simplify and speed up the design space exploration process of GPPs with RAs. In our case study we combine a superscalar processor and a Coarse-Grained Reconfigurable Architecture. Additionally, considering the accuracy of the prediction, we investigate ten different algorithms by comparing their error prediction rate. In this investigation, we were able to achieve an error prediction rate bellow 2% on average and reduce the time for exploring the design space up to 33x when comparing with a scenario that uses a high-level simulation tool.
C1 [Bezerra Lopes, Alba Sandyra; Pereira, Monica Magalhaes] Univ Fed Rio Grande do Norte, Dept Informat & Matemat Aplicada, Natal, RN, Brazil.
   [Bezerra Lopes, Alba Sandyra] Inst Fed Rio Grande do Norte, Campus Natal Zona Norte, Natal, RN, Brazil.
RP Lopes, ASB (corresponding author), Univ Fed Rio Grande do Norte, Dept Informat & Matemat Aplicada, Natal, RN, Brazil.; Lopes, ASB (corresponding author), Inst Fed Rio Grande do Norte, Campus Natal Zona Norte, Natal, RN, Brazil.
EM alba.lopes@ifrn.edu.br; monicapereira@dimap.ufrn.br
CR Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Brandalero M, 2017, DES AUT TEST EUROPE, P1468, DOI 10.23919/DATE.2017.7927223
   Breughe MB, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2678277
   Chen TS, 2014, CONF PROC INT SYMP C, P85, DOI 10.1109/ISCA.2014.6853198
   Compton K, 2002, ACM COMPUT SURV, V34, P171, DOI 10.1145/508352.508353
   de Moura RF, 2016, IEEE COMP SOC ANN, P701, DOI 10.1109/ISVLSI.2016.67
   Dutta B, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P240, DOI 10.1145/3203217.3203273
   Gellert A, 2012, IET COMPUT DIGIT TEC, V6, P205, DOI 10.1049/iet-cdt.2011.0116
   Guo Q., 2011, TWENTY SECOND INT JO
   Guo Q, 2013, MICROPROCESS MICROSY, V37, P41, DOI 10.1016/j.micpro.2012.07.006
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Hall Mark, 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278
   Ipek E., 2006, EFFICIENTLY EXPLORIN, V41, P11
   Kareemullah H, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1500, DOI 10.1109/ICCSP.2017.8286636
   Kim RG, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243483
   Lee BC, 2006, ACM SIGPLAN NOTICES, V41, P185, DOI [10.1145/1168919.1168881, 10.1145/1168917.1168881]
   Li JT, 2009, INT SYM PERFORM ANAL, P89, DOI 10.1109/ISPASS.2009.4919641
   Li W, 2017, CHINESE J ELECTRON, V26, P1161, DOI 10.1049/cje.2017.06.010
   Lopes A., 2019 IX BRAZILIAN S
   Meng PF, 2016, DES AUT TEST EUROPE, P918
   O'Neal K, 2018, IEEE COMP SOC ANN, P763, DOI 10.1109/ISVLSI.2018.00143
   Ozisikyilmaz B, 2008, DES AUT CON, P966
   Beck ACS, 2007, VLSI-SOC 2007: PROCEEDINGS OF THE 2007 IFIP WG 10.5 INTERNATIONAL CONFERENCE ON VERY LARGE SCALE INTEGRATION, P66
   Singh G., 2019, P 56 ANN DES AUT C, P27
   Wang LJ, 2016, 2016 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY FOR MANUFACTURING SYSTEMS (ITMS 2016), P328, DOI 10.1109/ICCD.2016.7753297
NR 25
TC 4
Z9 4
U1 0
U2 0
PY 2020
DI 10.1109/sbcci50935.2020.9189899
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Özdemir, S
   Khasawneh, M
   Rao, S
   Madden, PH
AF Ozdemir, Sarp
   Khasawneh, Mohammad
   Rao, Smriti
   Madden, Patrick H.
GP ACM
TI Kernel Mapping Techniques for Deep Learning Neural Network Accelerators
SO ISPD'22: PROCEEDINGS OF THE 2022 INTERNATIONAL SYMPOSIUM ON PHYSICAL
   DESIGN
DT Proceedings Paper
CT 31st edition of the ACM International Symposium on Physical Design
   (ISPD)
CY MAR 27-30, 2022
CL ELECTR NETWORK
DE deep learning; machine learning; combinatorial optimization; kernel
   mapping; placement
AB Deep learning applications are compute intensive and naturally parallel; this has spurred the development of new processor architectures tuned for the work load. In this paper, we consider structural differences between deep learning neural networks and more conventional circuits - highlighting how this impacts strategies for mapping neural network compute kernels onto available hardware. We present an efficient mapping approach based on dynamic programming, and also a method to establish performance bounds. We also propose an architectural approach to extend the practical life time of hardware accelerators, enabling the integration of a variety of heterogenous processors into a high performance system. Experimental results using benchmarks from a recent ISPD contest are also reported.
C1 [Ozdemir, Sarp; Khasawneh, Mohammad; Rao, Smriti; Madden, Patrick H.] SUNY Binghamton CSD, Binghamton, NY 13901 USA.
   [Khasawneh, Mohammad] MathWorks, Binghamton, NY USA.
   [Rao, Smriti] Ixigo, Binghamton, NY USA.
RP Özdemir, S (corresponding author), SUNY Binghamton CSD, Binghamton, NY 13901 USA.
EM sozdemi2@binghamton.edu; mkhasaw1@binghamton.edu; srao12@binghamton.edu;
   pmadden@binghamton.edu
CR AMDAHL GM, 1967, P APR 18 20 1967 SPR, P483, DOI DOI 10.1145/1465482.1465560
   BENTLEY JL, 1980, COMMUN ACM, V23, P214, DOI 10.1145/358841.358850
   Chang CC, 2003, ASP-DAC 2003: PROCEEDINGS OF THE ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, P621, DOI 10.1109/ASPDAC.2003.1195099
   Chen J., 2020, P ICCAD
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Cormen T. H., 1990, INTRO ALGORITHMS
   Dambre J., 2001, PROC SYSTEM LEVEL IN, P49
   Fricker J. P., 2019, PROC SUPERCOMPUTING
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   James M, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'20), P145, DOI 10.1145/3372780.3380846
   LANDMAN BS, 1971, IEEE T COMPUT, VC 20, P1469, DOI 10.1109/T-C.1971.223159
   MOORE GE, 1965, ELECTRONICS, V38
   Ono S, 2005, ASIA S PACIF DES AUT, P331, DOI 10.1145/1120725.1120864
   Scheffer L. K., 2021, P ISPD, P101
   Silver D, 2017, Arxiv, DOI arXiv:1712.01815
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Yidiz MC, 2001, DES AUT CON, P776, DOI 10.1109/DAC.2001.935610
   Zisserman, 2014, CORR
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 21
EP 28
DI 10.1145/3505170.3506730
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Gómez-Luna, J
   Guo, YX
   Brocard, S
   Legriel, J
   Cimadomo, R
   Oliveira, GF
   Singh, G
   Mutlu, O
AF Gomez-Luna, Juan
   Guo, Yuxin
   Brocard, Sylvan
   Legriel, Julien
   Cimadomo, Remy
   Oliveira, Geraldo F.
   Singh, Gagandeep
   Mutlu, Onur
GP IEEE
TI Machine Learning Training on a Real Processing-in-Memory System
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
DE machine learning; processing-in-memory; regression; classification;
   clustering; benchmarking
ID ACCELERATOR
AB Machine learning (ML) algorithms [1-6] have become ubiquitous in many fields of science and technology due to their ability to learn from and improve with experience with minimal human intervention. These algorithms train by updating their model parameters in an iterative manner to improve the overall prediction accuracy. However, training machine learning algorithms is a computationally intensive process, which requires large amounts of training data. Accessing training data in current processor-centric systems (e.g., CPU, GPU) implies costly data movement between memory and processors, which results in high energy consumption and a large percentage of the total execution cycles. This data movement can become the bottleneck of the training process, if there is not enough computation and locality to amortize its cost.
C1 [Gomez-Luna, Juan; Guo, Yuxin; Oliveira, Geraldo F.; Singh, Gagandeep; Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Brocard, Sylvan; Legriel, Julien; Cimadomo, Remy] UPMEM, Grenoble, France.
RP Gómez-Luna, J (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Abadi Martin, 2016, arXiv
   Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Ahmed H., 2019, DATE
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Akin B, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P131, DOI 10.1145/2749469.2750397
   Ali M. F., 2019, IEEE TCAS REGULAR PA
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P1
   Angizi Shaahin, 2018, 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC). Proceedings, DOI 10.1109/DAC.2018.8465706
   Angizi S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317764
   Angizi S, 2019, PR GR LAK SYMP VLSI, P45, DOI 10.1145/3299874.3317984
   [Anonymous], 2016, MACHINE LEARNING MOD
   [Anonymous], 2017, DATE
   [Anonymous], 2016, MICRO
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   Asghari-Moghaddam H, 2016, INT SYMP MICROARCH
   Babarinsa O, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2069, DOI 10.1145/2723372.2764942
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Besta M., 2021, MICRO
   Boroumand A., 2016, CAL
   Boroumand A., 2020, THESIS C MELLON U
   Boroumand A., 2021, ARXIV
   Boroumand A., 2021, PACT
   Boroumand A., 2022, ICDE
   Boroumand A., 2021, ARXIV
   Boroumand A, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P629, DOI 10.1145/3307650.3322266
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3173162.3173177, 10.1145/3296957.3173177]
   Cali DS, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P951, DOI 10.1109/MICRO50266.2020.00081
   Chang KK, 2016, INT S HIGH PERF COMP, P568, DOI 10.1109/HPCA.2016.7446095
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cho S, 2020, IEEE ACCESS, V8, P135223, DOI 10.1109/ACCESS.2020.3011265
   Christy R, 2020, ISSCC DIG TECH PAP I, P148, DOI 10.1109/ISSCC19947.2020.9062889
   Dai GH, 2019, IEEE T COMPUT AID D, V38, P640, DOI 10.1109/TCAD.2018.2821565
   Deng Q, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317845
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Denzler A, 2021, Arxiv, DOI arXiv:2112.14216
   Devaux F., 2019, HOT CHIPS
   Diab S., 2022, HICOMB
   Diab S., 2022, ARXIV
   Draper J., 2002, Conference Proceedings of the 2002 International Conference on SUPERCOMPUTING, P14, DOI 10.1145/514191.514197
   Drumond M, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P639, DOI 10.1145/3079856.3080233
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Fernandez I, 2020, PR IEEE COMP DESIGN, P120, DOI 10.1109/ICCD50377.2020.00035
   Ferreira JD, 2021, Arxiv, DOI arXiv:2104.07699
   Freedman D.A., 2009, STAT MODELS THEORY P
   Fujiki D, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P397, DOI 10.1145/3307650.3322257
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   Gaillardon PE, 2016, DES AUT TEST EUROPE, P427
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2016, CONF PROC INT SYMP C, P506, DOI 10.1109/ISCA.2016.51
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Geron A., HANDS ON MACHINE LEA
   Ghiasi N. M., 2022, ASPLOS
   Gholami A., LOW POWER COMPUTER V
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Giannoula C., 2022, ARXIV
   Giannoula C, 2021, INT S HIGH PERF COMP, P263, DOI 10.1109/HPCA51647.2021.00031
   Giannoula Christina, 2022, SIGMETRICS
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Gokhale M., 2015, MEMSYS
   Gomez-Luna J., 2021, IGSC
   Gomez-Luna J., 2022, EVALUATING MACHINE L
   Gomez-Luna J., 2021, ARXIV
   Gomez-Luna J, 2022, IEEE ACCESS, V10, P52565, DOI 10.1109/ACCESS.2022.3174101
   Goodfellow, 2016, DEEP LEARNING
   Gu B, 2016, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA.2016.23
   Gu P, 2020, ANN I S COM, P804, DOI 10.1109/ISCA45697.2020.00071
   Gu Q., 2014, WONDP
   Hajinazar Nastaran, 2021, ASPLOS
   Hamdioui S, 2017, DES AUT TEST EUROPE, P722, DOI 10.23919/DATE.2017.7927083
   Hamdioui S, 2015, DES AUT TEST EUROPE, P1718
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   Hashemi M, 2016, CONF PROC INT SYMP C, P444, DOI 10.1109/ISCA.2016.46
   Herruzo JM, 2021, J SUPERCOMPUT, V77, P10226, DOI 10.1007/s11227-021-03661-3
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1
   Hsieh K, 2016, PR IEEE COMP DESIGN, P25, DOI 10.1109/ICCD.2016.7753257
   Hsieh K, 2016, CONF PROC INT SYMP C, P204, DOI 10.1109/ISCA.2016.27
   Huang Y., 2020, IPDPS
   Hwu W. -M., 2017, ICRC
   Jacob A. C., 2016, RC25644WAT1612008 IB
   Jain S, 2018, DES AUT TEST EUROPE, P1640, DOI 10.23919/DATE.2018.8342277
   JEDEC, 2013, JESD235 JEDEC
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kang Y, 2012, PR IEEE COMP DESIGN, P5, DOI [10.1109/APPEEC.2012.6307592, 10.1109/ICCD.2012.6378608]
   Kautz W. H., 1969, IEEE TC
   Ke L., 2021, IEEE MICRO
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim G, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126965
   Kim JS, 2019, INT S HIGH PERF COMP, P582, DOI 10.1109/HPCA.2019.00011
   Kim JS, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4460-0
   Kim JS, 2018, INT S HIGH PERF COMP, P194, DOI 10.1109/HPCA.2018.00026
   Kirk D. B., 2017, APPL CASE STUDY MACH, V3rd
   Kogge P. M., 1994, ICPP
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Kvatinsky S, 2014, IEEE T VLSI SYST, V22, P2054, DOI 10.1109/TVLSI.2013.2282132
   Kvatinsky S, 2011, 2011 IEEE 29TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P142, DOI 10.1109/ICCD.2011.6081389
   Kwon Y.-C., 2021, ISSCC
   Landgraf J., 2021, COMBINING EMULATION
   Lavenier D, 2020, IEEE INT C BIOINFORM, P204, DOI 10.1109/BIBM49941.2020.9313351
   Lee D, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2832911
   Lee JH, 2015, INT CONFER PARA, P241, DOI 10.1109/PACT.2015.42
   Lee S., 2022, ISSCC
   Lee S, 2021, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA52012.2021.00013
   Levy Y, 2014, MICROELECTRON J, V45, P1429, DOI 10.1016/j.mejo.2014.06.006
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Li SC, 2016, DES AUT CON, DOI [10.1145/2897937.2898064, 10.1109/ICAUMS.2016.8479697]
   Liu ZY, 2017, PROCEEDINGS OF THE 29TH ACM SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES (SPAA'17), P235, DOI 10.1145/3087556.3087582
   Lloyd S., 2018, MEMSYS
   Lloyd S., 2015, COMPUTER
   Lloyd S, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P26, DOI 10.1145/3132402.3132434
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mai K, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P161, DOI [10.1145/342001.339673, 10.1109/ISCA.2000.854387]
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Mohri Mehryar, 2012, FDN MACHINE LEARNING
   Morad A., 2015, ACM T ARCHIT CODE OP
   Murphy R. C., INTELLIGENT MEMORY S
   Mutlu O, 2022, Arxiv, DOI arXiv:2012.03112
   Mutlu O, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3323476
   Mutlu O, 2019, PR GR LAK SYMP VLSI, P5, DOI 10.1145/3299874.3322805
   Mutlu Onur, 2014, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V1, P19
   Mutlu O, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P21, DOI 10.1109/IMW.2013.6582088
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nair R, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2409732
   Nair R, 2015, P IEEE, V103, P1331, DOI 10.1109/JPROC.2015.2435018
   Niu D., 2022, ISSCC
   NVIDIA, 2022, CISC VIS NETW IND GL
   Olgun A., 2021, ISCA
   Oliveira GF, 2022, Arxiv, DOI arXiv:2105.03725
   Oliveira GF, 2021, IEEE ACCESS, V9, P134457, DOI 10.1109/ACCESS.2021.3110993
   Oskin M, 1998, CONF PROC INT SYMP C, P192, DOI 10.1109/ISCA.1998.694774
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Peng Y, 2015, DES AUT CON, DOI 10.1145/2744769.2744819
   Pugsley SH, 2014, INT SYM PERFORM ANAL, P190, DOI 10.1109/ISPASS.2014.6844483
   Raschka S., 2019, PYTHON MACHINE LEARN
   Rezaei S. H. S, 2020, CAL
   Rodrigues A., 2019, MEMSYS
   Run:AI, 2021, BEST GPU DEEP LEARN
   Santos PC, 2017, DES AUT TEST EUROPE, P710, DOI 10.23919/DATE.2017.7927081
   Seshadri V., 2013, MICRO
   Seshadri V, 2016, Arxiv, DOI arXiv:1611.09988
   Seshadri V, 2020, Arxiv, DOI arXiv:1905.09822
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Seshadri V, 2017, ADV COMPUT, V106, P107, DOI 10.1016/bs.adcom.2017.04.004
   Seshadri V, 2015, IEEE COMPUT ARCHIT L, V14, P127, DOI 10.1109/LCA.2015.2434872
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shalev-Schwartz Ben-David S., 2014, UNDERSTANDING MACHIN
   Shaw D. E., 1981, IEEE DATABASE ENG B
   Shin H, 2018, IEEE T COMPUT AID D, V37, P2613, DOI 10.1109/TCAD.2018.2857044
   Singh G., 2021, ACM T RECONFIG TECHN
   Singh G, 2021, IEEE MICRO, V41, P39, DOI 10.1109/MM.2021.3088396
   Singh G, 2020, I C FIELD PROG LOGIC, P9, DOI 10.1109/FPL50879.2020.00014
   Singh G, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317867
   Singh T, 2017, ISSCC DIG TECH PAP I, P52
   STONE HS, 1970, IEEE T COMPUT, VC 19, P73, DOI 10.1109/TC.1970.5008902
   Sura Z., 2015, CF
   UPMEM, 2021, UPMEM US MAN
   UPMEM, 2018, CISC VIS NETW IND GL
   UPMEM, 2021, UPMEM SOFTW DEV KIT
   UPMEM, 2020, UPMEM WEBS
   Wang YH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P313, DOI 10.1109/MICRO50266.2020.00036
   Weber D, 2005, IEEE INT INTERC TECH, P185, DOI 10.1109/IITC.2005.1499974
   Weisstein E. W., 2004, THE TAYLOR SERIES
   Xi Y., 2020, P IEEE
   Xie L, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P335, DOI 10.1109/ICCD.2015.7357122
   Xin X, 2020, INT S HIGH PERF COMP, P303, DOI 10.1109/HPCA47549.2020.00033
   Yan X., 2009, LINEAR REGRESSION AN, DOI DOI 10.1142/6986
   Yavits L., 2021, IEEE TPDS
   Yu JT, 2018, DES AUT TEST EUROPE, P1646, DOI 10.23919/DATE.2018.8342278
   Yuffe Marcelo, 2011, ISSCC
   Zha Y, 2020, ANN I S COM, P846, DOI 10.1109/ISCA45697.2020.00074
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zheng L, 2016, IEEE INT SYMP CIRC S, P1382, DOI 10.1109/ISCAS.2016.7527507
   Zhu QL, 2013, IEEE HIGH PERF EXTR
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
   Zmora N., ACHIEVING FP32 ACCUR
   Zois V., 2018, PACT
NR 184
TC 0
Z9 0
U1 1
U2 2
PY 2022
BP 292
EP 295
DI 10.1109/ISVLSI54635.2022.00064
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Esmaeilzadeh, H
   Ghodrati, S
   Kahng, AB
   Kim, JK
   Kinzer, S
   Kundu, S
   Mahapatra, R
   Manasi, SD
   Sapatnekar, SS
   Wang, ZA
   Zeng, ZQ
AF Esmaeilzadeh, Hadi
   Ghodrati, Soroush
   Kahng, Andrew B.
   Kim, Joon Kyung
   Kinzer, Sean
   Kundu, Sayak
   Mahapatra, Rohan
   Manasi, Susmita Dey
   Sapatnekar, Sachin S.
   Wang, Zhiang
   Zeng, Ziqing
GP Assoc Comp Machinery
TI Physically Accurate Learning-based Performance Prediction of
   Hardware-accelerated ML Algorithms
SO MLCAD '22: PROCEEDINGS OF THE 2022 ACM/IEEE 4TH WORKSHOP ON MACHINE
   LEARNING FOR CAD (MLCAD)
DT Proceedings Paper
CT 4th ACM/IEEE Workshop on Machine Learning for CAD (MLCAD)
CY SEP 12-13, 2022
CL Snowbird, UT
DE PPA prediction; design space exploration; ML accelerator
AB Parameterizable ML accelerators are the product of recent break-throughs in machine learning (ML). To fully enable the design space exploration, we propose a physical-design-driven, learning-based prediction framework for hardware-accelerated deep neural network (DNN) and non-DNN ML algorithms. It employs a unified methodology, coupling backend power, performance and area (PPA) analysis with frontend performance simulation, thus achieving realistic estimation of both backend PPA and system metrics (runtime and energy). Experimental studies show that the approach provides excellent predictions for both ASIC (in a 12nm commercial process) and FPGA implementations on the VTA and VcriGOOD-ML platforms.
C1 [Esmaeilzadeh, Hadi; Ghodrati, Soroush; Kahng, Andrew B.; Kim, Joon Kyung; Kinzer, Sean; Kundu, Sayak; Mahapatra, Rohan; Wang, Zhiang] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Manasi, Susmita Dey; Sapatnekar, Sachin S.; Zeng, Ziqing] Univ Minnesota, Minneapolis, MN USA.
RP Esmaeilzadeh, H (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
CR Agnesina A, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415690
   [Anonymous], VTA HARDWARE DESIGN
   [Anonymous], VERIGOOD ML
   AUTOML, AUT MACH LEARN
   Bai C., 2021, P ICCAD
   Banerjee S, 2021, Arxiv, DOI arXiv:2111.15024
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Esmaeilzadeh H., 2021, P ICCAD, P1
   Genc Hasan, 2021, 2021 58th ACM/IEEE Design Automation Conference (DAC), P769, DOI 10.1109/DAC18074.2021.9586216
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kahng AB, 2015, IEEE EMBED SYST LETT, V7, P41, DOI 10.1109/LES.2015.2402197
   Last F., 2021, PROC MLCAD, P1
   Lee W, 2015, I SYMPOS LOW POWER E, P189, DOI 10.1109/ISLPED.2015.7273512
   Lin Z., 2020, THESIS, P574
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Manasi SD, 2021, ASIA S PACIF DES AUT, P235, DOI 10.1145/3394885.3431539
   Manasi SD, 2020, IEEE T VLSI SYST, V28, P1844, DOI 10.1109/TVLSI.2020.2995135
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Tabanelli Enrico, 2021, ARXIV
   van der Laan MJ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1309
   Wang HS, 2002, INT SYMP MICROARCH, P294, DOI 10.1109/MICRO.2002.1176258
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
NR 26
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 119
EP 126
DI 10.1145/3551901.3556489
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Reagen, B
   Hernández-Lobato, JM
   Adolf, R
   Gelbart, M
   Whatmough, P
   Wei, GY
   Brooks, D
AF Reagen, Brandon
   Hernandez-Lobato, Jose Miguel
   Adolf, Robert
   Gelbart, Michael
   Whatmough, Paul
   Wei, Gu-Yeon
   Brooks, David
GP IEEE
TI A Case for Efficient Accelerator Design Space Exploration via Bayesian
   Optimization
SO 2017 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN (ISLPED)
SE International Symposium on Low Power Electronics and Design
DT Proceedings Paper
CT 22nd IEEE/ACM International Symposium on Low Power Electronics and
   Design (ISLPED)
CY JUL 24-26, 2017
CL Natl Taiwan Univ, Taipei, TAIWAN
HO Natl Taiwan Univ
AB In this paper we propose using machine learning to improve the design of deep neural network hardware accelerators. We show how to adapt multi-objective Bayesian optimization to overcome a challenging design problem: optimizing deep neural network hardware accelerators for both accuracy and energy efficiency. DNN accelerators exhibit all aspects of a challenging optimization space: the landscape is rough, evaluating designs is expensive, the objectives compete with each other, and both design spaces (algorithmic and microarchitectural) are unwieldy. With multi-objective Bayesian optimization, the design space exploration is made tractable and the design points found vastly outperform traditional methods across all metrics of interest.
C1 [Reagen, Brandon; Adolf, Robert; Whatmough, Paul; Wei, Gu-Yeon; Brooks, David] Harvard Univ, Cambridge, MA 02138 USA.
   [Hernandez-Lobato, Jose Miguel] Univ Cambridge, Cambridge, England.
   [Gelbart, Michael] Univ British Columbia, Vancouver, BC, Canada.
   [Whatmough, Paul] ARM Res, Cambridge, England.
RP Reagen, B (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
CR Bergstra J, 2012, RANDOM SEARCH HYPER
   Chen T., 2014, DIANNAO SMAII FOOTPR
   Chen Yu-Hsin, 2016, EYERISS SPATIAL ARCH
   Deb K, 2002, INT C PAR PROBL SOLV
   Grosse R., 2014, WHICH RES RESULTS WI
   Hernandez-Lobato D., 2016, PREDICTIVE ENTROPY S
   Hernandez-Lobato J. M., 2016, NIPS WORKSH BAY OPT
   LeCun Y., MNIST DATABASE HANDW
   LEE B, 2006, ACCURATE EFFICIENT R
   Liu H. Y., 2012, DATE
   Liu H.-Y., 2013, LEAMING BASED METHOD
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Reagen B., 2013, QUANTIFYING ACCELER
   Reagen B., 2016, ENABLING LOW POWER H
   Shahriari B., 2016, P 0 IEEE
   Shao Y. S., 2014, ALADDIN PRERTL POWER
   Smithson SC, 2016, NEURAL NETWORKS DESI
   Snoek J., 2012, ARXIV, DOI DOI 10.48550/ARXIV.1206.2944
   ZITZLER E, 1999, MULTIOBJECTIVE EVOLU
   Zuluaga M., 2012, SMART DESIGN SPACE S
NR 20
TC 9
Z9 9
U1 1
U2 3
PY 2017
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Giri, D
   Chiu, KL
   Di Guglielmo, G
   Mantovani, P
   Carloni, LP
AF Giri, Davide
   Chiu, Kuan-Lin
   Di Guglielmo, Giuseppe
   Mantovani, Paolo
   Carloni, Luca P.
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine
   Learning
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB We present ESP4ML, an open-source system-level design flow to build and program SoC architectures for embedded applications that require the hardware acceleration of machine learning and signal processing algorithms. We realized ESP4ML by combining two established open-source projects (ESP and HLS4ML) into a new, fully-automated design flow. For the SoC integration of accelerators generated by HLS4ML, we designed a set of new parameterized interface circuits synthesizable with high-level synthesis. For accelerator configuration and management, we developed an embedded software runtime system on top of Linux. With this HW/SW layer, we addressed the challenge of dynamically shaping the data traffic on a network-on-chip to activate and support the reconfigurable pipelines of accelerators that are needed by the application workloads currently running on the SoC. We demonstrate our vertically-integrated contributions with the FPGA-based implementations of complete SoC instances booting Linux and executing computer-vision applications that process images taken from the Google Street View database
C1 [Giri, Davide; Chiu, Kuan-Lin; Di Guglielmo, Giuseppe; Mantovani, Paolo; Carloni, Luca P.] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
RP Giri, D (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
EM davide_giri@cs.columbia.edu; chiu@cs.columbia.edu;
   giuseppe@cs.columbia.edu; paolo@cs.columbia.edu; luca@cs.columbia.edu
CR [Anonymous], 2018, OPEN NEURAL NETWORK
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Carloni LP, 2016, DES AUT CON, DOI 10.1145/2897937.2905018
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Giri D., 2018, P 12 IEEE ACM INT S
   Giri D, 2018, IEEE MICRO, V38, P36, DOI 10.1109/MM.2018.2877288
   Gupta G., 2017, IEEE COMPUTER
   Hao C., 2018, P ICSICT OCT
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mantovani P, 2016, DES AUT CON, DOI 10.1145/2897937.2897984
   Mantovani P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURE AND SYNTHESIS FOR EMBEDDED SYSTEMS (CASES), DOI 10.1145/2968455.2968509
   Mantovani P, 2016, ASIA S PACIF DES AUT, P204, DOI 10.1109/ASPDAC.2016.7428012
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Pursley D., 2017, P VLSI DAT APR, P1
   Song YH, 2003, IEEE T PARALL DISTR, V14, P259, DOI 10.1109/TPDS.2003.1189584
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   xilinx, XIL VIV DES SUIT
   Yunbin Deng, 2019, Proceedings of the SPIE, V10993, DOI 10.1117/12.2518469
   Yuval N., 2011, STREET VIEW HOUSE NU
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang XF, 2017, ICCAD-IEEE ACM INT, P894, DOI 10.1109/ICCAD.2017.8203875
NR 24
TC 6
Z9 6
U1 0
U2 0
PY 2020
BP 1049
EP 1054
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Industrial; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Vincent, L
   Nabe, M
   Goret, G
AF Vincent, Lionel
   Nabe, Mamady
   Goret, Gael
BE Yokota, R
   Weiland, M
   Shalf, J
   Alam, S
TI Self-optimization Strategy for IO Accelerator Parameterization
SO HIGH PERFORMANCE COMPUTING, ISC HIGH PERFORMANCE 2018
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT International Supercomputing Conference (ISC) on High Performance
CY JUN 28, 2018
CL Frankfurt am Main, GERMANY
DE HPC; Supercomputing; IO; Optimization; Regression; Inference; Machine
   learning; Auto-tuning; Parameterization; Data management
AB Exascale reaching imposes a high automation level on HPC supercomputers. In this paper, a self-optimization strategy is proposed to improve application IO performance using statistical and machine learning based methods.
   The proposed method takes advantage of collected IO data through an off-line analysis to infers the most relevant parameterization of an IO accelerator that should be used for the next launch of a similar job. This is thus a continuous improvement process that will converge toward an optimal parameterization along iterations.
   The inference process uses a numerical optimization method to propose the parameterization that minimizes the execution time of the considered application. A regression method is used to model the objective function to be optimized from a sparse set of collected data from the past runs.
   Experiments on different artificial parametric spaces show that the convergence speed of the proposed method requires less than 20 runs to converge toward a parameterization of the IO accelerator.
C1 [Vincent, Lionel; Nabe, Mamady; Goret, Gael] ATOS Bull, BDS R&D Software Data Management, F-38130 Echirolles, France.
RP Goret, G (corresponding author), ATOS Bull, BDS R&D Software Data Management, F-38130 Echirolles, France.
EM lionel.vincent.external@atos.net; mamady.nabe@atos.net;
   gael.goret@atos.net
CR Abrahm E., 2015, 2015 18 INT C NETW B
   Bergman K., 2008, AIR FORCE RES LAB, V15
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Gainaru A, 2013, INT J HIGH PERFORM C, V27, P273, DOI 10.1177/1094342013488258
   Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970
   Jamil Momin, 2013, International Journal of Mathematical Modelling and Numerical Optimisation, V4, P150
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Vu KK, 2017, INT T OPER RES, V24, P393, DOI 10.1111/itor.12292
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
NR 11
TC 1
Z9 1
U1 0
U2 1
PY 2018
VL 11203
BP 157
EP 170
DI 10.1007/978-3-030-02465-9_11
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Zhang, XY
   Bashizade, R
   Wang, YC
   Mukherjee, S
   Lebeck, AR
AF Zhang, Xiangyu
   Bashizade, Ramin
   Wang, Yicheng
   Mukherjee, Sayan
   Lebeck, Alvin R.
GP Assoc Comp Machinery
TI Statistical Robustness of Markov Chain Monte Carlo Accelerators
SO ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL
   SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 26th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY APR 12-23, 2021
CL ELECTR NETWORK
DE accelerator; statistical machine learning; probabilistic computing;
   statistical robustness; markov chain monte carlo
ID INFERENCE; HARDWARE; CONVERGENCE; QUALITY
AB Statistical machine learning often uses probabilistic models and algorithms, such as Markov Chain Monte Carlo (MCMC), to solve a wide range of problems. Probabilistic computations, often considered too slow on conventional processors, can be accelerated with specialized hardware by exploiting parallelism and optimizing the design using various approximation techniques. Current methodologies for evaluating correctness of probabilistic accelerators are often incomplete, mostly focusing only on end-point result quality ("accuracy"). It is important for hardware designers and domain experts to look beyond end-point "accuracy" and be aware of how hardware optimizations impact statistical properties.
   This work takes a first step toward defining metrics and a methodology for quantitatively evaluating correctness of probabilistic accelerators. We propose three pillars of statistical robustness: 1) sampling quality, 2) convergence diagnostic, and 3) goodness of fit. We apply our framework to a representative MCMC accelerator and surface design issues that cannot be exposed using only application end-point result quality. We demonstrate the benefits of this framework to guide design space exploration in a case study showing that statistical robustness comparable to floating-point software can be achieved with limited precision, avoiding floating-point hardware overheads.
C1 [Zhang, Xiangyu; Bashizade, Ramin; Wang, Yicheng; Mukherjee, Sayan; Lebeck, Alvin R.] Duke Univ, Durham, NC 27706 USA.
RP Zhang, XY (corresponding author), Duke Univ, Durham, NC 27706 USA.
EM xiangyu.zhang@duke.edu; ramin@cs.duke.edu; sayan@stat.duke.edu;
   alvy@cs.duke.edu
CR Thompson MB, 2010, Arxiv, DOI arXiv:1011.0175
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Banerjee SS, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P515, DOI 10.1145/3297858.3304019
   Barnard Aubrey, 2019, THESIS U WISCONSINS
   BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836
   Betancourt M, 2018, Arxiv, DOI arXiv:1701.02434
   Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Chakrapani LN, 2006, DES AUT TEST EUROPE, P1110
   Chee J, 2018, PR MACH LEARN RES, V84
   Cheng WJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162211
   Click TH, 2011, J COMPUT CHEM, V32, P513, DOI 10.1002/jcc.21638
   CODDINGTON PD, 1994, INT J MOD PHYS C, V5, P547, DOI 10.1142/S0129183194000726
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Cowles MK, 1996, J AM STAT ASSOC, V91, P883, DOI 10.2307/2291683
   Dabiri K, 2020, IEEE T PARALL DISTR, V31, P1681, DOI 10.1109/TPDS.2020.2972359
   Darulova Eva, 2014, THESIS EPFL, DOI [10.5075/epfl-thesis-6343, DOI 10.5075/EPFL-THESIS-6343]
   Finkel J. R., 2005, ACL, P363, DOI DOI 10.3115/1219840.1219885
   Flegal JM, 2008, STAT SCI, V23, P250, DOI 10.1214/08-STS257
   Freeman Linton C, 1965, ELEMENTARY APPL STAT
   Gal Y, 2016, PR MACH LEARN RES, V48
   Ge R, 2020, Arxiv, DOI arXiv:1812.00793
   Gelman A., 1992, STAT SCI, V7, P457, DOI [10.1214/ss/1177011136, DOI 10.1214/SS/1177011136]
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Geng SN, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P156
   Ghahramani Z, 2015, NATURE, V521, P452, DOI 10.1038/nature14541
   Gong L, 2016, J COMPUT GRAPH STAT, V25, P684, DOI 10.1080/10618600.2015.1044092
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Gupta S., 2015, ARXIV
   Haldane A, 2021, COMPUT PHYS COMMUN, V260, DOI 10.1016/j.cpc.2020.107312
   Hamra G, 2013, INT J EPIDEMIOL, V42, P627, DOI 10.1093/ije/dyt043
   Haselich M., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1823, DOI 10.1109/ROBIO.2012.6491233
   Hedstrom JC, 2017, IEEE T WIREL COMMUN, V16, P7718, DOI 10.1109/TWC.2017.2750667
   Herschlag Gregory, 2018, ARXIV
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Hüllermeier E, 2020, Arxiv, DOI arXiv:1910.09457
   Hurkat S, 2019, INT S HIGH PERF COMP, P345, DOI 10.1109/HPCA.2019.00049
   Intel<(R), 2019, FLOAT POINT IP COR U
   Intel<(R), 2019, INT QUART PRIM SOFTW
   Johndrow James E., 2015, ARXIV
   Kass RE, 1998, AM STAT, V52, P93, DOI 10.2307/2685466
   Kendall A., 2017, ADV NEURAL INFORM PR, V30, P5574
   Khan OU, 2016, IEEE T VLSI SYST, V24, P837, DOI 10.1109/TVLSI.2015.2420663
   Kharya P, 2020, TENSORFLOAT 32 A100
   Kish L., 1965, SURVEY SAMPLING
   Ko GG, 2019, I C FIELD PROG LOGIC, P159, DOI 10.1109/FPL.2019.00033
   Krishnan R, 2020, Arxiv, DOI arXiv:2012.07923
   Kwon Y, 2020, COMPUT STAT DATA AN, V142, DOI 10.1016/j.csda.2019.106816
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin MJ, 2010, FPGA 10, P73
   Linderman MD, 2010, INT SYM CODE GENER, P230, DOI 10.1145/1772954.1772987
   Liu SL, 2015, 2015 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (FPT), P120, DOI 10.1109/FPT.2015.7393138
   Mahajan D, 2016, CONF PROC INT SYMP C, P66, DOI 10.1109/ISCA.2016.16
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Malinin Andrey, 2018, ADV NEUR IN, P7047
   Mansinghka V, 2014, Arxiv, DOI arXiv:1402.4914
   Martino L, 2016, DIGIT SIGNAL PROCESS, V58, P64, DOI 10.1016/j.dsp.2016.07.013
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   McClure P, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00067
   Mingas G, 2017, INT J APPROX REASON, V83, P413, DOI 10.1016/j.ijar.2016.10.011
   Neal RM, 2011, CH CRC HANDB MOD STA, P113
   Ould Bachir Tarek, 2008, 2008 Canadian Conference on Electrical and Computer Engineering - CCECE, P001393, DOI 10.1109/CCECE.2008.4564770
   Park J, 2016, ACM SIGPLAN NOTICES, V51, P623, DOI 10.1145/2954679.2872376
   Pflug GC, 1992, ANN OPER RES, V39, P173
   Postels J, 2019, IEEE I CONF COMP VIS, P2931, DOI 10.1109/ICCV.2019.00302
   Robert C.P., 2004, MONTE CARLO STAT MET
   Rouhani Bita Darvish, 2020, ADV NEURAL INFORM PR, V33
   Saad Feras A, 2019, 22 INT C ARTIFICIAL, P1640
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schmid F, 1995, INT J MOD PHYS C, V6, P781, DOI 10.1142/S0129183195000642
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shukla P, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180701
   Thomas David B., 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P344, DOI 10.1109/FPT.2009.5377680
   Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI [10.1145/1390156.1390290, DOI 10.1145/1390156.1390290]
   Tribble Seth D, 2007, MARKOV CHAIN MONTE C
   Varshney KR, 2017, BIG DATA-US, V5, P246, DOI 10.1089/big.2016.0051
   Vats D, 2018, REVISITING GELMAN RU
   Vats Dootika., 2015, ARXIV
   Vehtari A., 2015, ARXIV
   Wang S, 2019, BFLOAT16 SECRET HIGH
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Wang YE, 2019, INT SYM PERFORM ANAL, P177, DOI 10.1109/ISPASS.2019.00031
   Welling M., 2011, P 28 INT C MACH LEAR, P681, DOI DOI 10.5555/3104482.3104568
   Yao YL, 2018, PR MACH LEARN RES, V80
   Zhang XY, 2018, CONF PROC INT SYMP C, P301, DOI 10.1109/ISCA.2018.00034
   Zierke S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-184
NR 88
TC 4
Z9 4
U1 0
U2 0
PY 2021
BP 959
EP 974
DI 10.1145/3445814.3446697
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Pidanic, J
   Vyas, A
   Karki, R
   Vij, P
   Trivedi, G
   Nemec, Z
AF Pidanic, Jan
   Vyas, Arpan
   Karki, Rishav
   Vij, Prateek
   Trivedi, Gaurav
   Nemec, Zdenek
GP IEEE
TI A Scalable and Adaptive Convolutional Neural Network Accelerator
SO 2022 32ND INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA)
DT Proceedings Paper
CT 32nd International Conference on Radioelectronics (RADIOELECTRONICS)
CY APR 21-22, 2022
CL Kosice, SLOVAKIA
DE Convolutional Neural Networks; Hardware Accelerator; Scalable; Adaptive;
   FPGA
ID CNN
AB Machine learning has become ubiquitous and penetrated every field of technology, medicine, and finance. Convolutional Neural Network (CNN) is one of the most commonly used class of machine learning algorithms that is being used in video and image processing, big data processing, natural language processing, robotics, and a variety of pattern matching and recognition tasks. Depending on the end application, CNNs are being employed on different scales ranging from tiny motion sensors and smartphones to automobiles and server farms. Although existing CNN accelerators are adaptive for different types of CNN models, they are generally suited for a particular scale of operation. In this paper, we describe a scalable and adaptive CNN accelerator. The same hardware-cum-software stack can be configured by a system-level parameter to be synthesized for different scales of operation. This makes the accelerator highly portable across systems of different scales. Furthermore, one single synthesized hardware can run inference for multiple CNN models because of the flexible software stack and hardware control unit making the system highly adaptive. We demonstrate the working of the system at different scales by implementing it on the Xilinx Virtex 7 FPGA and by running multiple CNN models at each scale.
C1 [Pidanic, Jan; Nemec, Zdenek] Univ Pardubice, Dept Elect Engn, Pardubice, Czech Republic.
   [Vyas, Arpan; Karki, Rishav; Trivedi, Gaurav] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati, India.
   [Vij, Prateek] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, India.
RP Pidanic, J (corresponding author), Univ Pardubice, Dept Elect Engn, Pardubice, Czech Republic.
EM jan.pidanic@upce.cz; v.arpan@iitg.ernet.in; k.rishav@iitg.ernet.in;
   v.prateek@iitg.ernet.in; trivedi@iitg.ac.in; zdenek.nemec@upce.cz
CR Abdelouahab K., 2018, ACCELERATING CNN INF
   Allard UC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2464, DOI 10.1109/IROS.2016.7759384
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Yuan T, 2021, IEEE T CIRCUITS-I, V68, P250, DOI 10.1109/TCSI.2020.3030663
   Zisserman, 2014, CORR
NR 11
TC 1
Z9 1
U1 0
U2 2
PY 2022
BP 138
EP 142
DI 10.1109/RADIOELEKTRONIKA54537.2022.9764951
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Huang, HT
   Khalid, RS
   Liu, W
   Yu, H
AF Huang, Hantao
   Khalid, Rai Suleman
   Liu, Wenye
   Yu, Hao
GP IEEE
TI Work-in-Progress: A Fast Online Sequential Learning Accelerator for IoT
   Network Intrusion Detection
SO 2017 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM
   SYNTHESIS (CODES+ISSS)
DT Proceedings Paper
CT International Conference on Hardware/Software Codesign and System
   Synthesis (CODES+ISSS)
CY OCT 15-20, 2017
CL Seoul, SOUTH KOREA
AB Deployment of IoT devices for smart buildings and homes will offer a high level of comfortability with increased energy efficiency; but can also introduce potential cyber-attacks such as network intrusions via linked IoT devices. Due to the low-power and low-latency requirement to secure IoT network, traditional software based security system is not applicable. Instead, an embedded hardware-accelerator based data analytics is more preferred for network intrusion detection. In this paper, we propose an online sequential machine learning hardware accelerator to perform real-time network intrusion detection. A single hidden layer feedforward neural network based learning algorithm is developed with a least-squares solver realized on hardware. Experimental results on a single FPGA achieve a bandwidth of 409.6 Gbps with fast yet low-power network intrusion detection based on a number of benchmarks.
C1 [Huang, Hantao; Khalid, Rai Suleman; Liu, Wenye; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
RP Huang, HT (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
EM haoyu@ntn.edu.sg
CR [Anonymous], 2012, NSL KDD DATASET
   Hall Mark, 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278
   HUANG HT, 2016, IEEE ACM DATE
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Viegas E, 2017, IEEE T COMPUT, V66, P163, DOI 10.1109/TC.2016.2560839
NR 5
TC 1
Z9 1
U1 1
U2 2
PY 2017
DI 10.1145/3125502.3125532
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Flajolet, A
   Monroc, CB
   Beguir, K
   Pierrot, T
AF Flajolet, Arthur
   Monroc, Claire Bizon
   Beguir, Karim
   Pierrot, Thomas
BA Chaudhuri, K
   Jegelka, S
   Song, L
   Szepesvari, C
   Niu, G
   Sabato, S
BF Chaudhuri, K
   Jegelka, S
   Song, L
   Szepesvari, C
   Niu, G
   Sabato, S
TI Fast Population-Based Reinforcement Learning on a Single Machine
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 162
SE Proceedings of Machine Learning Research
DT Proceedings Paper
CT 38th International Conference on Machine Learning (ICML)
CY JUL 17-23, 2022
CL Baltimore, MD
ID LEVEL
AB Training populations of agents has demonstrated great promise in Reinforcement Learning for stabilizing training, improving exploration and asymptotic performance, and generating a diverse set of solutions. However, population-based training is often not considered by practitioners as it is perceived to be either prohibitively slow (when implemented sequentially), or computationally expensive (if agents are trained in parallel on independent accelerators). In this work, we compare implementations and revisit previous studies to show that the judicious use of compilation and vectorization allows population-based training to be performed on a single machine with one accelerator with minimal overhead compared to training a single agent. We also show that, when provided with a few accelerators, our protocols extend to large population sizes for applications such as hyperparameter tuning. We hope that this work and the public release of our code will encourage practitioners to use population-based learning more frequently for their research and applications.
C1 [Flajolet, Arthur; Monroc, Claire Bizon; Beguir, Karim; Pierrot, Thomas] InstaDeep Ltd, London, England.
RP Flajolet, A; Pierrot, T (corresponding author), InstaDeep Ltd, London, England.
EM a.flajolet@instadeep.com; t.pierrot@instadeep.com
CR Agarwal Rishabh, 2021, ADV NEURAL INFORM PR, V34
   [Anonymous], 2018, ICLR, DOI DOI 10.1159/000492809
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   Brockman G., 2016, ARXIV160601540, P1
   Colas C, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P67, DOI 10.1145/3377930.3390217
   Daniel Freeman C., 2021, BRAX DIFFERENTIABLE
   Espeholt L, 2018, PR MACH LEARN RES, V80
   Eysenbach B., 2019, 7 INT C LEARN REPR I
   Frostig R., 2018, SYSML
   Fujimoto S, 2018, PR MACH LEARN RES, V80
   Haarnoja, 2018, ARXIV181205905
   Hennigan T., 2020, HAIKU SONNET JAX
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Hoffman M., 2020, ARXIV200600979
   Jaderberg M, 2019, SCIENCE, V364, P859, DOI 10.1126/science.aau6249
   Jaderberg Max, 2017, POPULATION BASED TRA
   Jung Whiyoung, 2020, INT C LEARN REPR
   Makoviychuk Viktor, 2021, ISAAC GYM HIGH PERFO
   Mnih V., 2013, ARXIV, DOI DOI 10.1038/NATURE14236
   Mnih V, 2016, PR MACH LEARN RES, V48
   Nilsson O, 2021, PROCEEDINGS OF THE 2021 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'21), P866, DOI 10.1145/3449639.3459304
   Ota K., 2021, ARXIV210207920
   Parker-Holder J., 2020, P ADV NEUR INF PROC, V33, P18050
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Petrenko Aleksei, 2020, P MACHINE LEARNING R, V119, P7652
   Pierrot T., 2022, ICLR WORKSH AG LEARN
   Pourchot A., 2019, INT C LEARN REPR
   Raffin A, 2021, J MACH LEARN RES, V22, P1
   Sharifnassab A., 2020, P INT C LEARN REPR, P1
   Stooke A., 2018, ARXIV180302811
   Stooke Adam, 2021, PR MACH LEARN RES, P9870
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
NR 33
TC 1
Z9 1
U1 0
U2 0
PY 2022
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Shen, YM
   Ferdman, M
   Milder, P
AF Shen, Yongming
   Ferdman, Michael
   Milder, Peter
GP IEEE
TI Overcoming Resource Underutilization in Spatial CNN Accelerators
SO 2016 26TH INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)
SE International Conference on Field Programmable and Logic Applications
DT Proceedings Paper
CT 26th International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2016
CL Ecole Polytechnique Federale de Lausanne, Lausanne, SWITZERLAND
HO Ecole Polytechnique Federale de Lausanne
ID COPROCESSOR
AB Convolutional neural networks (CNNs) are revolutionizing a variety of machine learning tasks, but they present significant computational challenges. Recently, FPGA-based accelerators have been proposed to improve the speed and efficiency of CNNs. Current approaches construct an accelerator optimized to maximize the overall throughput of iteratively computing the CNN layers. However, this approach leads to dynamic resource underutilization because the same accelerator is used to compute CNN layers of radically varying dimensions.
   We present a new CNN accelerator design that improves the dynamic resource utilization. Using the same FPGA resources, we build multiple accelerators, each specialized for specific CNN layers. Our design achieves 1.3x higher throughput than the state of the art when evaluating the convolutional layers of the popular AlexNet CNN on a Xilinx Virtex-7 FPGA.
C1 [Shen, Yongming; Ferdman, Michael; Milder, Peter] SUNY Stony Brook, Stony Brook, NY 11794 USA.
RP Shen, YM (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
EM yoshen@cs.stonybrook.edu; mferdman@cs.stonybrook.edu;
   peter.milder@stonybrook.edu
CR Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Shen Y., ARXIV160700064
   Van den Oord A., 2013, ADV NEURAL INF PROCE, V26
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 10
TC 23
Z9 26
U1 0
U2 2
PY 2016
DI 10.1109/FPL.2016.7577315
WC Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Caselli, M
   Debacker, P
   Boni, A
AF Caselli, Michele
   Debacker, Peter
   Boni, Andrea
TI Memory Devices and A/D Interfaces: Design Tradeoffs in Mixed-Signal
   Accelerators for Machine Learning Applications
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Random access memory; Voltage; Resistance; Transistors; Computer
   architecture; Circuits and systems; Analog-digital conversion; AiMC;
   DNNs; SRAM; RRAM; IGZO DRAM; SOT MRAM; SAR ADC; Flash ADC; Serial ADC
ID COMPUTE-IN-MEMORY; SRAM MACRO; RRAM; EFFICIENT; CHIP
AB This tutorial focuses on memory elements and analog/digital (A/D) interfaces used in mixed-signal accelerators for deep neural networks (DNNs) in machine learning (ML) applications. These very dedicated systems exploit analog in-memory computation (AiMC) of weights and input activations to accelerate the DNN algorithm. The co-optimization of the memory cell storing the weights with the peripheral circuits is mandatory for improving the performance metrics of the accelerator. In this tutorial, four memory devices for AiMC are reported and analyzed with their computation scheme, including the digital-to-analog converter (DAC). Moreover, we review analog-to-digital converters (ADCs) for the quantization of the AiMC results, focusing on the design trade-offs of the different topologies given by the context.
C1 [Caselli, Michele; Boni, Andrea] Univ Parma, Dept Engn & Architecture, I-42124 Parma, Italy.
   [Debacker, Peter] IMEC, Compute Syst Architecture CSA, B-3001 Leuven, Belgium.
RP Boni, A (corresponding author), Univ Parma, Dept Engn & Architecture, I-42124 Parma, Italy.
EM michele.caselli@unipr.it; peter.debacker@imec.be; andrea.boni@unipr.it
CR Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Belmonte A, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371900
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Boni A., 2021, PROC IEEE INT C ELEC, P1
   Cai ZW, 2017, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR.2017.574
   Caselli M., 2022 IEEE INT S CIRC, P1462
   Caselli M, 2021, PRIMATES, V62, P571, DOI 10.1007/s10329-021-00916-8
   Chen ZY, 2019, IEEE T VLSI SYST, V27, P2655, DOI 10.1109/TVLSI.2019.2925937
   Cosemans S, 2019, INT EL DEVICES MEET
   Doevenspeck J., 2021, 2021 Symposium on VLSI Technology
   Doevenspeck J, 2020, S VLSI TECH, DOI 10.1109/vlsitechnology18217.2020.9265099
   Doevenspeck J, 2018, PROC EUR S-STATE DEV, P62, DOI 10.1109/ESSDERC.2018.8486860
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Garello K., 2019, IEEE INT MEM WORKSH
   He ZZ, 2019, PROC CVPR IEEE, P11430, DOI 10.1109/CVPR.2019.01170
   Houshmand P, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372006
   Huang CL, 2021, IEEE J ELECTRON DEVI, V9, P645, DOI 10.1109/JEDS.2021.3093478
   Jiang ZW, 2020, IEEE J SOLID-ST CIRC, V55, P1888, DOI 10.1109/JSSC.2020.2992886
   Kim H, 2021, PROC CVPR IEEE, P7858, DOI 10.1109/CVPR46437.2021.00777
   Lim J, 2020, MIDWEST SYMP CIRCUIT, P603, DOI [10.1109/MWSCAS48704.2020.9184587, 10.1109/mwscas48704.2020.9184587]
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Murmann B, 2021, IEEE T VLSI SYST, V29, P3, DOI 10.1109/TVLSI.2020.3020286
   Papistas IA, 2021, IEEE CUST INTEGR CIR, DOI 10.1109/CICC51472.2021.9431575
   Raman SRS, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401798
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Subhechha S., 2021, 2021 Symposium on VLSI Technology
   Ueyoshi K., 2022, 2022 IEEE INT SOLID, V1
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yin SH, 2020, IEEE T ELECTRON DEV, V67, P4185, DOI 10.1109/TED.2020.3015178
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yoon JH, 2022, IEEE J SOLID-ST CIRC, V57, P68, DOI 10.1109/JSSC.2021.3101209
   Yu SM, 2021, IEEE T CIRCUITS-I, V68, P2753, DOI 10.1109/TCSI.2021.3072200
   Zhang S, 2020, IEEE T CIRCUITS-I, V67, P1867, DOI 10.1109/TCSI.2020.2971642
   Zhou KJ, 2021, IEEE T CIRCUITS-II, V68, P2932, DOI 10.1109/TCSII.2021.3065697
NR 36
TC 1
Z9 1
U1 10
U2 26
PD JUL
PY 2022
VL 69
IS 7
BP 3084
EP 3089
DI 10.1109/TCSII.2022.3174622
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Whiteson, S
   Whiteson, D
AF Whiteson, Shimon
   Whiteson, Daniel
TI Machine learning for event selection in high energy physics
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
DT Article
DE Machine learning; Neural networks; Evolutionary computation; High energy
   physics; Event selection
ID TOP-QUARK PRODUCTION
AB The field of high energy physics aims to discover the underlying structure of matter by searching for and studying exotic particles, such as the top quark and Higgs boson, produced in collisions at modern accelerators. Since such accelerators are extraordinarily expensive, extracting maximal information from the resulting data is essential. However, most accelerator events do not produce particles of interest, so making effective measurements requires event selection, in which events producing particles of interest (signal) are separated from events producing other particles (background). This article studies the use of machine learning to aid event selection. First, we apply supervised learning methods, which have succeeded previously in similar tasks. However, they are suboptimal in this case because they assume that the selector with the highest classification accuracy will yield the best final analysis: this is not true in practice, as such analyses are more sensitive to some backgrounds than others. Second, we present a new approach that uses stochastic optimization techniques to directly search for selectors that maximize either the precision of top quark mass measurements or the sensitivity to the presence of the Higgs boson. Empirical results confirm that stochastically optimized selectors result in substantially better analyses. We also describe a case study in which the best selector is applied to real data from the Fermilab Tevatron accelerator, resulting in the most precise top quark mass measurement of this type to date. Hence, this new approach to event selection has already contributed to our knowledge of the top quark's mass and our understanding of the larger questions upon which it sheds light. (C) 2009 Elsevier Ltd. All rights reserved.
C1 [Whiteson, Shimon] Univ Amsterdam, Inst Informat, NL-1098 XG Amsterdam, Netherlands.
   [Whiteson, Daniel] Univ Calif Irvine, Dept Phys & Astron, Irvine, CA 92697 USA.
RP Whiteson, S (corresponding author), Univ Amsterdam, Inst Informat, Sci Pk 107, NL-1098 XG Amsterdam, Netherlands.
EM s.a.whiteson@uva.nl; daniel@uci.edu
CR Aaltonen T, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.062005
   Aaltonen T, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.152001
   ABACHI S, 1995, PHYS REV LETT, V74, P2632, DOI 10.1103/PhysRevLett.74.2632
   Abazov VM, 2001, PHYS LETT B, V517, P282, DOI 10.1016/S0370-2693(01)01009-7
   ABE F, 1995, PHYS REV LETT, V74, P2626, DOI 10.1103/PhysRevLett.74.2638
   ABULENCIA A, 2004, PHYS REV LETT, V93
   ABULENCIA A, 2005, PHYS REV LETT, V96
   ABULENCIA A, 2005, PHYS REV D, V71
   ACOSTA D, 2005, PHYS REV D, V52
   Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   [Anonymous], 1999, P 5 ACM SIGKDD INT C
   [Anonymous], P 19 ANN INN APPL AR
   [Anonymous], 2004, THESIS STANFORD U
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   BRUBAKER E, 2004, THESIS U CALIFORNIA
   Cho A, 2006, SCIENCE, V312, P1302, DOI 10.1126/science.312.5778.1302
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cranmer K, 2005, COMPUT PHYS COMMUN, V167, P165, DOI 10.1016/j.cpc.2004.12.006
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Elkan C., 2001, P 17 INT JOINT C ART, DOI DOI 10.5555/1642194.1642224
   ESTRADA J, 2001, THESIS U ROCHESTER
   FAWCETT T, 1993, THESIS U MASSASSACHU
   GETOOR L, 2007, INTRO RELATIONAL STA
   GLASHOW SL, 1961, NUCL PHYS, V22, P579, DOI 10.1016/0029-5582(61)90469-2
   GOMEZ F, 2006, P EUR C MACH LEARN
   Hashimoto M, 2001, PHYS REV D, V64, DOI 10.1103/PhysRevD.64.056003
   Heinemeyer S, 2003, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2003/09/075
   HIGGS PW, 1966, PHYS REV, V145, P1156, DOI 10.1103/PhysRev.145.1156
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   JAYATILAKA B, 2006, THESIS U MICHIGAN
   KADO MM, 2002, PHYS LETT, V565, P61
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   KOVALEV A, 2005, THESIS U PENNSYLVANI
   *LEP COLL, 2004, CERNPHEP2004069 LEP
   MIRANSKY VA, 1989, MOD PHYS LETT A, V4, P1043, DOI 10.1142/S0217732389001210
   PEDRO L, 2002, ESTIMATION DISTRIBUT
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rumelhart David E., 1986, PARALLEL DISTRIBUTED, V1, DOI 10.1016/b978-1-4832-1446-7.50035-2
   Shakhnarovish G., 2005, NEAREST NEIGHBOR MET
   Sjöstrand T, 2001, COMPUT PHYS COMMUN, V135, P238, DOI 10.1016/S0010-4655(00)00236-8
   Stanley KO, 2005, IEEE T EVOLUT COMPUT, V9, P653, DOI 10.1109/TEVC.2005.856210
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   UTGOFF PE, 2001, MACHINES LEARN PLAY, P131
   VARNES E, 1997, THESIS U CALIFORNIA
   WEINBERG S, 1967, PHYS REV LETT, V19, P1264, DOI 10.1103/PhysRevLett.19.1264
   Whiteson DO, 2003, NEUROCOMPUTING, V55, P251, DOI 10.1016/S0925-2312(03)00366-7
   Whiteson S, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P1225
   Whiteson S, 2006, J MACH LEARN RES, V7, P877
   Yao WM, 2006, J PHYS G NUCL PARTIC, V33, P1, DOI 10.1088/0954-3899/33/1/001
   Yao X, 1999, P IEEE, V87, P1423, DOI 10.1109/5.784219
NR 51
TC 39
Z9 40
U1 0
U2 8
PD DEC
PY 2009
VL 22
IS 8
BP 1203
EP 1217
DI 10.1016/j.engappai.2009.05.004
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Bolhasani, H
   Jassbi, SJ
   Sharifi, A
AF Bolhasani, Hamidreza
   Jassbi, Somayyeh Jafarali
   Sharifi, Arash
TI DLA-H: A Deep Learning Accelerator for Histopathologic Image
   Classification
SO JOURNAL OF DIGITAL IMAGING
DT Article
DE Hardware accelerator; Data flow; Deep neural networks; Convolutional
   neural networks; Deep learning; Histopathologic images; Classification
AB It is more than a decade since machine learning and especially its leading subtype deep learning have become one of the most interesting topics in almost all areas of science and industry. In numerous contexts, at least one of the applications of deep learning is utilized or is going to be utilized. Using deep learning for image classification is now very popular and widely used in various use cases. Many types of research in medical sciences have been focused on the advantages of deep learning for image classification problems. Some recent researches show more than 90% accuracy for breast tissue classification which is a breakthrough. A huge number of computations in deep neural networks are considered a big challenge both from software and hardware point of view. From the architectural perspective, this big amount of computing operations will result in high power consumption and computation runtime. This led to the emersion of deep learning accelerators which are designed mainly for improving performance and energy efficiency. Data reuse and localization are two great opportunities for achieving energy-efficient computations with lower runtime. Data flows are mainly designed based on these important parameters. In this paper, DLA-H and BJS, a deep learning accelerator, and its data flow for histopathologic image classification are proposed. The simulation results with the MAESTRO tool showed 756 cycles for total runtime and 3.21 x 10(6 )GFLOPS roofline throughput that is an extreme performance improvement in comparison to current general-purpose deep learning accelerators and data flows.
C1 [Bolhasani, Hamidreza; Jassbi, Somayyeh Jafarali; Sharifi, Arash] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
RP Jassbi, SJ (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
EM hamidreza.bolhasani@srbiau.ac.ir; s.jassbi@srbiau.ac.ir;
   a.sharifi@srbiau.ac.ir
CR Bolhasani Hamidreza, 2020, Informatics in Medicine Unlocked, V19, P276, DOI 10.1016/j.imu.2020.100341
   Bolhasani H, 2021, INFORM MED UNLOCKED, V23, DOI [DOI 10.1016/J.IMU.2021.100550, 10.1016/j.imu.2021.100550]
   Bolhasani H, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00377-8
   Brauer Jurgen, 2018, INTRO DEEP LEARNING
   Capra M, 2020, IEEE ACCESS, V8, P225134, DOI 10.1109/ACCESS.2020.3039858
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Fabiani C, 2019, FRONT CELL NEUROSCI, V13, DOI 10.3389/fncel.2019.00309
   Fernandez I, 2020, PR IEEE COMP DESIGN, P120, DOI 10.1109/ICCD50377.2020.00035
   Hoda Syed A., ROSENS BREAST PATHOL, P430
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon H., 2018, ARXIV
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Pellauer Michael, 2018, MODELING ANAL DEEP L
   Schwartz AM, 2014, ARCH PATHOL LAB MED, V138, P1048, DOI 10.5858/arpa.2013-0435-OA
   Sze Vivienne, 2020, SYNTHESIS LECT COMPU, DOI DOI 10.2200/S01004ED1V01Y202004CAC050
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Yari Y, 2020, IEEE ACCESS, V8, P162432, DOI 10.1109/ACCESS.2020.3021557
   Zavareh P. H., 2021, ARXIV
NR 22
TC 0
Z9 0
U1 0
U2 3
PD APR
PY 2023
VL 36
IS 2
BP 433
EP 440
DI 10.1007/s10278-022-00743-3
EA NOV 2022
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Vranjkovic, V
   Struharik, R
AF Vranjkovic, Vuk
   Struharik, Rastislav
BE Minarik, I
   Rybarova, R
   Truchly, P
   Rozinaj, G
TI Coarse-grained Reconfigurable Hardware Accelerator of Machine Learning
   Classifiers
SO PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON SYSTEMS, SIGNALS AND
   IMAGE PROCESSING, (IWSSIP 2016)
SE International Conference on Systems Signals and Image Processing
DT Proceedings Paper
CT 23rd International Conference on Systems, Signals and Image Processing
   (IWSSIP)
CY MAY 23-25, 2016
CL Bratislava, SLOVAKIA
DE Data Mining; Machine Learning; Decision Trees; Support Vector Machines;
   Artificial Neural Networks; Hardware Acceleration; Reconfigurable
   Hardware; FPGA; WEKA; R project
AB In this paper a universal, coarse-grained reconfigurable architecture for hardware acceleration of decision trees (DTs), artificial neural networks (ANNs), and support vector machines (SVMs) is proposed. Using proposed architecture, two versions of DTs (Functional DT and Axis-Parallel DT), two versions of SVMs (with polynomial and radial kernels) and two versions of ANNs (Multi Layer Perceptron and Radial Basis), have been implemented in FPGA. Experimental results, based on 18 benchmark datasets from standard UCI Machine Learning Repository Database, indicate that FPGA implementation provides significant improvement (1-3 orders of magnitude) in the average instance classification time, in comparison with software implementations, based on WEKA and R project.
C1 [Vranjkovic, Vuk; Struharik, Rastislav] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
RP Struharik, R (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
EM rasti@uns.ac.rs
CR [Anonymous], 2015, UCI REPOSITORY MACHI
   Challa S., 2011, FUNDAMENTALS OBJECT
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Flach PA, 2012, MACHINE LEARNING ART
   Grosan C, 2011, INTEL SYST REF LIBR, V17, P1, DOI 10.1007/978-3-642-21004-4
   Hall Mark, 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278
   Haykin S., 2008, NEURAL NETWORKS LEAR
   Mierswa I., 2006, P 12 ACM SIGKDD INT
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Omondi AR, 2006, FPGA IMPLEMENTATIONS OF NEURAL NETWORKS, P1, DOI 10.1007/0-387-28487-7_1
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Prince S. J., 2012, COMPUTER VISION MODE
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Struharik RJR, 2009, IET COMPUT DIGIT TEC, V3, P259, DOI 10.1049/iet-cdt.2008.0055
   Struharik RJR, 2013, J CIRCUIT SYST COMP, V22, DOI 10.1142/S0218126613500321
   Vranjkovic V., 2011, 2011 19th Telecommunications Forum Telfor (TELFOR), P1543, DOI 10.1109/TELFOR.2011.6143852
   Wiley, 2013, WIL INT REV
   Witten IH, 2011, MOR KAUF D, P3, DOI 10.1016/B978-0-12-374856-0.00001-8
   Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653
NR 20
TC 2
Z9 2
U1 0
U2 2
PY 2016
BP 193
EP 196
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT J
AU Liu, QY
   Setter, J
   Huff, D
   Strange, M
   Feng, K
   Horowitz, M
   Raina, P
   Kjolstad, F
AF Liu, Qiaoyi
   Setter, Jeff
   Huff, Dillon
   Strange, Maxwell
   Feng, Kathleen
   Horowitz, Mark
   Raina, Priyanka
   Kjolstad, Fredrik
TI Unified Buffer: Compiling Image Processing and Machine Learning
   Applications to Push-Memory Accelerators
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE Hardware accelerators; memory abstraction; polyhedral analysis; machine
   learning
ID LANGUAGE
AB Image processing and machine learning applications benefit tremendously from hardware acceleration. Existing compilers target either FPGAs, which sacrifice power and performance for programmability, or ASICs, which become obsolete as applications change. Programmable domain-specific accelerators, such as coarse-grained reconfigurable arrays (CGRAs), have emerged as a promising middle-ground, but they have traditionally been difficult compiler targets since they use a different memory abstraction. In contrast to CPUs and GPUs, the memory hierarchies of domain-specific accelerators use push memories: memories that send input data streams to computation kernels or to higher or lower levels in the memory hierarchy and store the resulting output data streams. To address the compilation challenge caused by push memories, we propose that the representation of these memories in the compiler be altered to directly represent them by combining storage with address generation and control logic in a single structure-a unified buffer.
   The unified buffer abstraction enables the compiler to separate generic push memory optimizations from the mapping to specific memory implementations in the backend. This separation allows our compiler to map high-level Halide applications to different CGRA memory designs, including some with a ready-valid interface. The separation also opens the opportunity for optimizing push memory elements on reconfigurable arrays. Our optimized memory implementation, the Physical Unified Buffer, uses a wide-fetch, single-port SRAM macro with built-in address generation logic to implement a buffer with two read and two write ports. It is 18% smaller and consumes 31% less energy than a physical buffer implementation using a dual-port memory that only supports two ports.
   Finally, our system evaluation shows that enabling a compiler to support CGRAs leads to performance and energy benefits. Over a wide range of image processing and machine learning applications, our CGRA achieves 4.7xbetter runtime and 3.5xbetter energy-efficiency compared to an FPGA.
C1 [Liu, Qiaoyi; Setter, Jeff; Huff, Dillon; Strange, Maxwell; Feng, Kathleen; Horowitz, Mark; Raina, Priyanka; Kjolstad, Fredrik] Gates Comp Sci, 353 Serra Mall, Stanford, CA 94305 USA.
RP Liu, QY (corresponding author), Gates Comp Sci, 353 Serra Mall, Stanford, CA 94305 USA.
EM joeyliu@stanford.edu; setter@stanford.edu; dillonhuff@gmail.com;
   mstrange@stanford.edu; kzf@stanford.edu; horowitz@ee.stanford.edu;
   praina@stanford.edu; kjolstad@stanford.edu
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Atak O, 2013, IEEE T VLSI SYST, V21, P1285, DOI 10.1109/TVLSI.2012.2207748
   Bondhugula U, 2008, PLDI'08: PROCEEDINGS OF THE 2008 SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN & IMPLEMENTATION, P101, DOI 10.1145/1375581.1375595
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chi YZ, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240850
   Chugh N, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P327, DOI 10.1145/2967938.2967969
   Durst D, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P408, DOI 10.1145/3385412.3385983
   Escobedo J, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P199, DOI 10.1145/3174243.3174251
   Fan XT, 2018, IEEE T VLSI SYST, V26, P1098, DOI 10.1109/TVLSI.2018.2797600
   FEAUTRIER P, 1992, INT J PARALLEL PROG, V21, P313, DOI 10.1007/BF01407835
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hegarty J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925892
   Hegarty J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601174
   Huff D, 2021, ANN IEEE SYM FIELD P, P186, DOI 10.1109/FCCM51124.2021.00030
   Ikarashi Y, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P703, DOI 10.1145/3519939.3523446
   Intel Inc, 2022, ALT OPENCL
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jie Wang, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P93, DOI 10.1145/3431920.3439292
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kasgen P, 2021, I C FIELD PROG LOGIC, P380, DOI 10.1109/FPL53798.2021.00074
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Li JJ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P51, DOI 10.1145/3373087.3375320
   Maxeler Inc, 2022, MAXCOMPILER
   Meeus W, 2012, DES AUTOM EMBED SYST, V16, P31, DOI 10.1007/s10617-012-9096-8
   Mei BF, 2003, LECT NOTES COMPUT SC, V2778, P61
   Mentor, 2019, CAT SYNTH US REF MAN
   Mentor Graphics Inc, 2022, CATAPULT HIGH LEVEL
   Mirsky E, 1996, IEEE SYMPOSIUM ON FPGAS FOR CUSTOM COMPUTING MACHINES, PROCEEDINGS, P157, DOI 10.1109/FPGA.1996.564808
   Moreau T., 2018, ARXIV
   Moreau T, 2018, 1ST ACM REQUEST WORKSHOP/TOURNAMENT ON REPRODUCIBLE SOFTWARE/HARDWARE CO-DESIGN OF PARETO-EFFICIENT DEEP LEARNING, DOI 10.1145/3229762.3229766
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Nautiyal V, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P12, DOI 10.1109/SOCC.2017.8225996
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Parashar Angshuman, 2021, P 11 INT WORKSHOP PO
   Pellauer M, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P137, DOI 10.1145/3297858.3304025
   Podobas A, 2020, IEEE ACCESS, V8, P146719, DOI 10.1109/ACCESS.2020.3012084
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Pu J, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3107953
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Reiche O, 2014, 2014 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2656075.2656081
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sharma H, 2016, INT SYMP MICROARCH
   Sohrabizadeh A, 2022, ACM T DES AUTOMAT EL, V27, DOI 10.1145/3494534
   Torng C, 2021, INT S HIGH PERF COMP, P412, DOI 10.1109/HPCA51647.2021.00042
   Vasilyev Artem, 2019, EVALUATING SPATIALLY
   Verdoolaege S, 2010, LECT NOTES COMPUT SC, V6327, P299, DOI 10.1007/978-3-642-15582-6_49
   Xilinx, 2019, VIVADO DESIGN SUITE
   Xilinx Inc, 2022, VIV HIGH LEV SYNTH
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Ylvisaker Benjamin, 2010, ENHANCED LOOP FLATTE
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhang YQ, 2021, CONF PROC INT SYMP C, P1041, DOI 10.1109/ISCA52012.2021.00085
   Zhang ZR, 2013, ICCAD-IEEE ACM INT, P211, DOI 10.1109/ICCAD.2013.6691121
   Zuo W, 2013, P ACMSIGDA INT S FIE, P9, DOI DOI 10.1145/2435264.2435271
NR 57
TC 1
Z9 1
U1 0
U2 0
PD JUN
PY 2023
VL 20
IS 2
AR 26
DI 10.1145/3572908
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Shawahna, A
   Sait, SM
   El-Maleh, A
AF Shawahna, Ahmad
   Sait, Sadiq M.
   El-Maleh, Aiman
TI FPGA-Based Accelerators of Deep Learning Networks for Learning and
   Classification: A Review
SO IEEE ACCESS
DT Review
DE Adaptable architectures; convolutional neural networks (CNNs); deep
   learning; dynamic reconfiguration; energy-efficient architecture; field
   programmable gate arrays (FPGAs); hardware accelerator; machine
   learning; neural networks; optimization; parallel computer architecture;
   reconfigurable computing
ID CONVOLUTIONAL NEURAL-NETWORKS; HIGH-LEVEL SYNTHESIS; RANGE VISION;
   COPROCESSOR; PERFORMANCE; ARCHITECTURE; RECOGNITION; CONVOLVERS;
   DADIANNAO
AB Due to recent advances in digital technologies, and availability of credible data, an area of artificial intelligence, deep learning, has emerged and has demonstrated its ability and effectiveness in solving complex learning problems not possible before. In particular, convolutional neural networks (CNNs) have demonstrated their effectiveness in the image detection and recognition applications. However, they require intensive CPU operations and memory bandwidth that make general CPUs fail to achieve the desired performance levels. Consequently, hardware accelerators that use application-specific integrated circuits, field-programmable gate arrays (FPGAs), and graphic processing units have been employed to improve the throughput of CNNs. More precisely, FPGAs have been recently adopted for accelerating the implementation of deep learning networks due to their ability to maximize parallelism and their energy efficiency. In this paper, we review the recent existing techniques for accelerating deep learning networks on FPGAs. We highlight the key features employed by the various techniques for improving the acceleration performance. In addition, we provide recommendations for enhancing the utilization of FPGAs for CNNs acceleration. The techniques investigated in this paper represent the recent trends in the FPGA-based accelerators of deep learning networks. Thus, this paper is expected to direct the future advances on efficient hardware accelerators and to be useful for deep learning researchers.
C1 [Shawahna, Ahmad; Sait, Sadiq M.; El-Maleh, Aiman] King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran 31261, Saudi Arabia.
   [Sait, Sadiq M.] King Fahd Univ Petr & Minerals, Res Inst, Ctr Commun & IT Res, Dhahran 31261, Saudi Arabia.
RP Sait, SM (corresponding author), King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran 31261, Saudi Arabia.; Sait, SM (corresponding author), King Fahd Univ Petr & Minerals, Res Inst, Ctr Commun & IT Res, Dhahran 31261, Saudi Arabia.
EM sadiq@kfupm.edu.sa
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   [Anonymous], P HOT CHIPS
   [Anonymous], 2016, BITWISE NEURAL NETWO
   [Anonymous], 2016, BINARIZED NEURAL NET
   [Anonymous], 2015, DEEP LEARNING
   [Anonymous], 2014, CUDNN EFFICIENT PRIM
   [Anonymous], P INT C NEUR INF PRO
   [Anonymous], J HOPKINS STUDIES MA
   [Anonymous], 2014, CVPR WARKSHOPS
   [Anonymous], ACM IEEE 43 ANN INT
   [Anonymous], WHAT IS DEEP LEARN
   [Anonymous], 2012, P INT C ENG RECONFIG
   [Anonymous], OPENCL DES EX
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, ARCHITECTURE EXPLORA
   [Anonymous], DESIGN FPGA BASED CO
   [Anonymous], WHAT IS LOCAL RESPON
   [Anonymous], 1980, ARITHMETIC COMPLEXIT
   [Anonymous], 2006, COMPUTER VISION PATT
   [Anonymous], 2006, FPGA IMPLEMENTATIONS
   [Anonymous], 2018, BEGINNERS GUIDE UNDE
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 2018, DLA COMPILER FPGA OV
   [Anonymous], 2018, CONVOLUTIONAL NEURAL
   [Anonymous], 2009, INT C MACH LEARN ICM
   [Anonymous], DE5 NET FPGA KIT US
   [Anonymous], P WORKSH MACH LEARN
   [Anonymous], P CAINE
   [Anonymous], 2012, FIELD PROGRAMMABLE G
   [Anonymous], 2013, FOUND TRENDS SIGNAL, DOI DOI 10.1561/2000000039
   [Anonymous], IMAGENET LARG SCAL V
   [Anonymous], 2015, NEURAL NETWORKS DEEP
   [Anonymous], 2013, NIPS
   [Anonymous], 2014, INT WORKSHOP OPENCL
   [Anonymous], 1995, CONVOLUTIONAL NETWOR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], JTAG UART COR
   [Anonymous], 2006, HAL
   [Anonymous], 2009, LEARNING MULTIPLE LA
   [Anonymous], 2015, RESILIENCY DEEP NEUR
   [Anonymous], 2016, DOREFA NET TRAINING
   [Anonymous], 1999, ITERATIVE COMPUTER A
   [Anonymous], EIGEN V3 2010
   [Anonymous], P 53 ANN DES AUT C
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 1989, ADV NEURAL INFORM PR
   [Anonymous], 2000, ARTIFICIAL NEURAL NE
   [Anonymous], 2016, ARXIV
   [Anonymous], 2018, DEEP LEARNING BASED
   [Anonymous], 2014, ARXIV
   [Anonymous], 1988, LEARNING REPRESENTAT
   [Anonymous], 1998, MNIST DATABASE HANDW
   [Anonymous], P S BRAS AUT INT BRA
   [Anonymous], P 52 ANN DES AUT C J
   [Anonymous], ACM SIGARCH COMPUTER
   [Anonymous], ALGORITHMS DESIGN TE
   [Anonymous], 1992, COMPUTATIONAL FRAMEW
   [Anonymous], P395 D8 OPENCL FPGA
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   BACON DF, 1994, ACM COMPUT SURV, V26, P345, DOI 10.1145/197405.197406
   Bai B, 2010, INFORM RETRIEVAL, V13, P291, DOI 10.1007/s10791-009-9117-9
   Barros Pablo, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P403, DOI 10.1007/978-3-319-11179-7_51
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Benkrid K, 2002, THIRD INTERNATIONAL WORKSHOP ON DIGITAL AND COMPUTATIONAL VIDEO, PROCEEDINGS, P85, DOI 10.1109/DCV.2002.1218747
   Beric A, 2008, IEEE T CIRC SYST VID, V18, P439, DOI 10.1109/TCSVT.2008.918775
   Bosi B, 1999, IEEE T VLSI SYST, V7, P299, DOI 10.1109/92.784091
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Cardells-Tormo F, 2005, IEEE WRK SIG PRO SYS, P209, DOI 10.1109/SIPS.2005.1579866
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chilimbi Trishul, 2014, P USENIX OSDI
   Cloutier J., 1996, Proceedings of the Fifth International Conference on Microelectronics for Neural Networks and Fuzzy Systems. MicroNeuro'96, P330, DOI 10.1109/MNNFS.1996.493811
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Dayhoff J. E., 1990, NEURAL NETWORK ARCHI
   Denton Emily L, 2014, ADV NEURAL INFORM PR, DOI DOI 10.5555/2968826.2968968
   DIXON JD, 1981, MATH COMPUT, V36, P255, DOI 10.1090/S0025-5718-1981-0595059-1
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Farabet Clement, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P878, DOI 10.1109/ICCVW.2009.5457611
   Farabet C., 2011, SCALING MACHINE LEAR, P399
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Gironés RG, 2005, J VLSI SIG PROC SYST, V40, P189, DOI 10.1007/s11265-005-4961-3
   Goodfellow I., 2016, DEEP LEARNING VOL, V1
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Hadsell R, 2007, IASTED INT CONF ROBO, P457
   Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2015, C NEUR INF PROC SYST
   Hassibi B., 1992, P ADV NEUR INF PROC, V5, DOI DOI 10.5555/645753.668069
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Herbordt MC, 2008, COMPUT SCI ENG, V10, P35, DOI 10.1109/MCSE.2008.143
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Jain AK, 2015, ANN IEEE SYM FIELD P, P25, DOI 10.1109/FCCM.2015.15
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim Y, 2014, EMNLP
   Korekado K, 2005, 2005 SYMPOSIUM ON VLSI CIRCUITS, DIGEST OF TECHNICAL PAPERS, P220
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   LeCun Y., 1990, HANDWRITTEN DIGIT RE, V2, P396, DOI DOI 10.1111/DSU.12130
   LEE EA, 1987, P IEEE, V75, P1235, DOI 10.1109/PROC.1987.13876
   Li HH, 2016, FOOD ANAL METHOD, V9, P3015, DOI 10.1007/s12161-016-0475-9
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Liang Y, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/649057
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Ma Y., 2016, IEEE MTT S INT MICR, P1
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   MacQueen J., 1967, P 5 BERK S MATH STAT, P1
   McNelis PD, 2005, NEURAL NETWORKS FINA
   Mirowski PW, 2008, MACHINE LEARN SIGN P, P244, DOI 10.1109/MLSP.2008.4685487
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Montgomery PL., 1994, CWI Q, V7, P337
   Muller U., 2006, ADV NEURAL INFORM PR, P739
   Munshi A., 2009, 2009 IEEE HOT CHIPS, P1
   Nair V, 2010, INT C MACH LEARN HAI, V27, P807
   Nasse F, 2009, LECT NOTES COMPUT SC, V5702, P83, DOI 10.1007/978-3-642-03767-2_10
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Pouchet L., 2013, P ACMSIGDA INT S FIE, P29, DOI DOI 10.1145/2435264.2435273
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J., 2016, ARXIV160207360, P779
   Reeves C. R., 1995, ADV TOPICS COMPUTER
   Rere LMR, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/1537325
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Sato A, 1996, ADV NEUR IN, V8, P423
   Savich AW, 2007, IEEE T NEURAL NETWOR, V18, P240, DOI 10.1109/TNN.2006.883002
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sermanet P, 2009, J FIELD ROBOT, V26, P52, DOI 10.1002/rob.20270
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Simard PY, 2003, PROC INT CONF DOC, P958
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sze V, 2017, 2017 IEEE CUSTOM INT, P1
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C., 2017, P 31 AAAI C ART INT, V4, P12
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vanderbauwhede W., 2013, HIGH PERFORMANCE COM
   Vasudevan A, 2017, IEEE INT CONF ASAP, P19, DOI 10.1109/ASAP.2017.7995254
   Venieris S. I., 2017, P 27 INT C FIELD PRO, P1, DOI [10.23919/FPL.2017.8056828, DOI 10.1109/ICMTS.2017.7954259]
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Villasenor J, 1997, SCI AM, V276, P66, DOI 10.1038/scientificamerican0697-66
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Whaley R Clinton, 1998, P 1998 ACMIEEE C SUP, P38, DOI [10.5555/509058.509096, DOI 10.1109/SC.1998.10004]
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Xie LX, 2017, IEEE I CONF COMP VIS, P1388, DOI 10.1109/ICCV.2017.154
   Yazdanbakhsh A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P482, DOI 10.1145/2830772.2830810
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C., 2016, PROC IEEEACM INT C C, P1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang H, 2007, IEEE T CIRCUITS-II, V54, P200, DOI 10.1109/TCSII.2006.886898
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zisserman A., 2014, 14091556 ARXIV
   Zuo W, 2013, P ACMSIGDA INT S FIE, P9, DOI DOI 10.1145/2435264.2435271
NR 206
TC 206
Z9 211
U1 58
U2 315
PY 2019
VL 7
BP 7823
EP 7859
DI 10.1109/ACCESS.2018.2890150
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
HC Y
HP N
DA 2023-11-11
ER

PT J
AU Moon, GE
   Kwon, H
   Jeong, G
   Chatarasi, P
   Rajamanickam, S
   Krishna, T
AF Moon, Gordon Euhyun
   Kwon, Hyoukjun
   Jeong, Geonhwa
   Chatarasi, Prasanth
   Rajamanickam, Sivasankaran
   Krishna, Tushar
TI Evaluating Spatial Accelerator Architectures with Tiled Matrix-Matrix
   Multiplication
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Kernel; Analytical models; Runtime; Hardware; Shape; Parallel
   processing; Sparse matrices; Spatial accelerator; DNN accelerator;
   dataflow; GEMM mapping
ID HIGH-PERFORMANCE
AB There is a growing interest in custom spatial accelerators for machine learning applications. These accelerators employ a spatial array of processing elements (PEs) interacting via custom buffer hierarchies and networks-on-chip. The efficiency of these accelerators comes from employing optimized dataflow (i.e., spatial/temporal partitioning of data across the PEs and fine-grained scheduling) strategies to optimize data reuse. The focus of this work is to evaluate these accelerator architectures using a tiled general matrix-matrix multiplication (GEMM) kernel. To do so, we develop a framework that finds optimized mappings (dataflow and tile sizes) for a tiled GEMM for a given spatial accelerator and workload combination, leveraging an analytical cost model for runtime and energy. Our evaluations over five spatial accelerators demonstrate that the tiled GEMM mappings systematically generated by our framework achieve high performance on various GEMM workloads and accelerators.
C1 [Moon, Gordon Euhyun] Korea Aerosp Univ, Dept Software, Gyeonggi 10540, South Korea.
   [Kwon, Hyoukjun; Jeong, Geonhwa; Chatarasi, Prasanth] Georgia Inst Technol, Sch Comp Sci, Atlanta, GA 30332 USA.
   [Rajamanickam, Sivasankaran] Sandia Natl Labs, Ctr Comp Res, Albuquerque, NM 87123 USA.
   [Krishna, Tushar] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Moon, GE (corresponding author), Korea Aerosp Univ, Dept Software, Gyeonggi 10540, South Korea.
EM ehmoon@kau.ac.kr; hyoukjun@gatech.edu; geonhwa.jeong@gatech.edu;
   cprasanth@gatech.edu; srajama@sandia.gov; tushar@ece.gatech.edu
CR Abdelfattah A, 2016, LECT NOTES COMPUT SC, V9697, P21, DOI 10.1007/978-3-319-41321-1_2
   Bavier E., 1970, SCI PROGRAMMING-NETH, V20
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Davis TA, 2016, ACTA NUMER, V25, P383, DOI 10.1017/S0962492916000076
   Demmel J, 2005, P IEEE, V93, P293, DOI 10.1109/JPROC.2004.840848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Franchetti F, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P2530
   Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053
   Goto K, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1377603.1377607
   Guirado R, 2019, IEEE I C ELECT CIRC, P85, DOI [10.1109/icecs46596.2019.8964858, 10.1109/ICECS46596.2019.8964858]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard M., 2018, 2018 P 10 INT C COMP
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kågström B, 1998, ACM T MATH SOFTWARE, V24, P268, DOI 10.1145/292395.292412
   Kerr A., 2017, NVIDIA DEV BLOG
   Kim K, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126941
   Kwon H, 2017, 11 IEEE ACM INT S NE, V2017, P1, DOI [10.1145/3130218.3130230, DOI 10.1145/3130218.3130230]
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Li XH, 2019, PROCEEDINGS OF THE 24TH SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '19), P229, DOI 10.1145/3293883.3295734
   Louw T., USING GRAPHCORE IPU, P2021
   MAESTRO, 2020, OP SOURC INFR MOD DA
   Moon G. E., ARXIV210610499, V2021
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Pedram A, 2012, IEEE T COMPUT, V61, P1724, DOI 10.1109/TC.2012.132
   Pedram A, 2011, IEEE INT CONF ASAP, P35, DOI 10.1109/ASAP.2011.6043234
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Rocki K, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00062
   To T., 2018, NDDS NVIDIA DEEP LEA
   VanDeGeijn RA, 1997, CONCURRENCY-PRACT EX, V9, P255, DOI 10.1002/(SICI)1096-9128(199704)9:4<255::AID-CPE250>3.0.CO;2-2
   Whaley RC, 2001, PARALLEL COMPUT, V27, P3, DOI 10.1016/S0167-8191(00)00087-9
   Xilinx, ACC DNNS XIL ALV ACC
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhao ZY, 2019, INT SYM PERFORM ANAL, P282, DOI 10.1109/ISPASS.2019.00040
NR 40
TC 7
Z9 8
U1 2
U2 11
PD APR 1
PY 2022
VL 33
IS 4
BP 1002
EP 1014
DI 10.1109/TPDS.2021.3104240
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Arpaia, P
   Azzopardi, G
   Blanc, F
   Bregliozzi, G
   Buffat, X
   Coyle, L
   Fol, E
   Giordano, F
   Giovannozzi, M
   Pieloni, T
   Prevete, R
   Redaelli, S
   Salvachua, B
   Salvant, B
   Schenk, M
   Camillocci, MS
   Tomás, R
   Valentino, G
   Van der Veken, FF
   Wenninger, J
AF Arpaia, P.
   Azzopardi, G.
   Blanc, F.
   Bregliozzi, G.
   Buffat, X.
   Coyle, L.
   Fol, E.
   Giordano, F.
   Giovannozzi, M.
   Pieloni, T.
   Prevete, R.
   Redaelli, S.
   Salvachua, B.
   Salvant, B.
   Schenk, M.
   Camillocci, M. Solfaroli
   Tomas, R.
   Valentino, G.
   Van der Veken, F. F.
   Wenninger, J.
TI Machine learning for beam dynamics studies at the CERN Large Hadron
   Collider
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Machine Learning; Beam dynamics; LHC
ID LHC; SEARCH
AB Machine learning entails a broad range of techniques that have been widely used in Science and Engineering since decades. High-energy physics has also profiled from the power of these tools for advanced analysis of colliders data. It is only up until recently that Machine Learning has started to be applied successfully in the domain of Accelerator Physics, which is testified by intense efforts deployed in this domain by several laboratories worldwide. This is also the case of CERN, where recently focused efforts have been devoted to the application of Machine Learning techniques to beam dynamics studies at the Large Hadron Collider (LHC). This implies a wide spectrum of applications from beam measurements and machine performance optimisation to analysis of numerical data from tracking simulations of non-linear beam dynamics. In this paper, the LHC-related applications that are currently pursued are presented and discussed in detail, paying also attention to future developments.
C1 [Arpaia, P.; Giordano, F.; Prevete, R.] Univ Napoli Federico II, Dipartimento Ingn Elettr & Tecnol Informaz DIETI, I-80125 Naples, Italy.
   [Azzopardi, G.; Buffat, X.; Coyle, L.; Fol, E.; Giordano, F.; Giovannozzi, M.; Pieloni, T.; Redaelli, S.; Salvachua, B.; Salvant, B.; Camillocci, M. Solfaroli; Tomas, R.; Van der Veken, F. F.; Wenninger, J.] CERN, Beams Dept, Esplanade Particules 1, CH-1211 Geneva 23, Switzerland.
   [Blanc, F.; Coyle, L.; Pieloni, T.; Schenk, M.] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
   [Bregliozzi, G.] CERN, Technol Dept, Esplanade Particules 1, CH-1211 Geneva 23, Switzerland.
   [Fol, E.] Goethe Univ Frankfurt, Max von Laue Str 9, D-60438 Frankfurt, Germany.
   [Valentino, G.; Van der Veken, F. F.] Univ Malta, MSD-2080 Msida, Malta.
RP Giovannozzi, M (corresponding author), CERN, Beams Dept, Esplanade Particules 1, CH-1211 Geneva 23, Switzerland.
EM massimo.giovannozzi@cern.ch
CR Abada A, 2019, EUR PHYS J-SPEC TOP, V228, P755, DOI 10.1140/epjst/e2019-900087-0
   Aiba M, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.081002
   [Anonymous], 2013, INT J DATABASE MANAG
   [Anonymous], 2011, P 2011 SIAM INT C DA, DOI DOI 10.1137/1.9781611972818.60
   Assmann R. W., 2004, P 9 EUR PART ACC C E, P1825
   Azzopardi G, 2019, P 17 INT C ACC LARG
   Azzopardi G., 2019, P 10 INT PART ACC C, P1208
   Azzopardi G., 2017, P 16 INT C ACC LARG
   Azzopardi G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.093001
   Azzopardi G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.083002
   Azzopardi G, 2019, NUCL INSTRUM METH A, V934, P10, DOI 10.1016/j.nima.2019.04.057
   Bazzani A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.104003
   Bellman R., 1959, P IRE, V4, P1, DOI 10.1109/TAC.1959.1104847
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bishop C. M., 2006, MACH LEARN
   Bonaccorso G., 2019, HANDS ON UNSUPERVISE
   Bonetta R, 2020, PROTEINS, V88, P397, DOI 10.1002/prot.25832
   Bozoki E., 1994, P 4 EUR PART ACC C E, P1589
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Bruce R, 2017, NUCL INSTRUM METH A, V848, P19, DOI 10.1016/j.nima.2016.12.039
   Bruce R, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.061001
   Bruce R, 2014, PHYS REV SPEC TOP-AC, V17, DOI 10.1103/PhysRevSTAB.17.081004
   Bruning OS., 2004, LHC DESIGN REPORT, DOI DOI 10.5170/CERN-2004-003-V-1
   Carver L., 2017, ACC2017117 CERN
   Chalup SK, 2007, IEEE T SYST MAN CY C, V37, P297, DOI 10.1109/TSMCC.2006.886964
   Coyle L., 2018, THESIS
   Coyle L.T.D., 2019, MD 4510 WORKING POIN
   Dal Pozzolo A, 2018, IEEE T NEUR NET LEAR, V29, P3784, DOI 10.1109/TNNLS.2017.2736643
   Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784
   Edelen A., 2018, ARXIV181103172
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507
   Fartoukh S, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.111002
   Fol E., 2018, P 9 INT PART ACC C I, P1967, DOI [10.18429/JACoW-IPAC2018-WEPAF062, DOI 10.18429/JACOW-IPAC2018-WEPAF062.]
   Fol E., 2019, P 39 INT FREE EL LAS
   Fol E., 2019, P 10 INT PART ACC C, P2668
   Fol E., 2017, THESIS
   Fol E., 2020, ISOLATION FOREST ALG
   Fol E., 2020, REGRESSION MODELS MA
   Fol E., 2019, P 10 INT PARTICLE AC, P3990, DOI DOI 10.18429/JACOW-IPAC2019-THPRB077
   Giovannozzi M, 2019, NUCL INSTRUM METH A, V927, P471, DOI 10.1016/j.nima.2019.01.072
   Giovannozzi M, 2018, NUCL INSTRUM METH A, V908, P1, DOI 10.1016/j.nima.2018.08.019
   Giovannozzi M, 2018, NUCL INSTRUM METH A, V905, P171, DOI 10.1016/j.nima.2018.07.063
   Giusti R, 2013, 2013 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P82, DOI 10.1109/BRACIS.2013.22
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Grobner O., 1999, TECH REP
   Hussein S, 2019, IEEE T MED IMAGING, V38, P1777, DOI 10.1109/TMI.2019.2894349
   Jimenez JM, 2009, VACUUM, V84, P2, DOI 10.1016/j.vacuum.2009.05.015
   Ke G., 2017, ADV NEURAL INFORM PR, V30, P3146, DOI DOI 10.5555/3294996.3295074
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   LaValle SM, 2004, INT J ROBOT RES, V23, P673, DOI 10.1177/0278364904045481
   LeCun Y., 1995, HDB BRAIN THEORY NEU, P276, DOI 10.5555/303568.303704
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Li YJ, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.054601
   Liu F, 2008, ACTA HORTIC, V792, P413, DOI 10.17660/ActaHortic.2008.792.48
   Meier E., 2012, P 3 INT PART ACC C I, P2837
   Minh DL, 2018, IEEE ACCESS, V6, P55392, DOI 10.1109/ACCESS.2018.2868970
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Mullner D., 2011, MODERN HIERARCHICAL, DOI DOI 10.1109/LSP.2012.2188026
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Neyman J., 1992, BREAKTHROUGHS STAT M, P123, DOI DOI 10.1007/978-1-4612-4380-9_12
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Persson T, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.061002
   Reeves SJ, 1999, IEEE T SIGNAL PROCES, V47, P123, DOI 10.1109/78.738245
   Rifkin R., 2007, TECH REP
   Robbins H., 1987, J MULTIVARIATE ANAL, V23, P77
   Rubinstein R, 2008, CS TECHNION
   Rumolo G, 2003, PHYS REV SPEC TOP-AC, V6, DOI 10.1103/PhysRevSTAB.6.081002
   Saccomanno A, 2012, IEEE SENS J, V12, P3392, DOI 10.1109/JSEN.2012.2205989
   Salvant B., 2013, P 4 INT PART ACC C I, P1646
   Senin P., 2008, TECH REP
   Serrano J., 2010, TECH REP
   Sokolov A.A., 1966, SINKHROTRON RAD
   Su J, 2018, IEEE T VEH TECHNOL, V67, P5650, DOI 10.1109/TVT.2018.2819806
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Todesco E, 1996, PHYS REV E, V53, P4067, DOI 10.1103/PhysRevE.53.4067
   Tomás R, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.091001
   Tomás R, 2010, PHYS REV SPEC TOP-AC, V13, DOI 10.1103/PhysRevSTAB.13.121004
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   Valentino G, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.051002
   Van der Veken F.F., 2018, P 61 ICFA ADV BEAM D, P260
   Vega L, 2017, J PHYS CONF SER, V874, DOI 10.1088/1742-6596/874/1/012100
   Vert J. P., 2004, KERNEL METHODS COMPU, DOI [10.7551/mitpress/4057.003.0004, DOI 10.7551/MITPRESS/4057.003.0004]
   Vilsmeier D, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.052801
   Wan JY, 2019, NUCL INSTRUM METH A, V946, DOI 10.1016/j.nima.2019.162683
   Wenninger J., 2018, P PROSP CHARG HIGGS
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xu XY, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.032805
   Zannini C., 2014, 5 INT PART ACC C DRE, P1711
NR 92
TC 18
Z9 19
U1 0
U2 7
PD JAN 1
PY 2021
VL 985
AR 164651
DI 10.1016/j.nima.2020.164652
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Angioli, M
   Barbirotta, M
   Mastrandrea, A
   Jamili, S
   Olivieri, M
AF Angioli, Marco
   Barbirotta, Marcello
   Mastrandrea, Antonio
   Jamili, Saeid
   Olivieri, Mauro
GP IEEE
TI Automatic Hardware Accelerators Reconfiguration through LinearUCB
   Algorithms on a RISC-V Processor
SO 2023 18TH CONFERENCE ON PH.D RESEARCH IN MICROELECTRONICS AND
   ELECTRONICS, PRIME
DT Proceedings Paper
CT 18th International Conference on Ph.D Research in Microelectronics and
   Electronics (PRIME)
CY JUN 18-21, 2023
CL Valencia, SPAIN
DE Reconfigurable Hardware Accelerators; Run-time Reconfiguration;
   Reinforcement Learning; LinearUCB; Contextual Bandits
AB Reconfigurable processors are hardware architectures that allow for the dynamic configuration of processing resources to optimize performance and power consumption, using partial reconfiguration to modify a portion of the design or update it without affecting the entire system. In this work, we present an automatic reconfiguration technique that leverages machine learning (ML) algorithms to automatically select the optimal configuration of a general-purpose hardware accelerator according to the workload and reconfigure the architecture at run-time. The problem is formulated as a Contextual Bandit (CB) case using the Linear Upper Confidence Bound (LinearUCB) algorithms and verified using the RISC-V Klessydra family cores as a case of study.
C1 [Angioli, Marco; Barbirotta, Marcello; Mastrandrea, Antonio; Jamili, Saeid; Olivieri, Mauro] Sapienza Univ Rome, Via Eudossiana 18, I-00184 Rome, Italy.
RP Angioli, M (corresponding author), Sapienza Univ Rome, Via Eudossiana 18, I-00184 Rome, Italy.
EM marco.angioli@uniroma1.it
CR [Anonymous], 2017, 2017 IEEEACM INT S L
   Barbirotta Marcello, 2022, 2022 17th Conference on Ph.D Research in Microelectronics and Electronics (PRIME)., P237, DOI 10.1109/PRIME55000.2022.9816771
   Barbirotta M, 2023, J LOW POWER ELECT AP, V13, DOI 10.3390/jlpea13010002
   Barbirotta M, 2022, IEEE ACCESS, V10, P126074, DOI 10.1109/ACCESS.2022.3225975
   Lopes ASB, 2020, 33RD SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN (SBCCI 2020), DOI 10.1109/sbcci50935.2020.9189899
   Cheikh A., 2019, P APPL ELECT PERVADI, P529, DOI [10.1007/978-3-030-37277-4_62, DOI 10.1007/978-3-030-37277-4_62]
   Cheikh A, 2021, IEEE MICRO, V41, P64, DOI 10.1109/MM.2021.3050962
   Li L., 2010, P 19 INT C WORLD WID, P661, DOI DOI 10.1145/1772690.1772758
   Li Lihong, 2011, P 4 ACM INT C WEB SE, P297, DOI DOI 10.1145/1935826.1935878
   Olivieri M, 2017, 2017 FIRST NEW GENERATION OF CAS (NGCAS), P45, DOI 10.1109/NGCAS.2017.61
   Sordillo S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040518
   Wang C, 2017, Arxiv, DOI arXiv:1712.04771
   Wu N., 2021, P GREAT LAK S VLSI J, P39
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 169
EP 172
DI 10.1109/PRIME58259.2023.10161944
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Chang, KC
   Fan, CP
AF Chang, Keng-Chia
   Fan, Chih-Peng
GP IEEE
TI Cost-Efficient Adaboost-based Face Detection with FPGA Hardware
   Accelerator
SO 2019 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - TAIWAN
   (ICCE-TW)
SE IEEE International Conference on Consumer Electronics-Taiwan
DT Proceedings Paper
CT IEEE International Conference on Consumer Electronics-Taiwan (IEEE
   ICCE-TW)
CY MAY 20-22, 2019
CL Ilan, TAIWAN
DE Adaboost design; machine learning; hardware accelerator; face detection
AB In this paper, a cost-efficient Adaboost-based hardware accelerator design is developed for face detection. For the realization, a lot of operations and fast calculations of the rectangular Haar features of partial image regions are required. To speed up the processing time for integral image and face detection functions, the hardware accelerator implementation is an important issue for real-time application. In experimental results, by Xilinx XC7a200t device at 205MHz operational frequency, the applied integral image accelerator performs up to 1161 frames/sec with the image size of 240x360 pixels. When the input ROI sizes are 80x80 and 64x64 pixels, the proposed Adaboost-based classifier operates up to 574 and 821 face ROIs/sec, respectively.
C1 [Chang, Keng-Chia; Fan, Chih-Peng] Natl Chung Hsing Univ, Dept Elect Engn, Taichung, Taiwan.
RP Chang, KC (corresponding author), Natl Chung Hsing Univ, Dept Elect Engn, Taichung, Taiwan.
CR [Anonymous], HAAR FEATURE BASED C
   Irgens P, 2017, HARDWAREX, V1, P68, DOI 10.1016/j.ohx.2017.03.002
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Ouyang P, 2015, IEEE T CIRCUITS-II, V62, P75, DOI 10.1109/TCSII.2014.2362651
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yin SY, 2017, IEEE SYST J, V11, P260, DOI 10.1109/JSYST.2015.2418680
NR 6
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1109/icce-tw46550.2019.8991862
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Streeter, MJV
   Colgan, C
   Cobo, CC
   Arran, C
   Los, EE
   Watt, R
   Bourgeois, N
   Calvin, L
   Carderelli, J
   Cavanagh, N
   Dann, SJD
   Fitzgarrald, R
   Gerstmayr, E
   Joglekar, AS
   Kettle, B
   Mckenna, P
   Murphy, CD
   Najmudin, Z
   Parsons, P
   Qian, Q
   Rajeev, PP
   Ridgers, CP
   Symes, DR
   Thomas, AGR
   Sarri, G
   Mangles, SPD
AF Streeter, M. J. V.
   Colgan, C.
   Cobo, C. C.
   Arran, C.
   Los, E. E.
   Watt, R.
   Bourgeois, N.
   Calvin, L.
   Carderelli, J.
   Cavanagh, N.
   Dann, S. J. D.
   Fitzgarrald, R.
   Gerstmayr, E.
   Joglekar, A. S.
   Kettle, B.
   Mckenna, P.
   Murphy, C. D.
   Najmudin, Z.
   Parsons, P.
   Qian, Q.
   Rajeev, P. P.
   Ridgers, C. P.
   Symes, D. R.
   Thomas, A. G. R.
   Sarri, G.
   Mangles, S. P. D.
TI Laser wakefield accelerator modelling with variational neural networks
SO HIGH POWER LASER SCIENCE AND ENGINEERING
DT Article
DE laser plasma interactions; particle acceleration; neural networks;
   machine learning
ID RADIATION REACTION; ELECTRON-BEAMS; OPTIMIZATION; FEMTOSECOND
AB A machine learning model was created to predict the electron spectrum generated by a GeV-class laser wakefield accelerator. The model was constructed from variational convolutional neural networks, which mapped the results of secondary laser and plasma diagnostics to the generated electron spectrum. An ensemble of trained networks was used to predict the electron spectrum and to provide an estimation of the uncertainty of that prediction. It is anticipated that this approach will be useful for inferring the electron spectrum prior to undergoing any process that can alter or destroy the beam. In addition, the model provides insight into the scaling of electron beam properties due to stochastic fluctuations in the laser energy and plasma electron density.
C1 [Streeter, M. J. V.; Calvin, L.; Cavanagh, N.; Sarri, G.] Queens Univ Belfast, Sch Math & Phys, Belfast, North Ireland.
   [Colgan, C.; Los, E. E.; Watt, R.; Gerstmayr, E.; Kettle, B.; Najmudin, Z.; Mangles, S. P. D.] Imperial Coll London, John Adams Inst Accelerator Sci, London, England.
   [Cobo, C. C.; Arran, C.; Murphy, C. D.; Ridgers, C. P.] Univ York, Sch Phys Engn & Technol, York Plasma Inst, York, England.
   [Bourgeois, N.; Dann, S. J. D.; Parsons, P.; Rajeev, P. P.; Symes, D. R.] STFC Rutherford Appleton Lab, Cent Laser Facil, Didcot, England.
   [Carderelli, J.; Fitzgarrald, R.; Joglekar, A. S.; Qian, Q.; Thomas, A. G. R.] Univ Michigan, Gerard Mourou Ctr Ultrafast Opt Sci, Ann Arbor, MI USA.
   [Joglekar, A. S.] Ergodic LLC, San Francisco, CA USA.
   [Mckenna, P.] Univ Strathclyde, SUPA, Dept Phys, Glasgow, Scotland.
   [Streeter, M. J. V.] Queens Univ Belfast, Sch Math & Phys, Belfast BT7 1NN, North Ireland.
RP Streeter, MJV (corresponding author), Queens Univ Belfast, Sch Math & Phys, Belfast BT7 1NN, North Ireland.
EM m.streeter@qub.ac.uk
CR Albert F, 2016, PLASMA PHYS CONTR F, V58, DOI 10.1088/0741-3335/58/10/103001
   Arran C, 2019, PLASMA PHYS CONTR F, V61, DOI 10.1088/1361-6587/ab20f6
   Baird CD, 2019, NEW J PHYS, V21, DOI 10.1088/1367-2630/ab1baf
   Barnsley F., 2016, 11 NEW OPPORTUNITIES, P23
   Blackburn TG, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.015001
   Bloom MS, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.061301
   Chen M, 2012, PHYS PLASMAS, V19, DOI 10.1063/1.3689922
   Clayton CE, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.105003
   Cole JM, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.011020
   Cros B., ARXIV
   Dann SJD, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.041303
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Gonsalves AJ, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.084801
   Hafz NAM, 2008, NAT PHOTONICS, V2, P571, DOI 10.1038/nphoton.2008.155
   Hanuka A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82473-0
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   Jalas S, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.104801
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kirchen M, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.174801
   Kneip S, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.035002
   Kristiadi A, 2020, PR MACH LEARN RES, V119
   Leemans WP, 2006, NAT PHYS, V2, P696, DOI 10.1038/nphys418
   Leemans WP, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.245002
   Lin JP, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0047940
   Lu W, 2007, PHYS REV SPEC TOP-AC, V10, DOI 10.1103/PhysRevSTAB.10.061301
   Maier AR, 2012, PHYS REV X, V2, DOI 10.1103/PhysRevX.2.031019
   Maier AR, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.031039
   Matsuoka T, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.034801
   McGuffey C, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.025004
   Osterhoff J, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.085002
   P. Burgess Christopher, 2018, Arxiv, DOI [arXiv:1804.03599, DOI 10.48550/ARXIV.1804.03599]
   Kingma DP, 2014, Arxiv, DOI [arXiv:1312.6114, DOI 10.48550/ARXIV.1312.6114]
   Pak A, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.025003
   Poder K, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.031004
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Ren X, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.040701
   Rowlands-Rees TP, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.105005
   Sävert A, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.055002
   Samarin GM, 2018, J MOD OPTIC, V65, P1362, DOI 10.1080/09500340.2017.1353655
   Sarri G, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.224801
   Sarri G, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.255002
   Schlenvoigt HP, 2008, NAT PHYS, V4, P130, DOI 10.1038/nphys811
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Streeter MJV, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.254801
   Thomas AGR, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.054802
   Thomas AGR, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.095004
   Thomas AGR, 2012, PHYS REV X, V2, DOI 10.1103/PhysRevX.2.041004
   Wang JG, 2018, PLASMA PHYS CONTR F, V60, DOI 10.1088/1361-6587/aaa4dc
   Wang WT, 2021, NATURE, V595, P516, DOI 10.1038/s41586-021-03678-x
   Wang XM, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2988
   Xia CQ, 2011, PHYS PLASMAS, V18, DOI 10.1063/1.3656958
   Xu B, 2015, Arxiv, DOI [arXiv:1505.00853, DOI 10.48550/ARXIV.1505.00853]
   Zhang CJ, 2018, PLASMA PHYS CONTR F, V60, DOI 10.1088/1361-6587/aaabfd
NR 53
TC 1
Z9 1
U1 9
U2 10
PD JAN 6
PY 2023
VL 11
AR e9
DI 10.1017/hpl.2022.47
WC Optics
DA 2023-11-11
ER

PT C
AU Struharik, R
   Vukobratovic, B
   Erdeljan, A
   Rakanovic, D
AF Struharik, Rastislav
   Vukobratovic, Bogdan
   Erdeljan, Andrea
   Rakanovic, Damjan
BE Novotny, M
   Konofaos, N
   Skavhaug, A
TI CoNNA - Compressed CNN Hardware Accelerator
SO 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018)
DT Proceedings Paper
CT 21st Euromicro Conference on Digital System Design (DSD)
CY AUG 29-31, 2018
CL Prague, CZECH REPUBLIC
DE machine learning; convolutional neural network; compressed CNN; hardware
   acceleration; FPGA
AB In this paper we propose a novel Convolutional Neural Network hardware accelerator, called CoNNA, capable of accelerating pruned, quantized, CNNs. In contrast to most existing solutions, CoNNA offers a complete solution to the full, compressed CNN acceleration, being able to accelerate all layer types commonly found in contemporary CNNs. CoNNA is designed as a coarse-grained reconfigurable architecture, which uses rapid, dynamic reconfiguration during CNN layer processing. Furthermore, by being able to directly process compressed feature and kernel maps, CoNNA is able to achieve higher CNN processing efficiency than some of the previously proposed solutions. Results of the experiments indicate that CoNNA architecture is up to 14.10 times faster than previously proposed MIT's Eyeriss CNN accelerator, up to 6.05 times faster than NullHop CNN accelerator, and up to 4.91 times faster than NVIDIA's Deep Learning Accelerator (NVDLA), while using identical number of computing units and operating at the same clock frequency.
C1 [Struharik, Rastislav; Erdeljan, Andrea; Rakanovic, Damjan] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradov 6, Novi Sad, Serbia.
   [Vukobratovic, Bogdan] Kortiq GmbH, Gebruder Eicher Ring 45, Forstern, Germany.
RP Struharik, R (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradov 6, Novi Sad, Serbia.
EM rasti@uns.ac.rs; bogdan.vukobratovic@kortiq.com;
   andrea.erdeljan@uns.ac.rs; rdamjan@uns.ac.rs
CR Aimar A., 2017, ARXIV170601406
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Erdeljan A., 2017, 25 TEL FOR TELFOR 20
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2016, P IEEE C COMPUTER VI
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Liu ZC, 2017, BMC MED IMAGING, V17, DOI 10.1186/s12880-017-0183-y
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 24
TC 11
Z9 11
U1 0
U2 4
PY 2018
BP 365
EP 372
DI 10.1109/DSD.2018.00070
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Jiang, ZW
   Yin, SH
   Seo, JS
   Seok, M
AF Jiang, Zhewei
   Yin, Shihui
   Seo, Jae-sun
   Seok, Mingoo
GP Assoc Comp Machinery
TI XNOR-SRAM: In-Bitcell Computing SRAM Macro based on Resistive Computing
   Mechanism
SO GLSVLSI '19 - PROCEEDINGS OF THE 2019 ON GREAT LAKES SYMPOSIUM ON VLSI
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT 29th Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 09-11, 2019
CL Tysons Corner, VA
DE In-memory computing; near-memory computing; machine learning
   accelerator; mixed-signal processing
AB We present an in-memory computing SRAM macro for binary neural networks. The memory macro computes XNOR-and-accumulate for binary/ternary deep convolutional neural networks on the bitline without row-by-row data access. It achieves 33X better energy and 300X better energy-delay-product than digital ASIC and achieves high accuracy in machine learning tasks (98.3% for MNIST and 85.7% for CIFAR-10 datasets).
C1 [Jiang, Zhewei; Seok, Mingoo] Columbia Univ, Elect Engn, New York, NY 10027 USA.
   [Yin, Shihui; Seo, Jae-sun] Arizona State Univ, Sch ECEE, Tempe, AZ USA.
RP Jiang, ZW (corresponding author), Columbia Univ, Elect Engn, New York, NY 10027 USA.
EM zj2139@columbia.edu; syin11@asu.edu; jseo28@asu.edu; ms4415@columbia.edu
CR Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Borkar S, 2005, IEEE MICRO, V25, P10, DOI 10.1109/MM.2005.110
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhao Y, 2017, ADVANCES IN ENERGY AND ENVIRONMENT RESEARCH, P345
NR 11
TC 8
Z9 8
U1 0
U2 11
PY 2019
BP 417
EP 422
DI 10.1145/3299874.3319458
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Beerel, PA
   Pedram, M
AF Beerel, Peter A.
   Pedram, Massoud
GP IEEE
TI Opportunities for Machine Learning in Electronic Design Automation
SO 2018 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 27-30, 2018
CL Florence, ITALY
ID POWER MANAGEMENT; CIRCUITS; SYSTEM; BLADE
AB The rise of machine learning (ML) has introduced many opportunities for computer-aided-design, VLSI design, and their intersection. Related to computer-aided design, we review several classical CAD algorithms which can benefit from ML, outline the key challenges, and discuss promising approaches. In particular, because some of the existing ML accelerators have used asynchronous design, we review the state-of-the-art in asynchronous CAD support, and identify opportunities for ML within these flows.
C1 [Beerel, Peter A.; Pedram, Massoud] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
RP Beerel, PA (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM pabeerel@usc.edu; pedram@usc.edu
CR Akopyan FA, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'16), P59, DOI 10.1145/2872334.2878629
   Beerel PA, 2011, IEEE DES TEST COMPUT, V28, P36, DOI 10.1109/MDT.2011.114
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cai R., 2017, P INT C COMP DES OCT
   Cai R., 2018, P 23 ACM INT C ARCH
   Cardoso JF, 1996, IEEE T SIGNAL PROCES, V44, P3017, DOI 10.1109/78.553476
   Chan WTJ, 2017, ISPD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P15, DOI 10.1145/3036669.3036681
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cortadella J, 2006, IEEE T COMPUT AID D, V25, P1904, DOI 10.1109/TCAD.2005.860958
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Davies Mike, 2014, 2014 20th IEEE International Symposium on Asynchronous Circuits and Systems (ASYNC), P103, DOI 10.1109/ASYNC.2014.22
   Dey S., 2017, ARXIV171102131
   Dey S, 2017, CONF REC ASILOMAR C, P1979, DOI 10.1109/ACSSC.2017.8335713
   Dey S, 2017, LECT NOTES COMPUT SC, V10613, P273, DOI 10.1007/978-3-319-68600-4_32
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hand D, 2015, INT SYMP ASYNCHRON C, P61, DOI 10.1109/ASYNC.2015.18
   Hand D, 2015, INT SYMP ASYNCHRON C, P21, DOI 10.1109/ASYNC.2015.13
   Joachims T., 1998, P 10 EUR C MACH LEAR
   Lin X, 2014, ICCAD-IEEE ACM INT, P32
   Lin X, 2016, INT CONF CLOUD ENG, P135, DOI 10.1109/IC2E.2016.33
   Mayberry M., 2017, INTELS NEW SELF LEAR
   Najibi M, 2013, ICCAD-IEEE ACM INT, P219, DOI 10.1109/ICCAD.2013.6691122
   Najibi M, 2013, INT SYMP ASYNCHRON C, P75, DOI 10.1109/ASYNC.2013.30
   Nazemi M., 2017, P 28 ANN IEEE INT C
   Panda P., 2017, LEARNING RECOGNIZE A
   Reese RB, 2012, INT SYMP ASYNCHRON C, P65, DOI 10.1109/ASYNC.2012.14
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shin Y, 2011, IEEE DES TEST COMPUT, V28, P50, DOI 10.1109/MDT.2011.24
   Snoek J., 2012, PROC INT C NEURAL IN, V25, P2951
   Snoek J, 2015, PR MACH LEARN RES, V37, P2171
   SUTHERLAND IE, 1989, COMMUN ACM, V32, P720, DOI 10.1145/63526.63532
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Triki M, 2015, INTEGRATION, V48, P10, DOI 10.1016/j.vlsi.2014.06.001
   Wang HT, 2017, MATH PROBL ENG, V2017, P1, DOI 10.1155/2017/3847049
   Wang YZ, 2016, IEEE T COMPUT, V65, P3713, DOI 10.1109/TC.2016.2543219
   Wang YZ, 2011, DES AUT CON, P41
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wu G, 2014, ICCAD-IEEE ACM INT, P641, DOI 10.1109/ICCAD.2014.7001420
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou X., 2016, ABS160406154 CORR
   Ziegler MM, 2016, DES AUT TEST EUROPE, P1148
NR 46
TC 19
Z9 19
U1 0
U2 4
PY 2018
DI 10.1109/ISCAS.2018.8351731
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Tennant, C
   Freeman, B
   Kazimi, R
   Moser, D
   Abell, D
   Edelen, J
   Einstein-Curtis, J
AF Tennant, Chris
   Freeman, Brian
   Kazimi, Reza
   Moser, Daniel
   Abell, Dan
   Edelen, Jonathan
   Einstein-Curtis, Joshua
TI A smart alarm for particle accelerator beamline operations
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
DT Article
DE particle accelerator; machine learning; operations; alarm system;
   anomaly detection
AB We present the initial results of a proof-of-concept 'smart alarm' for the Continuous Electron Beam Accelerator Facility injector beamline at Jefferson Lab. To minimize machine downtime and improve operational efficiency, an autonomous alarm system able to identify and diagnose unusual machine states is needed. Our approach leverages a trained neural network capable of alerting operators (a) when an anomalous condition exists in the beamline and (b) identifying the element setting that is the root cause. The tool is based on an inverse model that maps beamline readings (diagnostic readbacks) to settings (beamline attributes operators can modify). The model takes as input readings from the machine and computes machine settings which are compared to control setpoints. Instances where predictions differ from setpoints by a user-defined threshold are flagged as anomalous. Given data corresponding to 354 anomalous injector configurations, the model can narrow the root cause of an anomalous condition to three potential candidates with 94.6% accuracy. Furthermore, compared to the current method of identifying anomalous conditions which raises an alarm when machine parameters drift outside their normal tolerances, the data-driven model can identify 83% more anomalous conditions.
C1 [Tennant, Chris; Freeman, Brian; Kazimi, Reza; Moser, Daniel] Jefferson Lab, 12000 Jefferson Ave, Newport News, VA 23606 USA.
   [Abell, Dan; Edelen, Jonathan; Einstein-Curtis, Joshua] RadiaSoft LLC, 1790 38th St,Suite 306, Boulder, CO 80301 USA.
RP Tennant, C (corresponding author), Jefferson Lab, 12000 Jefferson Ave, Newport News, VA 23606 USA.
EM tennant@jlab.org
CR Blokland W, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.122802
   Coyle L., 2021, PROC 12 INT PARTICLE, P4318, DOI [10.18429/JACoW-IPAC2021-THPAB260, DOI 10.18429/JACOW-IPAC2021-THPAB260]
   Epics Development Team, 2013, EPICS EXP PHYS IND C
   Fol E, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.102805
   Grünhagen A, 2021, ASIAN TEST SYMPOSIUM, P61, DOI 10.1109/ATS52891.2021.00023
   Hinton GE., 2008, JMLR, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Humble R, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.122804
   Isermann R., 2006, FAULT DIAGNOSIS SYST
   Nawaz A., 2018, PROC 9 INT PARTICLE, P2502, DOI [10.18429/JACoW-IPAC2018-WEPMF058, DOI 10.18429/JACOW-IPAC2018-WEPMF058]
   Obermair C, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.104601
   Piekarski M., 2019, PROC 17 INT C ACCELE, P1379, DOI [10.18429/JACoW-ICALEPCS2019-WEPHA121, DOI 10.18429/JACOW-ICALEPCS2019-WEPHA121]
   Radaideh MI, 2022, DATA BRIEF, V43, DOI 10.1016/j.dib.2022.108473
   Keskar NS, 2017, Arxiv, DOI arXiv:1712.07628
   Slominski C., 2009, PROC 12 INT C ACCELE, P447
   Tennant C., 2023, SAVED INVERSE MODEL
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Tilaro F, 2018, 16 INT C ACCELERATOR, DOI [10.18429/JACoW-ICALEPCS2017-TUCPA04, DOI 10.18429/JACOW-ICALEPCS2017-TUCPA04]
   Valentino G, 2017, J PHYS CONF SER, V874, DOI 10.1088/1742-6596/874/1/012002
   Webb GI, 2016, DATA MIN KNOWL DISC, V30, P964, DOI 10.1007/s10618-015-0448-4
   Webb Geoffrey I, 2017, ARXIV
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
NR 21
TC 0
Z9 0
U1 4
U2 4
PD MAR 1
PY 2023
VL 4
IS 1
AR 015021
DI 10.1088/2632-2153/acb98d
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Chen, JC
   Lange, T
   Andjelkovic, M
   Simevski, A
   Lu, L
   Krstic, M
AF Chen, Junchao
   Lange, Thomas
   Andjelkovic, Marko
   Simevski, Aleksandar
   Lu, Li
   Krstic, Milos
TI Solar Particle Event and Single Event Upset Prediction from SRAM-Based
   Monitor and Supervised Machine Learning
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Machine learning; Single event upsets; Random access memory; Monitoring;
   Machine learning algorithms; Predictive models; Space missions; Solar
   particle event; single event upset; machine learning; online learning;
   hardware accelerator; reliability; self-adaptive multiprocessing system
ID RADIATION; SPACE
AB The intensity of cosmic radiation may differ over five orders of magnitude within a few hours or days during the Solar Particle Events (SPEs), thus increasing for several orders of magnitude the probability of Single Event Upsets (SEUs) in space-borne electronic systems. Therefore, it is vital to enable the early detection of the SEU rate changes in order to ensure timely activation of dynamic radiation hardening measures. In this paper, an embedded approach for the prediction of SPEs and SRAM SEU rate is presented. The proposed solution combines the real-time SRAM-based SEU monitor, the offline-trained machine learning model and online learning algorithm for the prediction. With respect to the state-of-the-art, our solution brings the following benefits: (1) Use of existing on-chip data storage SRAM as a particle detector, thus minimizing the hardware and power overhead, (2) Prediction of SRAM SEU rate one hour in advance, with the fine-grained hourly tracking of SEU variations during SPEs as well as under normal conditions, (3) Online optimization of the prediction model for enhancing the prediction accuracy during run-time, (4) Negligible cost of hardware accelerator design for the implementation of selected machine learning model and online learning algorithm. The proposed design is intended for a highly dependable and self-adaptive multiprocessing system employed in space applications, allowing to trigger the radiation mitigation mechanisms before the onset of high radiation levels.
C1 [Chen, Junchao; Andjelkovic, Marko; Simevski, Aleksandar; Lu, Li; Krstic, Milos] IHP Leibniz Inst Innovat Mikroelekt, D-15236 Frankfurt, Germany.
   [Lange, Thomas] iROC, F-38000 Grenoble, France.
   [Lange, Thomas] Politecn Torino, I-10129 Turin, Italy.
   [Krstic, Milos] Univ Potsdam, D-14469 Potsdam, Germany.
RP Chen, JC (corresponding author), IHP Leibniz Inst Innovat Mikroelekt, D-15236 Frankfurt, Germany.
EM chen@ihp-microelectronics.com
CR Andjelkovic M., 2020, PROC IEEE INT C ELEC, P1
   [Anonymous], NATL OCEANIC ATMOSPH
   [Anonymous], CREME96 TOOL
   [Anonymous], GEOSTATIONARY OPERAT
   [Anonymous], 2005, FUNCTIONAL SAFETY EL
   [Anonymous], ADV COMPOSITION EXPL
   Bagatin M, 2020, IEEE T NUCL SCI, V67, P154, DOI 10.1109/TNS.2019.2955776
   Bain H. M, 2018, PROC SOARS, DOI [10.5065/kzsz-vf38, DOI 10.5065/KZSZ-VF38]
   Barth JL, 2003, IEEE T NUCL SCI, V50, P466, DOI 10.1109/TNS.2003.813131
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Camporeale E, 2019, SPACE WEATHER, V17, P1166, DOI 10.1029/2018SW002061
   Chen J, 2020, INT SYM DEFEC FAU TO, DOI 10.1109/dft50435.2020.9250856
   Chen J, 2020, MICROELECTRON RELIAB, V114, DOI 10.1016/j.microrel.2020.113799
   Chen JC, 2019, 2019 22ND EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P514, DOI 10.1109/DSD.2019.00080
   Chollet F., 2015, KERAS, P33
   Community coordinated modeling center, 2016, CORONAL MASS EJECTIO
   Cretolle J., 2001, P 6 EUR C RAD EFF CO, P37, DOI DOI 10.1109/RADECS.2001.1159256
   Cui QM, 2019, IEEE COMMUN MAG, V57, P63, DOI 10.1109/MCOM.2019.1800644
   da Rosa FR, 2019, IEEE T CIRCUITS-I, V66, P2151, DOI 10.1109/TCSI.2019.2906155
   Dodd PE, 2003, IEEE T NUCL SCI, V50, P583, DOI 10.1109/TNS.2003.813129
   Engell AJ, 2017, SPACE WEATHER, V15, P1321, DOI 10.1002/2017SW001660
   Glein R, 2016, 2016 16TH EUROPEAN CONFERENCE ON RADIATION AND ITS EFFECTS ON COMPONENTS AND SYSTEMS (RADECS)
   Glein R, 2017, NASA ESA CONF, P1, DOI 10.1109/AHS.2017.8046352
   Glein R, 2014, ANN IEEE SYM FIELD P, P251, DOI 10.1109/FCCM.2014.79
   Gupta V, 2017, THESIS U MONTPELLIER
   Hansen DL, 2007, IEEE T NUCL SCI, V54, P2525, DOI 10.1109/TNS.2007.908787
   Hirokawa S., 2016, P 16 EUR C RAD EFF C, P1, DOI DOI 10.1109/RADECS.2016.8093181
   Hoyos SE, 2004, IEEE T NUCL SCI, V51, P2927, DOI 10.1109/TNS.2004.835072
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lange T, 2019, IEEE INT ON LINE, P7, DOI [10.1109/IOLTS.2019.8854423, 10.1109/iolts.2019.8854423]
   Petrovic V, 2014, MICROELECTRON RELIAB, V54, P1613, DOI 10.1016/j.microrel.2014.04.001
   Petrovic V, 2015, IEEE INT SYMP DESIGN, P203, DOI 10.1109/DDECS.2015.65
   PICKEL JC, 1980, IEEE T NUCL SCI, V27, P1006, DOI 10.1109/TNS.1980.4330967
   Bastos RP, 2020, IEEE T NUCL SCI, V67, P1404, DOI 10.1109/TNS.2020.2975923
   Prinzie J, 2019, IEEE T NUCL SCI, V66, P282, DOI 10.1109/TNS.2018.2885693
   Secondo R, 2016, IEEE T NUCL SCI, V63, P2168, DOI 10.1109/TNS.2016.2521485
   Simevski A, 2020, IEEE INT ON LINE, DOI 10.1109/iolts50870.2020.9159716
   Simevski A, 2014, 2014 IEEE 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SOCS (MCSOC), P175, DOI 10.1109/MCSoC.2014.33
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tsiligiannis G, 2014, IEEE T NUCL SCI, V61, P1663, DOI 10.1109/TNS.2014.2299733
   Tylka AJ, 1996, IEEE T NUCL SCI, V43, P2758, DOI 10.1109/23.556863
   Upasani G, 2016, IEEE T COMPUT, V65, P5, DOI 10.1109/TC.2015.2419652
   Wong WS, 2020, RADIAT MEAS, V131, DOI 10.1016/j.radmeas.2019.106230
   Yearby KH, 2014, SPACE WEATHER, V12, P24, DOI 10.1002/2013SW000985
   Ytre-Hauge KS, 2015, NUCL INSTRUM METH A, V804, P64, DOI 10.1016/j.nima.2015.09.049
NR 45
TC 4
Z9 4
U1 3
U2 10
PD APR-JUN
PY 2022
VL 10
IS 2
BP 564
EP 580
DI 10.1109/TETC.2022.3147376
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT C
AU Li, BL
   Gadepally, V
   Samsi, S
   Tiwari, D
AF Li, Baolin
   Gadepally, Viiay
   Samsi, Siddharth
   Tiwari, Devesh
GP IEEE Comp Soc
TI Characterizing Multi-Instance GPU for Machine Learning Workloads
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE Machine Learning; GPU; Characterization
AB As machine learning (ML) becomes more and more popular, datacenter operators use hardware accelerators such as GPUs to tackle the high computation demand of ML workloads. However, recent studies show that user-submitted jobs often underutilize the GPU streaming multiprocessor (SM) cores, resulting in hardware resource wastage. Motivated by this observation, GPU vendors have released software and hardware support for GPU resource sharing, for example, the NVIDIA Multi-Instance GPU (MIG) technique on A100 Tensor Core GPUs. In this work, we use several state-of-the-art deep learning (DL) models from various application areas to characterize the performance and energy consumption of the A100 GPU MIG mode operation. Our characterization reveals valuable insights into operating a MIG-enabled GPU datacenter.
C1 [Li, Baolin; Tiwari, Devesh] Northeastern Univ, Boston, MA 02115 USA.
   [Gadepally, Viiay; Samsi, Siddharth] MIT, Lincoln Lab, 244 Wood St, Lexington, MA 02173 USA.
RP Li, BL (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
CR Ali A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00073
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2022, 19 USENIX S NETW SYS
   Azevedo D., 2010, GREEN GRID, V32
   Chaudhary S, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387555
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571, DOI DOI 10.1108/01439911111122716
   Chuangang Ren, 2012, 2012 IEEE 20th International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS), P391, DOI 10.1109/MASCOTS.2012.51
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Cui HG, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901323
   Cui WH, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476143
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Devlin J., 2019, PROC ACL, V1
   Dhakal Aditya, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P492, DOI 10.1145/3419111.3421284
   Eliad S, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P381
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gu JC, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P485
   Gujarati A, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P443
   Gulli A., 2017, DEEP LEARNING KERAS
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harlap A, 2018, Arxiv, DOI arXiv:1806.03377
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu QH, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476223
   Hu YT, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '21), P624, DOI 10.1145/3472883.3486993
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jia XY, 2018, Arxiv, DOI arXiv:1807.11205
   Kaman RS, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303958
   Karakus C, 2021, Arxiv, DOI arXiv:2111.05972
   Li B, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401486
   Liu H, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3289, DOI 10.1145/3447548.3467146
   Mullapudi RT, 2019, IEEE I CONF COMP VIS, P3572, DOI 10.1109/ICCV.2019.00367
   Murray Derek G., 2021, P VLDB 2021
   Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209
   Narayanan D, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P481
   Narayanan Deepak, 2021, INT C MACHINE LEARNI, P7937
   NVIDIA, NVIDIA MULTIINSTANCE
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Pennington J., 2014, P EMNLP, P1532, DOI DOI 10.3115/V1/D14-1162
   Pumma S, 2019, ACM TRANS PARALLEL C, V6, DOI 10.1145/3331526
   Rajbhandari S., 2021, P INT C HIGH PERF CO, P1
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024
   Ren J, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P551
   Renugadevi T, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12166383
   Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397
   Shi S., 2021, P MACHINE LEARNING S, V3, P401
   Vaswani A, 2017, ADV NEUR IN, V30
   Xiao WC, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P533
   Xiao WC, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P595
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P811, DOI 10.1109/MICRO50266.2020.00071
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhou HS, 2018, IEEE REAL TIME, P190, DOI 10.1109/RTAS.2018.00028
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
   Zhu ZW, 2020, J SYST ARCHITECT, V109, DOI 10.1016/j.sysarc.2020.101810
NR 53
TC 1
Z9 1
U1 0
U2 2
PY 2022
BP 724
EP 731
DI 10.1109/IPDPSW55747.2022.00124
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Khan, OU
   Wentzloff, DD
AF Khan, Osama U.
   Wentzloff, David D.
TI Hardware Accelerator for Probabilistic Inference in 65-nm CMOS
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Bayesian network (BN); clique-tree; embedded machine learning; hardware
   accelerator; intelligent sensor node; message passing; probabilistic
   graphical model; probabilistic inference
ID NETWORKS
AB A hardware accelerator is presented to compute the probabilistic inference for a Bayesian network (BN) in distributed sensing applications. For energy efficiency, the accelerator is operated at a near-threshold voltage of 0.5 V, while achieving a maximum clock frequency of 33 MHz. Clique-tree message passing algorithm is leveraged to compute the probabilistic inference. The theoretical maximum size of a factor that the proposed hardware accelerator can handle is 2((8x20)=160) entries, which is sufficient for handling massive BNs, such as PATHFINDER, MUNIN, and so on (>1000 nodes). A Logical Alarm Reduction Mechanism (ALARM) BN is used to benchmark the performance of the accelerator. The accelerator consumes 76 nJ to execute the ALARM network using a clique-tree message-passing algorithm, while the same algorithm executed on an ultralow-power microcontroller consumes 20 mJ.
C1 [Khan, Osama U.] Univ Calif Berkeley, Dept Elect Engn, Berkeley, CA 94720 USA.
   [Wentzloff, David D.] Univ Michigan, Dept Elect Engn, Ann Arbor, MI 48109 USA.
RP Khan, OU (corresponding author), Univ Calif Berkeley, Dept Elect Engn, Berkeley, CA 94720 USA.; Wentzloff, DD (corresponding author), Univ Michigan, Dept Elect Engn, Ann Arbor, MI 48109 USA.
EM oukhan@berkeley.edu; wentzlof@umich.edu
CR Analytic bridge, 2011, BAYES NETW NEWSL
   [Anonymous], 2014, CISC KEYN HIGHL CES
   [Anonymous], 2007, PATTERN RECOGN, V16
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Beinlich I. A., 1989, AIME 89. Second European Conference on Artificial Intelligence in Medicine Proceedings, P247
   Calhoun BH, 2012, P IEEE, V100, P91, DOI 10.1109/JPROC.2011.2161240
   Chen G., 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P310, DOI 10.1109/ISSCC.2011.5746332
   Chirarattananon P, 2014, BIOINSPIR BIOMIM, V9, DOI 10.1088/1748-3182/9/2/025004
   Dreslinski RG, 2010, P IEEE, V98, P253, DOI 10.1109/JPROC.2009.2034764
   IBM, 2014, WATS EC
   Koller D., 2009, PROBABILISTIC GRAPHI
   Kong ZH, 2008, 2008 INTERNATIONAL SYMPOSIUM ON VLSI DESIGN, AUTOMATION AND TEST (VLSI-DAT), PROCEEDINGS OF TECHNICAL PROGRAM, P275, DOI 10.1109/VDAT.2008.4542466
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lin MJ, 2010, FPGA 10, P73
   Marra S, 2004, IEEE IJCNN, P2613
   Microchip, 2014, PIC12 L F1822 DAT SH
   MOORE GE, 1965, ELECTRONICS, V38
   PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X
   Rabaey J. M., 2005, AMBIENT INTELLIGENCE
   Scutari M., 2013, BAYESIAN NETWORK REP
   Wang JF, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2027, DOI 10.1109/ICNN.1995.488985
   Yanushkevich SN, 2011, SOFT COMPUT, V15, P3, DOI 10.1007/s00500-009-0512-3
NR 22
TC 5
Z9 5
U1 1
U2 8
PD MAR
PY 2016
VL 24
IS 3
BP 837
EP 845
DI 10.1109/TVLSI.2015.2420663
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Kim, S
   Howe, P
   Moreau, T
   Alaghi, A
   Ceze, L
   Sathe, V
AF Kim, Sung
   Howe, Patrick
   Moreau, Thierry
   Alaghi, Armin
   Ceze, Luis
   Sathe, Visvesh
GP IEEE
TI MATIC: Learning Around Errors for Efficient Low-Voltage Neural Network
   Accelerators
SO PROCEEDINGS OF THE 2018 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 19-23, 2018
CL Dresden, GERMANY
DE Deep neural networks; voltage scaling; SRAM; machine learning
   acceleration
AB As a result of the increasing demand for deep neural network (DNN)-based services, efforts to develop dedicated hardware accelerators for DNNs are growing rapidly. However, while accelerators with high performance and efficiency on convolutional deep neural networks (Conv-DNNs) have been developed, less progress has been made with regards to fully-connected DNNs (FC-DNNs). In this paper, we propose MATIC (Memory Adaptive Training with In-situ Canaries), a methodology that enables aggressive voltage scaling of accelerator weight memories to improve the energy-efficiency of DNN accelerators. To enable accurate operation with voltage overscaling, MATIC combines the characteristics of destructive SRAM reads with the error resilience of neural networks in a memory-adaptive training process. Furthermore, PVT-related voltage margins are eliminated using bit-cells from synaptic weights as in-situ canaries to track runtime environmental variation. Demonstrated on a low-power DNN accelerator that we fabricate in 65 nm CMOS, MATIC enables up to 60-80 mV of voltage overscaling (3.3x total energy reduction versus the nominal voltage), or 18.6x application error reduction.
C1 [Kim, Sung; Howe, Patrick; Sathe, Visvesh] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   [Moreau, Thierry; Alaghi, Armin; Ceze, Luis] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
RP Kim, S (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
EM sungk9@ee.washington.edu; pdh4@ee.washington.edu;
   moreau@cs.washington.edu; armin@cs.washington.edu;
   ceze@cs.washington.edu; sathe@ee.washington.edu
CR Alvira M., 2001, TECH REP
   [Anonymous], 2003, TECH REP
   [Anonymous], DAC 17
   [Anonymous], 2009, OPENMSP430
   [Anonymous], 2007, PATTERN RECOGN, V16
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Guo Z, 2009, IEEE J SOLID-ST CIRC, V44, P3174, DOI 10.1109/JSSC.2009.2032698
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Srinivasan G, 2016, DES AUT TEST EUROPE, P151
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Wang SH, 2017, DES AUT TEST EUROPE, P1032, DOI 10.23919/DATE.2017.7927142
   Xia L., 2017, DAC
   Yang LT, 2017, INT SYM QUAL ELECT, P7, DOI 10.1109/ISQED.2017.7918284
NR 23
TC 36
Z9 36
U1 0
U2 5
PY 2018
BP 1
EP 6
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, XY
   Wu, C
   Dong, S
   Dy, J
   Kaeli, D
AF Li, Xiangyu
   Wu, Chieh
   Dong, Shi
   Dy, Jennifer
   Kaeli, David
BE Brandes, U
   Reddy, C
   Tagarelli, A
TI Interactive Kernel Dimension Alternative Clustering on GPUs
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS
   ANALYSIS AND MINING (ASONAM)
DT Proceedings Paper
CT IEEE/ACM International Conference on Advances in Social Networks
   Analysis and Mining (ASONAM)
CY AUG 28-31, 2018
CL Barcelona, SPAIN
DE KDAC; clustering; GPU; Machine Learning; Big Data
AB Machine learning has seen tremendous growth in recent years thanks to two key advances in technology: massive data generation and highly-parallel accelerator architectures. The rate that data is being generated is exploding across multiple domains, including medical research, environmental science, web-search, and e-commerce. Many of these advances have benefited from emergent web-based applications, and improvements in data storage and sensing technologies. Innovations in parallel accelerator hardware, such as GPUs, has made it possible to process massive amounts of data in a timely fashion. Given these advanced data acquisition technology and hardware, machine learning researchers are equipped to generate and sift through much larger and complex datasets quickly.
   In this work, we focus on accelerating Kernel Dimension Alternative Clustering algorithms using GPUs. We conduct a thorough performance analysis by using both synthetic and real-world datasets, while also modifying both the structure of the data, and the size of the datasets. Our GPU implementation reduces execution time from minutes to seconds, which enables us to develop a web-based application for users to, interactively, view alternative clustering solutions.
C1 [Li, Xiangyu; Wu, Chieh; Dong, Shi; Dy, Jennifer; Kaeli, David] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
RP Li, XY (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM xili@ece.neu.edu; chiehwu@ece.neu.edu; shidong@ece.neu.edu;
   jdy@ece.neu.edu; kaeli@ece.neu.edu
CR [Anonymous], 2010, PROGRAMMING MASSIVEL
   [Anonymous], 2011, GPU COMPUTING GEMS E
   Azmandian F, 2012, IEEE DATA MINING, P51, DOI 10.1109/ICDM.2012.51
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jorgensen M., 2017, 2017 IEEE MIT UND RE, P1
   Kaeli D., 2015, HETEROGENEOUS COMPUT
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nickolls J., 2008, ACM SIGGRAPH 2008 CL, P16
   Niu D, 2011, P 14 INT C ARTIFICIA, P552
   Niu DL, 2014, IEEE T PATTERN ANAL, V36, P1340, DOI 10.1109/TPAMI.2013.180
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Volkov V, 2008, P 2008 ACM IEEE C SU, DOI DOI 10.1109/SC.2008.5214359
   Wu C., 2018, INT C ART INT STAT, V84, P115
NR 14
TC 4
Z9 4
U1 0
U2 0
PY 2018
BP 885
EP 892
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Roussel, R
   Edelen, A
   Ratner, D
   Dubey, K
   Gonzalez-Aguilera, JP
   Kim, YK
   Kuklev, N
AF Roussel, R.
   Edelen, A.
   Ratner, D.
   Dubey, K.
   Gonzalez-Aguilera, J. P.
   Kim, Y. K.
   Kuklev, N.
TI Differentiable Preisach Modeling for Characterization and Optimization
   of Particle Accelerator Systems with Hysteresis
SO PHYSICAL REVIEW LETTERS
DT Article
ID IDENTIFICATION; ALGORITHM
AB Future improvements in particle accelerator performance are predicated on increasingly accurate online modeling of accelerators. Hysteresis effects in magnetic, mechanical, and material components of accelerators are often neglected in online accelerator models used to inform control algorithms, even though reproducibility errors from systems exhibiting hysteresis are not negligible in high precision accelerators. In this Letter, we combine the classical Preisach model of hysteresis with machine learning techniques to efficiently create nonparametric, high-fidelity models of arbitrary systems exhibiting hysteresis. We experimentally demonstrate how these methods can be used in situ, where a hysteresis model of an accelerator magnet is combined with a Bayesian statistical model of the beam response, allowing characterization of magnetic hysteresis solely from beam-based measurements. Finally, we explore how using these joint hysteresis-Bayesian statistical models allows us to overcome optimization performance limitations that arise when hysteresis effects are ignored.
C1 [Roussel, R.; Edelen, A.; Ratner, D.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Dubey, K.; Gonzalez-Aguilera, J. P.; Kim, Y. K.] Univ Chicago, Chicago, IL 60637 USA.
   [Kuklev, N.] Argonne Natl Lab, Adv Photon Source, 9700 South Cass Ave, Argonne, IL 60439 USA.
RP Roussel, R (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM roussel@slac.stanford.edu
CR Aicheler M., 2012, CERN2012007
   [Anonymous], SUPPLEMENTAL MAT, DOI [10.1103/PhysRevLett.128.204801, DOI 10.1103/PHYSREVLETT.128.204801]
   Bellman R., 1961, ADAPTIVE CONTROL PRO
   Bertotti G., 2006, SCI HYSTERESIS, VI-III
   Borland M., 2018, PROC 9 INT PARTICLE, P2872, DOI DOI 10.18429/JACOWIPAC2018-THXGBD1
   BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Hanuka A., 2021, P 12 INT PARTICLE AC, P4
   Hergli K, 2019, J KING SAUD UNIV SCI, V31, P746, DOI 10.1016/j.jksus.2017.11.005
   HOFFMANN KH, 1989, NUMER MATH, V55, P695, DOI 10.1007/BF01389337
   Iyer RV, 2004, IEEE T MAGN, V40, P3227, DOI 10.1109/TMAG.2004.833427
   JILES DC, 1986, J MAGN MAGN MATER, V61, P48, DOI 10.1016/0304-8853(86)90066-1
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kirschner J., ARXIV1902 03229
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Marouani H, 2019, ARAB J SCI ENG, V44, P6941, DOI 10.1007/s13369-019-03727-8
   MAYERGOYZ ID, 1988, IEEE T MAGN, V24, P212, DOI 10.1109/20.43892
   Paszke A, 2019, ADV NEUR IN, V32
   Pomerening JR, 2003, NAT CELL BIOL, V5, P346, DOI 10.1038/ncb954
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Roussel R., 2021, P 12 INT PARTICLE AC, P2159
   Roussel R, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25757-3
   Ruderman M, 2012, IEEE T MAGN, V48, P1281, DOI 10.1109/TMAG.2011.2172931
   Sammut N. J., 2008, 1107 LHC
   Snoek J., 2012, PROC INT C NEURAL IN, V25, P2951
   Srinivas N., 2010, P 27 INT C INT C MAC, P1015, DOI DOI 10.1109/TIT.2011.2182033
   Sun Y., 2021, P 12 INT PARTICLE AC, P3959
   Sutor A, 2010, APPL PHYS A-MATER, V100, P425, DOI 10.1007/s00339-010-5884-9
   Tan XB, 2001, PROC SPIE, V4326, P101, DOI 10.1117/12.436463
   Tanabe J., 2005, SLACR754 NAT ACC LAB
   Uwe Sauer Dirk., 2009, ENCY ELECTROCHEMICAL, P443
   Warnecke M, 2003, J MECH DESIGN, V125, P620, DOI 10.1115/1.1596241
   Willa R, 2016, PHYS REV B, V93, DOI 10.1103/PhysRevB.93.064515
   Wingate D., ARXIV13011299
NR 34
TC 2
Z9 2
U1 3
U2 14
PD MAY 20
PY 2022
VL 128
IS 20
AR 204801
DI 10.1103/PhysRevLett.128.204801
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Chen, F
   Song, LH
   Li, H
   Chen, YR
AF Chen, Fan
   Song, Linghao
   Li, Hai
   Chen, Yiran
GP ACM
TI ZARA: A Novel Zero-free Dataflow Accelerator for Generative Adversarial
   Networks in 3D ReRAM
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
DE GAN; 3D ReRAM; unsupervised learning
AB Generative Adversarial Networks (GANs) recently demonstrated a great opportunity toward unsupervised learning with the intention to mitigate the massive human efforts on data labeling in supervised learning algorithms. GAN combines a generative model and a discriminative model to oppose each other in an adversarial situation to refine their abilities. Existing nonvolatile memory based machine learning accelerators, however, could not support the computational needs required by GAN training. Specifically, the generator utilizes a new operator, called transposed convolution, which introduces significant resource underutilization when executed on conventional neural network accelerators as it inserts massive zeros in its input before a convolution operation. In this work, we propose a novel computational deformation technique that synergistically optimizes the forward and backward functions in transposed convolution to eliminate the large resource underutilization. In addition, we present dedicated control units - a dataflow mapper and an operation scheduler, to support the proposed execution model with high parallelism and low energy consumption. ZARA is implemented with commodity ReRAM chips, and experimental results show that our design can improve GAN's training performance by averagely 1.6x similar to 23x over CMOS-based GAN accelerators. Compared to state-of-the-art ReRAM-based accelerator designs, ZARA also provides 1.15x similar to 2.1x performance improvement.
C1 [Chen, Fan; Song, Linghao; Li, Hai; Chen, Yiran] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
RP Chen, F (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
EM fan.chen@duke.edu; linghao.song@duke.edu; hai.li@duke.edu;
   yiran.chen@duke.edu
CR [Anonymous], DATE
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Collobert R., 2008, P 25 ICML, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Dong X., 2012, IEEE T COMPUTER AIDE
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graham Benjamin, 2014, ARXIV E PRINTS
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kim Taeksoo, 2017, ARXIV E PRINTS
   Kreutz-Delgado K., 2017, ARXIV170502583
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mao H., 2018, MICRO
   Qian Lou, 2018, ICCAD
   Radford A., 2015, ARXIV151106434
   Salimans T, 2016, ADV NEUR IN, V29
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Song M., 2018, HPCA
   Tan Wei Ren, 2017, ARXIV E PRINTS
   Wen W., 2017, ICCAD
   Wu Jiajun, 2016, P NIPS
   Xu Dawen, 2018, ICCAD
   Yazdanbakhsh A, 2018, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2018.00019
   Yazdanbakhsh A, 2018, CONF PROC INT SYMP C, P650, DOI 10.1109/ISCA.2018.00060
NR 26
TC 12
Z9 12
U1 1
U2 3
PY 2019
DI 10.1145/3316781.3317936
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Serpa, MS
   Krause, AM
   Cruz, EHM
   Navaux, POA
   Pasin, M
   Felber, P
AF Serpa, Matheus S.
   Krause, Arthur M.
   Cruz, Eduardo H. M.
   Navaux, Philippe O. A.
   Pasin, Marcelo
   Felber, Pascal
BE Merelli, I
   Lio, P
   Kotenko, I
TI Optimizing Machine Learning Algorithms on Multi-core and Many-core
   Architectures using Thread and Data Mapping
SO 2018 26TH EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED,
   AND NETWORK-BASED PROCESSING (PDP 2018)
SE Euromicro Conference on Parallel Distributed and Network-Based
   Processing
DT Proceedings Paper
CT 26th Euromicro International Conference on Parallel, Distributed, and
   Network-Based Processing (PDP)
CY MAR 21-23, 2018
CL Univ Cambridge, Comp Lab, Cambridge, ENGLAND
HO Univ Cambridge, Comp Lab
DE Machine learning; Thread mapping; Data mapping; Memory accesses
AB Driven by the development of new technologies such as personal assistants or autonomous cars, machine learning has rapidly become one of the most active fields in computer science. The algorithms at the core of machine learning are notoriously demanding in terms of resources. It is therefore of paramount importance to optimize their operation on modern processors. Several approaches have been proposed to accelerate machine learning on GPUs and massively parallel computers, as well as dedicated ASICs. In this paper, we focus on Intel's multi-core Xeon and many-core accelerator Xeon Phi Knights Landing, which can host several hundreds of threads on the same CPU. In such architectures, thread and data mapping are keys for performance. We study the impact of mapping strategies, revealing that, with smart mapping policies, one can indeed significantly speed up machine learning applications on manycore architectures. Execution time was reduced by up to 25.2% and 18.5% on Intel Xeon and Xeon Phi KNL, respectively.
C1 [Serpa, Matheus S.; Krause, Arthur M.; Cruz, Eduardo H. M.; Navaux, Philippe O. A.] Fed Univ Rio Grande Sul UFRGS, Inst Informat, Porto Alegre, RS, Brazil.
   [Pasin, Marcelo; Felber, Pascal] Univ Neuchatel, Neuchatel, Switzerland.
RP Serpa, MS (corresponding author), Fed Univ Rio Grande Sul UFRGS, Inst Informat, Porto Alegre, RS, Brazil.
EM msserpa@inf.ufrgs.br; akrause@inf.ufrgs.br; ehmcruz@inf.ufrgs.br;
   navaux@inf.ufrgs.br; marcelo.pasin@unine.ch; pascal.felber@unine.ch
CR Bach M, 2010, COMPUTER, V43, P34, DOI 10.1109/MC.2010.60
   Che S., 2010, IISWC, DOI DOI 10.1109/IISWC.2010.5650274
   Corbet Jonathan, 2012, BETTER NUMA SCHEDULI
   Cruz EHM, 2016, PARALLEL COMPUT, V54, P59, DOI 10.1016/j.parco.2015.12.001
   Cruz EHM, 2014, J PARALLEL DISTR COM, V74, P2215, DOI 10.1016/j.jpdc.2013.11.006
   Diener M, 2014, INT CONFER PARA, P277, DOI 10.1145/2628071.2628085
   Diener M, 2016, IEEE T PARALL DISTR, V27, P2653, DOI 10.1109/TPDS.2015.2504985
   Diener M, 2015, PARALLEL COMPUT, V43, P43, DOI 10.1016/j.parco.2015.01.005
   He JZ, 2016, PARALLEL COMPUT, V51, P56, DOI 10.1016/j.parco.2015.10.011
   Liu GT, 2015, ASIA S PACIF DES AUT, P429, DOI 10.1109/ASPDAC.2015.7059044
   Mazouz Abdelhafid, 2011, 2011 International Conference on High Performance Computing & Simulation, P273
   Ribeiro CP, 2009, INT SYM COMP ARCHIT, P59, DOI 10.1109/SBAC-PAD.2009.16
   Tousimojarad A, 2014, ADV PARALLEL COMPUT, V25, P63, DOI 10.3233/978-1-61499-381-0-63
NR 13
TC 7
Z9 7
U1 0
U2 1
PY 2018
BP 329
EP 333
DI 10.1109/PDP2018.2018.00058
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xin, GZ
   Zhao, YF
   Han, J
AF Xin, Guozhu
   Zhao, Yifan
   Han, Jun
GP IEEE
TI A Multi-Layer Parallel Hardware Architecture for Homomorphic Computation
   in Machine Learning
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 22-28, 2021
CL Daegu, SOUTH KOREA
DE Homomorphic encryption; machine learning; parallelism; hardware
   acceleration; FPGA
ID PROCESSOR
AB Homomorphic Encryption (HE) allows untrusted parties to process encrypted data without revealing its content. People could encrypt the data locally and send it to the cloud to conduct neural network training or inferencing, which achieves data privacy in AI. However, the combined AI and HE computation could be extremely slow. To deal with it, we propose a multi-level parallel hardware accelerator for homomorphic computations in machine learning. The vectorized Number Theoretic Transform (NTT) unit is designed to form the low-level parallelism, and we apply a Residue Number System (RNS) to form the mid-level parallelism in one polynomial. Finally, a fully pipelined and parallel accelerator for two ciphertext operands is proposed to form the high-level parallelism. To address the core computation (matrix-vector multiplication) in neural networks, our work is designed to support Multiply-Accumulate (MAC) operations natively between ciphertexts. We have analyzed our design on FPGA ZCU102, and experimental results show that it outperforms previous works and achieves over an order of magnitude acceleration than software implementations.
C1 [Xin, Guozhu; Zhao, Yifan; Han, Jun] Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
RP Han, J (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
EM junhan@fudan.edu.cn
CR Albrecht M., 2018, HOMOMORPHIC ENCRYPTI
   [Anonymous], 2020, MICROSOFT SEAL RELEA
   Cathebras J., 2018, IACR T CHES, V2018, P69
   Chen DD, 2015, IEEE T CIRCUITS-I, V62, P157, DOI 10.1109/TCSI.2014.2350431
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   Dai W., 2015, CUHE HOMOMORPHIC ENC
   Fan J., 2012, IACR CRYPTOL EPRINT
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Halevi S, 2014, LECT NOTES COMPUT SC, V8616, P554, DOI 10.1007/978-3-662-44371-2_31
   Joan D., 2002, ANTHR POLITICS
   Mert AC, 2020, IEEE T VLSI SYST, V28, P353, DOI 10.1109/TVLSI.2019.2943127
   Öztürk E, 2017, IEEE T COMPUT, V66, P3, DOI 10.1109/TC.2016.2574340
   Poppelmann Thomas, 2012, Progress in Cryptology - LATINCRYPT 2012. Proceedings of the 2nd International Conference on Cryptology and Information Security in Latin America, P139, DOI 10.1007/978-3-642-33481-8_8
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Roy SS, 2018, IEEE T COMPUT, V67, P1637, DOI 10.1109/TC.2018.2816640
   Turan F, 2020, IEEE T COMPUT, V69, P1185, DOI 10.1109/TC.2020.2988765
   Xin GZ, 2020, IEEE T CIRCUITS-I, V67, P2672, DOI 10.1109/TCSI.2020.2983185
NR 18
TC 5
Z9 5
U1 2
U2 7
PY 2021
DI 10.1109/ISCAS51556.2021.9401623
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ono, T
   Shoji, T
   Waidyasooriya, HM
   Hariyama, M
   Aoki, Y
   Kondoh, Y
   Nakagawa, Y
AF Ono, Taisuke
   Shoji, Tomoki
   Waidyasooriya, Hasitha Muthumala
   Hariyama, Masanori
   Aoki, Yuichiro
   Kondoh, Yuki
   Nakagawa, Yaoko
GP IEEE
TI FPGA-based Acceleration of Word2vec Using OpenCL
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
DE Word embedding; FPGA; machine learning; natural language processing
AB Word2vee is a word embedding method that converts words into vectors in such a way that the semantically and syntactically relevant words are close to each other in the vector space. The processing time of Word2vec is very large due to the huge data size. We propose a power efficient FPGA-based accelerator designed using OpenCL. We achieved 13.4 times speed-up compared to single-core CPU implementation with only 53W of power consumption. The proposed FPGA-based accelerator has the highest power-efficiency compared to existing top-end GPU-based accelerators.
C1 [Ono, Taisuke; Shoji, Tomoki; Waidyasooriya, Hasitha Muthumala; Hariyama, Masanori] Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-3-09 Aramaki Aza Aoba, Sendai, Miyagi 9808579, Japan.
   [Aoki, Yuichiro; Kondoh, Yuki; Nakagawa, Yaoko] Hitachi Ltd, Res & Dev Grp, Kokubunji, Tokyo 1858601, Japan.
RP Ono, T (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-3-09 Aramaki Aza Aoba, Sendai, Miyagi 9808579, Japan.
EM ono52@dc.tohoku.ac.jp; tomoki.shoji.q1@dc.tohoku.ac.jp;
   hasitha@tohoku.ac.jp; hariyama@tohoku.ac.jp;
   yuichiro.aoki.jk@hitachi.com; yuki.kondo.fe@hitachi.com;
   yaoko.nakagawa.gn@hitachi.com
CR Agrawal RK, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P6, DOI 10.1109/ICCMC.2017.8282627
   [Anonymous], 2012, P INT C ENG RECONFIG
   [Anonymous], 2016, INTEL FPGA SDK OPENC
   [Anonymous], 2016, WORD2VEC
   [Anonymous], 2016, ARXIV160404661
   [Anonymous], 2018, INTEL FPGA SDK OPENC
   Bai X, 2014, IEEE INT CONGR BIG, P358, DOI 10.1109/BigData.Congress.2014.59
   Canny J, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P233, DOI 10.1109/BigData.2015.7363760
   Chelba C., 2014, ARXIV PREPRINT ARXIV
   Goldberg Y, 2014, ARXIV
   Ji S., 2016, P NIPS WORKSH EFF ME
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, P3294, DOI DOI 10.5555/2969442.2969607
   Kobayashi R, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING IN ASIA-PACIFIC REGION (HPC ASIA 2018), P192, DOI 10.1145/3149457.3149479
   Liu YF, 2014, INT C DIGITAL HOME, P8, DOI 10.1109/ICDH.2014.9
   Ma L, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2895, DOI 10.1109/BigData.2015.7364114
   Mikolov T., 2013, P WORKSHOP ICLR
   Mikolov Tomas, 2013, ADV NEURAL INFORM PR, P3111
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Rengasamy V., 2017, P 7 WORKSH IRR APPL, P3
   Seong H, 2016, 2016 URSI ASIA-PACIFIC RADIO SCIENCE CONFERENCE (URSI AP-RASC), P269, DOI 10.1109/URSIAP-RASC.2016.7601160
   Simonton T. M., 2017, HIGH PERF EXTR COMP, P1
   Waidyasooriya H., 2017, DESIGN FPGA BASED CO
NR 22
TC 2
Z9 2
U1 0
U2 0
PY 2019
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Baru, C
   Campbell, L
   Dade, A
   Fulay, P
   Loewi, A
   Maughan, D
   Mohedas, I
   Molnar, L
   Pozmantier, M
   Reksulak, M
   Smith, S
   Tehrani, N
AF Baru, Chaitanya
   Campbell, Lara
   Dade, Aurali
   Fulay, Pradeep
   Loewi, Alex
   Maughan, Douglas
   Mohedas, Ibrahim
   Molnar, Linda
   Pozmantier, Michael
   Reksulak, Michael
   Smith, Shelby
   Tehrani, Nicole
TI The NSF Convergence Accelerator program
SO AI MAGAZINE
DT Article
AB The National Science Foundation's Convergence Accelerator is a unique program offering researchers and innovators the opportunity to translate research results into tangible solutions that make a difference for society. Through an intense innovation curriculum and a mentorship program, researchers gain skills and experiences that are of use not only during this program but throughout their careers. This article describes the NSF Convergence Accelerator program and its initial funded convergence research topics-or "tracks"-funded in 2019 and 2020. In almost every track and NSF-funded project, artificial intelligence and machine learning (AI/ML) approaches and methods are playing an essential role.
C1 [Baru, Chaitanya; Campbell, Lara; Dade, Aurali; Fulay, Pradeep; Loewi, Alex; Maughan, Douglas; Mohedas, Ibrahim; Molnar, Linda; Pozmantier, Michael; Reksulak, Michael; Smith, Shelby; Tehrani, Nicole] Natl Sci Fdn, Alexandria, VA 22314 USA.
   [Baru, Chaitanya] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Dade, Aurali; Reksulak, Michael] George Mason Univ, Fairfax, VA 22030 USA.
   [Fulay, Pradeep] West Virginia Univ, Morgantown, WV 26506 USA.
RP Baru, C (corresponding author), Natl Sci Fdn, Convergence Accelerator, Off Director, 2415 Eisenhower Ave, Alexandria, VA 22314 USA.
EM cbaru@ucsd.edu
CR CORD, 2019, COVID 19 OP RES DAT
   Fecho K, 2019, CTS-CLIN TRANSL SCI, V12, P86, DOI 10.1111/cts.12591
   FWHTF, 2020, FUT WORK HUM TECHN F
   HDR, 2017, NSF HARN DAT REV BIG
   I2M, 2021, STANF ID TO MARK COU
   Isabel Cardenas-Navia, 2021, ISSUES SCI TECHNOL
   NITRD, 2017, NITRD OP KNOWL NETW
   NSCAI, 2021, FIN REP NAT SEC COMM
   NSF, 2021, ANN 2021 COH TRACK E
   NSF, 2021, NSF CONV ACC 2021 CO
   NSF, 2022, JOINT NSF DOD PHAS 1
   NSF, 2020, NSF 21 012 DEAR COLL
   NSF, 2020, NSF 20 061 DEAR COLL
   NSF, 2019, NSF 19 050 DEAR COLL
   NSF, 2022, 22036 NSF DCL
   NSF, 2016, GROW CONV RES
   NSF, 2019, NSF CONV ACC 2021 PO
   Schwartz David, 2020, WALL STREET J 2020
NR 18
TC 0
Z9 0
U1 0
U2 1
PD MAR
PY 2022
VL 43
IS 1
BP 6
EP 16
DI 10.1002/aaai.12032
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Han, S
   Dally, WJ
AF Han, Song
   Dally, William J.
GP IEEE
TI INVITED: Bandwidth-Efficient Deep Learning
SO 2018 55TH ACM/ESDA/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 55th ACM/ESDA/IEEE Design Automation Conference (DAC)
CY JUN 24-28, 2018
CL San Francisco, CA
DE Neural Networks; Accelerator; Inference; Training; Model Compression;
   Gradient Compression
AB Deep learning algorithms are achieving increasingly higher prediction accuracy on many machine learning tasks. However, applying brute-force programming to data demands a huge amount of machine power to perform training and inference, and a huge amount of manpower to design the neural network models, which is inefficient. In this paper, we provide techniques to solve these bottlenecks: saving memory bandwidth for inference by model compression, saving networking bandwidth for training by gradient compression, and saving engineer bandwidth for model design by using AI to automate the design of models.
C1 [Han, Song] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Han, Song] Google, Mountain View, CA 94043 USA.
   [Dally, William J.] Stanford Univ, Stanford, CA 94305 USA.
   [Dally, William J.] NVIDIA, Santa Clara, CA USA.
RP Han, S (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Han, S (corresponding author), Google, Mountain View, CA 94043 USA.
EM songhan@mit.edu; dally@stanford.edu
CR [Anonymous], 2015, COMPUTER SCI
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571, DOI DOI 10.1108/01439911111122716
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Facebook, 2017, DEL REAL TIM AI PALM
   Google, 2017, INTR TENSORFLOW LIT
   Google, 2017, GOOGL CLOUD AI
   Han S., 2015, ARXIV151000149
   Han S, 2017, THESIS
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2015, C NEUR INF PROC SYST
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Johnson Matthew B, 2018, PRUNING HYPOTHESIS C
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lanzerotti MY, 2005, IBM J RES DEV, V49, P777, DOI 10.1147/rd.494.0777
   Lin Y., 2018, ICLR 2018
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Moritz Philipp, 2015, ARXIV151106051
   NVIDIA, 2017, NVIDIA GPU CLOUD
   Parashar Angshuman, 2017, 44 INT S COMP ARCH
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   RAUSCHECKER JP, 1984, HUM NEUROBIOL, V3, P109
   Walsh CA, 2013, NATURE, V502, P172, DOI 10.1038/502172a
   Wen W., 2017, ARXIV170507878, DOI DOI 10.1109/ICC.2017.7997306
   Xing Eric P., 2015, IEEE Transactions on Big Data, V1, P49, DOI 10.1109/TBDATA.2015.2472014
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zinkevich Martin, 2010, ADV NEURAL INFORM PR, P2595
NR 29
TC 3
Z9 3
U1 0
U2 0
PY 2018
DI 10.1145/3195970.3199847
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT J
AU Xu, Z
   Chen, X
   Shen, J
   Zhang, Y
   Chen, C
   Yang, CQ
AF Xu, Zhen
   Chen, Xuhao
   Shen, Jie
   Zhang, Yang
   Chen, Cheng
   Yang, Canqun
TI GARDENIA: A Graph Processing Benchmark Suite for Next-Generation
   Accelerators
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Benchmark suite; graph processing; massive multithreading; irregular
   workloads
ID FRAMEWORK
AB This article presents the Graph Algorithm Repository for Designing Next-generation Accelerators (GARDENIA), a benchmark suite for studying irregular graph algorithms on massively parallel accelerators. Applications with limited control and data irregularity are the main focus of existing generic benchmarks for accelerators, while available graph processing benchmarks do not apply state-of-the-art algorithms and/or optimization techniques. GARDENIA includes emerging graph processing workloads from graph analytics, sparse linear algebra. and machine-learning domains, which mimic massively multithreaded commercial programs running on modern large-scale datacenters. Our characterization shows that GARDENIA exhibits irregular microarchitectural behavior, which is quite different from structured workloads and straightforward-implemented graph benchmarks.
C1 [Xu, Zhen; Chen, Xuhao; Shen, Jie; Zhang, Yang; Chen, Cheng; Yang, Canqun] Natl Univ Def Technol, 109 Deya Rd, Changsha 410073, Hunan, Peoples R China.
RP Xu, Z (corresponding author), Natl Univ Def Technol, 109 Deya Rd, Changsha 410073, Hunan, Peoples R China.
EM zhenx@nudt.edu.cn; chenxuhao@nudt.edu.cn; j.shen@nudt.edu.cn;
   zhangyang@nudt.edu.cn; chencheng@nudt.edu.cn; canqun@nudt.edu.cn
CR [Anonymous], 1999, WWW 1999
   [Anonymous], GPU COMPUTING
   [Anonymous], 2017, CONCURR COMPUT PRACT
   [Anonymous], 2016, ACM SIGARCH COMPUTER
   [Anonymous], P INT C HIGH PERF CO
   [Anonymous], 2015, ABS150803619 CORR
   [Anonymous], 2012, CTR RELIABLE HIGH PE
   [Anonymous], 2014, CUSP GENERIC PARALLE
   Beamer S, 2015, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2015.12
   Beamer S, 2013, SCI PROGRAMMING-NETH, V21, P137, DOI [10.3233/SPR-130370, 10.1155/2013/702694]
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Burtscher M., 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P141, DOI 10.1109/IISWC.2012.6402918
   Che S, 2013, I S WORKL CHAR PROC, P185, DOI 10.1109/IISWC.2013.6704684
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Davidson A, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.45
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Ham TJ, 2016, INT SYMP MICROARCH
   Hong SP, 2011, ACM SIGPLAN NOTICES, V46, P267, DOI 10.1145/2038037.1941590
   Khorasani Farzad, 2014, P 23 INT S HIGH PERF, P239, DOI DOI 10.1145/2600212.2600227
   Kunegis J, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1343
   Leskovec J., 2013, SNAP STANFORD NETWOR
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Low Yucheng, 2010, UNCERTAINTY ARTIFICI
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167, DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184]
   Merrill D, 2012, ACM SIGPLAN NOTICES, V47, P117, DOI 10.1145/2370036.2145832
   Meyer U, 2003, J ALGORITHMS, V49, P114, DOI 10.1016/S0196-6774(03)00076-2
   Nai LF, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807626
   Nasre R, 2013, INT PARALL DISTRIB P, P463, DOI 10.1109/IPDPS.2013.28
   Ozdal MM, 2016, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2016.24
   Shun JL, 2013, ACM SIGPLAN NOTICES, V48, P135, DOI 10.1145/2517327.2442530
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Yu XY, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P178, DOI 10.1145/2830772.2830807
   Zhong JL, 2014, IEEE T PARALL DISTR, V25, P1543, DOI 10.1109/TPDS.2013.111
NR 34
TC 3
Z9 4
U1 1
U2 9
PD FEB
PY 2019
VL 15
IS 1
SI SI
AR 9
DI 10.1145/3283450
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Brennsteiner, S
   Arslan, T
   Thompson, J
   McCormick, A
AF Brennsteiner, Stefan
   Arslan, Tughrul
   Thompson, John
   McCormick, Andrew
TI A Real-Time Deep Learning OFDM Receiver
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Neural networks; OFDM; FPGA; physical layer processing; machine learning
   acceleration; real time
ID ACCELERATORS; NETWORKS
AB Machine learning in the physical layer of communication systems holds the potential to improve performance and simplify design methodology. Many algorithms have been proposed; however, the model complexity is often unfeasible for real-time deployment. The real-time processing capability of these systems has not been proven yet. In this work, we propose a novel, less complex, fully connected neural network to perform channel estimation and signal detection in an orthogonal frequency division multiplexing system. The memory requirement, which is often the bottleneck for fully connected neural networks, is reduced by approximate to 27 times by applying known compression techniques in a three-step training process. Extensive experiments were performed for pruning and quantizing the weights of the neural network detector. Additionally, Huffman encoding was used on the weights to further reduce memory requirements. Based on this approach, we propose the first field-programmable gate array based, real-time capable neural network accelerator, specifically designed to accelerate the orthogonal frequency division multiplexing detector workload. The accelerator is synthesized for a Xilinx RFSoC field-programmable gate array, uses small-batch processing to increase throughput, efficiently supports branching neural networks, and implements superscalar Huffman decoders.
C1 [Brennsteiner, Stefan; Arslan, Tughrul] Univ Edinburgh, Kings Bldg,Alexander Crum Brown Rd, Edinburgh, Midlothian, Scotland.
   [Thompson, John] Univ Edinburgh, Kings Bldg,Thomas Bayes Rd, Edinburgh, Midlothian, Scotland.
   [McCormick, Andrew] Alpha Data Parallel Syst Ltd, 160 Dundee St, Edinburgh, Midlothian, Scotland.
RP Brennsteiner, S (corresponding author), Univ Edinburgh, Kings Bldg,Alexander Crum Brown Rd, Edinburgh, Midlothian, Scotland.
EM stefan.brennsteiner@ed.ac.uk; tughrul.arslan@ed.ac.uk;
   john.thompson@ed.ac.uk; ani@alpha-data.com
CR 3GPP, 2020, 38820 TS 3GPP
   3GPP, 2019, 21915 3GPP TR
   *3GPP, 36211 3GPP TR
   Aggarwal CC., 2018, SPRINGER, DOI DOI 10.1007/978-3-319-94463-0
   Alpha Data Ltd, ADM XRC 9R1 FPGA COT
   [Anonymous], 1985, INT COMMUN HEAT MASS, DOI DOI 10.1016/0735-1933(85)90003-X
   [Anonymous], 2014, INT WORKSHOP OPENCL
   [Anonymous], 2019, DPU CONV NEUR NETW V
   [Anonymous], 2007, OFDM BASEBAND RECEIV
   Aspar Z, 2000, TENCON IEEE REGION, P73
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Csaji B. C., 2001, FACULTY SCI ETVS LOR, V24, P7
   Dörner S, 2018, IEEE J-STSP, V12, P132, DOI 10.1109/JSTSP.2017.2784180
   ElWazeer Khaled, 2009, 2009 21st International Conference on Microelectronics (ICM 2009), P280, DOI 10.1109/ICM.2009.5418629
   Felix A, 2018, IEEE INT WORK SIGN P, P56
   Gao XX, 2018, IEEE COMMUN LETT, V22, P2627, DOI 10.1109/LCOMM.2018.2877965
   GitHub, 2020, HAOYYE OFDM DNN
   GitHub, GOOGL RES GOOGL RES
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo Y., 2018, ARXIV180804752 CS ST
   Han Song, 2015, ARXIV151000149 CS
   He HT, 2019, IEEE WIREL COMMUN, V26, P77, DOI 10.1109/MWC.2019.1800447
   IEEE, 2019, 754 2019 IEEE STANDA, P1, DOI [10.1109/IEEESTD.2019.8766229, DOI 10.1109/IEEESTD.2019.8766229]
   Laplante P. A, 2012, REAL TIME SYSTEMS DE, V4th
   Ledwon M, 2020, IEEE ACCESS, V8, P62207, DOI 10.1109/ACCESS.2020.2984191
   Letaief KB, 2019, IEEE COMMUN MAG, V57, P84, DOI 10.1109/MCOM.2019.1900271
   Lin H, 2015, IEEE ACCESS, V3, P1861, DOI 10.1109/ACCESS.2015.2480749
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Mao Q, 2018, IEEE COMMUN SURV TUT, V20, P2595, DOI 10.1109/COMST.2018.2846401
   MathWorks United Kingdom, 2021 EST CHANN US IN
   MathWorks United Kingdom, 2021 EQ OFDM DAT US
   Molisch A. F., 2012, WIRELESS COMMUNICATI, V34
   O'Shea T, 2017, IEEE T COGN COMMUN, V3, P563, DOI 10.1109/TCCN.2017.2758370
   OShea Timothy J., 2017, ARXIV170707980 CS MA
   Pal C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351234
   Posewsky T, 2018, MICROPROCESS MICROSY, V60, P151, DOI 10.1016/j.micpro.2018.04.004
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Sesia S., 2011, LTE THE UMTS LONG TE
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shlezinger N, 2019, IEEE INT WORK SIGN P, DOI 10.1109/spawc.2019.8815457
   Van Leeuwen J., 1976, P 3 INT C AUT LANG P, P382
   Wang TQ, 2017, CHINA COMMUN, V14, P92, DOI 10.1109/CC.2017.8233654
   Xilinx Inc, 2018, ZYNQ ULTRASCALE RFSO
   Xilinx Inc, 2020, ULTRASCALE ARCHITECT
   Xue SY, 2019, IEEE WIREL COMMUN LE, V8, P177, DOI 10.1109/LWC.2018.2865563
   Yao M, 2019, IEEE COMMUN MAG, V57, P14, DOI 10.1109/MCOM.2019.1800629
   Ye H, 2018, IEEE WIREL COMMUN LE, V7, P114, DOI 10.1109/LWC.2017.2757490
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang L, 2019, CHINA COMMUN, V16, P1, DOI 10.23919/JCC.2019.08.001
NR 50
TC 1
Z9 1
U1 0
U2 9
PD SEP
PY 2022
VL 15
IS 3
SI SI
AR 26
DI 10.1145/3494049
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Huang, BY
   Zhang, HC
   Subramanyan, P
   Vizel, Y
   Gupta, A
   Malik, S
AF Huang, Bo-Yuan
   Zhang, Hongce
   Subramanyan, Pramod
   Vizel, Yakir
   Gupta, Aarti
   Malik, Sharad
TI Instruction-Level Abstraction (ILA): A Uniform Specification for
   System-on-Chip (SoC) Verification
SO ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS
DT Article
DE System on chip; hardware specification; application-specific
   accelerator; architecture; instruction-level abstraction; formal
   verification; equivalence checking
AB Modern Systems-on-Chip (SoC) designs are increasingly heterogeneous and contain specialized semi-programmable accelerators in addition to programmable processors. In contrast to the pre-accelerator era, when the ISA played an important role in verification by enabling a clean separation of concerns between software and hardware, verification of these "accelerator-rich" SoCs presents new challenges. From the perspective of hardware designers, there is a lack of a common framework for formal functional specification of accelerator behavior. From the perspective of software developers, there exists no unified framework for reasoning about software/hardware interactions of programs that interact with accelerators.
   This article addresses these challenges by providing a formal specification and high-level abstraction for accelerator functional behavior. It formalizes the concept of an Instruction Level Abstraction (ILA), developed informally in our previous work, and shows its application in modeling and verification of accelerators. This formal ILA extends the familiar notion of instructions to accelerators and provides a uniform, modular, and hierarchical abstraction for modeling software-visible behavior of both accelerators and programmable processors. We demonstrate the applicability of the ILA through several case studies of accelerators (for image processing, machine learning, and cryptography), and a general-purpose processor (RISC-V). We show how the ILA model facilitates equivalence checking between two ILAs, and between an ILA and its hardware finite-state machine (FSM) implementation. Further, this equivalence checking supports accelerator upgrades using the notion of ILA compatibility, similar to processor upgrades using ISA compatibility.
C1 [Huang, Bo-Yuan; Zhang, Hongce; Gupta, Aarti; Malik, Sharad] Princeton Univ, 1 Nassau Hall, Princeton, NJ 08544 USA.
   [Subramanyan, Pramod] Indian Inst Technol Kanpur, Kanpur 208016, Uttar Pradesh, India.
   [Vizel, Yakir] Technion Israel Inst Technol, Viazman 87, IL-3200003 Haifa, Haifa District, Israel.
RP Huang, BY (corresponding author), Princeton Univ, 1 Nassau Hall, Princeton, NJ 08544 USA.
EM byhuang@princeton.edu; hongcez@princeton.edu; spramod@cse.iitk.ac.in;
   yvizel@cs.technion.ac.il; aartig@cs.princeton.edu; sharad@princeton.edu
CR Abdi S, 2006, INT J PARALLEL PROG, V34, P29, DOI 10.1007/s10766-005-0001-y
   Alglave J, 2014, ACM T PROGR LANG SYS, V36, DOI 10.1145/2627752
   Alur R, 2004, ACM T PROGR LANG SYS, V26, P339, DOI 10.1145/973097.973101
   Alur R, 2015, NATO SCI PEAC SECUR, V40, P1, DOI 10.3233/978-1-61499-495-4-1
   [Anonymous], 2016, INT 64 IA 32 ARCH SO
   [Anonymous], 2011, LECT NOTES COMPUTER, DOI DOI 10.1007/978-3-642-22110-1_32
   [Anonymous], 2017, RISC 5 INSTRUCTION S
   Ardestani EK, 2013, INT S HIGH PERF COMP, P448, DOI 10.1109/HPCA.2013.6522340
   ARM Ltd, 2010, CORT M3 DEV GEN US G
   Arvind, 1999, IEEE MICRO, V19, P36, DOI 10.1109/40.768501
   Asanovic K., 2016, ROCKET CHIP GENERATO
   Bacchini F, 2007, DES AUT CON, P444, DOI 10.1109/DAC.2007.375205
   Bachrach J, 2012, DES AUT CON, P1212
   Barrett C., 2010, SMT, VVolume 13, P14
   Batty M, 2012, ACM SIGPLAN NOTICES, V47, P509, DOI 10.1145/2103621.2103717
   Batty M, 2011, ACM SIGPLAN NOTICES, V46, P55, DOI 10.1145/1925844.1926394
   Berry G, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P433
   Biere A, 2003, ADV COMPUT, V58, P117
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Bornholt J, 2017, ACM SIGPLAN NOTICES, V52, P467, DOI [10.1145/3062341.3062353, 10.1145/3140587.3062353]
   Burch J. R., 1994, P CAV, P68
   Cadence Design Systems Inc., 2018, JASPERGOLD FORM PROP
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Chan Wei-Ting Jonas, 2014, 2014 IEEE 32nd International Conference on Computer Design (ICCD), P153, DOI 10.1109/ICCD.2014.6974675
   Choi J, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3110268
   Clarke E, 2004, LECT NOTES COMPUT SC, V2988, P168, DOI 10.1007/978-3-540-24730-2_15
   Clarke EM, 1999, MODEL CHECKING, P1
   Copty F, 2001, LECT NOTES COMPUT SC, V2102, P436
   Cota EG, 2015, DES AUT CON, DOI 10.1145/2744769.2744794
   Dave N., 2011, 2011 9th IEEE/ACM International Conference on Formal Methods and Models for Codesign (MEMOCODE 2011), P61, DOI 10.1109/MEMCOD.2011.5970511
   Dave N, 2007, MEMOCODE'07: FIFTH ACM & IEEE INTERNATIONAL CONFERENCE ON FORMAL METHODS AND MODELS FOR CO-DESIGN, PROCEEDINGS, P51, DOI 10.1109/MEMCOD.2007.371249
   de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24
   De Moura L, 2011, COMMUN ACM, V54, P69, DOI 10.1145/1995376.1995394
   Dömer R, 2008, EURASIP J EMBED SYST, DOI 10.1155/2008/647953
   Goel S, 2014, 2014 FORMAL METHODS IN COMPUTER-AIDED DESIGN (FMCAD), P91, DOI 10.1109/FMCAD.2014.6987600
   Harel D., 1996, ACM Transactions on Software Engineering and Methodology, V5, P293, DOI 10.1145/235321.235322
   Herber P, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2435227.2435257
   Hoe JC, 2000, ICCAD - 2000 : IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, P511, DOI 10.1109/ICCAD.2000.896524
   Holzmann GJ, 1997, IEEE T SOFTWARE ENG, V23, P279, DOI 10.1109/32.588521
   Impulse Accelerated Technologies, 2003, IMP CODEVELOPER C TO
   Jain H, 2005, DES AUT CON, P445, DOI 10.1109/DAC.2005.193850
   Jha S., 2010, ICSE 10, P215, DOI DOI 10.1145/1806799.1806833
   Jhala R, 2001, LECT NOTES COMPUT SC, V2102, P396
   Lee S, 2014, LECT NOTES COMPUT SC, V8559, P849, DOI 10.1007/978-3-319-08867-9_56
   Lipmaa Helger, 2000, COMMENTS NIST AES MO
   Lockhart D, 2014, INT SYMP MICROARCH, P280, DOI 10.1109/MICRO.2014.50
   Lustig D, 2016, ACM SIGPLAN NOTICES, V51, P233, DOI 10.1145/2954679.2872399
   Lustig D, 2014, INT SYMP MICROARCH, P635, DOI 10.1109/MICRO.2014.38
   McMillan K. L., 1993, SYMBOLIC MODEL CHECK
   Milner R., 1989, Communication and concurrency
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Nikhil R, 2004, Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, Proceedings, P69
   OWICKI S, 1976, ACTA INFORM, V6, P319, DOI 10.1007/BF00268134
   Panda PR, 2001, ISSS'01: 14TH INTERNATIONAL SYMPOSIUM ON SYSTEM SYNTHESIS, P75, DOI 10.1109/ISSS.2001.957916
   Pilato C, 2013, I C FIELD PROG LOGIC
   Pilato C, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P406, DOI 10.1145/2903150.2906141
   Pu J, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3107953
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Reid A, 2016, PROCEEDINGS OF THE 2016 16TH CONFERENCE ON FORMAL METHODS IN COMPUTER-AIDED DESIGN (FMCAD 2016), P161
   Reid A, 2016, LECT NOTES COMPUT SC, V9780, P42, DOI 10.1007/978-3-319-41540-6_3
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Shao YS, 2015, IEEE MICRO, V35, P58, DOI 10.1109/MM.2015.50
   Subramanyan P., 2016, DATE, P1393, DOI DOI 10.3850/9783981537079_0793
   Subramanyan P, 2018, IEEE T COMPUT AID D, V37, P1692, DOI 10.1109/TCAD.2017.2764482
   Trippel C, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P119, DOI 10.1145/3037697.3037719
   Vijayaraghavan M, 2015, LECT NOTES COMPUT SC, V9207, P109, DOI 10.1007/978-3-319-21668-3_7
   Vizel Y., 2017, FMCAD, P160
   Vizel Y, 2012, PROCEEDINGS OF THE 12TH CONFERENCE ON FORMAL METHODS IN COMPUTER-AIDED DESIGN (FMCAD 2012), P173
   Weber Tjark, 2004, HDB SATISFIABILITY, V185, P825, DOI [10.1145/1995376.1995394, DOI 10.1145/1995376.1995394]
NR 69
TC 16
Z9 17
U1 0
U2 9
PD JAN
PY 2019
VL 24
IS 1
AR 10
DI 10.1145/3282444
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Matsubara, K
   Sato, A
AF Matsubara, Katsuya
   Sato, Atsuya
GP IEEE
TI An Access Control Mechanism for Pre-trained ML Models in Mobile Apps
SO 2019 TWELFTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS
   NETWORK (ICMU)
DT Proceedings Paper
CT 12th International Conference on Mobile Computing and Ubiquitous
   Networking (ICMU)
CY NOV 04-06, 2019
CL Kathmandu, NEPAL
DE machine learning inference; Android; smartphone; access control
AB Utilizing machine learning inference in mobile platforms have been made realistic since recent smartphones may have high-performance processors and hardware accelerators of signal and image processing. However, it could bring issues. One of the most significant issues is that any machine learning inferences can be unlimitedly applied to personal data which once the application got permitted to. Furthermore, it could be quite hard to understand the behavior of a 'pre-trained' machine learning model and the behavior of an installed application can be transparently modified afterword by replacing a used model. This research aims to implement access control against such functionalities of machine learning inference for mobile platforms. In this paper, we describe how to verify used pre-trained models and how to implement permission control at Android Neural Networks API for Android as a target platform. And we also show an evaluation result with a prototype implementation.
C1 [Matsubara, Katsuya] Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido, Japan.
   [Sato, Atsuya] Future Univ Hakodate, Dept Complex & Intelligent Syst, Hakodate, Hokkaido, Japan.
RP Matsubara, K (corresponding author), Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido, Japan.
EM matsu@fun.ac.jp
CR [Anonymous], 2018, KERAS
   Bucila C., 2006, P 12 ACM SIGKDD INT, DOI [DOI 10.1145/1150402.1150464, 10.1145/1150402.1150464]
   Google, 2018, PIX VIS COR IM PROC
   Howard A. G., 2017, ARXIV
   Kawabata H., 2013, IPSJ J, V54, P2090
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
NR 7
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.23919/icmu48249.2019.9006661
WC Computer Science, Theory & Methods; Telecommunications
DA 2023-11-11
ER

PT J
AU Wang, CC
   Liao, YC
   Kao, MC
   Liang, WY
   Hung, SH
AF Wang, Chuan-Chi
   Liao, Ying-Chiao
   Kao, Ming-Chang
   Liang, Wen-Yew
   Hung, Shih-Hao
TI Toward Accurate Platform-Aware Performance Modeling for Deep Neural
   Networks
SO APPLIED COMPUTING REVIEW
DT Article
DE Machine Learning; Benchmark; Performance Prediction; Heterogeneous
   Systems
AB In this paper, we provide a fine-grain machine learning-based method, PerfNetV2, which improves the accuracy of our previous work for modeling the neural network performance on a variety of GPU accelerators. Given an application, the proposed method can be used to predict the inference time and training time of the convolutional neural networks used in the application, which enables the system developer to optimize the performance by choosing the neural networks and/or incorporating the hardware accelerators to deliver satisfactory results in time. Furthermore, the proposed method is capable of predicting the performance of an unseen or non-existing device, e.g. a new GPU which has a higher operating frequency with less processor cores, but more memory capacity. This allows a system developer to quickly search the hardware design space and/or fine-tune the system configuration. Compared to the previous works, PerfNetV2 delivers more accurate results by modeling detailed host-accelerator interactions in executing the full neural networks and improving the architecture of the machine learning model used in the predictor. Our case studies show that PerfNetV2 yields a mean absolute percentage error within 13.1% on LeNet, AlexNet, and VGG16 on NVIDIA GTX-1080Ti, while the error rate on a previous work published in ICBD 2018 could be as large as 200%.
C1 [Wang, Chuan-Chi; Kao, Ming-Chang; Liang, Wen-Yew] ADLINK Technol Inc, New Taipei, Taiwan.
   [Liao, Ying-Chiao; Hung, Shih-Hao] Natl Taiwan Univ, Taipei, Taiwan.
RP Wang, CC (corresponding author), ADLINK Technol Inc, New Taipei, Taiwan.
EM chi.wang@adlinktech.com; d08922004@ntu.edu.tw;
   fencer.kao@adlinktech.com; william.liang@adlinktech.com;
   hungsh@csie.ntu.edu.tw
CR [Anonymous], INT C LEARN REPR ICL
   [Anonymous], 2015, COMPUTER SCI
   Cao B., 2018, IEEE C COMP VIS PATT
   Cody C., 2017, NIPS ML SYST WORKSH
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Justus D, 2018, IEEE INT CONF BIG DA, P3873, DOI 10.1109/BigData.2018.8622396
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   LHPCSiu C. Y, 2018, INT C HIGH PERF COMP
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Nikouei S. Y, 2018, IEEE INT C EDG COMP
   P. Software, BENCHMARKS
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Simonyan K., 2015, ICLR
   Tran B, 2019, ACM SIGIR C RES DEV
   Wang C.-C., 2020, RES ADAPTIVE CONVERG
NR 17
TC 1
Z9 1
U1 0
U2 0
PD MAR
PY 2021
VL 21
IS 1
BP 50
EP 61
DI 10.1145/3400286.3418245
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT J
AU Zhang, CY
   Zhang, F
   Guo, XG
   He, BS
   Zhang, X
   Du, XY
AF Zhang, Chenyang
   Zhang, Feng
   Guo, Xiaoguang
   He, Bingsheng
   Zhang, Xiao
   Du, Xiaoyong
TI iMLBench: A Machine Learning Benchmark Suite for CPU-GPU Integrated
   Architectures
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Computer architecture; Machine learning; Benchmark testing; Graphics
   processing units; Task analysis; Hardware; Training; Machine learning;
   benchmark; CPU; GPU; integrated architectures
ID EFFICIENT
AB Utilizing heterogeneous accelerators, especially GPUs, to accelerate machine learning tasks has shown to be a great success in recent years. GPUs bring huge performance improvements to machine learning and greatly promote the widespread adoption of machine learning. However, the discrete CPU-GPU architecture design with high PCIe transmission overhead decreases the GPU computing benefits in machine learning training tasks. To overcome such limitations, hardware vendors release CPU-GPU integrated architectures with shared unified memory. In this article, we design a benchmark suite for machine learning training on CPU-GPU integrated architectures, called iMLBench, covering a wide range of machine learning applications and kernels. We mainly explore two features on integrated architectures: 1) zero-copy, which means that the PCIe overhead has been eliminated for machine learning tasks and 2) co-running, which means that the CPU and the GPU co-run together to process a single machine learning task. Our experimental results on iMLBench show that the integrated architecture brings an average 7.1x performance improvement over the original implementations. Specifically, the zero-copy design brings 4.65x performance improvement, and co-running brings 1.78x improvement. Moreover, integrated architectures exhibit promising results from both performance-per-dollar and energy perspectives, achieving 6.50x performance-price ratio while 4.06x energy efficiency over discrete GPUs. The benchmark is open-sourced at https://github.com/ChenyangZhang-cs/iMLBench.
C1 [Zhang, Chenyang; Zhang, Feng; Guo, Xiaoguang; Zhang, Xiao; Du, Xiaoyong] Renmin Univ China, Key Lab Data Engn & Knowledge Engn MOE, Beijing 100872, Peoples R China.
   [Zhang, Chenyang; Zhang, Feng; Guo, Xiaoguang; Zhang, Xiao; Du, Xiaoyong] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
   [He, Bingsheng] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
RP Zhang, F (corresponding author), Renmin Univ China, Key Lab Data Engn & Knowledge Engn MOE, Beijing 100872, Peoples R China.; Zhang, F (corresponding author), Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
EM chenyangzhang@ruc.edu.cn; fengzhang@ruc.edu.cn; xiaoguangguo@ruc.edu.cn;
   hebs@comp.nus.edu.sg; zhangxiao@ruc.edu.cn; duyong@ruc.edu.cn
CR [Anonymous], 2020, NEXT GENERATION AMD
   [Anonymous], 2018, TOP 10 MACHINE LEARN
   [Anonymous], 2018, 10 MACHINE LEARNING
   [Anonymous], 2020, AMD ROCM V3 5 1 PATC
   [Anonymous], 2019, AMD TOTAL GPU MARKET
   [Anonymous], 2019, XBOX ONE VS PLAYSTAT
   Bhalachandra S, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P911, DOI 10.1109/IPDPSW.2015.144
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen X, 2020, P ANN C INN DAT SYST
   Cheng Y., 2017, ARXIV171009282
   clNET, 2018, OPENCL NETS
   Daga M., 2011, Proceedings of the 2011 Symposium on Application Accelerators in High-Performance Computing (SAAHPC 2011), P141, DOI 10.1109/SAAHPC.2011.29
   Dai W, 2019, 2019 IEEE FIRST INTERNATIONAL CONFERENCE ON COGNITIVE MACHINE INTELLIGENCE (COGMI 2019), P148, DOI 10.1109/CogMI48466.2019.00029
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   Ditty M., 2014, HOT CHIPS 26 S HCS 2, P1
   Fu H, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225077
   Gao T, 2020, IEEE T PARALL DISTR, V31, P2734, DOI 10.1109/TPDS.2019.2932066
   Gao W., 2018, INT S BENCHMARKING M, P3
   Georgakoudis G, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3158643
   Go Y, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P83
   He BS, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P260, DOI 10.1145/1454115.1454152
   Hong S, 2010, CONF PROC INT SYMP C, P280, DOI 10.1145/1816038.1815998
   Hosseini B, 2020, DATA SCI ENG, V5, P126, DOI 10.1007/s41019-020-00123-3
   Hoste K, 2007, IEEE MICRO, V27, P63, DOI 10.1109/MM.2007.56
   Huber S., 2018, THESIS ETH ZURICH
   Imandoust S.B., 2013, INT J ENG RES APPL, V3, P605, DOI DOI 10.1016/J.JTBI.2009.08.004
   Intel, 2014, COMP ARCH INT PROC G
   Jain P, 2019, 33RD INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2019), P25, DOI [10.1109/ICOIN.2019.8717981, 10.1109/icoin.2019.8717981]
   Kramer GJ, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.035003
   Krishnan G, 2016, IEEE MICRO, V36, P22, DOI 10.1109/MM.2016.24
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li PL, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS), P347, DOI 10.1109/NAS.2015.7255222
   Liu Y, 2018, PROC VLDB ENDOW, V11, P1220, DOI 10.14778/3231751.3231770
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Mukherjee S, 2016, INT SYM PERFORM ANAL, P183, DOI 10.1109/ISPASS.2016.7482093
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Olson RS, 2017, BIODATA MIN, V10, DOI 10.1186/s13040-017-0154-4
   Pinto G, 2017, IEEE INT CONF AUTOM, P765, DOI 10.1109/ASE.2017.8115687
   Pouchet L.-N., 2012, POLYBENCH POLYHEDRAL
   Schuld M, 2016, PHYS REV A, V94, DOI 10.1103/PhysRevA.94.022342
   Schulte MJ, 2015, IEEE MICRO, V35, P26, DOI 10.1109/MM.2015.71
   Sheng H, 2020, IEEE INTERNET THINGS, V7, P9611, DOI 10.1109/JIOT.2020.2980549
   Si M, 2014, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, (ICS'14), P125, DOI 10.1145/2597652.2597658
   Stratton J. A, 2012, CTR RELIABLE HIGH PE, P127
   Tang SJ, 2022, IEEE T KNOWL DATA EN, V34, P71, DOI 10.1109/TKDE.2020.2975652
   Vijayaraghavan T, 2017, INT S HIGH PERF COMP, P85, DOI 10.1109/HPCA.2017.42
   Waldo J, 1998, IEEE CONCURR, V6, P5, DOI 10.1109/4434.708248
   Yan D, 2020, PROCEEDINGS OF THE 25TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '20), P32, DOI 10.1145/3332466.3374520
   Zhang F, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P633
   Zhang F, 2021, IEEE T KNOWL DATA EN, V33, P867, DOI 10.1109/TKDE.2019.2940184
   Zhang F, 2017, INT SYM CODE GENER, P27, DOI 10.1109/CGO.2017.7863726
   Zhang F, 2017, IEEE T PARALL DISTR, V28, P905, DOI 10.1109/TPDS.2016.2586074
   Zhang K, 2017, PROC INT CONF DATA, P671, DOI 10.1109/ICDE.2017.120
   Zhang SQ, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-018-7386-4
NR 56
TC 5
Z9 5
U1 1
U2 27
PD JUL 1
PY 2021
VL 32
IS 7
BP 1740
EP 1752
DI 10.1109/TPDS.2020.3046870
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sevilla, J
   Heim, L
   Ho, A
   Besiroglu, T
   Hobbhahn, M
   Villalobos, P
AF Sevilla, Jaime
   Heim, Lennart
   Ho, Anson
   Besiroglu, Tamay
   Hobbhahn, Marius
   Villalobos, Pablo
GP IEEE
TI Compute Trends Across Three Eras of Machine Learning
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
DE machine learning; artificial intelligence; deep learning; computational
   efficiency; AI accelerators; backpropagation; high performance computing
ID DEEP NEURAL-NETWORKS; LEVEL; GAME; MODEL; GO
AB Compute, data, and algorithmic advances are the three fundamental factors that drive progress in modern Machine Learning (ML). In this paper we study trends in the most readily quantified factor - compute. We make three novel contributions: (1) we curate a dataset with the training compute of 123 milestone ML systems, 3x larger than previous such datasets. (2) We frame the trends in compute in in three eras - the Pre Deep Learning Era, the Deep Learning Era, and the Large-Scale Era, based on our identification of a novel trend emerging around 2015. (3) We find a Deep Learning Era compute doubling time of around 6 months, significantly longer than previous findings. Overall, our work highlights the fast-growing compute requirements for training advanced ML systems.
C1 [Sevilla, Jaime; Heim, Lennart; Ho, Anson; Besiroglu, Tamay; Hobbhahn, Marius; Villalobos, Pablo] Epoch, Tokyo, Japan.
   [Sevilla, Jaime] Univ Aberdeen, Aberdeen, Scotland.
   [Besiroglu, Tamay] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
   [Heim, Lennart] Ctr Governance AI, Berkeley, CA USA.
   [Hobbhahn, Marius] Univ Tubingen, Tubingen, Germany.
RP Sevilla, J (corresponding author), Epoch, Tokyo, Japan.; Sevilla, J (corresponding author), Univ Aberdeen, Aberdeen, Scotland.
CR Adiwardana D., 2020, CONVERSATIONAL AGENT
   Ajmera A., 2021, FORD SHUT SOME N AM
   Alayrac Jean-Baptiste, 2022, FLAMINGO VISUAL LANG
   Alom M Z, 2018, ARXIV180301164, DOI DOI 10.48550/ARXIV.1803.01164
   Alvi A., 2021, USING DEEPSPEED MEGA
   Amodei D, 2015, Arxiv, DOI arXiv:1512.02595
   Amodei Dario, 2018, AI AND COMPUTE
   [Anonymous], 2022, AKR LIGHTON AI RES
   [Anonymous], 2022, HARDWAREUND NACHRICH
   [Anonymous], 2022, COMPUTER PROGR
   [Anonymous], GPT NEO
   [Anonymous], 2020, MUCH DID ALPHAGO ZER
   [Anonymous], 2022, AI TRACKER
   [Anonymous], 2021, OPENAI API PRIC
   [Anonymous], 2020, ARXIV PREPRINT ARXIV
   Antoun W., 2020, ARAGPT2 PRETRAINED T
   Athlur S., 2021, VARUNA SCALABLE LOW
   Attinasi M.G., 2021, ECB EC B
   Ba J. L., 2016, ARXIV160706450
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Baker B., 2019, EMERGENT TOOL USE MU
   Barbu A, 2019, ADV NEUR IN, V32
   Bard N, 2020, ARTIF INTELL, V280, DOI 10.1016/j.artint.2019.103216
   Barrett E., 2021, TAIWANS DROUGHT IS E
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Berner C., 2019, ARXIV PREPRINT ARXIV
   Bordes A., 2013, ADV NEURAL INFORM PR, V26, DOI DOI 10.5555/2999792.2999923
   Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]
   Brown N, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5226
   Brown T., 2020, PROC ADV NEUR INF PR, P1877
   Cai H., 2019, ONCE FOR ALL TRAIN O
   Cai H., 2018, ARXIV181200332
   Catanzaro B., 2008, ICML 08
   Chellapilla Kumar, 2006, HIGH PERFORMANCE CON
   Chen M., 2020, IMAGE GPT
   Chen SH, 1998, IEEE T SPEECH AUDI P, V6, P226, DOI 10.1109/89.668817
   Chollet F, 2017, Arxiv, DOI [arXiv:1610.02357, DOI 10.48550/ARXIV.1610.02357]
   Chowdhery A., 2022, PALM SCALING LANGUAG
   Ciresan D. C., 2011, IJCAI 11
   Ciresan D, 2012, Arxiv, DOI [arXiv:1202.2745, DOI 10.48550/ARXIV.1202.2745]
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Zeiler MD, 2013, Arxiv, DOI arXiv:1311.2901
   Dai JF, 2016, ADV NEUR IN, V29
   Deng L., 2009, DEEP LEARNING SPEECH
   Desislavov R., 2021, COMPUTE ENERGY CONSU
   Ding M, 2021, COGVIEW MASTERING TE
   Dosovitskiy A., 2020, IMAGE ISWORTH 16X16W
   E. Hinton Geoffrey, 2012, Arxiv, DOI [arXiv:1207.0580, 10.48550/arXiv.1207.0580, DOI 10.48550/ARXIV.1207.0580]
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Espeholt L, 2018, Arxiv, DOI [arXiv:1802.01561, 10.48550/ARXIV.1802.01561]
   Fedus William, 2021, SWITCH TRANSFORMERS
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Glorot X., 2010, P JMLR WORKSH C P 13, P249, DOI DOI 10.1177/1753193409103364.
   Goodfellow I. J., 2014, INT C LEARNING REPRE, DOI DOI 10.1109/CVPR.2016.90
   Goyal Priya, 2021, ARXIV210301988
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2015, Arxiv, DOI [arXiv:1502.01852, DOI 10.48550/ARXIV.1502.01852]
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hestness J, 2017, Arxiv, DOI arXiv:1712.00409
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Ho J., 2020, DENOISING DIFFUSION, DOI DOI 10.48550/ARXIV.2006.11239
   Hoffmann J, 2022, TRAINING COMPUTE OPT
   Hsu W.-N., 2021, HUBERT SELF SUPERVIS
   Huang YP, 2019, ADV NEUR IN, V32
   Jaderberg M, 2019, SCIENCE, V364, P859, DOI 10.1126/science.aau6249
   Jia C., 2021, SCALING VISUAL VISIO, P4904
   Kaplan Jared, 2020, ARXIV200108361
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Klein D., MIGHTY MOUSE
   Kohs G., 2017, ALPHAGO
   Komatsuzaki A, 2021, GPT J 6B 6B JAX BASE
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Jones AL, 2021, Arxiv, DOI arXiv:2104.03113
   Lan Z., 2020, INT C LEARNING REPRE, P1
   Leahy C, 2022, ANNOUNCING GPT NEOX
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lepikhin Dmitry, 2020, GSHARD SCALING GIANT
   Li C, 2020, LAMBDA
   Li ZH, 2020, Arxiv, DOI arXiv:2002.11794
   Lieber O., ANNOUNCING AI21 STUD
   Lillicrap T. P., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1509.02971
   Lin J, 2021, M6 10T SHARING DELIN
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Lohn A J, 2022, MUCH LONGER CAN COMP
   Loshchilov I., 2018, INT C LEARN REPR ICL
   Lyzhov A, 2021, AI COMPUTE TREND ISN
   Madani Ali, 2020, BIORXIV
   Microsoft, 2020, TURING NLG 17 BILLIO
   Mikolov T., 2013, NIPS, P3111
   Mikolov T., 2010, INTERSPEECH
   Mnih V, 2013, Arxiv, DOI arXiv:1312.5602
   MOORE GE, 1965, ELECTRONICS, V38
   Moravcík M, 2017, SCIENCE, V356, P508, DOI 10.1126/science.aam6960
   Mudigere Dheevatsa, 2021, SOFTWARE HARDWARE CO
   nad Mikhail Pavlov A. R., DALLE CREATING IMAGE
   Naumov Maxim, 2019, ABS190600091 CORR
   OpenAI, SOLVING RUBIKS CUBE
   Orme J., 2022, REPORT MICROSOFT HAN
   Kingma DP, 2014, Arxiv, DOI [arXiv:1312.6114, DOI 10.48550/ARXIV.1312.6114]
   Patel N, 2021, WHY GLOBAL CHIP SHOR
   Pham Hieu, 2020, META PSEUDO LABELS
   Pomerleau D. A., 1989, ADV NEURAL INFORM PR, P305
   Radford A., 2018, IMPROVING LANGUAGE U
   Radford A, 2019, BETTER LANGUAGE MODE
   Radford A, 2021, PR MACH LEARN RES, V139
   Rae J., LANGUAGE MODELLING S
   Raffel C, 2020, J MACH LEARN RES, V21
   Raina Rajat, 2009, INT C MACHINE LEARNI, P873, DOI DOI 10.1145/1553374.1553486
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rosenfeld JS, 2019, Arxiv, DOI arXiv:1909.12673
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Sastry G., 2019, AI COMPUTE ADDENDUM
   Schuster T., 2019, CROSS LINGUAL ALIGNM
   Sejnowski T. J, PARALLEL NETWORKS LE
   Selfridge O. G., PANDEMONIUM PARADIGM
   Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7
   Sevilla J., 2022, ESTIMATING TRAINING
   Sevilla Jaime, 2021, EMPHPARAMETER COUNTS
   Sharir O., 2020, COST TRAINING NLP MO
   Shazeer N, 2017, ARXIV
   Shilov A., 2020, GPU SHORTAGES HIT NV
   Shoeybi M., 2019, ARXIV190908053
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   So D. R., 2021, PRIMER SEARCHING EFF
   Steinkraus D, 2005, PROC INT CONF DOC, P1115, DOI 10.1109/ICDAR.2005.251
   Sun C, 2017, Arxiv, DOI arXiv:1707.02968
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Sutskever I, 2014, Arxiv, DOI arXiv:1409.3215
   Sutton R., 2019, BITTER LESSON
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697
   Thoppilan R., 2022, LAMDA LANGUAGE MODEL
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2001, RAPID OBJECT DETECTI, V1, pI
   Wang K, 2020, DEEPMIND ACHIEVED ST
   Wang L., 2019, ALPHAX EXPLORING NEU
   Wang X, 2019, KEPLER UNIFIED MODEL
   Widrow B., 1988, NEUROCOMPUTING FDN R, P123
   Wiggers K, 2021, GOOGLE TRAINED TRILL
   Woodie A., 2021, CHIP SHORTAGE SEEMS
   Wu S., 2021, YUAN 10 LARGE SCALE
   Wu X., 2021, J PHYS C SERIES, V1971
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Zeng W., 2021, PANGU ALPHA LARGE SC
   Zhai X., 2021, SCALING VISION TRANS
   Zhang Z, 2020, CPM LARGE SCALE GENE
   Zhang Zizhao, 2021, AGGREGATING NESTED T
   Zhou H., 2020, WAV2VEC 20 FRAMEWORK
   Zoph B, 2017, Arxiv, DOI arXiv:1611.01578
NR 164
TC 15
Z9 15
U1 1
U2 2
PY 2022
DI 10.1109/IJCNN55064.2022.9891914
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic; Neurosciences
DA 2023-11-11
ER

PT C
AU Zheng, S
   Chen, SY
   Song, PD
   Chen, RZ
   Li, XH
   Yan, SG
   Lin, DH
   Leng, JW
   Liang, Y
AF Zheng, Size
   Chen, Siyuan
   Song, Peidi
   Chen, Renze
   Li, Xiuhong
   Yan, Shengen
   Lin, Dahua
   Leng, Jingwen
   Liang, Yun
GP IEEE
TI Chimera: An Analytical Optimizing Framework for Effective
   Compute-intensive Operators Fusion
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
AB Machine learning models with various tensor operators are becoming ubiquitous in recent years. There are two types of operators in machine learning: compute-intensive operators (e.g., GEMM and convolution) and memory-intensive operators (e.g., ReLU and softmax). In emerging machine learning models, compute-intensive operators are usually organized in a chain structure. With the continual specialization of hardware, the gap between computing performance and memory bandwidth has become more prominent. Consequently, the implementations of many compute-intensive operator chains are bounded by memory bandwidth, and generating fused kernels to improve locality for these compute-intensive operators becomes necessary. But in existing machine learning compilers, there lack both precise analysis and efficient optimization for compute-intensive operator chains on different accelerators. As a result, they usually produce sub-optimal performance for these operator chains.
   In this paper, we propose Chimera, an optimizing framework that can efficiently improve the locality of compute-intensive operator chains on different hardware accelerators. In Chimera, each compute-intensive operator is composed of a series of computation blocks. To generate efficient fused kernels for the operator chains, optimizations for both inter-block and intrablock are required. For inter-block optimization, Chimera decides the optimized block execution order by minimizing the data movement volume among blocks using an analytical model. For intra-block optimization, Chimera uses unified replaceable micro kernels to apply hardware-specific optimizations for different accelerators. Finally, Chimera generates fused kernels for computeintensive operator chains. Evaluation of batch GEMM chains and convolution chains on CPU, GPU, and NPU shows that Chimera achieves up to 2:87x, 2:29x, and 2:39x speedups to hand-tuned libraries. Compared to state-of-the-art compilers, the speedups are up to 2:29x, 1:64x, and 1:14x for CPU, GPU, and NPU.
C1 [Zheng, Size; Chen, Siyuan; Song, Peidi; Chen, Renze; Liang, Yun] Peking Univ, Beijing, Peoples R China.
   [Li, Xiuhong; Yan, Shengen] Sensetime Res, Shanghai, Peoples R China.
   [Lin, Dahua] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Lin, Dahua] Shanghai Lab, Shanghai, Peoples R China.
   [Leng, Jingwen] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Liang, Yun] Beijing Adv Innovat Ctr Integrated Circuits, Beijing, Peoples R China.
RP Liang, Y (corresponding author), Peking Univ, Beijing, Peoples R China.; Liang, Y (corresponding author), Beijing Adv Innovat Ctr Integrated Circuits, Beijing, Peoples R China.
EM zhengsz@pku.edu.cn; chensiyuan@pku.edu.cn; ppppaidy@pku.edu.cn;
   crz@pku.edu.cn; lixiuhong@sensetime.com; yanshengen@sensetime.com;
   dhlin@ie.cuhk.edu.hk; leng-jw@sjtu.edu.cn; ericlyun@pku.edu.cn
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Alwani M, 2016, INT SYMP MICROARCH
   Ashari A, 2015, ACM SIGPLAN NOTICES, V50, P173, DOI [10.1145/2858788.2688521, 10.1145/2688500.2688521]
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Baghdadi R, 2019, INT SYM CODE GENER, P193, DOI [10.5281/zenodo.2375075, 10.1109/CGO.2019.8661197]
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TQ, 2018, ADV NEUR IN, V31
   developer.nvidia, NVIDIA CUDNN
   developer.nvidia, NVID CUBLAS
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   docs.nvidia, NVID TENSORRT
   Dosovitskiy A, 2021, INT C LEARNING REPRE
   e.huawei, HUAW COMP ARCH NEUR
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   github, NVID CUTLASS
   github, INT ONEAPI DEEP NEUR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P943, DOI 10.1145/3445814.3446762
   Huang QJ, 2021, CONF PROC INT SYMP C, P554, DOI 10.1109/ISCA52012.2021.00050
   Jia ZH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P47, DOI 10.1145/3341301.3359630
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Li R, 2021, Arxiv, DOI arXiv:2101.09808
   Li R, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P928, DOI 10.1145/3445814.3446759
   Li XH, 2019, PROCEEDINGS OF THE 24TH SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '19), P229, DOI 10.1145/3293883.3295734
   Liang Y, 2015, IEEE T PARALL DISTR, V26, P748, DOI 10.1109/TPDS.2014.2313342
   Liao H, 2021, INT S HIGH PERF COMP, P789, DOI 10.1109/HPCA51647.2021.00071
   Low TM, 2016, ACM T MATH SOFTWARE, V43, DOI 10.1145/2925987
   Ma LX, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P881
   Meng J, 2021, I C FIELD PROG LOGIC, P9, DOI 10.1109/FPL53798.2021.00010
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Iandola FN, 2016, Arxiv, DOI [arXiv:1602.07360, 10.7717/peerj-cs.528/fig-8]
   Nakandala S, 2020, Arxiv, DOI arXiv:2010.04804
   Niu W, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P883, DOI 10.1145/3453483.3454083
   nvidia, NVID AMP WHIT
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roesch Jared, 2019, ARXIV
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sivathanu M, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P909, DOI 10.1145/3297858.3304072
   software.intel, INT ONEAPI MATH KERN
   Tolstikhin I, 2021, ARXIV
   Vasilache N, 2018, Arxiv, DOI arXiv:1802.04730
   Vaswani A, 2017, ADV NEUR IN, V30
   Wahib M, 2014, INT CONF HIGH PERFOR, P191, DOI 10.1109/SC.2014.21
   Wang XY, 2020, LECT NOTES COMPUT SC, V12247, P219, DOI 10.1007/978-3-030-57675-2_14
   Whatmough P. N., 2019, P MACHINE LEARNING S
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xiao QC, 2021, CONF PROC INT SYMP C, P1055, DOI 10.1109/ISCA52012.2021.00086
   Xing Jiarong, 2022, P MACHINE LEARNING S
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhao J, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P1233, DOI 10.1145/3453483.3454106
   Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863
   Zheng S., 2021, IEEE T PARALL DISTR
   Zheng SX, 2022, INT S HIGH PERF COMP, P475, DOI 10.1109/HPCA53966.2022.00042
   Zheng SZ, 2022, CONF PROC INT SYMP C, P874, DOI 10.1145/3470496.3527440
   Zheng SZ, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P859, DOI 10.1145/3373376.3378508
   Zheng Z, 2021, Arxiv, DOI arXiv:2009.10924
   Zheng Z, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P359, DOI 10.1145/3503222.3507723
   Zheng Z, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P587, DOI 10.1145/3123939.3123978
   Zhu HY, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P233
NR 65
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 1113
EP 1126
DI 10.1109/HPCA56546.2023.10071018
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Saikia, J
   Yin, SH
   Jiang, ZW
   Seok, M
   Seo, JS
AF Saikia, Jyotishman
   Yin, Shihui
   Jiang, Zhewei
   Seok, Mingoo
   Seo, Jae-sun
GP IEEE
TI K-Nearest Neighbor Hardware Accelerator Using In-Memory Computing SRAM
SO 2019 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN (ISLPED)
SE International Symposium on Low Power Electronics and Design
DT Proceedings Paper
CT IEEE/ACM International Symposium on Low Power Electronics and Design
   (ISLPED)
CY JUL 29-31, 2019
CL Lausanne, SWITZERLAND
DE k-nearest neighbor; content addressable memory; in-memory computing;
   hardware accelerator
AB The k-nearest neighbor (kNN) is one of the most popular algorithms in machine learning owing to its simplicity, versatility, and implementation viability without any assumptions about the data. However, for large-scale data, it incurs a large amount of memory access and computational complexity, resulting in long latency and high power consumption. In this paper, we present a kNN hardware accelerator in 65nm CMOS. This accelerator combines in-memory computing SRAM that is recently developed for binarized deep neural networks and digital hardware that performs top-k sorting. We designed and simulated the kNN accelerator, which performs up to 17.9 million query vectors per second while consuming 11.8 mW, demonstrating >4.8X energy improvement over prior works.
C1 [Saikia, Jyotishman; Yin, Shihui; Seo, Jae-sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
   [Jiang, Zhewei; Seok, Mingoo] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
RP Saikia, J (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
EM jsaikia@asu.edu
CR Anh Tuan Do, 2013, 2013 Proceedings of the ESSCIRC. 39th European Solid State Circuits Conference (ESSCIRC), P209, DOI 10.1109/ESSCIRC.2013.6649109
   Bremler-Barr A., 2015, P 11 INT WORKSH DAT
   Choi W, 2018, DES AUT CON, DOI 10.1145/3195970.3196014
   Hong I., 2013, IEEE S VLSI CIRC
   Huang PT, 2011, IEEE J SOLID-ST CIRC, V46, P507, DOI 10.1109/JSSC.2010.2082270
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107, DOI DOI 10.5555/3157382.3157557
   Imani M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P228
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jiang YN, 2017, SCI REP-UK, V7, DOI 10.1038/srep45233
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kaplan R, 2018, IEEE T NANOTECHNOL, V17, P889, DOI 10.1109/TNANO.2018.2799872
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Kim G, 2013, IEEE J SOLID-ST CIRC, V48, P1615, DOI 10.1109/JSSC.2013.2253220
   Lee VT, 2017, INT PARALL DISTRIB P, P523, DOI 10.1109/IPDPS.2017.12
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
NR 19
TC 12
Z9 12
U1 0
U2 1
PY 2019
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Wang, HD
   Choy, CS
AF Wang, Hongda
   Choy, Chiu-Sing
BE Chakrabarti, S
   Saha, HN
TI Hardware acceleration of support vector machine based on high level
   synthesis
SO 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE
   COMMUNICATION CONFERENCE (IEMCON)
DT Proceedings Paper
CT 9th IEEE Annual Information Technology, Electronics and Mobile
   Communication Conference (IEMCON)
CY NOV 01-03, 2018
CL Univ British Columbia, Vancouver, CANADA
HO Univ British Columbia
DE support vector machine; high level synthesis; FPGA
AB Hardware accelerator design of machine learning algorithms is of great significance since huge amount of data are generated continuously and the computation load keeps increasing fast. Traditional solutions which rely on general purpose processors like X86 CPUs and ARM embedded processors cannot achieve high computation performance and energy efficiency due to lack of adaptability to specific algorithms. Domain-specific hardware accelerator is a promising alternative solution since the hardware is specifically designed to deal with one type of problems, the computation performance and energy efficiency can outperform traditional solutions by more than one order of magnitude. In this paper, we have proposed a hardware accelerator for support vector machine based on high level synthesis. Through the proposed loop dependence analysis and batch processing method, the speedup can reach about 153x on Xilinx ZC706 with unroll factor of 160, which is very close to its limit. This hardware implementation can be used in data centers as a coprocessor to accelerate the data processing speed in many classification applications.
C1 [Wang, Hongda; Choy, Chiu-Sing] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
RP Wang, HD (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM hdwang@ee.cuhk.edu.hk; cschoy@ee.cuhk.edu.hk
CR Altaf M. A. B., 2013, PROC IEEE INT SOLID, P100
   Bin Altaf M. A., 2015, IEEE J SOLID STATE C
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Lee KH, 2012, J SIGNAL PROCESS SYS, V69, P339, DOI 10.1007/s11265-012-0672-8
   Tsoutsouras V, 2017, J SIGNAL PROCESS SYS, V88, P127, DOI 10.1007/s11265-017-1230-1
   Wang JC, 2015, IEEE T VLSI SYST, V23, P1355, DOI 10.1109/TVLSI.2014.2335112
NR 7
TC 1
Z9 1
U1 0
U2 0
PY 2018
BP 956
EP 959
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Wang, J
   Gao, A
   Li, JX
AF Wang, Jie
   Gao, Ao
   Li, Jingxin
BE Lai, Y
   Wang, T
   Jiang, M
   Xu, G
   Liang, W
   Castiglione, A
TI Design of Face Detection Algorithm Accelerator Based on Vitis
SO ALGORITHMS AND ARCHITECTURES FOR PARALLEL PROCESSING, ICA3PP 2021, PT II
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 21st International Conference on Algorithms and Architectures for
   Parallel Processing (ICA3PP)
CY DEC 03-05, 2021
CL ELECTR NETWORK
DE Face detection; FPGA; Vitis; Deep learning; Hardware acceleration
ID DEEP NEURAL-NETWORKS
AB With the development of artificial intelligence, Machine learning based FPGA (Field Programmable Gate Array) is becoming more and more important, Compared with CPU and GPU, FPGA has the advantages of reconfigurability, low power consumption and high performance of parallel computing. Due to the complexity of FPGA development process. This can be said to be the biggest obstacle for FPGA to be widely used in the field of artificial intelligence. In this paper, the FPGA accelerator is designed by a concise computation framework. This development method shortens the development time. And the accelerator built in this paper detection speed is 9 times that of CPU. The detection power consumption is about 0.1 times that of GPU.
C1 [Wang, Jie; Gao, Ao; Li, Jingxin] Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
   [Wang, Jie; Gao, Ao; Li, Jingxin] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian, Peoples R China.
RP Wang, J (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.; Wang, J (corresponding author), Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian, Peoples R China.
EM wang_jie@dlut.edu.cn
CR Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Lin C, 2021, IEEE ACM T NETWORK, V29, P2478, DOI 10.1109/TNET.2021.3095280
   Lin C, 2019, IEEE INFOCOM SER, P1819, DOI [10.1109/infocom.2019.8737589, 10.1109/INFOCOM.2019.8737589]
   Lin C, 2019, IEEE INFOCOM SER, P856, DOI [10.1109/infocom.2019.8737403, 10.1109/INFOCOM.2019.8737403]
   Lin C, 2018, IEEE INFOCOM SER, P99, DOI 10.1109/INFOCOM.2018.8486402
   Lin C, 2018, IEEE T MOBILE COMPUT, V17, P211, DOI 10.1109/TMC.2017.2703094
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma Y, 2020, IEEE T COMPUT AID D, V39, P424, DOI 10.1109/TCAD.2018.2884972
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Park J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS-ASIA (ICCE-ASIA)
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Seng KP, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080895
   Wang T, 2021, IEEE T COMPUT, V70, P1285, DOI 10.1109/TC.2021.3060484
   Wang T, 2022, IEEE T NETW SCI ENG, V9, P2015, DOI 10.1109/TNSE.2021.3083263
   Windh S, 2015, P IEEE, V103, P390, DOI 10.1109/JPROC.2015.2399275
   Wu YK, 2020, INFORM SCIENCES, V508, P79, DOI 10.1016/j.ins.2019.08.064
   Yu YX, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P122, DOI 10.1145/3373087.3375311
NR 23
TC 0
Z9 0
U1 1
U2 2
PY 2022
VL 13156
BP 546
EP 554
DI 10.1007/978-3-030-95388-1_36
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Peng, XC
   Kaul, A
   Bakir, MS
   Yu, SM
AF Peng, Xiaochen
   Kaul, Ankit
   Bakir, Muhannad S.
   Yu, Shimeng
TI Heterogeneous 3-D Integration of Multitier Compute-in-Memory
   Accelerators: An Electrical-Thermal Co-Design
SO IEEE TRANSACTIONS ON ELECTRON DEVICES
DT Article
DE Compute-in-memory (CIM); emerging nonvolatile memory (eNVM);
   heterogeneous 3-D integration (H3D); machine learning accelerator;
   through-silicon via (TSV)
ID TECHNOLOGY
AB Emerging nonvolatile memory (eNVM)-based compute-in-memory (CIM) accelerators have been proven in silicon for machine learning at the macrolevel. To fully unleash the system-level benefits, the heterogeneous 3-D integration (H3D) using through-silicon via (TSV) is a promising approach, to: 1) address the challenges of areahungry peripheries in CIM accelerators; 2) solve the 2-D scaling challenges of eNVM; and 3) stack enormous amount of embedded memories that are required in state-of-theart deep neural network models. This article presents an electrical-thermal co-design of multitier CIM accelerators, based on SRAMand/oreNVM, with hybrid technology nodes for logic andmemory tiers. We benchmark the CIMaccelerators on 8-bit ResNet-34 for ImageNet recognition, with layerby-layer and pipelined schemes, respectively. By sweeping TSV diameter from 30 mu m to 100 nm, we investigate the tradeoffs of system performance metrics (TOPS/W, TOPS, and TOPS/mm(2)) and H3D challenges (thermal and IR-drop in power delivery). Finally, we find the sweet spot of TSV diameter for multitier H3D system is 1-3 mu m, to guarantee balanced area-overhead, performance, and IR-drop in power delivery. The extended benchmark framework is released onGitHub ( https:// github. com/ neurosim) as an open-source tool for the research community.
C1 [Peng, Xiaochen; Kaul, Ankit; Bakir, Muhannad S.; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Peng, XC (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM xpeng76@gatech.edu; shimeng.yu@ece.gatech.edu
CR [Anonymous], 3D NEUROSIM FRAMEWOR
   Athikulwongse K, 2010, ICCAD-IEEE ACM INT, P669, DOI 10.1109/ICCAD.2010.5654245
   Beyne E, 2020, P IEEE S VLSI TECHN, P1
   Chen MF, 2020, IEEE T ELECTRON DEV, V67, P5343, DOI 10.1109/TED.2020.3021358
   Cheng YK, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372005
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Fisher DW, 2020, ELEC COMP C, P595, DOI 10.1109/ECTC32862.2020.00099
   He WX, 2020, IEEE SOLID-ST CIRC L, V3, P194, DOI 10.1109/LSSC.2020.3010795
   Jourdain A, 2020, ELEC COMP C, P42, DOI 10.1109/ECTC32862.2020.00020
   Kaul A, 2020, ELEC COMP C, P1459, DOI 10.1109/ECTC32862.2020.00231
   Lee DU, 2014, ISSCC DIG TECH PAP I, V57, P432, DOI 10.1109/ISSCC.2014.6757501
   Okoro C, 2007, ELEC COMP C, P249, DOI 10.1109/ECTC.2007.373805
   Peng XC, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372091
   Peng XC, 2020, IEEE T CIRCUITS-I, V67, P1333, DOI 10.1109/TCSI.2019.2958568
   Shim W, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405210
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Thadesar PA, 2016, IEEE T COMP PACK MAN, V6, P1009, DOI 10.1109/TCPMT.2016.2524691
   Thadesar PA, 2013, IEEE INT INTERC TECH
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yang YK, 2020, NEURAL NETWORKS, V125, P70, DOI 10.1016/j.neunet.2019.12.027
   Yu SM, 2021, IEEE T CIRCUITS-I, V68, P2753, DOI 10.1109/TCSI.2021.3072200
   Zhang Y, 2014, IEEE T COMP PACK MAN, V4, P1914, DOI 10.1109/TCPMT.2014.2364742
NR 22
TC 5
Z9 5
U1 4
U2 15
PD NOV
PY 2021
VL 68
IS 11
BP 5598
EP 5605
DI 10.1109/TED.2021.3111857
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Jasemi, M
   Hessabi, S
   Bagherzadeh, N
AF Jasemi, Masoomeh
   Hessabi, Shaahin
   Bagherzadeh, Nader
TI Enhancing Reliability of Emerging Memory Technology for Machine Learning
   Accelerators
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Computer architecture; Microprocessors; Reliability; Nonvolatile memory;
   Resistance; Magnetic tunneling; Random access memory; Fixed-point;
   floating-point; computer arithmetic; machine learning; MLC STT-RAM;
   reliability; accelerators
AB An efficient and reliable Multi-Level Cell (MLC) Spin-Transfer Torque Random Access Memory (STT-RAM) is proposed based on a Drop-And-Rearrange Approach, called DARA. Since CNN models are rather robust, less important bits are dropped, allowing important bits to be written in safe and reliable Single-Level Cell mode. Also, bits are rearranged to make the representation better aligned with memory cell characteristics. Bits with higher impact on the features value are stored in safer bit positions reducing the chance of read/write circuits to malfunction. Experimental results show that our approach provides comparable to error-free scenario reliability level, while doubling the bandwidth and maintaining error rate of less than 0.02 percent.
C1 [Jasemi, Masoomeh; Hessabi, Shaahin] Sharif Univ Technol, Dept Comp Engn, Tehran 1458889694, Iran.
   [Jasemi, Masoomeh; Bagherzadeh, Nader] Univ Calif Irvine, Elect Engn & Comp Sci Dept, Irvine, CA 92697 USA.
RP Jasemi, M (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran 1458889694, Iran.
EM mjasemi@uci.edu
CR Chen A, 2019, IEEE DES TEST, V36, P46, DOI 10.1109/MDAT.2019.2902359
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cheng XD, 2016, IEEE VTS VEH TECHNOL, DOI 10.1109/VTCSpring.2016.7504065
   Diao ZT, 2007, J PHYS-CONDENS MAT, V19, DOI 10.1088/0953-8984/19/16/165209
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Gupta S, 2015, I C DEPEND SYS NETWO, P37, DOI 10.1109/DSN.2015.52
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   Jasemi M., 2020, RELIABLE ENERGY EFFI
   Li GP, 2018, IEEE INT SYMP SOFTW, P313, DOI [10.1109/ISSREW.2018.00024, 10.1109/1SSREW.2018.00024]
   Liu, 2015, IEEE T COMPUT AID D, V37, P1985
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Ranjan A. K., 2015, PROC INT C CIRCUITS, P1
   Ryu S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317784
   Song LL, 2017, IEEE T VLSI SYST, V25, P1285, DOI 10.1109/TVLSI.2016.2644279
   Wen WJ, 2014, DES AUT CON
   Zhang YJ, 2012, ICCAD-IEEE ACM INT, P526
NR 16
TC 1
Z9 1
U1 0
U2 0
PD OCT 1
PY 2021
VL 9
IS 4
BP 2234
EP 2240
DI 10.1109/TETC.2020.2984992
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT J
AU Savich, A
   Areibi, S
AF Savich, Antony
   Areibi, Shawki
TI A Low-Power Scalable Stream Compute Accelerator for General Matrix
   Multiply (GEMM)
SO VLSI DESIGN
DT Article
AB Many applications ranging from machine learning, image processing, and machine vision to optimization utilize matrix multiplication as a fundamental block. Matrix operations play an important role in determining the performance of such applications. This paper proposes a novel efficient, highly scalable hardware accelerator that is of equivalent performance to a 2 GHz quad core PC but can be used in low-power applications targeting embedded systems requiring high performance computation. Power, performance, and resource consumption are demonstrated on a fully-functional prototype. The proposed hardware accelerator is 36x more energy efficient per unit of computation compared to state-of-the-art Xeon processor of equal vintage and is 14x more efficient as a stand-alone platform with equivalent performance. An important comparison between simulated system estimates and real system performance is carried out.
C1 [Savich, Antony; Areibi, Shawki] Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
RP Savich, A (corresponding author), Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
EM asavich@uoguelph.ca
CR Bensaali F, 2005, IEE P-CIRC DEV SYST, V152, P236, DOI 10.1049/ip-cds:20040838
   Dave N, 2007, MEMOCODE'07: FIFTH ACM & IEEE INTERNATIONAL CONFERENCE ON FORMAL METHODS AND MODELS FOR CO-DESIGN, PROCEEDINGS, P97, DOI 10.1109/MEMCOD.2007.371239
   Jang JW, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P93, DOI 10.1109/FPT.2002.1188669
   Jiang JA, 2009, 2009 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS, P48, DOI 10.1109/ReConFig.2009.30
   Kumar VBY, 2010, INT J PARALLEL PROG, V38, P322, DOI 10.1007/s10766-010-0131-8
   Lin Colin Yu, 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P369, DOI 10.1109/FPT.2010.5681425
   Qasim A., 2010, P WORLD C ENG COMP S, V1, P1
   Sotiropoulos I, 2009, I C FIELD PROG LOGIC, P276, DOI 10.1109/FPL.2009.5272287
   Vucha M., 2011, INT J COMPUTER APPL, V26, P18, DOI DOI 10.5120/3084-4222
   Yang DP, 2009, ANN IEEE SYM FIELD P, P303, DOI 10.1109/FCCM.2009.47
NR 10
TC 1
Z9 1
U1 0
U2 0
PY 2014
AR 712085
DI 10.1155/2014/712085
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Shiflett, K
   Wright, D
   Karanth, A
   Louri, A
AF Shiflett, Kyle
   Wright, Dylan
   Karanth, Avinash
   Louri, Ahmed
GP IEEE
TI PIXEL: Photonic Neural Network Accelerator
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2020)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 26th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 22-26, 2020
CL San Diego, CA
DE deep neural network; machine learning; silicon photonics; accelerator;
   microring resonator; Mach-Zehnder interferometer
ID ON-CHIP; LOGIC; CIRCUIT
AB Machine learning (ML) architectures such as Deep Neural Networks (DNNs) have achieved unprecedented accuracy on modern applications such as image classification and speech recognition. With power dissipation becoming a major concern in ML architectures, computer architects have focused on designing both energy-efficient hardware platforms as well as optimizing ML algorithms. To dramatically reduce power consumption and increase parallelism in neural network accelerators, disruptive technology such as silicon photonics has been proposed which can improve the performance-per-Watt when compared to electrical implementation. In this paper, we propose PIXEL - Photonic Neural Network Accelerator that efficiently implements the fundamental operation in neural computation, namely the multiply and accumulate (MAC) functionality using photonic components such as microring resonators (MRRs) and Mach-Zehnder interferometer (MZI). We design two versions of PIXEL - a hybrid version that multiplies optically and accumulates electrically and a fully optical version that multiplies and accumulates optically. We perform a detailed power, area and timing analysis of the different versions of photonic and electronic accelerators for different convolution neural networks (AlexNet, VGG16, and others). Our results indicate a significant improvement in the energy-delay product for both PIXEL designs over traditional electrical designs (48.4% for OE and 73.9% for OO) while minimizing latency, at the cost of increased area over electrical designs.
C1 [Shiflett, Kyle; Wright, Dylan; Karanth, Avinash] Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
   [Louri, Ahmed] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
RP Shiflett, K (corresponding author), Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
EM ks117713@ohio.edu; dw437013@ohio.edu; karanth@ohio.edu; louri@gwu.edu
CR Ahn J, 2009, APPL PHYS A-MATER, V95, P989, DOI 10.1007/s00339-009-5109-2
   [Anonymous], 2013, INT J COMPUT APPL
   [Anonymous], APPL PHYS
   [Anonymous], OPTICS LETT
   Azizimazreah A, 2019, INT S HIGH PERF COMP, P94, DOI 10.1109/HPCA.2019.00030
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Clark M, 2018, DES AUT CON, DOI 10.1145/3195970.3196068
   Demir Y, 2016, INT S HIGH PERF COMP, P321, DOI 10.1109/HPCA.2016.7446075
   Ding JF, 2013, J LIGHTWAVE TECHNOL, V31, P2434, DOI 10.1109/JLT.2013.2262522
   Ding L, 2012, PROCEEDINGS OF ISCRAM ASIA 2012 CONFERENCE ON INFORMATION SYSTEMS FOR CRISIS RESPONSE AND MANAGEMENT, P201
   DiTomaso D, 2016, INT SYMP MICROARCH
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fettes Q, 2019, IEEE T COMPUT, V68, P375, DOI 10.1109/TC.2018.2875476
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Georgas M, 2011, IEEE CUST INTEGR CIR
   Guoliang Li, 2013, IEEE Journal of Selected Topics in Quantum Electronics, V19, DOI 10.1109/JSTQE.2013.2278885
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2016, INT SYMP MICROARCH
   Kirman N, 2006, INT SYMP MICROARCH, P492
   Kirman N, 2010, ASPLOS XV: FIFTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P15
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Li GL, 2011, OPT EXPRESS, V19, P20435, DOI 10.1364/OE.19.020435
   Manipatruni S, 2010, OPT EXPRESS, V18, P18235, DOI 10.1364/OE.18.018235
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Miller DAB, 2015, OPTICA, V2, P747, DOI 10.1364/OPTICA.2.000747
   Miller DAB, 2013, OPT EXPRESS, V21, P6360, DOI 10.1364/OE.21.006360
   Miller DAB, 2009, P IEEE, V97, P1166, DOI 10.1109/JPROC.2009.2014298
   Morris R, 2012, INT SYMP MICROARCH, P282, DOI 10.1109/MICRO.2012.34
   Namin AH, 2009, IEEE INT SYMP CIRC S, P2117, DOI 10.1109/ISCAS.2009.5118213
   Pan Y, 2009, CONF PROC INT SYMP C, P429, DOI 10.1145/1555815.1555808
   Patel S, 2008, IEEE MICRO, V28, P4, DOI 10.1109/MM.2008.50
   Pérez D, 2018, OPT EXPRESS, V26, P27265, DOI 10.1364/OE.26.027265
   Prucnal PR, 2017, NEUROMORPHIC PHOTONICS, P1
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qiu CY, 2012, OPT LETT, V37, P3942, DOI 10.1364/OL.37.003942
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Ribeiro A, 2016, OPTICA, V3, P1348, DOI 10.1364/OPTICA.3.001348
   Shacham A, 2008, IEEE T COMPUT, V57, P1246, DOI 10.1109/TC.2008.78
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Sun C, 2015, NATURE, V528, P534, DOI 10.1038/nature16454
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tait AN, 2015, OPT EXPRESS, V23, P12758, DOI 10.1364/OE.23.012758
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Van Winkle S, 2018, INT S HIGH PERF COMP, P480, DOI 10.1109/HPCA.2018.00048
   Vantrease D, 2008, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA.2008.35
   Wang K, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P589, DOI 10.1145/3307650.3322274
   Wang K, 2019, DES AUT TEST EUROPE, P1166, DOI [10.23919/date.2019.8714869, 10.23919/DATE.2019.8714869]
   Xu L, 2012, IEEE PHOTONIC TECH L, V24, P473, DOI 10.1109/LPT.2011.2180374
   Xu QF, 2007, OPT EXPRESS, V15, P924, DOI 10.1364/OE.15.000924
   Xu QF, 2011, OPT EXPRESS, V19, P5244, DOI 10.1364/OE.19.005244
   Zamanlooy B, 2014, IEEE T VLSI SYST, V22, P39, DOI 10.1109/TVLSI.2012.2232321
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang L, 2012, OPT EXPRESS, V20, P11605, DOI 10.1364/OE.20.011605
   Zheng H, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317768
   Zheng XZ, 2012, J LIGHTWAVE TECHNOL, V30, P641, DOI 10.1109/JLT.2011.2179287
   Ziabari AK, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P273, DOI 10.1145/2751205.2751229
NR 62
TC 21
Z9 24
U1 2
U2 11
PY 2020
BP 474
EP 487
DI 10.1109/HPCA47549.2020.00046
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Yi, W
   Park, J
   Kim, JJ
AF Yi, Wooseok
   Park, Junki
   Kim, Jae-Joon
TI GeCo: Classification Restricted Boltzmann Machine Hardware for On-Chip
   Semisupervised Learning and Bayesian Inference
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Hardware; Training; Neurons; System-on-chip; Inference algorithms;
   Semisupervised learning; Bayes methods; Bayesian inference;
   classification restricted Boltzmann machine (ClassRBM); generative core
   (GeCo); generative model; hardware accelerator; neural network; on-chip
   learning; restricted Boltzmann machine (RBM); semisupervised
AB The probabilistic Bayesian inference of real-time input data is becoming more popular, and the importance of semisupervised learning is growing. We present a classification restricted Boltzmann machine (ClassRBM)-based hardware accelerator with on-chip semisupervised learning and Bayesian inference capability. ClassRBM is a specific type of Markov network that can perform classification tasks and reconstruct its input data. ClassRBM has several advantages in terms of hardware implementation compared to other backpropagation-based neural networks. However, its accuracy is relatively low compared to backpropagation-based learning. To improve the accuracy of ClassRBM, we propose the multi-neuron-per-class (multi-NPC) voting scheme. We also reveal that the contrastive divergence (CD) algorithm, which is commonly used to train RBM, shows poor performance in this multi-NPC ClassRBM. As an alternative, we propose an asymmetric contrastive divergence (ACD) training algorithm that improves the accuracy of multi-NPC ClassRBM. With the ACD learning algorithm, ClassRBM operates in the form of a combination of Markov Chain training and Bayesian inference. The experimental results on a field-programmable gate array (FPGA) board for a Modified National Institute of Standards and Technology data set confirm that the inference accuracy of the proposed ACD algorithm is 5.82% higher for a supervised learning case and 12.78% higher for a 1% labeled semisupervised learning case than the conventional CD algorithm. Also, the GeCo ver.2 hardware implemented on a Xilinx ZCU102 FPGA board was 349.04 times faster than the C simulation on CPU.
C1 [Yi, Wooseok; Park, Junki; Kim, Jae-Joon] Pohang Univ Sci & Technol POSTECH, Dept Creat IT Engn, Pohang 37673, South Korea.
RP Kim, JJ (corresponding author), Pohang Univ Sci & Technol POSTECH, Dept Creat IT Engn, Pohang 37673, South Korea.
EM wooseok.yi@postech.ac.kr; junkipark@postech.ac.kr; jaejoon@postech.ac.kr
CR [Anonymous], [No title captured]
   [Anonymous], 2010, P INT JOINT C NEURAL
   Caner H, 2008, IEEE T VEH TECHNOL, V57, P2675, DOI 10.1109/TVT.2008.915524
   Chen DD, 2018, IEEE T NEUR NET LEAR, V29, P2651, DOI 10.1109/TNNLS.2017.2692773
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jung S, 2007, IEEE T IND ELECTRON, V54, P265, DOI 10.1109/TIE.2006.888791
   Kim LW, 2018, IEEE T NEUR NET LEAR, V29, P1441, DOI 10.1109/TNNLS.2017.2665555
   Kim LW, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2539125
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Larochelle H, 2012, J MACH LEARN RES, V13, P643
   Lasserre JA., 2006, IEEE COMPUTER SOCIET, V1, P87, DOI DOI 10.1109/CVPR.2006.227
   Liu J, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, P371, DOI 10.1109/ISCAS.1999.777586
   Marukame T, 2017, IEEE T CIRCUITS-II, V64, P462, DOI 10.1109/TCSII.2016.2585675
   Masud MM, 2012, KNOWL INF SYST, V33, P213, DOI 10.1007/s10115-011-0447-8
   Neftci E, 2014, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00272
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Park SW, 2015, IEEE T BIOMED CIRC S, V9, P838, DOI 10.1109/TBCAS.2015.2504563
   Savich A. W., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P35, DOI 10.1109/ReConFig.2011.79
   Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293
   Susskind Joshua M, 2008, AFFECTIVE COMPUTING
   Vanhoucke V., 2011, PROC DEEP LEARN UNS, V1, P4
   Wan L., 2013, P 30 INT C MACH LEAR, V28, P1058
   Wooseok Yi, 2017, 2017 International Symposium on Rapid System Prototyping (RSP), P30, DOI 10.1145/3130265.3138856
   Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002
NR 29
TC 6
Z9 6
U1 1
U2 16
PD JAN
PY 2020
VL 31
IS 1
BP 53
EP 65
DI 10.1109/TNNLS.2019.2899386
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yousefzadeh, S
   Basharkhah, K
   Nosrati, N
   Rajabalipanah, M
   Ghasemi, SM
   Navabi, Z
AF Yousefzadeh, Saba
   Basharkhah, Katayoon
   Nosrati, Nooshin
   Rajabalipanah, Maryam
   Ghasemi, Seyedeh Maryam
   Navabi, Zainalabedin
GP IEEE
TI Reconfiguration of Embedded Accelerators by Microprogramming for
   Intensive Loop Computations
SO 2020 23RD INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS & SYSTEMS (DDECS 2020)
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 23rd IEEE International Symposium on Design and Diagnostics of
   Electronic Circuits and Systems (DDECS)
CY APR 22-24, 2020
CL Univ Novi Sad, Novi Sad, SERBIA
HO Univ Novi Sad
DE Microprogramming; Accelerator; Reconfigurability; Microinstructions;
   FPGA prototyping
AB The work presented in this paper is on reconfigurable accelerators for the implementation of iterative computations and loops that form the core computations of applications like those in digital signal processing and machine learning. The accelerators become computation engines of an embedded system that can be reconfigured by an embedded processor for handling various kernels of embedded applications. This paper presents our MicroProgramed Configurable Accelerator (iMPAC) architecture and compares implementing a kernel (here a matrix multiplication) on this architecture with a) a program running of an embedded processor and b) with a hardwired controller accelerator. Our prototyping on an FPGA shows very little penalty in terms of energy consumption and required clock cycles when compared with the latter, and significant improvement of both energy and timing when compared with the former. At the same time, we have the programming flexibility of the former.
C1 [Yousefzadeh, Saba; Basharkhah, Katayoon; Nosrati, Nooshin; Rajabalipanah, Maryam; Ghasemi, Seyedeh Maryam; Navabi, Zainalabedin] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
RP Yousefzadeh, S (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
EM saba.yousefzadeh@ut.ac.ir; basharkhah.kt96@ut.ac.ir;
   nosrati.nooshin@ut.ac.ir; m.rajabalipanah@ut.ac.ir;
   s_ma_ghasemy@ut.ac.ir; navabi@ut.ac.ir
CR Das S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351749
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   Santoro G, 2018, DES AUT TEST EUROPE, P1151, DOI 10.23919/DATE.2018.8342185
   Youssef S.B.H., 2019, IEEE WCNC, P1, DOI DOI 10.1109/wcnc.2019.8885479
NR 4
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/ddecs50862.2020.9095688
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, CM
   Geng, T
   Guo, AQ
   Tian, JN
   Herbordt, M
   Li, A
   Tao, DW
AF Zhang, Chengming
   Geng, Tong
   Guo, Anqi
   Tian, Jiannan
   Herbordt, Martin
   Li, Ang
   Tao, Dingwen
GP IEEE
TI H-GCN: A Graph Convolutional Network Accelerator on Versal ACAP
   Architecture
SO 2022 32ND INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS, FPL
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 32nd International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2022
CL Belfast, NORTH IRELAND
AB Graph Neural Networks (GNNs) have drawn tremendous attention due to their unique capability to extend Machine Learning (ML) approaches to applications broadly-defined as having unstructured data, especially graphs. Compared with other Machine Learning (ML) modalities, the acceleration of Graph Neural Networks (GNNs) is more challenging due to the irregularity and heterogeneity derived from graph typologies. Existing efforts, however, have focused mainly on handling graphs' irregularity and have not studied their heterogeneity. To this end we propose H-GCN, a PL (Programmable Logic) and AIE (AI Engine) based hybrid accelerator that leverages the emerging heterogeneity of Xilinx Versal Adaptive Compute Acceleration Platforms (ACAPs) to achieve high-performance GNN inference. In particular, H-GCN partitions each graph into three subgraphs based on its inherent heterogeneity, and processes them using PL and AIE, respectively. To further improve performance, we explore the sparsity support of AIE and develop an efficient density-aware method to automatically map tiles of sparse matrix-matrix multiplication (SpMM) onto the systolic tensor array. Compared with state-of-the-art GCN accelerators, H-GCN achieves, on average, speedups of 1.1 similar to 2.3x.
C1 [Zhang, Chengming; Tian, Jiannan; Tao, Dingwen] Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA.
   [Geng, Tong; Li, Ang] Pacific Northwest Natl Lab, Math & Comp Sci Div, Richland, WA 99352 USA.
   [Guo, Anqi; Herbordt, Martin] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.
   [Geng, Tong] Univ Rochester, Dept Elect & Comp Engn, Rochester, NY USA.
   [Zhang, Chengming; Tao, Dingwen] Indiana Univ, Sch Informat Comp & Engn, Bloomington, IN 47405 USA.
RP Tao, DW (corresponding author), Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA.; Tao, DW (corresponding author), Indiana Univ, Sch Informat Comp & Engn, Bloomington, IN 47405 USA.
EM dingwen.tao@wsu.edu
CR [Anonymous], 2022, VCK5000 VERS DEV CAR
   Arai J, 2016, INT PARALL DISTRIB P, P22, DOI 10.1109/IPDPS.2016.110
   Bojchevski Aleksandar, 2017, ARXIV170703815
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Corradi G., 2020, IEEE INT ULTRASONICS, P1, DOI DOI 10.1109/IUS46767.2020.9251749
   Errica Federico, 2019, ARXIV191209893
   Fey M., ARXIV190302428, V2019
   Gaide B, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P84, DOI 10.1145/3289602.3293906
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Geng Tong, 2021, MICRO54 54 ANN IEEE, P1051
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Hamilton WL., 2017, ADV NEURAL INFORM PR, V2017, P1025, DOI DOI 10.48550/ARXIV.1706.02216
   Kipf T. N., 2017, PROC 5 INT C LEARN R, P1, DOI DOI 10.48550/ARXIV.1609.02907
   LaSalle D, 2013, INT PARALL DISTRIB P, P225, DOI 10.1109/IPDPS.2013.50
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li XM, 2019, J CHEM INF MODEL, V59, P1044, DOI 10.1021/acs.jcim.8b00672
   Liang S., 2020, IEEE T COMPUTERS
   Lumsdaine A, 2007, PARALLEL PROCESS LET, V17, P5, DOI 10.1142/S0129626407002843
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Srivastava N, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P766, DOI 10.1109/MICRO50266.2020.00068
   Wang MX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P803
   Xilinx, 2022, US
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yang ZH, 2016, J INEQUAL APPL, DOI 10.1186/s13660-016-0988-1
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Zeng H., 2019, ARXIV PREPRINT ARXIV
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhang BY, 2021, ANN IEEE SYM FIELD P, P29, DOI 10.1109/FCCM51124.2021.00012
   Zhang BY, 2020, IEEE INT CONF ASAP, P61, DOI 10.1109/ASAP49362.2020.00019
   Zhang MH, 2018, ADV NEUR IN, V31
   Zhang Xiaotong, 2019, ARXIV190601210
   Zhou F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2357, DOI 10.1145/3357384.3358106
NR 32
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 200
EP 208
DI 10.1109/FPL57034.2022.00040
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Liu, ZH
   Yazdanbakhsh, A
   Park, T
   Esmaeilzadeh, H
   Kim, NS
AF Liu, Zhenhong
   Yazdanbakhsh, Amir
   Park, Taejoon
   Esmaeilzadeh, Hadi
   Kim, Nam Sung
TI SiMul: An Algorithm-Driven Approximate Multiplier Design for Machine
   Learning
SO IEEE MICRO
DT Article
AB The need to support various machine learning (ML) algorithms on energy-constrained computing devices has steadily grown. In this article, we propose an approximate multiplier, which is a key hardware component in various ML accelerators. Dubbed SiMul, our approximate multiplier features user-controlled precision that exploits the common characteristics of ML algorithms. SiMul supports a tradeoff between compute precision and energy consumption at runtime, reducing the energy consumption of the accelerator while satisfying a desired inference accuracy requirement. Compared improves the energy efficiency of multiplication by 11.6x to 3.2x while achieving 81.7-percent to 98.5-percent precision for individual multiplication operations (96.0-, 97.8-, and 97.7-percent inference accuracy for three distinct applications, respectively, compared to the baseline inference accuracy of 98.3, 99.0, and 97.7 percent using precise multipliers). A neural accelerator implemented with our multiplier can provide 1.7x (up to 2.1x) higher energy efficiency over one implemented with the precise multiplier with a negligible impact on the accuracy of the output for various applications.
C1 [Liu, Zhenhong; Kim, Nam Sung] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
   [Yazdanbakhsh, Amir] Georgia Inst Technol, Alternat Comp Technol ACT Lab, Atlanta, GA 30332 USA.
   [Park, Taejoon] Hanyang Univ, Dept Robot Engn, Seoul, South Korea.
   [Park, Taejoon] Hanyang Univ, Collaborat AI Robot Engn CARE Ctr, Seoul, South Korea.
   [Esmaeilzadeh, Hadi] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Liu, ZH (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
EM zliu118@illinois.edu; a.yazdanbakhsh@gatech.edu; taejoon@hanyang.ac.kr;
   hadi@eng.ucsd.edu; nskim@illinois.edu
CR Albericio J., 2017, P 45 INT S COMP ARCH
   [Anonymous], 2015, P 48 INT S MICR
   [Anonymous], 2017, P 50 ANN IEEE ACM IN
   [Anonymous], P 38 INT S COMP ARCH
   Babic Z, 2011, MICROPROCESS MICROSY, V35, P23, DOI 10.1016/j.micpro.2010.07.001
   Chapman K., 1996, INT S LOW POW EL DES
   Chapman K., 1996, CONSTANT COEFFICIENT
   Esmaeilzadeh H., 2012, P 45 ANN IEEE ACM IN
   Gupta V., 2011, INT S LOW POW EL DES
   LeCun Y., MNIST DATABASE HANDW
   LeCun Y., MNIST DATABASE HANDW
   REAGEN B, 2016, INFORM PROCESSING LE, DOI DOI 10.1016/J.IPL.2005.05.019
   Sakhi O., FACE DETECTION USING
   Sakhi O., TI 46 WORD SPEECH DA
   Sharman H., 2018, P 50 ANN IEEE ACM IN
   Verstraeten D, 2005, INFORM PROCESS LETT, V95, P521, DOI 10.1016/j.ipl.2005.05.019
   Yazdanbakhsh A., 2015, P 47 DES AUT C DAC
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
   Yazdanbakhsh Amir, 2018, P 45 INT S COMP ARCH
NR 19
TC 13
Z9 13
U1 0
U2 2
PD JUL-AUG
PY 2018
VL 38
IS 4
BP 50
EP 59
DI 10.1109/MM.2018.043191125
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Tan, CY
   Ismail, N
   Ooi, CY
   Hon, JY
AF Tan, Chong Yeam
   Ismail, Nordinah
   Ooi, Chia Yee
   Hon, Jin Yong
TI Accelerating Extreme Learning Machine on FPGA by Hardware Implementation
   of Given Rotation - QRD
SO INTERNATIONAL JOURNAL OF INTEGRATED ENGINEERING
DT Article
DE Extreme Learning Machine (ELM); machine learning; field programmable
   gate array (FPGA); hardware implementation
AB Currently, Extreme Learning Machine (ELM) is one of the research trends in the machine learning field due to its remarkable performances in terms of complexity and computational speed. However, the big data era and the limitations of general-purpose processor cause the increasing of interest in hardware implementation of ELM in order to reduce the computational time. Hence, this work presents the hardware-software co-design of ELM to improve the overall performances. In the co-design paradigm, one of the important components of ELM, namely Given Rotation-QRD (GR-QRD) is developed as a hardware core. Field Programmable Gate Array (FPGA) is chosen as the platform for ELM implementation due to its reconfigurable capability and high parallelism. Moreover, the learning accuracy and computational time would be used to evaluate the performances of the proposed ELM design. Our experiment has shown that GR-QRD accelerator helps to reduce the computational time of ELM training by 41.75% while maintaining the same training accuracy in comparison to pure software of ELM.
C1 [Tan, Chong Yeam; Ismail, Nordinah; Ooi, Chia Yee; Hon, Jin Yong] Univ Teknol Malaysia, Embedded Syst Res Lab, MJIIT, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
RP Ismail, N (corresponding author), Univ Teknol Malaysia, Embedded Syst Res Lab, MJIIT, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
EM nordinah.kl@utm.my
CR [Anonymous], 2009, INTRO EMBEDDED SYSTE
   Blake CL, 1998, UCI REPOSITORY MACHI
   Culler D., 2007, PARALLEL COMPUTER AR
   Erdos L., 2000, QR FACTORIZATION REV, P30
   Frances-Villora JV, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110308
   Frances-Villora JV, 2016, COMPUT ELECTR ENG, V51, P139, DOI 10.1016/j.compeleceng.2016.02.007
   Golub G. H., 2012, MATRIX COMPUTATIONS, V3
   Huang G. B., 2004, 2004 IEEE INTERNATIO
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang YW, 2012, AASRI PROC, V3, P375, DOI 10.1016/j.aasri.2012.11.059
   Ja'afar NH, 2012, INT J INTEGR ENG, V4, P26
   Kanhiroth Vazhoth, 2017, THESIS, P845
   Lightbody G, 2000, J VLSI SIG PROCESS S, V24, P67, DOI 10.1023/A:1008118711904
   Serre D., 2011, MATRICES THEORY APPL
   Sofian H, 2018, INT J INTEGR ENG, V10, P43, DOI 10.30880/ijie.2018.10.07.005
   Tsukada Mineto, 2018, P INT EUR C PAR DIST, P518
   Yeam TC, 2017, TENCON IEEE REGION, P1868, DOI 10.1109/TENCON.2017.8228163
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2019
VL 11
IS 7
SI SI
BP 31
EP 39
WC Engineering, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Blanquer, I
   Brasileiro, F
   Brito, A
   Calatrava, A
   Carvalho, A
   Fetzer, C
   Figueiredo, F
   Guimaraes, RP
   Marinho, L
   Meira, W
   Silva, A
   Alberich-Bayarri, A
   Camacho-Ramos, E
   Jimenez-Pastor, A
   Ribeiro, ALL
   Nascimento, BR
   Silva, F
AF Blanquer, Ignacio
   Brasileiro, Francisco
   Brito, Andrey
   Calatrava, Amanda
   Carvalho, Andre
   Fetzer, Christof
   Figueiredo, Flavio
   Guimaraes, Ronny Petterson
   Marinho, Leandro
   Meira, Wagner, Jr.
   Silva, Altigran
   Alberich-Bayarri, Angel
   Camacho-Ramos, Eduardo
   Jimenez-Pastor, Ana
   Ribeiro, Antonio Luiz L.
   Nascimento, Bruno Ramos
   Silva, Fabio
TI Federated and secure cloud services for building medical image
   classifiers on an intercontinental infrastructure
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
DT Article
DE Trustworthy cloud services; Federated clouds; Medical imaging
ID RHEUMATIC HEART-DISEASE; PLATFORM
AB Medical data processing has found a new dimension with the extensive use of machine-learning techniques to classify and extract features. Machine learning strongly benefits from computing accelerators. However, such accelerators are not easily available at hospital premises, although they can be easily found on public cloud infrastructures or research centers. Nevertheless, the sensitivity of medical data poses several challenges on the access to such data, requiring security guarantees and isolation. In this paper we present an architecture that addresses this problem. It keeps critical data encrypted in memory and disk, which can only be accessed inside trusted execution environments protected by hardware extensions. Data is anonymized inside these environments and securely transferred to external sites that host accelerator devices, keeping the same network space and reducing security risks even in untrusted cloud backends. Results on the processing of data in different scenarios are presented and discussed. The results are demonstrated on a geographically-wide deployment provided by the ATMOSPHERE project. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Blanquer, Ignacio; Calatrava, Amanda] Univ Politecn Valencia, Valencia, Spain.
   [Brasileiro, Francisco; Brito, Andrey; Marinho, Leandro; Silva, Fabio] Univ Fed Campina Grande, Campina Grande, Paraiba, Brazil.
   [Carvalho, Andre; Guimaraes, Ronny Petterson; Silva, Altigran] Univ Fed Amazonas, Manaus, Amazonas, Brazil.
   [Fetzer, Christof] Tech Univ Dresden, Dresden, Germany.
   [Figueiredo, Flavio; Meira, Wagner, Jr.; Ribeiro, Antonio Luiz L.; Nascimento, Bruno Ramos] Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil.
   [Alberich-Bayarri, Angel; Camacho-Ramos, Eduardo; Jimenez-Pastor, Ana] QUIBIM, Valencia, Spain.
RP Blanquer, I (corresponding author), Univ Politecn Valencia, Valencia, Spain.
EM iblanque@dsic.upv.es; fubica@computacao.ufcg.edu.br;
   andrey@computacao.ufcg.edu.br; amcaar@i3m.upv.es;
   andre@icomp.ufam.edu.br; christof.fetzer@tu-dresden.de;
   flaviovdf@dcc.ufmg.br; ronny@ufam.edu.br;
   lbmarinho@computacao.ufcg.edu.br; meira@dcc.ufmg.br;
   alti@icomp.ufam.edu.br; angel@quibim.com; educamacho@quibim.com;
   anajimenez@quibim.com; alpr1963br@gmail.com; ramosnas@gmail.com;
   fabiofernando@copin.ufcg.edu.br
CR Accenture, 2019, COST CYB
   AKIN IH, 2015, IACR CRYPTOL EPRINT, V2015, P82, DOI DOI 10.1109/BDCLOUD.2014.75
   Alic AS, 2019, FUTURE GENER COMP SY, V96, P243, DOI 10.1016/j.future.2019.02.011
   Antunes N, 2018, I C DEPENDABLE SYST, P188, DOI 10.1109/DSN-W.2018.00063
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Arnautov S, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P689
   Bajaj S., 2011, P ACM SIGMOD INT C M, P205, DOI [DOI 10.1145/1989323.1989346, 10.1145/1989323.1989346]
   Leal MTBC, 2019, REV SOC BRAS MED TRO, V52, DOI 10.1590/0037-8682-0041-2019
   Barbaro M., 2006, NY TIMES, V9, P8
   Baumann A, 2015, ACM T COMPUT SYST, V33, DOI 10.1145/2799647
   Brasileiro F, 2016, IEEE 30TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA 2016), P165, DOI 10.1109/WAINA.2016.128
   Buyya R, 2010, LECT NOTES COMPUT SC, V6081, P13
   Caballer M, 2015, J GRID COMPUT, V13, P53, DOI 10.1007/s10723-014-9296-5
   Calatrava A, 2016, FUTURE GENER COMP SY, V61, P13, DOI 10.1016/j.future.2016.01.018
   Carlini E, 2012, LECT NOTES COMPUT SC, V7155, P159, DOI 10.1007/978-3-642-29737-3_19
   Chickowski E., 2018, LEAKY BUCKETS 10 WOR
   Chollet F., 2015, KERAS
   Costan V., 2016, INTEL SGX EXPLAINED, DOI DOI 10.1145/3061639.3062276
   D. Inc, 2019, DOCK SWARM
   de Alfonso C, 2013, COMPUT ELECTR ENG, V39, P2579, DOI 10.1016/j.compeleceng.2013.05.004
   Dougherty S, 2017, ANN PEDIAT CARDIOL, V10, P39, DOI 10.4103/0974-2069.197051
   Duggan J, 2015, SIGMOD REC, V44, P11, DOI 10.1145/2814710.2814713
   Fiore S, 2019, FUTURE GENER COMP SY, V94, P895, DOI 10.1016/j.future.2017.11.034
   Hassan MM, 2010, ANN TELECOMMUN, V65, P669, DOI 10.1007/s12243-010-0184-0
   Jansen W.A., 1998, HICSS, P1
   Lee CA, 2016, IEEE CLOUD COMPUT, V3, P42, DOI 10.1109/MCC.2016.15
   Londero D., 2019, TRANSFUS MED
   Lopes ELV, 2018, J TELEMED TELECARE, V24, P101, DOI 10.1177/1357633X16677902
   Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, DOI [10.1145/1217299, DOI 10.1145/1217299]
   Marascio G, 2013, HEART ASIA, V5, P213, DOI 10.1136/heartasia-2013-010392
   Maros A, 2019, IEEE INT CONF CLOUD, P99, DOI 10.1109/CLOUD.2019.00028
   Marosi AC, 2011, CLOUD COMPUTING 2011: THE SECOND INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, GRIDS, AND VIRTUALIZATION, P7
   MESOSPHERE I, 2019, MARATHON
   MESOSPHERE I, 2019, CHRONOS
   Nascimento BR, 2016, INT J CARDIOL, V219, P439, DOI 10.1016/j.ijcard.2016.06.088
   Naveed M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P644, DOI 10.1145/2810103.2813651
   Newhouse S.J., 2012, LECT NOTES COMPUTER, V7616, P849
   OASIS, 2019, TOSCA TOP ORCH SPEC
   Oleksenko O, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P227
   Papadimitriou A, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P587
   Peterson R, 2019, INT CONF CLOUD COMP, P103, DOI 10.1109/CloudCom.2019.00026
   Pires L, 2018, IEEE ENG MED BIO, P3582, DOI 10.1109/EMBC.2018.8512963
   Poddar R., 2016, CRYPTOLOGY EPRINT AR, V2016
   Popa RA, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P85
   Prasser Fabian, 2014, AMIA Annu Symp Proc, V2014, P984
   RedHat, 2019, ANS SOFTW
   Reményi B, 2012, NAT REV CARDIOL, V9, P297, DOI 10.1038/nrcardio.2012.7
   Remenyi B, 2020, HEART LUNG CIRC, V29, P859, DOI 10.1016/j.hlc.2019.02.196
   Rochwerger B, 2009, IBM J RES DEV, V53, DOI 10.1147/JRD.2009.5429058
   Salomoni D, 2018, J GRID COMPUT, V16, P381, DOI 10.1007/s10723-018-9453-3
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   T. A. S. Foundation, 2019, AP MES
   Tania B., 2019, ANAIS 37 S BRASILEIR, P7
   The Linux Foundation, 2019, KUB K8S SOFTW
   Tsai CC, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P645
   Tu S, 2013, PROC VLDB ENDOW, V6, P289
NR 57
TC 6
Z9 6
U1 1
U2 17
PD SEP
PY 2020
VL 110
BP 119
EP 134
DI 10.1016/j.future.2020.04.012
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Kara, K
   Alonso, G
AF Kara, Kaan
   Alonso, Gustavo
TI PipeArch: Generic and Context-Switch Capable Data Processing on FPGAs
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; generic architecture; programmable; context-switch;
   high-performance; machine learning; generalized linear models; training;
   matrix factorization; data processing
ID REAL-TIME; EFFICIENT; SYSTEM; SCALE; END
AB Data processing systems based on FPGAs offer high performance and energy efficiency for a variety of applications. However, these advantages are achieved through highly specialized designs. The high degree of specialization leads to accelerators with narrow functionality and designs adhering to a rigid execution flow. For multi-tenant systems this limits the scope of applicability of FPGA-based accelerators, because, first, supporting a single operation is unlikely to have any significant impact on the overall performance of the system, and, second, serving multiple users satisfactorily is difficult due to simplistic scheduling policies enforced when using the accelerator. Standard operating system and database management system features that would help address these limitations, such as context-switching, preemptive scheduling, and thread migration are practically non-existent in current FPGA accelerator efforts.
   In this work, we propose PipeArch, an open-source project(1) for developing FPGA-based accelerators that combine the high efficiency of specialized hardware designs with the generality and functionality known from conventional CPU threads. PipeArch provides programmability and extensibility in the accelerator without losing the advantages of SIMD-parallelism and deep pipelining. PipeArch supports context-switching and thread migration, thereby enabling for the first time new capabilities such as preemptive scheduling in FPGA accelerators within a high-performance data processing setting. We have used PipeArch to implement a variety of machine learning methods for generalized linear model training and recommender systems showing empirically their advantages over a high-end CPU and even over fully specialized FPGA designs.
C1 [Kara, Kaan; Alonso, Gustavo] Swiss Fed Inst Technol, Syst Grp, Dept Comp Sci, Stampfenbachstr 114, CH-8092 Zurich, Switzerland.
RP Kara, K (corresponding author), Swiss Fed Inst Technol, Syst Grp, Dept Comp Sci, Stampfenbachstr 114, CH-8092 Zurich, Switzerland.
EM kaan.kara@outlook.com; alonso@inf.ethz.ch
CR Agron J., 2009, P 7 IEEE ACM INT C H, P393
   Al Kadi M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3173548
   [Anonymous], 1997, MICROPROCESSOR ARCHI
   [Anonymous], 2014, P 2014 ACM SIGDA INT
   Asiatici M, 2017, IEEE ACCESS, V5, P1900, DOI 10.1109/ACCESS.2017.2661582
   Bennett J., 2007, P KDD CUP WORKSH NEW, P3
   Bourge A, 2016, ACM T RECONFIG TECHN, V10, DOI 10.1145/2996199
   Burger D, 2004, COMPUTER, V37, P44, DOI 10.1109/MC.2004.65
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cheah HY, 2012, 2012 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT'12), P151, DOI 10.1109/FPT.2012.6412128
   Chen Fei, 2014, P 11 ACM C COMPUTING, P3
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chin WS, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2668133
   Chou CH, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P15
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cong J, 2014, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2014.12
   Coole J, 2014, IEEE MICRO, V34, P42, DOI 10.1109/MM.2013.108
   Fleming K., 2014, PROC 24 INT C FIELD, P1, DOI [10.1109/FPL.2014.6927488, DOI 10.1109/FPL.2014.6927488]
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gebhart M, 2009, ACM SIGPLAN NOTICES, V44, P1, DOI 10.1145/1508284.1508246
   Goldstein SC, 1999, CONF PROC INT SYMP C, P28, DOI [10.1145/307338.300982, 10.1109/ISCA.1999.765937]
   Govindaraju V, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.51
   Hämäläinen P, 2005, DSD 2005: 8TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN, PROCEEDINGS, P144
   Happe Markus, 2015, Applied Reconfigurable Computing. 11th International Symposium, ARC 2015. Proceedings: LNCS 9040, P79, DOI 10.1007/978-3-319-16214-0_7
   Hoogerbrugge Jan, 1995, P 1 ANN C ADV SCH CO
   Idreos S., 2012, DATA ENG, V40
   Ismail A, 2011, ANN IEEE SYM FIELD P, P170, DOI 10.1109/FCCM.2011.48
   István Z, 2016, ANN IEEE SYM FIELD P, P204, DOI [10.1109/FCCM.016.61, 10.1109/FCCM.2016.61]
   Iturbe X, 2013, IEEE T COMPUT, V62, P1542, DOI 10.1109/TC.2013.79
   Jääskeläinen P, 2018, IEEE SYM PARA DISTR, P83, DOI 10.1109/IPDPSW.2018.00022
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kapre Nachiket, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293942
   Kapre N, 2016, ACM T RECONFIG TECHN, V9, DOI 10.1145/2912884
   Kara K, 2018, PROC VLDB ENDOW, V12, P348, DOI 10.14778/3297753.3297756
   Kara K, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P433, DOI 10.1145/3035918.3035946
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Kara K, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577353
   Knodel Oliver, 2016, ACM SIGARCH Computer Architecture News, V44, P56, DOI 10.1145/3039902.3039913
   Koch D, 2007, FPGA 2007: FIFTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P188
   Lattner Chris, 2019, MLIR PRIMER COMPILER
   Liu C, 2015, 2015 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (FPT), P56, DOI 10.1109/FPT.2015.7393130
   Liu Y, 2018, PROC VLDB ENDOW, V11, P1220, DOI 10.14778/3231751.3231770
   Lübbers E, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596540
   Mahajan D, 2018, PROC VLDB ENDOW, V11, P1317, DOI 10.14778/3236187.3236188
   Morales-Villanueva A, 2016, DES AUT TEST EUROPE, P1505
   Nagarajan R, 2001, INT SYMP MICROARCH, P40
   Oliver N., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P80, DOI 10.1109/ReConFig.2011.4
   Owaida M, 2019, PROC VLDB ENDOW, V13, P71, DOI 10.14778/3357377.3357383
   Owaida M, 2017, I C FIELD PROG LOGIC
   Owaida M, 2017, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2017.37
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Paul K., 2012, 2012 15th Euromicro Conference on Digital System Design (DSD 2012), P26, DOI 10.1109/DSD.2012.111
   Putnam A, 2014, IEEE HOT CHIP SYMP
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Recht B, 2013, MATH PROGRAM COMPUT, V5, P201, DOI 10.1007/s12532-013-0053-8
   Severance A, 2012, 2012 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT'12), P261, DOI 10.1109/FPT.2012.6412146
   Shalev-Shwartz S, 2011, J MACH LEARN RES, V12, P1865
   Sidler D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1659, DOI 10.1145/3035918.3058746
   Sukhwani B, 2012, INT CONFER PARA, P411
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vaishnav A, 2018, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2018.00031
   Wang Z., 2019, PROC VLDB ENDOW, V12, P807, DOI DOI 10.14778/3317315.3317322
   Weerasinghe J, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P36, DOI 10.1109/FPT.2016.7929186
   Wirbel L., 2014, XILINX SDACCEL WHITE
   Yiannacouras P., 2008, CASES 08 P 2008 INT, P61
   Zhang JN, 2017, AER ADV ENG RES, V105, P22
   Zhang Tong, 2004, ICML
   Zhu ZD, 2021, IEEE T CLOUD COMPUT, V9, P610, DOI 10.1109/TCC.2018.2874011
NR 70
TC 0
Z9 0
U1 1
U2 2
PD MAR
PY 2021
VL 14
IS 1
AR 3
DI 10.1145/3418465
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Solyanik-Gorgone, M
   Kang, HY
   Nouri, BM
   Dalir, H
   Sorger, VJ
AF Solyanik-Gorgone, Maria
   Kang, Haoyan
   Nouri, Behrouz Movahhed
   Dalir, Hamed
   Sorger, Volker J.
TI Hashing for secure optical information compression in a heterogeneous
   convolutional neural network
SO APPLIED PHYSICS REVIEWS
DT Article
ID IMAGE ENCRYPTION; FOURIER-TRANSFORM; MODULATOR
AB In recent years, heterogeneous machine learning accelerators have become of significant interest to science, engineering, and industry. At the same time, the looming post-quantum encryption era instigates the demand for increased data security. From a hardware processing point of view, electronic computing hardware is challenged by electronic capacitive interconnect delay and associated energy consumption. In heterogeneous systems, such as electronic-photonic accelerators, parasitic domain crossings limit throughput and speed. With analog optical accelerators exhibiting a strong potential for high throughput (up to petaoperations per second) and operation efficiency, their ability to perform machine learning classification tasks on encrypted data has not been broadly recognized. This work is a significant step in that direction. Here, we present an optical hashing and compression scheme that is inspired by SWIFFT, a post-quantum hashing family of algorithms. High degree optical hardware-to-algorithm homomorphism allows one to optimally harvest the potential of free-space data processing: innate parallelism, low latency tensor by-element multiplication, and zero-energy Fourier transformation operations. The algorithm can provide several orders of magnitude increase in processing speed as compared to optical machine learning accelerators with non-compressed input. This is achieved by replacing slow, high-resolution CMOS cameras with ultra-fast and signal-triggered CMOS detector arrays. Additionally, information acquired in this way will require much lower transmission throughput, less in silico processing power, storage, and will be pre-hashed, facilitating optical information security. This concept has the potential to allow heterogeneous convolutional Fourier classifiers to approach the performance of their fully electronic counterparts and enables data classification on hashed data.
C1 [Solyanik-Gorgone, Maria; Kang, Haoyan; Nouri, Behrouz Movahhed; Dalir, Hamed; Sorger, Volker J.] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [Kang, Haoyan; Nouri, Behrouz Movahhed; Dalir, Hamed; Sorger, Volker J.] Optelligence LLC, 10703 Marlboro Pike, Upper Marlboro, MD 20772 USA.
RP Sorger, VJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
EM sorger@gwu.edu
CR Abu-Raddad LJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85428-7
   Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Alfalou A, 2009, ADV OPT PHOTONICS, V1, P589, DOI 10.1364/AOP.1.000589
   Amin R, 2020, OPTICA, V7, P333, DOI 10.1364/OPTICA.389437
   Arbitman Y., 2008, SWIFFTX PROPOS UNPUB
   Ayoub AB, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98430-w
   Chen Y, 2021, OPT EXPRESS, V29, P22749, DOI 10.1364/OE.431032
   Choi S, 2021, OPTICA, V8, P143, DOI 10.1364/OPTICA.410622
   Dalir H., 2022, 2022 IEEE PHOT C IPC, DOI [10.1109/IPC53466.2022.9975733, DOI 10.1109/IPC53466.2022.9975733]
   Defienne H, 2021, NAT PHYS, V17, P591, DOI 10.1038/s41567-020-01156-1
   Derasari P, 2020, MIDWEST SYMP CIRCUIT, P945, DOI [10.1109/MWSCAS48704.2020.9184684, 10.1109/mwscas48704.2020.9184684]
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dudley A, 2012, OPT COMMUN, V285, P5, DOI 10.1016/j.optcom.2011.09.004
   Dufaux F, 2015, PROC SPIE, V9599, DOI 10.1117/12.2190997
   Fu WW, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00752-5
   Goodman J.W., 2005, INTRO FOURIER OPTICS
   Guo ZM, 2022, IEEE J SEL TOP QUANT, V28, DOI 10.1109/JSTQE.2022.3196884
   Gyorfi T., 2012, 2012343 IACR EPRINT
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hu ZB, 2022, Arxiv, DOI arXiv:2112.12297
   Hu ZB, 2022, LASER PHOTONICS REV, V16, DOI 10.1002/lpor.202200213
   Jin WM, 2007, OPTIK, V118, P38, DOI 10.1016/j.ijleo.2006.01.015
   Jorda M, 2019, IEEE ACCESS, V7, P70461, DOI 10.1109/ACCESS.2019.2918851
   Juleang P., 2021, APPL SCI TECHNOLOGY, P160
   Kang H., 2022, FRONTIERS OPTICS LAS
   Lang J, 2010, OPT COMMUN, V283, P2092, DOI 10.1016/j.optcom.2010.01.060
   Li SR, 2022, Arxiv, DOI arXiv:2211.05276
   Li XQ, 2016, PROC INT CONF PARAL, P67, DOI 10.1109/ICPP.2016.15
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Lyubashevsky V., 2006, NIST 2 CRYPT HASH WO
   Lyubashevsky V, 2008, LECT NOTES COMPUT SC, V5086, P54
   Lyubashevsky V, 2006, LECT NOTES COMPUT SC, V4052, P144
   Mills GA, 2005, APPL OPTICS, V44, P1216, DOI 10.1364/AO.44.001216
   Miscuglio M., 2021, C LAS EL CLEO
   Miscuglio M, 2020, OPTICA, V7, P1812, DOI 10.1364/OPTICA.408659
   Miscuglio M, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0001942
   Naughton TJ, 2003, APPL OPTICS, V42, P4758, DOI 10.1364/AO.42.004758
   Naughton TJ, 2002, APPL OPTICS, V41, P4124, DOI 10.1364/AO.41.004124
   Peserico N, 2022, OPT MATER EXPRESS, V12, P1347, DOI 10.1364/OME.451802
   Qaisar S, 2013, J COMMUN NETW-S KOR, V15, P443, DOI 10.1109/JCN.2013.000083
   Rahman MSS, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-020-00446-w
   Real-Time Computer Vision Group, 2011, GERM TRAFF SIGN REC
   Robertson J, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08703-1
   Semenov VV, 2021, CHAOS, V31, DOI 10.1063/5.0076846
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shi L, 2021, NATURE, V591, P234, DOI 10.1038/s41586-020-03152-0
   Singh N, 2010, OPT LASER ENG, V48, P398, DOI 10.1016/j.optlaseng.2009.10.001
   Situ GH, 2003, OPTIK, V114, P473, DOI 10.1078/0030-4026-00291
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Skalli A., 2022, OPT MATER EXPRESS, V12, P2395, DOI [10.1364/OME.450926, DOI 10.1364/OME.450926]
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tedeschi P., 2019, IEEE EUR S SEC PRIV
   Veli M, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20268-z
   Voelz D. G., 2011, COMPUTATION FOURIER
   Yang R, 2022, INNOVATIONS, V17, P382, DOI 10.1177/15569845221123259
   Yao F, 2018, INT S HIGH PERF COMP, P168, DOI 10.1109/HPCA.2018.00024
   Zhang LH, 2020, APPL PHYS B-LASERS O, V126, DOI 10.1007/s00340-019-7362-1
   Zhang LZ, 2018, OPT LASER TECHNOL, V105, P162, DOI 10.1016/j.optlastec.2018.03.004
   Zhang WP, 2022, OPTICA, V9, P579, DOI 10.1364/OPTICA.446100
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou JX, 2019, P NATL ACAD SCI USA, V116, P11137, DOI 10.1073/pnas.1820636116
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 62
TC 0
Z9 0
U1 7
U2 7
PD JUN
PY 2023
VL 10
IS 2
AR 021412
DI 10.1063/5.0127492
WC Physics, Applied
DA 2023-11-11
ER

PT C
AU Lingamneni, A
   Enz, C
   Palem, K
   Piguet, C
AF Lingamneni, Avinash
   Enz, Christian
   Palem, Krishna
   Piguet, Christian
GP IEEE
TI Highly Energy-efficient and Quality-tunable Inexact FFT Accelerators
SO 2014 IEEE PROCEEDINGS OF THE CUSTOM INTEGRATED CIRCUITS CONFERENCE
   (CICC)
SE IEEE Custom Integrated Circuits Conference
DT Proceedings Paper
CT 36th Annual IEEE Custom Integrated Circuits Conference (CICC) - The
   Showcase for Integrated Circuit Design in the Heart of Silicon Valley
CY SEP 15-17, 2014
CL San Jose, CA
AB We present inexact Fast Fourier Transform (FFT) accelerators that can realize energy-accuracy tradeoffs taking advantage of various inexact design techniques in conjunction with a machine-learning inspired waveform shaping technique. A 65nm ASIC test chip with several inexact FFTs shows a reduction in datapath energy consumption upto 75% and the total energy consumption upto 45% (a factor of 4X and 1.8X respectively) when compared to a conventional exact FFT at marginal Signal-to-Noise Ratio (SNR) losses between 0.0002 dB to 1 dB.
C1 [Lingamneni, Avinash; Palem, Krishna] Rice Univ, Dept Elect & Comp Engn, 6100 Main St, Houston, TX 77005 USA.
   [Enz, Christian] Inst Microengn IMT, EPFL, Neuchatel, Switzerland.
   [Piguet, Christian] Ctr Suisse Elect & Microtechn CSEM, Neuchatel, Switzerland.
RP Lingamneni, A (corresponding author), Rice Univ, Dept Elect & Comp Engn, 6100 Main St, Houston, TX 77005 USA.
CR [Anonymous], 2008, CASES
   [Anonymous], 2013, CUSTOM INTEGRATED CI
   Chen Y.L., 2008, FLORA CHINA, V12, P43, DOI DOI 10.1109/UPEC.2008.4651467]
   He S., 1996, P PAR PROC S
   Lingamneni A, 2013, 50TH DESIGN AUTOMATI, P20, DOI [10.1145/2463209.2488759, DOI 10.1145/2463209.2488759]
   Lingamneni A, 2011, DES AUT TEST EUROPE, P764
   Lingamneni A, 2013, J LOW POWER ELECTRON, V9, P141, DOI 10.1166/jolpe.2013.1249
   Mingoo Seok, 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P342, DOI 10.1109/ISSCC.2011.5746346
   Palem K, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465789
NR 9
TC 5
Z9 6
U1 0
U2 2
PY 2014
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Bertels, P
   Heirman, W
   D'Hollander, E
   Stroobandt, D
AF Bertels, Peter
   Heirman, Wim
   D'Hollander, Erik
   Stroobandt, Dirk
TI Efficient Memory Management for Hardware Accelerated Java Virtual
   Machines
SO ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS
DT Article
DE Algorithms; Experimentation; Performance; Dynamic memory management;
   Java Virtual Machine; hardware acceleration
ID SOFTWARE COSYNTHESIS
AB Application-specific hardware accelerators can significantly improve a system's performance. In a Java-based system, we then have to consider a hybrid architecture that consists of a Java Virtual Machine running on a general-purpose processor connected to the hardware accelerator. In such a hybrid architecture, data communication between the accelerator and the general-purpose processor can incur a significant cost, which may even annihilate the original performance improvement of adding the accelerator. A careful layout of the data in the memory structure is therefore of major importance to maintain the acceleration performance benefits.
   This article addresses the reduction of the communication cost in a distributed shared memory consisting of the main memory of the processor and the accelerator's local memory, which are unified in the Java heap. Since memory access times are highly nonuniform, a suitable allocation of objects in either main memory or the accelerator's local memory can significantly reduce the communication cost. We propose several techniques for finding the optimal location for each Java object's data, either statically through profiling or dynamically at runtime. We show how we can reduce communication cost by up to 86% for the SPECjvm and DaCapo benchmarks. We also show that the best strategy is application dependent and also depends on the relative cost of remote versus local accesses. For a relative cost higher than 10, a self-learning dynamic approach often results in the best performance.
C1 [Bertels, Peter; Heirman, Wim; D'Hollander, Erik; Stroobandt, Dirk] Univ Ghent, ELIS Dept, B-9000 Ghent, Belgium.
RP Bertels, P (corresponding author), Univ Ghent, ELIS Dept, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM peter.bertels@ugent.be; wim.heirman@ugent.be; erik.dhollander@ugent.be;
   dirk.stroobandt@ugent.be
CR [Anonymous], P 20 ANN INT C SUP C
   [Anonymous], 2008, P 2008 NEW TECHNOLOG
   Beck ACS, 2005, DES AUT CON, P732
   Blackburn S. M., 2006, P 21 ANN ACM SIGPLAN, P169, DOI DOI 10.1145/1167473.1167488
   BORG A, 2006, P 4 INT WORKSH JAV T, P58
   Eeckhaut H, 2007, IEEE T MULTIMEDIA, V9, P1508, DOI 10.1109/TMM.2007.906606
   ERNST R, 1993, IEEE DES TEST COMPUT, V10, P64, DOI 10.1109/54.245964
   Faes P., 2005, Proceedings. 2005 International Conference on Field Programmable Logic and Applications (IEEE Cat. No.05EX1155), P675
   FAES P, 2007, P 21 INT PAR DISTR P, P386
   Faes P., 2006, PROC 1 INT C SCALABL
   FAES P, 2004, P 16 IASTED INT C PA, P380
   GUPTA RK, 1993, IEEE DES TEST COMPUT, V10, P29, DOI 10.1109/54.232470
   Hakkennes E, 2001, J VLSI SIG PROC SYST, V28, P221, DOI 10.1023/A:1011117608815
   HELAIHEL R, 1997, P INT C COMP AID DES, P690
   Lattanzi E, 2005, INT J EMBED SYST, V1, P228, DOI 10.1504/IJES.2005.009952
   Lysecky R, 2006, ACM T DES AUTOMAT EL, V11, P659, DOI 10.1145/1142980.1142986
   Panainte EM, 2007, ACM T EMBED COMPUT S, V6, DOI 10.1145/1210268.1210274
   *STAND PERF EV COR, 1998, JAV VIRT MACH BENCHM
   *STAND PERF EV COR, 2008, JAV VIRT MACH BENCHM
   Vassiliadis S, 2004, IEEE T COMPUT, V53, P1363, DOI 10.1109/TC.2004.104
NR 20
TC 0
Z9 0
U1 0
U2 2
PD AUG
PY 2009
VL 14
IS 4
AR 48
DI 10.1145/1562514.1562516
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Inayat, K
   Chung, JY
AF Inayat, Kashif
   Chung, Jaeyong
TI Carry-Propagation-Adder-Factored Gemmini Systolic Array for Machine
   Learning Acceleration
SO ELECTRONICS
DT Article
DE machine learning; Gemmini; systolic array; factorization; accelerator
ID DEEP NEURAL-NETWORKS
AB Systolic arrays are the primary part of modern deep learning accelerators and are being used widely in real-life applications such as self-driving cars. This paper presents a novel factored systolic array, where the carry propagation adder for accumulation and the rounding logic are extracted out from each processing element, which reduces the area, power and delay of the processing elements substantially. The factoring is performed in the column-wise manner and the cost of the factored logic, placed at each column output, is amortized by the processing elements in a column. We demonstrate the proposed factoring in an open source systolic array, Gemmini. The factoring technique does not change the functionality of the base design and is transparent to applications. We show that the proposed technique leads to substantial reduction in area and delay up to 45.3% and 23.7%, respectively, compared to the Gemmini baseline.
C1 [Inayat, Kashif; Chung, Jaeyong] Incheon Natl Univ, Dept Elect Engn, Syst Chips Lab, Incheon 22012, South Korea.
RP Chung, JY (corresponding author), Incheon Natl Univ, Dept Elect Engn, Syst Chips Lab, Incheon 22012, South Korea.
EM kashif.inayat@inu.ac.kr; jychung@inu.ac.kr
CR [Anonymous], 2018, ARXIV180108058
   Bewick G. W., 1994, THESIS STANFORD U ST
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dave S., 2007, ARXIV 2020
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Ercegovac M.D., 2004, DIGITAL ARITHMETIC
   Haj-Ali A., 2019, ARXIV191109925
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hwang K., 1979, COMPUTER ARITHMETIC, P69
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kung H.T., 1982, PROC 4 REAL TIME SIG, V298, P19
   Kung H. T., 1979, INTRO VLSI SYSTEMS
   Kung H.T., 1981, SYSTOLIC 2 D CONVOLU
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Liu ZG, 2020, IEEE COMPUT ARCHIT L, V19, P34, DOI 10.1109/LCA.2020.2979965
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Lym S., 2020, ARXIV200413027
   NVIDIA, 2019, NVID TUR GPU ARCH
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Sze V., 2020, EFFICIENT PROCESSING, V15, P341
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Ullah I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218585
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
NR 31
TC 3
Z9 3
U1 0
U2 5
PD MAR
PY 2021
VL 10
IS 6
AR 652
DI 10.3390/electronics10060652
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Scherer, M
   Di Mauro, A
   Fischer, T
   Rutishauser, G
   Benini, L
AF Scherer, Moritz
   Di Mauro, Alfio
   Fischer, Tim
   Rutishauser, Georg
   Benini, Luca
TI TCN-CUTIE: A 1,036-TOp/s/W, 2.72-J/Inference, 12.2-mW All-Digital
   Ternary Accelerator in 22-nm FDX Technology
SO IEEE MICRO
DT Article
DE Machine learning; Computer architecture; Neural networks; Voltage
   control; System-on-chip; Feature extraction
AB Tiny machine learning (TinyML) applications impose mu J/inference constraints, with a maximum power consumption of tens of megawatt. It is extremely challenging to meet these requirements at a reasonable accuracy level. This work addresses the challenge with a flexible, fully digital ternary neural network (TNN) accelerator in a reduced instruction set computer-five (RISC-V)-based System-on-Chip (SoC). Besides supporting ternary convolutional neural networks, we introduce extensions to the accelerator design that enable the processing of time-dilated temporal convolutional neural networks (TCNs). The design achieves 5.5-mu J/inference, 12.2 mW, 8,000 inferences/s at 0.5 V for a dynamic vision sensor (DVS)-based TCN and an accuracy of 94.5%, and 2.72-mu J/inference, 12.2 mW, 3,200 inferences/s at 0.5 V for a nontrivial 9-layer, 96 channels-per-layer convolutional network with CIFAR-10 accuracy of 86%. The peak energy efficiency is 1,036 TOp/s/W, outperforming the state-of-the-art silicon-proven TinyML quantized accelerators by 1.67x while achieving competitive accuracy.
C1 [Scherer, Moritz; Di Mauro, Alfio; Fischer, Tim; Rutishauser, Georg; Benini, Luca] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, I-40126 Bologna, Italy.
RP Scherer, M (corresponding author), Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
EM scheremo@iis.ee.ethz.ch; adimauro@iis.ee.ethz.ch;
   fischeti@iis.ee.ethz.ch; georgr@iis.ee.ethz.ch; lbenini@iis.ee.ethz.ch
CR Amir A, 2017, PROC CVPR IEEE, P7388, DOI 10.1109/CVPR.2017.781
   Ceolini E, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00637
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Giraldo JSP, 2021, IEEE T VLSI SYST, V29, P2220, DOI 10.1109/TVLSI.2021.3120189
   Knag P. C., 2020, PROC IEEE S VLSI CIR, P1
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Moons B, 2018, IEEE CUST INTEGR CIR
   Pullen AG, 2018, STUD HIGH EDUC, V43, P2059, DOI 10.1080/03075079.2017.1304376
   Rutishauser G, 2022, DES AUT TEST EUROPE, P736, DOI 10.23919/DATE54114.2022.9774592
   Scherer M, 2022, IEEE T COMPUT AID D, V41, P1020, DOI 10.1109/TCAD.2021.3075420
   Schiavone P. D., 2018, IEEE SOI3DSUB MICRO, P1, DOI DOI 10.1109/S3S.2018.8640145
NR 11
TC 1
Z9 1
U1 0
U2 0
PD JAN 1
PY 2023
VL 43
IS 1
BP 42
EP 48
DI 10.1109/MM.2022.3226630
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Aftowicz, M
   Lehniger, K
   Langendoerfer, P
AF Aftowicz, Marcin
   Lehniger, Kai
   Langendoerfer, Peter
GP IEEE
TI Scalable FPGA hardware accelerator for SVM inference
SO 2022 11TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO)
SE Mediterranean Conference on Embedded Computing
DT Proceedings Paper
CT 11th Mediterranean Conference on Embedded Computing (MECO) / 3rd Summer
   School on Cyber-Physical + Systems and Internet of Things (CPS and IoT)
CY JUN 07-10, 2022
CL Budva, MONTENEGRO
DE SVM; Support Vector Machine; Classification; Machine Learning; FPGA
   implementation; Xilinx; Multiplier-less kernel
ID SUPPORT VECTOR MACHINE
AB In this paper we present a scalable hardware architecture implementing the Support Vector Machine (SVM) binary classification in a Xilinx Zynq FPGA. Our design utilizes a hardware friendly version of the RBF kernel running at 175MHz and taking 11.8 mu s to process 4096 support vectors with 15 features and 12 bit precision. The architecture is pipelined and calculates the L1-norm part of the hardware friendly kernel iteratively. The model is stored in on-chip memory.
C1 [Aftowicz, Marcin; Lehniger, Kai; Langendoerfer, Peter] IHP Leibniz Inst Innovat Mikroelekt, Frankfurt, Oder, Germany.
   [Langendoerfer, Peter] BTU Cottbus Senftenberg, Cottbus, Germany.
RP Aftowicz, M (corresponding author), IHP Leibniz Inst Innovat Mikroelekt, Frankfurt, Oder, Germany.
CR Afifi S., 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00128-9
   Afifi S, 2016, LECT NOTES COMPUT SC, V9555, P235, DOI 10.1007/978-3-319-30285-0_19
   Anguita D, 2007, IEEE IJCNN, P1360, DOI 10.1109/IJCNN.2007.4371156
   Anguita D, 2006, IEEE T NEURAL NETWOR, V17, P1328, DOI 10.1109/TNN.2006.877537
   Anguita D, 2011, J CIRCUIT SYST COMP, V20, P263, DOI 10.1142/S0218126611007244
   [Anonymous], 2010, 2010 INT JOINT C NEU
   Bhaswati M, 2014, P 16 INT C AUTOMATIC, P288
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Sarciada JG, 2010, PROC SPIE, V7703, DOI 10.1117/12.850781
   Jallad AHM, 2014, NASA ESA CONF, P256, DOI 10.1109/AHS.2014.6880185
   Kyrkou C, 2009, IEEE EMBED SYST LETT, V1, P46, DOI 10.1109/LES.2009.2034709
   Murphy C., 2017, XILINX ALL PROGRAMMA
   Vranjkovic V., 2011, 2011 19th Telecommunications Forum Telfor (TELFOR), P1543, DOI 10.1109/TELFOR.2011.6143852
   Wong S, 2002, EUROMICRO CONF PROC, P183, DOI 10.1109/EURMIC.2002.1046155
   Xipeng Pan, 2013, 2013 Fifth International Conference on Computational and Information Sciences (ICCIS 2013), P133, DOI 10.1109/ICCIS.2013.43
NR 15
TC 1
Z9 1
U1 3
U2 5
PY 2022
BP 44
EP 47
DI 10.1109/MECO55406.2022.9797110
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Cai, YJ
   Li, X
   Han, J
   Zeng, XY
AF Cai, Yujie
   Li, Xin
   Han, Jun
   Zeng, Xiaoyang
BE Qin, YJ
   Hong, ZL
   Tang, TA
TI A Configurable Nonlinear Operation Unit For Neural Network Accelerator
SO 2017 IEEE 12TH INTERNATIONAL CONFERENCE ON ASIC (ASICON)
SE International Conference on ASIC
DT Proceedings Paper
CT 12th IEEE International Conference on ASIC (ASICON)
CY OCT 25-28, 2017
CL Guiyang, PEOPLES R CHINA
DE Neural Network; Nonlinear Operation Unit
AB With the development of machine learning, neural network accelerators are widely used to speed up the calculation. Many of the accelerators are designed to be configurable so they can be widely used in different situations. Nonlinear operation is essential to a neural network with nonlinear fitting ability As there are a lot of optional nonlinear operations, a configurable nonlinear operation unit is necessary to a configurable neural network accelerator. This paper produced a configurable nonlinear operation unit used in neural network accelerators. It can realize different nonlinear operations by combining some basic operation units together. The connection mode among these basic units can be configured, so the nonlinear operation unit becomes very flexible. In addition, because of the re-use of these basic units, this circuit has an advantage of cell area and power consumption.
C1 [Cai, Yujie; Li, Xin; Han, Jun; Zeng, Xiaoyang] Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
RP Cai, YJ (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
EM 16210720048@fudan.edu.cn
CR Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2014, CVPR WARKSHOPS
   Farabet Clement, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P878, DOI 10.1109/ICCVW.2009.5457611
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Martinez J J, 2010, CELLULAR NANOSCALE N, P1
   Nakano H, 2015, 2015 INTERNATIONAL WORKSHOP ON ANTENNA TECHNOLOGY (IWAT), P1, DOI 10.1109/IWAT.2015.7365341
   Solazzo A, 2016, IEEE COMP SOC ANN, P224, DOI 10.1109/ISVLSI.2016.101
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 8
TC 5
Z9 5
U1 1
U2 5
PY 2017
BP 319
EP 322
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Phillips, R
   Ward, JW
   Bridge, P
   Appleyard, RM
   Beavis, AW
AF Phillips, Roger
   Ward, James W.
   Bridge, Pete
   Appleyard, Rob M.
   Beavis, Andrew W.
BE Woods, AJ
   Dodgson, NA
   Merritt, JO
   Bolas, MT
   McDowall, IE
TI A hybrid virtual environment for training of radiotherapy treatment of
   cancer
SO STEREOSCOPIC DISPLAYS AND VIRTUAL REALITY SYSTEMS XIII
SE Proceedings of SPIE
DT Proceedings Paper
CT Conference on Stereoscopic Displays and Virtual Reality Systems XIII
CY JAN 16-19, 2006
CL San Jose, CA
DE immersive visualization environment; hybrid virtual environment; virtual
   reality; radiotherapy; training; skin apposition; learning evaluation;
   validation; presence; realism
ID REALITY
AB There is often insufficient access to patients and linear accelerator treatment rooms to train radiotherapy students. An alternative approach is for some training to use a hybrid virtual environment (HVE) that simulates an actual radiotherapy treatment machine controlled with the actual machine's handheld control pendant. A study of training using such a HVE is presented for "skin apposition" treatment, where the patient couch and radiotherapy equipment are positioned so that the radiation beam strikes the skin perpendicularly. The HVE developed comprises a virtual treatment room with a linear accelerator, modelled from laser scan data and a virtual patient. A genuine linear accelerator control handheld "pendant" provided the user interface to the virtual linear accelerator. A virtual patient, based on the visible human female dataset, complete with rectangular markings for a range of different treatment sites, provided a range of treatment scenarios. Students were trained in groups with the virtual world being displayed stereoscopically on a large work-wall. A study of 42 students was conducted to evaluate learning. 93% of students perceived an improvement in their understanding of this treatment using the HVE and 69% found the control system to be easy to master.
C1 [Phillips, Roger; Ward, James W.] Univ Hull, Dept Comp Sci, Kingston Upon Hull, N Humberside, England.
   [Phillips, Roger; Ward, James W.; Beavis, Andrew W.] Univ Hull, Inst Clin Biosci, Kingston Upon Hull, N Humberside, England.
   [Beavis, Andrew W.] Hull & East Yorkshire Hosp NHS Trust, Princess Royal Hosp, Kingston Upon Hull, N Humberside, England.
RP Phillips, R (corresponding author), Univ Hull, Dept Comp Sci, Kingston Upon Hull, N Humberside, England.
EM r.phillips@hull.ac.uk
CR Agrawala M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P327, DOI 10.1145/258734.258875
   [Anonymous], 1992, PRESENCE, DOI DOI 10.1162/PRES.1992.1.1.127
   Ash D, 2004, CLIN ONCOL-UK, V16, P387, DOI 10.1016/j.clon.2004.06.006
   Bergin RA, 2003, COMPUT EDUC, V40, P361, DOI 10.1016/S0360-1315(02)00167-7
   Boyer AL, 2001, INT J RADIAT ONCOL, V51, P880, DOI 10.1016/S0360-3016(01)01749-7
   BRIDGE P, 2006, IN PRESS COMPUT ED
   Engum SA, 2003, AM J SURG, V186, P67, DOI 10.1016/S0002-9610(03)00109-0
   International Commision on Radiation Units & Measurements, 1999, 62 INT COMM RAD UN M
   Mayrose J, 2003, RESUSCITATION, V59, P133, DOI 10.1016/S0300-9572(03)00179-5
   Newman DR, 1997, J AM SOC INFORM SCI, V48, P484, DOI 10.1002/(SICI)1097-4571(199706)48:6<484::AID-ASI2>3.0.CO;2-Q
   Ost D, 2001, AM J RESP CRIT CARE, V164, P2248, DOI 10.1164/ajrccm.164.12.2102087
   PATRICK E, 2000, P SIGCHI C HUM FACT, P478
   Phillips R, 2005, ST HEAL T, V111, P390
   TYNDIUK F, 2004, P 3 INT C COMP GRAPH, P61
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER, P92, DOI [DOI 10.2307/J.CTVJF9VZ4.11, 10.2307/j.ctvjf9vz4]
   Wang JJ, 2004, NURS EDUC TODAY, V24, P589, DOI 10.1016/j.nedt.2004.07.004
   ZIEGLER R, 1995, COMPUT BIOL MED, V25, P193, DOI 10.1016/0010-4825(94)00038-R
NR 17
TC 0
Z9 0
U1 0
U2 6
PY 2006
VL 6055
AR 605508
DI 10.1117/12.650951
WC Optics
DA 2023-11-11
ER

PT C
AU Di Mauro, A
   Conti, F
   Schiavone, PD
   Rossi, D
   Benini, L
AF Di Mauro, Alfio
   Conti, Francesco
   Schiavone, Pasquale Davide
   Rossi, Davide
   Benini, Luca
GP IEEE
TI Pushing On-chip Memories Beyond Reliability Boundaries in Micropower
   Machine Learning Applications
SO 2019 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
SE IEEE International Electron Devices Meeting
DT Proceedings Paper
CT 65th IEEE Annual International Electron Devices Meeting (IEDM)
CY DEC 09-11, 2019
CL San Francisco, CA
AB Memory access dominates inference energy in today's Deep Neural Network (DNN) accelerators. We analyze voltage over-scaling for on-chip memories and explore the trade-off between energy efficiency and reliability for robust and computationally efficient deep Binary Neural Networks (BNNs). Experimental results on a BNN accelerator fabricated in FDX22 technology with on-chip SRAMs powered down to 0.4V (well below the 0.8V nominal Vdd) demonstrate major energy efficiency improvements (2.3x) at negligible end-to-end classification accuracy degradation.
C1 [Di Mauro, Alfio; Conti, Francesco; Schiavone, Pasquale Davide; Benini, Luca] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Conti, Francesco; Rossi, Davide; Benini, Luca] Univ Bologna, Bologna, Italy.
RP Di Mauro, A (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
EM adimauro@iis.ee.ethz.ch; fconti@iis.ee.ethz.ch; pschiavo@iis.ee.ethz.ch;
   davide.rossi@unibo.it; lbenini@iis.ee.ethz.ch
CR Calhoun BH, 2007, IEEE J SOLID-ST CIRC, V42, P680, DOI 10.1109/JSSC.2006.891726
   Chandramoorthy N., 2019, 2019 IEEE INT S HIGH
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Di Mauro A, 2018, IEEE SOI3DSUB MICRO
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Kim S., 2018, 2018 DES AUT TEST EU
   Kim S, 2018, IEEE T CIRCUITS-I, V65, P4285, DOI 10.1109/TCSI.2018.2839613
   Pullini A, 2019, IEEE J SOLID-ST CIRC, V54, P1970, DOI 10.1109/JSSC.2019.2912307
   Schiavone P. D., 2018, IEEE SOI3DSUB MICRO, P1, DOI DOI 10.1109/S3S.2018.8640145
   Teman A., 2015, 20 AS S PAC DES AUT
   Yang L., 2018, 2018 IEEE INT S CIRC
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1109/iedm19573.2019.8993434
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ni, LB
   Huang, HT
   Liu, ZC
   Joshi, RV
   Yu, H
AF Ni, Leibin
   Huang, Hantao
   Liu, Zichuan
   Joshi, Rajiv V.
   Yu, Hao
TI Distributed In-Memory Computing on Binary RRAM Crossbar
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE RRAM crossbar; L2-norm-based machine learning; hardware accelerator
AB The recently emerging resistive random-access memory (RRAM) can provide nonvolatile memory storage but also intrinsic computing for matrix-vector multiplication, which is ideal for the low-power and high-throughput data analytics accelerator performed in memory. However, the existing RRAM crossbar-based computing is mainly assumed as a multilevel analog computing, whose result is sensitive to process nonuniformity as well as additional overhead from AD-conversion and I/O. In this article, we explore the matrix-vector multiplication accelerator on a binary RRAM crossbar with adaptive 1-bit-comparator-based parallel conversion. Moreover, a distributed in-memory computing architecture is also developed with the according control protocol. Both memory array and logic accelerator are implemented on the binary RRAM crossbar, where the logic-memory pair can be distributed with the control bus protocol. Experimental results have shown that compared to the analog RRAM crossbar, the proposed binary RRAM crossbar can achieve significant area savings with better calculation accuracy. Moreover, significant speedup can be achieved for matrix-vector multiplication in neural network-based machine learning such that the overall training and testing time can be both reduced. In addition, large energy savings can be also achieved when compared to the traditional CMOS-based out-of-memory computing architecture.
C1 [Ni, Leibin; Huang, Hantao; Liu, Zichuan; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, VIRUTUS, 50 Nanyang Ave,S3-2-B2, Singapore 639798, Singapore.
   [Joshi, Rajiv V.] IBM Corp, TJ Watson Res Ctr, 1101 Kitchawan Rd, Yorktown Hts, NY 10598 USA.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, VIRUTUS, 50 Nanyang Ave,S3-2-B2, Singapore 639798, Singapore.
EM nile0001@e.ntu.edu.sg; hhuang013@e.ntu.edu.sg; zliu016@e.ntu.edu.sg;
   rvjoshi@us.ibm.com; haoyu@ntu.edu.sg
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], DESIGN EXPLORATION E
   [Anonymous], 2015, P 2015 52 ACM EDAC I
   [Anonymous], ARXIV151109085
   [Anonymous], P AS S PAC DES AUT C
   [Anonymous], 2010, CASIA FINGERPRINTV5
   [Anonymous], 2009, NEURAL NETWORKS LEAR
   [Anonymous], P AS S PAC DES AUT C
   Chen PY, 2015, DES AUT TEST EUROPE, P854
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Coates Adam, 2011, AISTATS, DOI DOI 10.1177/1753193410390845
   Fan DL, 2014, IEEE T NANOTECHNOL, V13, P574, DOI 10.1109/TNANO.2014.2312177
   Fei W, 2012, IEEE T VLSI SYST, V20, P1012, DOI 10.1109/TVLSI.2011.2136443
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   Higham NJ, 2009, WILEY INTERDISCIP RE, V1, P251, DOI 10.1002/wics.18
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G. B., 2008, WORKSHOP FACES INREA, P1
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Joshi R, 2011, ICCAD-IEEE ACM INT, P236, DOI 10.1109/ICCAD.2011.6105333
   Kang W, 2014, 2014 IEEE 14TH INTERNATIONAL CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P1
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kouzes RT, 2009, COMPUTER, V42, P26, DOI 10.1109/MC.2009.26
   Kumar V, 2014, IEEE T COMP PACK MAN, V4, P1335, DOI 10.1109/TCPMT.2014.2326798
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lee H. Y., 2008, P IEEE INT ELECT DEV, P1
   Matsunaga S, 2009, DES AUT TEST EUROPE, P433
   Müller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022
   Park S, 2013, DES AUT TEST EUROPE, P1637
   Shang Y, 2012, IEEE T CIRCUITS-I, V59, P1906, DOI 10.1109/TCSI.2011.2180441
   Singh PN, 2007, IEEE CUST INTEGR CIR, P189
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wang YH, 2015, IEEE T NANOTECHNOL, V14, P998, DOI 10.1109/TNANO.2015.2447531
   Wang YH, 2014, IEEE T VLSI SYST, V22, P957, DOI 10.1109/TVLSI.2013.2265754
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Williams S, 2008, IEEE SPECTRUM, V45, P24
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yongtae Kim, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P328, DOI 10.1109/SOCC.2012.6398336
NR 42
TC 25
Z9 25
U1 3
U2 52
PD MAY
PY 2017
VL 13
IS 3
SI SI
AR 36
DI 10.1145/2996192
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Iizuka, K
   Ito, K
   Hironaka, K
   Amano, H
AF Iizuka, Kensuke
   Ito, Kohei
   Hironaka, Kazuei
   Amano, Hideharu
GP IEEE
TI A Method of Partitioning Convolutional Layer to Multiple FPGAs
SO 2020 17TH INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC 2020)
SE International SoC Design Conference
DT Proceedings Paper
CT 17th International SoC Design Conference (ISOCC)
CY OCT 21-24, 2020
CL Yeosu, SOUTH KOREA
DE Multi-FPGA system; Convolutional Neural Network Accelerators; Deep
   Learning
AB We propose a partition method to improve the performance of convolutional neural networks (CNN) on a multi-FPGA system called Flow-in-Cloud (FiC) and implement the 2nd layer of AlexNet on FiC. As a result, our implementation is slightly more energy-efficient than the CPU and the GPU with an optimized machine learning framework.
C1 [Iizuka, Kensuke; Ito, Kohei; Hironaka, Kazuei; Amano, Hideharu] Keio Univ, Dept Informat & Comp Sci, Yokohama, Kanagawa, Japan.
RP Iizuka, K (corresponding author), Keio Univ, Dept Informat & Comp Sci, Yokohama, Kanagawa, Japan.
EM fic@am.ics.keio.ac.jp
CR Hinton G. E., P 25 INT C NEUR INF, V1, P1097
   Hironaka K, 2019, 2019 20TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P443, DOI [10.1109/SNPD.2019.8935738, 10.1109/snpd.2019.8935738]
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Lin DD, 2016, PR MACH LEARN RES, V48
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang WT, 2019, DES AUT TEST EUROPE, P1241, DOI [10.23919/date.2019.8715174, 10.23919/DATE.2019.8715174]
NR 6
TC 0
Z9 0
U1 0
U2 1
PY 2020
BP 25
EP 26
DI 10.1109/ISOCC50952.2020.9332929
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Calore, E
   Schifano, SF
AF Calore, Enrico
   Schifano, Sebastiano Fabio
TI FER: A Benchmark for the Roofline Analysis of FPGA Based HPC
   Accelerators
SO IEEE ACCESS
DT Article
DE Field programmable gate arrays; Benchmark testing; Computational
   modeling; Performance evaluation; Bandwidth; Hardware; Programming;
   Accelerator; benchmark; FPGA; HPC; performance; roofline
ID ENERGY-EFFICIENCY; PERFORMANCE; SCALE; MODEL
AB Nowadays, the use of hardware accelerators to boost the performance of HPC applications is a consolidated practice, and among others, GPUs are by far the most widespread. More recently, some data centers have successfully deployed also FPGA accelerated systems, especially to boost machine learning inference algorithms. Given the growing use of machine learning methods in various computational fields, and the increasing interest towards reconfigurable architectures, we may expect that in the near future FPGA based accelerators will be more common in HPC systems, and that they could be exploited also to accelerate general purpose HPC workloads. In view of this, tools able to benchmark FPGAs in the context of HPC are necessary for code developers to estimate the performance of applications, as well as for computer architects to model that of systems at scale. To fulfill these needs, we have developed FER (FPGA Empirical Roofline), a benchmarking tool able to empirically measure the computing performance of FPGA based accelerators, as well as the bandwidth of their on-chip and off-chip memories. FER measurements enable to draw Roofline plots for FPGAs, allowing for performance comparisons with other processors, such as CPUs and GPUs, and to estimate at the same time the performance upper-bounds that applications could achieve on a target device. In this paper we describe the theoretical model on which FER relies, its implementation details, and the results measured on Xilinx Alveo accelerator cards.
C1 [Calore, Enrico] Univ Ferrara, I-44121 Ferrara, Italy.
   INFN Ferrara, I-44122 Ferrara, Italy.
RP Calore, E (corresponding author), Univ Ferrara, I-44121 Ferrara, Italy.
EM enrico.calore@fe.infn.it
CR Alonso G, 2018, COMMUN ACM, V61, P48, DOI 10.1145/3209275
   [Anonymous], 2020, VITIS UNIFIED SOFTWA
   [Anonymous], 2020, ULTRASCALE ARCHITECT
   [Anonymous], 2020, ALVEO U50 DATA CTR A
   [Anonymous], 2020, UG1120 V12
   [Anonymous], 2020, PERFORMANCE RESOURCE
   [Anonymous], 2020, FLOATING POINT OPERA
   [Anonymous], TOP500 RANKING
   Bacon DF, 2013, COMMUN ACM, V56, P56, DOI 10.1145/2436256.2436271
   BDT, 2013, FLOAT POINT DSP EN E
   Bosch J, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P73, DOI 10.1109/FPT.2018.00021
   Brosser F, 2013, I C FIELD PROG LOGIC
   Calore E, 2019, INT J HIGH PERFORM C, V33, P124, DOI 10.1177/1094342017703771
   Calore E, 2020, FPGA EMPIRICAL ROOFL
   Calore E, 2021, I C FIELD PROG LOGIC, P83, DOI 10.1109/FPL53798.2021.00022
   Calore E, 2020, ADV PARALLEL COMPUT, V36, P555, DOI 10.3233/APC200085
   Calore E, 2020, COMPUTATION, V8, DOI 10.3390/computation8010020
   Cherubin S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3381039
   Cherubin Stefano, 2018, ADV PARALLEL COMPUTI, V32, P297, DOI [10.3233/978-1-61499-843-3-297, DOI 10.3233/978-1-61499-843-3-297]
   Colangelo P, 2018, ANN IEEE SYM FIELD P, P73, DOI 10.1109/FCCM.2018.00020
   Corda S, 2022, IEEE ACCESS, V10, P22819, DOI 10.1109/ACCESS.2022.3150861
   da Silva B, 2013, INT J RECONFIGURABLE, V2013, DOI 10.1155/2013/428078
   Licht JD, 2021, IEEE T PARALL DISTR, V32, P1014, DOI 10.1109/TPDS.2020.3039409
   Escobar FA, 2016, IEEE T PARALL DISTR, V27, P600, DOI 10.1109/TPDS.2015.2407896
   Fowers J, 2019, IEEE MICRO, V39, P20, DOI 10.1109/MM.2019.2910506
   Haidar A., 2017, P 8 WORKSHOP LATEST, P1
   Jin ZM, 2018, LECT NOTES COMPUT SC, V10659, P664, DOI 10.1007/978-3-319-75178-8_53
   Kara K, 2020, I C FIELD PROG LOGIC, P1, DOI 10.1109/FPL50879.2020.00013
   Lant J, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2019.2950655
   Licht JD, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P244, DOI 10.1145/3373087.3375296
   Lo YJ, 2015, LECT NOTES COMPUT SC, V8966, P129, DOI 10.1007/978-3-319-17248-4_7
   McCalpin John D., 1995, IEEE COMPUTER SOC TE, P19
   Meyer M, 2020, PROCEEDINGS OF H2RC 2020: 2020 SIXTH IEEE/ACM INTERNATIONAL WORKSHOP ON HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC), P10, DOI 10.1109/H2RC51942.2020.00007
   de Haro JM, 2021, IEEE T COMPUT, V70, P2029, DOI 10.1109/TC.2021.3086106
   Minhas Umar Ibrahim, 2014, Reconfigurable Computing: Architectures, Tools, and Applications. 10th International Symposium, ARC 2014. Proceedings: LNCS 8405, P298, DOI 10.1007/978-3-319-05960-0_32
   Muralidharan Sriram, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413041
   Nabi SW, 2018, IEEE SYM PARA DISTR, P194, DOI 10.1109/IPDPSW.2018.00036
   Nagasu K, 2017, J PARALLEL DISTR COM, V106, P153, DOI 10.1016/j.jpdc.2016.12.015
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Nguyen T, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6570
   Nguyen T, 2020, PROCEEDINGS OF 2020 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2020), P8, DOI 10.1109/PMBS51919.2020.00007
   Parker M., 2017, UNDERSTANDING PEAK F
   Putnam A, 2015, IEEE MICRO, V35, P10, DOI 10.1109/MM.2015.42
   Ronak B, 2016, IEEE T COMPUT AID D, V35, P573, DOI 10.1109/TCAD.2015.2474363
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   SIRACUSA M, 2020, PROC 39 INT C COMPUT, P1, DOI DOI 10.1145/3400302.3415730
   Siracusa M, 2021, IEEE T COMPUT, V71, P1903, DOI 10.1109/TC.2021.3111761
   van Werkhoven B, 2020, LECT NOTES COMPUT SC, V12143, P399, DOI 10.1007/978-3-030-50436-6_29
   Vanderbauwhede W., 2013, HIGH PERFORMANCE COM, V3
   Vanevenhoven T, 2011, 409 DSP ALG XIL FPGA
   Vestias M., 2014, 2014 24 INT C FIELD, P1
   VivadoHLS, VIVADOHLS
   Wang ZK, 2020, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM48280.2020.00024
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yang C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5547
   Yasudo R, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P317, DOI 10.1109/FPT.2018.00062
   Zeni A, 2021, LECT NOTES COMPUT SC, V12820, P616, DOI 10.1007/978-3-030-85665-6_38
   Zohouri HR, 2019, PROCEEDINGS OF H2RC 2019: 2019 FIFTH IEEE/ACM INTERNATIONAL WORKSHOP ON HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC), P11, DOI 10.1109/H2RC49586.2019.00007
   Zohouri HR, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P409, DOI 10.1109/SC.2016.34
NR 59
TC 1
Z9 1
U1 1
U2 2
PY 2022
VL 10
BP 94220
EP 94234
DI 10.1109/ACCESS.2022.3203566
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Ramamoorthy, P
   Nallasamy, V
AF Ramamoorthy, Prabhu
   Nallasamy, Viswanathan
TI A novel hybrid optimized and adaptive reconfigurable framework for the
   implementation of hybrid bio-inspired classifiers for diagnosis
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Bio-inspired classifiers; Accelerator; Finite state machines (FSM);
   Fusion; Shared DA; FPGA; IoT; Artificial intelligence
ID EXTREME LEARNING-MACHINE
AB Due to recent advances in IoT (Internet of Things) technologies, availability of reliable data and emergence of machine learning, bio-inspired learning and artificial intelligence, has demonstrated its ability to solve the large complex problems which is not possible before. In particular, machine learning and bio-inspired learning algorithms provides the effective solutions in image processing techniques. However, the implementation of the above-mentioned algorithms in the general CPU requires the intensive usage of bandwidth, area and power which makes the CPU unhealthy of usage and implementation. To overcome this problem, ASIC (application specific integrated circuits), GPU (Graphics Processing Unit) &FPGA (Field Programmable gate arrays) have been employed to improve the performance of the hybrid machine learning (ML) classifiers and deep learning algorithms. FPGA has been recently employed for an effective implementation and to achieve the high performance of the learning algorithms. But integrating the complex learning algorithms in FPGA still remains to be real challenge among the researchers. The paper proposes new reconfigurable architectures for bio- inspired classifiers to diagnosis the medical casualties which can be suitable for the tele health care applications. This paper aim is as follows (i) Design and implementation of Parallel Fusion of FSM and Reconfigurable shared Distributed Arithmetic for Bio-lnspired Classifiers (ii) Development of Accelerator Environment to test the performance of proposed architecture (iii) Performance evaluation of proposed architecture in terms of accuracy of detection in compared with MATLAB simulation iv) Implementation of proposed architectures in different ARtix-7 architectures and determination of power, throughput and area . Moreover, the proposed architecture has been tested with the and compared with the other existing architectures. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ramamoorthy, Prabhu] Gnanamani Coll Technol, Dept Elect & Commun Engn, Namakkal, Tamil Nadu, India.
   [Nallasamy, Viswanathan] Mahendra Engn Coll Autonomous, Dept Elect & Commun Engn, Namakkal, Tamil Nadu, India.
RP Ramamoorthy, P (corresponding author), Gnanamani Coll Technol, Dept Elect & Commun Engn, Namakkal, Tamil Nadu, India.
EM prabhuramamoorthy86@gmail.com
CR Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Ben Ameur MS, 2017, APPL SOFT COMPUT, V58, P378, DOI 10.1016/j.asoc.2017.04.015
   Ben Ameur MS, 2015, I C SCI TECH AUTO CO, P146, DOI 10.1109/STA.2015.7505213
   Bhatti F, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P559, DOI 10.1109/TSP.2017.8076049
   Feng LC, 2018, IEEE T BIOMED CIRC S, V12, P171, DOI 10.1109/TBCAS.2017.2762721
   Gao Chang, 2018, INT S FIELD PROGR GA, P21
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Khan K, 2012, INT J INTELL SYST, V4, P23, DOI [10.5815/ijisa10.5815/ijisa:2012.0710.5815/ijisa:2012.07.03, DOI 10.5815/IJISA.2012.07.03]
   Lian C, 2013, 2013 SIXTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P52, DOI 10.1109/ICACI.2013.6748473
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   Rizakis Michalis, 2018, INT S APPL REC COMP
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   SHALINI VK, 2018, INDIAN J SCI TECHNOL, V11, pNI161, DOI DOI 10.17485/ijst/2018/v11i18/123048
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Thakur Radhe Shyam, 2012, Frontiers in Genetics, V3, P280, DOI 10.3389/fgene.2012.00280
   Wang BT, 2015, NEUROCOMPUTING, V149, P224, DOI 10.1016/j.neucom.2014.03.076
   Wang ZQ, 2014, NEUROCOMPUTING, V128, P175, DOI 10.1016/j.neucom.2013.05.053
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Zhao WL, 2016, IEEE INT CONF ASAP, P107, DOI 10.1109/ASAP.2016.7760779
NR 20
TC 0
Z9 0
U1 0
U2 11
PD MAR
PY 2020
VL 73
AR 102960
DI 10.1016/j.micpro.2019.102960
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Tye, NJ
   Hofmann, S
   Stanley-Marbell, P
AF Tye, Nathaniel Joseph
   Hofmann, Stephan
   Stanley-Marbell, Phillip
TI Materials and devices as solutions to computational problems in machine
   learning
SO NATURE ELECTRONICS
DT Article
ID ON-CHIP; ELECTRONICS; NETWORK
AB The growth of machine learning, combined with the approaching limits of conventional digital computing, are driving a search for alternative and complementary forms of computation, but few novel devices have been adopted by mainstream computing systems. The development of such computer technology requires advances in both computational devices and computer architectures. However, a disconnect exists between the device community and the computer architecture community, which limits progress. Here we explore this disconnect with a focus on machine learning hardware accelerators. We argue that the direct mapping of computational problems to materials and device properties provides a powerful route forwards. We examine novel materials and devices that have been successfully applied as solutions to computational problems: non-volatile memories for matrix-vector multiplication, magnetic tunnel junctions for stochastic computing and resistive memory for reconfigurable logic. We also propose metrics to facilitate comparisons between different solutions to machine learning tasks and highlight applications where novel materials and devices could potentially be of use.
   This Perspective explores the potential of directly mapping computational problems in machine learning to materials and device properties, and proposes metrics to facilitate comparisons between different solutions to machine learning tasks.
C1 [Tye, Nathaniel Joseph; Hofmann, Stephan; Stanley-Marbell, Phillip] Univ Cambridge, Dept Engn, Cambridge, England.
   [Tye, Nathaniel Joseph] Univ Cambridge, Cambridge Graphene Ctr, Cambridge, England.
RP Stanley-Marbell, P (corresponding author), Univ Cambridge, Dept Engn, Cambridge, England.
EM phillip.stanley-marbell@eng.cam.ac.uk
CR Abu-Mostafa Y., 2012, LEARNING DATA
   Adolf R, 2016, I S WORKL CHAR PROC, P148
   Åkerman J, 2005, SCIENCE, V308, P508, DOI 10.1126/science.1110549
   Asanovic K., 2006, EECS2006183 UCB
   Bhuin S, 2017, IEEE CONF NANOTECH, P1027, DOI 10.1109/NANO.2017.8117297
   Bhuin S, 2017, IEEE INT SYMP NANO, P147, DOI 10.1109/NANOARCH.2017.8053738
   Borders WA, 2019, NATURE, V573, P390, DOI 10.1038/s41586-019-1557-9
   Brent Richard P., 1976, ANALYTIC COMPUTATION, P151
   Byerly A, 2021, NEUROCOMPUTING, V463, P545, DOI 10.1016/j.neucom.2021.08.064
   Camsari KY, 2019, APPL PHYS REV, V6, DOI 10.1063/1.5055860
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Chen JH, 2008, NAT NANOTECHNOL, V3, P206, DOI 10.1038/nnano.2008.58
   Chen Y, 2014, MATER HORIZONS, V1, P489, DOI 10.1039/c4mh00067f
   Chen ZP, 2015, COMP MATER SCI, V110, P102, DOI 10.1016/j.commatsci.2015.08.010
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   ERMENTROUT GB, 1986, SIAM J APPL MATH, V46, P233, DOI 10.1137/0146017
   Fernando C, 2003, LECT NOTES ARTIF INT, V2801, P588
   Fuchs A, 2019, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2019.00023
   Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413
   Galves A, 2013, J STAT PHYS, V151, P896, DOI 10.1007/s10955-013-0733-9
   Gao LG, 2017, IEEE T NUCL SCI, V64, P1535, DOI 10.1109/TNS.2017.2700434
   Garbin D, 2014, INT EL DEVICES MEET
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goswami S, 2021, NATURE, V597, P51, DOI 10.1038/s41586-021-03748-0
   HIATT WR, 1965, APPL PHYS LETT, V6, P106, DOI 10.1063/1.1754187
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu M, 2016, INT SYM QUAL ELECT, P374, DOI 10.1109/ISQED.2016.7479230
   Jolivet R, 2006, J COMPUT NEUROSCI, V21, P35, DOI 10.1007/s10827-006-7074-5
   Jongerius R, 2011, I S WORKL CHAR PROC, P74, DOI 10.1109/IISWC.2011.6114199
   Kaspar C, 2021, NATURE, V594, P345, DOI 10.1038/s41586-021-03453-y
   KEYES RW, 1985, SCIENCE, V230, P138, DOI 10.1126/science.230.4722.138
   Khasanvis S, 2015, IEEE T NANOTECHNOL, V14, P980, DOI 10.1109/TNANO.2015.2439618
   Kim J, 2020, NANO LETT, V20, P929, DOI 10.1021/acs.nanolett.9b03815
   Larger L, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.011015
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li C, 2018, IEEE INT MEM WORKSH, P161
   Li XG, 2015, INT CONF ACOUST SPEE, P4520, DOI 10.1109/ICASSP.2015.7178826
   Li YB, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aade3f
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Lupo N, 2016, IEEE INT SYMP CIRC S, P1594, DOI 10.1109/ISCAS.2016.7538869
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   McDowell DL, 2010, INTEGRATED DESIGN OF MULTISCALE, MULTIFUNCTIONAL MATERIALS AND PRODUCTS, P1
   Mehonic A, 2022, NATURE, V604, P255, DOI 10.1038/s41586-021-04362-w
   Mennel L, 2020, NATURE, V579, P62, DOI 10.1038/s41586-020-2038-x
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mizrahi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03963-w
   Moro F, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31157-y
   Moskowitz S., 2016, ADV MAT INNOVATION M
   Norrie T, 2021, IEEE MICRO, V41, P56, DOI 10.1109/MM.2021.3058217
   Oh S, 2021, NAT NANOTECHNOL, V16, P680, DOI 10.1038/s41565-021-00874-8
   Pagliarini SN, 2020, IEEE T NEUR NET LEAR, V31, P1113, DOI 10.1109/TNNLS.2019.2917819
   Painkras E, 2013, IEEE J SOLID-ST CIRC, V48, P1943, DOI 10.1109/JSSC.2013.2259038
   Palem KV, 2005, IEEE T COMPUT, V54, P1123, DOI 10.1109/TC.2005.145
   Park G, 2014, ADV HEALTHC MATER, V3, P515, DOI 10.1002/adhm.201300220
   Payvand M, 2019, FARADAY DISCUSS, V213, P487, DOI 10.1039/c8fd00114f
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Pesch IS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04614-9
   Querlioz D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1775, DOI 10.1109/IJCNN.2011.6033439
   Reddy M., 2011, API DESIGN C, P209
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Rumble J., 2019, CRC HDB CHEM PHYS 20
   Salas E. B., 2022, STATISTA
   Salmilehto J, 2017, SCI REP-UK, V7, DOI 10.1038/srep42044
   Sarpeshkar R, 1998, NEURAL COMPUT, V10, P1601, DOI 10.1162/089976698300017052
   Schuman CD, 2022, NAT COMPUT SCI, V2, P10, DOI 10.1038/s43588-021-00184-y
   Smith JD, 2022, NAT ELECTRON, V5, P102, DOI 10.1038/s41928-021-00705-7
   Soriano M. C., 2017, PHYSICS, DOI [10.1103/physics.10.12, DOI 10.1103/PHYSICS.10.12]
   Spagnolo M, 2022, NAT PHOTONICS, V16, P318, DOI 10.1038/s41566-022-00973-5
   Tan F, 2013, IEEE T NUCL SCI, V60, P4520, DOI 10.1109/TNS.2013.2287615
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Wang H, 2019, PHYS STATUS SOLIDI-R, V13, DOI 10.1002/pssr.201900073
   Wang Y, 2019, MATER TODAY, V28, P63, DOI 10.1016/j.mattod.2019.06.006
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
   Zadeh AH, 2019, I S WORKL CHAR PROC, P131, DOI 10.1109/IISWC47752.2019.9041972
   Zhang HT, 2022, SCIENCE, V375, P533, DOI 10.1126/science.abj7943
NR 80
TC 0
Z9 0
U1 13
U2 13
PD JUL
PY 2023
VL 6
IS 7
BP 479
EP 490
DI 10.1038/s41928-023-00977-1
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Pagliari, DJ
   Macii, E
   Poncino, M
AF Pagliari, Daniele Jahier
   Macii, Enrico
   Poncino, Massimo
GP ACM
TI Dynamic Bit-width Reconfiguration for Energy-Efficient Deep Learning
   Hardware
SO PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN (ISLPED '18)
SE International Symposium on Low Power Electronics and Design
DT Proceedings Paper
CT 23rd IEEE/ACM International Symposium on Low Power Electronics and
   Design (ISLPED)
CY JUL 23-25, 2018
CL Bellevue, WA
DE Energy-efficiency; Deep learning; Energy-quality tradeoff
AB Deep learning models have reached state of the art performance in many machine learning tasks. Benefits in terms of energy, bandwidth, latency, etc., can be obtained by evaluating these models directly within Internet of Things end nodes, rather than in the cloud. This calls for implementations of deep learning tasks that can run in resource limited environments with low energy footprints. Research and industry have recently investigated these aspects, coming up with specialized hardware accelerators for low power deep learning. One effective technique adopted in these devices consists in reducing the bit-width of calculations, exploiting the error resilience of deep learning. However, bit-widths are tipically set statically for a given model, regardless of input data. Unless models are retrained, this solution invariably sacrifices accuracy for energy efficiency.
   In this paper, we propose a new approach for implementing input-dependant dynamic bit-width reconfiguration in deep learning accelerators. Our method is based on a fully automatic characterization phase, and can be applied to popular models without retraining. Using the energy data from a real deep learning accelerator chip, we show that 50% energy reduction can be achieved with respect to a static bit-width selection, with less than 1% accuracy loss.
C1 [Pagliari, Daniele Jahier; Macii, Enrico; Poncino, Massimo] Politecn Torino, Turin, Italy.
RP Pagliari, DJ (corresponding author), Politecn Torino, Turin, Italy.
EM daniele.jahier@polito.it; enrico.macii@polito.it;
   massimo.poncino@polito.it
CR Alioto M, 2017, DES AUT TEST EUROPE, P127, DOI 10.23919/DATE.2017.7926970
   Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   Bong K, 2017, IEEE MICRO, V37, P30, DOI 10.1109/MM.2017.4241350
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107, DOI DOI 10.5555/3157382.3157557
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Moons B, 2017, DES AUT TEST EUROPE, P488, DOI 10.23919/DATE.2017.7927038
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Park E, 2015, 2015 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), P124, DOI 10.1109/CODESISSS.2015.7331375
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Tann H., IEEE ACM IFIP CODES, P1
   Venkataramani S., DAC 2015, P1
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
NR 20
TC 13
Z9 13
U1 0
U2 0
PY 2018
BP 267
EP 272
DI 10.1145/3218603.3218611
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Cococcioni, M
   Rossi, F
   Ruffaldi, E
   Saponara, S
AF Cococcioni, Marco
   Rossi, Federico
   Ruffaldi, Emanuele
   Saponara, Sergio
GP IEEE
TI Novel Arithmetics to Accelerate Machine Learning Classifiers in
   Autonomous Driving Applications
SO 2019 26TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND
   SYSTEMS (ICECS)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 26th IEEE International Conference on Electronics, Circuits and Systems
   (ICECS)
CY NOV 27-29, 2019
CL Genoa, ITALY
DE k-Nearest Neighbors (k-NN); Alternative Real Representation; Posits;
   Machine Learning (ML) Accelerator
AB Autonomous driving techniques frequently need the clustering and the classification of data coming from several input sensors, like cameras, radar and lidars. These sub-tasks need to be implemented in real-time in embedded on-board computing units. The trend for data classification and clustering in the signal processing community is moving towards machine learning (ML) algorithms. One of them, which plays a central role, is the k-nearest neighbors (k-NN) algorithm. To meet stringent requirements in terms of real-time computing capability and circuit/memory complexity, ML accelerators are needed. Innovation is required in terms of computing arithmetic since classic integer numbers lead to low classification accuracy with respect to the needs of safety critical applications like autonomous driving. Instead, floating numbers require too much circuit and memory. To overcome these issues the paper shows that the use of a new format, called Posit, implemented in a new cppPosit software library, can lead to a k-NN implementation having the same accuracy of floats, but with halved bit-size. This means that a Posit Processing Unit ( PPU) reduces by a factor higher than 2 the data transfer and storage complexity of ML accelerators. We also prove that a LUT-based complete tabulated implementation of a PPU for a 8-bit requires just 64 kB storage size, compliant with memory-constrained devices.
C1 [Cococcioni, Marco; Rossi, Federico; Saponara, Sergio] Univ Pisa, Dept Informat Engn, Pisa, Italy.
   [Ruffaldi, Emanuele] MMI Spa, Pisa, Italy.
RP Cococcioni, M (corresponding author), Univ Pisa, Dept Informat Engn, Pisa, Italy.
CR Bubolz TLA, 2019, IEEE T CIRCUITS-I, V66, P2124, DOI 10.1109/TCSI.2019.2903978
   [Anonymous], 2018, WP09183001, P1
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Cococcioni M., 2018, IEEE AUTOMOTIVE 2018
   Du L, 2020, IEEE T CIRCUITS-II, V67, P760, DOI 10.1109/TCSII.2019.2922657
   Gustafson J. L., 2017, SUPERCOMP FRONTIERS, V4
   Hubara I., 2017, J ML RES, V18
   Koster U., NIPS 2017, P1740
   Lo Bello L., 2019, IEEE TRAN IND INF, V15
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nousi P, 2018, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2018.8451600
   Popescu V., 2018, IEEE S COMP AR
   Reinhardt D., 2019010118 SAE
   Royo-Alvarez J, 2018, DIGITAL SIGNAL PROCE
   Saponara S., 2019, IEEE SIGNAL PROCESSI, V36
   Srivastava G., ICASSP 2019
   Tagliavini G., 2019, IEEE T CAD INT CIR S
   Venkatesh G., IEEE ICASSP 2017
NR 19
TC 6
Z9 6
U1 0
U2 4
PY 2019
BP 779
EP 782
DI 10.1109/icecs46596.2019.8965031
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Choudhury, R
   Ahamed, SR
   Guha, P
AF Choudhury, Rituparna
   Ahamed, Shaik Rafi
   Guha, Prithwijit
GP IEEE
TI FPGA Implementation of Low Complexity Hybrid Decision Tree Training
   Accelerator
SO 2021 IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)
CY AUG 09-11, 2021
CL ELECTR NETWORK
DE Machine Learning; Decision Tree; FPGA; Training Accelerator; Hybrid
   Decision Tree
ID CLASSIFICATION
AB Decision Tree (DT) algorithms perform classification of data according to decision criteria obtained during training which results in high computational complexity and latency. In this paper, a Hybrid DT (HDT) is proposed which reduces training complexity and achieves 8x speed-up as compared to conventional DT. The critical path of proposed HDT hardware enables the FPGA to operate at a maximum frequency of 125 MHz. Simulation results show that the proposed hardware achieves 1000 x speed-up as compared to software-based realisation and 60x speed-up as compared to existing FPGA training accelerator.
C1 [Choudhury, Rituparna; Ahamed, Shaik Rafi; Guha, Prithwijit] IIT Guwahati, Dept EEE, Gauhati, Assam, India.
RP Choudhury, R (corresponding author), IIT Guwahati, Dept EEE, Gauhati, Assam, India.
EM ritup176102101@iitg.ac.in; rafiahamed@iitg.ac.in; pguha@iitg.ac.in
CR Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1501/0000000035, 10.1561/0600000035]
   Dua D, 2020, UCI MACHINE LEARNING
   Foresti GL, 2004, IEEE T SYST MAN CY B, V34, P988, DOI 10.1109/TSMCB.2003.818538
   Muniyandi AP, 2012, PROCEDIA ENGINEER, V30, P174, DOI 10.1016/j.proeng.2012.01.849
   Qian M, 2006, 2006 IMACS: Multiconference on Computational Engineering in Systems Applications, Vols 1 and 2, P504
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Saegusa T, 2007, J REAL-TIME IMAGE PR, V2, P309, DOI 10.1007/s11554-007-0055-8
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Shoaran M, 2018, IEEE J EM SEL TOP C, V8, P693, DOI 10.1109/JETCAS.2018.2844733
   Tong D, 2017, IEEE T PARALL DISTR, V28, P3046, DOI 10.1109/TPDS.2017.2714661
   Winterstein F, 2013, I C FIELD PROG LOGIC
NR 13
TC 1
Z9 1
U1 1
U2 1
PY 2021
BP 511
EP 514
DI 10.1109/MWSCAS47672.2021.9531848
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Kim, DH
   Kim, HS
   Kwon, HJ
   Lee, SH
   Yun, SP
   Kim, SG
   Yu, YG
   Dang, JJ
AF Kim, Dong-Hwan
   Kim, Han-Sung
   Kwon, Hyeok-Jung
   Lee, Seung-Hyun
   Yun, Sang-Pil
   Kim, Seung-Geun
   Yu, Yong-Gyun
   Dang, Jeong-Jeung
TI Deep neural network-based prediction for low-energy beam transport
   tuning
SO JOURNAL OF THE KOREAN PHYSICAL SOCIETY
DT Article
DE RFQ-based accelerator; Beam-induced fluorescence monitor; Machine
   learning-based regression; Deep neural networks; Low-energy beam tuning
ID EMITTANCE MEASUREMENT; ION-SOURCE
AB Time-varying characteristics of an ion source are induced by environmental change or aging of parts inevitably, making a data-driven prediction model inaccurate. We consider non-invasively measured beam profiles as important features to represent initial beam from ion sources in real time. Beam-induced fluorescence monitor was tested to confirm change of beam properties by ion source operating conditions during a beam commissioning phase. Machine learning-based regression models were built with beam dynamics simulation datasets over a range of input parameters in the RFQ-based accelerator. Best prediction for the low-energy beam tuning was obtained by deep neural networks model. The methodology presented in the study can help develop advanced beam tuning models with non-invasive beam diagnostics in time-varying systems.
C1 [Kim, Dong-Hwan; Kim, Han-Sung; Kwon, Hyeok-Jung; Lee, Seung-Hyun; Yun, Sang-Pil] Korea Atom Energy Res Inst, Accelerator Dev & Res Div, Gyeoung Ju, South Korea.
   [Kim, Seung-Geun; Yu, Yong-Gyun] Korea Atom Energy Res Inst, Appl Artificial Intelligence Applicat & Strategy T, Daejeon, South Korea.
   [Dang, Jeong-Jeung] Korea Inst Energy Technol, Na Ju, South Korea.
RP Kim, DH (corresponding author), Korea Atom Energy Res Inst, Accelerator Dev & Res Div, Gyeoung Ju, South Korea.
EM one@kaeri.re.kr
CR ALLISON PW, 1983, IEEE T NUCL SCI, V30, P2204, DOI 10.1109/TNS.1983.4332762
   Becker F., 2011, P DIPAC2011 HAMB GER
   Bellan L, 2022, J PHYS CONF SER, V2244, DOI 10.1088/1742-6596/2244/1/012078
   Cheon YL, 2020, PHYS PLASMAS, V27, DOI 10.1063/5.0004651
   Cheon YL, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.064002
   Cheon YL, 2021, NUCL INSTRUM METH A, V1013, DOI 10.1016/j.nima.2021.165647
   Chimura M, 2022, PROG THEOR EXP PHYS, V2022, DOI 10.1093/ptep/ptac077
   Debongnie M., 2019, IPAC2019 MELB AUSTR
   Debongnie Mathieu, 2021, THESIS U GRENOBLE AL
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Fol E., 2018, 7 INT BEAM I C IBIC2
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Hachmann Max, 2012, THESIS HAMBURG U
   Harasimowicz J, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.122801
   HOCHADEL B, 1994, NUCL INSTRUM METH A, V343, P401, DOI 10.1016/0168-9002(94)90217-8
   Hong BH, 2020, J KOREAN PHYS SOC, V77, P1159, DOI 10.3938/jkps.77.1159
   Ke GL, 2017, ADV NEUR IN, V30
   Kim Han-Sung, 2022, 31 INT LIN ACC C LIN
   Kong YB, 2016, NUCL INSTRUM METH A, V806, P55, DOI 10.1016/j.nima.2015.09.095
   Kwon HJ, 2016, J KOREAN PHYS SOC, V69, P967, DOI 10.3938/jkps.69.967
   Kwon HJ, 2010, J KOREAN PHYS SOC, V56, P1998, DOI 10.3938/jkps.56.1998
   Miyamoto R, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/P07027
   Noll D., 2022, 31 INT LIN ACC C LIN
   Scheinker A, 2021, INFORMATION, V12, DOI 10.3390/info12040161
   Shemyakin A, 2017, AIP CONF PROC, V1869, DOI 10.1063/1.4995784
   Uriot D., 2015, 6 INT PART ACC C IPA
   Yao Z, 2008, REV SCI INSTRUM, V79, DOI 10.1063/1.2954967
NR 27
TC 0
Z9 0
U1 2
U2 2
PD OCT
PY 2023
VL 83
IS 8
SI SI
BP 647
EP 653
DI 10.1007/s40042-023-00848-0
EA JUL 2023
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Scheinker, A
   Cropp, F
   Filippetto, D
AF Scheinker, Alexander
   Cropp, Frederick
   Filippetto, Daniele
TI Adaptive autoencoder latent space tuning for more robust machine
   learning beyond the training set for six-dimensional phase space
   diagnostics of a time-varying ultrafast electron-diffraction compact
   accelerator
SO PHYSICAL REVIEW E
DT Article
ID NEURAL-NETWORKS; SEEKING
AB We present a general adaptive latent space tuning approach for improving the robustness of machine learning tools with respect to time variation and distribution shift. We demonstrate our approach by developing an encoder-decoder convolutional neural network-based virtual 6D phase space diagnostic of charged particle beams in the HiRES ultrafast electron diffraction (UED) compact particle accelerator with uncertainty quan-tification. Our method utilizes model-independent adaptive feedback to tune a low-dimensional 2D latent space representation of similar to 1 million dimensional objects which are the 15 unique 2D projections (x, y),...,(z, pz) of the 6D phase space (x, y, z, px, py, pz) of the charged particle beams. We demonstrate our method with numerical studies of short electron bunches utilizing experimentally measured UED input beam distributions.
C1 [Scheinker, Alexander] Los Alamos Natl Lab, Appl Electrodynam Grp, Los Alamos, NM 87545 USA.
   [Cropp, Frederick; Filippetto, Daniele] Lawrence Berkeley Natl Lab, One Cyclotron Rd, Berkeley, CA 94720 USA.
   [Cropp, Frederick] Univ Calif Los Angeles, Dept Phys & Astron, Los Angeles, CA 90095 USA.
RP Scheinker, A (corresponding author), Los Alamos Natl Lab, Appl Electrodynam Grp, Los Alamos, NM 87545 USA.
EM ascheink@lanl.gov
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   [Anonymous], 2013, CLASSICAL THEORY FIE
   [Anonymous], 2013, MONTE CARLO CONCEPTS
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Banerjee A, 2021, PHYS REV X, V11, DOI 10.1103/PhysRevX.11.031014
   Blokland W, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.122802
   Calandra Roberto, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. 22nd International Conference on Artificial Neural Networks, P379, DOI 10.1007/978-3-642-33266-1_47
   Cathey B, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.064804
   Dramsch JS, 2021, COMPUT GEOSCI-UK, V146, DOI 10.1016/j.cageo.2020.104643
   Duris J., 2018, P ICFA ADV BEAM DYN
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Faure J, 2006, NATURE, V444, P737, DOI 10.1038/nature05393
   Faure J, 2004, NATURE, V431, P541, DOI 10.1038/nature02963
   Filippetto D, 2016, J PHYS B-AT MOL OPT, V49, DOI 10.1088/0953-4075/49/10/104003
   Flurin E, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.011006
   Fösel T, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.031084
   Fol E, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-021-01348-5
   Fol E, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.102805
   Goehring T, 2019, J ACOUST SOC AM, V146, P705, DOI 10.1121/1.5119226
   Gupta L, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac27ff
   Huang JY, 2007, ADV NEURAL INFORM PR, V19, P601
   Javadi Golara, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P524, DOI 10.1007/978-3-030-59716-0_50
   Ji F, 2019, COMMUN PHYS-UK, V2, DOI 10.1038/s42005-019-0154-4
   John J. St., 2021, PHYS REV ACCEL BEAMS, V24
   Kabra K, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.022803
   Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5
   Khalil H. K, 2002, NONLINEAR SYSTEMS, V115
   Kirschner J, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.062802
   Koesdwiady A., 2018, P 2018 INT JOINT C N, V2018, DOI DOI 10.1109/IJCNN.2018.8489402
   Kuklev N., 2022, MACH LEARN PHYS SCI
   Kurle R., 2020, ICLR
   Labat M, 2023, NAT PHOTONICS, V17, P150, DOI 10.1038/s41566-022-01104-w
   Lemery F, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.044801
   Li S, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.114801
   Li SZ, 2019, PHYS REV B, V100, DOI 10.1103/PhysRevB.100.020302
   Malyzhenkov A, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.042018
   Ram¡rez MAM, 2019, Arxiv, DOI [arXiv:1905.06148, 10.48550/arXiv.1905.06148, DOI 10.48550/ARXIV.1905.06148]
   Mayet F, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.094601
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Roussel R, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25757-3
   Rrapaj E, 2021, PHYS REV E, V103, DOI 10.1103/PhysRevE.103.013302
   Scheinker A, 2021, J INSTRUM, V16, DOI 10.1088/1748-0221/16/10/P10008
   Scheinker A, 2020, Arxiv, DOI arXiv:2001.05461
   Scheinker A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98785-0
   Scheinker A, 2020, J APPL PHYS, V128, DOI 10.1063/5.0014725
   Scheinker A, 2021, INT J ADAPT CONTROL, V35, P1143, DOI 10.1002/acs.3097
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2017, IEEE T CONTR SYST T, V25, P1521, DOI 10.1109/TCST.2016.2604742
   Scheinker A, 2016, AUTOMATICA, V69, P250, DOI 10.1016/j.automatica.2016.02.023
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Scheinker A, 2013, P AMER CONTR CONF, P2637
   Scheinker A, 2013, IEEE T AUTOMAT CONTR, V58, P1107, DOI 10.1109/TAC.2012.2225514
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Shea DE, 2021, IEEE ACCESS, V9, P83453, DOI 10.1109/ACCESS.2021.3087595
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Sugiyama M, 2012, ADAPT COMPUT MACH LE, P1
   Sugiyama M., 2007, ADV NEURAL INFORM PR, V7, P1433, DOI DOI 10.1109/FG.2013.6553717
   Turner M, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.054801
   van Oudheusden T, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.264801
   Wolski A, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.122803
   Zhu J, 2021, PHYS REV APPL, V16, DOI 10.1103/PhysRevApplied.16.024005
NR 62
TC 0
Z9 0
U1 4
U2 4
PD APR 19
PY 2023
VL 107
IS 4
AR 045302
DI 10.1103/PhysRevE.107.045302
WC Physics, Fluids & Plasmas; Physics, Mathematical
DA 2023-11-11
ER

PT J
AU Ni, YF
   Deng, YD
   Li, SL
AF Ni, Yufei
   Deng, Yangdong
   Li, Songlin
TI PMBA: A Parallel MCMC Bayesian Computing Accelerator
SO IEEE ACCESS
DT Article
DE Bayes methods; Probabilistic logic; Markov processes; Hardware;
   Synchronization; Computational modeling; Task analysis; Accelerator
   architectures; Bayesian methods; FPGA; MCMC; parallel machines
ID CLASSIFICATION
AB Bayesian computing, including sampling probability distributions, learning graphic model, and Bayesian reasoning, is a powerful class of machine learning algorithms with such wide applications as biologic computing, financial analysis, natural language processing, autonomous driving, and robotics. The central pattern of Bayesian computing is the Markov Chain Monte Carlo (MCMC) computing, which is compute-intensive and lacks explicit parallelism. In this work, we propose a parallel MCMC Bayesian computing accelerator (PMBA) architecture. Designed as a probabilistic computing platform with native support for efficient single-chain parallel Metropolis-Hastings based MCMC sampling, PMBA boosts the performance of probabilistic programs with a massive-parallelism microarchitecture. PMBA is equipped with on-chip random number generators as the built-in source of randomness. The sampling units of PMBA are designed for parallel random sampling through a customized SIMD pipeline supporting data synchronization every iteration. A respective computing framework supporting automatic parallelization and mapping of probabilistic programs is also developed. Evaluation results demonstrate that PMBA enables a 17-21 folds speedup over a TITAN X GPU on MCMC sampling workload. On probabilistic benchmarks, PMBA outperforms prior best solutions by factor of 3.6 to 10.3. An exemplar based visual category learning algorithm is implemented on PMBA to demonstrate its efficiency and effectiveness for complex statistical learning problems.
C1 [Ni, Yufei] Tsinghua Univ, Inst Microelect, Beijing 100084, Peoples R China.
   [Deng, Yangdong; Li, Songlin] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
RP Deng, YD (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM dengyd@mail.tsinghua.edu.cn
CR [Anonymous], 2008, 2069 MITCSAILTR
   Banerjee SS, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P515, DOI 10.1145/3297858.3304019
   Bodik R., 2016, ARXIV160609242
   Brockwell AE, 2006, J COMPUT GRAPH STAT, V15, P246, DOI 10.1198/106186006X100579
   Calderhead B, 2014, P NATL ACAD SCI USA, V111, P17408, DOI 10.1073/pnas.1408184111
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Craiu RV, 2007, STAT COMPUT, V17, P109, DOI 10.1007/s11222-006-9009-4
   Fang K, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P241, DOI 10.1109/ICCD.2013.6657049
   Hartigan J. A., 1985, B AM MATH SOC, V12, P294
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Hernández-Lobato JM, 2015, PR MACH LEARN RES, V37, P1861
   Hosseini M, 2017, ANN IEEE SYM FIELD P, P201, DOI 10.1109/FCCM.2017.56
   Jacobs RA, 2011, WIRES COGN SCI, V2, P8, DOI 10.1002/wcs.80
   Jones M, 2011, BEHAV BRAIN SCI, V34, P169, DOI 10.1017/S0140525X10003134
   Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Körding KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Li J, 2011, IEEE T GEOSCI REMOTE, V49, P3947, DOI 10.1109/TGRS.2011.2128330
   Liu SL, 2017, IEEE T COMPUT, V66, P745, DOI 10.1109/TC.2016.2630682
   Liu SL, 2015, 2015 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (FPT), P120, DOI 10.1109/FPT.2015.7393138
   Ma WJ, 2014, NAT NEUROSCI, V17, P347, DOI 10.1038/nn.3655
   Mahani AS, 2015, COMPUT STAT DATA AN, V88, P75, DOI 10.1016/j.csda.2015.02.010
   Marni L, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351525
   Marni L, 2018, PR GR LAK SYMP VLSI, P165, DOI 10.1145/3194554.3194577
   MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037/0033-295X.85.3.207
   Milch B., 2004, P ICML WORKSH STAT R, P67
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mingas G, 2016, IEEE T COMPUT, V65, P1283, DOI 10.1109/TC.2015.2439256
   Patil A, 2010, J STAT SOFTW, V35, P1
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Ramage D., 2009, P 2009 C EMP METH NA, P248, DOI DOI 10.3115/1699510.1699543
   Rosenthal J., 2000, FAR E J THEORETICAL, V4, P207
   Rouhani BD, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P1, DOI 10.1145/3174243.3174259
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sunar B, 2007, IEEE T COMPUT, V56, P109, DOI 10.1109/TC.2007.250627
   Wang XY, 2015, ADV NEUR IN, V28
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
NR 39
TC 1
Z9 1
U1 0
U2 7
PY 2021
VL 9
BP 65536
EP 65546
DI 10.1109/ACCESS.2021.3076207
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Prabakaran, BS
   Mrazek, V
   Vasicek, Z
   Sekanina, L
   Shafique, M
AF Prabakaran, Bharath Srinivas
   Mrazek, Vojtech
   Vasicek, Zdenek
   Sekanina, Lukas
   Shafique, Muhammad
GP IEEE
TI ApproxFPGAs: Embracing ASIC-Based Approximate Arithmetic Components for
   FPGA-Based Systems
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
DE Approximate Computing; FPGA; ASIC; Adder; Multiplier; Arithmetic Units;
   Machine Learning; Statistics; Models; Synthesis
AB There has been abundant research on the development of Approximate Circuits (ACs) for ASICs. However, previous studies have illustrated that ASIC-based ACs offer asymmetrical gains in FPGA-based accelerators. Therefore, an AC that might be pareto-optimal for ASICs might not be pareto-optimal for FPGAs. In this work, we present the ApproxFPGAs methodology that uses machine learning models to reduce the exploration time for analyzing the state-of-the-art ASIC-based ACs to determine the set of pareto-optimal FPGA-based ACs. We also perform a case-study to illustrate the benefits obtained by deploying these pareto-optimal FPGA-based ACs in a state-of-the-art automation framework to systematically generate pareto-optimal approximate accelerators that can be deployed in FPGA-based systems to achieve high performance or low-power consumption.
C1 [Prabakaran, Bharath Srinivas; Shafique, Muhammad] Tech Univ Wien, TU Wien, Inst Comp Engn, Vienna, Austria.
   [Mrazek, Vojtech; Vasicek, Zdenek; Sekanina, Lukas] Brno Univ Technol, Fac Informat Technol, IT4Innovat Ctr Excellence, Brno, Czech Republic.
RP Prabakaran, BS (corresponding author), Tech Univ Wien, TU Wien, Inst Comp Engn, Vienna, Austria.
EM bharath.prabakaran@tuwien.ac.at; mrazek@fit.vutbr.cz;
   vasicek@fit.vutbr.cz; sekanina@fit.vutbr.cz;
   muhammad.shafique@tuwien.ac.at
CR [Anonymous], 2013, DAC
   Baek W, 2010, ACM SIGPLAN NOTICES, V45, P198, DOI 10.1145/1809028.1806620
   Crockett L.H., 2014, ZYNQ BOOK EMBEDDED P
   Echavarria J., 2016, FPT
   Han J, 2013, PROC EUR TEST SYMP
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Jiang H., 2015, GLSVLSI
   Khudia D. S., 2015, ISCA
   Mishra A. K., 2014, WACAS
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mrazek V., 2017, DATE
   Mrazek V, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317781
   Patel JN, 2016, PROCEEDINGS OF THE 2016 IEEE 21ST INTERNATIONAL MIXED-SIGNALS TEST WORKSHOP (IMSTW)
   Prabakaran B. S., 2018, DATE
   Saadat H, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317773
   Saadat H, 2018, IEEE T COMPUT AID D, V37, P2623, DOI 10.1109/TCAD.2018.2857262
   Sampson A, 2011, ACM SIGPLAN NOTICES, V46, P164, DOI 10.1145/1993316.1993518
   Trimberger Stephen M. Steve, 2018, IEEE Solid-State Circuits Magazine, V10, P16, DOI 10.1109/MSSC.2018.2822862
   Ullah S., 2018, DAC
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Venkataramani S., 2013, MICRO
   Watanabe R., 2019, P 10 HEART
   Yazdanbakhsh A, 2015, DES AUT TEST EUROPE, P812
NR 23
TC 10
Z9 10
U1 0
U2 0
PY 2020
DI 10.1109/dac18072.2020.9218533
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Merkel, C
   Hasan, R
   Soures, N
   Kudithipudi, D
   Taha, T
   Agarwal, S
   Marinella, M
AF Merkel, Cory
   Hasan, Raqibul
   Soures, Nicholas
   Kudithipudi, Dhireesha
   Taha, Tarek
   Agarwal, Sapan
   Marinella, Matthew
TI Neuromemristive Systems: Boosting Efficiency through Brain-Inspired
   Computing
SO COMPUTER
DT Article
AB Neuromemristive systems (NMSs) are gaining traction as an alternative to conventional CMOS-based von Neumann systems because of their greater energy and area efficiency. A proposed NMS accelerator for machine-learning tasks reduced power dissipation by five orders of magnitude, relative to a multicore reduced-instruction set computing processor.
C1 [Merkel, Cory] US Air Force Res Lab, Informat Directorate, Washington, DC USA.
   [Soures, Nicholas] Rochester Inst Technol, Rochester, NY 14623 USA.
   [Kudithipudi, Dhireesha] Rochester Inst Technol, Dept Comp Engn, Rochester, NY 14623 USA.
   [Taha, Tarek] Univ Dayton, Elect & Comp Engn, Dayton, OH 45469 USA.
   [Agarwal, Sapan; Marinella, Matthew] Sandia Natl Labs, Livermore, CA 94550 USA.
RP Merkel, C (corresponding author), US Air Force Res Lab, Informat Directorate, Washington, DC USA.
EM cory.merkel.1@us.af.mil; hasanm1@udayton.edu; nms9121@g.rit.edu;
   dxkeec@rit.edu; ttaha@ieee.org; sagarwa@sandia.gov; mmarine@sandia.gov
CR Austin T, 2002, COMPUTER, V35, P59, DOI 10.1109/2.982917
   Burr G.W., 2015, IEEE TRANS ELECTRON, VPP
   Cheng C.H., 2010, P IEEE INT EL DEV M, P4
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Hasan R., 2016, P IEE EINT C REB COM
   Hsu J, 2014, IEEE SPECTRUM, V51, P17, DOI 10.1109/MSPEC.2014.6905473
   Hung-Yen T., 2014, P IEEE INT SOL STAT, P196
   Liu X, 2015, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON E-BUSINESS, MANAGEMENT AND ECONOMICS (ICEME 2017), P66, DOI 10.1145/3157754.3157777
   Merkel Cory, 2014, PROC IEEE INTL SYSTE, P359
   Pickett MD, 2009, J APPL PHYS, V106, DOI 10.1063/1.3236506
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Zhiping Z., 2013, ELECT DEV LETT, V34, P1005
NR 12
TC 20
Z9 21
U1 0
U2 14
PD OCT
PY 2016
VL 49
IS 10
BP 56
EP 64
DI 10.1109/MC.2016.312
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Iwami, R
   Mihana, T
   Kanno, K
   Sunada, S
   Naruse, M
   Uchida, A
AF Iwami, Ryugo
   Mihana, Takatomo
   Kanno, Kazutaka
   Sunada, Satoshi
   Naruse, Makoto
   Uchida, Atsushi
TI Controlling chaotic itinerancy in laser dynamics for reinforcement
   learning
SO SCIENCE ADVANCES
DT Article
ID COHERENCE COLLAPSE; SYNCHRONIZATION; OPTIMIZATION; EXPLORATION;
   PHOTONICS; MODEL; GAME; GO
AB Photonic artificial intelligence has attracted considerable interest in accelerating machine learning; however, the unique optical properties have not been fully used for achieving higher-order functionalities. Chaotic itin-erancy, with its spontaneous transient dynamics among multiple quasi-attractors, can be used to realize brain-like functionalities. In this study, we numerically and experimentally investigate a method for controlling the chaotic itinerancy in a multimode semiconductor laser to solve a machine learning task, namely, the multiarmed bandit problem, which is fundamental to reinforcement learning. The proposed method uses chaotic itinerant motion in mode competition dynamics controlled via optical injection. We found that the exploration mecha-nism is completely different from a conventional searching algorithm and is highly scalable, outperforming the conventional approaches for large-scale bandit problems. This study paves the way to use chaotic itinerancy for effectively solving complex machine learning tasks as photonic hardware accelerators.
C1 [Iwami, Ryugo; Mihana, Takatomo; Kanno, Kazutaka; Uchida, Atsushi] Saitama Univ, Dept Informat & Comp Sci, 255 Shimo Okubo,Sakura Ku, Saitama, Saitama 3388570, Japan.
   [Sunada, Satoshi] Kanazawa Univ, Inst Sci & Engn, Fac Mech Engn, Kakuma Machi, Kanazawa, Ishikawa 9201192, Japan.
   [Sunada, Satoshi] Japan Sci & Technol Agcy JST, PRESTO, 4-1-8 Honcho, Kawaguchi, Saitama 3320012, Japan.
   [Naruse, Makoto] Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Informat Phys & Comp, 7-3-1 Hongo,Bunkyo Ku, Tokyo 1138656, Japan.
RP Iwami, R; Uchida, A (corresponding author), Saitama Univ, Dept Informat & Comp Sci, 255 Shimo Okubo,Sakura Ku, Saitama, Saitama 3388570, Japan.
EM r.iwami.692@ms.saitama-u.ac.jp; auchida@mail.saitama-u.ac.jp
CR Adachi M, 1997, NEURAL NETWORKS, V10, P83, DOI 10.1016/S0893-6080(96)00061-5
   AIDA T, 1994, IEEE J QUANTUM ELECT, V30, P2986, DOI 10.1109/3.362706
   [Anonymous], 2017, SEMICONDUCTOR LASERS
   Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Chen XL, 2019, J LIGHTWAVE TECHNOL, V37, P4155, DOI 10.1109/JLT.2019.2923615
   Fischer I, 1996, PHYS REV LETT, V76, P220, DOI 10.1103/PhysRevLett.76.220
   FREEMAN WJ, 1987, BIOL CYBERN, V56, P139, DOI 10.1007/BF00317988
   Hart JD, 2017, APL PHOTONICS, V2, DOI 10.1063/1.5000056
   Homma R, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45754-3
   Hwang SK, 2000, OPT COMMUN, V183, P195, DOI 10.1016/S0030-4018(00)00865-8
   IKEDA K, 1989, PROG THEOR PHYS SUPP, P295, DOI 10.1143/PTPS.99.295
   Ikegami T, 2007, J CONSCIOUSNESS STUD, V14, P111
   Inagaki T, 2016, SCIENCE, V354, P603, DOI 10.1126/science.aah4243
   Inoue K, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abb3989
   Ishihara T, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3178452
   Iwami R, 2022, Arxiv, DOI arXiv:2211.08185
   KANEKO K, 1990, PHYSICA D, V41, P137, DOI 10.1016/0167-2789(90)90119-A
   Kanno K, 2016, PHYS REV E, V93, DOI 10.1103/PhysRevE.93.032206
   Kim SJ, 2016, PHILOSOPHIES, V1, P245, DOI 10.3390/philosophies1030245
   Kim SJ, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/8/083023
   Kim SJ, 2010, BIOSYSTEMS, V101, P29, DOI 10.1016/j.biosystems.2010.04.002
   Kima SJ, 2014, IEICE NONLINEAR THEO, V5, P198, DOI 10.1587/nolta.5.198
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Kleinberg R., 2004, ADV NEURAL INFORM PR, V17, P697
   Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842_29
   Koryukin IV, 2004, PHYS REV A, V70, DOI 10.1103/PhysRevA.70.053819
   KOVANIS V, 1995, APPL PHYS LETT, V67, P2780, DOI 10.1063/1.114591
   Kroemer OB, 2010, ROBOT AUTON SYST, V58, P1105, DOI 10.1016/j.robot.2010.06.001
   Kuniyoshi Y, 2006, BIOL CYBERN, V95, P589, DOI 10.1007/s00422-006-0127-z
   Lai LF, 2011, IEEE T MOBILE COMPUT, V10, P239, DOI 10.1109/TMC.2010.65
   Lam WS, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.010602
   LANG R, 1980, IEEE J QUANTUM ELECT, V16, P347, DOI 10.1109/JQE.1980.1070479
   Larger L, 2012, OPT EXPRESS, V20, P3241, DOI 10.1364/OE.20.003241
   Liu Y, 1998, INT J BIFURCAT CHAOS, V8, P1685, DOI 10.1142/S0218127498001352
   Menkveld AJ, 2016, ANNU REV FINANC ECON, V8, P1, DOI 10.1146/annurev-financial-121415-033010
   Mihana T, 2020, OPT EXPRESS, V28, P40112, DOI 10.1364/OE.411140
   Mihana T, 2019, OPT EXPRESS, V27, P26989, DOI 10.1364/OE.27.026989
   Narisawa N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83726-8
   Naruse M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29117-y
   Naruse M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08585-8
   Niiyama T, 2020, J PHYS SOC JPN, V89, DOI 10.7566/JPSJ.89.014801
   OTT E, 1990, PHYS REV LETT, V64, P1196, DOI 10.1103/PhysRevLett.64.1196
   Park J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182518
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Rogister F, 2000, PHYS REV A, V62, DOI 10.1103/PhysRevA.62.061803
   SANO T, 1994, PHYS REV A, V50, P2719, DOI 10.1103/PhysRevA.50.2719
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Soriano MC, 2013, REV MOD PHYS, V85, P421, DOI 10.1103/RevModPhys.85.421
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Takano K, 2018, OPT EXPRESS, V26, P29424, DOI 10.1364/OE.26.029424
   Takeuchi S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58541-2
   Tsuchiya T, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aau2057
   TSUDA I, 1987, PROG THEOR PHYS, V78, P51, DOI 10.1143/PTP.78.51
   Tsuda I, 2001, BEHAV BRAIN SCI, V24, P793, DOI 10.1017/S0140525X01000097
   Tsuda I., 1991, WORLD FUTURES, V32, P167, DOI [DOI 10.1080/02604027.1991.9972257, 10.1080/02604027.1991.9972257]
   Tsuda I, 2015, CURR OPIN NEUROBIOL, V31, P67, DOI 10.1016/j.conb.2014.08.011
   Uchida A, 2001, PHYS REV A, V64, DOI 10.1103/PhysRevA.64.023801
   Uchida A., 2012, OPTICAL COMMUNICATIO, V1st
   Wada K, 2017, MATERIALS, V10, DOI 10.3390/ma10080950
   Wieczorek S, 2000, OPT COMMUN, V183, P215, DOI 10.1016/S0030-4018(00)00867-1
NR 64
TC 3
Z9 4
U1 5
U2 12
PD DEC 7
PY 2022
VL 8
IS 49
AR eabn8325
DI 10.1126/sciadv.abn8325
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Karam, R
   Paul, S
   Puri, R
   Bhunia, S
AF Karam, Robert
   Paul, Somnath
   Puri, Ruchir
   Bhunia, Swarup
TI Memory-Centric Reconfigurable Accelerator for Classification and Machine
   Learning Applications
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Reconfigurable architectures; hardware accelerators; machine learning;
   memory-centric; parallel processing; energy-efficiency
ID ANALYTICS; ALGORITHM
AB Big Data refers to the growing challenge of turning massive, often unstructured datasets into meaningful, organized, and actionable data. As datasets grow from petabytes to exabytes and beyond, it becomes increasingly difficult to run advanced analytics, especially Machine Learning (ML) applications, in a reasonable time and on a practical power budget using traditional architectures. Previous work has focused on accelerating analytics readily implemented as SQL queries on data-parallel platforms, generally using off-the-shelf CPUs and General Purpose Graphics Processing Units (GPGPUs) for computation or acceleration. However, these systems are general-purpose and still require a vast amount of data transfer between the storage devices and computing elements, thus limiting the system efficiency. As an alternative, this article presents a reconfigurable memory-centric advanced analytics accelerator that operates at the last level of memory and dramatically reduces energy required for data transfer. We functionally validate the framework using an FPGA-based hardware emulation platform and three representative applications: Naive Bayesian Classification, Convolutional Neural Networks, and k-Means Clustering. Results are compared with implementations on a modern CPU and workstation GPGPU. Finally, the use of in-memory dataset decompression to further reduce data transfer volume is investigated. With these techniques, the system achieves an average energy efficiency improvement of 74x and 212x over GPU and single-threaded CPU, respectively, while dataset compression is shown to improve overall efficiency by an additional 1.8x on average.
C1 [Karam, Robert; Bhunia, Swarup] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
   [Paul, Somnath] Intel Labs, Hillsboro, OR USA.
   [Puri, Ruchir] IBM TJ Watson Res Lab, Yorktown Hts, NY USA.
RP Karam, R (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
CR Altera, 2016, QUART 2 SUBSCR ED
   [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   [Anonymous], 2014, WONDP
   [Anonymous], 2012, P INT C HIGH PERF CO
   [Anonymous], 2015, 2015 INT C PERV COMP
   [Anonymous], 2008, EXASCALE COMPUTING S
   [Anonymous], P DES AUT TEST EUR C
   Araya-Polo M, 2011, IEEE T PARALL DISTR, V22, P147, DOI 10.1109/TPDS.2010.144
   Atasu K., 2013, PROC INT C FIELD PRO, P1
   Bakkum P., 2010, P 3 WORKSH GEN PURP, DOI DOI 10.1145/1735688.1735706
   Bergstra J., 2010, P PYTH SCI COMP C SC, P3
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Cong J., 1998, FPGA'98. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P179, DOI 10.1145/275107.275138
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Ebeling C., 1996, Field-Programmable Logic. Smart Applications, New Paradigms and Compilers. 6th International Workshop on Field-Programmable Logic and Applications, FPL '96 Proceedings, P126
   Esmaeilzadeh H, 2013, COMMUN ACM, V56, P93, DOI 10.1145/2408776.2408797
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Fu Zhisong, 2014, P WORKSH GRAPH DAT M, P1, DOI DOI 10.1145/2621934.2621936
   Garber L, 2012, COMPUTER, V45, P16, DOI 10.1109/MC.2012.358
   George V, 2007, IEEE ASIAN SOLID STA, P14
   Govindaraju Naga K., 2004, P 2004 ACM SIGMOD IN, P215, DOI [10.1145/1007568.1007594, DOI 10.1145/1007568.1007594]
   Gray Alexander, 2013, ANAL MASSIVE DATASET
   Halstead RJ, 2013, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2013.17
   Helmreich Stephen C., 2006, DATA CENTRIC COMPUTI
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Jacobs A, 2009, COMMUN ACM, V52, P36, DOI 10.1145/1536616.1536632
   Karam R, 2015, P IEEE, V103, P1311, DOI 10.1109/JPROC.2015.2434888
   Karam Robert, 2016, IEEE T VERY LARGE SC, V24, P12
   Karam Robert, 2015, 2015 IEEE 16 WORKSH, P1
   Kraj P, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-200
   Lavalle S, 2011, MIT SLOAN MANAGE REV, V52, P21
   LeCun Y., 2016, MNIST DATABASE HANDW
   Liu CC, 2005, IEEE DES TEST COMPUT, V22, P556, DOI 10.1109/MDT.2005.134
   MacQueen J., 1967, P 5 BERK S MATH STAT, P1
   Mirsky E, 1996, IEEE SYMPOSIUM ON FPGAS FOR CUSTOM COMPUTING MACHINES, PROCEEDINGS, P157, DOI 10.1109/FPGA.1996.564808
   Murakami K, 1997, ISSCC DIG TECH PAP I, V40, P228, DOI 10.1109/ISSCC.1997.585356
   Neshatpour K, 2015, ANN IEEE SYM FIELD P, P164, DOI 10.1109/FCCM.2015.59
   NVIDIA, 2016, CUDA TOOLK DOC
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Paul S, 2009, 2009 9TH IEEE CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P880
   Paul Somnath, 2014, IEEE T VERY LARGE SC, P1005
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Rogers Timothy G., 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P99, DOI 10.1145/2540708.2540718
   Shan Y, 2010, FPGA 10, P93
   Singh H, 2000, IEEE T COMPUT, V49, P465, DOI 10.1109/12.859540
   Stoffel K, 1999, LECT NOTES COMPUT SC, V1685, P1451
   Sukhwani B, 2012, INT CONFER PARA, P411
   Sun Helen, 2012, ORACLE REDWOOD SHORE
   Wang Yangzhu, 2014, ADV MECH ENG, V2014, P1, DOI DOI 10.1109/TITS.2014.2298352
   Wang YZH, 2015, ACM SIGPLAN NOTICES, V50, P265, DOI [10.1145/2688500.2688538, 10.1145/2858788.2688538]
   Woods L., 2011, Proceedings 2011 27th IEEE International Conference on Data Engineering Workshops (ICDEW 2011), P296, DOI 10.1109/ICDEW.2011.5767669
   Wu R, 2009, UCHPC-MAW09: UNCONVENTIONAL HIGH PERFORMANCE COMPUTING/MEMORY ACCESS: IS THE MEMORY FIT FOR MANYCORE?, P1
   Zhao WZ, 2009, LECT NOTES COMPUT SC, V5931, P674, DOI 10.1007/978-3-642-10665-1_71
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
   ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934
NR 57
TC 4
Z9 4
U1 0
U2 15
PD MAY
PY 2017
VL 13
IS 3
SI SI
AR 34
DI 10.1145/2997649
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Stamelos, I
   Koromilas, E
   Kachris, C
   Soudris, D
AF Stamelos, Ioannis
   Koromilas, Elias
   Kachris, Christoforos
   Soudris, Dimitrios
BE Smari, WW
   Zinedine, K
TI A novel framework for the Seamless integration of FPGA accelerators with
   Big Data analytics Frameworks in Heterogeneous data centers
SO PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING
   & SIMULATION (HPCS)
DT Proceedings Paper
CT International Conference on High Performance Computing & Simulation
   (HPCS)
CY JUL 16-20, 2018
CL orelans, FRANCE
DE heterogeneous computing; reconfigurable computing; FPGA; data center;
   accelerator; machine learning
AB To face the increased network traffic in the cloud, data center operators have started adopting an heterogeneous approach in their infrastructures. Heterogeneous infrastructures, e.g. based on FPGAs, can provide higher performance and better energy-efficiency compared to the contemporary processors. However, FPGAs lack of an easy-to-use framework for the efficient deployment from high-level programming frameworks. In this paper, we present a novel framework that allows the seamless integration of FPGAs from high-level programming languages, like Java and Scala. The proposed approach provides all the required APIs for the utilization of FPGAs from these languages. The proposed scheme has been mapped on Amazon AWS f1 infrastructure and a performance evaluation is presented for two widely used machine learning algorithms.
C1 [Stamelos, Ioannis; Koromilas, Elias; Kachris, Christoforos; Soudris, Dimitrios] Natl Tech Univ Athens, ICCS, Athens, Greece.
RP Stamelos, I (corresponding author), Natl Tech Univ Athens, ICCS, Athens, Greece.
CR [Anonymous], 2015, CORR
   Bacon David, 2013, QUEUE, V11, P40, DOI [10.1145/2436696.2443836, DOI 10.1145/2436696.2443836]
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chen Fei, 2014, P 11 ACM C COMP FRON
   Fahmy SA, 2015, INT CONF CLOUD COMP, P430, DOI 10.1109/CloudCom.2015.60
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Knodel O., 2015, 2 INT WORKSH FPGAS S
   Koromilas E, 2017, 2017 6TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   Segal Oren, 2014, FIELD PROGR LOG APPL, P1, DOI [10.1109/FPL.2014.6927442, DOI 10.1109/FPL.2014.6927442]
   Weerasinghe J., 2015, 2015 IEEE INT C CLOU
   Windh S, 2015, P IEEE, V103, P390, DOI 10.1109/JPROC.2015.2399275
NR 11
TC 3
Z9 3
U1 0
U2 2
PY 2018
BP 539
EP 545
DI 10.1109/HPCS.2018.00090
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kim, LW
AF Kim, Lok-Won
TI DeepX: Deep Learning Accelerator for Restricted Boltzmann Machine
   Artificial Neural Networks
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Deep belief networks (DBNs); hardware-based computational acceleration;
   pipeline and parallel architecture; reconfigurable computing; restricted
   Boltzmann machine (RBM)
ID FPGA; IMPLEMENTATION; PROCESSOR
AB Although there have been many decades of research and commercial presence on high performance general purpose processors, there are still many applications that require fully customized hardware architectures for further computational acceleration. Recently, deep learning has been successfully used to learn in a wide variety of applications, but their heavy computation demand has considerably limited their practical applications. This paper proposes a fully pipelined acceleration architecture to alleviate high computational demand of an artificial neural network (ANN) which is restricted Boltzmann machine (RBM) ANNs. The implemented RBM ANN accelerator (integrating 1024 x 1024 network size, using 128 input cases per batch, and running at a 303-MHz clock frequency) integrated in a state-of-the art field-programmable gate array (FPGA) (Xilinx Virtex 7 XC7V-2000T) provides a computational performance of 301-billion connection-updates-per-second and about 193 times higher performance than a software solution running on general purpose processors. Most importantly, the architecture enables over 4 times (12 times in batch learning) higher performance compared with a previous work when both are implemented in an FPGA device (XC2VP70).
C1 [Kim, Lok-Won] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90024 USA.
   [Kim, Lok-Won] Kyung Hee Univ, Dept Comp Sci & Engn, Seoul 02447, South Korea.
RP Kim, LW (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Seoul 02447, South Korea.
EM lwk@khu.ac.kr
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   [Anonymous], 2009, P ACMSIGDA INT S FIE
   BOSER BE, 1991, IEEE J SOLID-ST CIRC, V26, P2017, DOI 10.1109/4.104196
   Dias FM, 2004, ENG APPL ARTIF INTEL, V17, P945, DOI 10.1016/j.engappai.2004.08.011
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Jung S, 2007, IEEE T IND ELECTRON, V54, P265, DOI 10.1109/TIE.2006.888791
   Kim LW, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2539125
   Kim SK, 2010, ANN IEEE SYM FIELD P, P201, DOI 10.1109/FCCM.2010.38
   Le Ly D, 2010, IEEE T NEURAL NETWOR, V21, P1780, DOI 10.1109/TNN.2010.2073481
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lindsey C., 1994, P 3 WORKSH NEUR NETW, P26
   Liu J., 2013, ASYNCHRONOUS PARALLE
   Liu Y, 2011, PATTERN RECOGN, V44, P2287, DOI 10.1016/j.patcog.2010.12.012
   Ly D., 2008, DEP ELECT COMPUT ENG
   Maeda Y, 2003, IEEE T NEURAL NETWOR, V14, P688, DOI 10.1109/TNN.2003.811357
   Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953
   Min Ju Kim, 2015, 2015 11th Conference on Lasers and Electro-Optics Pacific Rim (CLEO-PR). Proceedings, P1, DOI 10.1109/CLEOPR.2015.7376173
   Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013
   Raina Rajat, 2009, INT C MACHINE LEARNI, P873, DOI DOI 10.1145/1553374.1553486
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   TAUSWORTHE RC, 1965, MATH COMPUT, V19, P201, DOI 10.2307/2003345
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhu JH, 2003, LECT NOTES COMPUT SC, V2778, P1062
NR 29
TC 40
Z9 42
U1 0
U2 33
PD MAY
PY 2018
VL 29
IS 5
BP 1441
EP 1453
DI 10.1109/TNNLS.2017.2665555
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chen, TQ
   Moreau, T
   Jiang, ZH
   Zheng, LM
   Yan, E
   Cowan, M
   Shen, H
   Wang, L
   Hu, Y
   Ceze, L
   Guestrin, C
   Krishnamurthy, A
AF Chen, Tianqi
   Moreau, Thierry
   Jiang, Ziheng
   Zheng, Lianmin
   Yan, Eddie
   Cowan, Meghan
   Shen, Haichen
   Wang, Leyuan
   Hu, Yuwei
   Ceze, Luis
   Guestrin, Carlos
   Krishnamurthy, Arvind
GP USENIX ASSOC
TI TVM: An Automated End-to-End Optimizing Compiler for Deep Learning
SO PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND
   IMPLEMENTATION
DT Proceedings Paper
CT 13th USENIX Symposium on Operating Systems Design and Implementation
   (OSDI)
CY OCT 08-10, 2018
CL Carlsbad, CA
ID PARALLELISM
AB There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms - such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) - requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-ofthe-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.
C1 [Chen, Tianqi; Moreau, Thierry; Jiang, Ziheng; Yan, Eddie; Cowan, Meghan; Shen, Haichen; Ceze, Luis; Guestrin, Carlos; Krishnamurthy, Arvind] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Jiang, Ziheng; Wang, Leyuan] AWS, Seattle, WA USA.
   [Zheng, Lianmin] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Wang, Leyuan] Univ Calif Davis, Davis, CA USA.
   [Hu, Yuwei] Cornell, Ithaca, NY USA.
RP Chen, TQ (corresponding author), Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
CR Abadi M., 2016, 12 S OP SYST DES IMP
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agarwal Amit, 2014, MSRTR2014112
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, NVIDIA TESL V100 GPU
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Baghdadi R, 2015, INT CONFER PARA, P138, DOI 10.1109/PACT.2015.17
   CHEN TF, 1995, IEEE T COMPUT, V44, P609, DOI 10.1109/12.381947
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Eggers SJ, 1997, IEEE MICRO, V17, P12, DOI 10.1109/40.621209
   Frigo M, 1998, INT CONF ACOUST SPEE, P1381, DOI 10.1109/ICASSP.1998.681704
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hegarty J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601174
   Henriksen T, 2017, ACM SIGPLAN NOTICES, V52, P556, DOI [10.1145/3062341.3062354, 10.1145/3140587.3062354]
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   JOUPPI NP, 1990, 17TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P364, DOI 10.1109/ISCA.1990.134547
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Klockner A., 2014, P ACM SIGPLAN INT WO, DOI [DOI 10.1145/2627373.2627387, 10.1145/2627373.2627387]
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li L., 2016, ABS160306560 CORR
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   OURBARIAUX M., 2015, ABS151100363 CORR
   Palkar Shoumik, 2017, ABS170906416 CORR
   Radford A., 2015, ARXIV151106434, DOI DOI 10.1007/978-3-319-71589-6_9
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sharma H, 2016, INT SYMP MICROARCH
   Smith J. E., 1982, 9th Annual Symposium on Computer Architecture, P112
   Steuwer M, 2017, INT SYM CODE GENER, P74, DOI 10.1109/CGO.2017.7863730
   Sujeeth A. K., 2011, P INT C MACH LEARN I
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   ULLOCH A., 2017, ARXIV PREPRINT ARXIV
   Umuroglu Y., 2016, ABS161207119 CORR
   VASILACHE N., COMMUNICATION
   Vasilache N., 2018, CORR
   Verdoolaege S, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400713
   Volkov V., 2016, THESIS U CALIFORNIA
   Wei R., 2017, ARXIV171103016
   Whaley R Clinton, 1998, P 1998 ACMIEEE C SUP, P38, DOI [10.5555/509058.509096, DOI 10.1109/SC.1998.10004]
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zaremba W., 2014, PREPRINT
NR 48
TC 571
Z9 599
U1 7
U2 21
PY 2018
BP 579
EP 594
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Mittal, S
   Umesh, S
AF Mittal, Sparsh
   Umesh, Sumanth
TI A survey On hardware accelerators and optimization techniques for RNNs
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Review
DE Recurrent neural networks; Deep learning; GPU; FPGA; ASIC; Pruning;
   Parallelization; Low-precision
ID SHORT-TERM-MEMORY; RECURRENT NEURAL-NETWORK; LSTM; ARCHITECTURE;
   COMPRESSION; DNN
AB "Recurrent neural networks " (RNNs) are powerful artificial intelligence models that have shown remarkable effectiveness in several tasks such as music generation, speech recognition and machine translation. RNN computations involve both intra-timestep and inter-timestep dependencies. Due to these features, hardware acceleration of RNNs is more challenging than that of CNNs. Recently, several researchers have proposed hardware architectures for RNNs. In this paper, we present a survey of GPU/FPGA/ASIC-based accelerators and optimization techniques for RNNs. We highlight the key ideas of different techniques to bring out their similarities and differences. Improvements in deep-learning algorithms have inevitably gone hand-in-hand with the improvements in the hardware-accelerators. Nevertheless, there is a need and scope of even greater synergy between these two fields. This survey seeks to synergize the efforts of researchers in the area of deep learning, computer architecture, and chip-design.
C1 [Mittal, Sparsh] IIT Roorkee, Dept Elect & Commun Engn, Roorkee, Uttar Pradesh, India.
   [Umesh, Sumanth] IIT Jodhpur, Dept Elect Engn, Jodhpur, Rajasthan, India.
RP Mittal, S (corresponding author), IIT Roorkee, Dept Elect & Commun Engn, Roorkee, Uttar Pradesh, India.
EM sparshfec@iitr.ac.in; sumanth.2@iitj.ac.in
CR [Anonymous], 2014, PROC INT S HIGH PERF, DOI DOI 10.1145/2600212.2600216
   [Anonymous], 2016, CORR
   [Anonymous], 2018, ARXIV180600512
   [Anonymous], 2018, P IEEE 23 INT C DIG
   [Anonymous], 2018, P INT C LEARN REPR
   [Anonymous], 2017, DES AUT C
   Ardakani A, 2019, DES AUT TEST EUROPE, P1427, DOI [10.23919/date.2019.8714765, 10.23919/DATE.2019.8714765]
   Azari E, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3366634
   Bank-Tavakoli E., 2019, IEEE T VERY LARGE SC
   Cao Q., 2017, P 1 INT WORKSH DEEP, P1, DOI DOI 10.1145/3089801.3089804
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Chandra A, 2018, CLIM POLICY, V18, P526, DOI 10.1080/14693062.2017.1316968
   Chang Andre Xian Ming, 2015, ARXIV151105552
   Chen KW, 2018, IEEE IMAGE PROC, P4168, DOI 10.1109/ICIP.2018.8451053
   Chen Z, 2018, MINERAL MET MAT SER, P3, DOI 10.1007/978-3-319-72059-3_1
   Cho K, 2014, ARXIV, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Conti F, 2018, IEEE CUST INTEGR CIR, DOI 10.1109/ICOPS35962.2018.9575761
   Dai XL, 2020, IEEE T COMPUT, V69, P441, DOI 10.1109/TC.2019.2954495
   Dey S, 2019, INT SYM QUAL ELECT, P183, DOI 10.1109/ISQED.2019.8697413
   Diamantopoulos D, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P341, DOI 10.1109/FPT.2018.00068
   Diamos Greg, 2016, INT C MACHINE LEARNI, P2024
   Ding CW, 2018, PR GR LAK SYMP VLSI, P353, DOI 10.1145/3194554.3194625
   Dong P., 2020, ARXIV200211474
   Ferreira JC, 2016, PROC INT CONF RECON
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao C., 2019, ARXIV191212193
   Gao CF, 2019, IEEE T POWER ELECTR, V34, P11725, DOI 10.1109/TPEL.2019.2908656
   Gao C, 2018, IEEE ANTENNAS PROP, P1075, DOI 10.1109/APUSNCURSINRSM.2018.8608678
   Gao P, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190541
   Gray Scott, 2017, GPU KERNELS BLOCK SP
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Gupta U, 2019, INT CONFER PARA, P1, DOI 10.1109/PACT.2019.00009
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hwang K, 2015, INT CONF ACOUST SPEE, P1047, DOI 10.1109/ICASSP.2015.7178129
   Jia Z., 2019, DISSECTING GRAPHCORE
   Jo J., 2019, I SYMPOS LOW POWER E, P1, DOI DOI 10.1109/islped.2019.8824862
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khalil K, 2019, IEEE T CIRCUITS-II, V66, P1885, DOI 10.1109/TCSII.2019.2924663
   Khorasani F, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P377, DOI 10.1109/MICRO.2018.00038
   Kouretas I, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   Kung J, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317879
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   Li BX, 2014, IEEE IJCNN, P4062, DOI 10.1109/IJCNN.2014.6889433
   Li Q, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P693, DOI 10.1145/3287624.3287717
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   Liu B, 2018, IEEE ACCESS, V6, P52227, DOI 10.1109/ACCESS.2018.2870273
   Liu D., 2018, ARXIV181209659
   Manohar SS, 2019, J SYST ARCHITECT, V100, DOI 10.1016/j.sysarc.2019.101648
   Mealey T, 2018, PROC NAECON IEEE NAT, P382, DOI 10.1109/NAECON.2018.8556674
   Meng C, 2017, P ML SYST WORKSH NIP
   Mittal S., 2020, TECHNICAL REPORT
   Mittal S, 2018, CONCURR COMP-PRACT E, V31, pe4666
   Mittal S, 2020, J SYST ARCHITECT, V104, DOI 10.1016/j.sysarc.2019.101689
   Mittal S, 2019, J SYST ARCHITECT, V99, DOI 10.1016/j.sysarc.2019.101635
   Mittal S, 2019, J SYST ARCHITECT, V98, P135, DOI 10.1016/j.sysarc.2019.07.006
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Mittal S, 2019, J SYST ARCHITECT, V97, P373, DOI 10.1016/j.sysarc.2018.11.001
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1537, DOI 10.1109/TPDS.2015.2442980
   Mittal S, 2014, J CIRCUIT SYST COMP, V23, DOI 10.1142/S0218126614300025
   Neil D., 2017, P 34 INT C MACH LEAR, P2584
   Nurvitadhi E, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P307, DOI 10.1109/ICFPT47387.2019.00054
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Park J, 2018, DES AUT TEST EUROPE, P7, DOI 10.23919/DATE.2018.8341971
   Park S, 2019, DES AUT TEST EUROPE, P1587, DOI [10.23919/date.2019.8715013, 10.23919/DATE.2019.8715013]
   Peng L, 2019, 2019 IEEE 13TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2019), P241, DOI 10.1109/MCSoC.2019.00042
   Puigcerver J, 2017, PROC INT CONF DOC, P67, DOI 10.1109/ICDAR.2017.20
   Que ZQ, 2019, IEEE INT CONF ASAP, P17, DOI 10.1109/ASAP.2019.00-42
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Rizakis Michalis, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P3, DOI 10.1007/978-3-319-78890-6_1
   Rybalkin V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P111, DOI 10.1145/3373087.3375301
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Rybalkin V, 2017, DES AUT TEST EUROPE, P1390, DOI 10.23919/DATE.2017.7927210
   Sen S, 2018, IEEE T COMPUT AID D, V37, P2266, DOI 10.1109/TCAD.2018.2858362
   Silfa F., 2019, ARXIV191104244
   Silfa F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P782, DOI 10.1145/3352460.3358309
   Silfa F, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243184
   Sim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062290
   Sun Yu-dan, 2019, Instrument Technique and Sensor, P18
   Sun ZR, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P1, DOI 10.1109/SmartCloud.2018.00009
   Tao J, 2019, SENSYS-ML'19: PROCEEDINGS OF THE FIRST WORKSHOP ON MACHINE LEARNING ON EDGE IN SENSOR SYSTEMS, P31, DOI 10.1145/3362743.3362965
   Umesh S, 2019, J SYST ARCHITECT, V97, P349, DOI 10.1016/j.sysarc.2018.11.005
   Van Keirsbilck M., 2019, ARXIV190512340
   Volder J. E., 1959, IRE T ELECT COMPUT, VEC-8, P330, DOI [10.1109/TEC.1959.5222693, DOI 10.1109/TEC.1959.5222693]
   Wang M., 2019, IEEE J EMERG SEL TOP
   Wang SR, 2019, IEEE ACCESS, V7, P62930, DOI 10.1109/ACCESS.2019.2917312
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wang ZS, 2018, IEEE SIGNAL PROC LET, V25, P984, DOI 10.1109/LSP.2018.2834872
   Wang ZS, 2017, IEEE T VLSI SYST, V25, P2763, DOI 10.1109/TVLSI.2017.2717950
   Wu, 2016, ARXIV160908144
   Wu JQ, 2019, IEEE T VLSI SYST, V27, P2939, DOI 10.1109/TVLSI.2019.2927375
   Yang XD, 2018, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2018.00677
   Yao ZL, 2019, AAAI CONF ARTIF INTE, P5676
   Yazdani R., 2019, ARXIV191101258
   Yin H., 2019, ARXIV190110997
   Yousefi MR, 2015, PROC INT CONF DOC, P1121, DOI 10.1109/ICDAR.2015.7333935
   Zhang Xiaofan, 2017, 2017 27 INT C FIELD, P1
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhang YW, 2017, IEEE INT SYMP PARAL, P614, DOI 10.1109/ISPA/IUCC.2017.00098
   Zhao J, 2019, IEEE ACCESS, V7, P108850, DOI 10.1109/ACCESS.2019.2933036
   Zheng B., 2018, ARXIV180508899
   Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269
NR 107
TC 20
Z9 20
U1 13
U2 92
PD JAN
PY 2021
VL 112
AR 101839
DI 10.1016/j.sysarc.2020.101839
EA JAN 2021
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Bruchon, N
   Fenu, G
   Gaio, G
   Lonza, M
   O'Shea, FH
   Pellegrino, FA
   Salvato, E
AF Bruchon, Niky
   Fenu, Gianfranco
   Gaio, Giulio
   Lonza, Marco
   O'Shea, Finn Henry
   Pellegrino, Felice Andrea
   Salvato, Erica
TI Basic Reinforcement Learning Techniques to Control the Intensity of a
   Seeded Free-Electron Laser
SO ELECTRONICS
DT Article
DE reinforcement learning; free-electron laser; optimization;
   control-system
ID ALGORITHMS
AB Optimal tuning of particle accelerators is a challenging task. Many different approaches have been proposed in the past to solve two main problems-attainment of an optimal working point and performance recovery after machine drifts. The most classical model-free techniques (e.g., Gradient Ascent or Extremum Seeking algorithms) have some intrinsic limitations. To overcome those limitations, Machine Learning tools, in particular Reinforcement Learning (RL), are attracting more and more attention in the particle accelerator community. We investigate the feasibility of RL model-free approaches to align the seed laser, as well as other service lasers, at FERMI, the free-electron laser facility at Elettra Sincrotrone Trieste. We apply two different techniques-the first, based on the episodic Q-learning with linear function approximation, for performance optimization; the second, based on the continuous Natural Policy Gradient REINFORCE algorithm, for performance recovery. Despite the simplicity of these approaches, we report satisfactory preliminary results, that represent the first step toward a new fully automatic procedure for the alignment of the seed laser to the electron beam. Such an alignment is, at present, performed manually.
C1 [Bruchon, Niky; Fenu, Gianfranco; Pellegrino, Felice Andrea; Salvato, Erica] Univ Trieste, Dept Engn & Architecture, I-34127 Trieste, TS, Italy.
   [Gaio, Giulio; Lonza, Marco; O'Shea, Finn Henry] Elettra Sincrotrone Trieste, I-34149 Trieste, TS, Italy.
RP Bruchon, N (corresponding author), Univ Trieste, Dept Engn & Architecture, I-34127 Trieste, TS, Italy.
EM niky.bruchon@phd.units.it; fenu@units.it; giulio.gaio@elettra.eu;
   marco.lonza@elettra.eu; finn.h.oshea@gmail.com; fapellegrino@units.it;
   erica.salvato@phd.units.it
CR Agapov I, 2014, NUCL INSTRUM METH A, V768, P151, DOI 10.1016/j.nima.2014.09.057
   Agapov I., 2015, P 6 INT PART ACC C I
   Allaria E, 2015, J SYNCHROTRON RADIAT, V22, P485, DOI 10.1107/S1600577515005366
   Allaria E, 2013, NAT PHOTONICS, V7, P913, DOI [10.1038/nphoton.2013.277, 10.1038/NPHOTON.2013.277]
   Allaria E, 2012, NAT PHOTONICS, V6, P699, DOI [10.1038/NPHOTON.2012.233, 10.1038/nphoton.2012.233]
   [Anonymous], 1972, HDB MATH FUNCTIONS A
   Ariyur K. B., 2003, REAL TIME OPTIMIZATI
   Bruchon N, 2019, 2019 23RD INTERNATIONAL CONFERENCE ON MECHATRONICS TECHNOLOGY (ICMT 2019), DOI 10.1109/icmect.2019.8932150
   Bruchon N, 2017, NUCL INSTRUM METH A, V871, P20, DOI 10.1016/j.nima.2017.07.048
   Cleva S., 2013, P 14 INT C ACC LARG
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A.L., 2017, USING NEURAL NETWORK
   Edelen A.L., 2017, P 31 C NEUR INF PROC
   Gaio G., 2017, P 16 INT C ACC LARG
   Gaio G., 2015, P 15 INT C ACC LARG
   Gaio G., 2013, P ICALEPCS SAN FRANC, P1362
   Geramifard Alborz, 2013, Foundations and Trends in Machine Learning, V6, P375, DOI 10.1561/2200000042
   Gu SX, 2016, PR MACH LEARN RES, V48
   Hirlaender S., 2019, P 2 ICFA WORKSH MACH
   Kakade S.M., 2001, P 15 C NEUR INF PROC
   McIntire M., 2016, P 7 INT PART ACC C I
   McIntire M., 2016, P 32 C UNC ART INT U
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278
   Recht B, 2019, ANNU REV CONTR ROBOT, V2, P253, DOI 10.1146/annurev-control-053018-023825
   Song J, 2004, I C CONT AUTOMAT ROB, P2223
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Szepesvari Csaba, 2010, ALGORITHMS REINFORCE, DOI [http://dx.doi.org/10.2200/S00268ED1V01Y201005AIM009, DOI 10.2200/S00268ED1V01Y201005AIM009]
   Tomin S., 2016, P 7 INT PART ACC C I
   Vermorel J, 2005, LECT NOTES ARTIF INT, V3720, P437, DOI 10.1007/11564096_42
   Veronese M., 2014, P 3 INT BEAM INSTR C
   Veronese M., 2008, P 13 BEAM INSTR WORK
   Veronese M., 2012, IBIC, V12, P449
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   YU LH, 1991, PHYS REV A, V44, P5178, DOI 10.1103/PhysRevA.44.5178
   Zhao T., 2011, P 25 C NEUR INF PROC
NR 37
TC 19
Z9 19
U1 1
U2 9
PD MAY
PY 2020
VL 9
IS 5
AR 781
DI 10.3390/electronics9050781
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Jafri, SMAH
   Hemani, A
   Paul, K
   Abbas, N
AF Jafri, Syed M. A. H.
   Hemani, Ahmed
   Paul, Kolin
   Abbas, Naeem
GP IEEE
TI MOCHA: Morphable locality and compression aware architecture for
   convolutional neural networks
SO 2017 31ST IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS)
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 31st IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 29-JUN 02, 2017
CL Orlando, FL
AB Today, machine learning based on neural networks has become mainstream, in many application domains. A small subset of machine learning algorithms, called Convolutional Neural Networks (CNN), are considered as state-ofthe- art for many applications (e.g. video/audio classification). The main challenge in implementing the CNNs, in embedded systems, is their large computation, memory, and bandwidth requirements. To meet these demands, dedicated hardware accelerators have been proposed. Since memory is the major cost in CNNs, recent accelerators focus on reducing the memory accesses. In particular, they exploit data locality using either tiling, layer merging or intra/inter feature map parallelism to reduce the memory footprint. However, they lack the flexibility to interleave or cascade these optimizations. Moreover, most of the existing accelerators do not exploit compression that can simultaneously reduce memory requirements, increase the throughput, and enhance the energy efficiency. To tackle these limitations, we present a flexible accelerator called MOCHA. MOCHA has three features that differentiate it from the state-of-the-art: (i) the ability to compress input/ kernels, (ii) the flexibility to interleave various optimizations, and (iii) intelligence to automatically interleave and cascade the optimizations, depending on the dimension of a specific CNN layer and available resources. Post layout Synthesis results reveal that MOCHA provides up to 63% higher energy efficiency, up to 42% higher throughput, and up to 30% less storage, compared to the next best accelerator, at the cost of 26-35% additional area.
C1 [Jafri, Syed M. A. H.; Hemani, Ahmed; Paul, Kolin] Royal Inst Technol, Dept Elect, Sch ICT, Stockholm, Sweden.
   Indian Inst Technol, Delhi, India.
   [Abbas, Naeem] Natl Univ Sci & Technol, Islamabad, Pakistan.
RP Jafri, SMAH (corresponding author), Royal Inst Technol, Dept Elect, Sch ICT, Stockholm, Sweden.
CR [Anonymous], 2011, PROC INT C FIELD PRO
   [Anonymous], 2014, THESIS
   [Anonymous], 2011, P 8 INT AUTOMOTIVE C
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farahini N, 2013, IEEE INT SYMP CIRC S, P1448, DOI 10.1109/ISCAS.2013.6572129
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Hemani A., 2017, SILAGO SOLUTION ARCH, P47
   Jafri SMAH, 2014, MICROPROCESS MICROSY, V38, P124, DOI 10.1016/j.micpro.2013.12.004
   Jafri S. M. A. H., 2016, IEEE T COMPUT, VPP, P1
   Jafri SMAH, 2014, ANN IEEE SYM FIELD P, P31, DOI [10.1109/FCCM.2014.18, 10.2209/FCCM.2014.18]
   Jafri SMAH, 2013, 16TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2013), P525, DOI 10.1109/DSD.2013.62
   Jafri SMAH, 2013, INT SYM QUAL ELECT, P104, DOI 10.1109/ISQED.2013.6523597
   Jafri SMAH, 2013, 2013 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (IC-SAMOS), P104, DOI 10.1109/SAMOS.2013.6621112
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2012, CUDA CONVNET
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Millberg M, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P890, DOI 10.1109/DATE.2004.1269001
   Peemen M, 2011, LECT NOTES COMPUT SC, V6915, P293, DOI 10.1007/978-3-642-23687-7_27
   Pekhimenko G., 2012, P INT C PAR COMP TEC
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI DOI 10.1145/2485922.2485925
   Shami MA, 2012, IEEE SYM PARA DISTR, P344, DOI 10.1109/IPDPSW.2012.42
   Shami MA, 2009, 2009 IEEE 8TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P122, DOI 10.1109/ASICON.2009.5351593
   Shami MA, 2009, IEEE WRK SIG PRO SYS, P167, DOI 10.1109/SIPS.2009.5336246
   Shi RB, 2015, 2015 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P591, DOI 10.1109/DSD.2015.70
   Song H., 2016, ACM IEEE 43 ANN INT
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajammul M. A., 2013, P APPL SPEC SYST ARC
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Yang L, 2010, ACM T EMBED COMPUT S, V9, DOI 10.1145/1698772.1698785
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 38
TC 9
Z9 9
U1 0
U2 1
PY 2017
BP 276
EP 286
DI 10.1109/IPDPS.2017.59
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, GP
   Hari, SKS
   Sullivan, M
   Tsai, T
   Pattabiraman, K
   Emer, J
   Keckler, SW
AF Li, Guanpeng
   Hari, Siva Kumar Sastry
   Sullivan, Michael
   Tsai, Timothy
   Pattabiraman, Karthik
   Emer, Joel
   Keckler, Stephen W.
GP Assoc Comp Machinery
TI Understanding Error Propagation in Deep Learning Neural Network (DNN)
   Accelerators and Applications
SO SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE
   COMPUTING, NETWORKING, STORAGE AND ANALYSIS
DT Proceedings Paper
CT International Conference for High Performance Computing, Networking,
   Storage and Analysis (SC)
CY NOV 12-17, 2017
CL Denver, CO
DE Deep Learning; Silent Data Corruption; Soft Error; Reliability
AB Deep learning neural networks (DNNs) have been successful in solving a wide range of machine learning problems. Specialized hardware accelerators have been proposed to accelerate the execution of DNN algorithms for high-performance and energy efficiency. Recently, they have been deployed in datacenters (potentially for business-critical or industrial applications) and safety-critical systems such as self-driving cars. Soft errors caused by high-energy particles have been increasing in hardware systems, and these can lead to catastrophic failures in DNN systems. Traditional methods for building resilient systems, e.g., Triple Modular Redundancy (TMR), are agnostic of the DNN algorithm and the DNN accelerator's architecture. Hence, these traditional resilience approaches incur high overheads, which makes them challenging to deploy. In this paper, we experimentally evaluate the resilience characteristics of DNN systems (i.e., DNN software running on specialized accelerators). We find that the error resilience of a DNN system depends on the data types, values, data reuses, and types of layers in the design. Based on our observations, we propose two efficient protection techniques for DNN systems.
C1 [Li, Guanpeng; Pattabiraman, Karthik] Univ British Columbia, Vancouver, BC, Canada.
   [Hari, Siva Kumar Sastry; Sullivan, Michael; Tsai, Timothy; Emer, Joel; Keckler, Stephen W.] NVIDIA, Santa Clara, CA USA.
RP Li, GP (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM gpli@ece.ubc.ca; shari@nvidia.com; misullivan@nvidia.com;
   timothyt@nvidia.com; karthikp@ece.ubc.ca; jemer@nvidia.com;
   skeckler@nvidia.com
CR [Anonymous], 2016, 615082016 IEC
   [Anonymous], IEEE T RELIABILITY
   [Anonymous], ACM SIGARCH COMPUTER
   [Anonymous], 2016, KEYNOTE AUTONOMOUS C
   [Anonymous], 2014, CIFAR DAT 2014
   August David I., 2005, PREC INT S COD GEN O
   Bojarski Mariusz, 2016, arXiv
   Bong Kyeongryeol, INT SOL STAT CIRC C
   Borkar S, 2005, IEEE MICRO, V25, P10, DOI 10.1109/MM.2005.110
   Cavigelli L., 2015, P 25 ED GREAT LAK S
   Chattopadhyay A.K., 2017, INCOMPLETE DATA ASTR, P1, DOI 10.1002/9781118445112.stat07942
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, IEEE MTT S INT MICR
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Constantinescu C, 2008, P REL MAINT S, P372
   ConvNet, 2014, HIGH PERF C PLUS PLU
   Cox David, 2010, FIELD PROGRAMMABLE T
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Feng Shuguang, 2010, ACM SIGARCH COMPUTER, V38, P385
   Fernandes F, 2016, ACM T ARCHIT CODE OP, V13, DOI 10.1145/2998573
   Gill Balkaran, 2012, SOFT ERROR SUSCEPTIB
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hari SKS, 2012, I C DEPEND SYS NETWO
   He K., 2015, PAPER PRESENTED 2015, DOI [DOI 10.1109/CVPR.2015.7299173, 10.1109/CVPR.2015.7299173]
   Jahan Jesmin, 2014, P INT S PERF AN SYST
   Jakkula Venkata, 2009, IEEE INT C APPL SPEC
   Judd Patrick, 2016, PROTEUS EXPLOITING N
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Laguna Ignacio, 2016, PREC INT S COD GEN O
   Lane ND, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P117, DOI 10.1145/2699343.2699349
   LeCun Y., 2010, P IEEE INT S CIRC SY
   Li Guanpeng, 2015, P INT C DEP SYST NET
   Li Guanpeng, 2016, P INT C HIGH PERF CO
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Lu QN, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3014586
   Pattabiraman K, 2011, IEEE T DEPEND SECURE, V8, P640, DOI 10.1109/TDSC.2010.19
   Piuri Vincenzo, 1995, IEEE T CIRCUITS SYST
   Piuri Vincenzo, 1998, IEEE T COMPUTERS
   Piuri Vincenzo, 2001, J PARALLEL DISTRIB C
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sachdev Manoj, 2016, NEUTRON RAD INDUCED
   Safety Standard, 2016, ISO26262
   Setio Arnaud AA, 2013, IEEE 31 INT C COMP D
   Shapiro D., 2016, INTRO XAVIER NVIDIA
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sullivan Michael, 2016, ANAL MODEL HARDENED
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   TPU, GOOGL SUP MACH LEARN
   Wei Jiesheng, 2014, P INT C DEP SYST NET
   Yann LeCun, 2000, DEEP LEARNING FUTURE
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zia V., 2009, P INT REL PHYS S IRP
NR 56
TC 199
Z9 199
U1 1
U2 12
PY 2017
DI 10.1145/3126908.3126964
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ali, M
   Göhringer, D
AF Ali, Muhammad
   Goehringer, Diana
GP IEEE
TI Application Specific Instruction-Set Processors for Machine Learning
   Applications
SO 2022 21ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY
   (ICFPT 2022)
DT Proceedings Paper
CT 21st International Conference on Field-Programmable Technology (ICFPT)
CY DEC 05-09, 2022
CL Hong Kong Univ Sci & Technol, Hong Kong, HONG KONG
HO Hong Kong Univ Sci & Technol
DE Application Specific Instruction-set Processors (ASIP);
   Instruction-Set-Architecture (ISA); Application-Specific Integrated
   Circuit (ASIC); Field Programmable Gate Array (FPGA); RISC-V
AB Machine learning algorithms are becoming more complicated with time in order to solve complex problems. This is creating a gap for embedded system solutions e.g. General-Purpose Processors (GPPs), Graphic Processing Units (GPUs), and hardware accelerators, for the machine learning algorithms. To bridge the gap between the available solutions, Application Specific Instruction-set Processors (ASIPs) are a promising solution. ASIPs are processor designs with a tailored architecture for a specific application. This allows a better efficiency (performance-to-power) ratio for the application execution. Furthermore, it adds more flexibility to the system as compared with hardware accelerators. The scope of this Ph.D. work is to develop a RISC-V-based ASIP for machine learning applications and explore the design space of the optimizations. RISC-V is an open-source Instruction-Set-Architecture (ISA) and allows the addition of custom application-specific instructions to the ISA. In the scope of this work three main design space optimization of ASIPs will be explored; specialized applicationspecific ISA, vector processing (for data-level parallelism), and multi-core architecture (for task-level parallelism). RISC-V 32-bit architecture is used as the base platform. For vector processing, RISC-V V-extension is utilized for a SIMD-based architecture called Vector Processing Unit (VPU) which is coupled with a 32-bit RISC-V host CPU. A modular memory system is implemented to have a shared (bus-based) and distributed (NoCbased) multi-core system. The memory system increases the flexibility and scalability of the system. Other known machine learning platforms are also explored and used as a comparison case.
C1 [Ali, Muhammad; Goehringer, Diana] Tech Univ Dresden, Chair Adapt Dynam Syst, Dresden, Germany.
RP Ali, M (corresponding author), Tech Univ Dresden, Chair Adapt Dynam Syst, Dresden, Germany.
EM muhammad.ali@tu-dresden.de; diana.goehringer@tu-dresden.de
CR Aarrestad T, 2021, Arxiv, DOI arXiv:2101.05108
   Al Kadi M, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P254, DOI 10.1145/2847263.2847273
   Ali Muhammad, 2020, Applied Reconfigurable Computing Architectures, Tools, and Applications. 16th International Symposium, ARC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 120830), P193, DOI 10.1007/978-3-030-44534-8_15
   Ali M, 2021, 2021 24TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2021), P30, DOI 10.1109/DSD53832.2021.00014
   Bytyn A, 2021, IEEE OPEN J CIRCUITS, V2, P3, DOI 10.1109/OJCAS.2020.3037758
   Cox S., 2016, EXTENDING RISC V APP
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   github, SPIKE RISC V ISA SIM
   Jha NK, 2019, I CONF VLSI DESIGN, P215, DOI 10.1109/VLSID.2019.00056
   Kalms L, 2021, J SIGNAL PROCESS SYS, V93, P513, DOI 10.1007/s11265-021-01651-5
   Kamaleldin A, 2019, 2019 IEEE 13TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2019), P68, DOI 10.1109/MCSoC.2019.00017
   Matthews E, 2017, I C FIELD PROG LOGIC
   open-mpi, US
   xilinx, MICROBLAZE SOFT PROC
   xilinx, VITIS
NR 15
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 274
EP 277
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT C
AU Kwon, Y
   Rhu, M
AF Kwon, Youngeun
   Rhu, Minsoo
GP IEEE
TI Beyond the Memory Wall: A Case for Memory-centric HPC System for Deep
   Learning
SO 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
DT Proceedings Paper
CT 51st Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 20-24, 2018
CL Fukuoka, JAPAN
DE System architecture; HPC; machine learning
AB As the models and the datasets to train deep learning (DL) models scale, system architects are faced with new challenges, one of which is the memory capacity bottleneck, where the limited physical memory inside the accelerator device constrains the algorithm that can be studied. We propose a memory-centric deep learning system that can transparently expand the memory capacity available to the accelerators while also providing fast inter-device communication for parallel training. Our proposal aggregates a pool of memory modules locally within the device side interconnect, which are decoupled from the host interface and function as a vehicle for transparent memory capacity expansion. Compared to conventional systems, our proposal achieves an average 2.8x speedup on eight DL applications and increases the system-wide memory capacity to tens of TBs.
C1 [Kwon, Youngeun; Rhu, Minsoo] Korea Adv Inst Sci & Technol, Sch Elect Engn, Seoul, South Korea.
RP Kwon, Y (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Seoul, South Korea.
EM yekwon@kaist.ac.kr; mrhu@kaist.ac.kr
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2016, 2016 IEEE INT S HIGH
   [Anonymous], 2017, MICR UNV PROJ BRAINW
   [Anonymous], 2016, NVIDIA TESL P100
   [Anonymous], NVIDIA VOLTA IBM POW
   Arunkumar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P320, DOI 10.1145/3079856.3080231
   Baidu, 2017, BRING HPC TECHN DEEP
   Baidu,, 2017, DEEPBENCH BENCHM DEE
   Chan E., 2006, Proceedings of the 2006 ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming PPoPP'06, P2, DOI 10.1145/1122971.1122975
   Chatterjee N., 2012, USIMM UTAH SIMULATED
   Chen Tianqi, 2016, ARXIV160406174
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Chi P., 2016, P INT S COMP ARCH IS
   Cho M., 2017, POWERAI DISTRIBUTED
   Cho Minsik, 2018, SYSML 18
   Dean Jeff, 2017, 2017 C NEUR INF PROC
   Delmas A., 2018, BIT TACTICAL EXPLOIT
   Du ZD, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P494, DOI 10.1145/2830772.2830789
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fukuda K., 2017, ABS171104325 CORR
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Goyal P., 2017, ABS170602677
   Graves A., 2014, NEURAL TURING MACHIN, DOI DOI 10.3389/NEUR0.12.006.2007
   Gulcehre C., 2017, ICLR
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2015, ARXIV
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   IBM, 2018, REAL VAL LARG MOD SU
   IBM, 2017, CHAIN OUT OF COR TRA
   IBM, 2017, IBM POWER9 MICR
   ImageNet, 2016, IMAGENET DAT
   Intel, 2017, INT XEON PROC
   Intel- Nervana, 2017, INT NERV HARDW LAK C
   Jeddeloh J., 2012, 2012 S VLSI TECHN VL, P87
   JEDEC, 2018, HIGH BANDW MEM HBM2
   Kannan A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P546, DOI 10.1145/2830772.2830808
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim G., 2014, P INT S MICR MICRO
   Kim G., 2013, P 22 INT C PAR ARCH
   Kim J, 2017, PR MACH LEARN RES, V70
   Kim Y., 2015, CAL
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lim K, 2012, INT S HIGH PERF COMP, P189
   Lim K, 2009, CONF PROC INT SYMP C, P267, DOI 10.1145/1555815.1555789
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Meng Chen, 2017, P ML SYST WORKSH NIP, V7
   Micron, 2017, MICR SYST POW CALC D
   Microsoft, 2017, MICR PROJ OL HYP GPU
   Moss DJM, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P107, DOI 10.1145/3174243.3174258
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Na S, 2017, IEEE I CONF COMP VIS, P677, DOI 10.1109/ICCV.2017.80
   Nurvitadhi E., 2017, P ACM INT S FIELD PR
   NVIDIA, 2018, NVSWITCH LEV NVLINK
   NVIDIA, 2017, NVIDIA DGX 1 SYST AR
   NVIDIA, 2016, NVLINK HIGH SPEED IN
   NVIDIA, 2017, NVIDIA COLL COMM LIB
   NVIDIA, 2017, NVIDIA DGX 2 DEEP LE
   NVIDIA, 2017, NVIDIA TESL V100
   NVIDIA, 2018, MEET AIRI AI READ IN
   NVIDIA, 2017, NVIDIA DGX 4 DEEP LE
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P367, DOI 10.1145/3123939.3123979
   Park J, 2018, ACM SIGPLAN NOTICES, V53, P411, DOI 10.1145/3200691.3178531
   Pichai B, 2014, ACM SIGPLAN NOTICES, V49, P743, DOI [10.1145/10.1145/2541940.2541942, 10.1145/2541940.2541942]
   Power J, 2014, INT S HIGH PERF COMP, P568, DOI 10.1109/HPCA.2014.6835965
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Rhu M., 2018, P INT S HIGH PERF CO
   Rhu M, 2016, INT SYMP MICROARCH
   Rosenfeld P., 2011, DRAMSIM2 CYCLE ACCUR
   Sakharnykh N., 2017, UNIFIED MEMORY PASCA, P28
   Samsung, 2016, 16GB 2GX72 MOD 288PI
   Samsung, 2016, 8GB 1GX72 MOD 288PIN
   Samsung, 2018, DDR4 SDRAM DATA SHEE
   Samsung, 2016, 32GB 4GX72 MOD 288PI
   Samsung, 2016, 64GB 8GX72 MOD 288PI
   Sharma H, 2016, INT SYMP MICROARCH
   Sridharan S., 2018, ARXIV PREPRINT ARXIV
   T. Hardware, 2015, MEAS DDR4 POW CONS
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Venkatesh G., 2017, P IEEE INT C AC SPEE
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Whatmough P., 2017, HOT CHIPS S HIGH PER
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Woolley C., 2015, NCCL ACCELERATED MUL
   Wu Zuxuan, 2018, DEEP LEARNING VIDEO
   Yin JM, 2018, CONF PROC INT SYMP C, P726, DOI 10.1109/ISCA.2018.00066
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zeng KH, 2017, AAAI CONF ARTIF INTE, P4334
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhu H., 2018, ARXIV180306905
   Zhu H., 2018, SYSML
NR 102
TC 33
Z9 33
U1 0
U2 1
PY 2018
BP 148
EP 161
DI 10.1109/MICRO.2018.00021
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Jin, LH
   Wang, C
   Gong, L
   Xu, CC
   Hu, YH
   Tan, LC
   Zhou, XH
AF Jin, Lihui
   Wang, Chao
   Gong, Lei
   Xu, Chongchong
   Hu, Yahui
   Tan, Luchao
   Zhou, Xuehai
GP IEEE
TI Work-in-Progress: Furion: Alleviating Overheads for Deep Learning
   Framework On Single Machine
SO 2018 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM
   SYNTHESIS (CODES+ISSS)
DT Proceedings Paper
CT ACM/IEEE International Conference on Hardware/Software Codesign and
   System Synthesis (CODES+ISSS)
CY SEP 30-OCT 05, 2018
CL Turin, ITALY
DE Deep Learning; Overhead; Throughput
AB Deep learning has been successful at solving many kinds of tasks. Hardware accelerators with high performance and parallelism have become mainstream to implement deep neural networks. In order to increase hardware utilization, multiple applications will share the same compute resource. However, different applications may use different deep learning frameworks and occupy different amounts of resources. If there are no scheduling platforms that are compatible with different frameworks, resources competition will result in longer response time, run out of memory, and other errors. When the resources of the system cannot satisfy all the applications at the same time, application switching overhead will be excessive without reasonable resource management strategy.
   In this paper, we propose Furion - a middleware alleviates overheads for deep learning framework on a single machine. Furion schedules tasks, overlaps the execution of different computing resource, and batches unknown inputs to increase the hardware accelerator utilization. It dynamically manages memory usage for each application to alleviate the overhead of application switching and make a complex model enable implement in a low-end GPU. Our experiment proved that Furion achieves 2.2x-2.7x speedup on the GTX1060.
C1 [Jin, Lihui; Wang, Chao; Gong, Lei; Xu, Chongchong; Hu, Yahui; Tan, Luchao; Zhou, Xuehai] Univ Sci & Technol China, Hefei, Peoples R China.
RP Jin, LH (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
CR Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Gong L., 2017, P 12 IEEE ACM IFIP I
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Sutskever I., 2014, ADV NEUR IN, P3104
NR 4
TC 0
Z9 0
U1 0
U2 0
PY 2018
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Azizimazreah, A
   Chen, LZ
AF Azizimazreah, Arash
   Chen, Lizhong
TI Polymorphic Accelerators for Deep Neural Networks
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Arrays; System-on-chip; Buffer storage; Neural networks; Parallel
   processing; Internet; Hardware; Deep neural networks; accelerators;
   configurable processing element (PE) array; PE array utilization; data
   reuse
AB Deep neural networks (DNNs) come with many forms, such as convolutional neural networks, multilayer perceptron, and recurrent neural networks, to meet diverse needs of machine learning applications. However, existing DNN accelerator designs, when used to execute multiple neural networks, suffer from underutilization of processing elements, heavy feature map traffic, and large area overhead. In this article, we propose a novel approach, Polymorphic Accelerators, to address the flexibility issue fundamentally. We introduce the abstraction of logical accelerators to decouple the fixed mapping with physical resources. Three procedures are proposed that work collaboratively to reconfigure the accelerator for the current network that is being executed and to enable cross-layer data reuse among logical accelerators. Evaluation results show that the proposed approach achieves significant improvement in data reuse, inference latency and performance, e.g., 1.52x and 1.63x increase in throughput compared with state-of-the-art flexible dataflow approach and resource partitioning approach, respectively. This demonstrates the effectiveness and promise of polymorphic accelerator architecture.
C1 [Azizimazreah, Arash; Chen, Lizhong] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
RP Azizimazreah, A (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
EM arash.a.mazreah@gmail.com; chenliz@oregonstate.edu
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Alwani M, 2016, INT SYMP MICROARCH
   Azizimazreah A., 2018, 2018 IEEE INT C, P1
   Azizimazreah A, 2019, INT S HIGH PERF COMP, P94, DOI 10.1109/HPCA.2019.00030
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Gudaparthi S, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P1, DOI 10.1145/3352460.3358316
   Guo HQ, 2019, IEEE INT CONF ASAP, P136, DOI 10.1109/ASAP.2019.00-16
   Han S, 2015, ADV NEUR IN, V28
   Hegde K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P933, DOI [10.1109/MICR0.2018.00080, 10.1109/MICRO.2018.00080]
   Hennessy J. L., 2017, COMPUTER ARCHIT QUAN
   Hill Parker, 2018, ARXIV180802513
   Horowitz M., 2014, ENERGY TABLE 45NM PR
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Morgan T. P., DRILLING MICROSOFT B
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Pourbabaee B, 2018, IEEE T SYST MAN CY-S, V48, P2095, DOI 10.1109/TSMC.2017.2705582
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rahman A, 2017, DES AUT TEST EUROPE, P1147, DOI 10.23919/DATE.2017.7927162
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Smith J. E, 1982, ACM SIGARCH COMPUT A, V10
   Song LH, 2020, INT S HIGH PERF COMP, P342, DOI 10.1109/HPCA47549.2020.00036
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Song MC, 2018, INT S HIGH PERF COMP, P92, DOI 10.1109/HPCA.2018.00018
   Sutskever I, 2014, ADV NEUR IN, V27
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wei XY, 2019, POLYM BULL, V76, P6077, DOI [10.1007/s00289-019-02690-6, 10.1109/icmmt45702.2019.8992910]
   Weste N.E.H., 2015, CMOS VLSI DESIGN CIR
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xilinx Product Specification, 2018, 7 SER FPGAS DAT SHEE
   Xilinx Product Specification, 2019, ULTRASCALE ARCHITECT
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 45
TC 6
Z9 7
U1 1
U2 12
PD MAR 1
PY 2022
VL 71
IS 3
BP 534
EP 546
DI 10.1109/TC.2020.3048624
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Sinha, M
   Gade, SH
   Singh, W
   Deb, S
AF Sinha, Mitali
   Gade, Sri Harsha
   Singh, Wazir
   Deb, Sujay
GP IEEE
TI Data-flow Aware CNN Accelerator with Hybrid Wireless Interconnection
SO 2018 IEEE 29TH INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 29th Annual IEEE International Conference on Application-Specific
   Systems, Architectures and Processors (ASAP)
CY JUL 10-12, 2018
CL Milan, ITALY
DE CNN hardware accelerators; wireless links
AB Deep convolution neural networks (CNNs) are computationally intensive machine learning algorithms with a large amount of data that impose various challenges for their hardware implementation. To meet the high computing demands of CNNs, many accelerator designs are proposed that revolve around achieving high parallelization, increasing on-chip data reuse and efficient memory hierarchy, etc. However, very few works have attempted to address the communication challenges in these massively parallel accelerators architectures, which is the most anticipated performance bottleneck. Traditional interconnections like bus, crossbar and even Network-on-Chip (NoC) topologies like mesh fail to achieve the peak performance required by the large number of processing elements on accelerators. In this work, we address the communication bottlenecks of accelerators by extensively studying the application data-flow. We propose an efficient accelerator architecture that employs broadcast enabled low latency wireless links along with traditional wired links to efficiently support the data-flow of accelerators and achieve high communication performance. Evaluation of the proposed design shows that it achieves 28% latency reduction, 19x bandwidth improvement and 35% network energy saving as compared to baseline wired networks.
C1 [Sinha, Mitali; Gade, Sri Harsha; Singh, Wazir; Deb, Sujay] IIIT Delhi, New Delhi, India.
RP Sinha, M (corresponding author), IIIT Delhi, New Delhi, India.
EM mitalis@iiitd.ac.in; harshag@iiitd.ac.in; wazirs@iiitd.ac.in;
   sdeb@iiitd.ac.in
CR Akopyan F., 2015, TCAD
   [Anonymous], 2013, ICASSP
   Chang MCF, 2008, ISPD'08: PROCEEDINGS OF THE 2008 ACM INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P78
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Choi, 2017, IEEE T COMPUTERS
   Deb S, 2013, IEEE T COMPUT, V62, P2382, DOI 10.1109/TC.2012.224
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gade H, 2017, IEEE T COMPUT, V66, P1145, DOI 10.1109/TC.2016.2643668
   HAMMERSTROM D, 1991, VLSI ARTIFICIAL INTELLIGENCE AND NEURAL NETWORKS, P357
   Krizhevsky A, 2012, NIPS, P1097
   Kwon H., P 11 IEEE ACM INT S, P19
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Shacham A, 2008, IEEE T COMPUT, V57, P1246, DOI 10.1109/TC.2008.78
   Ubal R, 2012, INT CONFER PARA, P335
NR 14
TC 8
Z9 8
U1 0
U2 0
PY 2018
BP 101
EP 104
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Feng, G
   Hu, ZY
   Chen, S
   Wu, F
AF Feng, Gan
   Hu, Zuyi
   Chen, Song
   Wu, Feng
BE Jiang, YL
   Tang, TA
   Huang, R
TI Energy-Efficient and High-Throughput FPGA-based Accelerator for
   Convolutional Neural Networks
SO 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED
   CIRCUIT TECHNOLOGY (ICSICT)
DT Proceedings Paper
CT 13th IEEE International Conference on Solid-State and Integrated-Circuit
   Technology (ICSICT)
CY OCT 25-28, 2016
CL Hangzhou, PEOPLES R CHINA
DE FPGA; CNN; accelerator; energy-efficient; LeNet-5
AB Convolutional Neural Networks (CNN) is widely applied in modern machine learning and pattern recognition area. Not only performance, more and more attention is paid on energy efficienct and scalable devices like FPGA as a better solution than CPU and GPU. In this paper, we propose methods to optimize CNN by fixed-point quantization, activation function approximation, loops and tasks pipelining and parallelization, memory reorganization, and implement an energy-efficient and high-throughput FPGA-based CNN accelerator for LeNet-5 based on Zynq-7000 platform. The accelerator can run at 166MHz and achieve a low error rate of 0.99%, the same as software implementations, and has 37% higher throughput and 93.7% less energy dissipation than a GPU implementation.
C1 [Feng, Gan; Hu, Zuyi; Chen, Song; Wu, Feng] Univ Sci & Technol China, Hefei 230046, Anhui, Peoples R China.
RP Chen, S (corresponding author), Univ Sci & Technol China, Hefei 230046, Anhui, Peoples R China.
EM songch@ustc.edu.cn
CR [Anonymous], VIVADO HIGH LEVEL SY
   [Anonymous], 2015, P 2015 ACM SIGDA INT
   [Anonymous], FIELD PROGR LOG APPL
   [Anonymous], 2014, P ACM INT C MULT
   [Anonymous], PERFORMANCE CONVOLUT
   [Anonymous], 2015, 2015 ACM IEEE 42 ANN
   [Anonymous], 2016, P 2016 ACM SIGDA INT
   [Anonymous], COMP VIS WORKSH ICCV
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], COMPUTER SCI INFORM
   Han S., 2015, ARXIV151000149
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
NR 12
TC 23
Z9 29
U1 2
U2 12
PY 2016
BP 624
EP 626
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Lee, KJ
   Moon, S
   Sim, JY
AF Lee, Kyeong-Jun
   Moon, Seunghyun
   Sim, Jae-Yoon
TI A 384G Output NonZeros/J Graph Convolutional Neural Network Accelerator
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article; Proceedings Paper
CT International Symposium on Integrated Circuits and Systems (ISICAS)
CY OCT 20-21, 2022
CL Bordeaux, FRANCE
DE Graph convolutional neural network (GCN); hardware accelerator; machine
   learning accelerator; sparse matrix multiplication; application-specific
   integrated circuit (ASIC)
AB This brief presents the first IC implementation of graph convolutional neural network (GCN) accelerator chip. A sparsity aware dataflow optimized for sub-block-wise processing of three different matrices in GCN is proposed to improve the utilization ratio of computing resources while reducing the amount of redundant access of off-chip memory. The implemented accelerator in 28-nm CMOS produces 384G NZ outputs/J for the extremely sparse matrix multiplications of the GCN. It shows 58k-to-143k, 38k-to-92k and 5k-to-13k Graph/J for the benchmark graph datasets of Cora, Citeseer and Pubmed, respectively. The energy efficiency in Graph/J of the proposed 16b ASIC implementation shows about 4-to-11x and 8-to-25x improvements compared to the previously reported 8b FPGA and 32b FPGA implementations, respectively.
C1 [Lee, Kyeong-Jun; Moon, Seunghyun] Pohang Univ Sci & Technol, Dept Convergence IT Engn, Pohang 37673, South Korea.
   [Sim, Jae-Yoon] Pohang Univ Sci & Technol, Dept Elect & Elect Engn, Pohang 37673, South Korea.
RP Lee, KJ (corresponding author), Pohang Univ Sci & Technol, Dept Convergence IT Engn, Pohang 37673, South Korea.
EM leekj9444@postech.ac.kr; thearth@postech.ac.kr; jysim@postech.ac.kr
CR Abou-Rjeili A., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Chen JF, 2018, PR MACH LEARN RES, V80
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Geng Tong, 2021, MICRO54 54 ANN IEEE, P1051
   Kipf T. N., 2017, PROC 5 INT C LEARN R, P1, DOI DOI 10.48550/ARXIV.1609.02907
   LeCun Y., 1995, HDB BRAIN THEORY NEU, P276, DOI 10.5555/303568.303704
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Lin CH, 2020, ISSCC DIG TECH PAP I, P134, DOI 10.1109/ISSCC19947.2020.9063111
   Luong M.T., 2015, EFFECTIVE APPROACHES
   Pal S, 2019, S VLSI TECH, pC150, DOI 10.23919/vlsic.2019.8778147
   Park JS, 2021, ISSCC DIG TECH PAP I, V64, P152, DOI 10.1109/ISSCC42613.2021.9365928
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Srivastava N, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P766, DOI 10.1109/MICRO50266.2020.00068
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Xie C, 2014, ADV NEUR IN, V27
   You HR, 2022, INT S HIGH PERF COMP, P460, DOI 10.1109/HPCA53966.2022.00041
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
NR 19
TC 0
Z9 0
U1 0
U2 2
PD OCT
PY 2022
VL 69
IS 10
BP 4158
EP 4162
DI 10.1109/TCSII.2022.3188428
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kara, K
   Wang, ZK
   Zhang, C
   Alonso, G
AF Kara, Kaan
   Wang, Zeke
   Zhang, Ce
   Alonso, Gustavo
TI doppioDB 2.0: Hardware Techniques for Improved Integration of Machine
   Learning into Databases
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article
AB Database engines are starting to incorporate machine learning (ML) functionality as part of their repertoire. Machine learning algorithms, however, have very different characteristics than those of relational operators. In this demonstration, we explore the challenges that arise when integrating generalized linear models into a database engine and how to incorporate hardware accelerators into the execution, a tool now widely used for ML workloads.
   The demo explores two complementary alternatives: (1) how to train models directly on compressed/encrypted column-stores using a specialized coordinate descent engine, and (2) how to use a bitwise weaving index for stochastic gradient descent on low precision input data. We present these techniques as implemented in our prototype database doppioDB 2.0 and show how the new functionality can be used from SQL.
C1 [Kara, Kaan; Wang, Zeke; Zhang, Ce; Alonso, Gustavo] Swiss Fed Inst Technol, Dept Comp Sci, Syst Grp, Zurich, Switzerland.
RP Kara, K (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Syst Grp, Zurich, Switzerland.
EM kaan.kara@inf.ethz.ch; zeke.wang@inf.ethz.ch; ce.zhang@inf.ethz.ch;
   gustavo.alonso@inf.ethz.ch
CR He Z., 2018, FPL
   Idreos S., 2012, DATA ENG, V40
   Kara K., 2017, FCCM
   Kara K., 2017, SIGMOD
   Kara K, 2018, PROC VLDB ENDOW, V12, P348, DOI 10.14778/3297753.3297756
   Kumar A., 2015, SIGMOD
   Li Y., 2013, SIGMOD
   Liu Y, 2018, PROC VLDB ENDOW, V11, P1220, DOI 10.14778/3231751.3231770
   Mahajan D, 2018, PROC VLDB ENDOW, V11, P1317, DOI 10.14778/3236187.3236188
   Owaida M., 2017, FCCM
   Putnam A, 2014, IEEE HOT CHIP SYMP
   Schleich M., 2016, SIGMOD
   Sidler D., 2017, SIGMOD
   Wang Z., 2019, PROC VLDB ENDOW, V12, P807, DOI DOI 10.14778/3317315.3317322
   Woods L., 2013, FCCM
   Zhang H., 2017, ICML
NR 16
TC 4
Z9 5
U1 1
U2 3
PD AUG
PY 2019
VL 12
IS 12
BP 1818
EP 1821
DI 10.14778/3352063.3352074
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Deng, JC
   Fang, YT
   Du, ZD
   Wang, Y
   Li, HW
   Temam, O
   Ienne, P
   Novo, D
   Li, XW
   Chen, YJ
   Wu, CY
AF Deng, Jiachao
   Fang, Yuntan
   Du, Zidong
   Wang, Ying
   Li, Huawei
   Temam, Olivier
   Ienne, Paolo
   Novo, David
   Li, Xiaowei
   Chen, Yunji
   Wu, Chengyong
GP IEEE
TI Retraining-Based Timing Error Mitigation for Hardware Neural Networks
SO 2015 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Conference on Design Automation Test in Europe (DATE)
CY MAR 09-13, 2015
CL Alpexpo Congress Center, Grenoble, FRANCE
HO Alpexpo Congress Center
DE neural networks; error tolerance; machine learning; timing errors;
   overclocking
ID YIELD
AB Recently, neural network (NN) accelerators are gaining popularity as part of future heterogeneous multi-core architectures due to their broad application scope and excellent energy efficiency. Additionally, since neural networks can be retrained, they are inherently resillient to errors and noises. Prior work has utilized the error tolerance feature to design approximate neural network circuits or tolerate logical faults. However, besides high-level faults or noises, timing errors induced by delay faults, process variations, aging, etc. are dominating the reliability of NN accelerator under nanoscale manufacturing process. In this paper, we leverage the error resiliency of neural network to mitigate timing errors in NN accelerators. Specifically, when timing errors significantly affect the output results, we propose to retrain the accelerators to update their weights, thus circumventing critical timing errors. Experimental results show that timing errors in NN accelerators can be well tamed for different applications.
C1 [Deng, Jiachao; Fang, Yuntan; Du, Zidong; Wang, Ying; Li, Huawei; Li, Xiaowei; Chen, Yunji; Wu, Chengyong] Chinese Acad Sci, Inst Comp Technol, SKL Comp Architecture, Beijing, Peoples R China.
   [Deng, Jiachao; Du, Zidong] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Fang, Yuntan] Huawei Technol Co Ltd, Shannon Lab, Shenzhen, Peoples R China.
   [Temam, Olivier] Google Inc, Mountain View, CA USA.
   [Fang, Yuntan; Ienne, Paolo; Novo, David] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
   [Chen, Yunji] Chinese Acad Sci, Ctr Excellence Brain Sci, Beijing, Peoples R China.
RP Deng, JC (corresponding author), Chinese Acad Sci, Inst Comp Technol, SKL Comp Architecture, Beijing, Peoples R China.
EM dengjiachao@ict.ac.cn; fangyuntan@huawei.com; duzidong@ict.ac.cn;
   wangying2009@ict.ac.cn; lihuawei@ict.ac.cn; olivier.temam@google.com;
   paolo.ienne@epfl.ch; david.novobruna@epfl.ch; lxw@ict.ac.cn;
   cyj@ict.ac.cn; cwu@ict.ac.cn
CR Amant R. St., 2014, ISCA
   [Anonymous], 2005, TECHNOLOGY INTEL MAG
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fang YT, 2014, IEEE T VLSI SYST, V22, P1450, DOI 10.1109/TVLSI.2013.2266668
   Fang YT, 2011, ASIAN TEST SYMPOSIUM, P329, DOI 10.1109/ATS.2011.72
   Hashmi A, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P1, DOI 10.1145/2024723.2000066
   HAYKIN S., 1999, NEURAL NETWORK COMPR
   Jiang ZG, 2009, IEEE T COMPUT AID D, V28, P1883, DOI 10.1109/TCAD.2009.2032375
   Kim Y, 2013, ICCAD-IEEE ACM INT, P130, DOI 10.1109/ICCAD.2013.6691108
   Lee KJ, 2012, IEEE T COMPUT AID D, V31, P754, DOI 10.1109/TCAD.2011.2179036
   Newman, UCI MACHINE LEARNING
   Sampson Adrian, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P25, DOI 10.1145/2540708.2540712
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Tianshi Chen, 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P36, DOI 10.1109/IISWC.2012.6402898
NR 16
TC 21
Z9 21
U1 1
U2 4
PY 2015
BP 593
EP 596
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xu, NY
   Cai, XF
   Gao, R
   Zhang, L
   Hsu, FH
AF Xu, Ning-Yi
   Cai, Xiong-Fei
   Gao, Rui
   Zhang, Lei
   Hsu, Feng-Hsiung
BE Amano, H
   Ye, A
   Ikenaga, T
TI FPGA-based accelerator design for RankBoost in Web search engines
SO ICFPT 2007: INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY,
   PROCEEDINGS
DT Proceedings Paper
CT Annual International Conference on Field Programmable Technology
CY DEC 12-14, 2007
CL Kitakyushu, JAPAN
AB Search relevance is a key measurement for the usefulness of search engines. Shift of search relevance among search engines can easily change a search company's market cap by tens of billions of dollars. With the ever-increasing scale of the Web, machine learning technologies have become important tools to improve search relevance ranking. RankBoost is a promising algorithm in this area, but it is not widely used due to its long training time. To reduce the computation time for RankBoost, we designed a FPGA-based accelerator system. The accelerator, plugged into a commodity PC, increased the training speed on MSN search engine data by 2 orders of magnitude compared to the original software implementation on a server. The proposed accelerator has been successfully used by researchers in the search relevance ranking.
C1 [Xu, Ning-Yi; Cai, Xiong-Fei; Gao, Rui; Zhang, Lei; Hsu, Feng-Hsiung] Microsoft Res Asia, Redmond, WA 98052 USA.
RP Xu, NY (corresponding author), Microsoft Res Asia, Redmond, WA 98052 USA.
EM ningyixu@microsoft.com; xfcai@microsoft.com; ruigao@microsoft.com;
   leizhang@microsoft.com; fhh@microsoft.com
CR [Anonymous], 2002, P 8 ACM SIGKDD INT C
   [Anonymous], 1999, MODERN INFORM RETRIE
   BRIN S, 1998, P 7 INT WORLD WID WE, P107, DOI [DOI 10.1016/S0169-7552(98)00110-X, 10.1016/S0169-7552(98)00110-X]
   Burges C., 2005, ICML, P89, DOI DOI 10.1145/1102351.1102363
   BURGES C, 2005, P NIPS2005 WORKSH LE
   ELGHAZAWI T, 2006, P ACM IEEE C SUP
   FAN W, 2004, HICSS, P8
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI DOI 10.1162/JMLR.2003.4.6.933
   FUHR N, 1989, ACM T INFORM SYST, V7, P183, DOI 10.1145/65943.65944
   IYER RD, 2000, CIKM, P70
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   LAPTEV I, 2006, P BMVC ED UK
   LIU X, 2004, PATTERN RECOGNITION
   Nallapati R., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P64, DOI 10.1145/1008992.1009006
   Qin T., 2006, LEARNING SEARCH WEB
   SCHAPIRE R, 2002, LECT NOTES STAT
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   SCHAPIRE RE, 1999, 6 INT JOINT C ART IN
   TSAI MF, 2006, FRANK RANKING METHOD
   Underwood KD, 2004, ANN IEEE SYM FIELD P, P219, DOI 10.1109/FCCM.2004.21
   Viola P., 2001, WORKSH STAT COMP THE
NR 22
TC 4
Z9 4
U1 0
U2 0
PY 2007
BP 33
EP 40
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nam, Y
   Zhou, MX
   Gupta, S
   De Micheli, G
   Cammarota, R
   Wilkerson, C
   Micciancio, D
   Rosing, T
AF Nam, Yujin
   Zhou, Minxuan
   Gupta, Saransh
   De Micheli, Gabrielle
   Cammarota, Rosario
   Wilkerson, Chris
   Micciancio, Daniele
   Rosing, Tajana
GP IEEE
TI Efficient Machine Learning on Encrypted Data using Hyperdimensional
   Computing
SO 2023 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN, ISLPED
DT Proceedings Paper
CT IEEE/ACM International Symposium on Low Power Electronics and Design
   (ISLPED)
CY AUG 07-08, 2023
CL Vienna, AUSTRIA
AB Fully Homomorphic Encryption (FHE) enables arbitrary computations on encrypted data without decryption, thus protecting data in cloud computing scenarios. However, FHE adoption has been slow due to the significant computation and memory overhead it introduces. This becomes particularly challenging for end-to-end processes, including training and inference, for conventional neural networks on FHE-encrypted data. Additionally, machine learning tasks require a high throughput system due to data-level parallelism. However, existing FHE accelerators only utilize a single SoC, disregarding the importance of scalability. In this work, we address these challenges through two key innovations. First, at an algorithmic level, we combine hyperdimensional Computing (HDC) with FHE. The machine learning formulation based on HDC, a brain-inspired model, provides lightweight operations that are inherently well-suited for FHE computation. Consequently, FHE-HD has significantly lower complexity while maintaining comparable accuracy to the state-of-the-art. Second, we propose an efficient and scalable FHE system for FHE-based machine learning. The proposed system adopts a novel interconnect network between multiple FHE accelerators, along with an automated scheduling and data allocation framework to optimize throughput and hardware utilization. We evaluate the value of the proposed FHE-HD system on the MNIST dataset and demonstrate that the expected training time is 4.7 times faster compared to state-of-the-art MLP training. Furthermore, our system framework exhibits up to 38.2 times speedup and 13.8 times energy efficiency improvement over the baseline scalable FHE systems that use the conventional dataparallel processing flow.
C1 [Nam, Yujin; Zhou, Minxuan; De Micheli, Gabrielle; Micciancio, Daniele; Rosing, Tajana] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
   [Gupta, Saransh] IBM Res, Santa Clara, CA USA.
   [Cammarota, Rosario; Wilkerson, Chris] Intel Labs, Santa Clara, CA USA.
RP Nam, Y (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM yujinnam@ucsd.edu; miz087@ucsd.edu; saransh@ibm.com;
   gdemicheli@ucsd.edu; rosario.cammarota@intel.com;
   chris.wilkerson@intel.com; dmicciancio@ucsd.edu; tajana@ucsd.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Albrecht M., 2018, HOMOMORPHIC ENCRYPTI
   Badawi A. A., 2022, 2022915 CRYPT EPR AR
   Brutzkus A, 2019, PR MACH LEARN RES, V97
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Cammarota R., 2022, CCSW
   Cheon JH, 2019, LECT NOTES COMPUT SC, V11922, P415, DOI 10.1007/978-3-030-34621-8_15
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   Cheon JH, 2018, LECT NOTES COMPUT SC, V10820, P360, DOI 10.1007/978-3-319-78381-9_14
   Curtis BR, 2019, PROCEEDINGS OF THE 7TH ACM WORKSHOP ON ENCRYPTED COMPUTING & APPLIED HOMOMORPHIC CRYPTOGRAPHY (WAHC'19), P1, DOI 10.1145/3338469.3358940
   Dheeru D., 2017, UCI MACHINE LEARNING
   Goldschmidt R. E., 1964, THESIS MIT
   Halevi S, 2018, LECT NOTES COMPUT SC, V10991, P93, DOI 10.1007/978-3-319-96884-1_4
   Han K., CT RSA 20
   Han K, 2019, AAAI CONF ARTIF INTE, P9466
   Imani M, 2021, INT S HIGH PERF COMP, P221, DOI 10.1109/HPCA51647.2021.00028
   Jang J, 2022, ASIA CCS'22: PROCEEDINGS OF THE 2022 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/3488932.3523253
   Kim J, 2022, INT SYMP MICROARCH, P1237, DOI 10.1109/MICRO56248.2022.00086
   Lee J.-W., 2022, IEEE ACCESS
   Li B., EUROCRYPT 21
   Li BY, 2022, LECT NOTES COMPUT SC, V13507, P560, DOI 10.1007/978-3-031-15802-5_20
   Lou Q., 2020, ADV NEURAL INFORM PR, V33, P9193
   Nandakumar K, 2019, IEEE COMPUT SOC CONF, P40, DOI 10.1109/CVPRW.2019.00011
   Samardzic N, 2022, CONF PROC INT SYMP C, P173, DOI 10.1145/3470496.3527393
   Zou ZW, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P850, DOI 10.23919/DATE51398.2021.9473987
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/ISLPED58423.2023.10244262
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sunny, F
   Nikdast, M
   Pasricha, S
AF Sunny, Febin
   Nikdast, Mahdi
   Pasricha, Sudeep
GP IEEE
TI RecLight: A Recurrent Neural Network Accelerator with Integrated Silicon
   Photonics
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
DE noncoherent photonics; machine learning; RNN acceleration; integrated
   photonic computation
AB Recurrent Neural Networks (RNNs) are used in applications that learn dependencies in data sequences, such as speech recognition, human activity recognition, and anomaly detection. In recent years, newer RNN variants, such as GRUs and LSTMs, have been used for implementing these applications. As many of these applications are employed in real-time scenarios, accelerating RNN/LSTM/GRU inference is crucial. In this paper, we propose a novel photonic hardware accelerator called RecLight for accelerating simple RNNs, GRUs, and LSTMs. Simulation results indicate that RecLight achieves 37x lower energy-per-bit and 10% better throughput compared to the state-of-the-art.
C1 [Sunny, Febin; Nikdast, Mahdi; Pasricha, Sudeep] Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO USA.
RP Sunny, F (corresponding author), Colorado State Univ, Dept Elect & Comp Engn, Ft Collins, CO USA.
EM febin.sunny@colostate.edu; mahdi.nikdast@colostate.edu;
   sudeep@colostate.edu
CR ANSYS Lumerical, US
   Azari E, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3366634
   Bogaerts W, 2012, LASER PHOTONICS REV, V6, P47, DOI 10.1002/lpor.201100017
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Cheng Q, 2020, P IEEE, V108
   Chittamuru S. V. R., 2015, IEEE DES TEST
   Chittamuru SVR, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3060517
   Cho K, 2014, ARXIV, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Conti F, 2018, IEEE CUST INTEGR CIR, DOI 10.1109/ICOPS35962.2018.9575761
   Dang D, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3446212
   Gao C, 2020, IEEE J EM SEL TOP C, V10, P419, DOI 10.1109/JETCAS.2020.3040300
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Inti R, 2021, CICC
   Lalapura VS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3448974
   Li X, 2020, J SEMICOND, V41, DOI 10.1088/1674-4926/41/11/111404
   Lu L, 2019, IEEE PHOTONICS J
   Milanizadeh M, 2019, J LIGHTWAVE TECHNOL, V37, P1325, DOI 10.1109/JLT.2019.2892512
   Pasricha S, 2020, IEEE DES TEST, V37, P60, DOI 10.1109/MDAT.2020.2982628
   Pintus P, 2019, LASER PHOTONICS REV, V13, DOI 10.1002/lpor.201800275
   QKeras, US
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shen JH, 2018, IEEE J SOLID-ST CIRC, V53, P1149, DOI 10.1109/JSSC.2017.2784761
   Stefan A, 2016, IEEE JLT
   Sunny F., 2021, DAC
   Sunny F., 2022, ACM GLSVLSI
   Sunny F., 2021, IEEEACM ASPDAC
   Sunny FP, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3459009
   Sunny FP, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3476988
   Sunny FP, 2021, IEEE T VLSI SYST, V29, P1206, DOI 10.1109/TVLSI.2021.3066990
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Thakkar I., 2016, IEEEACM NOCS
   Wang B, 2020, JLT
   Wang C., 2020, AOPC
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Weather dataset, US
   Zhao Z, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P705, DOI 10.1145/3287624.3287720
NR 38
TC 6
Z9 6
U1 1
U2 1
PY 2022
BP 98
EP 103
DI 10.1109/ISVLSI54635.2022.00030
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Ma, XR
   Zhao, RY
   Zhou, JY
AF Ma, Xinran
   Zhao, Ruiyong
   Zhou, Jianyang
GP IEEE
TI Convolutional Neural Network (CNN) Accelerator Chip Design
SO PROCEEDINGS OF 2019 IEEE 13TH INTERNATIONAL CONFERENCE ON
   ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION (IEEE-ASID'2019)
SE Proceedings of the International Conference on Anti-counterfeiting
   Security and Identification
DT Proceedings Paper
CT 13th IEEE International Conference on Anti-Counterfeiting, Security, and
   Identification (ASID)
CY OCT 25-27, 2019
CL Xiamen, PEOPLES R CHINA
DE CNN; hardware acceleration; systolic arrays; sequential logic design
AB With the development of artificial intelligence, artificial neural network has been applied in many industry fields. The convolutional neural network (CNN) which is one of the most important algorithms in deep learning plays an important role in computer vision and natural language processing. With machine learning becomes more complex, the amount of data and the amount of computation in CNN increase dramatically. A large amount of data multiplexing consumes a lot of data handling time for the traditional CPU (Von Neumann Architecture and Harvard Architecture). The data processing speed affects the CPU performance. Increasing computation speed and reducing data multiplexing have become the primary goal of neural network accelerators.
C1 [Ma, Xinran] Xiamen Univ, Xiamen, Peoples R China.
   [Zhao, Ruiyong] Shanghai Inst Microsyst & Informat Technol, Shanghai, Peoples R China.
RP Ma, XR (corresponding author), Xiamen Univ, Xiamen, Peoples R China.
EM 23120171152967@stu.xmu.edu.cn; 798229105@qq.com; zhoujy@xmu.edu.cn
CR Fang R., 2015, COMPUTER ENG APPL, P31
   Gonzalez AJ, 2016, IEEE GLOB COMM CONF
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lu H, 2013, PROCEEDINGS OF THE 9TH INTERNATIONAL PIPELINE CONFERENCE - 2012, VOL 1, P1
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Mnih V, 2013, P 29 INT C MACH LEAR, P567
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang K, 2013, TRANSPORT RES REC, P80, DOI 10.3141/2397-10
   Yu Q., 2007, RES RELIABILITY ASSE
   Yu Z. J., 2016, COMPUTER ENG, P109
NR 10
TC 1
Z9 1
U1 0
U2 2
PY 2019
BP 211
EP 215
DI 10.1109/icasid.2019.8925182
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Bertels, P
   Heirman, W
   Stroobandt, D
AF Bertels, Peter
   Heirman, Wim
   Stroobandt, Dirk
GP ACM
TI Strategies for Dynamic Memory Allocation in Hybrid Architectures
SO CF'09: CONFERENCE ON COMPUTING FRONTIERS & WORKSHOPS
DT Proceedings Paper
CT 6th ACM International Conference on Computing Frontiers and Workshops
CY MAY 18-20, 2009
CL Ischia, ITALY
DE Hardware acceleration; Java; Memory management
AB Hybrid architectures combining the strengths of general-purpose processors with application-specific hardware accelerators can lead to a significant performance improvement. Our hybrid architecture uses a Java Virtual Machine as an abstraction layer to hide the complexity of the hardware/software interface between processor and accelerator from the programmer. The data communication between the accelerator and the processor often incurs a significant cost, which sometimes annihilates the original speedup obtained by the accelerator. This article shows how we minimise this communication cost by dynamically chosing an optimal data layout in the Java heap memory which is distributed over both the accelerator and the processor memory. The proposed self-learning memory allocation strategy finds the optimal location for each Java object's data by means of runtime profiling. The communication cost is effectively reduced by up to 86% for the benchmarks in the DaCapo suite (51% on average).
C1 [Bertels, Peter; Heirman, Wim; Stroobandt, Dirk] Univ Ghent, Dept Elect & Informat Syst, B-9000 Ghent, Belgium.
RP Bertels, P (corresponding author), Univ Ghent, Dept Elect & Informat Syst, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM peter.bertels@ugent.be; wim.heirman@ugent.be; dirk.stroobandt@ugent.be
CR [Anonymous], P 20 ANN INT C SUP C
   Blackburn S. M., 2006, P 21 ANN ACM SIGPLAN, P169, DOI DOI 10.1145/1167473.1167488
   BORG A, 2006, P 4 INT WORKSH JAV T, P58
   Hakkennes E, 2001, J VLSI SIG PROC SYST, V28, P221, DOI 10.1023/A:1011117608815
   Helaihel R, 1997, 1997 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN - DIGEST OF TECHNICAL PAPERS, P690, DOI 10.1109/ICCAD.1997.643613
   Lattanzi E, 2005, INT J EMBED SYST, V1, P228, DOI 10.1504/IJES.2005.009952
   Lysecky R, 2006, ACM T DES AUTOMAT EL, V11, P659, DOI 10.1145/1142980.1142986
   Panainte EM, 2007, ACM T EMBED COMPUT S, V6, DOI 10.1145/1210268.1210274
   PORTHOUSE C, 2005, ARM WHITEPAPER   MAY
   Schoeberl M, 2008, J SYST ARCHITECT, V54, P265, DOI 10.1016/j.sysarc.2007.06.001
   Vassiliadis S, 2004, IEEE T COMPUT, V53, P1363, DOI 10.1109/TC.2004.104
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2009
BP 217
EP 220
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Zhang, Q
   Cao, JS
   Sui, YF
AF Zhang, Qi
   Cao, Jianshe
   Sui, Yanfeng
TI Development of a research platform for BEPC II accelerator fault
   diagnosis
SO RADIATION DETECTION TECHNOLOGY AND METHODS
DT Article
DE BEPC II; Integration framework; Fault diagnosis; Data mining; Machine
   learning
AB Background BEPC II is an electron-positron collider with a beam energy of 1.89 GeV and luminosity of 1 x 10(33) cm(-2) s(-1). Being a complex accelerator, fault diagnostics both in an accurate manner and in time are often challenging during its operation. Purpose The fault diagnosis research platform is capable of locating and resolving faults on time, thus can largely improve the operation of BEPCII by reducing downtime due to machine fault and consequently satisfying the demand for fault diagnosis of a complex system. Methods Making full use of the existing large-scale hardware foundation, abundant data resources and previous experiences, a fault diagnosis research platform was built by applying data mining, machine learning and other related algorithms to carry out specific fault analysis on the entire system. Conclusion The fault diagnosis research platform has been developed with implemented functions of data query, statistics and analysis. Partial fault diagnoses of the three subsystems have been realized. The 4W1 power supply fault has been successfully discovered, and effective solutions have been subsequently provided.
C1 [Zhang, Qi; Cao, Jianshe; Sui, Yanfeng] Chinese Acad Sci, Inst High Energy Phys, Key Lab Particle Accelerat Phys & Technol, Beijing 100049, Peoples R China.
   [Zhang, Qi; Cao, Jianshe; Sui, Yanfeng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RP Sui, YF (corresponding author), Chinese Acad Sci, Inst High Energy Phys, Key Lab Particle Accelerat Phys & Technol, Beijing 100049, Peoples R China.; Sui, YF (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM syf@ihep.ac.cn
CR [Anonymous], 2017, BEPC BEPC II
   [Anonymous], 2019, IK ANAL ELASTIC SEAR
   Brower J., 2017, FAULT ANAL TOOL ISIS
   Lin T, 2018, MOD ELECT TECHNOL, V41, P147
   Qian WN, 2002, J SOFTW, V13, P1387
   Sun Hyojung, 2016, THESIS
NR 6
TC 0
Z9 0
U1 2
U2 6
PD SEP
PY 2020
VL 4
IS 3
BP 269
EP 276
DI 10.1007/s41605-020-00180-2
EA JUN 2020
WC Nuclear Science & Technology
DA 2023-11-11
ER

PT C
AU Higuchi, T
   Yoshifuji, N
   Sakai, T
   Kitta, Y
   Takano, R
   Ikegami, T
   Taura, K
AF Higuchi, Tomokazu
   Yoshifuji, Naoki
   Sakai, Tomoya
   Kitta, Yoriyuki
   Takano, Ryousei
   Ikegami, Tsutomu
   Taura, Kenjiro
GP IEEE
TI ClPy: A NumPy-compatible Library Accelerated with OpenCL
SO 2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
DE OpenCL; NumPy; Python; Deep Learning; GPU
AB We developed ClPy, a Python library that supports OpenCL with a simple NumPy-like interface, and an extension of Chainer machine learning framework for OpenCL support. OpenCL emerged as a parallel computing standard with the goal of supporting a wide range of accelerators including GPUs (NVIDIA and others), FPGAs, DSPs, and CPUs. In contrast, many machine learning frameworks including Chainer have been built on top of CUDA, a predominant API for programming NVIDIA GPUs. As such, they cannot leverage other devices including non-NVIDIA GPUs and FPGAs. To facilitate developing cross-platform machine learning frameworks, ClPy is designed with an interface compatible with CuPy (CUDA Python), which itself has a NumPy-compatible interface and is used in Chainer to support both CPUs and NVIDIA GPUs. ClPy extends Chainer to any platform supporting OpenCL and can potentially do the same for other machine learning frameworks. This paper describes the design and implementation of ClPy and demonstrates it achieves reasonable performance on several machine learning applications. Our experiments show that the overhead of ClPy itself and serious performance degradation was caused by the lack of GPU-accelerated libraries of OpenCL including BLAS.
C1 [Higuchi, Tomokazu; Taura, Kenjiro] Univ Tokyo, Tokyo, Japan.
   [Yoshifuji, Naoki; Sakai, Tomoya; Kitta, Yoriyuki] Fixstars Corp, Tokyo, Japan.
   [Takano, Ryousei; Ikegami, Tsutomu] AIST, Tsukuba, Ibaraki, Japan.
RP Higuchi, T (corresponding author), Univ Tokyo, Tokyo, Japan.
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   [Anonymous], 2018, P INT WORKSH OPENCL
   Behnel S, 2011, COMPUT SCI ENG, V13, P31, DOI 10.1109/MCSE.2010.118
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chellapilla Kumar, 2006, 10 INT WORKSH FRONT
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Fang J, 2011, ENVIRONMENT, LOW-CARBON AND STRATEGY, P221
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guo K., 2017, ABS171208934 CORR
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Klöckner A, 2012, PARALLEL COMPUT, V38, P157, DOI 10.1016/j.parco.2011.09.001
   Li HY, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/6786184
   Liu ZQ, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P61, DOI 10.1109/FPT.2016.7929190
   Marcus M., 1994, HUMAN LANGUAGE TECHN
   Nair V., 2010, ICML, P807
   Okuta R., 2017, P WORKSHOP MACHINE L
   Patton RM, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Peterson P, 2001, SCIPY OPEN SOURCE SC
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sodani Avinash, 2015, 2015 IEEE Hot Chips 27 Symposium (HCS), DOI 10.1109/HOTCHIPS.2015.7477467
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tokui S., 2015, P WORKSH MACH LEARN, V5, P1
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
NR 31
TC 1
Z9 1
U1 0
U2 0
PY 2019
BP 933
EP 940
DI 10.1109/IPDPSW.2019.00159
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Ibrahim, A
   Valle, M
AF Ibrahim, Ali
   Valle, Maurizio
TI Real-Time Embedded Machine Learning for Tensorial Tactile Data
   Processing
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article; Proceedings Paper
CT 1st International Symposium on Integrated Circuits and Systems (ISICAS)
CY SEP 02-03, 2018
CL Taormina, ITALY
DE Embedded machine learning; real time processing; dedicated hardware
   implementation; tensorial kernel; tactile sensors; FPGA
ID SUPPORT VECTOR MACHINES; IMPLEMENTATION; ACCELERATOR; FRAMEWORK;
   ALGORITHM; SYSTEM
AB Machine learning (ML) has increasingly been recently employed to provide solutions for difficult tasks, such as image and speech recognition, and tactile data processing achieving a near human decision accuracy. However, the efficient hardware implementation of ML algorithms in particular for real time applications is still a challenge. This paper presents the hardware architectures and implementation of a real time ML method based on tensorial kernel approach dealing with multidimensional input tensors. Two different hardware architectures are proposed and assessed. Results demonstrate the feasibility of the proposed implementations for real time classification. The proposed parallel architecture achieves a peak performance of 302 G-ops while consuming 1.14 W for the Virtex-7 XC7VX980T FPGA device overcoming state of the art solutions.
C1 [Ibrahim, Ali; Valle, Maurizio] Univ Genoa, Dept Elect Elect & Telecommun Engn & Naval Archit, I-16145 Genoa, Italy.
RP Ibrahim, A (corresponding author), Univ Genoa, Dept Elect Elect & Telecommun Engn & Naval Archit, I-16145 Genoa, Italy.
EM ali.ibrahim@edu.unige.it
CR Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2001, LEARNING KERNELS
   [Anonymous], 2010, P 2010 4 INT C BIOIN, DOI [DOI 10.1109/ICBBE.2010.5517022, 10.1109/ICBBE.2010.5517022]
   Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Chakrabartty S, 2010, IEEE INT SYMP CIRC S, P513, DOI 10.1109/ISCAS.2010.5537578
   Danese G, 2002, IEEE MICRO, V22, P20, DOI 10.1109/MM.2002.1013301
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Decherchi S, 2012, IEEE T CIRCUITS-II, V59, P496, DOI 10.1109/TCSII.2012.2204112
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Fares H, 2017, 2017 FIRST NEW GENERATION OF CAS (NGCAS), P177, DOI 10.1109/NGCAS.2017.54
   Franceschi M., 2016, 12 C PHD RES MICR EL, DOI [10.1109/PRIME.2016.7519546, DOI 10.1109/PRIME.2016.7519546]
   Gastaldo P, 2014, IEEE SENS J, V14, P2216, DOI 10.1109/JSEN.2014.2320820
   Himavathi S, 2007, IEEE T NEURAL NETWOR, V18, P880, DOI 10.1109/TNN.2007.891626
   Ibrahim A, 2017, J LOW POWER ELECTRON, V13, P196, DOI 10.1166/jolpe.2017.1482
   Ibrahim A, 2015, IEEE COMP SOC ANN, P56, DOI 10.1109/ISVLSI.2015.63
   Ibrahim A, 2015, 2015 11TH CONFERENCE ON PH.D. RESEARCH IN MICROELECTRONICS AND ELECTRONICS (PRIME), P318, DOI 10.1109/PRIME.2015.7251399
   Khan S, 2015, PROCEEDINGS 5TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2015), P1, DOI 10.1109/ICCSCE.2015.7482148
   Kumar R, 2016, IEEE SENS J, V16, P177, DOI 10.1109/JSEN.2015.2475640
   LELE PP, 1954, J PHYSIOL-LONDON, V123, P187, DOI 10.1113/jphysiol.1954.sp005042
   Magno M, 2018, J LOW POWER ELECTRON, V14, P101, DOI 10.1166/jolpe.2018.1537
   Ortega-Zamorano F, 2016, IEEE T NEUR NET LEAR, V27, P1840, DOI 10.1109/TNNLS.2015.2460991
   Osta  M., 2018, P IEEE INT S CIRC SY, P1
   Osta M, 2018, J LOW POWER ELECTRON, V14, P110, DOI 10.1166/jolpe.2018.1536
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Pinna L, 2013, J CIRCUIT SYST COMP, V22, DOI 10.1142/S0218126613500667
   Seminara L, 2016, MECHATRONICS, V34, P84, DOI 10.1016/j.mechatronics.2015.04.001
   Signoretto M, 2011, NEURAL NETWORKS, V24, P861, DOI 10.1016/j.neunet.2011.05.011
   Tchendjou G. T., 2018, INT C MICR ICM DEC, DOI [10.1109/ICM.2017.8268848, DOI 10.1109/ICM.2017.8268848]
   Vachhani L, 2009, IEEE T CIRCUITS-II, V56, P61, DOI 10.1109/TCSII.2008.2010169
   Wang Z, 2015, IEEE T CIRCUITS-I, V62, P1136, DOI 10.1109/TCSI.2015.2395591
   Xia WJ, 2016, IEEE T NEUR NET LEAR, V27, P1094, DOI 10.1109/TNNLS.2015.2437901
   Yeam TC, 2017, TENCON IEEE REGION, P1868, DOI 10.1109/TENCON.2017.8228163
   Zhou BB, 1995, IEEE FIRST ICA3PP - IEEE FIRST INTERNATIONAL CONFERENCE ON ALGORITHMS AND ARCHITECTURES FOR PARALLEL PROCESSING, VOLS 1 AND 2, P256, DOI 10.1109/ICAPP.1995.472193
NR 33
TC 22
Z9 22
U1 3
U2 12
PD NOV
PY 2018
VL 65
IS 11
SI SI
BP 3897
EP 3906
DI 10.1109/TCSI.2018.2852260
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Murray, DG
   Simsa, J
   Klimovic, A
   Indyk, I
AF Murray, Derek G.
   Simsa, Jiri
   Klimovic, Ana
   Indyk, Ihor
TI tf.data: A Machine Learning Data Processing Framework
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article; Proceedings Paper
CT 47th International Conference on Very Large Data Bases (VLDB)
CY AUG 16-20, 2021
CL Copenhagen, DENMARK
AB Training machine learning models requires feeding input data for models to ingest. Input pipelines for machine learning jobs are often challenging to implement efficiently as they require reading large volumes of data, applying complex transformations, and transferring data to hardware accelerators while overlapping computation and communication to achieve optimal performance. We present tf . data, a framework for building and executing efficient input pipelines for machine learning jobs. The tf . data API provides operators that can be parameterized with user-defined computation, composed, and reused across different machine learning domains. These abstractions enable users to focus on the application logic of data processing, while tf . data's runtime ensures that pipelines run efficiently.
   We demonstrate that input pipeline performance is critical to the end-to-end training time of state-of-the-art machine learning models. tf . data delivers the high performance required, while avoiding the need for manual tuning of performance knobs. We show that tf . data features, such as parallelism, caching, static optimizations, and optional non-deterministic execution are essential for high performance. Finally, we characterize machine learning input pipelines for millions of jobs that ran in Google's datacenter fleet, showing that input data processing is highly diverse and consumes a significant fraction of job resources. Our analysis motivates future research directions, such as sharing computation across jobs and pushing data projection to the storage layer.
C1 [Murray, Derek G.] Lacework, San Jose, CA 95002 USA.
   [Simsa, Jiri; Indyk, Ihor] Google, Mountain View, CA 94043 USA.
   [Klimovic, Ana] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Murray, DG (corresponding author), Lacework, San Jose, CA 95002 USA.
EM derek.murray@lacework.net; jsimsa@google.com; aklimovic@ethz.ch;
   iindyk@google.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agarwal A, 2019, PR MACH LEARN RES, V97
   amazon, AM EC2 PRIC
   Ananthanarayanan Ganesh, 2012, NSDI, P20
   [Anonymous], 2008, OSDI 08
   [Anonymous], 2006, P 2006 ACM SIGMOD IN, DOI DOI 10.1145/1142473.1142552
   [Anonymous], 2019, BUILD GRAPH NETS TEN
   [Anonymous], 2020, APACHE BEAM ADV UNIF
   [Anonymous], 2010, HOTCLOUD 2010
   [Anonymous], 2019, IEEE WCNC, DOI [DOI 10.1109/wcnc.2019.8885834, DOI 10.1080/09593985.2019.1566940]
   [Anonymous], 2020, AMAZON EC2
   Apache Software Foundation, 2018, PARQUET
   Apache Software Foundation, 2012, AVRO
   BOTTOU L, 2009, P S LEARN DAT SCI PA
   Bradbury James, 2018, JAX COMPOSABLE PROGR
   Breck Eric, 2019, P MACHINE LEARNING 2
   Choi D, 2019, ARXIV PREPRINT ARXIV
   CORT J H, 1973, P458
   Cubuk E. D., 2019, COMPUT VIS PATTERN R
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Deslauriers Francis, 2016, USENIX WORKSHOP HOT
   Gharaibeh A., PSYARXIV, V13, P58, DOI [DOI 10.31234/OSF.IO/DR9Q3, 10.1016/j.amjms.2021.03.001,00089-6, DOI 10.1016/J.AMJMS.2021.03.001,00089-6, DOI 10.1007/S11270-007-9372-6]
   Google, PROT BUFF
   GRAEFE G, 1994, IEEE T KNOWL DATA EN, V6, P120, DOI 10.1109/69.273032
   Guan WJ, 2020, EUR RESPIR J, V55, DOI 10.1183/13993003.00547-2020
   Guirao Joaquin Anton, 2019, FAST DATA PREPROCESS
   Gunda Pradeep Kumar, 2010, OSDI P
   HADERLE DJ, 1984, IBM SYST J, V23, P112, DOI 10.1147/sj.232.0112
   He K., 2017, P IEEE INT C COMPUTE, DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Hinton G., 2015, P NIPS DEEP LEARNING, V14, P38, DOI DOI 10.48550/ARXIV.1503.02531
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Kakaraparthy A., 2019, P 11 USENIX WORKSH H
   Kalavri V, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P783
   Karanasos K., 2020, P C INN DAT SYST RES
   Ke Q., 2013, P 8 ACM EUROPEAN C C, P15
   Kumar AV, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P283
   Lattner Chris, 2020, MLIR COMPILER INFRAS
   Lee S, 2018, PROCEEDINGS OF 2018 IEEE/ACM MACHINE LEARNING IN HPC ENVIRONMENTS (MLHPC 2018), P47, DOI [10.1109/MLHPC.2018.000-4, 10.1109/MLHPC.2018.8638635]
   Li H., 2014, P ACM S CLOUD COMPUT, P1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mathur Ankit, 2020, ARXIV200713005 CSDB
   Micikevicius P., 2019, ARXIV PREPRINT ARXIV
   Mohan J, 2021, PROC VLDB ENDOW, V14, P771, DOI 10.14778/3446095.3446100
   Moldovan Dan, 2019, SYSML
   Murray DG, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P439, DOI 10.1145/2517349.2522738
   Oracle, 2020, PACK JAV UT STREAM
   Paszke A, 2019, ADV NEUR IN, V32
   Rashmi KV, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P401
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Rossbach CJ, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P49, DOI 10.1145/2517349.2522715
   Rossbach CJ, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P233
   Shore J. E., 1980, Performance Evaluation Review, V9, P217, DOI 10.1145/1009375.806166
   Simard PY, 2003, PROC INT CONF DOC, P958
   Tan RP, 2009, SECOND INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION, AND VALIDATION, PROCEEDINGS, P307, DOI 10.1109/ICST.2009.32
   TensorFlow. 2021, 2021, TFRECORD TFEXAMPLE
   Torch Contributors, 2019, PYTORCH DOCS
   Vaswani A, 2017, ADV NEUR IN, V30
   Welsh M., 2001, Operating Systems Review, V35, P230, DOI 10.1145/502059.502057
   WMT, 2016, 1 C MACHINE TRANSLAT
   WMT, 2017, 2 C MACHINE TRANSLAT
   Wu Y, 2016, ARXIV
   Xin D, 2018, PROC VLDB ENDOW, V11, P1958, DOI 10.14778/3229863.3236234
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zoph B, 2017, 5 INT C LEARN REPR I
NR 68
TC 13
Z9 13
U1 0
U2 1
PD AUG
PY 2021
VL 14
IS 12
BP 2945
EP 2958
DI 10.14778/3476311.3476374
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Zhao, T
   Rucker, A
   Olukotun, K
AF Zhao, Tian
   Rucker, Alexander
   Olukotun, Kunle
BE Aamodt, TM
   Jerger, NE
   Swift, M
TI Sigma: Compiling Einstein Summations to Locality-Aware Dataflow
SO PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL
   SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, VOL 2, ASPLOS
   2023
DT Proceedings Paper
CT 28th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY MAR 25-29, 2023
CL Vancouver, CANADA
DE machine learning; neural networks; reconfigurable dataflow accelerator;
   hardware acceleration; compiler; domain-specific language; index
   notation
ID NEURAL-NETWORKS; PARALLELISM; LANGUAGE
AB Most dataflow accelerator compilers achieve high performance by mapping each node in a dataflow program to a dedicated hardware element on a dataflow accelerator. However, this approach misses critical data reuse optimizations required to exploit the data bandwidth from fine-grained memory elements, e.g., FIFOs and pipeline registers. Moreover, writing performant dataflowprograms requires users to have domain expertise in the underlying dataflow accelerators. To address these issues, we designed Sigma, a novel compiler that supports high-level programming constructs such as Einstein summations, index notations, and tensors, finds opportunities for data reuse from high-level dataflow graphs, and exploits on-chip data bandwidth from fine-grained memory elements. Sigma targeting a research dataflow accelerator demonstrates a 5.4x speedup and 44.6x area-normalized speedup over Nvidia's V100 accelerator, and a 7.1x speedup over hand-written dataflow programs.
C1 [Zhao, Tian; Rucker, Alexander; Olukotun, Kunle] Stanford Univ, Stanford, CA 94305 USA.
RP Zhao, T (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
CR Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Albawi S, 2017, I C ENG TECHNOL
   [Anonymous], 2022, XIL VIV HIGHL SYNTH
   [Anonymous], 2022, INT HIGHL SYNTH COMP
   Babuschkin I., 2020, DEEPMIND JAX ECOSYST
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chatarasi P, 2020, Arxiv, DOI arXiv:2002.07752
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Dadu V, 2021, CONF PROC INT SYMP C, P595, DOI 10.1109/ISCA52012.2021.00053
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Feldman Matthew, 2022, EFFICIENT MEMORY PAR, DOI 10.48550/arXiv.2202.01261
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry R, 2021, P ACM PROGRAM LANG, V5, DOI 10.1145/3485505
   Hsu Olivia, 2022, PREPRINT, DOI [10.48550/arXiv.2211.03251, DOI 10.48550/ARXIV.2211.03251]
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Lim AW, 1998, PARALLEL COMPUT, V24, P445, DOI 10.1016/S0167-8191(98)00021-0
   MACBETH JD, 1979, J FINANC, V34, P1173, DOI 10.2307/2327242
   Martineau M, 2019, LECT NOTES COMPUT SC, V11339, P444, DOI 10.1007/978-3-030-10549-5_35
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paszke A, 2019, ADV NEUR IN, V32
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Rucker Alexander, 2021, MICRO54 54 ANN IEEEA, P1022, DOI 10.1145/3466752.3480047
   Sabne Amit., 2020, XLA COMPILING MACHIN
   Sankaralingam Karthikeyan, 2022, MOZART REUSE EXPOSED, DOI [10.1145/3470496.3533040, DOI 10.1145/3470496.3533040]
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Vasilache N, 2018, Arxiv, DOI arXiv:1802.04730
   Verdoolaege S, 2010, LECT NOTES COMPUT SC, V6327, P299, DOI 10.1007/978-3-642-15582-6_49
   Vilim M, 2021, CONF PROC INT SYMP C, P402, DOI 10.1109/ISCA52012.2021.00039
   Vingelmann P., 2020, CUDA
   Wang YX, 2013, DES AUT CON
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang SW, 2020, Arxiv, DOI [arXiv:2002.07442, 10.48550/arXiv.2002.07442]
   Zhang YQ, 2021, CONF PROC INT SYMP C, P1041, DOI 10.1109/ISCA52012.2021.00085
   Zhao Tian, 2019, P MACHINE LEARNING S, V1, P166
NR 48
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 718
EP 732
DI 10.1145/3575693.3575694
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Martínez, PA
   Peccerillo, B
   Bartolini, S
   García, JM
   Bernabé, G
AF Antonio Martinez, Pablo
   Peccerillo, Biagio
   Bartolini, Sandro
   Manuel Garcia, Jose
   Bernabe, Gregorio
TI Applying Intel's oneAPI to a machine learning case study
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE heterogeneous computing; high performance computing; performance
   portability; machine learning
AB Different technologies and approaches exist to work around the performance portability problem. Companies and academia work together to find a way to preserve performance across heterogeneous hardware using a unified language, one language to rule them all. Intel's oneAPI appears with this idea in mind. In this article, we try the new Intel solution to approach heterogeneous programming, choosing machine learning as our case study. More precisely, we choose Caffe, a machine learning framework that was created six years ago. Nevertheless, how would it be to make Caffe again from the beginning, using a fresh new technology like oneAPI? In terms of not only the ease of programming-because only one source code would be needed to deploy Caffe to CPUs, GPUs, FPGAs, and accelerators (platforms that oneAPI currently supports)-but also performance, where oneAPI may be capable of taking advantage of specific hardware automatically. Is Intel's oneAPI ready to take the leap?
C1 [Antonio Martinez, Pablo; Manuel Garcia, Jose; Bernabe, Gregorio] Univ Murcia, Comp Engn Dept, Murcia, Spain.
   [Peccerillo, Biagio; Bartolini, Sandro] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
RP Martínez, PA (corresponding author), Univ Murcia, Comp Engn Dept, Murcia, Spain.
EM pabloantonio.martiners@um.es
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Al-Rfou Rami, 2016, ABS160502688 ARXIV
   AnandTech, 2020, APPL ANN APPL SIL M1
   AnandTech, 2018, HISILICON KIR 970 AN
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chollet F., 2015, KERAS
   Chris L., 2002, UIUCDCSR20022292
   Codeplay, 2020, SYCL CUDA DEV EX MOD
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Goli M, 2020, PROCEEDINGS OF 2020 IEEE/ACM INTERNATIONAL WORKSHOP ON PERFORMANCE, PORTABILITY AND PRODUCTIVITY IN HPC (P3HPC 2020), P25, DOI 10.1109/P3HPC51967.2020.00008
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hill MD., 2020, ARXIV PREPRINT ARXIV
   Intel, 2021, ONEAPI EXT
   Intel, 2020, ONEAPI SPEC
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khronos OpenCL Working Group, 2019, SYCL PROV SPEC VERS
   Kosar T, 2016, INFORM SOFTWARE TECH, V71, P77, DOI 10.1016/j.infsof.2015.11.001
   Kotsifakou M, 2018, ACM SIGPLAN NOTICES, V53, P68, DOI 10.1145/3200691.3178493
   Lattner C., 2020, P COMP MACH LEARN WO
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Neely J., 2016, LLNLTR700962
   NVIDIA, 2021, NVIDIA CUDA C PROGR
   Paszke A, 2019, ADV NEUR IN, V32
   Peccerillo B, 2019, PROCEEDINGS OF THE TENTH INTERNATIONAL WORKSHOP ON PROGRAMMING MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM 2019), P91, DOI 10.1145/3303084.3309496
   Peccerillo B, 2019, IEEE T PARALL DISTR, V30, P174, DOI 10.1109/TPDS.2018.2855182
   Qualcomm, 2020, SNAPDR 855 MOB PLATF
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   WANG Y, 2021, ACM T ARCHIT CODE OP, V18
   Xilinx, TRISYCL
   Zhang Jiyuan, 2018, INT C MACHINE LEARNI, V80, P5776
NR 32
TC 1
Z9 1
U1 1
U2 3
PD JUN 10
PY 2022
VL 34
IS 13
AR e6917
DI 10.1002/cpe.6917
EA APR 2022
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Chaudhuri, A
   Talukdar, J
   Jung, J
   Nam, GJ
   Chakrabarty, K
AF Chaudhuri, Arjun
   Talukdar, Jonti
   Jung, Jinwook
   Nam, Gi-Joon
   Chakrabarty, Krishnendu
GP IEEE
TI Fault-Criticality Assessment for AI Accelerators using Graph
   Convolutional Networks
SO PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2021)
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY FEB 01-05, 2021
CL ELECTR NETWORK
AB Owing to the inherent fault tolerance of deep neural networks (DNNs), many structural faults in DNN accelerators tend to be functionally benign. In order to identify functionally critical faults, we analyze the functional impact of stuck-at faults in the processing elements of a 128x128 systolic-array accelerator that performs inferencing on the MNIST dataset. We present a 2-tier machine-learning framework that leverages graph convolutional networks (GCNs) for quick assessment of the functional criticality of structural faults. We describe a computationally efficient methodology for data sampling and feature engineering to train the GCN-based framework. The proposed framework achieves up to 90% classification accuracy with negligible misclassification of critical faults.
C1 [Chaudhuri, Arjun; Talukdar, Jonti; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
   [Jung, Jinwook; Nam, Gi-Joon] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY USA.
RP Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
CR [Anonymous], GOOGLE EDGE TPU CORA
   [Anonymous], DEEP GRAPH LIB PYTHO
   Chen Y., 2020, SURVEY ACCELERATOR A
   Gebregiorgis A, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000110
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Liu YD, 2020, IEEE T COMPUT AID D, V39, P1699, DOI 10.1109/TCAD.2019.2925353
   Ma YZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317838
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Shibahara S., 2018, CICC
   Wang H., 2020, 2020 57 ACM IEEE DES
   Welling M., 2017, ICLR 2017, P1, DOI [DOI 10.1109/ICDM.2019.00070, DOI 10.48550/ARXIV.1609.02907]
   Xiang D, 2017, IEEE T VLSI SYST, V25, P942, DOI 10.1109/TVLSI.2016.2606248
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
NR 15
TC 2
Z9 2
U1 1
U2 2
PY 2021
BP 1596
EP 1599
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Software Engineering
DA 2023-11-11
ER

PT J
AU Kafkes, D
   John, JS
AF Kafkes, Diana
   St. John, Jason
TI BOOSTR: A Dataset for Accelerator Control Systems
SO DATA
DT Article; Data Paper
DE dataset; artificial intelligence; machine learning; accelerator control
   systems; anomaly detection
AB The Booster Operation Optimization Sequential Time-series for Regression (BOOSTR) dataset was created to provide a cycle-by-cycle time series of readings and settings from instruments and controllable devices of the Booster, Fermilab's Rapid-Cycling Synchrotron (RCS) operating at 15 Hz. BOOSTR provides a time series from 55 device readings and settings that pertain most directly to the high-precision regulation of the Booster's gradient magnet power supply (GMPS). To our knowledge, this is one of the first well-documented datasets of accelerator device parameters made publicly available. We are releasing it in the hopes that it can be used to demonstrate aspects of artificial intelligence for advanced control systems, such as reinforcement learning and autonomous anomaly detection.
   Dataset: https://doi.org/10.5281/zenodo.4382663
   Data Set License: The dataset is made available under a Creative Commons Attribution 4.0 International license.
C1 [Kafkes, Diana; St. John, Jason] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
RP Kafkes, D (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM dkafkes@fnal.gov; stjohn@fnal.gov
CR Cahill K., 2008, ICFA BEAM DYN NEWSLE, V47, P106
   Duarte J.M., 2020, 201107371 ARXIV
   Hazelwood K.J., FERMILAB ELECT LOGBO
   Kafkes D., 2021, **DATA OBJECT**, DOI [10.5281/zenodo.4382663, DOI 10.5281/ZENODO.4382663]
   Kafkes D., 2020, **DATA OBJECT**, DOI [10.5281/zenodo.4088982, DOI 10.5281/ZENODO.4088982]
NR 5
TC 3
Z9 3
U1 2
U2 6
PD APR
PY 2021
VL 6
IS 4
AR 42
DI 10.3390/data6040042
WC Computer Science, Information Systems; Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Pedretti, G
   Serebryakov, S
   Strachan, JP
   Graves, CE
AF Pedretti, Giacomo
   Serebryakov, Sergey
   Strachan, John Paul
   Graves, Catherine E.
GP IEEE
TI A general tree-based machine learning accelerator with memristive analog
   CAM
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS 22)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-JUN 01, 2022
CL Austin, TX
ID CONTENT-ADDRESSABLE MEMORY
AB Deep learning models have reached high accuracy in multiple classification tasks. However these models lack explainability, namely the capability of understanding why a certain class is chosen along with the class predicted. On the other hand, tree-based models are top performers in several applications, particularly when the training set is limited, while also being more explainable. However, tree-based models are difficult to accelerate with conventional digital hardware due to irregular memory access patterns. Here we show a tree-based ML accelerator based on a novel analog content addressable memory with memristor devices, capable of handling multiple types of bagging and boosting techniques common in tree-based algorithms. Our results show a large improvement of similar to 60x lower latency and 160x reduced energy consumption compared to the state of the art, demonstrating the promise of our accelerator approach.
C1 [Pedretti, Giacomo; Serebryakov, Sergey; Graves, Catherine E.] Hewlett Packard Labs, Hewlett Packard Enterprise, Milpitas, CA 95035 USA.
   [Strachan, John Paul] Forschungszentrum Julich, Peter Grunberg Inst PGI 14, Julich, Germany.
   [Strachan, John Paul] Rhein Westfal TH Aachen, Aachen, Germany.
RP Pedretti, G (corresponding author), Hewlett Packard Labs, Hewlett Packard Enterprise, Milpitas, CA 95035 USA.
EM giacomo.pedretti@hpe.com; j.strachan@fz-juelich.de;
   catherine.graves@hpe.com
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2010, P 19 USENIX C SEC
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Chang MF, 2017, IEEE J SOLID-ST CIRC, V52, P1664, DOI 10.1109/JSSC.2017.2681458
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Graves CE, 2020, ADV MATER, V32, DOI 10.1002/adma.202003437
   Grossi A, 2018, IEEE T VLSI SYST, V26, P2599, DOI 10.1109/TVLSI.2018.2805470
   Gunning D., 2017, EXPLAINABLE ARTIFICI, V2, P2, DOI DOI 10.1126/SCIROBOTICS.AAY7120
   Huang K, 2013, 2013 ACM/IEEE SYMPOSIUM ON ARCHITECTURES FOR NETWORKING AND COMMUNICATIONS SYSTEMS (ANCS), P83, DOI 10.1109/ANCS.2013.6665178
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Kaggle, 2020, STAT MACH LEARN DAT
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15254-4
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Li C, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372119
   Li H., IEEE T ELECTRON DEV
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Pedretti G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25873-0
   Prisacariu Victor Adrian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3344, DOI 10.1109/ICPR.2010.816
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sun Z., 2019, 2019 Device Research Conference (DRC), P215, DOI 10.1109/DRC46940.2019.9046477
   Tracy T, 2016, LECT NOTES COMPUT SC, V9697, P200, DOI 10.1007/978-3-319-41321-1_11
   Wang X., IEEE T ELECTRON DEV, V68
   Xu CC, 2016, IEEE COMMUN SURV TUT, V18, P2991, DOI 10.1109/COMST.2016.2566669
   Yan L, 2020, NAT MACH INTELL, V2, P283, DOI 10.1038/s42256-020-0180-7
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 33
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 220
EP 224
DI 10.1109/ISCAS48785.2022.9937772
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Eldridge, S
   Appavoo, J
   Joshi, A
   Waterland, A
   Seltzer, M
AF Eldridge, Schuyler
   Appavoo, Jonathan
   Joshi, Ajay
   Waterland, Amos
   Seltzer, Margo
GP IEEE
TI Towards General-Purpose Neural Network Computing
SO 2015 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION
   (PACT)
SE International Conference on Parallel Architectures and Compilation
   Techniques
DT Proceedings Paper
CT 24th International Conference on Parallel Architecture and Compilation
   (PACT)
CY OCT 18-21, 2015
CL San Francisco, CA
AB Machine learning is becoming pervasive; decades of research in neural network computation is now being leveraged to learn patterns in data and perform computations that are difficult to express using standard programming approaches. Recent work has demonstrated that custom hardware accelerators for neural network processing can outperform software implementations in both performance and power consumption. However, there is neither an agreed-upon interface to neural network accelerators nor a consensus on neural network hardware implementations. We present a generic set of software/hardware extensions, X-FILES, that allow for the general-purpose integration of feedforward and feedback neural network computation in applications. The interface is independent of the network type, configuration, and implementation. Using these proposed extensions, we demonstrate and evaluate an example dynamically allocated, multi-context neural network accelerator architecture, DANA. We show that the combination of X-FILES and our hardware prototype, DANA, enables generic support and increased throughput for neural-network-based computation in multi-threaded scenarios.
C1 [Eldridge, Schuyler; Joshi, Ajay] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.
   [Appavoo, Jonathan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.
   [Waterland, Amos; Seltzer, Margo] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA USA.
RP Eldridge, S (corresponding author), Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.
EM schuye@bu.edu; jappavoo@bu.edu; joshi@bu.edu; apw@seas.harvard.edu;
   margo@eecs.harvard.edu
CR Agakov F, 2006, INT SYM CODE GENER, P295
   [Anonymous], 2003, AMB AX PROT SPEC
   [Anonymous], 2001, CACTI 3 0 INTEGRATED
   [Anonymous], 2003, IMPLEMENTATION FAST
   Bachrach J, 2012, DES AUT CON, P1212
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Clark N, 2008, CONF PROC INT SYMP C, P389, DOI 10.1109/ISCA.2008.33
   Cong J, 2012, DES AUT CON, P843
   Eldridge S, 2014, PR GR LAK SYMP VLSI, P169, DOI 10.1145/2591513.2591534
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Fieres J, 2008, IEEE IJCNN, P969, DOI 10.1109/IJCNN.2008.4633916
   Jiménez DA, 2002, ACM T COMPUT SYST, V20, P369, DOI 10.1145/571637.571639
   Justo JF, 1998, PHYS REV B, V58, P2539, DOI 10.1103/PhysRevB.58.2539
   Kara Y, 2011, EXPERT SYST APPL, V38, P5311, DOI 10.1016/j.eswa.2010.10.027
   Kestur S, 2012, ANN IEEE SYM FIELD P, P141, DOI 10.1109/FCCM.2012.33
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Kim LW, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2539125
   Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   Kim S, 2011, 2011 11TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1
   Le Ly D, 2010, IEEE T NEURAL NETWOR, V21, P1780, DOI 10.1109/TNN.2010.2073481
   Li B., 2013, P INT S LOW POW EL D
   Liu X., 2014, P HIGH PERF EXTR COM
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Park M. S., 2013, P DES AUT C DAC, P135
   St Amant R, 2014, CONF PROC INT SYMP C, P505, DOI 10.1109/ISCA.2014.6853213
   Stillwell PM, 2009, 16TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING (HIPC), PROCEEDINGS, P109, DOI 10.1109/HIPC.2009.5433219
   Vo H., 2013, WORKSH INT OP SYST C
   Waterland A, 2014, ACM SIGPLAN NOTICES, V49, P575, DOI 10.1145/2541940.2541985
   Waterman A, 2014, UCBEECS201454, VI
   Waterman A., 2015, RISC V INSTRUCTION S
NR 36
TC 10
Z9 10
U1 0
U2 4
PY 2015
BP 99
EP 112
DI 10.1109/PACT.2015.21
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lee, KH
   Wang, Z
   Verma, N
AF Lee, Kyong Ho
   Wang, Zhuo
   Verma, Naveen
GP IEEE
TI HARDWARE SPECIALIZATION OF MACHINE-LEARNING KERNELS: POSSIBILITIES FOR
   APPLICATIONS AND POSSIBILITIES FOR THE PLATFORM DESIGN SPACE (Invited)
SO 2013 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS)
SE IEEE Workshop on Signal Processing
DT Proceedings Paper
CT IEEE Workshop on Signal Processing Systems (SiPS)
CY OCT 16-18, 2013
CL Taipei, TAIWAN
DE accelerators; embedded systems hardware resilience; machine learning
AB This paper considers two challenging trends affecting low-power sensing systems: (1) the applications of interest increasingly involve embedded signals that are very complex to analyze; and (2) the platforms themselves face elevating constraints in terms of energy and possibly cost. Motivated by the complexities of analyzing the application signals, we emphasize the benefits of data-driven approaches. Most notably, these approaches are based on machine learning, as opposed to traditional DSP. We consider how the algorithms lend themselves to specialized signal-analysis platforms. Hardware specialization is well-regarded as an approach to address issues of computational efficiency, performance, and capacity, thus playing a key role in leveraging Moore's Law. However, we describe how hardware specialization of machine-learning kernels, this time with an explicit focus on error resilience, can also play a powerful role in enabling system-wide fault tolerance, thereby aiding Moore's Law on another dimension.
C1 [Lee, Kyong Ho; Wang, Zhuo; Verma, Naveen] Princeton Univ, Princeton, NJ 08544 USA.
RP Lee, KH (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.
CR Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2012, BOOSTING ADAPTIVE CO
   [Anonymous], 2005, TECHNOLOGY INTEL FEB
   Brinker K, 2003, P 20 INT C MACH LEAR, P59
   Csavoy A, 2009, SYMP VLSI CIRCUITS, P4
   DeOrio A., 2013, DATE
   Ganapathi A. S., 2009, THESIS U CAL BERKELE
   Ge Y, 2011, DES AUT CON, P95
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Khan FM, 2004, PROCEEDINGS OF THE EUROMICRO SYSTEMS ON DIGITAL SYSTEM DESIGN, P254
   Kyong Ho Lee, 2012, ESSCIRC 2012 - 38th European Solid State Circuits Conference, P285, DOI 10.1109/ESSCIRC.2012.6341275
   Lee KH, 2012, J SIGNAL PROCESS SYS, V69, P339, DOI 10.1007/s11265-012-0672-8
   Lee KH, 2011, INT CONF ACOUST SPEE, P1597
   Leem L., 2010, IEEE ACM DATE MAR
   Maeda A., 2012, 2012 IEEE Symposium on VLSI Circuits, P6, DOI 10.1109/VLSIC.2012.6243763
   Park J, 2012, IEEE J SOLID-ST CIRC, V47, P2711, DOI 10.1109/JSSC.2012.2211691
   Sartain G., TRANSFORMING 100 YEA
   Sartori J., 2011, CASES OCT
   Shanbhag N., 2010, DAC
   Shih E. I., 2010, THESIS MIT CAMBRIDGE
   Shoeb A., 2010, ICML
   Ubeyli E., 2007, DIGITAL SIGNAL PROCE
   Verma Naveen, 2011, Journal of Low Power Electronics and Applications, V1, P150, DOI 10.3390/jlpea1010150
   Verma N., 2012, ICASSP
   Verma N, 2010, IEEE J SOLID-ST CIRC, V45, P804, DOI 10.1109/JSSC.2010.2042245
   Yetim Y., 2013, DATE
NR 26
TC 1
Z9 1
U1 0
U2 0
PY 2013
BP 330
EP 335
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Catullo, E
   Gallegati, M
   Russo, A
AF Catullo, Ermanno
   Gallegati, Mauro
   Russo, Alberto
TI Forecasting in a complex environment: Machine learning sales
   expectations in a stock flow consistent agent-based simulation model
SO JOURNAL OF ECONOMIC DYNAMICS & CONTROL
DT Article
DE Agent-based model; Machine learning; Genetic algorithm; Forecasting;
   Policy shocks
ID FINANCIAL ACCELERATOR; POLICY; MACROECONOMICS; CREDIT; FRAGILITY;
   ACCURACY; BUSINESS; MARKET
AB The aim of this paper is to investigate how different degrees of sophistication in agents' behavioral rules may affect individual and macroeconomic performances. In particular, we analyze the effects of introducing into an agent-based macro model firms that are able to formulate effective sales forecasts by using simple machine learning algorithms. These techniques are able to provide predictions that are unbiased and present a certain degree of accuracy, especially in the case of a genetic algorithm. We observe that machine learning allows firms to increase profits, though this result in a declining wage share and a smaller long-run growth rate. Moreover, the predictive methods are able to formulate expectations that remain unbiased when shocks are not massive, thus providing firms with forecasting capabilities that to a certain extent may be consistent with the Lucas Critique. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Catullo, Ermanno] Univ Teramo, Teramo, Italy.
   [Gallegati, Mauro; Russo, Alberto] Univ Politecn Marche, Ancona, Italy.
   [Russo, Alberto] Univ Jaume 1, Castellon De La Plana, Spain.
RP Russo, A (corresponding author), Univ Jaume 1, Dept Econ, Campus Riu Sec,Avda Vicent Sos Baynat S-N, Castellon De La Plana, Spain.
EM russo@uji.es
CR [Anonymous], 2010, 497 U OXF DEP EC
   [Anonymous], 2012, BIELEFELD WORKING PA
   Anufriev M, 2012, AM ECON J-MICROECON, V4, P35, DOI 10.1257/mic.4.4.35
   Arifovic J, 2017, J ECON DYN CONTROL, V82, P21, DOI 10.1016/j.jedc.2017.04.005
   Arifovic J, 2010, J ECON DYN CONTROL, V34, P1768, DOI 10.1016/j.jedc.2010.06.023
   Bargigli L, 2020, J ECON INTERACT COOR, V15, P413, DOI 10.1007/s11403-018-0217-8
   Bargigli L, 2014, J ECON BEHAV ORGAN, V99, P109, DOI 10.1016/j.jebo.2013.12.018
   Bianchi Carlo, 2007, Computational Economics, V30, P245, DOI 10.1007/s10614-007-9097-z
   Caiani A, 2020, MACROECON DYN, V24, P191, DOI 10.1017/S1365100518000299
   Caiani A, 2019, J ECON BEHAV ORGAN, V162, P389, DOI 10.1016/j.jebo.2018.12.023
   Caiani A, 2019, J EVOL ECON, V29, P177, DOI 10.1007/s00191-018-0554-8
   Caiani A, 2018, IND CORP CHANGE, V27, P1123, DOI 10.1093/icc/dty016
   Caiani A, 2016, J ECON DYN CONTROL, V69, P375, DOI 10.1016/j.jedc.2016.06.001
   Caverzasi E, 2018, IND CORP CHANGE, V27, P999, DOI 10.1093/icc/dty043
   Cincotti S, 2010, ECONOMICS-KIEL, V4, DOI 10.5018/economics-ejournal.ja.2010-26
   Colasante A, 2017, INT J FORECASTING, V33, P988, DOI 10.1016/j.ijforecast.2017.06.003
   Dawid H, 2014, J ECON DYN CONTROL, V44, P54, DOI 10.1016/j.jedc.2014.04.004
   Dawid H, 2019, J EVOL ECON, V29, P467, DOI 10.1007/s00191-018-0594-0
   Dawid H, 2018, HANDB COMPUT ECON, V4, P63, DOI 10.1016/bs.hescom.2018.02.006
   Dosi G, 2017, J ECON DYN CONTROL, V81, P162, DOI 10.1016/j.jedc.2017.02.005
   Dosi G, 2015, J ECON DYN CONTROL, V52, P166, DOI 10.1016/j.jedc.2014.11.014
   Dosi G, 2010, J ECON DYN CONTROL, V34, P1748, DOI 10.1016/j.jedc.2010.06.018
   Evans G., 2012, LEARNING EXPECTATION
   Evans G.W., 1996, GROWING ARTIFICIAL S
   Gatti DD, 2011, NEW ECON WINDOWS, P1, DOI 10.1007/978-88-470-1971-3
   Gatti DD, 2010, J ECON DYN CONTROL, V34, P1627, DOI 10.1016/j.jedc.2010.06.019
   Gerali A, 2010, J MONEY CREDIT BANK, V42, P107, DOI 10.1111/j.1538-4616.2010.00331.x
   Giri F, 2019, J ECON BEHAV ORGAN, V157, P42, DOI 10.1016/j.jebo.2018.04.007
   GODE DK, 1993, J POLIT ECON, V101, P119, DOI 10.1086/261868
   Godley W, 2007, MONETARY ECONOMICS: AN INTEGRATED APPROACH TO CREDIT, MONEY, INCOME, PRODUCTION AND WEALTH, P1, DOI 10.1057/9780230626546
   Grazzini J, 2017, J ECON DYN CONTROL, V77, P26, DOI 10.1016/j.jedc.2017.01.014
   Greer M, 2003, INT J FORECASTING, V19, P291, DOI 10.1016/S0169-2070(01)00141-8
   Hommes C, 2005, REV FINANC STUD, V18, P955, DOI 10.1093/rfs/hhi003
   Hommes C., 2013, BEHAV RATIONALITY HE
   Hommes C, 2011, J ECON DYN CONTROL, V35, P1, DOI 10.1016/j.jedc.2010.10.003
   Hotelling H, 1929, ECON J, V39, P41, DOI 10.2307/2224214
   Keynes JM, 1937, Q J ECON, V51, P209, DOI 10.2307/1882087
   Knetsch TA, 2007, J FORECASTING, V26, P527, DOI 10.1002/for.1040
   Knight F.H., 2006, RISK
   LEITCH G, 1991, AM ECON REV, V81, P580
   Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5
   LUCAS RE, 1976, CARN ROCH CONF SERIE, V1, P19, DOI 10.1016/S0167-2231(76)80003-6
   MARIMON R, 1993, J ECON THEORY, V61, P74, DOI 10.1006/jeth.1993.1059
   MUTH JF, 1961, ECONOMETRICA, V29, P315, DOI 10.2307/1909635
   MYERS SC, 1984, J FINANC, V39, P575, DOI 10.2307/2327916
   North M. J., 2007, MANAGING BUSINESS CO
   Onaran O., 2012, CONDITIONS WORK EMPL
   Onaran O, 2016, CAMB J ECON, V40, P1517, DOI 10.1093/cje/bew009
   Pons J, 2000, J FORECASTING, V19, P53, DOI 10.1002/(SICI)1099-131X(200001)19:1<53::AID-FOR736>3.0.CO;2-J
   Qi M., 2003, J EMPIR FINANC, V10, P623
   Qiu MY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155133
   Riccetti L, 2018, MACROECON DYN, V22, P896, DOI 10.1017/S1365100516000444
   Riccetti L, 2016, ECON MODEL, V52, P162, DOI 10.1016/j.econmod.2014.11.028
   Riccetti L, 2015, J ECON INTERACT COOR, V10, P305, DOI 10.1007/s11403-014-0130-8
   Russo A, 2007, J ECON BEHAV ORGAN, V64, P426, DOI 10.1016/j.jebo.2006.06.016
   Russo A, 2016, J EVOL ECON, V26, P25, DOI 10.1007/s00191-015-0410-z
   Salle IL, 2015, ECON MODEL, V46, P130, DOI 10.1016/j.econmod.2014.12.040
   SALOP SC, 1979, BELL J ECON, V10, P141, DOI 10.2307/3003323
   Simon H. A., 1976, METHOD APPRAISAL EC, P86, DOI DOI 10.1007/978-1-4613-4367-7_6
   SIMON HA, 1959, AM ECON REV, V49, P253
   SIMS CA, 1980, ECONOMETRICA, V48, P1, DOI 10.2307/1912017
   Sinitskaya E, 2015, J ECON DYN CONTROL, V61, P152, DOI 10.1016/j.jedc.2015.09.011
   Smets F, 2007, AM ECON REV, V97, P586, DOI 10.1257/aer.97.3.586
   Smets F, 2003, J EUR ECON ASSOC, V1, P1123, DOI 10.1162/154247603770383415
   STANLEY MHR, 1995, ECON LETT, V49, P453, DOI 10.1016/0165-1765(95)00696-D
   Stiglitz J.E., 2016, J EUR ECON ASSOC, P591
   Stockhammer E, 2014, REV POLIT ECON, V26, P210, DOI 10.1080/09538259.2014.881011
   Stockhammer E, 2009, CAMB J ECON, V33, P139, DOI 10.1093/cje/ben026
   Taylor J. B., 1993, CARNEGIE-ROCHESTER C, V39, P195, DOI [10.1016/0167-2231(93)90009-L, DOI 10.1016/0167-2231(93)90009-L]
   Teglio A, 2019, J ECON BEHAV ORGAN, V157, P59, DOI 10.1016/j.jebo.2017.09.016
   Turrell A., 2015, Q B Q4
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   Uribe M., 2017, OPEN EC MACROECONOMI
   Wilson S. W., 2002, Natural Computing, V1, P211, DOI 10.1023/A:1016535925043
   Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149
   Woodford M, 2013, ANNU REV ECON, V5, P303, DOI 10.1146/annurev-economics-080511-110857
NR 76
TC 1
Z9 1
U1 8
U2 17
PD JUN
PY 2022
VL 139
AR 104405
DI 10.1016/j.jedc.2022.104405
EA APR 2022
WC Economics
DA 2023-11-11
ER

PT C
AU Prakash, S
   Callahan, T
   Bushagour, J
   Banbury, C
   Green, AV
   Warden, P
   Ansell, T
   Reddi, VJ
AF Prakash, Shvetank
   Callahan, Tim
   Bushagour, Joseph
   Banbury, Colby
   Green, Alan V.
   Warden, Pete
   Ansell, Tim
   Reddi, Vijay Janapa
GP IEEE
TI CFU Playground: Full-Stack Open-Source Framework for Tiny Machine
   Learning (TinyML) Acceleration on FPGAs
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE, ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY APR 23-25, 2023
CL Raleigh, NC
AB Need for the efficient processing of neural networks has given rise to the development of hardware accelerators. The increased adoption of specialized hardware has highlighted the need for more agile design flows for hardware-software co-design and domain-specific optimizations. In this paper, we present CFU Playground- a full-stack open-source framework that enables rapid and iterative design and evaluation of machine learning (ML) accelerators for embedded ML systems. Our tool provides a completely open-source end-to-end flow for hardware-software co-design on FPGAs and future systems research. This full-stack framework gives the users access to explore experimental and bespoke architectures that are customized and co-optimized for embedded ML. Our rapid, deploy-profile-optimization feedback loop lets ML hardware and software developers achieve significant returns out of a relatively small investment in customization. Using CFU Playground's design and evaluation loop, we show substantial speedups between 55x and 75x. The soft CPU coupled with the accelerator opens up a new, rich design space between the two components that we explore in an automated fashion using Vizier, an open-source black-box optimization service.
C1 [Prakash, Shvetank; Banbury, Colby; Reddi, Vijay Janapa] Harvard Univ, Cambridge, MA 02138 USA.
   [Callahan, Tim; Green, Alan V.; Ansell, Tim] Google, Mountain View, CA 94043 USA.
   [Bushagour, Joseph] Purdue Univ, W Lafayette, IN 47907 USA.
   [Warden, Pete] Stanford Univ, Stanford, CA 94305 USA.
RP Prakash, S (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
CR Amid A, 2020, IEEE MICRO, V40, P10, DOI 10.1109/MM.2020.2996616
   Antmicro, 2018, REN
   Banbury C., 2021, P NEUR INF PROC SYST
   Banbury C. R., 2020, ARXIV
   Bourdeauducq S., 2020, ARXIV
   Buch M, 2021, INT SYM PERFORM ANAL, P96, DOI 10.1109/ISPASS51385.2021.00027
   Cadence, 1997, TENS PROC IP
   David R., 2020, ARXIV201008678
   Fahim Farah, 2021, HLS4ML OPEN SOURCE C
   Gray J, 2022, INTRO COMPOSABLE CUS
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Hanawa Toshihiro, 2013, 2013 IEEE International Symposium on Parallel and Distributed Processing, Workshops and PhD Forum (IPDPSW), P1030, DOI 10.1109/IPDPSW.2013.226
   Hooker Sara, 2020, HARDWARE LOTTERY
   Huang QS, 2019, INTEGR ANAL SYST, P1, DOI [10.1007/978-981-32-9729-6_1, 10.1109/iccad45719.2019.8942048]
   Im-tomu, 2018, FOM HARDW
   Lai LZ, 2018, Arxiv, DOI arXiv:1801.06601
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   M-Labs, 2018, NMIG
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mantovani P, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415753
   Pappon C., 2017, VEXRISCV
   Prakash P., 2021, DAC
   Richins D., 2021, ACM TOCS
   Shah D, 2019, ANNU IEEE IND CONF, DOI [10.1109/indicon47234.2019.9029064, 10.1109/FCCM.2019.00010]
   Sharma H., 2016, WORKSH COGN ARCH
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Song X., 2022, AUTOML C SYSTEMS
   SymbiFlow, US
   Synopsys, 2017, AS DES
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris S., 2018, ARXIV
   Verilator, 2003, US
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Yang E., 2021, IEEE 32 ASAP
   Yang TJ, 2017, CONF REC ASILOMAR C, P1916, DOI 10.1109/ACSSC.2017.8335698
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 36
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 157
EP 167
DI 10.1109/ISPASS57527.2023.00024
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Choi, S
   Kim, Y
   Kim, JW
   Kim, Z
   Kim, WY
AF Choi, Sunghwan
   Kim, Yeonjoon
   Kim, Jin Woo
   Kim, Zeehyo
   Kim, Woo Youn
TI Feasibility of Activation Energy Prediction of Gas-Phase Reactions by
   Machine Learning
SO CHEMISTRY-A EUROPEAN JOURNAL
DT Article
DE activation energy; gas-phase reactions; machine learning; quantum
   chemistry
ID QUANTUM-CHEMISTRY; GROUP ADDITIVITY; CONSTRUCTION; ABSTRACTION
AB Machine learning based on big data has emerged as a powerful solution in various chemical problems. We investigated the feasibility of machine learning models for the prediction of activation energies of gas-phase reactions. Six different models with three different types, including the artificial neural network, the support vector regression, and the tree boosting methods, were tested. We used the structural and thermodynamic properties of molecules and their differences as input features without resorting to specific reaction types so as to maintain the most general input form for broad applicability. The tree boosting method showed the best performance among others in terms of the coefficient of determination, mean absolute error, and root mean square error, the values of which were 0.89, 1.95, and 4.49 kcal mol(-1), respectively. Computation time for the prediction of activation energies for 2541 test reactions was about one second on a single computing node without using accelerators.
C1 [Choi, Sunghwan; Kim, Yeonjoon; Kim, Jin Woo; Kim, Zeehyo; Kim, Woo Youn] Korea Adv Inst Sci & Technol, Dept Chem, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Choi, Sunghwan] Korea Inst Sci & Technol Informat, Natl Inst Supercomp & Network, 245 Daehak Ro, Daejeon 34141, South Korea.
   [Kim, Woo Youn] Korea Adv Inst Sci & Technol, KI Artificial Intelligence, 291 Daehak Ro, Daejeon, South Korea.
RP Kim, WY (corresponding author), Korea Adv Inst Sci & Technol, Dept Chem, 291 Daehak Ro, Daejeon 34141, South Korea.; Kim, WY (corresponding author), Korea Adv Inst Sci & Technol, KI Artificial Intelligence, 291 Daehak Ro, Daejeon, South Korea.
EM wooyoun@kaist.ac.kr
CR [Anonymous], 2016, ANGEW CHEMIE
   [Anonymous], 2016, KDD16 P 22 ACM, DOI DOI 10.1145/2939672.2939785
   Basak D., 2007, NEURAL INF PROCESS L, V11, P203
   Battin-Leclerc F, 2011, CHEM SOC REV, V40, P4762, DOI 10.1039/c0cs00207k
   Cohen AJ, 2012, CHEM REV, V112, P289, DOI 10.1021/cr200107z
   Gao CW, 2016, COMPUT PHYS COMMUN, V203, P212, DOI 10.1016/j.cpc.2016.02.013
   Hachmann J, 2011, J PHYS CHEM LETT, V2, P2241, DOI 10.1021/jz200866s
   Kim Y, 2018, CHEM SCI, V9, P825, DOI 10.1039/c7sc03628k
   Li X, 2014, J CHEM INF MODEL, V54, P1061, DOI 10.1021/ci5000467
   Lu TF, 2009, PROG ENERG COMBUST, V35, P192, DOI 10.1016/j.pecs.2008.10.002
   Montavon G, 2013, NEW J PHYS, V15, DOI 10.1088/1367-2630/15/9/095003
   MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018
   Pilania G, 2013, SCI REP-UK, V3, DOI 10.1038/srep02810
   Ramakrishnan R, 2017, REV COMP CH, V30, P225
   Ramakrishnan R, 2015, J CHEM THEORY COMPUT, V11, P2087, DOI 10.1021/acs.jctc.5b00099
   Sadeghi A, 2013, J CHEM PHYS, V139, DOI 10.1063/1.4828704
   Saeys M, 2006, CHEMPHYSCHEM, V7, P188, DOI 10.1002/cphc.200500206
   Schütt KT, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13890
   Skoraczynski G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02303-0
   Snyder JC, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.253002
   Suleimanov YV, 2015, J CHEM THEORY COMPUT, V11, P4248, DOI 10.1021/acs.jctc.5b00407
   Sumathi R, 2002, J PHYS CHEM A, V106, P5474, DOI 10.1021/jp013957c
   Sumathi R, 2001, J PHYS CHEM A, V105, P8969, DOI 10.1021/jp011827y
   Suzuki T, 2017, INT J QUANTUM CHEM, V117, P33, DOI 10.1002/qua.25307
   Szymkuc S, 2016, ANGEW CHEM INT EDIT, V55, P5904, DOI 10.1002/anie.201506101
   Van de Vijver R, 2015, CHEM ENG J, V278, P385, DOI 10.1016/j.cej.2014.10.067
   Vandewiele NM, 2012, CHEM ENG J, V207, P526, DOI 10.1016/j.cej.2012.07.014
   YAO X, 1993, INT J INTELL SYST, V8, P539, DOI 10.1002/int.4550080406
   Zimmerman PM, 2013, J CHEM THEORY COMPUT, V9, P3043, DOI 10.1021/ct400319w
NR 29
TC 26
Z9 25
U1 1
U2 35
PD AUG 22
PY 2018
VL 24
IS 47
SI SI
BP 12354
EP 12358
DI 10.1002/chem.201800345
WC Chemistry, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Rakotomamonjy, A
   Le Riche, R
   Gualandris, D
   Harchaoui, Z
AF Rakotomamonjy, A.
   Le Riche, R.
   Gualandris, D.
   Harchaoui, Z.
TI A comparison of statistical learning approaches for engine torque
   estimation
SO CONTROL ENGINEERING PRACTICE
DT Article
DE neural networks; support vector machines; engine torque; black box
ID SUPPORT VECTOR MACHINES; PREDICTION; NETWORKS
AB Engine torque estimation has important applications in the automotive industry: for example, automatically setting gears, optimizing engine performance, reducing emissions and designing drivelines.
   A methodology is described for the on line calculation of torque values from the gear, the accelerator pedal position and the engine rotational speed. It is based on the availability of input-torque experimental signals that are pre-processed (resampled, filtered and segmented) and then learned by a statistical machine learning method.
   Four methods, spanning the main learning principles, are reviewed in a unified framework and compared using the torque estimation problem: linear least squares, linear and non-linear neural networks and support vector machines. It is found that a non-linear model structure is necessary for accurate torque estimation. The most efficient torque model built is a non-linear neural network that achieves about 2% test normalized mean square error in nominal conditions. (c) 2007 Elsevier Ltd. All rights reserved.
C1 INSA, LITIS EA 4051, F-76801 St Etienne, France.
   Ecole Mines, CNRS UMR5146, 3MI & SMS, St Etienne, France.
   Rech & Innovat Automobile, PSA, Velizy Villacoublay, France.
   CNRS, LTCI, Paris, France.
   ENST, Paris, France.
RP Rakotomamonjy, A (corresponding author), INSA, LITIS EA 4051, F-76801 St Etienne, France.
EM alain.rakoto@insa-rouen.fr
CR [Anonymous], 1986, SYSTEM IDENTIFICATIO
   [Anonymous], 2001, LEANING KERNELS
   [Anonymous], 1998, NEW YORK
   [Anonymous], NC2TR1998030
   Bishop C.M., 1995, NEURAL NETWORKS PATT
   CANU S, 1999, SNOWBIRD 99 WORKSH
   Chalhoub NG, 1999, J SOUND VIB, V224, P489, DOI 10.1006/jsvi.1999.2192
   Chamaillard Y, 2004, CONTROL ENG PRACT, V12, P417, DOI 10.1016/S0967-0661(03)00113-8
   Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142
   DIXON J, 2000, Patent No. 006035252
   DYN N, 1987, TOPICS MULTIVARIATE
   EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636
   Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316
   GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219
   HAFNER M, 2002, 15 IFAC C BARC SPAIN
   Heywood J.B., 2018, INTERNAL COMBUSTION
   HOHMANN S, 2000, 9 IFAC S CONTROL TRA
   JANKOVIC M, 2002, P 15 INT S MATH THEO
   KARLSSON J, 1999, SAE C
   LERICHE R, 1999, 04199 INSA
   Levenberg K., 1944, Q APPL MATH, V2, P164, DOI [DOI 10.1090/QAM/10666, 10.1090/QAM/10666]
   Macready, 1995, SFITR9502010
   Maertens K, 2004, CONTROL ENG PRACT, V12, P615, DOI 10.1016/S0967-0661(03)00143-6
   Marquardt D., 1963, SIAM J APPL MATH, V11, P431, DOI DOI 10.1137/0111030
   MINOUX M, 1986, MATH PROGR THEORY AL
   NAMBA H, 1992, Patent No. 0230745
   Ripley B. D., 1996, PATTERN RECOGN
   SANO T, 1995, JSAE REV, V16, P328
   SCHERER M, 1999, Patent No. 005889204
   VITEK O, 2003, P FLUID DYN 2003
   Wang C.C.L., 1997, J SEGMENTATION MARKE, V1, P5
NR 31
TC 13
Z9 19
U1 0
U2 11
PD JAN
PY 2008
VL 16
IS 1
BP 43
EP 55
DI 10.1016/j.conengprac.2007.03.009
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kratochvila, L
AF Kratochvila, Lukas
BE Novak, V
TI COMPUTING PLATFORMS FOR DEEP LEARNING TASK IN COMPUTER VISION
SO PROCEEDINGS II OF THE 26TH CONFERENCE STUDENT EEICT 2020
DT Proceedings Paper
CT 26th Annual Conference on Student Electrical Engineering, Information
   Science and Communication Technologies (STUDENT EEICT)
CY APR 23, 2020
CL ELECTR NETWORK
DE Deep learning; Hardware; Cloud computing
AB The recent progress in machine learning in computer vision guides to enormous hardware requirements. This paper discovers new innovative hardware capable of dealing with immense demands. The important decision is concentrating on task learning or the final classification. The main concern is on five domains: single-board computers, hardware accelerators, graphics cards, workstations, and cloud computing. These devices have several key features for detection that are discussed. Cloud computing is another presented approach. Furthermore, different delivery models of cloud computing are addressed.
C1 [Kratochvila, Lukas] FEEC BUT, Doctoral Degree Programme 1, Brno, Czech Republic.
RP Kratochvila, L (corresponding author), FEEC BUT, Doctoral Degree Programme 1, Brno, Czech Republic.
EM kratochvila@feec.vutbr.cz
CR Badger L., 2014, NIST SPECIAL PUBLICA
   Horak K., 2016, INT J SIGNAL PROCESS, V4, P1
   Kapil D, 2017, 2017 INTERNATIONAL CONFERENCE ON GREEN INFORMATICS (ICGI), P71, DOI 10.1109/ICGI.2017.18
   Peteiro-Barral D., 2013, SURVEY METHODS DISTR
   Petrackova A, 2019, J IMMUNOL RES, V2019, DOI 10.1155/2019/3575803
   Pop D., 2016, MACH LEARNING CLOUD
   Shah M. D., 2015, CLOUD COMPUTING ARCH
NR 7
TC 1
Z9 1
U1 0
U2 5
PY 2020
BP 171
EP 175
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xu, Z
   Abraham, J
AF Xu, Zheng
   Abraham, Jacob
GP IEEE Computer Society
TI Design of a Safe Convolutional Neural Network Accelerator
SO 2019 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2019)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 18th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 15-17, 2019
CL Miami, FL
DE Convolutional Neural Network; Safety; Concurrent Error Detection;
   Availability
ID FAULT-TOLERANCE
AB Recently Machine Learning (ML) accelerators have grown into prominence with significant power and performance efficiency improvements over CPU and GPU. In this paper, we developed an Algorithm Based Error Checker (ABEC) for Concurrent Error Detection (CED) based on an industry quality Convolution Neural Network (CNN) accelerator with priority to meet high safety Diagnostic Coverage (DC) requirement and enhanced area and power efficiency. Furthermore, we developed an Algorithm Based Cluster Checker (ABCC) with coarse-grained error localization to improve run-time availability. Experimental results showed that we could achieve above 99% DC with only 30% area and power overhead for a selected configuration.
C1 [Xu, Zheng; Abraham, Jacob] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Xu, Z (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM johnzxu@outlook.com; jaa@cerc.utexas.edu
CR [Anonymous], 2016, THE 49TH ANNUAL IEEE
   Bosilca G., 2015, INT J NETWORKING COM, V5, P2
   Bosilca G, 2009, J PARALLEL DISTR COM, V69, P410, DOI 10.1016/j.jpdc.2008.12.002
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chippa VK, 2013, CONF REC ASILOMAR C, P111, DOI 10.1109/ACSSC.2013.6810241
   Constantinides K, 2006, INT S HIGH PERF COMP, P3, DOI 10.1109/HPCA.2006.1598108
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   ISO, 2018, 26262 ISO
   JHA NK, 1993, IEEE T COMPUT AID D, V12, P878, DOI 10.1109/43.229762
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LaFrieda C, 2007, I C DEPEND SYS NETWO, P317, DOI 10.1109/DSN.2007.100
   Li ML, 2008, ACM SIGPLAN NOTICES, V43, P265, DOI 10.1145/1353536.1346315
   Li XH, 2007, INT S HIGH PERF COMP, P181
   LO JC, 1992, IEEE T COMPUT AID D, V11, P525, DOI 10.1109/43.125100
   Mitra A, 2006, CREATING AGILE BUSINESS SYSTEMS WITH REUSABLE KNOWLEDGE, P1, DOI 10.2277/ 0521851637
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mukherjee SS, 2002, CONF PROC INT SYMP C, P99, DOI 10.1109/ISCA.2002.1003566
   Nvidia, 2018, NVDIA OP SOURC ML AC
   Oh N, 2002, IEEE T RELIAB, V51, P63, DOI 10.1109/24.994913
   Scholl Alexander, 2016, 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). Proceedings, P251, DOI 10.1109/DSN.2016.31
   Synopsys, 2018, Z01X FUNCT SAF ASS
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 248
EP 253
DI 10.1109/ISVLSI.2019.00053
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ryoo, J
   Arunachalam, M
   Khanna, R
   Kandemir, MT
AF Ryoo, Jihyun
   Arunachalam, Meena
   Khanna, Rahul
   Kandemir, Mahmut T.
GP IEEE
TI Efficient K Nearest Neighbor Algorithm Implementations for
   Throughput-Oriented Architectures
SO 2018 19TH INTERNATIONAL SYMPOSIUM ON QUALITY ELECTRONIC DESIGN (ISQED)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 19th International Symposium on Quality Electronic Design (ISQED)
CY MAR 13-14, 2018
CL Santa Clara, CA
DE Machine Learning; K Nearest Neighbor; K-d Tree; Xeon Phi; GPU;
   Parallelization; Training; Classification
AB Scores of emerging and domain-specific applications need the ability to acquire and augment new knowledge from offline training-sets and online user interactions. This requires an underlying computing platform that can host machine learning (ML) kernels. This in turn entails one to have efficient implementations of the frequently-used ML kernels on state-of-the-art multicores and many-cores, to act as high-performance accelerators. Motivated by this observation, this paper focuses on one such ML kernel, namely, K Nearest Neighbor (KNN), and conducts a comprehensive comparison of its behavior on two alternate accelerator-based systems: NVIDIA GPU and Intel Xeon Phi (both KNC and KNL architectures). More explicitly, we discuss and experimentally evaluate various optimizations that can be applied to both GPU and Xeon Phi, as well as optimizations that are specific to either GPU or Xeon Phi. Furthermore, we implement different versions of KNN on these candidate accelerators and collect experimental data using various inputs. Our experimental evaluations suggest that, by using both general purpose and accelerator specific optimizations, one can achieve average speedups ranging 0.49x-3.48x (training) and 1.43x-9.41x (classification) on Xeon Phi series, compared to 0.05x-0.60x (training), 1.61x-6.32x (classification) achieved by the GPU version, both over the standard host-only system.
C1 [Ryoo, Jihyun; Kandemir, Mahmut T.] Penn State Univ, Old Main, State Coll, PA 16801 USA.
   [Arunachalam, Meena; Khanna, Rahul] Intel, 2111 NE 25th Ave, Hillsboro, OR USA.
RP Ryoo, J (corresponding author), Penn State Univ, Old Main, State Coll, PA 16801 USA.
EM jihyun@cse.psu.eud; meena.arunachalam@intel.com; rahul.khanna@intel.com;
   kandemir@cse.psu.eud
CR Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Ciresan D., 2011, P IJCNN
   Garcia V., 2008, P CVPR WORKSH
   Herrero-Lopez S., 2010, P GPGPU
   Jia Y., 2014, P ACM MM
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Li Y., 2010, P CIT
   Lichman M., 2013, UCI MACHINE LEARNING
   Liu Q., 2016, IEEE T CYBERNETICS, P1
   Pandya DH, 2013, EXPERT SYST APPL, V40, P4137, DOI 10.1016/j.eswa.2013.01.033
   Patwary M. M. A., 2016, P IPDPS
   Rhu M., 2013, P HPCA
   Shaikh A., 2015, Sindh University Research Journal -Science Series, V47, P389
   Stisen A., 2015, P SENSYS
   Wang Y., 2007, P ICMLC
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 16
TC 3
Z9 3
U1 0
U2 0
PY 2018
BP 144
EP 150
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Du, L
   Du, Y
   Chang, MCF
AF Du, Li
   Du, Yuan
   Chang, Mau-Chung Frank
TI A Reconfigurable 64-Dimension <i>K</i>-Means Clustering Accelerator With
   Adaptive Overflow Control
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Machine learning; unsupervised learning; K-means; hardware accelerator;
   clustering; vector flow
AB This brief presents a novel reconfigurable $K$ -means clustering accelerator that is suitable for integration in both IoT and data center system. The high vector dimension reconfigurability and design cost reduction is achieved through vector-streaming and adaptive overflow control to adapt distance computation using as-needed precision (dynamic 16-bit fixed-point data format). A two-stage shift-bit counted comparator is proposed. It can determine most results through only turning on the shift-bit comparator (3-bit), reducing the power consumption by $7\times $ compared to the direct full dynamic range comparison. Four vectors with two cluster centroids are processed simultaneously. Up to 8-dimension cluster vectors are stored in local buffer to reduce data exchange between the main memory and the processing engine. A prototype accelerator was implemented in TSMC 65 nm. The accelerator occupied 0.26 mm(2) and can support up to 64-D vector clustering. It achieved 31.2M query vectors/s with 41-mW power consumption at 250-MHz clock (cluster number: 2, vector dimension: 64) and an energy efficiency of 0.41 TOPS/W at 30 MHz clock.
C1 [Du, Li; Du, Yuan; Chang, Mau-Chung Frank] Univ Calif Los Angeles, High Speed Elect Lab, Los Angeles, CA 90095 USA.
   [Chang, Mau-Chung Frank] Natl Chiao Tung Univ, Hsinchu 30010, Taiwan.
RP Du, Y (corresponding author), Univ Calif Los Angeles, High Speed Elect Lab, Los Angeles, CA 90095 USA.
EM yuandu@ucla.edu
CR Chen TW, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P324
   Chen TW, 2013, IEEE T CIRCUITS-I, V60, P2165, DOI 10.1109/TCSI.2013.2239098
   Chen TW, 2011, IEEE T MOBILE COMPUT, V10, P1646, DOI 10.1109/TMC.2011.23
   Chen TW, 2010, IEEE T VLSI SYST, V18, P957, DOI 10.1109/TVLSI.2009.2017543
   Michael S., 2011, ADV NEURAL INFORM PR, P2375
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   You Li, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P115, DOI 10.1109/CIT.2010.60
NR 7
TC 2
Z9 2
U1 0
U2 6
PD APR
PY 2020
VL 67
IS 4
BP 760
EP 764
DI 10.1109/TCSII.2019.2922657
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT S
AU Park, H
   Kim, S
AF Park, Hyunbin
   Kim, Shiho
BE Kim, S
   Deka, GC
TI Hardware accelerator systems for artificial intelligence and machine
   learning
SO HARDWARE ACCELERATOR SYSTEMS FOR ARTIFICIAL INTELLIGENCE AND MACHINE
   LEARNING
SE Advances in Computers
DT Article; Book Chapter
ID NEURAL-NETWORKS; COPROCESSOR; DESIGN; MODEL
AB Recent progress in parallel computing machines, deep neural networks, and training techniques have contributed to the significant advances in artificial intelligence (AI) with respect to tasks such as object classification, speech recognition, and natural language processing. The development of such deep learning-based techniques has enabled AI-based networks to outperform humans in the recognition of objects in images. The graphics processing unit (GPU) has been the primary component used for parallel computing during the inference and training phases of deep neural networks. In this study, we perform training using a desktop or a server with one or more GPUs and inference using hardware accelerators on embedded devices. Performance, power consumption, and requirements of embedded system present major hindrances to the application of deep neural network-based systems using embedded controllers such as drones, AI speakers, and autonomous vehicles. In particular, power consumption of a commercial GPU commonly surpasses the power budget of a stand-alone embedded system.
   To reduce the power consumption of hardware accelerators, reductions in the precision of input data and hardware weight have become popular topics of research in this field. However, precision and accuracy share a trade-off relationship. Therefore, it is essential to optimize precision in a manner that does not degrade the accuracy of the inference process. In this context, the primary issues faced by hardware accelerators are loss of accuracy and high power consumption.
C1 [Park, Hyunbin] Samsung Elect, IT & Mobile Commun, Seoul, South Korea.
   [Kim, Shiho] Yonsei Univ, Sch Integrated Technol, Seoul, South Korea.
RP Park, H (corresponding author), Samsung Elect, IT & Mobile Commun, Seoul, South Korea.
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Alwani M, 2016, INT SYMP MICROARCH
   Amodei D, 2016, PR MACH LEARN RES, V48
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2008, 7542008 IEEE, DOI 10.1109/IEEESTD.2008.4610935
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   DANDAPAT A, 2010, INT J ELECT ELECT EN, V4, P234
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Ercegovac T.L.M.D, 2003, DIGITAL ARITHMETIC
   Fadavi-Ardekani J., 1993, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V1, P120, DOI 10.1109/92.238424
   Gokhale V, 2017, P INT S CIRC SYST IS
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel P., 2016, THESIS U CALIFORNIA
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hubara I, 2018, J MACH LEARN RES, V18
   Hussin R, 2008, P EL DES PEN MAL
   Iandola F. N., 2016, SQUEEZENET ALEXNET L
   Itoh N, 2001, IEEE J SOLID-ST CIRC, V36, P249, DOI 10.1109/4.902765
   Jolivet R, 2004, J NEUROPHYSIOL, V92, P959, DOI 10.1152/jn.00190.2004
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2016, P 6 INT C LEARN REPR
   Kang H, 2018, ARXIV180409862
   Katole A. L., 2015, ARXIV150901951
   Kim D, 2017, DES AUT TEST EUROPE, P1462, DOI 10.23919/DATE.2017.7927222
   Kim JH, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P268, DOI 10.1109/SOCC.2017.8226056
   Kim Y, 2014, P 2014 C EMP METH NA, P1746, DOI [10.3115/v1/D14-1181, DOI 10.3115/V1/D14-1181]
   Koster U, 2017, P NIPS 2017 LONG BEA
   Krenker A, 2011, ARTIFICIAL NEURAL NETWORKS - METHODOLOGICAL ADVANCES AND BIOMEDICAL APPLICATIONS, P3, DOI 10.5772/15751
   Krizhevsky A, 2012, P 2012 ADV NEUR INF
   Kuang SR, 2010, IEEE T CIRCUITS-I, V57, P568, DOI 10.1109/TCSI.2009.2023763
   Kumari R., 2017, P 2 INT C INT THINGS, P1
   Lai L., 2017, P 34 INT C MACH LEAR
   Lakshmanan M.O, 2003, P INT C NEUR INF PRO
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H, 2004, IEEE INT SOC CONF, P123
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Lin DD, 2016, PR MACH LEARN RES, V48
   Liu ZH, 2018, IEEE MICRO, V38, P50, DOI 10.1109/MM.2018.043191125
   Lu W, 2016, P IEEE INT S HIGH PE
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luebke D, 2008, I S BIOMED IMAGING, P836, DOI 10.1109/ISBI.2008.4541126
   Luo LJ, 2010, DES AUT CON, P52
   Mahajan D, 2016, P IEEE INT S HIGH PE
   Minsky M., 1969, PERCEPTRONS INTRO CO
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Narasiman V, 2011, INT SYMP MICROARCH, P308, DOI 10.1145/2155620.2155656
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Nowatzki T, 2016, INT S HIGH PERF COMP, P27, DOI 10.1109/HPCA.2016.7446051
   Olsen E., 2017, ARXIV170603251
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Park H, 2018, ARXIV181207517V2
   Park J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P367, DOI 10.1145/3123939.3123979
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Prasad K, 2001, CONF REC ASILOMAR C, P129, DOI 10.1109/ACSSC.2001.986892
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Raj A Albert, 2008, VLSI DES
   Rao MJ, 2012, 2012 ASIA PACIFIC CONFERENCE ON POSTGRADUATE RESEARCH IN MICROELECTRONICS & ELECTRONICS (PRIMEASIA), P220, DOI 10.1109/PrimeAsia.2012.6458658
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sriram V, 2010, P 2010 INT C FIELD P
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tractica, 2018, DEEP LEARN INT ENT A
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Vinoth C, 2011, P EL COMP TECHN KAN
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zhang B, 2010, OPT EXPRESS, V18, P20201, DOI 10.1364/OE.18.020201
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhao R, 2017, P INT S FIELD PROGR
NR 93
TC 2
Z9 2
U1 1
U2 3
PY 2021
VL 122
BP 51
EP 95
DI 10.1016/bs.adcom.2020.11.005
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Shahshahani, M
   Bhatia, D
AF Shahshahani, Masoud
   Bhatia, Dinesh
GP IEEE Comp Soc
TI Resource and Performance Estimation for CNN Models using Machine
   Learning
SO 2021 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2021)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 20th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 07-09, 2017-2021
CL ELECTR NETWORK
DE Field Programmable Gate Arrays; Deep Neural Networks; High Level
   Synthesis; Performance Estimation
ID NETWORKS
AB Field-Programmable Gate Array (FPGA) based hardware accelerators offer reconfigurability, performance, adaptability, and good energy efficiency. The majority of Convolutional Neural Network (CNN) based inference systems are initially developed using standardized frameworks like PyTorch, Tensor Flow, and more. These Python or Python-like models can be mapped on FPGAs to build accelerators. Mapping frameworks to port designs on an FPGA convert the CNN models to high-level languages like C/C++ or OpenCL so that standard tools like high-level synthesis can facilitate the mapping of models on an FPGA. The logic utilization and performance of FPGA-based accelerators are dependent on the CNN network parameters, architectural selection (data-flow, pipelined, etc.), and synthesis-based control of design generation. A scalable multi-layer CNN hardware accelerator is modeled in Vitis 2020 HLS tool. Early estimation of performance and hardware resources helps choose the best CNN network before those are executed for time-consuming high-level synthesis and physical design mapping for FPGAs. We present various Machine Learning (ML) models to estimate the Logic Utilization and Computation Time from the Python design descriptions of CNNs. Our results show a very successful and accurate estimation for performance and resource utilization over various multi-layer CNN networks in negligible time before running HLS synthesis.
C1 [Shahshahani, Masoud; Bhatia, Dinesh] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
RP Shahshahani, M (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
EM masoud.shahshahani@utdallas.edu; dinesh@utdallas.edu
CR Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   Meeuws R., 2011, 2011 International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS XI), P140, DOI 10.1109/SAMOS.2011.6045455
   Shahshahani M, 2020, PROCEEDINGS OF THE 2020 IEEE DALLAS CIRCUITS AND SYSTEMS CONFERENCE (DCAS 2020), DOI 10.1109/DCAS51144.2020.9330667
   Shahshahani M, 2021, I CONF VLSI DESIGN, P322, DOI 10.1109/VLSID51830.2021.00060
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shea C, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3358699
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   VENIERIS SI, 2017, I C FIELD PROG LOGIC, DOI DOI 10.23919/FPL.2017.8056828
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
   Ye H., 2020, HYBRIDDNN FRAMEWORK
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhao JR, 2017, ICCAD-IEEE ACM INT, P430, DOI 10.1109/ICCAD.2017.8203809
NR 17
TC 4
Z9 4
U1 2
U2 3
PY 2021
BP 43
EP 48
DI 10.1109/ISVLSI51109.2021.00019
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Nannarelli, A
AF Nannarelli, Alberto
GP IEEE
TI Tunable Floating-Point for Energy Efficient Accelerators
SO 2018 IEEE 25TH SYMPOSIUM ON COMPUTER ARITHMETIC (ARITH)
SE Proceedings Symposium on Computer Arithmetic
DT Proceedings Paper
CT 25th International Symposium on Computer Arithmetic
CY JUN 25-27, 2018
CL Amherst, MA
AB In this work, we address the design of an on-chip accelerator for Machine Learning and other computation-demanding applications with a Tunable Floating-Point (TFP) precision. The precision can be chosen for a single operation by selecting a specific number of bits for significand and exponent in the floating-point representation. By tuning the precision of a given algorithm to the minimum precision achieving an acceptable target error, we can make the computation more power efficient. We focus on floating-point multiplication, which is the most power demanding arithmetic operation.
C1 [Nannarelli, Alberto] Tech Univ, Dept Appl Math & Comp Sci, Kongens Lyngby, Denmark.
RP Nannarelli, A (corresponding author), Tech Univ, Dept Appl Math & Comp Sci, Kongens Lyngby, Denmark.
EM alna@dtu.dk
CR [Anonymous], 2008, 754 IEEE
   Burgess N, 2007, P S COMP ARITHM, P87, DOI 10.1109/ARITH.2007.15
   Catanzaro  B., 2016, 23 IEEE S COMP AR JU
   Ercegovac M.D., 2004, DIGITAL ARITHMETIC
   Nannarelli A, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P351, DOI 10.1109/SOCC.2017.8226076
   Nurvitadhi E., 2017, P ACM FPGA 17 FEB
   Schwarz EM, 1997, P S COMP ARITHM, P2, DOI 10.1109/ARITH.1997.614873
NR 7
TC 7
Z9 7
U1 0
U2 2
PY 2018
BP 29
EP 36
WC Computer Science, Interdisciplinary Applications
DA 2023-11-11
ER

PT J
AU Teodorovic, P
   Struharik, R
AF Teodorovic, Predrag
   Struharik, Rastislav
TI Hardware Acceleration of Sparse Oblique Decision Trees for Edge
   Computing
SO ELEKTRONIKA IR ELEKTROTECHNIKA
DT Article
DE Decision trees; Hardware accelerator architectures; Genetic algorithms;
   Edge computing
ID IMPLEMENTATION; INDUCTION
AB This paper presents a hardware accelerator for sparse decision trees intended for FPGA applications. To the best of authors' knowledge, this is the first accelerator of this type. Beside the hardware accelerator itself, a novel algorithm for induction of sparse decision trees is also presented. Sparse decision trees can be attractive because they require less memory resources and can be more efficiently processed using specialized hardware compared to traditional oblique decision trees. This can be of significant interest, particularly, in the edge-based applications, where memory and compute resources as well as power consumption are severely constrained. The performance of the proposed sparse decision tree induction algorithm as well as developed hardware accelerator are studied using standard benchmark datasets obtained from the UCI Machine Learning Repository database. The results of the experimental study indicate that the proposed algorithm and hardware accelerator are very favourably compared with some of the existing solutions.
C1 [Teodorovic, Predrag; Struharik, Rastislav] Univ Novi Sad, Fac Tech Sci, Dept Power Elect & Telecommun Engn, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
RP Teodorovic, P (corresponding author), Univ Novi Sad, Fac Tech Sci, Dept Power Elect & Telecommun Engn, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
EM t_pedja@uns.ac.rs
CR [Anonymous], 2016, P INT C LEARN REPR
   Barba J, 2015, J SYST ARCHITECT, V61, P185, DOI 10.1016/j.sysarc.2015.01.001
   Barros RC, 2012, IEEE T SYST MAN CY C, V42, P291, DOI 10.1109/TSMCC.2011.2157494
   Bermak A, 2003, IEEE T NEURAL NETWOR, V14, P1097, DOI 10.1109/TNN.2003.816362
   Blake C.L., UCI REPOSITORY MACHI
   Breiman L., 1984, CLASSIFICATION REGRE, DOI [10.1201/9781315139470-8, DOI 10.1201/9781315139470-8]
   Cantú-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857
   Cha SH, 2009, J PATTERN RECOGNIT R, V4, P1, DOI 10.13176/11.44
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Han S., 2015, P 28 INT C NEUR INF, V1, P1135
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   HEATH D, 1993, IJCAI-93, VOLS 1 AND 2, P1002
   Iandola F. N., 2017, P 5 INT C LEARN REPR
   Islam Md Zahidul, 2012, Data Security and Security Data. 27th British National Conference on Databases, BNCOD 27. Revised Selected Papers, P55, DOI 10.1007/978-3-642-25704-9_7
   Kretowski M, 2004, LECT NOTES ARTIF INT, V3070, P432
   Kretowski M, 2006, LECT NOTES COMPUT SC, V4029, P400, DOI 10.1007/11785231_43
   Levi D, 2000, SECOND NASA/DOD WORKSHOP ON EVOLVABLE HARDWARE, PROCEEDINGS, P17, DOI 10.1109/EH.2000.869338
   Lin X, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P415, DOI 10.1145/3060403.3060416
   López-Chau A, 2013, EXPERT SYST APPL, V40, P6283, DOI 10.1016/j.eswa.2013.05.044
   Lopez-Estrada S., 2006, P 2006 IEEE INT C RE, P1, DOI [10.1109/RECONF.2006.307770, DOI 10.1109/RECONF.2006.307770]
   MAHMOOD AM, 2010, INT J COMPUTER SCI E, V2, P126
   Murthy SK, 1994, J ARTIF INTELL RES, V2, P1, DOI 10.1613/jair.63
   Otero FEB, 2012, APPL SOFT COMPUT, V12, P3615, DOI 10.1016/j.asoc.2012.05.028
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Struharik R, 2014, I S INTELL SYST INFO, P257, DOI 10.1109/SISY.2014.6923596
   Struharik RJR, 2009, IET COMPUT DIGIT TEC, V3, P259, DOI 10.1049/iet-cdt.2008.0055
   Struharik RJR, 2013, J CIRCUIT SYST COMP, V22, DOI 10.1142/S0218126613500321
   Yildiz OT, 2012, COMPUT J, V55, P293, DOI 10.1093/comjnl/bxr020
NR 29
TC 3
Z9 3
U1 0
U2 0
PY 2019
VL 25
IS 5
BP 18
EP 24
DI 10.5755/j01.eie.25.5.24351
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Scheinker, A
   Cropp, F
   Paiagua, S
   Filippetto, D
AF Scheinker, Alexander
   Cropp, Frederick
   Paiagua, Sergio
   Filippetto, Daniele
TI An adaptive approach to machine learning for compact particle
   accelerators
SO SCIENTIFIC REPORTS
DT Article
ID ELECTRON; SYSTEMS; NETWORK; SEEKING; MODEL
AB Machine learning (ML) tools are able to learn relationships between the inputs and outputs of large complex systems directly from data. However, for time-varying systems, the predictive capabilities of ML tools degrade if the systems are no longer accurately represented by the data with which the ML models were trained. For complex systems, re-training is only possible if the changes are slow relative to the rate at which large numbers of new input-output training data can be non-invasively recorded. In this work, we present an approach to deep learning for time-varying systems that does not require re-training, but uses instead an adaptive feedback in the architecture of deep convolutional neural networks (CNN). The feedback is based only on available system output measurements and is applied in the encoded low-dimensional dense layers of the encoder-decoder CNNs. First, we develop an inverse model of a complex accelerator system to map output beam measurements to input beam distributions, while both the accelerator components and the unknown input beam distribution vary rapidly with time. We then demonstrate our method on experimental measurements of the input and output beam distributions of the HiRES ultra-fast electron diffraction (UED) beam line at Lawrence Berkeley National Laboratory, and showcase its ability for automatic tracking of the time varying photocathode quantum efficiency map. Our method can be successfully used to aid both physics and ML-based surrogate online models to provide non-invasive beam diagnostics.
C1 [Scheinker, Alexander] Los Alamos Natl Lab, Appl Electrodynam Grp, Los Alamos, NM 87545 USA.
   [Cropp, Frederick] Univ Calif Los Angeles, Dept Phys & Astron, Los Angeles, CA 90095 USA.
   [Cropp, Frederick; Paiagua, Sergio; Filippetto, Daniele] Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.
RP Scheinker, A (corresponding author), Los Alamos Natl Lab, Appl Electrodynam Grp, Los Alamos, NM 87545 USA.
EM ascheink@lanl.gov
CR [Anonymous], 2013, CLASSICAL THEORY FIE
   [Anonymous], 2019, NEURIPS MACHINE LEAR
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Astrom K., 1995, ADAPTIVE CONTROL
   Berecibar M, 2019, NATURE, V568, P325, DOI 10.1038/d41586-019-01138-1
   Brynes AD, 2018, NEW J PHYS, V20, DOI 10.1088/1367-2630/aad21d
   Bulgarevich DS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20438-6
   Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2
   Carrasquilla J, 2017, NAT PHYS, V13, P431, DOI [10.1038/nphys4035, 10.1038/NPHYS4035]
   Cichos F, 2020, NAT MACH INTELL, V2, P94, DOI 10.1038/s42256-020-0146-9
   Decking W, 2020, NAT PHOTONICS, V14, P391, DOI 10.1038/s41566-020-0607-z
   Doho H, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00076
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Filippetto D, 2016, J PHYS B-AT MOL OPT, V49, DOI 10.1088/0953-4075/49/10/104003
   Fol E, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-021-01348-5
   Fol E., 2019, P 2019 INT PART ACC
   Fol E., 2019, P 10 INT PART ACC C, V2668
   Hanuka A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82473-0
   Hao Y., 2019, ARXIV PREPRINT ARXIV
   Ibrahim MM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82886-x
   Ibrahim MM, 2019, IEEE ACCESS, V7, P57894, DOI 10.1109/ACCESS.2019.2913872
   Irwin J, 1999, PHYS REV LETT, V82, P1684, DOI 10.1103/PhysRevLett.82.1684
   Ji F, 2019, COMMUN PHYS-UK, V2, DOI 10.1038/s42005-019-0154-4
   Lansford JL, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15340-7
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Lemery F, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.044801
   Li SZ, 2019, PHYS REV B, V100, DOI 10.1103/PhysRevB.100.020302
   Li YJ, 2019, PR MACH LEARN RES, V97
   Malyzhenkov A, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.042018
   Miller D, 2019, ADV ASTRONAUT SCI, V168, P1817
   Miller D, 2018, 2018 IEEE 20TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM)
   Muscoloni A, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01825-5
   Musumeci P, 2020, NAT PHOTONICS, V14, P199, DOI 10.1038/s41566-020-0613-1
   Nobukawa S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48950-3
   Nobukawa S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41535-0
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pilania G, 2016, SCI REP-UK, V6, DOI 10.1038/srep19375
   Qi D, 2020, P NATL ACAD SCI USA, V117, P52, DOI 10.1073/pnas.1917285117
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Ragno R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59553-8
   Ren X, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.040701
   Rrapaj E, 2021, PHYS REV E, V103, DOI 10.1103/PhysRevE.103.013302
   Scheinker A., 2013, P 2013 INT PART ACC, P1862
   Scheinker A, 2020, J APPL PHYS, V128, DOI 10.1063/5.0014725
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2018, INT J ROBUST NONLIN, V28, P568, DOI 10.1002/rnc.3886
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Scheinker A, 2013, IEEE T AUTOMAT CONTR, V58, P1107, DOI 10.1109/TAC.2012.2225514
   Scheinker D, 2020, INFORMS J APPL ANAL, V50, P176, DOI 10.1287/inte.2020.1036
   Shen YF, 2019, ACTA MATER, V170, P118, DOI 10.1016/j.actamat.2019.03.026
   Tkatchenko A, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17844-8
   Turner M, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.054801
   van der Geer SB, 2005, INST PHYS CONF SER, V175, P101
   van Oudheusden T, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.264801
   Wan J., ARXIV PREPRINT ARXIV
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Ward A, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00331-1
   Yang J, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.153002
   Yang X, 2021, J APPL PHYS, V129, DOI 10.1063/5.0036619
   Yang X, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73168-z
   Yang X, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39208-z
   Zhu J, 2021, PHYS REV APPL, V16, DOI 10.1103/PhysRevApplied.16.024005
   Zibar D, 2017, NAT PHOTONICS, V11, P749, DOI 10.1038/s41566-017-0058-3
NR 65
TC 7
Z9 7
U1 5
U2 10
PD SEP 28
PY 2021
VL 11
IS 1
AR 19187
DI 10.1038/s41598-021-98785-0
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Christoph, G
   Adrian, F
   Tobias, H
   Bernardo, PP
   Lubeck, K
   Oliver, B
AF Christoph, Gerum
   Adrian, Frischknecht
   Tobias, Hald
   Bernardo, Paul Palomero
   Lubeck, Konstantin
   Oliver, Bringmann
BE Fabelo, H
   Ortega, S
   Skavhaug, A
TI Hardware Accelerator and Neural Network Co-Optimization for
   Ultra-Low-Power Audio Processing Devices
SO 2022 25TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD)
SE EUROMICRO Conference Proceedings
DT Proceedings Paper
CT 25th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2022
CL Maspalomas, SPAIN
DE Machine Learning; Neural Networks; AutoML; Neural Architecture Search
AB The increasing spread of artificial neural networks does not stop at ultralow-power edge devices. However, these very often have high computational demand and require specialized hardware accelerators to ensure the design meets power and performance constraints. The manual optimization of neural networks along with the corresponding hardware accelerators can be very challenging. This paper presents HANNAH (Hardware Accelerator and Neural Network seArcH), a framework for automated and combined hardware/software co-design of deep neural networks and hardware accelerators for resource and power-constrained edge devices. The optimization approach uses an evolution-based search algorithm, a neural network template technique and analytical KPI models for the configurable UltraTrail hardware accelerator template in order to find an optimized neural network and accelerator configuration. We demonstrate that HANNAH can find suitable neural networks with minimized power consumption and high accuracy for different audio classification tasks such as single-class wake word detection, multi-class keyword detection and voice activity detection, which are superior to the related work.
C1 [Christoph, Gerum; Adrian, Frischknecht; Tobias, Hald; Bernardo, Paul Palomero; Lubeck, Konstantin; Oliver, Bringmann] Univ Tubingen, Dept Comp Sci, Tubingen, Germany.
RP Christoph, G (corresponding author), Univ Tubingen, Dept Comp Sci, Tubingen, Germany.
EM christoph.gerum@uni-tuebingen.de; adrian.frischknecht@uni-tuebingen.de;
   tobias.hald@student.uni-tuebingen.de;
   paul.palomero-bernardo@uni-uiebingen.de;
   konstantin.luebeck@uni-tuebingen.de; oliver.bringmann@uni-tuebingen.de
NR 0
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 365
EP 369
DI 10.1109/DSD57027.2022.00056
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT C
AU Shen, YM
   Ferdman, M
   Milder, P
AF Shen, Yongming
   Ferdman, Michael
   Milder, Peter
GP IEEE
TI Escher: A CNN Accelerator with Flexible Buffering to Minimize Off-Chip
   Transfer
SO 2017 IEEE 25TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2017)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 25th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY APR 30-MAY 02, 2017
CL Napa, CA
AB Convolutional neural networks (CNNs) are used to solve many challenging machine learning problems. Interest in CNNs has led to the design of CNN accelerators to improve CNN evaluation throughput and efficiency. Importantly, the bandwidth demand from weight data transfer for modern large CNNs causes CNN accelerators to be severely bandwidth bottlenecked, prompting the need for processing images in batches to increase weight reuse. However, existing CNN accelerator designs limit the choice of batch sizes and lack support for batch processing of convolutional layers.
   We observe that, for a given storage budget, choosing the best batch size requires balancing the input and weight transfer. We propose Escher, a CNN accelerator with a flexible data buffering scheme that ensures a balance between the input and weight transfer bandwidth, significantly reducing overall bandwidth requirements. For example, compared to the state-of-the-art CNN accelerator designs targeting a Virtex-7 690T FPGA, Escher reduces the accelerator peak bandwidth requirements by 2.4x across both fully-connected and convolutional layers on fixed-point AlexNet, and reduces convolutional layer bandwidth by up to 10.5x on fixed-point GoogleNet.
C1 [Shen, Yongming; Ferdman, Michael; Milder, Peter] SUNY Stony Brook, Stony Brook, NY 11794 USA.
RP Shen, YM (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
EM yoshen@cs.stonybrook.edu; mferdman@cs.stonybrook.edu;
   peter.milder@stonybrook.edu
CR Abadi M., 2016, ARXIV160304467
   ALWANI M, 2016, 49 IEEE ACM INT S MI
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 23 INT S FIELD PROGR
   [Anonymous], 2008, 25 INT C MACH LEARN
   [Anonymous], P 22 ACM INT C MULTI
   CHAKRADHAR S, 2010, 37 INT S COMP ARCH
   CHEN T, 2014, 19 INT C ARCH SUPP P
   Chen Y., 2014, 47 IEEE ACM INT S MI
   CHEN YH, 2016, 43 INT S COMP ARCH
   DU Z, 2015, 42 INT S COMP ARCH
   Farabet C., 2010, INT S CIRC SYST
   FARABET C, 2009, 19 INT C FIELD PROGR
   Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053
   HAN S, 2016, 43 INT S COMP ARCH
   Han S., 2015, CORR, V2
   Krizhevsky A., 2012, NEURIPS
   LI H, 2016, 26 INT C FIELD PROGR
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   PEEMEN M, 2013, 31 INT C COMP DES
   QADEER W, 2013, 40 INT S COMP ARCH
   QIU J, 2016, 24 INT S FIELD PROGR
   SANKARADAS M, 2009, 20 APPL SPECIFIC SYS
   SHEN Y, 2017, 44 INT S COMP ARCH
   SHEN Y, 2016, 26 INT C FIELD PROGR
   SONG L, 2016, 53 DES AUT C
   SZEGEDY C, 28 C COMP VIS PATT R
   VANDENOORD A, 2013, 27 C NEUR INF PROC S
   ZHANG C, 35 INT C COMP AID DE
   Zisserman A., 2014, 14091556 ARXIV
NR 30
TC 50
Z9 56
U1 2
U2 9
PY 2017
BP 93
EP 100
DI 10.1109/FCCM.2017.47
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Kao, SC
   Kwon, H
   Pellauer, M
   Parashar, A
   Krishna, T
AF Kao, Sheng-Chun
   Kwon, Hyoukjun
   Pellauer, Michael
   Parashar, Angshuman
   Krishna, Tushar
TI A Formalism of DNN Accelerator Flexibility
SO PROCEEDINGS OF THE ACM ON MEASUREMENT AND ANALYSIS OF COMPUTING SYSTEMS
DT Article; Proceedings Paper
CT ACM SIGMETRICS/Performance conference
CY JUN 06-10, 2022
CL Mumbai, INDIA
DE Accelerator; Hardware Flexibility; DNN Workloads
AB The high efficiency of domain-specific hardware accelerators for machine learning (ML) has come from specialization, with the trade-off of less configurability/ flexibility. There is growing interest in developing flexible ML accelerators to make them future-proof to the rapid evolution of Deep Neural Networks (DNNs). However, the notion of accelerator flexibility has always been used in an informal manner, restricting computer architects from conducting systematic apples-to-apples design-space exploration (DSE) across trillions of choices. In this work, we formally define accelerator flexibility and show how it can be integrated for DSE.
   Specifically, we capture DNN accelerator flexibility across four axes: tiling, ordering, parallelization, and array shape. We categorize existing accelerators into 16 classes based on their axes of flexibility support, and define a precise quantification of the degree of flexibility of an accelerator across each axis. We leverage these to develop a novel flexibility-aware DSE framework. We demonstrate how this can be used to perform first-of-their-kind evaluations, including an isolation study to identify the individual impact of the flexibility axes. We demonstrate that adding flexibility features to a hypothetical DNN accelerator designed in 2014 improves runtime on future (i.e., present-day) DNNs by 11.8x geomean.
C1 [Kao, Sheng-Chun; Kwon, Hyoukjun; Krishna, Tushar] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Pellauer, Michael; Parashar, Angshuman] NVIDIA, Santa Clara, CA USA.
RP Kao, SC (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM felix@gatech.edu; hyoukjun@gatech.edu; mpellauer@nvidia.com;
   aparashar@nvidia.com; tushar@ece.gatech.edu
CR Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2021, CUDA C PROGRAMMING G
   Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081
   Berger J, 2014, PHILOS PSYCHOL, V27, P829, DOI 10.1080/09515089.2013.771241
   Chatarasi P, 2020, Arxiv, DOI arXiv:2002.07752
   Chen M, 2020, PR MACH LEARN RES, V119
   Chen TQ, 2018, ADV NEUR IN, V31
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   eda, 2019, FREEPDK15 CONTENTS
   Fedus W, 2022, Arxiv, DOI [arXiv:2101.03961, 10.48550/ARXIV.2101.03961]
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Ghodrati S, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P681, DOI 10.1109/MICRO50266.2020.00062
   github, US
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hegde Kartik, MIND MAPPINGS ENABLI
   Huang Qijing, 2021, ARXIV
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Naumov Maxim, 2019, ARXIV
   Naumov Maxim, 2019, ABS190600091 CORR
   NVIDIA, 2017, NVDLA DEEP LEARN ACC
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Pellauer M, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P137, DOI 10.1145/3297858.3304025
   Putic M, 2018, DES AUT CON, DOI 10.1145/3195970.3196033
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Winograd Shmuel, 1980, SOC IND APPL MATH, P71, DOI DOI 10.1137/1.9781611970364
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhang YQ, 2021, CONF PROC INT SYMP C, P1041, DOI 10.1109/ISCA52012.2021.00085
NR 45
TC 0
Z9 0
U1 1
U2 1
PD JUN
PY 2022
VL 6
IS 2
AR 41
DI 10.1145/3530907
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Kochkov, D
   Smith, JA
   Alieva, A
   Wang, Q
   Brenner, MP
   Hoyer, S
AF Kochkov, Dmitrii
   Smith, Jamie A.
   Alieva, Ayya
   Wang, Qing
   Brenner, Michael P.
   Hoyer, Stephan
TI Machine learning-accelerated computational fluid dynamics
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
DT Article
DE machine learning; turbulence; computational physics; nonlinear partial
   differential equations
ID LARGE-EDDY SIMULATION
AB Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics, and plasma physics. Fluids are well described by the Navier- Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable tradeoffs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10x finer resolution in each spatial dimension, resulting in 40- to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization.
C1 [Kochkov, Dmitrii; Smith, Jamie A.; Alieva, Ayya; Wang, Qing; Brenner, Michael P.; Hoyer, Stephan] Google Res, Mountain View, CA 94043 USA.
   [Brenner, Michael P.] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
RP Kochkov, D; Smith, JA; Brenner, MP; Hoyer, S (corresponding author), Google Res, Mountain View, CA 94043 USA.; Brenner, MP (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
EM dkochkov@google.com; jamieas@google.com; brenner@seas.harvard.edu;
   shoyer@google.com
CR Alfonsi G, 2009, APPL MECH REV, V62, DOI 10.1115/1.3124648
   Anderson J., 2009, COMPUTATIONAL FLUID, V3rd ed., P3, DOI 10.1007/978-3-540-85056-4_1
   [Anonymous], 2018, ABS180601261 CORR
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   [Anonymous], 2007, WEATHER PREDICTION N
   Arroyo C. P., 2019, P GLOB POW PROP SOC
   Bakhshaii A, 2019, CAN J FOREST RES, V49, P565, DOI 10.1139/cjfr-2018-0138
   Bar-Sinai Y, 2019, P NATL ACAD SCI USA, V116, P15344, DOI 10.1073/pnas.1814058116
   Bauer P, 2015, NATURE, V525, P47, DOI 10.1038/nature14956
   Beck A, 2019, J COMPUT PHYS, V398, DOI 10.1016/j.jcp.2019.108910
   Ben-Haim Z., 2019, INUNDATION MODELING
   Bhattacharya Kaushik, 2020, MODEL REDUCTION NEUR
   Boffetta G, 2012, ANNU REV FLUID MECH, V44, P427, DOI 10.1146/annurev-fluid-120710-101240
   Boussinesq J., 1877, MEMOIRES LACADEMIE S, V23, P46
   Bradbury J., JAX COMPOSABLE TRANS
   Chandler GJ, 2013, J FLUID MECH, V722, P554, DOI 10.1017/jfm.2013.122
   Duraisamy K., 2020, PERSPECTIVES MACHINE
   Duraisamy K, 2019, ANNU REV FLUID MECH, V51, P357, DOI 10.1146/annurev-fluid-010518-040547
   Erichson N.B., 2019, PHYS INFORMED AUTOEN
   Esclapez L, 2017, COMBUST FLAME, V181, P82, DOI 10.1016/j.combustflame.2017.02.035
   Frisch U., 1995, TURBULENCE LEGACY AN
   Griewank A, 1994, OPTIM METHODS SOFTWA, V1, P35
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P59, DOI 10.1111/cgf.13619
   Klotz D., 2021, MC LSTM MASS CONSERV
   Kolmogoroff A, 1941, CR ACAD SCI URSS, V30, P301, DOI 10.1098/rspa.1991.0075
   KRAICHNAN RH, 1980, REP PROG PHYS, V43, P547, DOI 10.1088/0034-4885/43/5/001
   Lesieur M, 1996, ANNU REV FLUID MECH, V28, P45
   Li L, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.036401
   Li Z., 2020, NEURAL OPERATOR GRAP
   Ling J, 2016, J FLUID MECH, V807, P155, DOI 10.1017/jfm.2016.615
   Lu T., 2020, LARGE SCALE DISCRETE
   Lusch B, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07210-0
   Malé Q, 2019, FLOW TURBUL COMBUST, V103, P465, DOI 10.1007/s10494-019-00026-y
   Maulik R, 2019, J FLUID MECH, V858, P122, DOI 10.1017/jfm.2018.770
   Meneveau C, 2000, ANNU REV FLUID MECH, V32, P1, DOI 10.1146/annurev.fluid.32.1.1
   Moser R. D., 2020, ANNU REV FLUID MECH, V53
   Neumann P, 2019, PHILOS T R SOC A, V377, DOI 10.1098/rsta.2018.0148
   Nguyen T., 2020, ADV NEURAL INFORM PR, V33, P1924
   Obiols-Sales O., 2020, 34 ACM INT C SUP ACM
   Pathak J, 2020, USING MACHINE LEARNI
   Pope S.B., 2000, TURBUL FLOWS
   Pope SB, 2004, NEW J PHYS, V6, DOI 10.1088/1367-2630/6/1/035
   Sanchez-Gonzalez A., 2020, 37 INT C MACH LEARN
   Schneider T, 2017, NAT CLIM CHANGE, V7, P3, DOI 10.1038/nclimate3190
   Schoenholz S. S., 2020, ADV NEURAL INFORM PR, V33, P11428
   Sirignano J, 2020, J COMPUT PHYS, V423, DOI 10.1016/j.jcp.2020.109811
   Smagorinsky J.S., 1963, MON WEATHER REV, V91, P99, DOI [10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2, DOI 10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2, 10.1175/1520-0493(1963)091andlt;0099:GCEWTPandgt;2.3.CO;2, DOI 10.1175/1520-0493(1963)0912.3.CO;2]
   Tang WM, 2005, PLASMA PHYS CONTR F, V47, pR1, DOI 10.1088/0741-3335/47/2/R01
   Tompson J., 2017, 34 INT C MACH LEARN
   Um K., 2020, ADV NEURAL INFORM PR, V33, P6111
   Wang R, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1457, DOI 10.1145/3394486.3403198
   Wolf P, 2012, COMBUST FLAME, V159, P3398, DOI 10.1016/j.combustflame.2012.06.016
   Yang KZ, 2019, IEEE INT CONF COMM, DOI 10.1109/iccw.2019.8756884
   Zhuang J., PHYS REV FLUID
NR 54
TC 212
Z9 218
U1 55
U2 243
PD MAY 25
PY 2021
VL 118
IS 21
AR e2101784118
DI 10.1073/pnas.2101784118
WC Multidisciplinary Sciences
HC Y
HP N
DA 2023-11-11
ER

PT C
AU Penny, W
   Palomino, D
   Porto, M
   Zatt, B
AF Penny, Wagner
   Palomino, Daniel
   Porto, Marcelo
   Zatt, Bruno
GP IEEE
TI Power/QoS-Adaptive HEVC FME Hardware using Machine Learning-Based
   Approximation Control
SO 2020 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE
   PROCESSING (VCIP)
SE IEEE International Conference on Visual Communications and Image
   Processing
DT Proceedings Paper
CT IEEE International Conference on Visual Communications and Image
   Processing (VCIP)
CY DEC 01-04, 2020
CL ELECTR NETWORK
DE machine learning; decision trees; approximate computing; Fractional
   Motion Estimation; HEVC
AB This paper presents a machine learning-based adaptive approximate hardware design targeting the fractional motion estimation (FME) of HEVC encoder. Hardware designs targeting multiple levels of approximation are proposed, by changing FME filters coefficients and/or discarding taps. The level of approximation is defined by a decision tree, generated taking into account the behavior of several parameters of the encoding in order to predict homogeneous blocks, more suitable for more aggressive approximation without significant losses on quality of service (QoS). Instead of applying a specific level of approximation over the full video, different approximate FME accelerators are dynamically selected. Such a strategy is able to provide up to 50.54% of power reduction while keeping the QoS losses at 1.18% BD-BR.
C1 [Penny, Wagner; Palomino, Daniel; Porto, Marcelo; Zatt, Bruno] Fed Univ Pelotas UFPel, Video Technol Res Grp ViTech, Grad Program Comp PPGC, Pelotas, RS, Brazil.
   [Penny, Wagner] Sul Rio Grandense Fed Inst, Pelotas, RS, Brazil.
RP Penny, W (corresponding author), Fed Univ Pelotas UFPel, Video Technol Res Grp ViTech, Grad Program Comp PPGC, Pelotas, RS, Brazil.; Penny, W (corresponding author), Sul Rio Grandense Fed Inst, Pelotas, RS, Brazil.
CR [Anonymous], 2013, ISOIECJCT1SC29WG11
   Bai H., 2014, IEEE TCSVT
   Bjontegaard G., 2008, ITU T SG16 Q, P35
   Bossen Frank, 2011, JOINT COLLABORATIVE
   Cassa MB, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P493, DOI 10.1109/PCS.2012.6213262
   Chen Y., 2008, P IEEE
   Cisco, 2020, FOR METH 2018 2023
   Grellert M., 2016, PCS
   Hall Mark, 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278
   He G., 2015, IEEE TVLSI
   Lu Y., 2020, IEEE ACCESS
   Maung HM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P286, DOI 10.1109/ICDSP.2016.7868563
   Penny W, 2018, JRTIP
   Podder P., 2015, NEUROCOMPUTING
   Purnachand N., 2012, IEEE ICCE
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Silva R., 2019, SBCCI
   Statista, 2020, COR IMP ONL TRAFF SE
   Vanne J., 2012, IEEE TCSVT
   Venkataramani S., 2015, DATE
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2020
BP 78
EP 81
DI 10.1109/vcip49819.2020.9301797
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Imaging Science & Photographic Technology; Telecommunications
DA 2023-11-11
ER

PT J
AU Radaideh, MI
   Pappas, C
   Cousineau, S
AF Radaideh, Majdi I.
   Pappas, Chris
   Cousineau, Sarah
TI Real electronic signal data from particle accelerator power systems for
   machine learning anomaly detection
SO DATA IN BRIEF
DT Article; Data Paper
DE Machine Learning; High voltage converter modulators; Digital signal
   processing; Anomaly detection; Spallation neutron source; Fault
   classification
AB This article describes real time series datasets collected from the high voltage converter modulators (HVCM) of the Spallation Neutron Source facility. HVCMs are used to power the linear accelerator klystrons, which in turn produce the highpower radio frequency to accelerate the negative hydrogen ions (H -). Waveform signals have been collected from the operation of more than 15 HVCM systems categorized into four major subsystems during the years 2020-2022. The data collection process occurred in the Spallation Neutron Source facility of Oak Ridge, Tennessee in the United States. For each of the four subsystems, there are two datasets. The first one contains the waveform signals, while the second contains the label of the waveform, whether it has a normal or faulty signal. A variety of waveforms are included in the datasets including insulated-gate bipolar transistor (IGBT) currents in three phases, magnetic flux in the three phases, modulator current and voltage, cap bank current and voltage, and time derivative change of the modulator voltage. The datasets provided are useful to test and develop machine learning and statistical algorithms for applications related to anomaly detection, system fault detection and classification, and signal processing.
C1 [Radaideh, Majdi I.; Pappas, Chris; Cousineau, Sarah] Oak Ridge Natl Lab, Spallat Neutron Source, Oak Ridge, TN 37830 USA.
RP Radaideh, MI (corresponding author), Oak Ridge Natl Lab, Spallat Neutron Source, Oak Ridge, TN 37830 USA.
EM radaidehmi@ornl.gov
CR Mason TE, 2006, PHYSICA B, V385-86, P955, DOI 10.1016/j.physb.2006.05.281
   Pappas G., 2021, PROC IPAC 21 NO 12 I, P4303, DOI [10.18429/JACoW-IPAC2021-THPAB252, DOI 10.18429/JACOW-IPAC2021-THPAB252]
   Radaideh M. I., 2022, DIGIT SIGNAL PROCESS, DOI [10.2139/ssrn.4069225, DOI 10.1016/J.DSP.2022.103704]
   Solley DJ, 2012, IEEE INT POWER MODUL, P362, DOI 10.1109/IPMHVC.2012.6518755
NR 4
TC 3
Z9 3
U1 3
U2 8
PD AUG
PY 2022
VL 43
DI 10.1016/j.dib.2022.108473
EA JUL 2022
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Dinu, IM
   Trandafir, IS
   Alexa, C
AF Dinu, I. -M.
   Trandafir, I. S.
   Alexa, C.
TI A MACHINE LEARNING BASED MUON TRIGGER ALGORITHM FOR AN ASSEMBLY OF
   MICROMEGAS DETECTORS
SO ROMANIAN JOURNAL OF PHYSICS
DT Article
DE Data acquisition; machine learning; FPGA; trigger
AB While the particle detector's precision and the accelerator's luminosity are constantly improving, the trigger and data acquisition systems need to keep up with this pace. Assuming a set-up of eight Micromegas detector planes used for muons detection from high-energy p - p collisions, our data acquisition trigger should be able to identify tracks originated from the interaction point while rejecting both collision and non-collision backgrounds. To identify muon tracks and to determine if they originate from the supposed interaction point, we trained a convolutional neural network using simulated muons. This work aims to study the feasibility of using machine learning models on FPGA for trigger algorithm implementation. Our results show that this approach is suitable and is able to provide a very good precision.
C1 [Dinu, I. -M.; Trandafir, I. S.; Alexa, C.] Horia Hulubei Natl Inst Phys & Nucl Engn, Elementary Particle Phys Dept, Reactorului 30, Magurele 077125, Romania.
   [Dinu, I. -M.; Trandafir, I. S.] Univ Bucharest, Fac Phys, Atomistilor 405, Magurele 077125, Romania.
RP Alexa, C (corresponding author), Horia Hulubei Natl Inst Phys & Nucl Engn, Elementary Particle Phys Dept, Reactorului 30, Magurele 077125, Romania.
EM calin.alexa@nipne.ro
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Agarap A.F., 2018, ARXIV
   Attié D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125362
   Brun R, 1997, NUCL INSTRUM METH A, V389, P81, DOI 10.1016/S0168-9002(97)00048-X
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Giomataris Y, 1996, NUCL INSTRUM METH A, V376, P29, DOI 10.1016/0168-9002(96)00175-1
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang A., QUICK SIMULATION MMT
NR 10
TC 1
Z9 1
U1 0
U2 0
PY 2022
VL 67
IS 7-8
AR 401
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Dikbayir, D
   Çoban, EB
   Kesen, I
   Yuret, D
   Unat, D
AF Dikbayir, Doga
   Coban, Enis Berk
   Kesen, Ilker
   Yuret, Deniz
   Unat, Didem
TI Fast multidimensional reduction and broadcast operations on GPU for
   machine learning
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE broadcast; CUDA; GPU; machine learning; multidimensional arrays;
   reduction; tensor
AB Reduction and broadcast operations are commonly used in machine learning algorithms for different purposes. They widely appear in the calculation of the gradient values of a loss function, which are one of the core structures of neural networks. Both operations are implemented naively in many libraries usually for scalar reduction or broadcast; however, to our knowledge, there are no optimized multidimensional implementations available. This fact limits the performance of machine learning models requiring these operations to be performed on tensors. In this work, we address the problem and propose two new strategies that extend the existing implementations to perform on tensors. We introduce formal definitions of both operations using tensor notations, investigate their mathematical properties, and exploit these properties to provide an efficient solution for each. We implement our parallel strategies and test them on a CUDA enabled Tesla K40m GPU accelerator. Our performant implementations achieve up to 75% of the peak device memory bandwidth on different tensor sizes and dimensions. Significant speedups against the implementations available in the Knet Deep Learning framework are also achieved for both operations.
C1 [Dikbayir, Doga; Coban, Enis Berk; Kesen, Ilker; Yuret, Deniz; Unat, Didem] Koc Univ, Comp Sci & Engn, Istanbul, Turkey.
RP Dikbayir, D (corresponding author), Koc Univ, Comp Sci & Engn, Istanbul, Turkey.
EM ddikbayir17@ku.edu.tr; dunat@ku.edu.tr
CR [Anonymous], 2015, ABS150201852 CORR
   [Anonymous], 2017, WARP SHUFFLE FUNCTIO
   Bezanzon J., 2012, LANG NEXT
   Chapman B., 2007, USING OPENMP PORTABL
   Greenspan H., 2017, DEEP LEARNING MED IM
   Harris M, 2007, 2007 SUP C
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Liu B, 2017, 2017 IEEE INT C CLUS
   Luitijens J, 2014, FASTER PARALLEL REDU
   Makpaisit P, 2015, 2015 15 INT S COMM I
   Neumann AB, 2008, PARALLEL REDUCTION M
   NVIDIA, 2018, NVIDIA K40M ACT BOAR
   Wikipedia , 2017, STRID OF AN ARR
   Wilson G., 2007, BEAUTIFUL CODE LEADI, VFirst
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yuret D., 2016, 30 C NEUR INF PROC S
NR 17
TC 1
Z9 1
U1 1
U2 6
PD NOV 10
PY 2018
VL 30
IS 21
SI SI
AR e4691
DI 10.1002/cpe.4691
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Shukla, S
   Fleischer, B
   Ziegler, M
   Silberman, J
   Oh, J
   Srinivasan, V
   Choi, J
   Mueller, S
   Agrawal, A
   Babinsky, T
   Cao, NZ
   Chen, CY
   Chuang, P
   Fox, T
   Gristede, G
   Guillorn, M
   Haynie, H
   Klaiber, M
   Lee, D
   Lo, SH
   Maier, G
   Scheuermann, M
   Venkataramani, S
   Vezyrtzis, C
   Wang, NG
   Yee, FC
   Zhou, C
   Lu, PF
   Curran, B
   Chang, L
   Gopalakrishnan, K
AF Shukla, Sunil
   Fleischer, Bruce
   Ziegler, Matthew
   Silberman, Joel
   Oh, Jinwook
   Srinivasan, Vijayalakshmi
   Choi, Jungwook
   Mueller, Silvia
   Agrawal, Ankur
   Babinsky, Tina
   Cao, Nianzheng
   Chen, Chia-Yu
   Chuang, Pierce
   Fox, Thomas
   Gristede, George
   Guillorn, Michael
   Haynie, Howard
   Klaiber, Michael
   Lee, Dongsoo
   Lo, Shih-Hsien
   Maier, Gary
   Scheuermann, Michael
   Venkataramani, Swagath
   Vezyrtzis, Christos
   Wang, Naigang
   Yee, Fanchieh
   Zhou, Ching
   Lu, Pong-Fei
   Curran, Brian
   Chang, Leland
   Gopalakrishnan, Kailash
TI A Scalable Multi-TeraOPS Core for AI Training and Inference
SO IEEE SOLID-STATE CIRCUITS LETTERS
DT Article
DE Accelerators; artificial intelligence; dataflow; deep learning (DL);
   machine learning
AB This letter presents a multi-TOPS AI accelerator core for deep learning training and inference. With a programmable architecture and custom ISA, this engine achieves >90% sustained utilization across the range of neural network topologies by employing a dataflow architecture to provide high throughput and an on-chip scratchpad hierarchy to meet the bandwidth demands of the compute units. A custom 16b floating point (fp16) representation with 1 sign bit, 6 exponent bits, and 9 mantissa bits has also been developed for high model accuracy in training and inference as well as 1b/2b (binary/ternary) integer for aggressive inference performance. At 1.5 GHz, the AI core prototype achieves 1.5 TFLOPS fp16, 12 TOPS ternary, or 24 TOPS binary peak performance in 14-nm CMOS.
C1 [Shukla, Sunil; Fleischer, Bruce; Ziegler, Matthew; Silberman, Joel; Oh, Jinwook; Srinivasan, Vijayalakshmi; Choi, Jungwook; Agrawal, Ankur; Cao, Nianzheng; Chen, Chia-Yu; Chuang, Pierce; Fox, Thomas; Gristede, George; Guillorn, Michael; Lee, Dongsoo; Lo, Shih-Hsien; Scheuermann, Michael; Venkataramani, Swagath; Vezyrtzis, Christos; Wang, Naigang; Yee, Fanchieh; Zhou, Ching; Lu, Pong-Fei; Chang, Leland; Gopalakrishnan, Kailash] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Mueller, Silvia; Babinsky, Tina; Klaiber, Michael] IBM Syst Grp, D-71032 Boblingen, Germany.
   [Haynie, Howard; Curran, Brian] IBM Syst Grp, Poughkeepsie, NY 12601 USA.
   [Maier, Gary] IBM Syst Grp, East Fishkill, NY 12533 USA.
RP Shukla, S (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM skshukla@us.ibm.com
CR Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Desoli G, 2017, ISSCC DIG TECH PAP I, P238, DOI 10.1109/ISSCC.2017.7870349
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Knag Phil, 2016, 2016 IEEE Symposium on VLSI Circuits (VLSI-Circuits), DOI 10.1109/VLSIC.2016.7573526
   Venkataramani S, 2017, INT CONFER PARA, P146, DOI 10.1109/PACT.2017.39
   Yin SY, 2017, SYMP VLSI CIRCUITS, pC26, DOI 10.23919/VLSIC.2017.8008534
   Zhu C., 2017, 5 INT C LEARN REPR I
NR 8
TC 21
Z9 21
U1 0
U2 1
PD DEC
PY 2018
VL 1
IS 12
SI SI
BP 217
EP 220
DI 10.1109/LSSC.2019.2902738
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Colangelo, P
   Segal, O
   Speicher, A
   Margala, M
AF Colangelo, Philip
   Segal, Oren
   Speicher, Alex
   Margala, Martin
GP IEEE
TI Artificial Neural Network and Accelerator Co-design using Evolutionary
   Algorithms
SO 2019 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 24-26, 2019
CL Waltham, MA
DE evolutionary algorithm; machine learning; FPGA
AB Multilayer feed-forward Artificial Neural Networks (ANNs) are universal function approximators capable of modeling measurable functions to any desired degree of accuracy. In practice, designing practical, efficient neural network architectures requires significant effort and expertise. Further, designing efficient neural network architectures that fit optimally on hardware for the benefit of acceleration adds yet another degree of complexity. In this paper, we use Evolutionary Cell Aided Design (ECAD), a framework capable of searching the design spaces for ANN structures and reconfigurable hardware to find solutions based on a set of constraints and fitness functions. Providing a modular and scalable 2D systolic array based machine learning accelerator design built for an Arria 10 GX 1150 FPGA device using OpenCL enables results to be tested and deployed in real hardware. Along with the hardware, a software model of the architecture was developed to speed up the evolutionary process. We present results from the ECAD framework showing the effect various optimizations including accuracy, images per second, effective giga-operations per second, and latency have on both ANN and hardware configurations. Through this work we show that unique solutions can exist for each optimization resulting in the best performance. This work lays the foundation for finding machine learning based solutions for a wide range of applications having different system constraints.
C1 [Colangelo, Philip] Intel PSG, San Jose, CA 95134 USA.
   [Segal, Oren; Speicher, Alex] Hofstra Univ, Hempstead, NY 11550 USA.
   [Margala, Martin] Univ Massachusetts, Lowell, MA USA.
RP Colangelo, P (corresponding author), Intel PSG, San Jose, CA 95134 USA.
EM philip.colangelo@intel.com; oren.segal@hofstra.edu;
   aspeicher1@pride.hofstra.edu; Martin_Margala@uml.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2018, INTEL ARRIA10 DEVICE
   [Anonymous], 2018, ARXIV180201548
   [Anonymous], 2018, CORR
   [Anonymous], 1991, F GENETIC ALGORITHMS
   [Anonymous], 2016, P IEEE INT S CIRC SY, DOI DOI 10.48550/ARXIV.1605.07678
   [Anonymous], ABS170103534 CORR
   [Anonymous], ARXIV171100436
   Colangelo Philip, 2018, ABS180611547 CORR
   Gabriel E, 2004, LECT NOTES COMPUT SC, V3241, P97
   Gulli A., 2017, DEEP LEARNING KERAS
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3233231
   Kung H. T., 1979, SPARSE MATRIX P, V1, P256
   MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379
   Nurvitadhi Eriko, 2018, P 2018 ACM SIGDA INT, P287, DOI [10.1145/ 3174243.3174966, DOI 10.1145/3174243.3174966]
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Real E., 2017, LARGE SCALE EVOLUTIO
   Runger G, 2013, PARALLEL PROGRAMMING
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Umuroglu Y., 2016, ABS161207119 CORR
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 27
TC 9
Z9 9
U1 0
U2 0
PY 2019
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Vatsavai, SS
   Thakkar, I
AF Vatsavai, Sairam Sri
   Thakkar, Ishan
GP IEEE
TI Silicon Photonic Microring Based Chip-Scale Accelerator for Delayed
   Feedback Reservoir Computing
SO 2021 34TH INTERNATIONAL CONFERENCE ON VLSI DESIGN AND 2021 20TH
   INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS (VLSID & ES 2021)
SE International Conference on VLSI Design
DT Proceedings Paper
CT 34th International Conference on VLSI Design / 20th International
   Conference on Embedded Systems (VLSID)
CY FEB 20-24, 2021
CL ELECTR NETWORK
ID SYSTEMS
AB To perform temporal and sequential machine learning tasks, the use of conventional Recurrent Neural Networks (RNNs) has been dwindling due to the training complexities of RNNs. To this end, accelerators for delayed feedback reservoir computing (DFRC) have attracted attention in lieu of RNNs, due to their simple hardware implementations. A typical implementation of a DFRC accelerator consists of a delay loop and a single nonlinear neuron, together acting as multiple virtual nodes for computing. In prior work, photonic DFRC accelerators have shown an undisputed advantage of fast computation over their electronic counterparts. In this paper, we propose a more energy-efficient chip-scale DFRC accelerator that employs a silicon photonic microring (MR) based nonlinear neuron along with on-chip photonic waveguides-based delayed feedback loop. Our evaluations show that, compared to a well-known photonic DFRC accelerator from prior work, our proposed MR-based DFRC accelerator achieves 35% and 98.7% lower normalized root mean square error (NRMSE), respectively, for the prediction tasks of NARMAIO and Santa Fe time series. In addition, our MR-based DFRC accelerator achieves 58.8% lower symbol error rate (SER) for the Non-Linear Channel Equalization task Moreover, our MR-based DFRC accelerator has 98x and 938 faster training time, respectively, compared to an electronic and a photonic DFRC accelerators from prior work
C1 [Vatsavai, Sairam Sri; Thakkar, Ishan] Univ Kentucky, Elect & Comp Engn, Lexington, KY 40506 USA.
RP Vatsavai, SS (corresponding author), Univ Kentucky, Elect & Comp Engn, Lexington, KY 40506 USA.
EM sairam_srivatsavai@uky.edu; igthakkar@uky.edu
CR [Anonymous], 2001, ECHO STATE APPROACH
   [Anonymous], 2011, OPT EXPRESS, V19
   [Anonymous], 2002, NEURAL COMPUT
   [Anonymous], 2012, LASER PHOTONICS REV, V6
   Antonik P, 2016, PROC SPIE, V9732, DOI 10.1117/12.2210948
   Appeltant L, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1476
   Appeltant L, 2014, SCI REP-UK, V4, DOI 10.1038/srep03629
   Bahadori M., 2017, DATE
   Benjamin S., 2007, P 15 EUR S ART NEUR, P471
   Denis-LeCoarer F, 2018, IEEE J SEL TOP QUANT, V24, P1, DOI DOI 10.1109/JSTQE.2018.2836985
   Dhang D., 2019, ISQED
   Duport F, 2016, SCI REP-UK, V6, DOI 10.1038/srep22381
   Fiers MAA, 2014, IEEE T NEUR NET LEAR, V25, P344, DOI 10.1109/TNNLS.2013.2274670
   Haffner C, 2015, NAT PHOTONICS, V9, P525, DOI [10.1038/nphoton.2015.127, 10.1038/NPHOTON.2015.127]
   Hammer B., 2002, P ESANN
   Hendry R., 2014, P HIPEAC WORKSH
   Hermans M, 2015, J MACH LEARN RES, V16, P2081
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277
   Jaeger H., 2003, ADV NEURAL INFORM PR, P609
   Kantz H., 2004, NONLINEAR TIME SERIE, V7
   Katumba A, 2017, COGN COMPUT, V9, P307, DOI 10.1007/s12559-017-9465-5
   Li JL, 2018, INT SYM QUAL ELECT, P308, DOI 10.1109/ISQED.2018.8357305
   Luciano P, 2017, IEEE T NUCL SCI, V64, P1374, DOI 10.1109/TNS.2017.2706061
   MANDIC D, 2001, RECURRENT NEURAL NET, DOI 10.1002/047084535X
   Melloni, 2010, IEEE JPHOT
   Mesaritakis Charis, 2013, J OPT SOC AM
   Paquot Y, 2012, SCI REP-UK, V2, DOI 10.1038/srep00287
   Samarasinghe S, 2016, NEURAL NETWORKS APPL, DOI DOI 10.1201/9780849333750
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seyedi M., 2016, OSA CLEO
   Shoman H., 2018, OFC
   Solow Andrew R., 1994, SCIENCE
   Soriano M. C, 2015, FRONTIERS COMPUTATIO, V9
   Sugano C, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2929179
   Thraskias CA, 2018, IEEE COMMUN SURV TUT, V20, P2758, DOI 10.1109/COMST.2018.2839672
   Torrejon J, 2017, NATURE, V547, P428, DOI 10.1038/nature23011
   Urbain G, 2017, FRONT NEUROROBOTICS, V11, P1, DOI 10.3389/fnbot.2017.00016
   Vandoorne K, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4541
   Vandoorne K, 2011, IEEE T NEURAL NETWOR, V22, P1469, DOI 10.1109/TNN.2011.2161771
   Vatin J, 2018, 2018 EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC)
   Verstraeten D, 2007, NEURAL NETWORKS, V20, P391, DOI 10.1016/j.neunet.2007.04.003
NR 41
TC 2
Z9 2
U1 1
U2 4
PY 2021
BP 129
EP 134
DI 10.1109/VLSID51830.2021.00027
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Awais, M
   Platzner, M
AF Awais, Muhammad
   Platzner, Marco
GP IEEE
TI Automated Framework for Fast Synthesis of Approximate Hardware
   Accelerators
SO PROCEEDINGS OF THE 2022 IFIP/IEEE 30TH INTERNATIONAL CONFERENCE ON VERY
   LARGE SCALE INTEGRATION (VLSI-SOC)
DT Proceedings Paper
CT 30th IFIP/IEEE International Conference on Very Large Scale Integration
   (VLSI-SoC)
CY OCT 03-05, 2022
CL Univ Patras, Patras, GREECE
HO Univ Patras
DE Approximate computing; Design Space Exploration; Synthesis; Monte Carlo
   Tree Search
AB Generating approximate accelerators automatically via libraries of functional units faces combinatorial explosion due to extremely large design space. Moreover, long verification times become bottleneck in the process making it nearly impossible to find best suited approximate instances with exhaustive search. Multiple works try to explore the design space with a greedy-based approach that reduces the complexity of the process, albeit overlooking promising combinations and ultimately producing inferior solutions. This paper proposes an automated framework that handles the design space exploration problem with an learning-based search algorithm i.e., MCTS. Furthermore, by leveraging fast machine learning quality estimators, the framework offers up to 47x reduction of runtime when compared to a simulation-based framework.
C1 [Awais, Muhammad] Quaid E Awam Univ, Dept Artificial Intelligence, Nawabshah, Pakistan.
   [Platzner, Marco] Paderborn Univ, Dept Comp Sci, Paderborn, Germany.
RP Awais, M (corresponding author), Quaid E Awam Univ, Dept Artificial Intelligence, Nawabshah, Pakistan.
CR Awais M, 2018, IEEE INT CONF VLSI, P219, DOI 10.1109/VLSI-SoC.2018.8645026
   Barbareschi M, 2016, IEEE 30TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA 2016), P40, DOI 10.1109/WAINA.2016.172
   Browne CB, 2012, IEEE T COMP INTEL AI, V4, P1, DOI 10.1109/TCIAIG.2012.2186810
   Chandrasekharan A, 2016, ICCAD
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Nepal K, 2014, DES AUT TEST EUROPE
   Scarabottolo I, 2018, DES AUT TEST EUROPE, P545, DOI 10.23919/DATE.2018.8342067
   Witschen L, 2019, MICROELECTRON RELIAB, V99, P277, DOI 10.1016/j.microrel.2019.04.003
   Witschen L, 2019, PR GR LAK SYMP VLSI, P153, DOI 10.1145/3299874.3317998
NR 9
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/VLSI-SoC54400.2022.9939606
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Radaideh, MI
   Pappas, C
   Wezensky, M
   Ramuhalli, P
   Cousineau, S
AF Radaideh, Majdi I.
   Pappas, Chris
   Wezensky, Mark
   Ramuhalli, Pradeep
   Cousineau, Sarah
TI Early Fault Detection in Particle Accelerator Power Electronics Using
   Ensemble Learning
SO INTERNATIONAL JOURNAL OF PROGNOSTICS AND HEALTH MANAGEMENT
DT Article
ID PREDICTIVE MAINTENANCE; MACHINE; CLASSIFICATION
AB Early fault detection and fault prognosis are crucial to ensure efficient and safe operations of complex engineering systems such as the Spallation Neutron Source (SNS) and its power electronics (high voltage converter modulators). Following an advanced experimental facility setup that mimics SNS operating conditions, the authors successfully conducted early fault detection experiments, where fault precursors introduced in the system to a degree enough to cause degra-dation in the waveform signals, but not enough to reach a real fault. Nine different machine learning techniques based ensemble trees, convolutional neural networks, support vec-tor machines, and hierarchical voting ensembles are proposed to detect the fault precursors. Although all 9 models have shown a perfect and identical performance during the train-ing and testing phase, the performance of most models decreased in the next test phase once they got exposed to real world data from the 21 experiments. The hierarchical voting ensemble, which features multiple layers of diverse models, maintains a distinguished performance in early detection the fault precursors with 95% success rate (20/21 tests), fol-lowed by adaboost and extremely randomized trees with 52% and 48% success rates, respectively. The support vector ma-chine models were the worst with only 24% success rate (5/21 tests). The study concluded that a successful implementation of machine learning in the SNS or particle accelerator power systems would require a major upgrade in the controller and the data acquisition system to facilitate streaming and han-dling big data for the machine learning models. In addition, this study shows that the best performing models were verse and based on the ensemble concept to reduce the bias and hyperparameter sensitivity of individual models.
C1 [Radaideh, Majdi I.; Pappas, Chris; Wezensky, Mark; Ramuhalli, Pradeep; Cousineau, Sarah] Oak Ridge Natl Lab, Spallat Neutron Source, Oak Ridge, TN 37830 USA.
   [Radaideh, Majdi I.] Univ Michigan, Dept Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA.
RP Radaideh, MI (corresponding author), Oak Ridge Natl Lab, Spallat Neutron Source, Oak Ridge, TN 37830 USA.; Radaideh, MI (corresponding author), Univ Michigan, Dept Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA.
EM radaideh@umich.edu
CR Agasthian A, 2019, NEURAL COMPUT APPL, V31, P1503, DOI 10.1007/s00521-018-3690-z
   [Anonymous], 2014, NUCL INSTRUM METH A, V763, P610, DOI 10.1016/j.nima.2014.03.067
   Arunthavanathan R, 2021, PROCESS SAF ENVIRON, V154, P467, DOI 10.1016/j.psep.2021.08.022
   Belagoune S, 2021, MEASUREMENT, V177, DOI 10.1016/j.measurement.2021.109330
   Blokland W, 2021, Arxiv, DOI arXiv:2110.12006
   Bode G, 2020, ENERGY, V198, DOI 10.1016/j.energy.2020.117323
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bukkapatnam STS, 2019, CIRP ANN-MANUF TECHN, V68, P459, DOI 10.1016/j.cirp.2019.04.104
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Felsberger Lukas, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P139, DOI 10.1007/978-3-030-57321-8_8
   Fernandes M, 2022, APPL INTELL, V52, P14246, DOI 10.1007/s10489-022-03344-3
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Hajji M, 2021, EUR J CONTROL, V59, P313, DOI 10.1016/j.ejcon.2020.03.004
   Kolokas N, 2020, SIMUL MODEL PRACT TH, V103, DOI 10.1016/j.simpat.2020.102109
   Liu CC, 2021, IEEE ACCESS, V9, P49557, DOI 10.1109/ACCESS.2021.3069256
   Luo B, 2019, IEEE T IND ELECTRON, V66, P509, DOI 10.1109/TIE.2018.2807414
   Mohapatra D, 2020, FUSION ENG DES, V151, DOI 10.1016/j.fusengdes.2019.111401
   Amiruddin AAAM, 2020, NEURAL COMPUT APPL, V32, P447, DOI 10.1007/s00521-018-3911-5
   Nguyen D., 1991, ACCELERATION FEEDBAC
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Radaideh MI, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103704
   Radaideh MI, 2022, DATA BRIEF, V43, DOI 10.1016/j.dib.2022.108473
   Rescic M, 2022, NUCL INSTRUM METH A, V1025, DOI 10.1016/j.nima.2021.166064
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Saxena A, 2008, 2008 INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (PHM), P1
   Scheinker A, 2021, INFORMATION, V12, DOI 10.3390/info12040161
   Shao HD, 2017, KNOWL-BASED SYST, V119, P200, DOI 10.1016/j.knosys.2016.12.012
   Syafrudin M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092946
   Taqvi SA, 2020, NEURAL COMPUT APPL, V32, P3503, DOI 10.1007/s00521-018-3658-z
   Vachtsevanos G., 2006, INTELLIGENT FAULT DI
   Vrabic R, 2017, CIRP ANN-MANUF TECHN, V66, P433, DOI 10.1016/j.cirp.2017.04.001
   Wang L, 2017, IEEE T IND INFORM, V13, P1360, DOI 10.1109/TII.2016.2607179
   Wang P, 2021, SUSTAIN ENERGY TECHN, V47, DOI 10.1016/j.seta.2021.101366
   Zhang LW, 2019, IEEE ACCESS, V7, P162415, DOI 10.1109/ACCESS.2019.2950985
   Zhang WT, 2019, IEEE SYST J, V13, P2213, DOI 10.1109/JSYST.2019.2905565
   Zhang Y, 2020, INT J ADV MANUF TECH, V111, P341, DOI 10.1007/s00170-020-06078-z
NR 40
TC 0
Z9 0
U1 3
U2 3
PY 2023
VL 14
IS 1
AR 3419
DI 10.36001/IJPHM.2023.v14i1.3419
WC Engineering, Multidisciplinary; Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Wu, YN
   Emer, JS
   Sze, V
AF Wu, Yannan Nellie
   Emer, Joel S.
   Sze, Vivienne
GP IEEE
TI Accelergy: An Architecture-Level Energy Estimation Methodology for
   Accelerator Designs
SO 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 38th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 04-10, 2019
CL Westminster, CO
AB With Moore's law slowing down and Dennard scaling ended, energy-efficient domain-specific accelerators, such as deep neural network (DNN) processors for machine learning and programmable network switches for cloud applications, have become a promising way for hardware designers to continue bringing energy efficiency improvements to data and computation-intensive applications. To ensure the fast exploration of the accelerator design space, architecture-level energy estimators, which perform energy estimations without requiring complete hardware description of the designs, are critical to designers. However, it is difficult to use existing architecturelevel energy estimators to obtain accurate estimates for accelerator designs, as accelerator designs are diverse and sensitive to data patterns. This paper presents Accelergy, a generally applicable energy estimation methodology for accelerators that allows design specifications comprised of user-defined high-level compound components and user-defined low-level primitive components, which can be characterized by third-party energy estimation plug-ins. An example with primitive and compound components for DNN accelerator designs is also provided as an application of the proposed methodology. Overall, Accelergy achieves 95% accuracy on Eyeriss, a well-known DNN accelerator design, and can correctly capture the energy breakdown of components at different granularities.
C1 [Wu, Yannan Nellie; Sze, Vivienne] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Emer, Joel S.] MIT, NVIDIA, Westford, MA USA.
RP Wu, YN (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM nelliewu@mit.edu; emer@csail.mit.edu; sze@mit.edu
CR Akhlaghi Vahideh, 2018, ISCA
   Brooks D, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P83, DOI [10.1145/342001.339657, 10.1109/ISCA.2000.854380]
   Chen Y., 2017, J SENSORS, V2017, P1, DOI DOI 10.1155/2017/1591504
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Jain R, 2013, IEEE COMMUN MAG, V51, P24, DOI 10.1109/MCOM.2013.6658648
   Jeong K, 2009, 11TH INTERNATIONAL WORKSHOP ON SYSTEM-LEVEL INTERCONNECT PREDICTION (SLIP 09), P3
   Ke L., 2018, ISLPED
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee W, 2015, I SYMPOS LOW POWER E, P189, DOI 10.1109/ISLPED.2015.7273512
   Leng Jingwen, 2013, ISCA
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Parashar Angshuman, 2019, ISPASS
   Pellauer Michael, 2018, ASPLOS
   Shao Yakun Sophia, 2014, ISCA
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Truong Nguyen B., 2015, IM
   Wang Hang-Sheng, 2002, MICRO
   Yang T.-J., 2017, ASILOMAR
NR 22
TC 62
Z9 62
U1 0
U2 3
PY 2019
DI 10.1109/iccad45719.2019.8942149
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ghosh, A
   Al Mahmud, SA
   Uday, TIR
   Farid, DM
AF Ghosh, Amit
   Al Mahmud, Shamsul Arefeen
   Uday, Thajid Ibna Rouf
   Farid, Dewan Md
GP IEEE
TI Assistive Technology for Visually Impaired using Tensor Flow Object
   Detection in Raspberry Pi and Coral USB Accelerator
SO 2020 IEEE REGION 10 SYMPOSIUM (TENSYMP) - TECHNOLOGY FOR IMPACTFUL
   SUSTAINABLE DEVELOPMENT
SE IEEE Region 10 Symposium
DT Proceedings Paper
CT IEEE-Region-10 Symposium (TENSYMP) - Technology for Impactful
   Sustainable Development
CY JUN 05-07, 2020
CL ELECTR NETWORK
DE Assistive Technology; Computer Vision; Object Detection; Tensor Flow;
   Visually Impaired
AB Assistive Technology (AT) becomes an interesting field of research in this present era. According to the World Health Organisation (WHO - https://www.who.int), there are approximately 285 million visually impaired people around the world. To address this issue, many researchers are employing new technologies, e.g. Machine Learning (ML), Computer Vision (CV), Image Processing, etc. This paper aims to develop an assistive technology based on Computer Vision, Machine Learning and Tensor Flow to support visually impaired people. The proposed system will allow the users to navigate independently using real-time object detection and identification. Hardware implementation is done to test the performance of the system, and the performance is tracked using a monitoring server. The system is developed on Raspberry pi 4 and a dedicated server with NVIDIA Titan X graphics where Google coral USB accelerator is used to boost processing power.
C1 [Ghosh, Amit; Farid, Dewan Md] United Int Univ, Dept Comp Sci & Engn, Madani Ave, Dhaka 1212, Bangladesh.
   [Uday, Thajid Ibna Rouf] United Int Univ, Dept Elect & Elect Engn, Madani Ave, Dhaka 1212, Bangladesh.
   [Al Mahmud, Shamsul Arefeen] Aalto Univ, Dept Elect Engn & Automat, Espoo, Finland.
RP Ghosh, A (corresponding author), United Int Univ, Dept Comp Sci & Engn, Madani Ave, Dhaka 1212, Bangladesh.
EM amitbd1508@gmail.com; shamsul.almahmud@aalto.fi;
   tuday121102@bseee.uiu.ac.bd; dewanfarid@cse.uiu.ac.bd
CR Alam I, 2018, INT C EM TECHN DAT M, P1
   Alam I., IEEE TECHN SMART CIT
   Auvray M, 2007, PERCEPTION, V36, P416, DOI 10.1068/p5631
   Babir MRN, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P34, DOI [10.1109/icrest.2019.8644099, 10.1109/ICREST.2019.8644099]
   Bhowmick A, 2017, J MULTIMODAL USER IN, V11, P149, DOI 10.1007/s12193-016-0235-6
   Ghosh A, IEEE REG 10 S TENSYM
   Goel A, INT RES J ENG TECHNO, V5, P1639
   Hersh MA., 2008, TECHNOL DISABIL, V20, P193, DOI [DOI 10.3233/TAD-2008-20303, 10.3233/TAD-2008-20303]
   Leo M, 2017, COMPUT VIS IMAGE UND, V154, P1, DOI 10.1016/j.cviu.2016.09.001
   Rajalakshmi M. R, SMART NAVIGATION SYS
   Ross DA, 2001, IEEE INTELL SYST APP, V16, P47, DOI 10.1109/5254.940026
   SivacBryant S, 2016, PALGR STUD COMPROM, P1, DOI 10.1057/978-1-137-58838-8
   Tapu R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P444, DOI 10.1109/ICCVW.2013.65
   Tham Y.-C, 2018, SCI REP-UK, V8, P1
NR 14
TC 0
Z9 0
U1 0
U2 1
PY 2020
BP 186
EP 189
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Luo, YX
   Tan, C
   Agostini, NB
   Li, A
   Tumeo, A
   Dave, N
   Geng, T
AF Luo, Yixuan
   Tan, Cheng
   Agostini, Nicolas Bohm
   Li, Ang
   Tumeo, Antonin
   Dave, Nirav
   Geng, Tong
GP IEEE
TI ML-CGRA: An Integrated Compilation Framework to Enable Efficient Machine
   Learning Acceleration on CGRAs
SO 2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC
DT Proceedings Paper
CT 60th ACM/IEEE Design Automation Conference (DAC)
CY JUL 09-13, 2023
CL San Francisco, CA
AB Coarse-Grained Reconfigurable Arrays (CGRAs) can achieve higher energy-efficiency than general-purpose processors and accelerators or fine-grained reconfigurable devices, while maintaining adaptability to different computational patterns. CGRAs have shown some success as a platform to accelerate machine learning (ML) thanks to their flexibility, which allows them to support new models not considered by fixed accelerators. However, current solutions for CGRAs employ low level instruction-based compiler approaches and lack specialized compilation infrastructures from high-level ML frameworks that could leverage semantic information from the models, limiting the ability to efficiently map them on the reconfigurable substrate. This paper proposes ML-CGRA, an integrated compilation framework based on the MLIR infrastructure that enables efficient ML acceleration on CGRAs. ML-CGRA provides an end-to-end solution for mapping ML models on CGRAs that outperforms conventional approaches by 3.15x and 6.02 x on 4x4 and 8x8 CGRAs, respectively. The framework is open-source and available from https://github.com/tancheng/mlir-cgra.
C1 [Luo, Yixuan; Geng, Tong] Univ Rochester, Rochester, NY 14627 USA.
   [Agostini, Nicolas Bohm; Li, Ang; Tumeo, Antonin] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
   [Tan, Cheng; Dave, Nirav] Microsoft, Redmond, WA USA.
RP Luo, YX (corresponding author), Univ Rochester, Rochester, NY 14627 USA.
EM yluo37@rochester.edu; cheng.tan@microsoft.com;
   nicolas.agostini@pnnl.gov; ang.li@pnnl.gov; antonino.tumeo@pnnl.gov;
   nirav.dave@microsoft.com; tong.geng@rochester.edu
CR Agostini Nicolas Bohm, 2022, IEEE ACM INT C COMP, P1
   Ahmad S., 2019, 2019 IEEE HOT CHIPS, P1
   Ando K., 2017, CIRCUITS SYSTEMS, V8, P149
   Bae I, 2018, IEEE T COMPUT AID D, V37, P2301, DOI 10.1109/TCAD.2018.2857278
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chin SA, 2017, IEEE INT CONF ASAP, P184, DOI 10.1109/ASAP.2017.7995277
   Developers W. C., WAV COMP
   Dosovitskiy A, 2021, ARXIV
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Fan XT, 2018, IEEE T VLSI SYST, V26, P1098, DOI 10.1109/TVLSI.2018.2797600
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Lee J, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1408
   Liang ML, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P540, DOI 10.1109/APCCAS.2018.8605639
   Martin L, 2020, Arxiv, DOI arXiv:1911.03894
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Rau B. R., 1994, MICRO 94
   Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, DOI 10.48550/ARXIV.1908.10084]
   Tan C, 2022, INT S HIGH PERF COMP, P304, DOI 10.1109/HPCA53966.2022.00030
   Tan C, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1388, DOI 10.23919/DATE51398.2021.9473955
   Tan C, 2020, PR IEEE COMP DESIGN, P381, DOI 10.1109/ICCD50377.2020.00070
   Tanomoto M, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P73, DOI 10.1109/MCSoC.2015.41
   TVM Developers, 2020, VTA DEEP LEARN ACC S
   Wang WH, 2020, Arxiv, DOI arXiv:2002.10957
   Weng J, 2020, ANN I S COM, P268, DOI 10.1109/ISCA45697.2020.00032
   Xiao QC, 2021, CONF PROC INT SYMP C, P1055, DOI 10.1109/ISCA52012.2021.00086
   Ye HC, 2022, INT S HIGH PERF COMP, P741, DOI 10.1109/HPCA53966.2022.00060
   Ye HC, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218684
   Zhang XF, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415609
   Zulberti Luca, 2022, 2022 17th Conference on Ph.D Research in Microelectronics and Electronics (PRIME)., P373, DOI 10.1109/PRIME55000.2022.9816810
NR 29
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/DAC56929.2023.10247873
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Wang, ZX
   Che, BY
   Guo, L
   Du, Y
   Chen, Y
   Zhao, JZ
   He, W
AF Wang, Zixiao
   Che, Biyao
   Guo, Liang
   Du, Yang
   Chen, Ying
   Zhao, Jizhuang
   He, Wei
TI PipeFL: Hardware/Software co-Design of an FPGA Accelerator for Federated
   Learning
SO IEEE ACCESS
DT Article
DE Collaborative work; Field programmable gate arrays; Training data;
   Throughput; Cryptography; Signal processing algorithms; Machine learning
   algorithms; Homomorphic encryption; Data privacy; Federated learning;
   field programmable gate arrays; homomorphic encryption; privacy
   preserving
AB Federated learning has solved the problems of data silos and data fragmentation on the premise of satisfying privacy. However, cryptographic algorithms in federated learning brought significant increase in computational complexity, which limited the speed of model training. In this paper, we propose a hardware/software (HW/SW) co-designed field programmable gate array (FPGA) accelerator for federated learning. Firstly, we analyzed the time consumption of each stage in federated learning and the involved cryptographic algorithms, and found the performance bottleneck. Secondly, a HW/SW co-designed architecture is introduced, which can speed up encryption, decryption and ciphertext-space computation at the same time without reconfiguring FPGA circuit. In the HW part, we proposed a Hardware-aware Montgomery Algorithm (HWMA) which utilized data parallelism and pipeline, and designed an FPGA architecture to decouple data access and computation. In the SW part, an Operator Scheduling Engine (OSE) is designed, which can flexibly resolve the target algorithm into multiple HWMA calls, and complete other non-computation-intensive calculations. Finally, evaluations for both specific algorithms and practical applications are implemented. Experimental results show that when deployed on Intel Stratix 10 FPGA, our accelerator can increase the throughput of 2048-bit modular multiplication, modular exponentiation and Paillier algorithm to more than 3x of the CPU. When integrated into a industrial grade federated learning open source framework, the end-to-end training time of linear regression and logistic regression can be shortened by 2.28x and 3.30x respectively, which is more than 2x faster than the reported best results of FPGA accelerator.
C1 [Wang, Zixiao; Che, Biyao; Du, Yang; Chen, Ying; Zhao, Jizhuang] China Telecom Res Inst, Beijing 102209, Peoples R China.
   [Guo, Liang] Inst Cloud Comp & Big Data CAICT, Beijing 100191, Peoples R China.
   [He, Wei] China Telecom BestPay Co Ltd, Beijing 100031, Peoples R China.
RP Wang, ZX (corresponding author), China Telecom Res Inst, Beijing 102209, Peoples R China.
EM wangzx15@chinatelecom.cn
CR Bahadori M, 2020, IEEE T VLSI SYST, V28, P2182, DOI 10.1109/TVLSI.2020.3010585
   Dai WC, 2018, IEEE T COMPUT, V67, P1301, DOI 10.1109/TC.2018.2811466
   Daly A., 2002, FPGA 2002. Tenth ACM International Symposium on Field-Programmable Gate Arrays, P40, DOI 10.1145/503048.503055
   European Union, GEN DATA PROTECTION
   Han-Wen Hu, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P138, DOI 10.1109/ISSCC42614.2022.9731775
   Intel Corp, INTEL FPGA SDK OPENC
   Jing QH, 2019, Arxiv, DOI [arXiv:1912.12795, DOI 10.48550/ARXIV.1912.12795]
   Jung W, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P190, DOI 10.1145/3453483.3454038
   Karatsuba A. A., 1963, SOV PHYS DOKL, V7, P595
   KIRGSN, BREAST CANC WISCONSI
   Linux Foundation, FEDERATED TECHNOLOGY
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   MONTGOMERY PL, 1985, MATH COMPUT, V44, P519, DOI 10.1090/S0025-5718-1985-0777282-X
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Python Software Foundation, PYTHON WRAPPER OPENC
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   San I, 2016, SECUR COMMUN NETW, V9, P1535, DOI 10.1002/sec.1442
   San I, 2014, J SYST ARCHITECT, V60, P440, DOI 10.1016/j.sysarc.2013.10.013
   Keskar NS, 2017, Arxiv, DOI arXiv:1609.04836
   Sijun Tan, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P1021, DOI 10.1109/SP40001.2021.00098
   The Khronos Group, OPEN STANDARD PARALL
   UCI MACHINE LEARNING, ELECT MOTOR TEMPERAT
   Wang D., 2019, CHI 2019 P 2019 CHI, P1
   Wang D, 2016, Arxiv, DOI arXiv:1611.02450
   Wang ZX, 2020, IEEE ACCESS, V8, P116569, DOI 10.1109/ACCESS.2020.3004198
   Xilinx Corp, VITIS HIGH LEVEL SYN
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yang ZX, 2020, Arxiv, DOI arXiv:2007.10560
NR 28
TC 4
Z9 4
U1 6
U2 7
PY 2022
VL 10
BP 98649
EP 98661
DI 10.1109/ACCESS.2022.3206785
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Aboye, D
   Kupsh, D
   Lim, M
   Mai, J
   Dangwal, D
   Mirza, D
   Sherwood, T
AF Aboye, Dawit
   Kupsh, Dylan
   Lim, Maggie
   Mai, Jacqueline
   Dangwal, Deeksha
   Mirza, Diba
   Sherwood, Timothy
GP IEEE
TI PyRTLMatrix: an Object-Oriented Hardware Design Pattern for Prototyping
   ML Accelerators
SO 2019 2ND WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE
   COMPUTING FOR EMBEDDED APPLICATIONS (EMC2 2019)
DT Proceedings Paper
CT 2nd Workshop on Energy Efficient Machine Learning and Cognitive
   Computing for Embedded Applications (EMC2)
CY FEB 17, 2019
CL Washington, DC
AB As Machine Learning (ML) applications become pervasive and computer architects further integrate hardware support, the need to rapidly explore trade-offs between algorithms and hardware becomes pressing. While prior work on hardware accelerators has led to tremendous performance and energy improvements, it can be difficult to generalize these approaches without resorting to special purpose tools or even languages. Through object-oriented design principles we describe a general and reusable approach for generating parameterized neural network hardware. Specifically, we describe our experiences with high-level hardware design objects for building neural network hardware based on the open-source Python HDL, PyRTL. By thinking at a higher level of abstraction than simple "hardware modules,", we open the door to a process by which hardware can be developed with software engineering principles. This creates new opportunities for a tight feedback loop between machine learning algorithm innovation and hardware design reality. Future works considering hardware development for ML applications can benefit from our work analyzing the costs and benefits of abstraction.
C1 [Aboye, Dawit; Kupsh, Dylan; Lim, Maggie; Mai, Jacqueline; Dangwal, Deeksha; Mirza, Diba; Sherwood, Timothy] UC Santa Barbara, Santa Barbara, CA 93106 USA.
RP Aboye, D (corresponding author), UC Santa Barbara, Santa Barbara, CA 93106 USA.
EM dawit@ucsb.edu; dkupsh@ucsb.edu; maggielim@ucsb.edu;
   jacquelinemai@ucsb.edu; deeksha@cs.ucsb.edu; dimirza@cs.ucsb.edu;
   sherwood@cs.ucsb.edu
CR [Anonymous], 2004, LINUX J
   [Anonymous], 2017, ICLR
   Baaij C, 2010, 13TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN: ARCHITECTURES, METHODS AND TOOLS, P714, DOI 10.1109/DSD.2010.21
   Bachrach J, 2012, DES AUT CON, P1212
   Bjesse P, 1999, ACM SIGPLAN NOTICES, V34, P174, DOI 10.1145/291251.289440
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Clow J, 2017, I C FIELD PROG LOGIC
   Jiang SN, 2018, DES AUT CON, DOI 10.1145/3195970.3196073
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   LeCun Y., MNIST DATABASE HANDW
   Lockhart D, 2014, INT SYMP MICROARCH, P280, DOI 10.1109/MICRO.2014.50
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Richmond D, 2018, IEEE T COMPUT AID D, V37, P2835, DOI 10.1109/TCAD.2018.2857259
NR 15
TC 1
Z9 1
U1 0
U2 0
PY 2019
BP 36
EP 40
DI 10.1109/EMC249363.2019.00015
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chen, YJ
   Lan, HY
   Du, ZD
   Liu, SL
   Tao, JH
   Han, D
   Luo, T
   Guo, Q
   Li, L
   Xie, Y
   Chen, TS
AF Chen, Yunji
   Lan, Huiying
   Du, Zidong
   Liu, Shaoli
   Tao, Jinhua
   Han, Dong
   Luo, Tao
   Guo, Qi
   Li, Ling
   Xie, Yuan
   Chen, Tianshi
TI An Instruction Set Architecture for Machine Learning
SO ACM TRANSACTIONS ON COMPUTER SYSTEMS
DT Article
ID NETWORK
AB Machine Learning (ML) are a family of models for learning from the data to improve performance on a certain task. ML techniques, especially recent renewed neural networks (deep neural networks), have proven to be efficient for a broad range of applications. ML techniques are conventionally executed on general-purpose processors (such as CPU and GPGPU), which usually are not energy efficient, since they invest excessive hardware resources to flexibly support various workloads. Consequently, application-specific hardware accelerators have been proposed recently to improve energy efficiency. However, such accelerators were designed for a small set of ML techniques sharing similar computational patterns, and they adopt complex and informative instructions (control signals) directly corresponding to high-level functional blocks of an ML technique (such as layers in neural networks) or even an ML as a whole. Although straightforward and easy to implement for a limited set of similar ML techniques, the lack of agility in the instruction set prevents such accelerator designs from supporting a variety of different ML techniques with sufficient flexibility and efficiency.
   In this article, we first propose a novel domain-specific Instruction Set Architecture (ISA) for NN accelerators, called Cambricon, which is a load-store architecture that integrates scalar, vector, matrix, logical, data transfer, and control instructions, based on a comprehensive analysis of existing NN techniques. We then extend the application scope of Cambricon from NN to ML techniques. We also propose an assembly language, an assembler, and runtime to support programming with Cambricon, especially targeting large-scale ML problems. Our evaluation over a total of 16 representative yet distinct ML techniques have demonstrated that Cambricon exhibits strong descriptive capacity over a broad range of ML techniques and provides higher code density than general-purpose ISAs such as x86, MIPS, and GPGPU. Compared to the latest state-of-the-art NN accelerator design DaDianNao [7] (which can only accommodate three types of NN techniques), our Cambricon-based accelerator prototype implemented in TSMC 65nm technology incurs only negligible latency/power/area overheads, with a versatile coverage of 10 different NN benchmarks and 7 other ML benchmarks. Compared to the recent prevalent ML accelerator PuDianNao, our Cambricon-based accelerator is able to support all the ML techniques as well as the 10 NNs but with only approximate 5.1% performance loss.
C1 [Chen, Yunji; Lan, Huiying; Du, Zidong; Liu, Shaoli; Tao, Jinhua; Han, Dong; Luo, Tao; Guo, Qi; Chen, Tianshi] Chinese Acad Sci, Inst Comp Technol, SKL Comp Architecture, Beijing, Peoples R China.
   [Chen, Yunji; Li, Ling] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Chen, Yunji] BIT, ZJLab, Inst BrainIntelligence Technol, Zhanjiang Lab, Beijing, Peoples R China.
   [Chen, Yunji] Shanghai Res Ctr Brain Sci & Brain Inspired Intel, Shanghai, Peoples R China.
   [Li, Ling] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Xie, Yuan] UCSB, Dept Elect & Comp Engn, Santa Barbara, CA USA.
RP Du, ZD (corresponding author), Chinese Acad Sci, Inst Comp Technol, SKL Comp Architecture, Beijing, Peoples R China.
EM cyj@ict.ac.cn; lanhuiying@ict.ac.cn; duzidong@ict.ac.cn;
   liushaoli@ict.ac.cn; taojinhua@ict.ac.cn; handong@ict.ac.cn;
   luotao@ict.ac.cn; guoqi@ict.ac.cn; liling@iscas.ac.cn;
   yuanxie@ece.ucsb.edu; chentianshi@ict.ac.cn
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2013, PROC 30 INT C MACH L
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chang YF, 2014, ASIAPAC SIGN INFO PR
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen TS, 2015, IEEE MICRO, V35, P24, DOI 10.1109/MM.2015.41
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chi Ping, 2016, P IEEE C T COMP AID
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Edwards A.L., 1984, MATH GAZ, V69, P1, DOI DOI 10.1017/S0025557200105583
   Eijkhout V., 2011, INTRO HIGH PERFORMAN
   Esmaeilzadeh H, 2006, IEEE INT SYMP CIRC S, P2773, DOI 10.1109/ISCAS.2006.1693199
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farabet Clement, 2011, COMP VIS PATT REC WO
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Graves A, 2005, IEEE IJCNN, P2047
   Hashmi A, 2011, ACM SIGPLAN NOTICES, V46, P145, DOI 10.1145/1961296.1950385
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kantabutra V, 1996, IEEE T COMPUT, V45, P328, DOI 10.1109/12.485571
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, CUDA CONVNET HIGH PE
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Larochelle Hugo, 2007, P 24 INT C MACH LEAR, P473, DOI DOI 10.1145/1273496.1273556
   Le Q.V., 2013, P 2013 IEEE INT C AC
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu D, 2015, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2015/01/020
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Maashri A. A., 2012, P 49 ACM EDAC IEEE D
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Marsaglia G., 2000, J STAT SOFTW, V5, P1, DOI [DOI 10.18637/JSS.V005.I08, 10.18637/ jss.v005.i08]
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Motter M. A., 1999, Proceedings of the 1999 American Control Conference (Cat. No. 99CH36251), P1659, DOI 10.1109/ACC.1999.786111
   Oliveira CS, 2004, IEEE IJCNN, P937
   Park J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P367, DOI 10.1145/3123939.3123979
   PATTERSON R, 1981, HIGGINSON J, P8
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pineda Fernando J, 1987, PHYS REV LETT, P602
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Poremba M, 2016, DES AUT CON, DOI 10.1145/2897937.2898024
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725
   Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Wang XY, 2013, PR CHINAGRID, P22, DOI 10.1109/ChinaGrid.2013.15
   Wang Yu, 2015, P GREAT LAK S VLSI
   Xu C., 2015, P 21 INT S HIGH PERF
   Xu Tao, 2012, P 2012 8 INT C NAT C
   Zeng XH, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2885
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao JS, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2541228.2541231
NR 65
TC 6
Z9 6
U1 2
U2 19
PD AUG
PY 2019
VL 36
IS 3
AR 9
DI 10.1145/3331469
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Rahman, R
   Bandyopadhyay, S
AF Rahman, Rahnuma
   Bandyopadhyay, Supriyo
TI A Nonvolatile All-Spin Nonbinary Matrix Multiplier: An Efficient
   Hardware Accelerator for Machine Learning
SO IEEE TRANSACTIONS ON ELECTRON DEVICES
DT Article
DE Voltage; Magnetic tunneling; Strain; Magnetization; Logic gates;
   Magnetostriction; Resistance; Domain wall (DW) synapse; magnetic tunnel
   junction (MTJ); matrix multiplication; straintronics
ID DOMAIN-WALL
AB We propose and analyze a compact and non-volatile nanomagnetic (all-spin) nonbinarymatrix multiplier performing the multiply-and-accumulate (MAC) operation using two magnetic tunnel junctions (MTJs) - one activated by strain to act as the multiplier and the other activated by spin-orbit torque pulses to act as a domain wall (DW) synapse that performs the operation of the accumulator. Each MAC operation can be performed in similar to 5 ns and the energy dissipated per operation is similar to 500 aJ. This provides a very useful hardware accelerator for machine learning and artificial intelligence tasks that often involve the multiplication of large matrices. The nonvolatility allows the matrix multiplier to be embedded in powerful non-von- Neumann architectures. It also allows all computing to be done at the edge while reducing the need to access the cloud, thereby making artificial intelligence more resilient against cyberattacks.
C1 [Rahman, Rahnuma; Bandyopadhyay, Supriyo] Virginia Commonwealth Univ, Dept Elect & Comp Engn, Richmond, VA 23284 USA.
RP Bandyopadhyay, S (corresponding author), Virginia Commonwealth Univ, Dept Elect & Comp Engn, Richmond, VA 23284 USA.
EM rahmanr3@vcu.edu; sbandy@vcu.edu
CR [Anonymous], AI AND COMPUTE
   Bhunia S, 2014, P IEEE, V102, P1229, DOI 10.1109/JPROC.2014.2334493
   Cui JZ, 2013, APPL PHYS LETT, V103, DOI 10.1063/1.4838216
   Dutta S, 2017, NANO LETT, V17, P5869, DOI 10.1021/acs.nanolett.7b03199
   Emori S, 2014, PHYS REV B, V90, DOI 10.1103/PhysRevB.90.184427
   Emori S, 2013, NAT MATER, V12, P611, DOI [10.1038/NMAT3675, 10.1038/nmat3675]
   Hamerly Ryan, 2021, IEEE Spectrum, V58, P30, DOI 10.1109/MSPEC.2021.9475393
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Hong SJ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122138
   Khasanvis S, 2015, IEEE T NANOTECHNOL, V14, P980, DOI 10.1109/TNANO.2015.2439618
   Kish LB, 2002, PHYS LETT A, V305, P144, DOI 10.1016/S0375-9601(02)01365-8
   Lee EH, 2017, IEEE J SOLID-ST CIRC, V52, P261, DOI 10.1109/JSSC.2016.2599536
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Leonard T, 2022, Arxiv, DOI arXiv:2111.11516
   Liu S, 2021, APPL PHYS LETT, V118, DOI 10.1063/5.0046032
   Ngo DT, 2011, APPL PHYS EXPRESS, V4, DOI 10.1143/APEX.4.093002
   RANDELL B, 1971, COMPUT J, V14, P317, DOI 10.1093/comjnl/14.3.317
   Roy K, 2012, J APPL PHYS, V112, DOI 10.1063/1.4737792
   Ryu KS, 2013, NAT NANOTECHNOL, V8, P527, DOI [10.1038/NNANO.2013.102, 10.1038/nnano.2013.102]
   Sengupta A, 2016, IEEE T BIOMED CIRC S, V10, P1152, DOI 10.1109/TBCAS.2016.2525823
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Verma N, 2009, SYMP VLSI CIRCUITS, P62
   Yazdani Reza, 2016, P INT S MICROARCHITE, P1, DOI DOI 10.1109/MICRO.2016.7783750
   Zhang JT, 2015, ISSCC DIG TECH PAP I, V58, P332, DOI 10.1109/ISSCC.2015.7063061
   Zhao ZY, 2016, APPL PHYS LETT, V109, DOI 10.1063/1.4961670
NR 25
TC 1
Z9 1
U1 0
U2 3
PD DEC
PY 2022
VL 69
IS 12
BP 7120
EP 7127
DI 10.1109/TED.2022.3214167
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Owaida, M
   Kulkarni, A
   Alonso, G
AF Owaida, Muhsen
   Kulkarni, Amit
   Alonso, Gustavo
TI Distributed Inference over Decision Tree Ensembles on Clusters of FPGAs
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Decision trees; Microsoft Catapult; Intel HARP; FPGA cluster; machine
   learning; inference; distributed systems
AB Given the growth in data inputs and application complexity, it is often the case that a single hardware accelerator is not enough to solve a given problem. In particular, the computational demands and I/O of many tasks in machine learning often require a cluster of accelerators to make a relevant difference in performance. In this article, we explore the efficient construction of FPGA clusters using inference over Decision Tree Ensembles as the target application. The article explores several levels of the problem: (1) a lightweight inter-FPGA communication protocol and routing layer to facilitate the communication between the different FPGAs, (2) the data partitioning and distribution strategies maximizing performance, (3) and an in depth analysis on how applications can be efficiently distributed over such a cluster. The experimental analysis shows that the resulting system can support inference over decision tree ensembles at a significantly higher throughput than that achieved by existing systems.
C1 [Owaida, Muhsen; Kulkarni, Amit; Alonso, Gustavo] Swiss Fed Inst Technol, Syst Grp, Dept Comp Sci, Univ Str 6, CH-8092 Zurich, Switzerland.
RP Owaida, M (corresponding author), Swiss Fed Inst Technol, Syst Grp, Dept Comp Sci, Univ Str 6, CH-8092 Zurich, Switzerland.
EM muhsen.owaida@inf.ethz.ch; amit.kulkarni@inf.ethz.ch;
   gustavo.alonso@inf.ethz.ch
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Alkalay S, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P15, DOI 10.1145/2847263.2847287
   Alonso Gustavo, 2019, IEEE B, V42, P2
   Amato Flora, 2014, P ACM C INT DES CHIL
   [Anonymous], 2018, DISTRIBUTED INFERENC
   [Anonymous], 2011, J MACH LEARN RES
   [Anonymous], 2018, AMAZON EC2 F1 INSTAN
   Baker ZK, 2005, ANN IEEE SYM FIELD P, P3
   Barbareschi Mario, 2015, P INT WORKSH MULT CL
   Castillo J., 2009, P IEEE INT PAR DISTR
   Chen Tianqi, 2016, P ACM C KNOWL DISC D
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Friedman JH, 2003, STAT MED, V22, P1365, DOI 10.1002/sim.1501
   Geng T, 2018, ANN IEEE SYM FIELD P, P81, DOI 10.1109/FCCM.2018.00021
   He K., 2015, ARXIV
   Kara Kaan, 2018, P INT C VER LARG DAT
   Kara Kaan, 2017, P IEEE S FIELD PROGR
   Kono Yoshiaki, 2012, P INT C FIELD PROGR
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kulaga Rafal, 2015, IMAGE PROCESS COMMUN, V19, P2
   MENCER O, 2009, P SO PROGR LOG C SPL
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Oberg Jason, 2012, P INT C FIELD PROGR
   Oliver N., 2011, P INT C REC COMP FPG
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Owaida M., 2018, P 2018 28 INT C FIEL, P1
   Owaida Muhsen, 2017, P IEEE S FIELD PROGR
   Owaida Muhsen, 2017, P INT C FIELD PROGR
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qu YR, 2014, IEEE HIGH PERF EXTR
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Sidler David, 2017, P C ASS COMP MACH SP
   Struharik R., 2015, P IEEE 16 INT S INT
   Tarafdar Naif, 2017, P ACM SIGDA INT S FI
   Tracy Tommy, 2016, P INT C ISC HIGH PER
   Tsoi Kuen Hung, 2010, P ACM SIGDA INT S FI
   Van Essen Brian, 2012, P IEEE S FIELD PROGR
   Wang Zeke, 2019, P INT C VER LARG DAT
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Chen, 2016, P INT S LOW POW EL D
NR 42
TC 11
Z9 11
U1 1
U2 3
PD NOV
PY 2019
VL 12
IS 4
AR 17
DI 10.1145/3340263
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Goli, M
   Iwanski, L
   Lawson, J
   Dolinsky, U
   Richards, A
AF Goli, Mehdi
   Iwanski, Luke
   Lawson, John
   Dolinsky, Uwe
   Richards, Andrew
BE Deakin, T
TI TensorFlow Acceleration on ARM Hikey Board
SO IWOCL'18: PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL
DT Proceedings Paper
CT International Workshop on OpenCL (IWOCL)
CY MAY 14-16, 2018
CL Oxford, ENGLAND
DE Machine learning; TensorFlow; Eigen; OpenCL; GPGPU; ARM
AB There is huge demand for targeting complex and large-scale machine learning applications particularly those based on popular actively-maintained frameworks such as TensorFlow and CAFFE to a variety of platforms with accelerators ranging from high-end desktop GPUs to resource-constrained embedded or mobile GPUs, FPGAs, and DSPs. However, to deliver good performance different platforms may require different algorithms or data structures, yet code should be easily portable and reused as much as possible across different devices. The open SYCL standard addresses this by providing parallel processing through a single-source programming model enabling the same standard C++ code to be used on the CPU and accelerator. This allows high-level C++ abstractions and templates to be used to quickly configure device and host code to cover specific features of the platform. By targeting OpenCL, SYCL enables C++ applications such as TensorFlow to run efficiently on OpenCL devices without having to write OpenCL code.
C1 [Goli, Mehdi; Iwanski, Luke; Lawson, John; Dolinsky, Uwe; Richards, Andrew] Codeplay Software Ltd, Edinburgh, Midlothian, Scotland.
RP Goli, M (corresponding author), Codeplay Software Ltd, Edinburgh, Midlothian, Scotland.
EM mehdi.goli@codeplay.com; luke@codeplay.com; john@codeplay.com;
   uwe@codeplay.com; andrew@codeplay.com
CR Abadi M, 2016, 12 USENIX S OP SYST, P265, DOI 10.5555/3026877.3026899
   Angelova A, 2015, IEEE INT CONF ROBOT, P704, DOI 10.1109/ICRA.2015.7139256
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 2016, ARXIV E PRINTS
   [Anonymous], 2014, EIGEN C LINEAR ALGEB
   [Anonymous], 2015, ARXIV151201274
   ARB OpenMP, 2011, OPENMP APPL PROGR IN
   Collobert R., 2002, TECHNICAL REPORT
   CUDA Nvidia, 2010, PROGR GUID
   Goli M., 2017, P 5 INT WORKSH OPENC, P8
   Goli Mehdi, 2017, 1 WORKSH DISTR HET P
   Gu J., 2016, P 4 INT WORKSH OPENC, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Khronos OpenCL Working Group SYCL subgroup, 2015, SYCL SPEC
   Microsoft, 2013, C AMP LANG PROGR MOD
   OpenACC Working Group and others, 2011, OPENACC APPL PROGR I
   Sander Ben, 2015, HCC C COMPILER HETER
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2018
BP 33
EP 36
DI 10.1145/3204919.3204926
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Rasmussen, C
   Sottile, M
   Rasmussen, S
   Nagle, D
   Dumas, W
AF Rasmussen, Craig
   Sottile, Matthew
   Rasmussen, Soren
   Nagle, Dan
   Dumas, William
GP IEEE
TI CAFe: Coarray Fortran Extensions for Heterogeneous Computing
SO 2016 IEEE 30TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 30th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 23-27, 2016
CL Illinois Inst Technol, Chicago, IL
HO Illinois Inst Technol
DE distributed memory parallelism; domain specific language
AB Emerging hybrid accelerator architectures are often proposed for inclusion as components in an exascale machine, not only for performance reasons but also to reduce total power consumption. Unfortunately, programmers of these architectures face a daunting and steep learning curve that frequently requires learning a new language (e.g., OpenCL) or adopting a new programming model. Furthermore, the distributed (and frequently multi-level) nature of the memory organization of clusters of these machines provides an additional level of complexity. This paper presents preliminary work examining how Fortran coarray syntax can be extended to provide simpler access to accelerator architectures. This programming model integrates the Partitioned Global Address Space (PGAS) features of Fortran with some of the more task-oriented constructs in OpenMP 4.0 and OpenACC. It also includes the potential for compiler-based transformations targeting the Open Community Runtime (OCR) environment. We demonstrate these CoArray Fortran extensions (CAFe) by implementing a multigrid Laplacian solver and transforming this high-level code to a mixture of standard coarray Fortran and OpenCL kernels.
C1 [Rasmussen, Craig; Rasmussen, Soren; Dumas, William] Univ Oregon, Eugene, OR 97403 USA.
   [Nagle, Dan] NCAR, Boulder, CO USA.
   [Sottile, Matthew] Galois, Portland, OR USA.
RP Rasmussen, C (corresponding author), Univ Oregon, Eugene, OR 97403 USA.
CR [Anonymous], 2010, SUMMARY REPORT ADV S
   [Anonymous], 2008, ACM SIGPLAN FORTR FO
   [Anonymous], OPENCL SPEC VERS 1 1
   [Anonymous], 2014, OP COMM RUNT INT
   BRANDT A, 1977, MATH COMPUT, V31, P333, DOI 10.1090/S0025-5718-1977-0431719-X
   Bravenboer M, 2008, SCI COMPUT PROGRAM, V72, P52, DOI 10.1016/j.scico.2007.11.003
   Dokulil J, 2015, PROCEDIA COMPUT SCI, V51, P1453, DOI 10.1016/j.procs.2015.05.335
   Dubey A., 2014, WOSC 14, P57
   Dubey A., 2013, CORR
   Jin G., 2011, 25 IEEE INT S PAR DI
   Mellor-Crummey J., 2009, PGAS 09
   Numrich RW, 1998, SIGPLAN FORTRAN FORU, P1, DOI [DOI 10.1145/289918.289920, 10.1145/289918.289920]
   Prabhu P., 2011, STATE PRACTICE REPOR, P19
   Sottile MJ, 2013, INT J COMPUT SCI ENG, V8, P47, DOI 10.1504/IJCSE.2013.052113
   The Fortran Committee, 2014, J315007 FORTR COMM
   The Fortran Committee, 2014, N2007 ISOIEC JTC1SC2
   van den Brand MGJ, 2000, SOFTWARE PRACT EXPER, V30, P259, DOI 10.1002/(SICI)1097-024X(200003)30:3<259::AID-SPE298>3.0.CO;2-Y
NR 17
TC 2
Z9 2
U1 0
U2 2
PY 2016
BP 357
EP 365
DI 10.1109/IPDPSW.2016.140
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Tsai, CL
   Wu, CF
   Chang, YH
   Hu, HW
   Lee, YC
   Li, HP
   Kuo, TW
AF Tsai, Chieh-Lin
   Wu, Chun-Feng
   Chang, Yuan-Hao
   Hu, Han-Wen
   Lee, Yung-Chun
   Li, Hsiang-Pang
   Kuo, Tei-Wei
GP IEEE
TI A digital 3D TCAM accelerator for the inference phase of Random Forest
SO 2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC
DT Proceedings Paper
CT 60th ACM/IEEE Design Automation Conference (DAC)
CY JUL 09-13, 2023
CL San Francisco, CA
AB Random forest is a popular ensemble machine-learning algorithm for classification and regression tasks. However, the irregular tree shapes and non-deterministic memory access patterns make it hard for the current von Neumann architecture to handle random forest efficiently. This paper proposes a digital 3D TCAM-based accelerator for the random forest, adopting the idea of processing-in-memory (PIM) to reduce data movement. By utilizing this accelerator, we propose a TCAM-based approach to provide real-time inference with low energy consumption, making it suitable for edge or embedded environments. In the experiments, the proposed approach achieves an average of 3.13 times higher throughput with 22 times more energy saving than the GPU approach.
C1 [Tsai, Chieh-Lin; Kuo, Tei-Wei] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Wu, Chun-Feng] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Chang, Yuan-Hao] Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
   [Hu, Han-Wen; Lee, Yung-Chun; Li, Hsiang-Pang] Macronix Int Co Ltd, Hsinchu, Taiwan.
   [Hu, Han-Wen] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu, Taiwan.
   [Kuo, Tei-Wei] Mohamed Bin Zayed Univ Artificial Intelligence, Abu Dhabi, U Arab Emirates.
   [Kuo, Tei-Wei] Natl Taiwan Univ, NTU High Performance & Sci Comp Ctr, Taipei, Taiwan.
RP Tsai, CL (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM d09922013@ntu.edu.tw; cfwu417@cs.nycu.edu.tw; johnson@iis.sinica.edu.tw;
   paddingtonhu@mxic.com.tw; monixslee@mxic.com.tw; sbli@mxic.com.tw;
   ktw@csie.ntu.edu.tw
CR Arsovski I, 2003, IEEE J SOLID-ST CIRC, V38, P155, DOI 10.1109/JSSC.2002.806264
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen KH, 2022, ACM T EMBED COMPUT S, V21, DOI 10.1145/3508019
   Dua D, 2020, UCI MACHINE LEARNING
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Li Shuangchen, 2016, 2016 IEEE ACM INT C, P1
   nvidia, NVIDIA JETSON XAVIER
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pedretti G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25873-0
   Raschka S, 2020, Arxiv, DOI arXiv:2002.04803
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Wright M.N., 2020, PACKAGE RANGER FAST
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Zhao L, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P473, DOI 10.1145/3330345.3330387
NR 16
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/DAC56929.2023.10247695
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ajani, TS
   Imoize, AL
   Atayero, AA
AF Ajani, Taiwo Samuel
   Imoize, Agbotiname Lucky
   Atayero, Aderemi A.
TI An Overview of Machine Learning within Embedded and Mobile
   Devices-Optimizations and Applications
SO SENSORS
DT Review
DE embedded computing systems; computer architecture; mobile computing;
   machine learning; TinyML; deep learning; mobile devices; optimization
   techniques
ID SUPPORT VECTOR MACHINE; CONVOLUTIONAL NEURAL-NETWORK; INDOOR
   LOCALIZATION; RECOGNITION; IOT; CLASSIFICATION; DESIGN; MODELS; POWER;
   COST
AB Embedded systems technology is undergoing a phase of transformation owing to the novel advancements in computer architecture and the breakthroughs in machine learning applications. The areas of applications of embedded machine learning (EML) include accurate computer vision schemes, reliable speech recognition, innovative healthcare, robotics, and more. However, there exists a critical drawback in the efficient implementation of ML algorithms targeting embedded applications. Machine learning algorithms are generally computationally and memory intensive, making them unsuitable for resource-constrained environments such as embedded and mobile devices. In order to efficiently implement these compute and memory-intensive algorithms within the embedded and mobile computing space, innovative optimization techniques are required at the algorithm and hardware levels. To this end, this survey aims at exploring current research trends within this circumference. First, we present a brief overview of compute intensive machine learning algorithms such as hidden Markov models (HMM), k-nearest neighbors (k-NNs), support vector machines (SVMs), Gaussian mixture models (GMMs), and deep neural networks (DNNs). Furthermore, we consider different optimization techniques currently adopted to squeeze these computational and memory-intensive algorithms within resource-limited embedded and mobile environments. Additionally, we discuss the implementation of these algorithms in microcontroller units, mobile devices, and hardware accelerators. Conclusively, we give a comprehensive overview of key application areas of EML technology, point out key research directions and highlight key take-away lessons for future research exploration in the embedded machine learning domain.
C1 [Ajani, Taiwo Samuel; Imoize, Agbotiname Lucky] Univ Lagos, Fac Engn, Dept Elect & Elect Engn, Akoka 100213, Lagos State, Nigeria.
   [Imoize, Agbotiname Lucky] Ruhr Univ, Inst Digital Commun, Dept Elect Engn & Informat Technol, D-44801 Bochum, Germany.
   [Atayero, Aderemi A.] Covenant Univ, Dept Elect & Informat Engn, Ota 112233, Ogun State, Nigeria.
RP Imoize, AL (corresponding author), Univ Lagos, Fac Engn, Dept Elect & Elect Engn, Akoka 100213, Lagos State, Nigeria.; Imoize, AL (corresponding author), Ruhr Univ, Inst Digital Commun, Dept Elect Engn & Informat Technol, D-44801 Bochum, Germany.
EM taiwo.ajani.94@gmail.com; aimoize@unilag.edu.ng; atayero@cu.edu.ng
CR Afifi SM., 2015, INT J INNOV SCI ENG, V2, P733
   Al Mamun M, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (ICECOS), P217, DOI 10.1109/ICECOS.2017.8167137
   Al-Kofahi MM, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106457
   Albawi S., 2017, 2017 INT C ENG TECHN, P1, DOI [10.1109/ICEngTechnol.2017.8308186, DOI 10.1109/ICENGTECHNOL.2017.8308186]
   Anguita D., 2005, P 2005 IEEE INT JOIN, DOI [10.1109/IJCNN.2005.1555933, DOI 10.1109/IJCNN.2005.1555933]
   Anguita D, 2012, P INT WORKSH AMB ASS, P216
   Anguita D, 2007, IEEE IJCNN, P1360, DOI 10.1109/IJCNN.2007.4371156
   Anguita D, 2006, IEEE T NEURAL NETWOR, V17, P1328, DOI 10.1109/TNN.2006.877537
   [Anonymous], 2016, P 2016 IEEE 18 INT C
   [Anonymous], 2017, P 2017 IEEE GLOBAL C, DOI DOI 10.1109/GLOCOM.2017.8255023
   [Anonymous], MOBILE DEVICE IDENTI
   [Anonymous], STM32F469XX
   [Anonymous], 2012, PROC 10 ACM C EMBEDD
   [Anonymous], 2018, 2018 1 WORKSH EN, DOI DOI 10.1109/EMC2.2018.00012
   [Anonymous], 2016, 160908144 ARXIV
   Atmel, ATMEL ATMEGA48P 168P
   Atmel, SAM3X SAM3A SER DAT
   Atmel Corporation, 32 BIT ARM BAS MICR
   Atmel Corporation, ATMEL ATMEGA640V 128
   Azimi I, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126501
   Baldini G, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040783
   Banbury C., P 4 MLSYS C SAN JOS
   Baoli L., 2005, DIANZI YU XINXI XUEB, V27, P487
   Bengio, BINARIZED NEURAL NET
   Bhide VH, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1763, DOI 10.1109/ICCSP.2015.7322825
   Boni A, 2007, IEEE T INSTRUM MEAS, V56, P39, DOI 10.1109/TIM.2006.887319
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Bottou L, 1991, P NEURONIMES, V8, P1
   Branco S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111289
   BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P458, DOI 10.1109/72.88165
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Carbonell J.G., 1981, ACMSIGART B, V18, P29, DOI 10.1145/1056743.1056744
   Chan W, P 2016 IEEE INT C AC
   Chang A.X.M., RECURRENT NEURAL NET
   Chang Xu, 2009, Proceedings of the Second International Symposium on Information Science and Engineering (ISISE 2009), P500, DOI 10.1109/ISISE.2009.60
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Cheng XW, 2019, 2019 ACM/IEEE SYMPOSIUM ON ARCHITECTURES FOR NETWORKING AND COMMUNICATIONS SYSTEMS (ANCS), DOI 10.1109/ancs.2019.8901890
   Chittamuru SVR, 2018, IEEE T PARALL DISTR, V29, P2402, DOI 10.1109/TPDS.2018.2833876
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cornetta G, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050600
   Courbariaux M., P 3 INT C LEARN REPR, P1
   Courbariaux M., LOW PRECISION STORAG
   Cui XD, 2021, APPL ACOUST, V174, DOI 10.1016/j.apacoust.2020.107728
   Damljanovic A, 2018, IEEE IND ELEC, P2809, DOI 10.1109/IECON.2018.8591634
   Das A, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P441, DOI 10.1145/2660267.2660325
   Dean J, 2020, ISSCC DIG TECH PAP I, P8, DOI 10.1109/ISSCC19947.2020.9063049
   Degirmenci A., 2014, HARV U, V3, P1
   DHAR SS, 2015, IJISET INT J INNOV S, V2, P744
   Fafoutis X, 2018, 2018 IEEE 4TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P269, DOI 10.1109/WF-IoT.2018.8355116
   Faruk N, 2019, IEEE ACCESS, V7, P77293, DOI 10.1109/ACCESS.2019.2921411
   Frank M, 2020, COMPUTATION, V8, DOI 10.3390/computation8010015
   Fu R, 2011, COMM COM INF SC, V224, P602
   Giri Davide, 2020, Proceedings of 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), P1049, DOI 10.23919/DATE48585.2020.9116317
   Gorur P., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P386, DOI 10.1109/AVSS.2011.6027356
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gupta C, 2017, PR MACH LEARN RES, V70
   Gupta S., P 32 INT C MACH LEAR, P1737
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel P., RISTRETTO HARDWARE O
   Haigh K.Z, 2015, MACHINE LEARNING EMB, VVolume 8571, P1
   Haj R.B, P 2021 IEEE INT C PE
   Hakim A, 2017, PROCEDIA COMPUT SCI, V105, P46, DOI 10.1016/j.procs.2017.01.188
   Hammerstrom D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P537, DOI 10.1109/IJCNN.1990.137621
   Han S., P 4 INT C LEARN REPR, P1
   Han S., 2015, P 28 INT C NEUR INF, V1, P1135
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hochstetler J, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P341, DOI 10.1109/SEC.2018.00038
   Hu R., 2018, 2018 INT JOINT C NEU, P1, DOI DOI 10.1109/ICDSP.2018.8631588
   Hubara I, 2018, J MACH LEARN RES, V18
   Huynh LN, 2016, WEARSYS'16: PROCEEDINGS OF THE 2016 WORKSHOP ON WEARABLE SYSTEMS AND APPLICATIONS, P25, DOI 10.1145/2935643.2935650
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Iandola F.N, SQUEEZENET ALEXNET L
   Imoize AL, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/8838792
   Jadhav S. D., 2015, INT J SCI RES, V5, P1842, DOI [DOI 10.21275/V5I1.NOV153131, DOI 10.21275/V5I1.N0V153131]
   Jawandhiya P., 2018, INT J ARTIF INTELL A, V9, P63, DOI [10.5121/ijaia.2018.9105, DOI 10.5121/IJAIA.2018.9105]
   Johnson R., 2013, ADV NEURAL INFORM PR, V26, P315, DOI DOI 10.5555/2999611.2999647
   Jouppi NP, 2018, COMMUN ACM, V61, P50, DOI 10.1145/3154484
   Keras A., KERAS API REFERENCE
   Khan FM, 2005, IEEE INT SYMP CIRC S, P5154, DOI 10.1109/ISCAS.2005.1465795
   Khan MA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111771
   Khan MA, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100485
   Khoram S., 2018, P INT C LEARN REPR, P1
   Kim D, 2017, DES AUT TEST EUROPE, P1462, DOI 10.23919/DATE.2017.7927222
   Kim RG, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243483
   Kim RG, 2018, COMPUTER, V51, P66, DOI 10.1109/MC.2018.3011040
   Kodali S, 2017, PR IEEE COMP DESIGN, P589, DOI 10.1109/ICCD.2017.102
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kudo T, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P192
   Kurtz A., 2016, P PRIVACY ENHANCING, V2016, P4
   Lane ND, 2017, IEEE PERVAS COMPUT, V16, P82, DOI 10.1109/MPRV.2017.2940968
   Lane Nicholas D, 2016, P 15 INT C INFORM PR, P1
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Learning S.D, 2017, IEEE PERVAS COMPUT, V16, P82
   Lee D, 2017, CHINA COMMUN, V14, P23, DOI 10.1109/CC.2017.8068761
   Lee J, 2016, IEEE INT SYMP SIGNAL, P290, DOI 10.1109/ISSPIT.2016.7886051
   Lee Y. J., 2001, P 2001 SIAM INT C DA, V2001, P1, DOI DOI 10.1137/1.9781611972719.13
   Lei X, 2013, INTERSPEECH, P662
   Leiming Yu, 2014, 2014 43rd International Conference on Parallel Processing Workshops (ICCPW). Proceedings, P395, DOI 10.1109/ICPPW.2014.59
   Li DW, 2018, AAAI CONF ARTIF INTE, P2322
   Li L, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P911, DOI 10.1109/ICIVC.2018.8492754
   Li PL, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS), P347, DOI 10.1109/NAS.2015.7255222
   Huynh M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1635, DOI 10.1145/2810103.2810118
   Mazlan N. L., 2020, TEST ENG MANAGEMENT, V83, P8083
   Meng W., 2 BIT NETWORKS DEEP
   Mengistu D., 2019, PROC 5 INT C SMART P, P9
   Mittal A, 2018, PR GR LAK SYMP VLSI, P117, DOI 10.1145/3194554.3194594
   Mohsin MA, 2018, HEART 2018: PROCEEDINGS OF THE 9TH INTERNATIONAL SYMPOSIUM ON HIGHLY-EFFICIENT ACCELERATORS AND RECONFIGURABLE TECHNOLOGIES, DOI 10.1145/3241793.3241810
   Moons B, 2017, CONF REC ASILOMAR C, P1921, DOI 10.1109/ACSSC.2017.8335699
   Moreira MWL, 2016, INT CONF SEL TOP MOB, P84
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095
   Neshatpour K, 2018, 2018 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION (SAMOS XVIII), P89, DOI 10.1145/3229631.3229639
   Noronha DH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P110, DOI 10.1145/3289602.3293922
   Norouzi Mohammad, 2012, ADV NEURAL INFORM PR, P1061
   NVIDIA, ULT PC GPU NVID TIT
   NVIDIA, NVIDIA V100 TENS COR
   O'Shea K., INTRO CONVOLUTIONAL
   Oberstar E., FIXED POINT REPRESEN
   Ogbebor JO, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/7235362
   Ollander S, 2016, IEEE SYS MAN CYBERN, P4362, DOI 10.1109/SMC.2016.7844917
   Osuna E, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P276, DOI 10.1109/NNSP.1997.622408
   Pandey PS, 2017, PROCEEDINGS OF THE 2017 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS APPLICATIONS (ICCSA 2017)
   Papp D, 2015, ANN CONF PRIV SECUR, P145, DOI 10.1109/PST.2015.7232966
   Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761
   Park J., 2018, 181109886 ARXIV
   Pasricha S, 2020, IEEE DES TEST, V37, P60, DOI 10.1109/MDAT.2020.2982628
   Patil SS, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING AND INFORMATION PROCESSING (CCIP)
   Pedersen R, 2006, PROCEEDINGS OF THE FOURTH INTERNATIONAL WORKSHOP ON INTELLIGENT SOLUTIONS IN EMBEDDED SYSEMS, P79
   Popoola SI, 2019, IEEE ACCESS, V7, P150462, DOI 10.1109/ACCESS.2019.2947009
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Raparti VY, 2018, IEEE T MULTI-SCALE C, V4, P874, DOI 10.1109/TMSCS.2018.2871094
   Raspberry Pi Dramble, POW CONS BENCHM
   Razavi A, 2015, IEEE GLOBE WORK
   Real E, P 34 INT C MACH LEAR, P4429
   Ren T.I., 2012, INTELLIGENT DATA ENG, DOI [10.1007/978-3-642-32639-4_55, DOI 10.1007/978-3-642-32639-4_55]
   Reynolds D., 2009, GAUSSIAN MIXTURE MOD, P659
   Ronao CA, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147716683687
   Roth W., RESOURCE EFFICIENT N
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saikia J., 2019, P 2019 IEEE ACM INT, DOI [10.1109/ISLPED.2019.8824822, DOI 10.1109/ISLPED.2019.8824822]
   Salvadori C, 2017, J REAL-TIME IMAGE PR, V13, P273, DOI 10.1007/s11554-014-0402-5
   Sanchez-Iborra R, 2020, IEEE CIRC SYST MAG, V20, P4, DOI 10.1109/MCAS.2020.3005467
   Sattar H, 2019, IEEE ACCESS, V7, P144500, DOI 10.1109/ACCESS.2019.2940622
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]
   Shah S, 2019, I IEEE EMBS C NEUR E, P1138, DOI [10.1109/ner.2019.8717137, 10.1109/NER.2019.8717137]
   Sneha H.R., P 2 IEEE INT C EL CO, DOI 10.1109/ICECCT.2017.8117872
   Soref R, 2006, IEEE J SEL TOP QUANT, V12, P1678, DOI 10.1109/JSTQE.2006.883151
   Sowjanya K, 2015, IEEE INT ADV COMPUT, P397, DOI 10.1109/IADCC.2015.7154738
   ST Microelectronics, STM32F745XX STM32F74
   ST Microelectronics Inc, STM32F765XX STM32F76
   STMicroelectronics, STM32L073X8 STM32L07
   STMicroelectronics, STM32F215XX STM32F21
   Strielkina A., 2018, CEUR WORKSHOP PROC, V2104, P530
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sun F., P IEEE AS PAC C CIRC, DOI [10.1109/APCCAS.2008.4746128, DOI 10.1109/APCCAS.2008.4746128]
   Sun SL, 2020, IEEE T CYBERNETICS, V50, P3668, DOI 10.1109/TCYB.2019.2950779
   Suresh P., 2020, INT J POWER ELECT DR, V11, P235, DOI [10.11591/ijpeds.v11.i1.pp235-241, DOI 10.11591/IJPEDS.V11.I1.PP235-241]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Tan M, P 36 INT C MACH LEAR, P10691
   Tanaka K, 2020, SYMP HI PER INT, P43, DOI 10.1109/HOTI51249.2020.00021
   Taylor B, 2018, ACM SIGPLAN NOTICES, V53, P31, DOI [10.1145/3211332.3211336, 10.1145/3299710.3211336]
   Tiku S, 2020, J SYST ARCHITECT, V108, DOI 10.1016/j.sysarc.2020.101806
   Tong JYF, 2000, IEEE T VLSI SYST, V8, P273, DOI 10.1109/92.845894
   Tóth B, 2012, J ADV COMPUT INTELL, V16, P327, DOI 10.20965/jaciii.2012.p0327
   Tuama A, 2016, EUR SIGNAL PR CONF, P1183, DOI 10.1109/EUSIPCO.2016.7760435
   Vazquez R, 2019, 2019 TENTH INTERNATIONAL GREEN AND SUSTAINABLE COMPUTING CONFERENCE (IGSC), DOI 10.1109/igsc48788.2019.8957207
   Vhaduri S., 2019, 2019 IEEE INT C HEAL, P1, DOI [1(1.11(19/ICH1.2019.8904563, DOI 10.1109/ICHI.2019.8904563]
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang SQ, 2019, IEEE J SEL AREA COMM, V37, P1205, DOI 10.1109/JSAC.2019.2904348
   Wayne W, 2007, PRAISE HIGH PERFORMA
   Xiong ZH, 2019, IEEE VEH TECHNOL MAG, V14, P44, DOI 10.1109/MVT.2019.2903655
   Yates R., FIXED POINT ARITHMET
   You Y, 2015, J PARALLEL DISTR COM, V76, P16, DOI 10.1016/j.jpdc.2014.09.005
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Yunbin Deng, 2019, Proceedings of the SPIE, V10993, DOI 10.1117/12.2518469
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng ZQ, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P997, DOI 10.1109/ISKE.2008.4731075
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang L, P 2019 IEEE INT C CO, P1, DOI [10.1109/ICCE.2019.8661931, DOI 10.1109/ICCE.2019.8661931]
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zubair M, 2015, INT CONF IT CONVERGE
NR 185
TC 41
Z9 41
U1 17
U2 107
PD JUL
PY 2021
VL 21
IS 13
AR 4412
DI 10.3390/s21134412
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT C
AU Chaudhuri, A
   Talukdar, J
   Su, F
   Chakrabarty, K
AF Chaudhuri, Arjun
   Talukdar, Jonti
   Su, Fei
   Chakrabarty, Krishnendu
GP IEEE
TI Functional Criticality Classification of Structural Faults in AI
   Accelerators
SO 2020 IEEE INTERNATIONAL TEST CONFERENCE (ITC)
SE International Test Conference Proceedings
DT Proceedings Paper
CT IEEE International Test Conference (ITC)
CY NOV 03-05, 2020
CL ELECTR NETWORK
AB The ubiquitous application of deep neural networks (DNNs) has led to a rise in demand for artificial intelligence (AI) accelerators. This paper studies the problem of classifying structural faults in such an accelerator based on their functional criticality. We analyze the impact of stuck-at faults in the processing elements (PEs) of a 128x128 systolic array designed to perform classification on the MNIST dataset using both 32-bit and 16-bit data paths. We present a two-tier machine-learning (ML) based method to assess the functional criticality of these faults. We address the problem of minimizing misclassification by utilizing generative adversarial networks (GANs). The two-tier ML/GAN-based criticality assessment method leads to less than 1% test escapes during functional criticality evaluation.
C1 [Chaudhuri, Arjun; Talukdar, Jonti; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
   [Su, Fei] Intel Corp, Folsom, CA USA.
RP Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
CR [Anonymous], GOOGLE EDGE TPU CORA
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], SYSTEM ARCHITECTURE
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Ernst R, 2016, IEEE DES TEST, V33, P65, DOI 10.1109/MDAT.2016.2594790
   Gebregiorgis A., 2019, ITC
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Liu YD, 2020, IEEE T COMPUT AID D, V39, P1699, DOI 10.1109/TCAD.2019.2925353
   Schutze H., 2006, P 15 ACM INT C INFOR, P662
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
NR 14
TC 11
Z9 11
U1 2
U2 2
PY 2020
DI 10.1109/ITC44778.2020.9325272
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Banerjee, SS
   Kalbarczyk, ZT
   Iyer, RK
AF Banerjee, Subho S.
   Kalbarczyk, Zbigniew T.
   Iyer, Ravishankar K.
GP ACM
TI AcMC<SUP>2</SUP>: Accelerated Markov Chain Monte Carlo for Probabilistic
   Models
SO TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR
   PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV)
DT Proceedings Paper
CT 24th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY APR 13-17, 2019
CL Brown Univ, Providence, RI
HO Brown Univ
DE Accelerator; Markov Chain Monte Carlo; Probabilistic Graphical Models;
   Probabilistic Programming
ID ALGORITHMS; INFERENCE; ARCHITECTURES
AB Probabilistic models (PMs) are ubiquitously used across a variety of machine learning applications. They have been shown to successfully integrate structural prior information about data and effectively quantify uncertainty to enable the development of more powerful, interpretable, and efficient learning algorithms. This paper presents AcMC2, a compiler that transforms PMs into optimized hardware accelerators (for use in FPGAs or ASICs) that utilize Markov chain Monte Carlo methods to infer and query a distribution of posterior samples from the model. The compiler analyzes statistical dependencies in the PM to drive several optimizations to maximally exploit the parallelism and data locality available in the problem. We demonstrate the use of AcMC2 to implement several learning and inference tasks on a Xilinx Virtex-7 FPGA. AcMC2-generated accelerators provide a 47 - 100x improvement in runtime performance over a 6-core IBM Power8 CPU and a 8 - 18x improvement over an NVIDIA K80 GPU. This corresponds to a 753 - 1600x improvement over the CPU and 248 - 463x over the GPU in performance-per-watt terms.
C1 [Banerjee, Subho S.; Kalbarczyk, Zbigniew T.; Iyer, Ravishankar K.] Univ Illinois, Champaign, IL 61820 USA.
RP Banerjee, SS (corresponding author), Univ Illinois, Champaign, IL 61820 USA.
EM ssbaner2@illinois.edu; kalbarcz@illinois.edu; rkiyer@illinois.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Andres B., 2012, ABS12060111 CORR
   Angelino E, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P22
   [Anonymous], 2004, LECT NOTES MONOGR SE, DOI DOI 10.1214/LNMS/1196285403
   [Anonymous], 2017, INT C LEARN REPR ICL
   [Anonymous], 2011, HDB MARKOV CHAIN MON
   [Anonymous], 1987, READINGS COMPUTER VI, DOI DOI 10.1016/B978-0-08-051581-6.50057-X
   [Anonymous], 2013, PROBABILITY STAT PEA
   [Anonymous], 2012, ARXIV12122991
   Appleby A., 2008, MURMURHASH
   Asadi Narges Bani, 2010, 24th ACM International Conference on Supercomputing 2010, P83
   Bachrach J, 2012, DES AUT CON, P1212
   Banerjee S, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.270-035
   Bartholomew-Biggs M, 2000, J COMPUT APPL MATH, V124, P171, DOI 10.1016/S0377-0427(00)00422-2
   Brobbel Matthijs, 2015, CAPI STREAMING FRAME
   Brooks S, 2011, CH CRC HANDB MOD STA, pXIX
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Cao Phuong, 2015, P 2015 S BOOTC SCI S
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D
   De Sa C, 2016, PR MACH LEARN RES, V48
   Esler KP, 2012, COMPUT SCI ENG, V14, P40, DOI 10.1109/MCSE.2010.122
   Fan L, 2000, IEEE ACM T NETWORK, V8, P281, DOI 10.1109/90.851975
   Fifield Jeff, 2016, P 4 INT WORKSH OPENC
   Frey B., 2003, P 19 C UNC ART INT, P257
   Gal Y., 2016, UNCERTAINTY DEEP LEA
   Gonzalez J., 2011, P 14 INT C ARTIFICIA, P324
   Goodfellow I., 2016, DEEP LEARNING VOL, V1
   Goodman N. D., 2008, UAI, P220, DOI DOI 10.5555/3023476.3023503
   Gordon Andrew D, 2014, P FUTURE SOFTWARE EN, P167, DOI DOI 10.1145/2593882.2593900
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Hosseini M., 2017, 2017 IEEE 25 ANN INT, P201
   Huang D, 2017, ACM SIGPLAN NOTICES, V52, P111, DOI [10.1145/3140587.3062375, 10.1145/3062341.3062375]
   Huang ST, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P275, DOI 10.1145/3020078.3021749
   Jin QW, 2009, I C FIELD PROG LOGIC, P73, DOI 10.1109/FPL.2009.5272549
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karkooti M, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P579, DOI 10.1109/ITCC.2004.1286526
   Kim JD, 2012, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE 2012, PVP 2012, VOL 9, P209
   Koeplinger D, 2016, CONF PROC INT SYMP C, P115, DOI 10.1109/ISCA.2016.20
   Koller D., 2009, PROBABILISTIC GRAPHI
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   Ku David C, 2013, HIGH LEVEL SYNTHESIS, V177
   Leimkuhler B., 2004, SIMULATING HAMILTONI, V14
   Lin MJ, 2010, FPGA 10, P73
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Mansinghka V. K., 2014, VENTURE HIGHER ORDER
   Marsaglia G, 2003, J STAT SOFTW, V8, P14
   Martin G, 2009, IEEE DES TEST COMPUT, V26, P18, DOI 10.1109/MDT.2009.83
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   MILCH B, 2004, ICML 2004 WORKSH STA
   Mingas G, 2017, INT J APPROX REASON, V83, P413, DOI 10.1016/j.ijar.2016.10.011
   Mooij JM, 2010, J MACH LEARN RES, V11, P2169
   Paxson V, 1999, COMPUT NETW, V31, P2435, DOI 10.1016/S1389-1286(99)00112-7
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Robert C.P., 2004, MONTE CARLO METHODS
   Salvatier J, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.55
   Strid I, 2010, COMPUT STAT DATA AN, V54, P2814, DOI 10.1016/j.csda.2009.11.019
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Suchard MA, 2010, J COMPUT GRAPH STAT, V19, P419, DOI 10.1198/jcgs.2010.10016
   Terenin Alexander, 2018, STAT COMPUTING
   Varatharajah Y., 2017, ADV NEURAL INFORM PR, P5371
   Vigoda B., 2003, THESIS
   WALKER AJ, 1974, ELECTRON LETT, V10, P127, DOI 10.1049/el:19740097
   Wood F, 2014, JMLR WORKSH CONF PRO, V33, P1024
   Wu Y, 2016, IEEE IMAGE PROC, P3763, DOI 10.1109/ICIP.2016.7533063
NR 67
TC 11
Z9 11
U1 0
U2 0
PY 2019
BP 515
EP 528
DI 10.1145/3297858.3304019
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Famouri, M
   Taheri, M
   Azimifar, Z
AF Famouri, Mahmoud
   Taheri, Mohammad
   Azimifar, Zohreh
TI Fast Linear SVM Validation Based on Early Stopping in Iterative Learning
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
DT Article
DE Support vector machine; cross-validation; early stopping;
   generalization; parameter selection
ID SUPPORT VECTOR MACHINES; CLASSIFICATION; MULTICLASS; SELECTION; SOFTWARE
AB Classification is an important field in machine learning and pattern recognition. Amongst various types of classifiers such as nearest neighbor, neural network and Bayesian classifiers, support vector machine (SVM) is known as a very powerful classifier.
   One of the advantages of SVM in comparison with the other methods, is its efficient and adjustable generalization capability. The performance of SVM classifier depends on its parameters, specially regularization parameter C, that is usually selected by cross-validation. Despite its generalization, SVM suffers from some limitations such as its considerable low speed training phase. Cross-validation is a very time consuming part of training phase, because for any candidate value of the parameter C, the entire process of training and validating must be repeated completely.
   In this paper, we propose a novel approach for early stopping of the SVM learning algorithm. The proposed early stopping occurs by integrating the validation part into the optimization part of the SVM training without losing any generality or degrading performance of the classifier. Moreover, this method can be considered in conjunction with the other available accelerator methods since there is not any dependency between our proposed method and the other accelerator ones, thus no redundancy will happen. Our method was tested and verified on various IJCI repository datasets and the results indicate that this method speeds up the learning phase of SVM without losing any generality or affecting the final model of classifier.
C1 [Famouri, Mahmoud; Taheri, Mohammad; Azimifar, Zohreh] Shiraz Univ, Dept IT Comp Sci & Engn, Sch Elect & Comp Engn, Shiraz, Iran.
RP Azimifar, Z (corresponding author), Shiraz Univ, Dept IT Comp Sci & Engn, Sch Elect & Comp Engn, Shiraz, Iran.
EM famouri@cse.shirazu.ac.ir; taheri@cse.shirazu.ac.ir;
   azimifar@cse.shirazu.ac.ir
CR [Anonymous], 2005, P 6 INT S HUNG RES C
   [Anonymous], LIBSVM LIB SUPPORT V
   [Anonymous], 2010, P 3 WORKSH GEN PURP
   [Anonymous], 2011, P 28 INT C MACHINE L
   Boyd S., 2014, CONVEX OPTIMIZATION
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Frandi E, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413600033
   Fung G, 2003, NEUROCOMPUTING, V55, P39, DOI 10.1016/S0925-2312(03)00379-5
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu QH, 2008, EXPERT SYST APPL, V34, P866, DOI 10.1016/j.eswa.2006.10.043
   Ismael K, 2008, IFMBE PROC, V21, P183
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   Li YH, 2011, PATTERN RECOGN LETT, V32, P1517, DOI 10.1016/j.patrec.2011.04.013
   Mathur A, 2008, IEEE GEOSCI REMOTE S, V5, P241, DOI 10.1109/LGRS.2008.915597
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Scheinberg K, 2006, J MACH LEARN RES, V7, P2237
   Segata N, 2009, LECT NOTES ARTIF INT, V5632, P295, DOI 10.1007/978-3-642-03070-3_22
   Shilton A, 2005, IEEE T NEURAL NETWOR, V16, P114, DOI 10.1109/TNN.2004.836201
   Song XF, 2008, INT J INNOV COMPUT I, V4, P1751
   Su J., 2006, P 23 INT C MACH LEAR
   Tsang IW, 2005, J MACH LEARN RES, V6, P363
   Vapnik V., 1995, NATURE STAT LEARNING
   Yuan GX, 2010, J MACH LEARN RES, V11, P3183
   Zanni L, 2006, J MACH LEARN RES, V7, P1467
   Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072
   Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [DOI 10.1109/CVPR.2006.301, 10.1109/CVPR.2006.301]
NR 29
TC 11
Z9 11
U1 0
U2 7
PD DEC
PY 2015
VL 29
IS 8
AR 1551013
DI 10.1142/S0218001415510131
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Kristensen, AT
   Giterman, R
   Balatsoukas-Stimming, A
   Burg, A
AF Kristensen, Andreas Toftegaard
   Giterman, Robert
   Balatsoukas-Stimming, Alexios
   Burg, Andreas
GP IEEE
TI LUPULUS: A FLEXIBLE HARDWARE ACCELERATOR FOR NEURAL NETWORKS
SO 2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
DT Proceedings Paper
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 04-08, 2020
CL Barcelona, SPAIN
AB Neural networks have become indispensable for a wide range of applications, but they suffer from high computational- and memory-requirements, requiring optimizations from the algorithmic description of the network to the hardware implementation. Moreover, the high rate of innovation in machine learning makes it important that hardware implementations provide a high level of programmability to support current and future requirements of neural networks. In this work, we present a flexible hardware accelerator for neural networks, called Lupulus, supporting various methods for scheduling and mapping of operations onto the accelerator. Lupulus was implemented in a 28nm FD-SOI technology and demonstrates a peak performance of 380GOPS/GHz with latencies of 21.4 ms and 183.6 ms for the convolutional layers of AlexNet and VGG-16, respectively.
C1 [Kristensen, Andreas Toftegaard; Giterman, Robert; Balatsoukas-Stimming, Alexios; Burg, Andreas] Ecole Polytech Fed Lausanne, Telecommun Circuits Lab, Lausanne, Switzerland.
RP Kristensen, AT (corresponding author), Ecole Polytech Fed Lausanne, Telecommun Circuits Lab, Lausanne, Switzerland.
CR Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Desoli G, 2017, ISSCC DIG TECH PAP I, P238, DOI 10.1109/ISSCC.2017.7870349
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2020
BP 1608
EP 1612
DI 10.1109/icassp40776.2020.9054764
WC Acoustics; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kim, M
   Mohanty, A
   Kadetotad, D
   Suda, N
   Wei, LN
   Saseendran, P
   He, XF
   Cao, Y
   Seo, JS
AF Kim, Minkyu
   Mohanty, Abinash
   Kadetotad, Deepak
   Suda, Naveen
   Wei, Luning
   Saseendran, Pooja
   He, Xiaofei
   Cao, Yu
   Seo, Jae-sun
GP IEEE
TI A Real-time 17-Scale Object Detection Accelerator with Adaptive
   2000-Stage Classification in 65nm CMOS
SO 2017 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-31, 2017
CL Baltimore, MD
DE object detection; machine learning; classification; real-time;
   low-power; special-purpose accelerator
AB This paper presents an object detection accelerator that features many-scale (17), many-object (up to 50), multi-class (e.g., face, traffic sign), and high accuracy (average precision of 0.79/0.65 for AFW/BTSD datasets). Employing 10 gradient/color channels, integral features are extracted, and the results of 2,000 simple classifiers for rigid boosted templates are adaptively combined to make a strong classification. By jointly optimizing the algorithm and the hardware architecture, the prototype chip implemented in 65nm CMOS demonstrates real-time object detection of 13-35 frames per second with low power consumption of 22-160mW at 0.58-1.0V supply.
C1 [Kim, Minkyu; Mohanty, Abinash; Kadetotad, Deepak; Saseendran, Pooja; Cao, Yu; Seo, Jae-sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
   [Wei, Luning; He, Xiaofei] Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
   [Suda, Naveen] ARM Inc, San Jose, CA USA.
RP Kim, M (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
EM mkim152@asu.edu
CR Advani S, 2015, I C FIELD PROG LOGIC
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], 2015, IEEE GLOB COMM CONF, DOI DOI 10.1109/GLOCOM.2015.7417362
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2012, IEEE C COMP VIS PATT
   Everingham M., 2012, PASCAL VISUAL OBJECT, DOI DOI 10.1109/HASE.2017.36
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Jeon D., 2015, IEEE S VLSI CIRC
   Kostinger M., 2011, IEEE INT C COMP VIS
   Mathias M., 2014, EUR C COMP VIS ECCV
   Suleiman A., 2015, J SIGNAL PROCESSING, P1
   Takagi K., 2013, IEEE INT C AC SPEECH
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2017
BP 2038
EP 2041
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Steinert, F
   Kreowsky, P
   Wisotzky, EL
   Unger, C
   Stabernack, B
AF Steinert, Fritjof
   Kreowsky, Philipp
   Wisotzky, Eric L.
   Unger, Christian
   Stabernack, Benno
GP IEEE Comp Soc
TI A Hardware/Software Framework for the Integration of FPGA-based
   Accelerators into Cloud Computing Infrastructures
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD 2020)
DT Proceedings Paper
CT 5th IEEE International Conference on Smart Cloud (IEEE SmartCloud) / 5th
   IEEE International Symposium on Reinforcement Learning (IEEE ISRL)
CY NOV 06-08, 2020
CL ELECTR NETWORK
DE Heterogeneous Computing; Accelerator; FPGA; Cloud Computing; Resource
   Management
AB The need for high computing power has increased enormously in recent years, particularly in the field of image signal processing and machine learning applications, very powerful computing systems are required. It has been shown that homogeneous architectures in data centers work very inefficiently regarding these special applications, showing high latency of the response times and providing a very poor power efficiency. In order to integrate FPGA (Field Programming Gate Array)- as well as GPU-based accelerators into cloud computing infrastructures as compute nodes we present a generic hardware/software framework for using heterogeneous computing systems. A real industrial image processing application shows the acceleration achieved.
C1 [Steinert, Fritjof; Kreowsky, Philipp; Wisotzky, Eric L.; Stabernack, Benno] Fraunhofer Inst Telecommun, Heinrich Hertz Inst, Berlin, Germany.
   [Unger, Christian] CPU 24 7 GmbH Potsdam, Potsdam, Germany.
   [Stabernack, Benno] Univ Potsdam, Embedded Syst Architectures Signal Proc, Potsdam, Germany.
RP Steinert, F (corresponding author), Fraunhofer Inst Telecommun, Heinrich Hertz Inst, Berlin, Germany.
EM fritjof.steinert@hhi-extern.fraunhofer.de;
   philipp.kreowsky@hhi.fraunhofer.de; eric.wisotzky@hhi.fraunhofer.de;
   c.unger@cpu-24-7.com; benno.stabernack@hhi.fraunhofer.de
CR ARM Ltd, 2011, AMBA AXI ACE PROT SP
   Blumenthal-Barby DC, 2014, COMPUT GRAPH-UK, V39, P89, DOI 10.1016/j.cag.2013.12.001
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chalamalasetti S. R., 2013, FPGA 13, P245254
   Fahmy SA, 2015, INT CONF CLOUD COMP, P430, DOI 10.1109/CloudCom.2015.60
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Micusik B, 2017, INT J COMPUT VISION, V124, P65, DOI 10.1007/s11263-016-0971-9
   Putnam A, 2015, IEEE MICRO, V35, P10, DOI 10.1109/MM.2015.42
   Seo K., 2014, ADV SCI TECHNOLOGY L, V66, P105
   Shan Y, 2010, FPGA 10, P93
   Silla F, 2016, 2016 2ND IEEE INTERNATIONAL WORKSHOP ON HIGH-PERFORMANCE INTERCONNECTION NETWORKS IN THE EXASCALE AND BIG-DATA ERA (HIPINEB), P41, DOI 10.1109/HIPINEB.2016.8
NR 12
TC 4
Z9 4
U1 0
U2 0
PY 2020
BP 23
EP 28
DI 10.1109/SmartCloud49737.2020.00014
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ham, TJ
   Jung, SJ
   Kim, S
   Oh, YH
   Park, Y
   Song, Y
   Park, JH
   Lee, S
   Park, K
   Lee, JW
   Jeong, DK
AF Ham, Tae Jun
   Jung, Sung Jun
   Kim, Seonghak
   Oh, Young H.
   Park, Yeonhong
   Song, Yoonho
   Park, Jung-Hun
   Lee, Sanghee
   Park, Kyoung
   Lee, Jae W.
   Jeong, Deog-Kyoon
GP IEEE
TI A<SUP>3</SUP>: Accelerating Attention Mechanisms in Neural Networks with
   Approximation
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2020)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 26th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 22-26, 2020
CL San Diego, CA
DE Attention Mechanism; Accelerators; Approximation; Neural Networks;
   Machine Learning; ASIC
AB With the increasing computational demands of neural networks, many hardware accelerators for the neural networks have been proposed. Such existing neural network accelerators often focus on popular neural network types such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs); however, not much attention has been paid to attention mechanisms, an emerging neural network primitive that enables neural networks to retrieve most relevant information from a knowledge-base, external memory, or past states. The attention mechanism is widely adopted by many state-of-the-art neural networks for computer vision, natural language processing, and machine translation, and accounts for a large portion of total execution time. We observe today's practice of implementing this mechanism using matrix-vector multiplication is suboptimal as the attention mechanism is semantically a content-based search where a large portion of computations ends up not being used. Based on this observation, we design and architect A(3), which accelerates attention mechanisms in neural networks with algorithmic approximation and hardware specialization. Our proposed accelerator achieves multiple orders of magnitude improvement in energy efficiency (performance/watt) as well as substantial speedup over the state-of-the-art conventional hardware.
C1 [Ham, Tae Jun; Jung, Sung Jun; Kim, Seonghak; Park, Yeonhong; Song, Yoonho; Park, Jung-Hun; Lee, Sanghee; Lee, Jae W.; Jeong, Deog-Kyoon] Seoul Natl Univ, Seoul, South Korea.
   [Oh, Young H.] Sungkyunkwan Univ, Seoul, South Korea.
   [Park, Kyoung] SK Hynix, Ichon, South Korea.
RP Ham, TJ (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM taejunham@snu.ac.kr; miguel92@snu.ac.kr; ksh1102@snu.ac.kr;
   younghwan@skku.edu; ilil96@snu.ac.kr; yhsong@snu.ac.kr;
   jhpark94@snu.ac.kr; shlee95@snu.ac.kr; kyoung.park@sk.com;
   jaewlee@snu.ac.kr; dkjeong@snu.ac.kr
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2016, ACM SIGDA INT S FIEL
   [Anonymous], INT C ARCH SUPP PROG
   [Anonymous], 2018, ACM SIGDA INT S FIEL
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], INT S COMP ARCH
   [Anonymous], 2016, CORR
   [Anonymous], 2017, ACM T EMBED COMPUT S
   [Anonymous], 2016, EMPIRICAL METHODS NA
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], 2017, INT C LEARN REPR
   [Anonymous], ACM SIGDA INTT S FIE
   [Anonymous], INT S COMP ARCH
   [Anonymous], INSIDE VOLTA WORLDS
   [Anonymous], 2014, ARXIV14105401
   [Anonymous], C EUR CHAPT ASS COMP
   [Anonymous], SKYL SERV MICR INT
   [Anonymous], TENSORFLOW CODE PRET
   [Anonymous], INT XEON GOLD 6128 P
   [Anonymous], DESIGN AUTOMATION TE
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], INT S COMP ARCH
   [Anonymous], ACM SIGKDD INT C KNO
   [Anonymous], 2016, EMPIRICAL METHODS NA
   [Anonymous], 2015, CORR
   [Anonymous], INT C LEARN REPR
   [Anonymous], MEMN2N BABI PYTHON
   [Anonymous], INT C COMP VIS
   [Anonymous], 2016, INT S COMP ARCH
   [Anonymous], INT S COMP ARCH
   [Anonymous], 2017, INT C NEUR INF PROC
   [Anonymous], 2017, INT JOINT C ART INT
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], C EMP METH NAT LANG
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], C N AM CHAPT ASS COM
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], INT C LEARN REPR
   [Anonymous], 2016, INT C LEARN REPR
   [Anonymous], 2016, WORD EMBEDDINGS EXPL
   [Anonymous], 2015, ADV NEURAL INFORM PR
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Devlin J., NAACL HLT, P4171, DOI 10.18653/v1/N19-1423
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2016, INT SYMP MICROARCH
   Lin Z., 2017, INT C LEARN REPR ICL
   Masadeh M, 2019, IEEE ACCESS, V7, P147129, DOI 10.1109/ACCESS.2019.2946513
   Mikolov T., 2013, INT C NEUR INF PROC
   Miller A., 2016, EMPIRICAL METHODS NA
   Mohapatra D, 2011, DES AUT TEST EUROPE, P950
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pennington J, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Popescu-Belis Andrei, 2017, P 8 INT JOINT C NAT, P1015
   Raha A, 2017, IEEE T VLSI SYST, V25, P462, DOI 10.1109/TVLSI.2016.2586379
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Wang B., 2016, ANN M ASS COMP LING
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 71
TC 66
Z9 67
U1 2
U2 8
PY 2020
BP 328
EP 341
DI 10.1109/HPCA47549.2020.00035
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Chen, Y
   Yang, XB
   Li, JH
   Wang, PX
   Qian, YH
AF Chen, Yan
   Yang, Xibei
   Li, Jinhai
   Wang, Pingxin
   Qian, Yuhua
TI Fusing attribute reduction accelerators
SO INFORMATION SCIENCES
DT Article
DE Accelerator; Attribute reduction; Granularity; Rough set
ID ROUGH SET; FEATURE-SELECTION; INFORMATION FUSION; APPROXIMATION;
   GRANULATION; ENTROPY
AB In the fields of rough set and machine learning, attribute reduction has been demonstrated to be effective in removing redundant attributes with clear explanations. Therefore, not only the generalization performances of the derived reducts, but also the efficiencies of searching reducts have drawn much attention. Immediately, various accelerators for quickly deriving reducts have been designed. However, most of the existing solutions merely speed up the procedure of searching reduct from one and only one perspective, it follows that the efficiencies of those accelerators may be further improved with a fusion view. For such a reason, a framework called Fusing Attribute Reduction Accelerators (FARA) is developed. Our framework is specifically characterized by the following three aspects: (1) sample based accelerator, which is realized by gradually reducing the volume of samples based on the mechanism of positive approximation; (2) attribute based accelerator, which is realized by adding multiple qualified attributes into the potential reduct for each iteration; (3) granularity based accelerator, which is realized by ignoring the candidate attributes within coarser granularity. By examining both the efficiencies of the searchings and the effectiveness of the searched reducts, comprehensive experiments over 20 public datasets fairly validated the superiorities of our framework against 5 popular accelerators. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Chen, Yan; Yang, Xibei] Jiangsu Univ Sci & Technol, Sch Comp, Zhenjiang 212100, Jiangsu, Peoples R China.
   [Yang, Xibei] Jiangsu Univ Sci & Technol, Sch Econ & Management, Zhenjiang 212100, Jiangsu, Peoples R China.
   [Li, Jinhai] Kunming Univ Sci & Technol, Data Sci Res Ctr, Kunming 650500, Yunnan, Peoples R China.
   [Li, Jinhai] Kunming Univ Sci & Technol, Fac Sci, Kunming 650500, Yunnan, Peoples R China.
   [Wang, Pingxin] Jiangsu Univ Sci & Technol, Sch Sci, Zhenjiang 212100, Jiangsu, Peoples R China.
   [Qian, Yuhua] Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan 030006, Shanxi, Peoples R China.
   [Chen, Yan; Yang, Xibei] Shanxi Univ, Intelligent Informat Proc Key Lab Shanxi Prov, Taiyuan 030006, Shanxi, Peoples R China.
   [Yang, Xibei; Wang, Pingxin] Zhejiang Ocean Univ, Key Lab Oceanog Big Data Min & Applicat Zhejiang, Zhoushan 316022, Zhejiang, Peoples R China.
RP Yang, XB (corresponding author), Jiangsu Univ Sci & Technol, Sch Comp, Zhenjiang 212100, Jiangsu, Peoples R China.
EM chenyan@stu.just.edu.cn; jsjxy_yxb@just.edu.cn; jhlixjtu@163.com;
   jinchengqyh@126.com
CR [Anonymous], 2016, APPL SOFT COMPUT, DOI DOI 10.1016/j.asoc.2016.04.003
   Bania RK, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105122
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Chen Y, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107326
   Chen Y, 2020, INFORM SCIENCES, V535, P64, DOI 10.1016/j.ins.2020.05.010
   Dai JH, 2013, INFORM SCIENCES, V240, P72, DOI 10.1016/j.ins.2013.03.045
   Ding WP, 2021, IEEE TETCI, V5, P130, DOI 10.1109/TETCI.2018.2869919
   Fan J, 2017, INFORM SCIENCES, V397, P15, DOI 10.1016/j.ins.2017.02.032
   Fujita H, 2019, IEEE T CYBERNETICS, V49, P1835, DOI 10.1109/TCYB.2018.2815178
   Grzegorowski M, 2019, INFORM SCIENCES, V499, P25, DOI 10.1016/j.ins.2019.05.041
   Hu QH, 2008, EXPERT SYST APPL, V34, P866, DOI 10.1016/j.eswa.2006.10.043
   Janusz A, 2014, APPL ARTIF INTELL, V28, P220, DOI 10.1080/08839514.2014.883902
   Jiang ZH, 2020, INT J APPROX REASON, V119, P122, DOI 10.1016/j.ijar.2019.12.013
   Jiang ZH, 2019, KNOWL-BASED SYST, V177, P145, DOI 10.1016/j.knosys.2019.04.014
   Benítez-Caballero MJ, 2020, FUZZY SET SYST, V391, P117, DOI 10.1016/j.fss.2019.11.009
   Benítez-Caballero MJ, 2020, INT J COMPUT MATH, V97, P387, DOI 10.1080/00207160.2019.1613530
   Benítez-Caballero MJ, 2018, INFORM SCIENCES, V435, P26, DOI 10.1016/j.ins.2017.12.037
   Li JH, 2016, KNOWL-BASED SYST, V91, P152, DOI 10.1016/j.knosys.2015.07.024
   Liang JY, 2004, INT J UNCERTAIN FUZZ, V12, P37, DOI 10.1142/S0218488504002631
   Liu D, 2015, KNOWL-BASED SYST, V73, P81, DOI 10.1016/j.knosys.2014.09.008
   Liu FL, 2018, INFORM SCIENCES, V448, P1, DOI 10.1016/j.ins.2018.03.030
   Liu Y, 2014, INFORM SCIENCES, V271, P65, DOI 10.1016/j.ins.2014.02.093
   Pawlak Z., 1991, ROUGH SETS THEORETIC, DOI 10.1007/978-94-011-3534-4
   Pedrycz W, 2015, KNOWL-BASED SYST, V80, P98, DOI 10.1016/j.knosys.2014.12.030
   Qian YH, 2018, INT J APPROX REASON, V97, P38, DOI 10.1016/j.ijar.2018.01.008
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Qin KY, 2019, INT J MACH LEARN CYB, V10, P2837, DOI 10.1007/s13042-018-00907-0
   Rao XS, 2020, KNOWL-BASED SYST, V200, DOI 10.1016/j.knosys.2020.106014
   Sang BB, 2020, INFORM SCIENCES, V541, P475, DOI 10.1016/j.ins.2020.06.051
   She YH, 2019, INT J MACH LEARN CYB, V10, P3263, DOI 10.1007/s13042-019-01015-3
   Slezak D, 2002, FUND INFORM, V53, P365
   Sowkuntla P, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105104
   Stawicki S, 2017, INT J APPROX REASON, V84, P75, DOI 10.1016/j.ijar.2017.02.007
   Sun BZ, 2016, SOFT COMPUT, V20, P3617, DOI 10.1007/s00500-015-1721-6
   Tsang ECC, 2019, INT J MACH LEARN CYB, V10, P1407, DOI 10.1007/s13042-018-0822-9
   Tsang ECC, 2016, INT J MACH LEARN CYB, V7, P1, DOI 10.1007/s13042-014-0232-6
   Wang YB, 2019, INT J MACH LEARN CYB, V10, P3619, DOI 10.1007/s13042-019-00948-z
   Wei W, 2019, INFORM FUSION, V48, P107, DOI 10.1016/j.inffus.2018.08.007
   Xu SP, 2016, KNOWL-BASED SYST, V104, P52, DOI 10.1016/j.knosys.2016.04.012
   Yang L, 2020, INT J APPROX REASON, V122, P47, DOI 10.1016/j.ijar.2020.04.003
   Yang XB, 2019, INT J APPROX REASON, V105, P112, DOI 10.1016/j.ijar.2018.11.010
   Yao YY, 2006, LECT NOTES ARTIF INT, V4062, P297
   Zhang X, 2016, PATTERN RECOGN, V56, P1, DOI 10.1016/j.patcog.2016.02.013
   Zhang XQ, 2020, INT J MACH LEARN CYB, V11, P1095, DOI 10.1007/s13042-020-01101-x
   Zhu PF, 2017, PATTERN RECOGN, V66, P364, DOI 10.1016/j.patcog.2017.01.016
NR 45
TC 15
Z9 15
U1 4
U2 17
PD MAR
PY 2022
VL 587
BP 354
EP 370
DI 10.1016/j.ins.2021.12.047
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Longchar, I
   Das, P
   Kapoor, HK
AF Longchar, Imlijungla
   Das, Palash
   Kapoor, Hemangee K.
GP IEEE
TI ZaLoBI: Zero avoiding Load Balanced Inference accelerator
SO PROCEEDINGS OF THE 2022 IFIP/IEEE 30TH INTERNATIONAL CONFERENCE ON VERY
   LARGE SCALE INTEGRATION (VLSI-SOC)
DT Proceedings Paper
CT 30th IFIP/IEEE International Conference on Very Large Scale Integration
   (VLSI-SoC)
CY OCT 03-05, 2022
CL Univ Patras, Patras, GREECE
HO Univ Patras
DE Convolutional Neural Network; Accelerator architecture; Sparsity; Load
   balance aware solution
AB Convolutional neural networks are prevalent machine learning tools used in computer vision. Their ubiquitous use and high compute requirement have given rise to the design and development of accelerators for the same. Among several approaches to improve the performance of these accelerators, exploiting data sparsity has become very popular. Along similar lines, this paper proposes a design that skips the computation of zero-valued data operands and achieves better speedup. The savings in zero-valued computations also results in energy savings. The proposed accelerator exploits two levels of data parallelism to distribute work across multiple processing elements (PEs). The random distribution of zero values results in certain PEs getting idle due to the skipping of computations, thus creating load imbalance in the system. To address this issue, we extend our contribution in performing load balancing by dynamically scheduling tasks to the idle PEs. Our zero avoiding load-balanced accelerator (ZaLoBI) achieves around 76% and 5.57% speedup over the respective baselines and also outperforms the state-of-the-art works while saving energy.
C1 [Longchar, Imlijungla; Das, Palash; Kapoor, Hemangee K.] IIT Guwahati, Dept CSE, Gauhati, India.
RP Longchar, I (corresponding author), IIT Guwahati, Dept CSE, Gauhati, India.
EM ilongchar@iitg.ac.in; palash.das@iitg.ac.in; hemangee@iitg.ac.in
CR ALBERICIO J, 2016, ACM INT C ARCH SUPP, P1, DOI DOI 10.1109/ISCA.2016.11
   Azarkhish Erfan, 2018, IEEE Transactions on Parallel and Distributed Systems, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Das P, 2021, IEEE T COMPUT AID D, V40, P1573, DOI 10.1109/TCAD.2020.3022330
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   KIM D, 2016, ACM SIGARCH COMPUTER, P380, DOI DOI 10.1109/ISCA.2016.41
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lee BC, 2009, CONF PROC INT SYMP C, P2, DOI 10.1145/1555815.1555758
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Sen S, 2019, IEEE T COMPUT, V68, P912, DOI 10.1109/TC.2018.2879434
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang JF, 2021, IEEE J SOLID-ST CIRC, V56, P636, DOI 10.1109/JSSC.2020.3043870
NR 16
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/VLSI-SoC54400.2022.9939591
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xu, SY
   Schafer, BC
AF Xu, Siyuan
   Schafer, Benjamin Carrion
GP IEEE
TI Approximating Behavioral HW Accelerators through Selective Partial
   Extractions onto Synthesizable Predictive Models
SO 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 38th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 04-10, 2019
CL Westminster, CO
DE Approximate Computing; Machine Learning; High-level Synthesis; Hardware
   Accelerators
AB This work presents a method to selectively extract portions of a behavioral description to be synthesized as a hardware accelerator using High-Level Synthesis (HLS) onto different predictive models in order to trade-off the accuracy of the accelerators' outputs with area and power. Because the main aim of this work is to synthesize the newly approximated behavioral description, we investigate the use of different predictive models, mainly linear regression (LR) and multi-layer perceptron (MLP), highlighting the trade-offs of using one over the other. In addition, we further extend the search space by reducing the precision of the predictive models' coefficients, thus, leading to a wider range of solutions. Experimental results using a variety of benchmarks from different domains show that our proposed method works well compared to another state of the art approximate solution.
C1 [Xu, Siyuan; Schafer, Benjamin Carrion] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
RP Xu, SY (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
EM siyuan.xu@utdallas.edu; schaferb@utdallas.edu
CR [Anonymous], 1966, WILEY SERIES PROBABI
   [Anonymous], APPL CONVERSION RES
   [Anonymous], 2014, PROC DESIGN AUTOM TE
   [Anonymous], 2015 IEEE 21 INT S H
   [Anonymous], P 2012 ACM IEEE INT
   [Anonymous], 2009, INT PARALL DISTRIB P
   [Anonymous], MICRO IEEE
   [Anonymous], 2018 8 INT C COMP KN
   [Anonymous], 2016, ACM COMPUT SURV, DOI DOI 10.1145/2893356
   [Anonymous], TRANS EVOL COMP
   Baek W, 2010, ACM SIGPLAN NOTICES, V45, P198, DOI 10.1145/1809028.1806620
   Bhattacharya B, 2002, AM STAT, V56, P202, DOI 10.1198/000313002146
   Chau TCP, 2015, ACM T RECONFIG TECHN, V7, DOI 10.1145/2629469
   Cong J, 2016, ASIA S PACIF DES AUT, P503, DOI 10.1109/ASPDAC.2016.7428062
   Dosselmann R., 2005, CAN C EL COMP ENG SA, P1906
   Grigorian B, 2014, PR IEEE COMP DESIGN, P317, DOI 10.1109/ICCD.2014.6974700
   Imani M, 2016, DES AUT TEST EUROPE, P1327
   Khudia DS, 2016, IEEE DES TEST, V33, P43, DOI 10.1109/MDAT.2015.2501306
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Li C., 2015, 52 ACMIEEE DESIGN AU, P1
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Oliveira GF, 2018, DES AUT CON, DOI 10.1145/3195970.3196043
   Schafer BC, 2014, IEEE EMBED SYST LETT, V6, P53, DOI 10.1109/LES.2014.2320556
   Sidiroglou-Douskos S., 2011, 19 ACM SIGSOFT, P124, DOI DOI 10.1145/2025113.2025133
   Tian Y, 2017, ICCAD-IEEE ACM INT, P438, DOI 10.1109/ICCAD.2017.8203810
   Wu Y, 2017, ASIA S PACIF DES AUT, P163, DOI 10.1109/ASPDAC.2017.7858314
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
   Xu SY, 2017, IEEE T VLSI SYST, V25, P3077, DOI 10.1109/TVLSI.2017.2735299
NR 29
TC 0
Z9 0
U1 0
U2 1
PY 2019
DI 10.1109/iccad45719.2019.8942119
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Wan, JY
   Jiao, Y
AF Wan, Jinyu
   Jiao, Yi
TI Machine learning enabled fast evaluation of dynamic aperture for storage
   ring accelerators
SO NEW JOURNAL OF PHYSICS
DT Article
DE storage ring; dynamic aperture; motion stability; machine learning;
   complex dynamical system
ID SCIENCE; PHYSICS; BEAM
AB For any storage ring-based large-scale scientific facility, one of the most important performance parameters is the dynamic aperture (DA), which measures the motion stability of charged particles in a global manner. To date, long-term tracking-based simulation is regarded as the most reliable method to calculate DA. However, numerical tracking may become a significant issue, especially when a plethora of candidate designs of a storage ring need to be evaluated. In this paper, we present a novel machine learning-based method, which can reduce the computation cost of DA tracking by approximately one order of magnitude, while keeping sufficiently high evaluation accuracy. Moreover, we demonstrate that this method is independent of concrete physical models of a storage ring. This method has the potential to be applied to similar problems of identifying irregular motions in other complex dynamical systems.
C1 [Wan, Jinyu; Jiao, Yi] Chinese Acad Sci, Inst High Energy Phys, Key Lab Particle Accelerat Phys & Technol, Beijing 100049, Peoples R China.
   [Wan, Jinyu; Jiao, Yi] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RP Jiao, Y (corresponding author), Chinese Acad Sci, Inst High Energy Phys, Key Lab Particle Accelerat Phys & Technol, Beijing 100049, Peoples R China.; Jiao, Y (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM jiaoyi@ihep.ac.cn
CR [Anonymous], MACH LEARN
   [Anonymous], 2018, PHYS REV D, DOI [DOI 10.1103/PHYSREVD.98.030001, 10.1103/PhysRevD.98.030001, DOI 10.1103/PhysRevD.98.030001]
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Bartolini R, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.054003
   BAZZANI A, 1988, NUOVO CIMENTO B, V102, P51, DOI 10.1007/BF02728793
   Benedikt M, 2019, NAT REV PHYS, V1, P238, DOI 10.1038/s42254-019-0048-0
   Biasci J. C., 2014, Synchrotron Radiation News, V27, P8, DOI 10.1080/08940886.2014.970931
   Borland M., 2000, LS287 ADV PHOT SOURC, VLS-287
   Cai Y., 1995, Proceedings of the 1995 Particle Accelerator Conference (Cat. No.95CH35843), P576, DOI 10.1109/PAC.1995.504724
   Cai YH, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.054002
   Chao A.W., 1999, HDB ACCELERATOR PHYS
   Chao A.W., 1991, P 1991 PART ACC C SA, P336
   Chen JH, 2019, NUCL INSTRUM METH A, V920, P1, DOI 10.1016/j.nima.2018.12.009
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chollet F., 2015, KERAS
   Clemens H., 2017, NEUTRONS SYNCHROTRON, P1, DOI [10.1002/9783527684489.ch1, DOI 10.1002/9783527684489.CH1]
   COURANT ED, 1958, ANN PHYS-NEW YORK, V3, P1, DOI 10.1016/0003-4916(58)90012-5
   Danilov V, 2010, PHYS REV SPEC TOP-AC, V13, DOI 10.1103/PhysRevSTAB.13.084002
   DOUGLAS DR, 1983, IEEE T NUCL SCI, V30, P2442, DOI 10.1109/TNS.1983.4332841
   DRAGT AJ, 1988, ANNU REV NUCL PART S, V38, P455, DOI 10.1146/annurev.nucl.38.1.455
   Duan Z., 2018, P 9 INT PART ACC C V, P4182
   Eriksson M, 2014, J SYNCHROTRON RADIAT, V21, P837, DOI 10.1107/S1600577514019286
   FROESCHLE C, 1984, CELESTIAL MECH, V34, P95, DOI 10.1007/BF01235793
   Grote H., 1989, EMPHPROC 1989 IEEE P, P1292
   Hemsing E, 2014, REV MOD PHYS, V86, P897, DOI 10.1103/RevModPhys.86.897
   Jiao Y., 2018, P IPAC 18, P1363, DOI [10.18429/JACoW-IPAC2018-TUPMF049, DOI 10.18429/JACOW-IPAC2018-TUPMF049]
   Jiao Y, 2020, RADIAT DETECT TECHNO, V4, P415, DOI 10.1007/s41605-020-00189-7
   Jiao Y, 2018, J SYNCHROTRON RADIAT, V25, P1611, DOI 10.1107/S1600577518012110
   Jiao Y, 2017, CHINESE PHYS C, V41, DOI 10.1088/1674-1137/41/2/027001
   Jiao Y, 2016, CHINESE PHYS C, V40, DOI 10.1088/1674-1137/40/7/077002
   Kranjcevic M, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.014601
   LASKAR J, 1992, PHYSICA D, V56, P253, DOI 10.1016/0167-2789(92)90028-L
   Leemann SC, 2018, NUCL INSTRUM METH A, V883, P33, DOI 10.1016/j.nima.2017.11.072
   Li YJ, 2021, NUCL INSTRUM METH A, V988, DOI 10.1016/j.nima.2020.164936
   Lippmann R. P., 1987, IEEE ASSP Magazine, V4, P4, DOI 10.1145/44571.44572
   Litvinov YA., 2013, NUCL INSTRUM METHO B, V317, P603, DOI [10.1016/j.nimb.2013.07.025, DOI 10.1016/J.NIMB.2013.07.025]
   Meirer F, 2018, NAT REV MATER, V3, P324, DOI 10.1038/s41578-018-0044-5
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   POLLOCK RE, 1991, ANNU REV NUCL PART S, V41, P357
   SCANDALE W, 1995, AIP CONF PROC, P52, DOI 10.1063/1.47306
   Schmidt F., 1994, SIXTRACK VERSION 1 2
   Schneider JR, 2010, REV ACCEL SCI TECH, V3, P13, DOI 10.1142/S1793626810000348
   Shiltsev V, 2021, REV MOD PHYS, V93, DOI 10.1103/RevModPhys.93.015006
   Song MH, 2020, NUCL INSTRUM METH A, V976, DOI 10.1016/j.nima.2020.164273
   Steier C, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.056506
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tao Y., 2019, SYNCHROTRON RAD NEWS, V32, P40
   Terebilo A., 2001, SLACPUB8732
   Wan JY, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.081601
   Wan JY, 2019, NUCL INSTRUM METH A, V946, DOI 10.1016/j.nima.2019.162683
   Wang F., ARXIV191014220
   Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807
   Wu J., 2017, P 13 S ACC PHYS JISH, P43
   Yang PH, 2019, NUCL INSTRUM METH A, V943, DOI 10.1016/j.nima.2019.162506
NR 54
TC 2
Z9 2
U1 4
U2 13
PD JUN 1
PY 2022
VL 24
IS 6
AR 063030
DI 10.1088/1367-2630/ac77ac
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Zacharopoulos, G
   Barbon, A
   Ansaloni, G
   Pozzi, L
AF Zacharopoulos, Georgios
   Barbon, Andrea
   Ansaloni, Giovanni
   Pozzi, Laura
BE Smari, WW
   Zinedine, K
TI Machine Learning Approach for Loop Unrolling Factor Prediction in High
   Level Synthesis
SO PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING
   & SIMULATION (HPCS)
DT Proceedings Paper
CT International Conference on High Performance Computing and Simulation
   (HPCS)
CY JUL 16-20, 2018
CL orelans, FRANCE
DE Loop Unrolling; Machine Learning; High Level Synthesis;
   Hardware/Software Co-design; Customizable Processors; ASIPs
AB High Level Synthesis development flows rely on user-defined directives to optimize the hardware implementation of digital circuits. Nevertheless, the most beneficial directive values are hard to predict, and exhaustive explorations are infeasible even for moderately complex designs. Focusing on the Loop Unrolling directive, we herein address this challenge by proposing a novel Machine Learning methodology, able to jointly forecast the optimal loop unrolling factors for all the loops in a target application. We showcase that our method results in a better prediction score (up to 63%) and a reduced convergence time compared to other state-of-the-art approaches. Our method achieves 90% of the speedup that can be obtained (with a perfect a-priori knowledge of optimal loop unrolling factors) when synthesizing the computational hotspots of each considered benchmark as hardware accelerators.
C1 [Zacharopoulos, Georgios; Barbon, Andrea; Ansaloni, Giovanni; Pozzi, Laura] Univ Svizzera Italiana, Fac Informat, Lugano, Switzerland.
RP Zacharopoulos, G (corresponding author), Univ Svizzera Italiana, Fac Informat, Lugano, Switzerland.
EM georgios.zacharopoulos@usi.ch; andrea.barbon@usi.ch;
   giovanni.ansaloni@usi.ch; laura.pozzi@usi.ch
CR Agakov F, 2006, INT SYM CODE GENER, P295
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   Hara Y, 2008, IEEE INT SYMP CIRC S, P1192
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kulkarni S, 2012, ACM SIGPLAN NOTICES, V47, P147, DOI 10.1145/2398857.2384628
   Kurra S, 2007, DES AUT TEST EUROPE, P391
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Liu HY, 2013, DES AUT CON
   Mariani G, 2012, IEEE T COMPUT AID D, V31, P740, DOI 10.1109/TCAD.2011.2177457
   Monsifrot A, 2002, LECT NOTES ARTIF INT, V2443, P41
   Ozisikyilmaz B, 2008, DES AUT CON, P966
   Palermo G, 2009, IEEE T COMPUT AID D, V28, P1816, DOI 10.1109/TCAD.2009.2028681
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Stephenson M, 2005, INT SYM CODE GENER, P123, DOI 10.1109/CGO.2005.29
   Villarreal J, 2010, ANN IEEE SYM FIELD P, P127, DOI 10.1109/FCCM.2010.28
   Xilinx, 2017, VIV HIGH LEV SYNTH
   Xydis S, 2013, DES AUT TEST EUROPE, P659
   Zuluaga M, 2012, ACM SIGPLAN NOTICES, V47, P119, DOI 10.1145/2345141.2248436
NR 20
TC 11
Z9 11
U1 0
U2 1
PY 2018
BP 91
EP 97
DI 10.1109/HPCS.2018.00030
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chaudhuri, A
   Liu, CS
   Fan, XX
   Chakrabarty, K
AF Chaudhuri, Arjun
   Liu, Chunsheng
   Fan, Xiaoxin
   Chakrabarty, Krishnendu
GP IEEE
TI C-Testing of AI Accelerators
SO 2020 IEEE 29TH ASIAN TEST SYMPOSIUM (ATS)
SE Asian Test Symposium Proceedings
DT Proceedings Paper
CT 29th IEEE Asian Test Symposium (ATS)
CY NOV 22-25, 2020
CL ELECTR NETWORK
DE AI accelerator; C-testing; reconfigurable scan
AB Accelerators for machine learning (AI) inferencing applications are homogeneous designs composed of identical cores. Each core, or processing element (PE), contains multiply-and-accumulate units, control logic, and registers for storing and forwarding weights and activations. Testing homogeneous array-based AI accelerator chips by running automatic test pattern generation (ATPG) at the array level results in a high CPU time and pattern count. We propose a constant-testable (C-testable) method for test generation at the PE level such that the ATPG effort does not increase with the number of PEs. Our results show that, compared to the traditional array-level testing, the proposed method achieves up to 4.2x (3.5x), 1530x (2388x), and 170x (142x) reduction in the test pattern count, ATPG runtime, and test cycle count, respectively, for stuck-at (transition) faults in a 256 x 256 array, while preserving the test coverage. A reconfigurable scan architecture is introduced to enable C-testing for the entire accelerator array.
C1 [Chaudhuri, Arjun; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
   [Liu, Chunsheng; Fan, Xiaoxin] Alibaba Grp Inc, Sunnyvale, CA USA.
RP Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
CR Chen Y., 2020, SURVEY ACCELERATOR A
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Haj-Ali A., 2019, ARXIV191109925
   Han T, 2015, IEEE T VLSI SYST, V23, P1439, DOI 10.1109/TVLSI.2014.2341674
   Jiang LJ, 2017, PROC INT CONF PARAL, P422, DOI 10.1109/ICPP.2017.51
   Jiao Y., 2020, INT SOL STAT CIRC C
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Knowles M., 2018, WHITE PAPER MENTOR S
   Liu X, 2016, 2016 IEEE 25TH NORTH ATLANTIC TEST WORKSHOP (NATW), P12, DOI 10.1109/NATW.2016.10
   Marinissen E. J., 1999, International Test Conference 1999. Proceedings (IEEE Cat. No.99CH37034), P616, DOI 10.1109/TEST.1999.805786
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Rajski J, 2002, INT TEST CONF P, P301, DOI 10.1109/TEST.2002.1041773
   Ramdas A, 2013, IEEE T COMPUT AID D, V32, P1124, DOI 10.1109/TCAD.2013.2245376
   Samajdar Ananda, 2018, SCALE SIM SYSTOLIC C
   Sharma M., 2011, Proceedings of the 2011 IEEE International Test Conference (ITC), P1, DOI 10.1109/TEST.2011.6139171
   Singhal R., 2019, WHITE PAPER MENTOR S
   Sun BH, 2018, IEEE COMPUT SOC CONF, P1758, DOI 10.1109/CVPRW.2018.00219
   Whetsel L., 2005, US Patent App, Patent No. [11/051,696, 11051696]
   Wu YJ, 2003, IEEE T COMPUT AID D, V22, P327, DOI 10.1109/TCAD.2002.807889
NR 20
TC 8
Z9 8
U1 0
U2 2
PY 2020
BP 18
EP 23
DI 10.1109/ats49688.2020.9301581
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Chen, SY
   Zhou, ZQ
   Ha, YJ
AF Chen, Shaoyi
   Zhou, Zhiqi
   Ha, Yajun
GP IEEE
TI An Ultra Energy Efficient Streaming-based FPGA Accelerator for
   Lightweight Neural Network
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS 22)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-JUN 01, 2022
CL Austin, TX
DE Accelerator architecture; object detection; fieldprogrammable gate
   array(FPGA)
AB Convolutional Neural Networks (CNN) is widely applied in modern machine learning and pattern recognition area. Streaming hardware accelerator is an efficient design that reduces power dissipation by lowering off-chip memory access. Streaming architecture requires putting the entire network onchip, which is a challenging task for resource-constrained embedded systems. This paper presents a streaming hardware accelerator to implement SkyNet, a lightweight neural network to address real-time object detection. The net is retrained and quantized to a very low bit in order to put all the weights into the on-chip BRAMs. We designed a highly balanced pipeline based on each layer's calculation to improve resource utilization. We demonstrate the streaming-based accelerator on the Ultra96v2 board and achieve a throughput of 536 frames per second (FPS) at 333MHz and intersection over Union (IoU) of 73.1% on the DAC-SDC dataset. The overall computational efficiency of our accelerator is 98%. Compared to the state-of-the-art, our work achieves 2.5x throughput, 2.7x energy efficiency.
C1 [Chen, Shaoyi; Zhou, Zhiqi; Ha, Yajun] ShanghaiTech Univ, Sch Informat & Sci Technol, Shanghai, Peoples R China.
   [Chen, Shaoyi] Chinese Acad Sci, Shanghai Inst Tech Phys, Beijing, Peoples R China.
   [Ha, Yajun] Shanghai Engn Res Ctr Energy Efficient & Custom A, Shanghai, Peoples R China.
   [Chen, Shaoyi; Zhou, Zhiqi] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Ha, YJ (corresponding author), ShanghaiTech Univ, Sch Informat & Sci Technol, Shanghai, Peoples R China.; Ha, YJ (corresponding author), Shanghai Engn Res Ctr Energy Efficient & Custom A, Shanghai, Peoples R China.
EM chenshy2@shanghaitech.edu.cn; zhouzq@shanghaitech.edu.cn;
   hayj@shanghaitech.edu.cn
CR [Anonymous], 2017, DEEP LEARNING INT8 O
   Chen YH, 2020, INT SOC DESIGN CONF, P189, DOI 10.1109/ISOCC50952.2020.9333049
   D. A. Conference, 2021, 2021 DAC SDC CONT RE
   Ding R., 2019, P 2019 IEEE INT C EL, P1
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Ge Z., 2021, ARXIV
   Lee S, 2019, IEEE T COMPUT AID D, V38, P888, DOI 10.1109/TCAD.2018.2824280
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Ye Liu, 2020, Proceedings of the 2020 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA), P61, DOI 10.1109/ICTA50426.2020.9331957
   Zhang Xiaofan, 2019, ARXIV190909709
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
NR 12
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 3111
EP 3114
DI 10.1109/ISCAS48785.2022.9937510
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, Y
   Shen, J
   Xu, Z
   Qiu, SK
   Chen, XH
AF Zhang, Yang
   Shen, Jie
   Xu, Zhen
   Qiu, Shikai
   Chen, Xuhao
GP IEEE Comp Soc
TI Architectural Implications in Graph Processing of Accelerator with
   Gardenia Benchmark Suite
SO 2019 IEEE INTL CONF ON PARALLEL & DISTRIBUTED PROCESSING WITH
   APPLICATIONS, BIG DATA & CLOUD COMPUTING, SUSTAINABLE COMPUTING &
   COMMUNICATIONS, SOCIAL COMPUTING & NETWORKING
   (ISPA/BDCLOUD/SOCIALCOM/SUSTAINCOM 2019)
SE IEEE International Symposium on Parallel and Distributed Processing with
   Applications
DT Proceedings Paper
CT IEEE Int Conf on Parallel and Distributed Processing with Applications,
   Big Data and Cloud Computing, Sustainable Computing and Communications,
   Social Computing and Networking (ISPA/BDCloud/SocialCom/SustainCom)
CY DEC 16-18, 2019
CL Xiamen, PEOPLES R CHINA
DE benchmark suite; performance measurement; massive multithreading; graph
   analytics
ID ALGORITHMS; FRAMEWORK
AB Existing generic benchmarks for accelerators (e.g. Parboil and Rodinia) have focused on high performance computing (HPC) applications which have limited control flows and data irregularity. Previous available graph analytics benchmark suites include straightforward implemented workloads which do not employ up-to-date optimization techniques and thus have quite different behaviors from real-world applications. This paper first briefly presents and characterizes the Graph Analytics Repository for Designing Next-generation Accelerators (GARDENIA), which is a benchmark suite for studies of irregular algorithms on various massively parallel accelerators. It includes emerging irregular big-data and machine learning applications, in which mimic massively multithreaded programs deployed on not only datacenters but also hand-on devices. Then we characterize Nvidia GPU with GARDENIA, covering a wide spectrum of metrics such as parallelization, cache locality, off-chip traffic and irregularity. Based on the characterization on Nvidia GPU, we unveil the performance bottlenecks of the current mainstream accelerator and give architectural insights for building high performance and energy-efficient domain-specific accelerators for graph applications.
C1 [Zhang, Yang; Shen, Jie; Xu, Zhen; Qiu, Shikai] Natl Univ Def Technol, Dept Comp Sci & Technol, Changsha, Peoples R China.
   [Chen, Xuhao] Univ Texas Austin, Inst Computat Engn & Sci, Austin, TX 78712 USA.
RP Zhang, Y (corresponding author), Natl Univ Def Technol, Dept Comp Sci & Technol, Changsha, Peoples R China.
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   [Anonymous], P IEEE INT PAR DISTR
   [Anonymous], 1999, TECH REP
   [Anonymous], 2013, KOBLENZ NETWORK COLL
   [Anonymous], 2014, CUSP GENERIC PARALLE
   Baxter S., 2016, MODERNGPU 2 0
   Beamer S, 2012, INT CONF HIGH PERFOR
   Beamer S, 2015, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2015.12
   Beamer Scott, 2015, CORR
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Burtscher M., 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P141, DOI 10.1109/IISWC.2012.6402918
   Che S, 2013, I S WORKL CHAR PROC, P185, DOI 10.1109/IISWC.2013.6704684
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen XH, 2014, INT SYMP MICROARCH, P343, DOI 10.1109/MICRO.2014.11
   Davidson A, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.45
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Ham TJ, 2016, INT SYMP MICROARCH
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hong SP, 2011, ACM SIGPLAN NOTICES, V46, P267, DOI 10.1145/2038037.1941590
   Khorasani Farzad, 2014, P 23 INT S HIGH PERF, P239, DOI DOI 10.1145/2600212.2600227
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Leskovec J., 2013, SNAP STANFORD NETWOR
   Li P., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534146
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Low Yucheng, 2010, UNCERTAINTY ARTIFICI
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167, DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184]
   McLaughlin A, 2014, INT CONF HIGH PERFOR, P572, DOI 10.1109/SC.2014.52
   Merrill D, 2012, ACM SIGPLAN NOTICES, V47, P117, DOI 10.1145/2370036.2145832
   Merrill Duane, 2015, NVIDIA RES
   Meyer U, 2003, J ALGORITHMS, V49, P114, DOI 10.1016/S0196-6774(03)00076-2
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nai LF, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807626
   Nasre R, 2013, INT PARALL DISTRIB P, P463, DOI 10.1109/IPDPS.2013.28
   Nasre R, 2013, ACM SIGPLAN NOTICES, V48, P147, DOI 10.1145/2517327.2442531
   Nobari S, 2012, ACM SIGPLAN NOTICES, V47, P205, DOI 10.1145/2370036.2145842
   NVIDIA, 2016, CUSPARSE LIB
   NVIDIA, 2016, CUDNN LIB
   NVIDIA, 2016, NVGRAPH LIB
   Ozdal MM, 2016, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2016.24
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI DOI 10.1145/2485922.2485925
   Sengupta D, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807655
   Shun JL, 2013, ACM SIGPLAN NOTICES, V48, P135, DOI 10.1145/2517327.2442530
   Slota GM, 2015, INT PARALL DISTRIB P, P17, DOI 10.1109/IPDPS.2015.54
   Stratton J A, 2020, CTR RELIABLE HIGH PE
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Xie XL, 2017, HPDC'17: PROCEEDINGS OF THE 26TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P79, DOI 10.1145/3078597.3078602
   Zhong JL, 2014, IEEE T PARALL DISTR, V25, P1543, DOI 10.1109/TPDS.2013.111
NR 48
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 1329
EP 1339
DI 10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00191
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Moss, A
   Lee, H
   Xun, L
   Min, CH
   Kawsar, F
   Montanari, A
AF Moss, Arthur
   Lee, Hyunjong
   Xun, Lei
   Min, Chulhong
   Kawsar, Fahim
   Montanari, Alessandro
GP ACM
TI Ultra-low Power DNN Accelerators for IoT: Resource Characterization of
   the MAX78000
SO PROCEEDINGS OF THE TWENTIETH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR
   SYSTEMS, SENSYS 2022
DT Proceedings Paper
CT 20th ACM Conference on Embedded Networked Sensor Systems (SenSys)
CY NOV 06-09, 2022
CL Boston, MA
DE Resource characterisation; edge accelerators; neural networks
AB The development of edge devices with dedicated hardware accelerators has pushed the deployment and inference of Deep Neural Network (DNN) models closer to users and real-world sensory systems than ever before (e.g., wearables, IoT). Recently, a further subset of these devices has emerged: ultra-low power DNN accelerators. These microcontrollers possess a dedicated hardware accelerator and are able to operate with only mu J's of energy in milliseconds of time. With their small form-factor, such devices could be used for battery-powered machine learning (ML) applications. In this work, we take a close look at one such device: the MAX78000 by Maxim Integrated. We characterize the device's performance by running five DNN models of various sizes and architectures, and analyze its operational latency, power consumption, and memory footprint. To better understand the performance characteristics, we take a step further and investigate how different layer types (operation type, kernel size, number of input and output channels) and the selection of accelerator processors affect the execution time.
C1 [Moss, Arthur] Univ Newcastle, Newcastle, NSW, Australia.
   [Lee, Hyunjong] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Lee, Hyunjong] Univ Southampton, Southampton, England.
   [Kawsar, Fahim] Univ Glasgow, Glasgow, Scotland.
   [Moss, Arthur; Lee, Hyunjong; Xun, Lei; Min, Chulhong; Kawsar, Fahim; Montanari, Alessandro] Nokia Bell Labs, Cambridge, England.
RP Moss, A (corresponding author), Univ Newcastle, Newcastle, NSW, Australia.
CR Afshin Niktash, 2021, DEV POW OPT APPL MAX
   [Anonymous], MAXIM INTEGRATED 302
   Antonini M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL WORKSHOP ON CHALLENGES IN ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR INTERNET OF THINGS (AICHALLENGEIOT '19), P49, DOI 10.1145/3363347.3363363
   Arm, 2022, ETH U55
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Cai Han, 2020, INT C LEAN RER ICLR
   Clay M, 2022, PROC SPIE, V12102, DOI 10.1117/12.2622390
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Google, 2022, EDG TPU
   Greenwaves, 2022, ULTR POW GAP PROC
   Han S., 2015, ARXIV151000149
   Hao Liu, 2021, SenSys '21: Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems, P478, DOI 10.1145/3485730.3493454
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hasanpour SH, 2018, Arxiv, DOI arXiv:1608.06037
   Intel, 2022, INT NEUR COMP STICK
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiser M, 2022, DES AUT TEST EUROPE, P963, DOI 10.23919/DATE54114.2022.9774653
   Krizhevsky Alex, 2009, TECH REP
   Lane ND, 2016, 2016 15TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN)
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lou W, 2021, IEEE COMPUT SOC CONF, P3104, DOI 10.1109/CVPRW53098.2021.00347
   Michaels Philip, A16 BON VS A15 BIONI
   Min C., 2022, IEEE T MOBILE COMPUT
   Min C, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P271, DOI 10.1145/3356250.3360043
   Montanari Alessandro, 2020, SenSys '20: Proceedings of the 18th Conference on Embedded Networked Sensor Systems, P382, DOI 10.1145/3384419.3430782
   Montanari A., 2019, ADJ P 2019 ACM INT J
   Nvidia, 2022, ADV AI EMB SYST
   Okman Erman, 2020, FACE IDENTIFICATION
   Parry H, 2021, 2021 ACM/IEEE 3RD WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD), DOI 10.1109/MLCAD52597.2021.9531281
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Reuther A, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622867
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Safarpour M, 2021, 2021 IEEE NORDIC CIRCUITS AND SYSTEMS CONFERENCE (NORCAS), DOI [10.1109/NorCAS53631.2021.9599648, 10.1109/NORCAS53631.2021.9599648]
   Sze V, 2017, IEEE CUST INTEGR CIR
   TensorFlow.org, 2022, TENSORFLOW LIT MICR
   Xun L, 2019, 2019 ACM/IEEE 1ST WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD), DOI 10.1109/mlcad48534.2019.9142052
   Xun L, 2020, DES AUT TEST EUROPE, P1556, DOI 10.23919/DATE48585.2020.9116235
NR 39
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 934
EP 940
DI 10.1145/3560905.3568300
DA 2023-11-11
ER

PT C
AU Skrimponis, P
   Pissadakis, E
   Alachiotis, N
   Pnevmatikatos, D
AF Skrimponis, Panagiotis
   Pissadakis, Emmanouil
   Alachiotis, Nikolaos
   Pnevmatikatos, Dionisios
BE Foster, I
   Joubert, GR
   Kucera, L
   Nagel, WE
   Peters, F
TI Accelerating Binarized Convolutional Neural Networks with Dynamic
   Partial Reconfiguration on Disaggregated FPGAs
SO PARALLEL COMPUTING: TECHNOLOGY TRENDS
SE Advances in Parallel Computing
DT Proceedings Paper
CT Conference on Parallel Computing - Technology Trends (ParCo)
CY SEP 10-13, 2019
CL Charles Univ, Prague, CZECH REPUBLIC
HO Charles Univ
DE Binarized Neural Network; FPGA accelerator; Dynamic Partial
   Reconfiguration
AB Convolutional Neural Networks (CNNs) currently dominate the fields of artificial intelligence and machine learning due to their high accuracy. However, their computational and memory needs intensify with the complexity of the problems they are deployed to address, frequently requiring highly parallel and/or accelerated solutions. Recent advances in machine learning showcased the potential of CNNs with reduced precision, by relying on binarized weights and activations, thereby leading to Binarized Neural Networks (BNNs). Due to the embarassingly parallel and discrete arithmetic nature of the required operations, BNNs fit well to FPGA technology, thus allowing to considerably scale up problem complexity. However, the fixed amount of resources per chip introduces an upper bound on the dimensions of the problems that FPGA-accelerated BNNs can solve. To this end, we explore the potential of remote FPGAs operating in tandem within a disaggregated computing environment to accelerate BNN computations, and exploit dynamic partial reconfiguration (DPR) to boost aggregate system performance. We find that DPR alone boosts throughput performance of a fixed set of BNN accelerators deployed on a remote FPGA by up to 3x in comparison with a static design that deploys the same accelerator cores on a software-programmable FPGA locally. In addition, performance increases linearly with the number of remote devices when inter-FPGA communication is reduced. To exploit DPR on remote FPGAs and reduce communication, we adopt a versatile remote-accelerator deployment framework for disaggregated datacenters, thereby boosting BNN performance with negligible development effort.
C1 [Skrimponis, Panagiotis] NYU, Tandon Sch Engn, Brooklyn, NY 11201 USA.
   [Pissadakis, Emmanouil; Alachiotis, Nikolaos; Pnevmatikatos, Dionisios] Tech Univ Crete, Khania, Greece.
   [Alachiotis, Nikolaos; Pnevmatikatos, Dionisios] FORTH ICS, Iraklion, Greece.
RP Skrimponis, P (corresponding author), NYU, Tandon Sch Engn, Brooklyn, NY 11201 USA.
CR Alkalay S, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P15, DOI 10.1145/2847263.2847287
   Courbariaux M, 2015, CORR, V28, P3123
   Iandola F. N., 2016, ARXIV
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kathail V., 2016, FPGA
   Katrinis K, 2016, DES AUT TEST EUROPE, P690
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kstner F., 2018, IEEE INT PAR DISTR P
   Li H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1, DOI 10.1109/RTEICT.2016.7807769
   Liang S., 2017, NEUROCOMPUTING
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, DOI DOI 10.2118/18761-MS
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Pissadakis E., 2018, ICFPT
   Qiu J., 2016, I C FIELD PROG LOGIC
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Xie XF, 2018, ACM T EMBED COMPUT S, V17, DOI 10.1145/3122788
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
NR 25
TC 4
Z9 4
U1 1
U2 3
PY 2020
VL 36
BP 691
EP 700
DI 10.3233/APC200099
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Liu, SQ
   Karanth, A
AF Liu, Siqin
   Karanth, Avinash
GP IEEE Comp Soc
TI Dynamic Voltage and Frequency Scaling to Improve Energy-Efficiency of
   Hardware Accelerators
SO 2021 IEEE 28TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS (HIPC 2021)
SE International Conference on High Performance Computing
DT Proceedings Paper
CT 28th Annual IEEE International Conference on High Performance Computing,
   Data, and Analytics (HiPC)
CY DEC 17-18, 2021
CL ELECTR NETWORK
DE Dynamic Frequency and Voltage Scaling (DVFS); Hardware Accelerator;
   Machine Learning; Neural Networks
ID DEEP NEURAL-NETWORKS; FLOW
AB Neural networks (NNs) have been used in a wide variety of artificial intelligence (AI) applications, including speech recognition, image recognition, automatic robotics, and games. State-of-the-art NNs provide high prediction accuracy at the expense of massive computation that involves large model parameters which consume substantial energy. Though sparse NNs have emerged to reduce the computation and storage overhead, existing specialized DNN accelerators cannot maximize the energy savings when exploiting both dynamic and static sparsity, especially for irregular NNs. In this paper, we propose a dynamic voltage and frequency scaling (DVFS) based hardware accelerator that effectively exploits the dynamic and static sparsity of NNs with dynamic voltage/frequency (V/F) scaling and power gating techniques to reduce both static and dynamic power. To explore the efficiency of DVFS implementation al different granularities, we evaluate both coarse-grained and fine-grained DVFS implementation with different design trade-offs. Further, our proposed DVFS model predicts the dynamic computation workloads as well as V/F pairs to be supplied to processing elements (PEs) in the hardware intelligently through pre-trained weight vectors. The machine learning based prediction algorithm is deployed to improve the DVFS mode selection accuracy. Our simulation results on AlexiNet, VGG16, and ResNet50 show that we can achieve an average dynamic energy savings of 59-66% and an average static power reduction of 69-80% compared to the baseline.
C1 [Liu, Siqin; Karanth, Avinash] Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
RP Liu, SQ (corresponding author), Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
EM ls847719@ohio.edu; karanth@ohio.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Asgari B, 2020, INT S HIGH PERF COMP, P249, DOI 10.1109/HPCA47549.2020.00029
   Chen Sun, 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P201, DOI 10.1109/NOCS.2012.31
   Chen X, 2013, DES AUT CON
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE MICRO, V37, P12, DOI 10.1109/MM.2017.54
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Clark M, 2020, INT PARALL DISTRIB P, P1, DOI 10.1109/IPDPS47924.2020.00011
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain R, 2016, DES AUT TEST EUROPE, P253
   Jung H, 2010, IEEE T COMPUT AID D, V29, P1395, DOI 10.1109/TCAD.2010.2059270
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kurup P., 2012, LOGIC SYNTHESIS USIN
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Nabavinejad SM, 2019, IEEE COMPUT ARCHIT L, V18, P136, DOI 10.1109/LCA.2019.2942020
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Thapa R, 2017, P IEEE INT C MICRO, P5, DOI 10.1109/MSE.2017.7945072
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 28
TC 4
Z9 4
U1 1
U2 3
PY 2021
BP 232
EP 241
DI 10.1109/HiPC53243.2021.00037
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Mathematics, Applied
DA 2023-11-11
ER

PT C
AU Lahari, PL
   Yellampalli, SS
   Vaddi, R
AF Lahari, P. L.
   Yellampalli, Siva Sankar
   Vaddi, Ramesh
GP IEEE
TI Systolic Array based. Multiply Accumulation Unit for IoT Edge
   Accelerators
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES
   2021)
DT Proceedings Paper
CT 7th IEEE International Symposium on Smart Electronic Systems (IEEE-iSES)
CY DEC 18-22, 2021
CL Jaipur, INDIA
DE Systolic Array; Accelerator; Multiply Accumulate Unit; Processor
AB Accelerator is a hardware that runs along with the processor and executes the key functions much faster than the processor. The Main purpose of the Accelerator is to increase speed. Deep Neural Networks has achieved wide results in the various Machine Learning Applications Such as image, video, text classification and language translation. The purpose of DNN Accelerators is to speed up the most complex computation i.e., matrix multiplication. Systolic array Based Accelerator seems like multiply Accumulate unit with Systolic Array based multiplication followed by Adder and accumulator, Multiply Accumulate Unit comprises multiplier, adder and Accumulator. Multiplier is designed used systolic array and that output is given as one of the inputs to the adder followed by Accumulator. In this paper general Matrix based Multiply Accumulate Unit is compared with systolic array based Multiply Accumulate Unit using Xilinx ISE 14.5, various parameters like area, delay and speed are compared. Systolic Array based Multiply Accumulate Unit consumes less area of 49%, less delay of 35% and in turn provides high speed when compared with general matrix multiplier-based multiplier Accumulate unit.
C1 [Lahari, P. L.; Yellampalli, Siva Sankar; Vaddi, Ramesh] SRM Univ, Dept Elect & Commun Engn, Amaravati, Andhra Pradesh, India.
RP Lahari, PL (corresponding author), SRM Univ, Dept Elect & Commun Engn, Amaravati, Andhra Pradesh, India.
EM lahari_p@srmap.edu.in; Sivasankar.y@srmap.edu.in; Ramesh.v@srmap.edu.in
CR Bharathi M., 2020, 2020 7 INT C SMART S
   Jia LC, 2020, IEEE MICRO, V40, P85, DOI 10.1109/MM.2020.2997611
   Lin S.-Y., 2020, 2020 IEEE INT C CONS
   Shomron Gil, 2019, IEEE Computer Architecture Letters, V18, P99, DOI 10.1109/LCA.2019.2924007
   Snopce H., 2020, 2020 INT C EL COMM C
   Sutisna N., 2020, PROC IEEE INT C COMM
   Ullah I., 2020, DES AUT CON
   Waris H, 2019, IEEE WRK SIG PRO SYS, P13, DOI [10.1109/sips47522.2019.9020404, 10.1109/SiPS47522.2019.9020404]
   Yago E., 2020, 2020 23 EUR C DIG SY
   Zhang J, 2020, IEEE DES TEST, V37, P93, DOI 10.1109/MDAT.2019.2947271
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
NR 11
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 220
EP 223
DI 10.1109/iSES52644.2021.00058
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Dave, S
   Baghdadi, R
   Nowatzki, T
   Avancha, S
   Shrivastava, A
   Li, BX
AF Dave, Shail
   Baghdadi, Riyadh
   Nowatzki, Tony
   Avancha, Sasikanth
   Shrivastava, Aviral
   Li, Baoxin
TI Hardware Acceleration of Sparse and Irregular Tensor Computations of ML
   Models: A Survey and Insights
SO PROCEEDINGS OF THE IEEE
DT Article
DE Tensors; Computational modeling; Hardware acceleration; Data models;
   Analytical models; Shape; Quantization (signal); Compact models;
   compiler optimizations; dataflow; deep learning; deep neural networks
   (DNNs); dimension reduction; energy efficiency; hardware; software;
   model codesign; machine learning (ML); pruning; quantization;
   reconfigurable computing; sparsity; spatial architecture; tensor
   decomposition; VLSI
ID DEEP NEURAL-NETWORKS; ARCHITECTURE; COMPRESSION; PROCESSOR; DESIGN;
   ARRAY
AB Machine learning (ML) models are widely used in many important domains. For efficiently processing these computational- and memory-intensive applications, tensors of these overparameterized models are compressed by leveraging sparsity, size reduction, and quantization of tensors. Unstructured sparsity and tensors with varying dimensions yield irregular computation, communication, and memory access patterns; processing them on hardware accelerators in a conventional manner does not inherently leverage acceleration opportunities. This article provides a comprehensive survey on the efficient execution of sparse and irregular tensor computations of ML models on hardware accelerators. In particular, it discusses enhancement modules in the architecture design and the software support, categorizes different hardware designs and acceleration techniques, analyzes them in terms of hardware and execution costs, analyzes achievable accelerations for recent DNNs, and highlights further opportunities in terms of hardware/software/model codesign optimizations (inter/intramodule). The takeaways from this article include the following: understanding the key challenges in accelerating sparse, irregular shaped, and quantized tensors; understanding enhancements in accelerator systems for supporting their efficient computations; analyzing tradeoffs in opting for a specific design choice for encoding, storing, extracting, communicating, computing, and load-balancing the nonzeros; understanding how structured sparsity can improve storage efficiency and balance computations; understanding how to compile and map models with sparse tensors on the accelerators; and understanding recent design trends for efficient accelerations and further opportunities.
C1 [Dave, Shail; Shrivastava, Aviral; Li, Baoxin] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA.
   [Baghdadi, Riyadh] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Nowatzki, Tony] Univ Calif Los Angeles, Sch Comp Sci, Los Angeles, CA 90095 USA.
   [Avancha, Sasikanth] Intel Labs, Parallel Comp Lab, Bengaluru 560103, India.
RP Dave, S (corresponding author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA.
EM shail.dave@asu.edu; baghdadi@mit.edu; tjn@cs.ucla.edu;
   sasikanth.avancha@intel.com; aviral.shrivastava@asu.edu;
   baoxin.li@asu.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdelfattah M. S., 2020, ARXIV200205022
   Acun B., 2020, ARXIV201105497
   Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Adelman M., 2018, ARXIV180508079
   Agakov F, 2006, INT SYM CODE GENER, P295
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Alwani M., 2016, MICROPAGE, P1
   Amid A, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2942284
   Amodei D, 2016, PR MACH LEARN RES, V48
   Amodei Dario, 2018, AI AND COMPUTE
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2003, AUTOMATIC PERFORMANC
   [Anonymous], 2017, ARXIV170407724
   [Anonymous], 2017, ARXIV170500125
   [Anonymous], CHILL FRAMEWORK COMP
   [Anonymous], 2018, ARXIV180904070
   Asgari B, 2019, IEEE MICRO, V39, P46, DOI 10.1109/MM.2019.2930057
   Azizimazreah A, 2019, INT S HIGH PERF COMP, P94, DOI 10.1109/HPCA.2019.00030
   Bachrach J, 2012, DES AUT CON, P1212
   Bader B.W., 2015, MATLAB TENSOR TOOLBO
   Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489
   Baghdadi R, 2015, RR8706 INRIA
   Baghdadi R, 2019, INT SYM CODE GENER, P193, DOI [10.5281/zenodo.2375075, 10.1109/CGO.2019.8661197]
   Baghdadi R, 2015, INT CONFER PARA, P138, DOI 10.1109/PACT.2015.17
   Banbury Colby R., 2020, ARXIV200304821
   Baskaran M, 2012, IEEE HIGH PERF EXTR
   Ben Ahmed A, 2018, INT SYMP NETW CHIP
   Benabderrahmane M.-W., 2010, P 19 JOINT EUR C THE
   Bojarski Mariusz, 2016, arXiv
   Bondhugula U, 2008, PLDI'08: PROCEEDINGS OF THE 2008 SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN & IMPLEMENTATION, P101, DOI 10.1145/1375581.1375595
   Brown T., 2020, PROC ADV NEUR INF PR, P1877
   Buckler M, 2018, CONF PROC INT SYMP C, P533, DOI 10.1109/ISCA.2018.00051
   Buluc A., 2009, P 21 ANN S PAR ALG A
   Buluç A, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P1876
   Cao SJ, 2019, PROC CVPR IEEE, P11208, DOI 10.1109/CVPR.2019.01147
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen L., 2017, ABS170605587 CORR, Vabs/1706.05587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen TL, 2020, ANN OPER RES, V290, P813, DOI 10.1007/s10479-018-2969-x
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2019, ACM T COMPUT SYST, V36, DOI 10.1145/3331469
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Chole S., 2018, P SYSML C, P1
   Chou S, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276493
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   Dave S, 2020, INT CONF ACOUST SPEE, P1544, DOI [10.1109/ICASSP40776.2020.9054275, 10.1109/icassp40776.2020.9054275]
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Dean J, 2020, ISSCC DIG TECH PAP I, P8, DOI 10.1109/ISSCC19947.2020.9063049
   Deng HW, 2014, PROC SPIE, V9247, DOI 10.1117/12.2064087
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Dong X, 2019, INT CONFER PARA, P178, DOI 10.1109/PACT.2019.00022
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du ZD, 2020, P IEEE, V108, P1047, DOI 10.1109/JPROC.2020.2977722
   DUFF IS, 1977, P IEEE, V65, P500, DOI 10.1109/PROC.1977.10514
   Elsen Erich, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14617, DOI 10.1109/CVPR42600.2020.01464
   Elsken T, 2019, J MACH LEARN RES, V20
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   FEAUTRIER P, 1991, INT J PARALLEL PROG, V20, P23, DOI 10.1007/BF01407931
   Feautrier Paul, 2011, ENCY PARALLEL COMPUT, P1581, DOI [10.1007/978-0-387-09766-4_502, DOI 10.1007/978-0-387-09766-4_502]
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Fowers J, 2015, ANN IEEE SYM FIELD P, P52, DOI 10.1109/FCCM.2015.46
   Frankle J., 2019, P INT C LEARN REPR, P1
   Gale T., 2019, ARXIV190209574
   Gale T, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00021
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Georgiadis G, 2019, PROC CVPR IEEE, P7078, DOI 10.1109/CVPR.2019.00725
   Gonçalves LR, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358174
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gopinath S, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P79, DOI 10.1145/3314221.3314597
   Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053
   Grosser T, 2012, PARALLEL PROCESS LET, V22, DOI 10.1142/S0129626412500107
   Grover V., 2018, P 2 ACM SIGPLAN INT
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo KY, 2017, IEEE MICRO, V37, P18, DOI 10.1109/MM.2017.39
   Gupta U, 2019, INT CONFER PARA, P1, DOI 10.1109/PACT.2019.00009
   Gupta V., 2020, ARXIV201008899
   Ham T. J., 2020, ARXIV200210941
   Ham TJ, 2016, INT SYMP MICROARCH
   Hamilton W. L., 2017, ARXIV170905584
   Han S., 2015, ARXIV151000149
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hartono A, 2009, ICS'09: PROCEEDINGS OF THE 2009 ACM SIGARCH INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P147, DOI 10.1145/1542275.1542301
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hegde K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P933, DOI [10.1109/MICR0.2018.00080, 10.1109/MICRO.2018.00080]
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hong C., 2019, P 24 S PRINC PRACT P
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hu YM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356506
   Hubara I, 2018, J MACH LEARN RES, V18
   IGNATOV A, 2019, ARXIV191006663
   Im E. -J., 1998, P WORKSH PROF FEEDB, V139, P1
   Intel, UND MEM FORM INT MKL
   Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kalamkar D., 2019, ARXIV190512322
   Kang HJ, 2020, IEEE T CIRC SYST VID, V30, P2093, DOI 10.1109/TCSVT.2019.2911674
   Kaviani Baghbaderani Razieh, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P1, DOI 10.1007/978-3-030-58577-8_1
   Khan K., 2018, XILINX DNN PROCESSOR
   Kim D, 2018, IEEE DES TEST, V35, P39, DOI 10.1109/MDAT.2017.2741463
   Kim Y, 2011, IEEE T COMPUT AID D, V30, P1599, DOI 10.1109/TCAD.2011.2161217
   Kincaid D. R., 1984, ELLIPTIC PROBLEM SOL, P53
   King J, 2016, LECT NOTES COMPUT SC, V9697, P61, DOI 10.1007/978-3-319-41321-1_4
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Krashinsky Ronny., 2020, NVIDIA AMPERE ARCHIT
   Krishnamoorthi R., 2018, ARXIV180608342, V8, P667
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Kung HT, 2018, INT C PATT RECOG, P1006, DOI 10.1109/ICPR.2018.8545462
   Kurth T., 2018, P INT C HIGH PERF CO, P649, DOI [DOI 10.1109/SC.2018.00054, 10.1109/SC.2018.00054]
   Kwon H, 2017, 11 IEEE ACM INT S NE, V2017, P1, DOI [10.1145/3130218.3130230, DOI 10.1145/3130218.3130230]
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lattner C., 2020, ARXIV200211054
   Leary C., 2017, XLA TENSORFLOW COMPI
   Lee C.-E., 2018, P SYSML C, P1
   Lee D, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P139, DOI 10.1145/3205289.3205295
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Li JJ, 2019, IEEE T COMPUT, V68, P1663, DOI 10.1109/TC.2019.2924215
   Li MZ, 2021, IEEE T PARALL DISTR, V32, P708, DOI 10.1109/TPDS.2020.3030548
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Lin YL, 2018, INT CONF SYST SCI EN
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu ZG, 2020, IEEE COMPUT ARCHIT L, V19, P34, DOI 10.1109/LCA.2020.2979965
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma X., 2019, ARXIV190702124
   Mahdiani H, 2020, IEEE MICRO, V40, P67, DOI 10.1109/MM.2019.2948345
   Mahmoud M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P134, DOI 10.1109/MICRO.2018.00020
   Marculescu D, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243479
   McDanel B, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P449, DOI 10.1145/3330345.3330385
   Mendis C, 2019, PR MACH LEARN RES, V97
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Mishra AK, 2017, ASIA S PACIF DES AUT, P635, DOI 10.1109/ASPDAC.2017.7858395
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moreau T, 2018, ARXIV180704188
   Moroney L., 2018, INTRO RAGGED TENSORS
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI [10.1145/2694344.2694364, 10.1145/2775054.2694364]
   Narang S., 2017, ARXIV170405119, P1, DOI DOI 10.1109/ACEPT.2017.8168546
   National Institute of Standards and Technology, 2013, MATR MARK EXCH FORM
   Naumov Maxim, 2019, ABS190600091 CORR
   NVIDIA, CUSP CUDA SPARS MATR
   NVIDIA Corporation, NVIDIA DEEP LEARN AC
   Olukotun K., 2018, C NEUR INF PROC SYST
   Page Adam, 2017, ACM Journal on Emerging Technologies in Computing Systems, V13, DOI 10.1145/3005448
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park Ji Ho, 2018, BAM BOTTLENECK ATTEN
   Paszke A, 2019, ADV NEUR IN, V32
   Pathan T., 2012, P INT WORKSH LANG CO, P17
   Peterson P, 2001, SCIPY OPEN SOURCE SC
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Radford A., 2015, ARXIV151106434
   Ragan-Kelley J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185528
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Redmon J., 2016, ARXIV160207360, P779
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Ren A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P925, DOI 10.1145/3297858.3304076
   Ren MY, 2018, PROC CVPR IEEE, P8711, DOI 10.1109/CVPR.2018.00908
   REUTHER A, 2019, P IEEE HPEC SEP, P1, DOI DOI 10.1109/HPEC.2019.8916327
   Rezk NM, 2020, IEEE ACCESS, V8, P57967, DOI 10.1109/ACCESS.2020.2982416
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Saad Y, 1990, NASACR185876 NTRS RE
   Saad Y., 2003, ITERATIVE METHODS SP, Vsecond
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharifian A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P940, DOI 10.1145/3352460.3358292
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Sharma H, 2016, INT SYMP MICROARCH
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shi Runbin, 2020, P 34 ACM INT C SUP J, P1
   Silfa F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P782, DOI 10.1145/3352460.3358309
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith S, 2017, FROSTT FILE FORMAT
   Smith SC, 2015, WILSON-JOHNSON CORRESPONDENCE, 1964-69, P1
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Srivastava G, 2019, INT CONF ACOUST SPEE, P1393, DOI 10.1109/ICASSP.2019.8682791
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steely S. C., 2019, U.S. Patent, Patent No. [10 445 250, 10445250]
   Struharik R, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P365, DOI 10.1109/DSD.2018.00070
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tann H, 2017, DES AUT CON, DOI 10.1145/3061639.3062259
   Tew P. A., 2016, THESIS MIT CAMBRIDGE
   Trifunovic K, 2009, INT CONFER PARA, P327, DOI 10.1109/PACT.2009.18
   Truong L, 2016, ACM SIGPLAN NOTICES, V51, P209, DOI [10.1145/2908080.2908105, 10.1145/2980983.2908105]
   Tung F, 2018, PROC CVPR IEEE, P7873, DOI 10.1109/CVPR.2018.00821
   Turakhia Y, 2018, ACM SIGPLAN NOTICES, V53, P199, DOI [10.1145/3173162.3173193, 10.1145/3296957.3173193]
   Vainbrand Dmitri, 2010, 2010 ACM/IEEE International Symposium on Networks-on-Chip (NOCS), P135, DOI 10.1109/NOCS.2010.23
   Vasilache N., 2018, CORR
   Vaswani A, 2017, ADV NEUR IN, V30
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Venkatesan R., 2019, P IEEE ACM INT C COM, P1
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   Verdoolaege S, 2010, LECT NOTES COMPUT SC, V6327, P299, DOI 10.1007/978-3-642-15582-6_49
   Vooturi D. T., 2018, ARXIV180803420
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Wang H., 2020, ARXIV201209852
   Wang PQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196116
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Warden P., 2015, WHY ARE 8 BITS ENOUG
   Wei R., 2017, ARXIV171103016
   Wei Y, 2020, IEEE T BIOMED CIRC S, V14, P145, DOI 10.1109/TBCAS.2020.2974154
   Wen W., 2016, ADV NEURAL INFORM PR, P2082, DOI DOI 10.1016/J.CCR.2008.06.009
   Weste N.E.H., 2015, CMOS VLSI DESIGN CIR
   Whatmough PN, 2018, IEEE J SOLID-ST CIRC, V53, P2722, DOI 10.1109/JSSC.2018.2841824
   Willcock J., 2006, ICS 06, P307, DOI DOI 10.1145/1183401.1183444
   Wolf M. E., 1992, THESIS STANFORD U ST
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu LS, 2014, ACM SIGPLAN NOTICES, V49, P255, DOI 10.1145/2541940.2541961
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xin He, 2020, ICS '20: Proceedings of the 34th ACM International Conference on Supercomputing, DOI 10.1145/3392717.3392751
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
   Yan M., 2020, P IEEE INT S HIGH PE
   Yan MY, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P615, DOI 10.1145/3352460.3358318
   Yang H, 2019, P IEEE CVF C COMP VI, P2178
   Yang Q., 2019, ARXIV190906964
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yavits L, 2018, IEEE COMPUT ARCHIT L, V17, P21, DOI 10.1109/LCA.2017.2714667
   Yazdanbakhsh A, 2018, CONF PROC INT SYMP C, P650, DOI 10.1109/ISCA.2018.00060
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Ying Wang, 2019, 2019 56th ACM/IEEE Design Automation Conference (DAC). Proceedings, DOI 10.1145/3316781.3317749
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Yuan Z, 2020, IEEE J SOLID-ST CIRC, V55, P465, DOI 10.1109/JSSC.2019.2946771
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
   Zhang J, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358178
   Zhang JF, 2019, SYMP VLSI CIRCUITS, pC306, DOI 10.23919/VLSIC.2019.8778193
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang X., 2018, 2018 IEEEACM INT C C, P56
   Zhang XY, 2019, IEEE COMP SOC ANN, P25, DOI 10.1109/ISVLSI.2019.00014
   Zheng S., 2018, P DES AUT C, P137
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhu JY, 2018, DES AUT TEST EUROPE, P241, DOI 10.23919/DATE.2018.8342010
   Zhu Michael, 2017, ARXIV171001878
   Zhu YH, 2018, CONF PROC INT SYMP C, P547, DOI 10.1109/ISCA.2018.00052
   Zmora Neta, 2019, ARXIV191012232
NR 274
TC 24
Z9 24
U1 2
U2 28
PD OCT
PY 2021
VL 109
IS 10
BP 1706
EP 1752
DI 10.1109/JPROC.2021.3098483
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ferianc, M
   Fan, HX
   Manocha, D
   Zhou, HY
   Liu, SL
   Niu, XY
   Luk, W
AF Ferianc, Martin
   Fan, Hongxiang
   Manocha, Divyansh
   Zhou, Hongyu
   Liu, Shuanglong
   Niu, Xinyu
   Luk, Wayne
TI Improving Performance Estimation for Design Space Exploration for
   Convolutional Neural Network Accelerators
SO ELECTRONICS
DT Article
DE field-programmable gate array; deep learning; neural network;
   performance estimation; Gaussian process
AB Contemporary advances in neural networks (NNs) have demonstrated their potential in different applications such as in image classification, object detection or natural language processing. In particular, reconfigurable accelerators have been widely used for the acceleration of NNs due to their reconfigurability and efficiency in specific application instances. To determine the configuration of the accelerator, it is necessary to conduct design space exploration to optimize the performance. However, the process of design space exploration is time consuming because of the slow performance evaluation for different configurations. Therefore, there is a demand for an accurate and fast performance prediction method to speed up design space exploration. This work introduces a novel method for fast and accurate estimation of different metrics that are of importance when performing design space exploration. The method is based on a Gaussian process regression model parametrised by the features of the accelerator and the target NN to be accelerated. We evaluate the proposed method together with other popular machine learning based methods in estimating the latency and energy consumption of our implemented accelerator on two different hardware platforms targeting convolutional neural networks. We demonstrate improvements in estimation accuracy, without the need for significant implementation effort or tuning.
C1 [Ferianc, Martin] UCL, Dept Elect & Elect Engn, London WC1E 7JE, England.
   [Fan, Hongxiang; Luk, Wayne] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
   [Liu, Shuanglong] Hunan Normal Univ, Sch Phys & Elect, Changsha 410081, Peoples R China.
   [Niu, Xinyu] Corerain Technol Ltd, Shanghai 201203, Peoples R China.
RP Ferianc, M (corresponding author), UCL, Dept Elect & Elect Engn, London WC1E 7JE, England.
EM martin.ferianc.19@ucl.ac.uk; h.fan17@imperial.ac.uk;
   divyanshmanocha@gmail.com; hongyu.hyzhou@gmail.com;
   liu.shuanglong@hunnu.edu.cn; xinyu.niu@corerain.com;
   w.luk@imperial.ac.uk
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46448-0_2
   Brown T., 2020, PROC ADV NEUR INF PR, P1877
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Fan HX, 2019, IEEE INT CONF ASAP, P1, DOI 10.1109/ASAP.2019.00-44
   Fan HX, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P17, DOI 10.1109/FPT.2018.00014
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Intel Corporation, 2018, EASIC TECHN
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kwon Y, 2020, COMPUT STAT DATA AN, V142, DOI 10.1016/j.csda.2019.106816
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu SL, 2019, I C FIELD PROG LOGIC, P187, DOI 10.1109/FPL.2019.00037
   Liu SL, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242900
   Luk W., 2020, INT S APPL RECONFIGU, V3, P13
   Matthews AGD, 2017, J MACH LEARN RES, V18, P1
   McAllister R, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4745
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Nguyen NP, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091541
   Park D., 2019, P 2019 2 INT C CONTR, P80, DOI [10.1145/3387304.3387327, DOI 10.1145/3387304.3387327]
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Rahman A, 2017, DES AUT TEST EUROPE, P1147, DOI 10.23919/DATE.2017.7927162
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rodrigues M., 2020, ARXIV200706103
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PMLR
   Titsias M., 2009, ARTIF INTELL, P567
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Williams CKI, 1996, ADV NEUR IN, V8, P514
   Xuan-Mung N, 2019, INT C CONTR AUTOMAT, P1359, DOI [10.23919/iccas47443.2019.8971729, 10.23919/ICCAS47443.2019.8971729]
   Yasudo R, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P317, DOI 10.1109/FPT.2018.00062
NR 34
TC 1
Z9 1
U1 0
U2 5
PD FEB
PY 2021
VL 10
IS 4
AR 520
DI 10.3390/electronics10040520
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Henkel, J
   Li, H
   Raghunathan, A
   Tahoori, MB
   Venkataramani, S
   Yang, XX
   Zervakis, G
AF Henkel, Jorg
   Li, Hai
   Raghunathan, Anand
   Tahoori, Mehdi B.
   Venkataramani, Swagath
   Yang, Xiaoxuan
   Zervakis, Georgios
GP IEEE
TI Approximate Computing and the Efficient Machine Learning Expedition
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
DE Approximate Computing; In-memory; Machine Learning; Precision Scaling;
   Printed Electronics; Pruning; Quantization; Transformers
ID DESIGN; ACCELERATOR; CIRCUITS; SYSTEM; POWER
AB Approximate computing (AxC) has been long accepted as a design alternative for efficient system implementation at the cost of relaxed accuracy requirements. Despite the AxC research activities in various application domains, AxC thrived the past decade when it was applied in Machine Learning (ML). The by definition approximate notion of ML models but also the increased computational overheads associated with ML applications-that were effectively mitigated by corresponding approximations-led to a perfect matching and a fruitful synergy. AxC for AI/ML has transcended beyond academic prototypes. In this work, we enlighten the synergistic nature of AxC and ML and elucidate the impact of AxC in designing efficient ML systems. To that end, we present an overview and taxonomy of AxC for ML and use two descriptive application scenarios to demonstrate how AxC boosts the efficiency of ML systems.
C1 [Henkel, Jorg; Tahoori, Mehdi B.; Zervakis, Georgios] Karlsruhe Inst Technol, Karlsruhe, Germany.
   [Li, Hai; Yang, Xiaoxuan] Duke Univ, Durham, NC 27706 USA.
   [Raghunathan, Anand] Purdue Univ, W Lafayette, IN 47907 USA.
   [Venkataramani, Swagath] IBM Res, Yorktown Hts, NY USA.
   [Zervakis, Georgios] Univ Patras, GR-26110 Patras, Greece.
RP Zervakis, G (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.; Zervakis, G (corresponding author), Univ Patras, GR-26110 Patras, Greece.
CR Agrawal A, 2019, P S COMP ARITHM, P92, DOI 10.1109/ARITH.2019.00023
   Amrouch H, 2020, IEEE T COMPUT AID D, V39, P3842, DOI 10.1109/TCAD.2020.3012753
   [Anonymous], 2015, DESIGN AUTOMATION C
   Armeniakos G, 2022, ACM COMPUT SURV
   Armeniakos G, 2022, DES AUT TEST EUROPE, P190, DOI 10.23919/DATE54114.2022.9774689
   Balaskas Konstantinos, 2022, INT S QUALITY ELECT
   Biggs J, 2021, NATURE, V595, P532, DOI 10.1038/s41586-021-03625-w
   Bleier N, 2020, ANN I S COM, P213, DOI 10.1109/ISCA45697.2020.00028
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chakradhar ST, 2010, DES AUT CON, P865
   Chang JS, 2017, IEEE J EM SEL TOP C, V7, P7, DOI 10.1109/JETCAS.2017.2673863
   Chen CY, 2017, Arxiv, DOI arXiv:1712.02679
   Chen CY, 2018, DES AUT TEST EUROPE, P821, DOI 10.23919/DATE.2018.8342119
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chippa VK, 2013, DES AUT CON
   Choi J., 2019, P MACHINE LEARNING S, V1, P348
   Choi J, 2018, Arxiv, DOI arXiv:1805.06085
   Danopoulos D, 2022, Arxiv, DOI arXiv:2203.04071
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Dheeru D., 2017, UCI MACHINE LEARNING
   Douthwaite M., 2019, BIOMED CIRC SYST C, P1
   Elsken T, 2019, J MACH LEARN RES, V20
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Guesmi A, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P990, DOI 10.1145/3445814.3446747
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He ZZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317870
   Henkel J, 2015, DES AUT CON, DOI 10.1145/2744769.2747938
   Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]
   Hsu K. C., 2015, SSDM
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang YW, 2020, IEEE T COMPUT AID D, V39, P3856, DOI 10.1109/TCAD.2020.3012250
   Kim Y, 2019, DES AUT TEST EUROPE, P576, DOI [10.23919/date.2019.8714872, 10.23919/DATE.2019.8714872]
   Lacy P., 2020, CIRCULAR EC HDB
   Liu S, 2011, ACM SIGPLAN NOTICES, V46, P213, DOI 10.1145/1961296.1950391
   Mengte J., 2010, IPDPS 10, P1
   Minh SQ, 2021, ANN INT S MICROARCHI, P100
   Mubarik MH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P73, DOI 10.1109/MICRO50266.2020.00019
   Ozer E, 2020, NAT ELECTRON, V3, P419, DOI 10.1038/s41928-020-0437-5
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Panda P, 2019, IEEE ACCESS, V7, P70157, DOI 10.1109/ACCESS.2019.2919463
   Pool Jeff, 2021, NVIDIA BLOG
   Prato G, 2020, Arxiv, DOI arXiv:1910.10485
   Ranjan A, 2015, DES AUT CON, DOI 10.1145/2744769.2744799
   San Miguel J, 2014, INT SYMP MICROARCH, P127, DOI 10.1109/MICRO.2014.22
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Sen S, 2019, IEEE T COMPUT, V68, P912, DOI 10.1109/TC.2018.2879434
   Seung Ryul Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P71, DOI 10.1109/VLSIT.2012.6242466
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   ShiboWang Pankaj, 2019, GOOGLE BLOG
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sun X, 2019, ADV NEUR IN, V32
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Venkataramani S, 2021, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA52012.2021.00021
   Venkataramani S, 2020, P IEEE, V108, P2232, DOI 10.1109/JPROC.2020.3029453
   Venkataramani S, 2015, DES AUT CON, DOI 10.1145/2744769.2744904
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Venkataramani S, 2012, DES AUT CON, P796
   WeiWen ChunpengWu, 2016, ADV NEURAL INFORM PR, V29
   Weller Dennis D., 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P446, DOI 10.1109/ASP-DAC47756.2020.9045211
   Weller DD, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P914, DOI 10.23919/DATE51398.2021.9474254
   Yan BN, 2017, ICCAD-IEEE ACM INT, P541, DOI 10.1109/ICCAD.2017.8203824
   Yang XX, 2022, IEEE T CIRCUITS-I, V69, P1845, DOI 10.1109/TCSI.2022.3159153
   Yang XX, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643444
   Yang XX, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415640
   Yu Joonsang, 2021, ARXIV
   Yu SM, 2012, IEEE T ELECTRON DEV, V59, P1183, DOI 10.1109/TED.2012.2184544
   Zafrir O, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zervakis G, 2022, IEEE T COMPUT, V71, P2687, DOI 10.1109/TC.2022.3141054
   Zervakis G, 2021, DES AUT CON, P481, DOI 10.1109/DAC18074.2021.9586092
   Zervakis G, 2019, IEEE T VLSI SYST, V27, P1460, DOI 10.1109/TVLSI.2019.2900160
   Zervakis G, 2016, IEEE T VLSI SYST, V24, P3105, DOI 10.1109/TVLSI.2016.2535398
   Zhang Wei, 2016, P 25 INT JOINT C ART, P2350
   Zhao R, 2019, PR MACH LEARN RES, V97
   Zheng Cui, 2016, PRINTED ELECT MAT TE
NR 82
TC 1
Z9 1
U1 1
U2 1
PY 2022
DI 10.1145/3508352.3561105
WC Computer Science, Theory & Methods; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chung, YL
   Hsu, SC
   Nachman, B
AF Chung, Y. -L.
   Hsu, S. -C.
   Nachman, B.
TI Disentangling boosted Higgs Boson production modes with machine learning
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Accelerator Applications; Analysis and statistical methods; Data
   processing methods; Pattern recognition; cluster finding; calibration
   and fitting methods
AB Higgs Bosons produced via gluon-gluon fusion with large transverse momentum (p(T)) are sensitive probes of physics beyond the Standard Model. However, high p(T) Higgs Boson production is contaminated by many production modes other than gluon-gluon fusion, including vector boson fusion, production of a Higgs boson in association with a vector boson, and production of a Higgs boson with a top-quark pair. By using modern machine learning techniques to analyze jet substructure and event information, we demonstrate the capability of machine learning to identify production modes accurately. These tools hold great discovery potential for boosted Higgs bosons produced via ggF, and may also provide additional information about the Higgs Boson sector of the Standard Model in extreme regions of phase space for other production modes.
C1 [Chung, Y. -L.] Natl Tsing Hua Univ, Dept Phys, Hsinchu 300, Taiwan.
   [Hsu, S. -C.] Univ Washington, Dept Phys, Seattle, WA 98195 USA.
   [Nachman, B.] Lawrence Berkeley Natl Lab, Div Phys, Berkeley, CA 94720 USA.
RP Chung, YL (corresponding author), Natl Tsing Hua Univ, Dept Phys, Hsinchu 300, Taiwan.
EM s107022801@m107.nthu.edu.tw
CR Aad G, 2019, EUR PHYS J C, V79, DOI 10.1140/epjc/s10052-019-7335-x
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Albertsson K, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/2/022008
   Almeida LG, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2015)086
   Alwall J, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2014)079
   Andrews M., 2020, Computing and Software for Big Science, V4, DOI 10.1007/s41781-020-00038-8
   [Anonymous], 2017, ATLPHYSPUB2017017 CE
   [Anonymous], 2018, PHYS REV D, DOI [DOI 10.1103/PHYSREVD.98.030001, 10.1103/PhysRevD.98.030001, DOI 10.1103/PhysRevD.98.030001]
   Artoisenet P, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP11(2013)043
   ATLAS collaboration, 2018, ATLASCONF2018052 CER
   ATLAS Collaboration, 2019, ATLPHYSPUB2019028 CE
   Azatov A, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2014)014
   Barnard J, 2017, PHYS REV D, V95, DOI 10.1103/PhysRevD.95.014018
   Becker K., ARXIV200507762, V7762
   Belyaev N, 2017, J PHYS CONF SER, V934, DOI 10.1088/1742-6596/934/1/012030
   Botje M., ARXIV 11 0 1 0538
   Bourilkov D, 2019, INT J MOD PHYS A, V34, DOI 10.1142/S0217751X19300199
   Buckley A, 2016, EUR PHYS J C, V76, DOI 10.1140/epjc/s10052-016-3925-z
   Cacciari M, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/04/063
   Cacciari M, 2012, EUR PHYS J C, V72, DOI 10.1140/epjc/s10052-012-1896-2
   Cacciari M, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/04/005
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Chan CH, 2017, PHYS REV D, V96, DOI 10.1103/PhysRevD.96.096009
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   CMS collaboration, 2017, CERNCMSDP2017027
   CMS collaboration, 2018, CERNCMSDP2018046
   CMS collaboration, 2020, JHEP, V12
   Cogan J, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2015)118
   Conway JS, 2016, PHYS REV D, V94, DOI 10.1103/PhysRevD.94.094027
   Dasgupta M, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP09(2013)029
   Datta K, 2018, J HIGH ENERGY PHYS, DOI 10.1007/JHEP03(2018)086
   de Oliveira L, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2016)069
   Demartin F, 2014, EUR PHYS J C, V74, DOI 10.1140/epjc/s10052-014-3065-2
   Frederix R, 2012, J HIGH ENERGY PHYS, DOI 10.1007/JHEP12(2012)061
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Guest D, 2018, ANNU REV NUCL PART S, V68, P161, DOI 10.1146/annurev-nucl-101917-021019
   Kasieczka G, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP05(2017)006
   Ke G., 2017, ADV NEURAL INFORM PR, V30, P3146, DOI DOI 10.5555/3294996.3295074
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Komiske PT, 2018, PHYS REV D, V98, DOI 10.1103/PhysRevD.98.011502
   Komiske PT, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2017)110
   Larkoski AJ, 2020, PHYS REP, V841, P1, DOI 10.1016/j.physrep.2019.11.001
   Larkoski AJ, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP05(2014)146
   LHC Higgs Cross Section Working Group, 2016, HDB LHC HIGGS CROSS
   Li J., ARXIV 2 00 9 00 17 0
   Li JM, 2021, J HIGH ENERGY PHYS, DOI 10.1007/JHEP04(2021)156
   Lin JS, 2018, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2018)101
   Macaluso S, 2018, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2018)121
   Moreno EA, 2020, PHYS REV D, V102, DOI 10.1103/PhysRevD.102.012010
   Moult I, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP12(2016)153
   Ngairangbam VS, 2020, EUR PHYS J C, V80, DOI 10.1140/epjc/s10052-020-08629-w
   Nguyen T. Q., 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0028-1
   Pagani D, 2020, J HIGH ENERGY PHYS, DOI 10.1007/JHEP11(2020)036
   Pappadopulo D, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP09(2014)060
   PUMPLIN J, 1991, PHYS REV D, V44, P2025, DOI 10.1103/PhysRevD.44.2025
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Ridgeway G., 2020, GEN BOOSTED MODELS G
   Shelton J., 2013, THEORETICAL ADV STUD, V2
   Sirunyan AM, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.071802
   Sjöstrand T, 2008, COMPUT PHYS COMMUN, V178, P852, DOI 10.1016/j.cpc.2008.01.036
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zeiler M. D., 2012, ARXIV 121257 0 1
NR 62
TC 4
Z9 4
U1 1
U2 1
PD JUL
PY 2021
VL 16
IS 7
AR P07002
DI 10.1088/1748-0221/16/07/P07002
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT J
AU Thomadakis, P
   Garner, K
   Gavalian, G
   Chrisochoides, N
AF Thomadakis, Polykarpos
   Garner, Kevin
   Gavalian, Gagik
   Chrisochoides, Nikos
TI Charged particle reconstruction in CLAS12 using Machine Learning
SO COMPUTER PHYSICS COMMUNICATIONS
DT Article
DE Machine Learning; Jefferson Lab; Tracking; Drift Chambers; CLAS12;
   Particle accelerators
AB In this work, we present studies of track parameter reconstruction from raw information in CLAS12 detector's Drift Chambers, using Machine Learning (ML). We study the resolution of tracks reconstructed with different types of ML models/algorithms, including Multi-Layer Perceptron (MLP), Extremely Randomized Trees (ERT) and Gradient Boosting Trees (GBT) using simulated data. The resulting ML model is capable of reconstructing track parameters (particle momentum, and polar and azimuthal angles) with accuracy similar to Hit Based (HB) tracking code, but 150 times faster. Moreover, physics reactions can be identified using the particles reconstructed by the neural network in real-time (with a rate of about 34 kHz) during experimental data collection. The developed model can be used in numerous applications, such as triggering specific physics reactions in real-time, detector performance monitoring, and real-time detector calibration.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Thomadakis, Polykarpos; Garner, Kevin; Chrisochoides, Nikos] Old Dominion Univ, Dept Comp Sci, CRTC, Norfolk, VA 23529 USA.
   [Gavalian, Gagik] Jefferson Lab, Newport News, VA USA.
RP Thomadakis, P (corresponding author), Old Dominion Univ, Dept Comp Sci, CRTC, Norfolk, VA 23529 USA.
EM pthom001@odu.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   Alaoui A.E., 2012, PHYSCS PROC, V37, P773
   Anaconda Software Distribution, US
   [Anonymous], OFFICIAL YAML WEB SI
   Burkert VD, 2020, NUCL INSTRUM METH A, V959, DOI 10.1016/j.nima.2020.163419
   Chatagnon P, 2021, PHYS REV LETT, V127, DOI 10.1103/PhysRevLett.127.262501
   Chen T., XGBOOST SCALABLE POR
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chollet F., 2015, KERAS, P33
   Gavalian G., 2022, ARXIV
   Gavalian G, 2022, Arxiv, DOI arXiv:2202.06869
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Haykin S., 1994, NEURAL NETWORKS COMP
   Reddi SJ, 2019, Arxiv, DOI arXiv:1904.09237
   Khachatryan M, 2021, NATURE, V599, P565, DOI 10.1038/s41586-021-04046-5
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Mestayer MD, 2020, NUCL INSTRUM METH A, V959, DOI 10.1016/j.nima.2020.163518
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Thomadakis P, 2022, COMPUT PHYS COMMUN, V276, DOI 10.1016/j.cpc.2022.108360
   Thomadakis P, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108201
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Ungaro M., 2020, GEANT BASED MONTE CA
   Ziegler V, 2020, NUCL INSTRUM METH A, V959, DOI 10.1016/j.nima.2020.163472
NR 25
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2023
VL 287
AR 108694
DI 10.1016/j.cpc.2023.108694
EA FEB 2023
WC Computer Science, Interdisciplinary Applications; Physics, Mathematical
DA 2023-11-11
ER

PT C
AU Deng, CH
   Gong, YB
   Han, F
   Liao, SY
   Yi, JG
   Yuan, B
AF Deng, Chunhua
   Gong, Yongbin
   Han, Feng
   Liao, Siyu
   Yi, Jingang
   Yuan, Bo
BE Matthews, MB
TI VLSI Hardware Architecture for Gaussian Process
SO 2020 54TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS, AND COMPUTERS
SE Conference Record of the Asilomar Conference on Signals Systems and
   Computers
DT Proceedings Paper
CT 54th Asilomar Conference on Signals, Systems and Computers
CY NOV 01-05, 2020
CL ELECTR NETWORK
DE Gaussian Process; VLSI
AB Gaussian process (GP) is a popular machine learning technique that is widely used in many application domains, especially in robotics. However, GP is very computation intensive and time consuming during the inference phase, thereby bringing severe challenges for its large-scale deployment in real-time applications. In this paper, we propose two efficient hardware architecture for GP accelerator. One architecture targets for general GP inference, and the other architecture is specifically optimized for the scenario when the data point is gradually observed. Evaluation results show that the proposed hardware accelerator provides significant hardware performance improvement than the general-purpose computing platform.
C1 [Deng, Chunhua; Liao, Siyu; Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   [Gong, Yongbin; Han, Feng; Yi, Jingang] Rutgers State Univ, Dept Mech & Aerosp, Piscataway, NJ USA.
RP Deng, CH (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
EM chunhua.deng@rutgers.edu; yg283@scarletmail.rutgers.edu;
   fh233@scarletmail.rutgers.edu; siyu.liao@rutgers.edu; jgyi@rutgers.edu;
   bo.yuan@soe.rutgers.edu
CR [Anonymous], 1996, SIAM, DOI DOI 10.1137/1.9781611971484
   Aslan S, 2009, INT CONF ELECTRO INF, P243
   Golub G. H., 2012, MATRIX COMPUTATIONS, V3
   Hertzmann, 2006, ADV NEURAL INFORM PR, P1441
   Karkooti M, 2005, 2005 39TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, VOLS 1 AND 2, P1625
   Lu TT, 2002, COMPUT MATH APPL, V43, P119, DOI 10.1016/S0898-1221(01)00278-4
   Luethi P, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P830, DOI 10.1109/APCCAS.2008.4746151
   Quiñonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939
   Singh CK, 2007, I CONF VLSI DESIGN, P836, DOI 10.1109/VLSID.2007.177
   Urtasun R., 2006, P 2006 IEEE COMP SOC, V1, P238, DOI DOI 10.1109/CVPR.2006.15
NR 10
TC 1
Z9 1
U1 0
U2 1
PY 2020
BP 121
EP 124
DI 10.1109/IEEECONF51394.2020.9443272
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Telecommunications
DA 2023-11-11
ER

PT C
AU Resch, S
   Khatamifard, SK
   Chowdhury, ZI
   Zabihi, M
   Zhao, ZY
   Cilasun, H
   Wang, JP
   Sapatnekar, SS
   Karpuzcu, UR
AF Resch, Salonik
   Khatamifard, S. Karen
   Chowdhury, Zamshed, I
   Zabihi, Masoud
   Zhao, Zhengyang
   Cilasun, Husrev
   Wang, Jian-Ping
   Sapatnekar, Sachin S.
   Karpuzcu, Ulya R.
GP IEEE COMP SOC
TI MOUSE: Inference In Non-volatile Memory for Energy Harvesting
   Applications
SO 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO 2020)
DT Proceedings Paper
CT 53rd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 17-21, 2020
CL ELECTR NETWORK
DE Intermittent computing; Processing-in-Memory
ID LOW-POWER; SOT-MRAM; TECHNOLOGIES; PERFORMANCE; MODEL
AB There is increasing demand to bring machine learning capabilities to low power devices. By integrating the computational power of machine learning with the deployment capabilities of low power devices, a number of new applications become possible. In some applications, such devices will not even have a battery, and must rely solely on energy harvesting techniques. This puts extreme constraints on the hardware, which must be energy efficient and capable of tolerating interruptions due to power outages. Here, we propose an in-memory machine learning accelerator utilizing non-volatile spintronic memory. The combination of processing-in-memory and non-volatility provides a key advantage in that progress is effectively saved after every operation. This enables instant shut down and restart capabilities with minimal overhead. Additionally, the operations are highly energy efficient leading to low power consumption.
C1 [Resch, Salonik; Khatamifard, S. Karen; Chowdhury, Zamshed, I; Zabihi, Masoud; Zhao, Zhengyang; Cilasun, Husrev; Wang, Jian-Ping; Sapatnekar, Sachin S.; Karpuzcu, Ulya R.] Univ Minnesota, Minneapolis, MN 55455 USA.
RP Resch, S (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
EM resc0059@umn.edu; khatami@umn.edu; chowh005@umn.edu; zabih003@umn.edu;
   zhaox526@umn.edu; cilas001@umn.edu; jpwang@umn.edu; sachin@umn.edu;
   ukarpuzc@umn.edu
CR Anguita Davide, 2013, ESANN
   [Anonymous], 2019, US
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Aouda F.A., 2014, RECOSOC, P1
   Balsamo D, 2016, IEEE T COMPUT AID D, V35, P1968, DOI 10.1109/TCAD.2016.2547919
   Balsamo D, 2016, IEEE T COMPUT AID D, V35, P738, DOI 10.1109/TCAD.2016.2527713
   Balsamo D, 2015, IEEE EMBED SYST LETT, V7, P15, DOI 10.1109/LES.2014.2371494
   Berthou G, 2017, 2017 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS 2017), P189
   Chandrakasan AP, 2008, SYMP VLSI CIRCUITS, P2, DOI 10.1109/VLSIC.2008.4585930
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chowdhury Z, 2018, IEEE COMPUT ARCHIT L, V17, P42, DOI 10.1109/LCA.2017.2751042
   Cilasun H, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218673
   Colin A, 2018, CC'18: PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON COMPILER CONSTRUCTION, P116, DOI 10.1145/3178372.3179525
   Colin A, 2018, ACM SIGPLAN NOTICES, V53, P767, DOI [10.1145/3296957.3173210, 10.1145/3173162.3173210]
   Colin A, 2016, ACM SIGPLAN NOTICES, V51, P514, DOI 10.1145/3022671.2983995
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   de Winkel J, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P53, DOI 10.1145/3373376.3378464
   Diao ZT, 2007, APPL PHYS LETT, V90, DOI 10.1063/1.2717556
   Dong XY, 2008, DES AUT CON, P554
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Dürrenfeld P, 2015, PHYS REV B, V92, DOI 10.1103/PhysRevB.92.214424
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fang Su, 2017, 2017 Symposium on VLSI Technology, pT260, DOI 10.23919/VLSIT.2017.7998149
   Ganesan K, 2019, INT S HIGH PERF COMP, P211, DOI 10.1109/HPCA.2019.00039
   Garello K, 2018, SYMP VLSI CIRCUITS, P81, DOI 10.1109/VLSIC.2018.8502269
   Gobieski G, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P199, DOI 10.1145/3297858.3304011
   Gobieski Graham, 2018, INTERMITTENT DEEP NE
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Harjani Ramesh, 2014, P IEEE CUSTOM INTEGR, P1
   Hester J., 2017, P 15 ACM C EMBEDDED, P17
   Hester J, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3131674
   Hester J, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P5, DOI 10.1145/2809695.2809707
   Hester Josiah, 2016, P ACM C EMBEDDED NET, P216, DOI [10.1145/2994551, DOI 10.1145/2994551.2994554]
   Hicks M, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P228, DOI 10.1145/3079856.3080238
   Hu G, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Hubara I, 2018, J MACH LEARN RES, V18
   Jan G, 2014, S VLSI TECH
   Jayakumar H, 2014, I CONF VLSI DESIGN, P330, DOI 10.1109/VLSID.2014.63
   Jian-PingWang Mahdi., 2016, NANOMAGNETIC SPINTRO, P133
   Jung W, 2014, ISSCC DIG TECH PAP I, V57, P398, DOI 10.1109/ISSCC.2014.6757486
   Kashiwada S., 2016, P IEEE S VLSI TECHNO, P1
   Kim S, 2014, P IEEE, V102, P1649, DOI 10.1109/JPROC.2014.2357031
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Kortbeek V, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P85, DOI 10.1145/3373376.3378476
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leonov V, 2013, IEEE SENS J, V13, P2284, DOI 10.1109/JSEN.2013.2252526
   Li SC, 2016, DES AUT CON, DOI [10.1145/2897937.2898064, 10.1109/ICAUMS.2016.8479697]
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu Q., 2016, NONV MEM SYST APPL S, P1
   Liu YP, 2015, DES AUT CON, DOI 10.1145/2744769.2747910
   Lucia B, 2015, ACM SIGPLAN NOTICES, V50, P575, DOI [10.1145/2813885.2737978, 10.1145/2737924.2737978]
   Lucia Brandon, 2017, 2 SUMM ADV PROGR LAN, V8, P1
   Lukosevicius Giedrius, 2017, P 5 ACM INT WORKSHOP, P31
   Ma KS, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P204, DOI 10.1145/3123939.3124533
   Ma KS, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3077575
   Ma KS, 2015, INT S HIGH PERF COMP, P526, DOI 10.1109/HPCA.2015.7056060
   Maeng K, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P129
   Maeng K, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133920
   Manic M, 2016, IEEE IND ELECTRON M, V10, P32, DOI 10.1109/MIE.2016.2615575
   Miguel JS, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P600, DOI [10.1109/MICR0.2018.00055, 10.1109/MICRO.2018.00055]
   Mizukami S, 2009, J APPL PHYS, V105, DOI 10.1063/1.3067607
   Noguchi H, 2015, ISSCC DIG TECH PAP I, V58, P136, DOI 10.1109/ISSCC.2015.7062963
   Oboril F, 2015, IEEE T COMPUT AID D, V34, P367, DOI 10.1109/TCAD.2015.2391254
   Raats M. M., 1991, Food Quality and Preference, V3, P89, DOI 10.1016/0950-3293(91)90028-D
   Ransford B, 2011, ACM SIGPLAN NOTICES, V46, P159, DOI [10.1145/1961296.1950386, 10.1145/1961295.1950386]
   Rarnadass YK, 2007, IEEE POWER ELECTRON, P2353
   Resch S, 2019, ACM T ARCHIT CODE OP, V16, DOI 10.1145/3357250
   Ruppel E, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P1085, DOI 10.1145/3314221.3314583
   Sample AP, 2008, IEEE T INSTRUM MEAS, V57, P2608, DOI 10.1109/TIM.2008.925019
   Sato H, 2014, APPL PHYS LETT, V105, DOI 10.1063/1.4892924
   Seok M, 2008, SYMP VLSI CIRCUITS, P188, DOI 10.1109/VLSIC.2008.4586001
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Van der Woude J, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P17
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Williams H, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P69, DOI 10.1145/3373376.3378478
   Xia L., 2016, P 53 ACMEDACIEEE ANN, P1
   Xia LX, 2016, DES AUT CON, DOI 10.1145/2897937.2898101
   Yu SM, 2016, INT EL DEVICES MEET
   Zabihi M, 2020, IEEE J EXPLOR SOLID-, V6, P71, DOI 10.1109/JXCDC.2020.2985314
   Zabihi M, 2019, IEEE T COMPUT, V68, P1159, DOI 10.1109/TC.2018.2858251
   Zabihi M, 2019, INT SYM QUAL ELECT, P52, DOI 10.1109/ISQED.2019.8697377
   Zhang CZ, 2019, IEEE T FUZZY SYST, V27, P278, DOI 10.1109/TFUZZ.2018.2856187
   Zhang JT, 2019, IEEE J EM SEL TOP C, V9, P358, DOI 10.1109/JETCAS.2019.2912352
NR 90
TC 15
Z9 15
U1 0
U2 1
PY 2020
BP 400
EP 414
DI 10.1109/MICRO50266.2020.00042
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Rahman, A
   Oh, S
   Lee, J
   Choi, K
AF Rahman, Atul
   Oh, Sangyun
   Lee, Jongeun
   Choi, Kiyoung
GP IEEE
TI Design Space Exploration of FPGA Accelerators for Convolutional Neural
   Networks
SO PROCEEDINGS OF THE 2017 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 20th Conference and Exhibition on Design, Automation and Test in Europe
   (DATE)
CY MAR 27-31, 2017
CL EPFL Campus, Lausanne, SWITZERLAND
HO EPFL Campus
AB The increasing use of machine learning algorithms, such as Convolutional Neural Networks (CNNs), makes the hardware accelerator approach very compelling. However the question of how to best design an accelerator for a given CNN has not been answered yet, even on a very fundamental level. This paper addresses that challenge, by providing a novel framework that can universally and accurately evaluate and explore various architectural choices for CNN accelerators on FPGAs. Our exploration framework is more extensive than that of any previous work in terms of the design space, and takes into account various FPGA resources to maximize performance including DSP resources, on-chip memory, and off-chip memory bandwidth. Our experimental results using some of the largest CNN models including one that has 16 convolutional layers demonstrate the efficacy of our framework, as well as the need for such a high-level architecture exploration approach to find the best architecture for a CNN model.
C1 [Rahman, Atul] Samsung Elect, Suwon, South Korea.
   [Oh, Sangyun; Lee, Jongeun] UNIST, Sch Elect & Comp Engn, Ulsan, South Korea.
   [Choi, Kiyoung] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
RP Lee, J (corresponding author), UNIST, Sch Elect & Comp Engn, Ulsan, South Korea.
EM jlee@unist.ac.kr
CR [Anonymous], 2012, ICML
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Nguyen D., 2017, DATE
   Peemen M, 2015, DES AUT TEST EUROPE, P169
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zisserman A., 2014, 14091556 ARXIV
NR 9
TC 26
Z9 27
U1 2
U2 10
PY 2017
BP 1147
EP 1152
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chantry, M
   Hatfield, S
   Dueben, P
   Polichtchouk, I
   Palmer, T
AF Chantry, Matthew
   Hatfield, Sam
   Dueben, Peter
   Polichtchouk, Inna
   Palmer, Tim
TI Machine Learning Emulation of Gravity Wave Drag in Numerical Weather
   Forecasting
SO JOURNAL OF ADVANCES IN MODELING EARTH SYSTEMS
DT Article
DE machine learning; numerical weather prediction
ID PARAMETERIZATION; CIRCULATION; CLIMATE
AB We assess the value of machine learning as an accelerator for the parameterization schemes of operational weather forecasting systems, specifically the parameterization of nonorographic gravity wave drag. Emulators of this scheme can be trained to produce stable and accurate results up to seasonal forecasting timescales. Generally, networks that are more complex produce emulators that are more accurate. By training on an increased complexity version of the existing parameterization scheme, we build emulators that produce more accurate forecasts. For medium range forecasting, we have found evidence that our emulators are more accurate than the version of the parametrization scheme that is used for operational predictions. Using the current operational CPU hardware, our emulators have a similar computational cost to the existing scheme, but are heavily limited by data movement. On GPU hardware, our emulators perform 10 times faster than the existing scheme on a CPU.
C1 [Chantry, Matthew; Palmer, Tim] Univ Oxford, Atmospher Ocean & Planetary Phys, Oxford, England.
   [Hatfield, Sam; Dueben, Peter; Polichtchouk, Inna] European Ctr Medium Range Weather Forecasts, Reading, Berks, England.
RP Chantry, M (corresponding author), Univ Oxford, Atmospher Ocean & Planetary Phys, Oxford, England.
EM matthew.chantry@physics.ox.ac.uk
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Baldi P., 2019, ARXIV PREPRINT ARXIV
   Bauer P., 2020, ECMWF SCALABILITY PR
   Bergstra J, 2013, PROC INT C MACH LEAR, V28, P115, DOI DOI 10.5555/3042817.3042832
   Blackford LS, 2002, ACM T MATH SOFTWARE, V28, P135, DOI 10.1145/567806.567807
   Brenowitz ND, 2018, GEOPHYS RES LETT, V45, P6289, DOI 10.1029/2018GL078510
   Brenowitz N.D., 2020, ARXIV PREPRINT ARXIV
   Brenowitz ND, 2019, J ADV MODEL EARTH SY, V11, P2728, DOI 10.1029/2019MS001711
   Chantry M, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0083
   Chevallier F, 1998, J APPL METEOROL, V37, P1385, DOI 10.1175/1520-0450(1998)037<1385:ANNAFA>2.0.CO;2
   Dijkstra HA, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00153
   Dunkerton TJ, 1997, J GEOPHYS RES-ATMOS, V102, P26053, DOI 10.1029/96JD03678
   ECMWF, 2018, IFS DOC CY45R1
   Ern M, 2004, J GEOPHYS RES-ATMOS, V109, DOI 10.1029/2004JD004752
   GARCIA RR, 1994, J ATMOS SCI, V51, P2238, DOI 10.1175/1520-0469(1994)051<2238:COTMMC>2.0.CO;2
   GARDNER CS, 1989, J ATMOS SCI, V46, P1838, DOI 10.1175/1520-0469(1989)046<1838:RLOOGW>2.0.CO;2
   Geer AJ, 2016, TELLUS A, V68, DOI 10.3402/tellusa.v68.30229
   Gentine P, 2018, GEOPHYS RES LETT, V45, P5742, DOI 10.1029/2018GL078202
   Gettelman A, 2021, J ADV MODEL EARTH SY, V13, DOI 10.1029/2020MS002268
   Hatfield S., 2021, ARXIV PREPRINT ARXIV
   Hatfield S, 2019, PROCEEDINGS OF THE PLATFORM FOR ADVANCED SCIENTIFIC COMPUTING CONFERENCE (PASC '19), DOI 10.1145/3324989.3325711
   Krasnopolsky V., 1997, RES ACTIVITIES ATMOS
   Morcrette JJ, 2008, MON WEATHER REV, V136, P4760, DOI 10.1175/2008MWR2590.1
   NVIDIA, 2017, NVID TESL V100 GPU A NVIDIA TESLA V100 GP
   O'Gorman PA, 2018, J ADV MODEL EARTH SY, V10, P2548, DOI 10.1029/2018MS001351
   Orr A, 2010, J CLIMATE, V23, P5905, DOI 10.1175/2010JCLI3490.1
   Ott J., 2020, ARXIV PREPRINT ARXIV
   Palmer T., 2020, ARXIV200704830
   Polichtchouk I, 2018, J ATMOS SCI, V75, P1525, DOI 10.1175/JAS-D-17-0304.1
   Polichtchouk I, 2018, GEOPHYS RES LETT, V45, P8612, DOI 10.1029/2018GL078981
   Ramachandran, 2017, ARXIV171005941, P1
   Rasp S., 2020, ARXIV PREPRINT ARXIV
   Rasp S, 2021, J ADV MODEL EARTH SY, V13, DOI 10.1029/2020MS002405
   Rasp S, 2018, P NATL ACAD SCI USA, V115, P9684, DOI 10.1073/pnas.1810286115
   Saffin L, 2020, Q J ROY METEOR SOC, V146, P1590, DOI 10.1002/qj.3754
   Scinocca JF, 2003, J ATMOS SCI, V60, P667, DOI 10.1175/1520-0469(2003)060<0667:AASNGW>2.0.CO;2
   Sonderby CK, 2020, METNET NEURAL WEATHE, V2003, DOI DOI 10.48550/ARXIV.2003.12140
   Ukkonen P, 2020, J ADV MODEL EARTH SY, V12, DOI 10.1029/2020MS002226
   Vána F, 2017, MON WEATHER REV, V145, P495, DOI 10.1175/MWR-D-16-0228.1
   Veerman MA, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0095
   Warner CD, 2001, J ATMOS SCI, V58, P1837, DOI 10.1175/1520-0469(2001)058<1837:AUSPFN>2.0.CO;2
   Weyn JA, 2019, J ADV MODEL EARTH SY, V11, P2680, DOI 10.1029/2019MS001705
   Yuval J, 2021, GEOPHYS RES LETT, V48, DOI 10.1029/2020GL091363
   Yuval J, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17142-3
NR 44
TC 20
Z9 20
U1 0
U2 8
PD JUL
PY 2021
VL 13
IS 7
AR e2021MS002477
DI 10.1029/2021MS002477
WC Meteorology & Atmospheric Sciences
DA 2023-11-11
ER

PT J
AU Mateo-Garcia, G
   Veitch-Michaelis, J
   Smith, L
   Oprea, SV
   Schumann, G
   Gal, Y
   Baydin, AG
   Backes, D
AF Mateo-Garcia, Gonzalo
   Veitch-Michaelis, Joshua
   Smith, Lewis
   Oprea, Silviu Vlad
   Schumann, Guy
   Gal, Yarin
   Baydin, Atilim Guenes
   Backes, Dietmar
TI Towards global flood mapping onboard low cost satellites with machine
   learning
SO SCIENTIFIC REPORTS
DT Article
ID WATER INDEX NDWI; SURFACE-WATER; HYPERION; MISSION; SYSTEM
AB Spaceborne Earth observation is a key technology for flood response, offering valuable information to decision makers on the ground. Very large constellations of small, nano satellites- 'CubeSats' are a promising solution to reduce revisit time in disaster areas from days to hours. However, data transmission to ground receivers is limited by constraints on power and bandwidth of CubeSats. Onboard processing offers a solution to decrease the amount of data to transmit by reducing large sensor images to smaller data products. The ESA's recent PhiSat-1 mission aims to facilitate the demonstration of this concept, providing the hardware capability to perform onboard processing by including a power-constrained machine learning accelerator and the software to run custom applications. This work demonstrates a flood segmentation algorithm that produces flood masks to be transmitted instead of the raw images, while running efficiently on the accelerator aboard the PhiSat-1. Our models are trained on WorldFloods: a newly compiled dataset of 119 globally verified flooding events from disaster response organizations, which we make available in a common format. We test the system on independent locations, demonstrating that it produces fast and accurate segmentation masks on the hardware accelerator, acting as a proof of concept for this approach.
C1 [Mateo-Garcia, Gonzalo] Univ Valencia, Valencia, Spain.
   [Veitch-Michaelis, Joshua] Liverpool John Moores Univ, Liverpool, Merseyside, England.
   [Smith, Lewis; Gal, Yarin; Baydin, Atilim Guenes] Univ Oxford, Oxford, England.
   [Oprea, Silviu Vlad] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
   [Schumann, Guy] Univ Bristol, Bristol, Avon, England.
   [Schumann, Guy] RED, RSS Hydro, Dudelange, Luxembourg.
   [Backes, Dietmar] Univ Luxembourg, Luxembourg, Luxembourg.
   [Backes, Dietmar] UCL, London, England.
RP Mateo-Garcia, G (corresponding author), Univ Valencia, Valencia, Spain.
EM Gonzalo.Mateo-Garcia@uv.es
CR Ahmad SK, 2020, IEEE T GEOSCI REMOTE, V58, P2471, DOI 10.1109/TGRS.2019.2950705
   [Anonymous], JRC YEARLY WATER CLA
   [Anonymous], WORLDFLOODS GITLAB R
   [Anonymous], 2002, SCI ENG GUIDE DIGITA
   [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   [Anonymous], S2CLOUDLESS SENTINEL
   [Anonymous], GLOBAL FLOOD INUNDAT
   Berger M, 2012, REMOTE SENS ENVIRON, V120, P84, DOI 10.1016/j.rse.2011.07.023
   Bonafilia D., 2020, P IEEE CVF C COMP VI, P210
   Camps A, 2018, INT GEOSCI REMOTE SE, P8285, DOI 10.1109/IGARSS.2018.8518405
   Centre for Research on the Epidemiology of Disasters, 2015, HUMAN COST WEATHER R
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cooley SW, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121306
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Doggett T, 2006, REMOTE SENS ENVIRON, V101, P447, DOI 10.1016/j.rse.2005.11.014
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Esposito M, 2019, PROC SPIE, V11131, DOI 10.1117/12.2532262
   Esposito M, 2018, PROC SPIE, V11180, DOI 10.1117/12.2535991
   Esposito M., 2019, ESA LIVING PLANET S, DOI [10.13140/RG.2.2.25659.67367, DOI 10.13140/RG.2.2.25659.67367]
   Estlin TA, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168764
   Francis R, 2017, SCI ROBOT, V2, DOI 10.1126/scirobotics.aan4582
   Giuffrida G, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142205
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9
   Griffin M, 2003, INT GEOSCI REMOTE SE, P86
   Gupta RK., 2019, P IEEECVF C COMPUTER, P1
   Havas C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122766
   Heidt H., 2000, ANN USU C SMALL SAT
   Huang B., 2019, ARXIV180512219CS
   International Charter, SPAC MAJ DIS
   Ip F, 2006, REMOTE SENS ENVIRON, V101, P463, DOI 10.1016/j.rse.2005.12.018
   Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
   Isikdogan LF, 2020, IEEE GEOSCI REMOTE S, V17, P1662, DOI 10.1109/LGRS.2019.2953261
   Jones JW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040374
   Mandanici E, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121014
   Manzillo P.F, 2017, 4S S
   Martinis S, 2015, INT J REMOTE SENS, V36, P3519, DOI 10.1080/01431161.2015.1060647
   Mateo-Garcia G. etal, 2019, ARXIV PREPRINT ARXIV
   Mateo-García G, 2021, IEEE J-STARS, V14, P747, DOI 10.1109/JSTARS.2020.3031741
   Mateo-García G, 2020, ISPRS J PHOTOGRAMM, V160, P1, DOI 10.1016/j.isprsjprs.2019.11.024
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   McFeeters SK, 2013, REMOTE SENS-BASEL, V5, P3544, DOI 10.3390/rs5073544
   Memon AA, 2015, EGYPT J REMOTE SENS, V18, P99, DOI 10.1016/j.ejrs.2015.03.003
   Nemni E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162532
   Oberstadler R, 1997, HYDROL PROCESS, V11, P1415, DOI 10.1002/(SICI)1099-1085(199708)11:10&lt;1415::AID-HYP532&gt;3.0.CO;2-2
   Pearlman JS, 2003, IEEE T GEOSCI REMOTE, V41, P1160, DOI 10.1109/TGRS.2003.815018
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Ploton P, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18321-y
   Rambour C., 2020, INT ARCH PHOTOGRAMME, V43, P1343, DOI DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-1343-2020
   Ronneberger O., 2015, P MED IM COMP COMP A, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Rudner TGJ, 2019, AAAI CONF ARTIF INTE, P702
   Schmitt M., 2019, ISPRS ANN PHOTOGRAMM, DOI [10.5194/isprs-annals-IV-2-W7-153-2019, 10.5194/isprs-annals-IV-2-W7-153-2019(, DOI 10.5194/ISPRS-ANNALS-IV-2-W7-153-2019, DOI 10.5194/ISPRS-ANNALS-IV-2-W7]
   Schumann GJP, 2019, HYDROL PROCESS, V33, P3138, DOI 10.1002/hyp.13547
   Schumann GJP, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081230
   Serpico SB, 2012, P IEEE, V100, P2946, DOI 10.1109/JPROC.2012.2198030
   Simard PY, 2003, PROC INT CONF DOC, P958
   Stringham C, 2019, INT GEOSCI REMOTE SE, P9248, DOI [10.1109/IGARSS.2019.8900410, 10.1109/igarss.2019.8900410]
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Twele A, 2016, INT J REMOTE SENS, V37, P2990, DOI 10.1080/01431161.2016.1192304
   United Nations, 2015, GLOBAL ASSESSMENT RE
   United Nations, 2019, GLOBAL ASSESSMENT RE
   VANE G, 1993, REMOTE SENS ENVIRON, V44, P127, DOI 10.1016/0034-4257(93)90012-M
   Wieland M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192330
   Wieland M, 2019, REMOTE SENS ENVIRON, V230, DOI 10.1016/j.rse.2019.05.022
NR 64
TC 39
Z9 39
U1 4
U2 9
PD MAR 31
PY 2021
VL 11
IS 1
AR 7249
DI 10.1038/s41598-021-86650-z
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Ramirez-Gargallo, G
   Garcia-Gasulla, M
   Mantovani, F
AF Ramirez-Gargallo, Guillem
   Garcia-Gasulla, Marta
   Mantovani, Filippo
GP IEEE
TI TensorFlow on state-of-the-art HPC clusters: a machine learning use case
SO 2019 19TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID
   COMPUTING (CCGRID)
SE IEEE-ACM International Symposium on Cluster Cloud and Grid Computing
DT Proceedings Paper
CT 19th Annual IEEE/ACM International Symposium on Cluster, Cloud, and Grid
   Computing (CCGRID)
CY MAY 14-17, 2019
CL Larnaca, CYPRUS
DE TensorFlow; High Performance Computing; Parallel Computing; Machine
   Learning; Image Recognition; Training; Arm; Power9; x86; Clusters
AB The recent rapid growth of the data-flow programming paradigm enabled the development of specific architectures, e.g., for machine learning. The most known example is the Tensor Processing Unit (TPU) by Google. Standard data-centers, however, still can not foresee large partitions dedicated to machine learning specific architectures. Within data-centers, the High-Performance Computing (HPC) clusters are highly parallel machines targeting a broad class of compute-intensive workflows, as such they can be used for tackling machine learning challenges. On top of this, HPC architectures are rapidly changing, including accelerators and instruction sets other than the classical x86 CPUs. In this blurry scenario, identifying which are the best hardware/software configurations to efficiently support machine learning workloads on HPC clusters is not trivial. In this paper, we considered the workflow of TensorFlow for image recognition. We highlight the strong dependency of the performance in the training phase on the availability of arithmetic libraries optimized for the underlying architecture. Following the example of Intel leveraging the MKL libraries for improving the TensorFlow performance, we plugged the Arm Performance Libraries into Tensorflow and tested on an HPC cluster based on Marvell ThunderX2 CPUs. Also, we performed a scalability study on three state-of-the-art HPC clusters based on different CPU architectures, x86 Intel Skylake, Arm-v8 Marvell ThunderX2, and PowerPC IBM Power9.
C1 [Ramirez-Gargallo, Guillem; Garcia-Gasulla, Marta; Mantovani, Filippo] Barcelona Supercomp Ctr, Comp Sci Dept, Barcelona, Spain.
RP Ramirez-Gargallo, G (corresponding author), Barcelona Supercomp Ctr, Comp Sci Dept, Barcelona, Spain.
EM guillem.ramirez@bsc.es; marta.garcia@bsc.es; filippo.mantovani@bsc.es
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alzantot Moustafa, 2017, MobiSys, V2017, P7, DOI 10.1145/3089801.3089805
   [Anonymous], 2018, ADV PARALLEL COMPUTI
   [Anonymous], 2019, TECH REP
   [Anonymous], 2018, FUTURE GENERATION CO
   Cunha R. L. d. F., 2018, P HIGH PERF MACH LEA
   Garcia-Gasulla M, 2018, INT CONF PARA PROC, DOI 10.1145/3229710.3229736
   Hasabnis N., 2018, ARXIV181201665
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Mantovani Filippo, 2018, Journal of Low Power Electronics and Applications, V8, DOI 10.3390/jlpea8020013
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Ould-Ahmed-Vall E., 2017, ACCELERATING TENSORF
   Rajovic N, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P444, DOI 10.1109/SC.2016.37
   Rudyy O., 2019, 2019 IEEE 33 INT PAR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sakiyama K., 2018, P HIGH PERF MACH LEA
   Sarbu P. - C., 2018, P HIGH PERF MACH LEA
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Shams S, 2017, INT CON DISTR COMP S, P1389, DOI 10.1109/ICDCS.2017.259
NR 19
TC 12
Z9 12
U1 0
U2 3
PY 2019
BP 526
EP 533
DI 10.1109/CCGRID.2019.00067
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT C
AU Cadambi, S
   Majumdar, A
   Becchi, M
   Chakradhar, S
   Graf, HP
AF Cadambi, Srihari
   Majumdar, Abhinandan
   Becchi, Michela
   Chakradhar, Srimat
   Graf, Hans Peter
GP ACM
TI A Programmable Parallel Accelerator for Learning and Classification
SO PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON
   PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES
DT Proceedings Paper
CT 19th International Conference on Parallel Architectures and Compilation
   Techniques
CY SEP 11-15, 2010
CL Austrian Acad Sci Vienna, Vienna, AUSTRIA
HO Austrian Acad Sci Vienna
DE Accelerator-based systems; parallel computing; heterogeneous computing;
   machine learning
ID RECOGNITION
AB For learning and classification workloads that operate on large amounts of unstructured data with stringent performance constraints, general purpose processor performance scales poorly with data size. In this paper, we present a programmable accelerator for this workload domain. To architect the accelerator, we profile five representative workloads, and find that their computationally intensive portions can be formulated as matrix or vector operations generating large amounts of intermediate data, which are then reduced by a secondary operation such as array ranking, finding max/min and aggregation. The proposed accelerator, called MAPLE, has hundreds of simple processing elements (PEs) laid out in a two-dimensional grid, with two key features. First, it uses in-memory processing where on-chip memory blocks perform the secondary reduction operations. By doing so, the intermediate data are dynamically processed and never stored or sent off-chip. Second, MAPLE uses banked off-chip memory, and organizes its PEs into independent groups each with its own off-chip memory bank. These two features together allow MAPLE to scale its performance with data size. This paper describes the MAPLE architecture, explores its design space with a simulator, and illustrates how to automatically map application kernels to the hardware. We also implement a 512-PE FPGA prototype of MAPLE and find that it is 1.5-10x faster than a 2.5 GHz quadcore Xeon processor despite running at a modest 125 MHz.
C1 [Cadambi, Srihari; Majumdar, Abhinandan; Becchi, Michela; Chakradhar, Srimat; Graf, Hans Peter] NEC Labs Amer Inc, Princeton, NJ 08540 USA.
RP Cadambi, S (corresponding author), NEC Labs Amer Inc, 4 Independence Way, Princeton, NJ 08540 USA.
EM cadambi@nec-labs.com; abhi@nec-labs.com; mbecchi@nec-labs.com;
   chak@nec-labs.com; hpg@nec-labs.com
CR BAI B, 2009, LEARNING RANK INFORM
   Burger D, 2004, COMPUTER, V37, P44, DOI 10.1109/MC.2004.65
   CADAMBI S, P IEEE S FCCM 2009 N
   CATANZARO B, 2008, MACH LEARN 25 INT C
   Chellapilla Kumar, 2006, HIGH PERFORMANCE CON
   COLLOBERT R, 2008, P 25 INT C MACH LEAR, V307, P160
   Cosatto E, 2008, P INT C PATT REC
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DIAMOND JR, 2008, P 13 ACM SIGPLAN PPO
   GRAF HP, 2008, NEURAL INFORM PR DEC
   Hall J., 2004, ACM WORKSH GEN PURP
   Kapasi UJ, 2003, COMPUTER, V36, P54, DOI 10.1109/MC.2003.1220582
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lloyd S., IEEE T INFORM THEORY, V28, P129
   MACQUEEN J, P BERK S MATH STAT P, P281
   Mei Tao, 2007, P 15 ACM INT C MULTI, P1075
   NASSE F, 2009, LNCS
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Platt J., 1999, ADV KERNEL METHODS S
   Raina R, 2009, P 26 INT C MACH LEAR
   ROUSSEAUX S, P 3 ANN REC SYST SUM
   Sankaradas M., 2009, P 20 IEEE INT C APPL
   SATO A, 1995, NIPS, P423
   SEILER L, ACM SIGGRAPH 2008
   Taylor MB, 2002, IEEE MICRO, V22, P25, DOI 10.1109/MM.2002.997877
   ZHUO L, 2005, ACM IEEE C SUP P 200
NR 27
TC 63
Z9 78
U1 1
U2 9
PY 2010
BP 273
EP 283
DI 10.1145/1854273.1854309
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Hughes, MC
   Shumlak, U
   Golingo, RP
   Nelson, BA
   Ross, MP
AF Hughes, M. C.
   Shumlak, U.
   Golingo, R. P.
   Nelson, B. A.
   Ross, M. P.
BE Sinars, D
   BottSuzuki, S
TI QUASI-STEADY ACCELERATOR OPERATION ON THE ZAP FLOW Z-PINCH
SO 9TH INTERNATIONAL CONFERENCE ON DENSE Z PINCHES
SE AIP Conference Proceedings
DT Proceedings Paper
CT 9th International Conference on Dense Z Pinches
CY AUG 03-07, 2014
CL Napa, CA
ID DEFLAGRATION
AB The ZaP Flow Z-Pinch Experiment utilizes sheared flows to stabilize an otherwise unstable equilibrium. The sheared flows are maintained by streaming high velocity plasma parallel to the pinch. Previous operations of the machine show depletion of the accelerator's neutral gas supply late in the pulse leading to pinch instability. The current distribution in the accelerator exhibits characteristic modes during this operation, which is corroborated by interferometric signals. The decrease in density precipitates a loss of plasma quiescence in the pinch, which occurs on a timescale related to the flow velocity from the plasma source. To abate the depletion, the geometry of the accelerator is altered to increase the neutral gas supply. The design creates a standing deflagration front in the accelerator that persists for the pulse duration. The new operating mode is characterized by the same diagnostics as the previous mode. The lessons learned in the accelerator operations have been applied to the design of a new experiment, ZaP-HD. This work was supported by grants from the Department of Energy and the National Nuclear Security Administration.
C1 [Hughes, M. C.; Shumlak, U.; Golingo, R. P.; Nelson, B. A.; Ross, M. P.] Univ Washington, Aerosp & Energet Res Program, Seattle, WA 98195 USA.
RP Hughes, MC (corresponding author), Univ Washington, Aerosp & Energet Res Program, Seattle, WA 98195 USA.
EM mchugs@uw.edu
CR CHENG DY, 1970, NUCL FUSION, V10, P305, DOI 10.1088/0029-5515/10/3/011
   Golingo RP, 2005, PHYS PLASMAS, V12, DOI 10.1063/1.1928249
   Golingo RP, 2003, REV SCI INSTRUM, V74, P2332, DOI 10.1063/1.1556956
   Shumlak U, 2012, FUSION SCI TECHNOL, V61, P119, DOI 10.13182/FST12-A13407
   WOODALL DM, 1985, J APPL PHYS, V57, P961, DOI 10.1063/1.334697
NR 5
TC 0
Z9 0
U1 0
U2 1
PY 2014
VL 1639
BP 88
EP 91
DI 10.1063/1.4904784
WC Physics, Applied
DA 2023-11-11
ER

PT J
AU Lopes, A
   Pereira, M
AF Lopes, Alba
   Pereira, Monica
TI Fast DSE of reconfigurable accelerator systems via ensemble machine
   learning
SO ANALOG INTEGRATED CIRCUITS AND SIGNAL PROCESSING
DT Article
DE Ensemble learning; Reconfigurable accelerators; DSE
AB Reconfigurable hardware accelerators (RAs) attached to processors have become a frequent choice to meet the performance demand of current embedded applications. However, answering when the combination of general purpose processors (GPPs) and RAs can provide the expected performance at the additional area and energy cost demands an extensive design space exploration (DSE). Performing DSE through hardware synthesis is an extremely time-consuming and costly task. High-level simulations are a faster and simpler DSE method at the cost of accuracy loss. Even so, the use of high-level simulation does not allow simulating all design solutions and meeting time-to-market. In this scenario, machine learning (ML) has become a promising solution to provide robustness to the DSE of large hardware designs by predicting aspects such as performance and energy. A main challenge in the design of a high-accuracy predictor is to select one ML algorithm to encompass a wide range of applications. In this context, ensemble learning is a promising solution since it can use multiple models and combine their predictions. In this work we employ the use of ensemble methods to simplify and speed up the DSE of GPPs with RAs. In our investigation, we evaluate three ensemble methods, Random Forest, AdaBoosting and Gradient Boosting. We compare them to the most used regression algorithms found in literature to perform DSE of computer architectures. Results show an error prediction rate below 2% for some benchmarks when using ensemble methods and a throughput of more than 6000 predictions per second when using Gradient Boosting.
C1 [Lopes, Alba] Inst Fed Rio Grande do Norte, Natal, RN, Brazil.
   [Pereira, Monica] Univ Fed Rio Grande do Norte, Natal, RN, Brazil.
RP Lopes, A (corresponding author), Inst Fed Rio Grande do Norte, Natal, RN, Brazil.
EM alba.lopes@ifrn.edu.br; monicapereira@dimap.ufrn.br
CR [Anonymous], 2013, MODERN PROCESSOR DES
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Bonaccorso G, 2017, MACHINE LEARNING ALG
   Brandalero M, 2019, DES AUT TEST EUROPE, P582, DOI [10.23919/date.2019.8715121, 10.23919/DATE.2019.8715121]
   Brandalero M, 2017, DES AUT TEST EUROPE, P1468, DOI 10.23919/DATE.2017.7927223
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breughe MB, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2678277
   Browniee J, 2019, 14 DIFFERENT TYPES L
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Compton K, 2002, ACM COMPUT SURV, V34, P171, DOI 10.1145/508352.508353
   Guo Q., 2011, 22 INT JOINT C ART I
   Guo Q, 2013, MICROPROCESS MICROSY, V37, P41, DOI 10.1016/j.micpro.2012.07.006
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Hartenstein R, 2011, RECONFIGURABLE COMPUTING: FROM FPGAS TO HARDWARE/SOFTWARE CODESIGN, P7, DOI 10.1007/978-1-4614-0061-5_2
   Ipek Engin, 2006, EFFICIENTLY EXPLORIN, V41
   Josipovic L, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126525
   Kareemullah H, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1500, DOI 10.1109/ICCSP.2017.8286636
   Kim RG, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243483
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Krawczyk B, 2017, INFORM FUSION, V37, P132, DOI 10.1016/j.inffus.2017.02.004
   Li HF, 2012, QUAL RELIAB ENG INT, V28, P67, DOI 10.1002/qre.1216
   Lin C, 2016, 2016 INTERNATIONAL SYMPOSIUM ON VLSI DESIGN, AUTOMATION AND TEST (VLSI-DAT)
   Liu F, 2019, P IEEE, V107, P1537, DOI 10.1109/JPROC.2019.2920341
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Lopes A., 2019, SBESC
   Malazgirt GA, 2017, J SYST ARCHITECT, V72, P3, DOI 10.1016/j.sysarc.2016.07.004
   Nair R, 1997, ACM COMP AR, P13, DOI 10.1145/384286.264125
   Ozisikyilmaz B, 2008, DES AUT CON, P966
   Palermo G, 2009, IEEE T COMPUT AID D, V28, P1816, DOI 10.1109/TCAD.2009.2028681
   Ponomarev D, 2001, INT SYMP MICROARCH, P90, DOI 10.1109/MICRO.2001.991108
   Ramchoun H, 2016, INT J INTERACT MULTI, V4, P26, DOI 10.9781/ijimai.2016.415
   Rutzig M. B, 2008, GERENCIAMENTO AUTOMA
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Beck ACS, 2007, VLSI-SOC 2007: PROCEEDINGS OF THE 2007 IFIP WG 10.5 INTERNATIONAL CONFERENCE ON VERY LARGE SCALE INTEGRATION, P66
   Seber GA, 2012, LINEAR REGRESSION AN, V329
   Singh G, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317867
   Song YS, 2017, NEUROCOMPUTING, V251, P26, DOI 10.1016/j.neucom.2017.04.018
   Sotiriou-Xanthopoulos E., 2016, ACM T EMBED COMPUT S, V15, P1, DOI DOI 10.1145/2866578
   WikiChip, WIK SEM COMP ENG
NR 39
TC 0
Z9 0
U1 1
U2 2
PD SEP
PY 2021
VL 108
IS 3
BP 495
EP 509
DI 10.1007/s10470-021-01885-0
EA MAY 2021
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT S
AU Yu, H
   Ni, LB
   Huang, HT
AF Yu, Hao
   Ni, Leibin
   Huang, Hantao
BE Vaidyanathan, S
   Volos, C
TI Distributed In-Memory Computing on Binary Memristor-Crossbar for Machine
   Learning
SO ADVANCES IN MEMRISTORS, MEMRISTIVE DEVICES AND SYSTEMS
SE Studies in Computational Intelligence
DT Article; Book Chapter
AB The recent emerging memristor can provide non-volatile memory storage but also intrinsic computing for matrix-vector multiplication, which is ideal for low-power and high-throughput data analytics accelerator performed in memory. However, the existing memristor-crossbar based computing is mainly assumed as a multi-level analog computing, whose result is sensitive to process non-uniformity as well as additional overhead from AD-conversion and I/O. In this chapter, we explore the matrix-vector multiplication accelerator on a binary memristor-crossbar with adaptive 1-bit-comparator based parallel conversion. Moreover, a distributed in-memory computing architecture is also developed with according control protocol. Both memory array and logic accelerator are implemented on the binary memristor-crossbar, where logic-memory pair can be distributed with protocol of control bus. Experiment results have shown that compared to the analog memristor-crossbar, the proposed binary memristor-crossbar can achieve significant area-saving with better calculation accuracy. Moreover, significant speedup can be achieved for matrix-vector multiplication in the neuron-network based machine learning such that the overall training and testing time can be both reduced respectively. In addition, large energy saving can be also achieved when compared to the traditional CMOS-based out-of-memory computing architecture.
C1 [Yu, Hao; Ni, Leibin; Huang, Hantao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
EM haoyu@ntu.edu.sg; nile0001@e.ntu.edu.sg; hhuang013@e.ntu.edu.sg
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   [Anonymous], IEEE DATE
   [Anonymous], ARXIV151109085
   [Anonymous], IEEE INT
   [Anonymous], 2015, MORE MOORE TECHNOLOG
   [Anonymous], 2014, DESIGN EXPLORATION E
   [Anonymous], 2010, CASIA FINGERPRINTV5
   [Anonymous], 2009, NEURAL NETWORKS LEAR
   [Anonymous], 2016, ADV APPL CHAOTIC SYS
   [Anonymous], ARXIV11114144
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Coates Adam, 2011, AISTATS, DOI DOI 10.1177/1753193410390845
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Fan DL, 2014, IEEE T NANOTECHNOL, V13, P574, DOI 10.1109/TNANO.2014.2312177
   Fei W, 2012, IEEE T VLSI SYST, V20, P1012, DOI 10.1109/TVLSI.2011.2136443
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   Higham NJ, 2009, WILEY INTERDISCIP RE, V1, P251, DOI 10.1002/wics.18
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G. B., 2008, WORKSHOP FACES INREA, P1
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kang W, 2014, 2014 IEEE 14TH INTERNATIONAL CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P1
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kouzes RT, 2009, COMPUTER, V42, P26, DOI 10.1109/MC.2009.26
   Kumar V, 2014, IEEE T COMP PACK MAN, V4, P1335, DOI 10.1109/TCPMT.2014.2326798
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lichman M., 2013, UCI MACHINE LEARNING
   Liu XF, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/950262
   Lu W., 2011, DES AUT C ASP DAC
   Matsunaga S, 2009, DES AUT TEST EUROPE, P433
   Müller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022
   Park S, 2013, DES AUT TEST EUROPE, P1637
   Shang Y, 2012, IEEE T CIRCUITS-I, V59, P1906, DOI 10.1109/TCSI.2011.2180441
   SINGH PN, 2007, CUST INT CIRC C CICC, P189
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Vaidyanathan Sundarapandian, 2016, ADV APPL NONLINEAR C, V635
   Wang YH, 2015, IEEE T NANOTECHNOL, V14, P998, DOI 10.1109/TNANO.2015.2447531
   Wang YH, 2014, IEEE T VLSI SYST, V22, P957, DOI 10.1109/TVLSI.2013.2265754
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Williams R., 2008, IEEE Spectrum, V45, P28, DOI 10.1109/MSPEC.2008.4687366
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yi-Chung Chen, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P367, DOI 10.1109/FPL.2012.6339206
   Yongtae Kim, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P328, DOI 10.1109/SOCC.2012.6398336
   Young Yang Liauw, 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P406, DOI 10.1109/ISSCC.2012.6177067
NR 48
TC 4
Z9 4
U1 0
U2 0
PY 2017
VL 701
BP 275
EP 304
DI 10.1007/978-3-319-51724-7_12
D2 10.1007/978-3-319-51724-7
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Rezaeizadeh, A
   Smith, RS
AF Rezaeizadeh, Amin
   Smith, Roy S.
TI Iterative Learning Control for the Radio Frequency Subsystems of a
   Free-Electron Laser
SO IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY
DT Article
DE Accelerator; iterative learning control (ILC); Klystron; pulse
   compressor; system identification
ID SYSTEMS
AB In linear particle accelerators used for free-electron lasers, it is often required that the electron hunches experience the same electric field as they pass through the accelerating structures. For radio frequency (RF) pulsed mode machines, like the SwissFEL, this means that the amplitude and phase of the RF pulses feeding the structures through the waveguides should he kept constant over the pulselength. This raises an interesting problem that can be addressed by an iterative learning control (ILC) technique. This method manipulates the input waveforms iteratively, in order to generate flat amplitude and phase pulses at the output of the system. In this paper, we introduce two ILC algorithms, one with a model and one without, which have been tested on three different high-power RF subsystems, namely, the klystron, pulse compressor, and RF Gun.
C1 [Rezaeizadeh, Amin] Sharif Univ Technol, Dept Elect Engn, Tehran 1458889694, Iran.
   [Smith, Roy S.] Swiss Fed Inst Technol, Automat Control Lab, CH-8092 Zurich, Switzerland.
RP Rezaeizadeh, A (corresponding author), Sharif Univ Technol, Dept Elect Engn, Tehran 1458889694, Iran.
EM aminre@sharif.ir; rsmith@control.ee.ethz.ch
CR Amann N, 1995, PROCEEDINGS OF THE 34TH IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-4, P1696, DOI 10.1109/CDC.1995.480384
   Amann N, 1996, IEE P-CONTR THEOR AP, V143, P217, DOI 10.1049/ip-cta:19960244
   [Anonymous], 2017, NEW HIGHL SWITZ RES
   ARIMOTO S, 1984, J ROBOTIC SYST, V1, P123, DOI 10.1002/rob.4620010203
   BRIGGS PAN, 1966, P I ELECTR ENG, V113, P1259, DOI 10.1049/piee.1966.0213
   Bristow DA, 2006, IEEE CONTR SYST MAG, V26, P96, DOI 10.1109/MCS.2006.1636313
   Falone A., 2011, P IPAC2011 SAN SEB S, P3179
   Fiebig A., 1990, P EUR PART C NIC FRA, P937
   Janssens P., 2011, P 18 IFAC WORLD C MI, P11556
   Kichhoff S, 2008, IEEE DECIS CONTR P, P3032, DOI 10.1109/CDC.2008.4739064
   Mueller F. L., 2012, 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012), P3276, DOI 10.1109/IROS.2012.6385647
   Rezaeizadeh A., 2016, THESIS EIDGENOSSISCH
   Rezaeizadeh A., 2014, P FEL2014 BAS SWITZ, P824
   Rezaeizadeh A, 2016, IEEE T NUCL SCI, V63, P842, DOI 10.1109/TNS.2015.2463103
   Schaer M., 2013, P INT PART ACC C SHA
   Schilcher T., 1998, THESIS
   Schollig Angela, 2009, 2009 European Control Conference (ECC), P1505
   Uchiyama M., 1978, Transactions of the Society of Instrument and Control Engineers, V14, P706
   VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5
   Zennaro R., 2013, P 4 INT PART ACC C I, P2827
NR 20
TC 3
Z9 3
U1 0
U2 5
PD SEP
PY 2018
VL 26
IS 5
BP 1567
EP 1577
DI 10.1109/TCST.2017.2727439
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Spanò, S
   Cardarilli, GC
   Di Nunzio, L
   Fazzolari, R
   Giardino, D
   Matta, M
   Nannarelli, A
   Re, M
AF Spano, Sergio
   Cardarilli, Gian Carlo
   Di Nunzio, Luca
   Fazzolari, Rocco
   Giardino, Daniele
   Matta, Marco
   Nannarelli, Alberto
   Re, Marco
TI An Efficient Hardware Implementation of Reinforcement Learning: The
   Q-Learning Algorithm
SO IEEE ACCESS
DT Article
DE Artificial intelligence; hardware accelerator; machine learning;
   Q-learning; reinforcement learning; SARSA; FPGA; ASIC; IoT; multi-agent
ID INTELLIGENCE
AB In this paper we propose an efficient hardware architecture that implements the Q-Learning algorithm, suitable for real-time applications. Its main features are low-power, high throughput and limited hardware resources. We also propose a technique based on approximated multipliers to reduce the hardware complexity of the algorithm. We implemented the design on a Xilinx Zynq Ultrascale + MPSoC ZCU106 Evaluation Kit. The implementation results are evaluated in terms of hardware resources, throughput and power consumption. The architecture is compared to the state of the art of Q-Learning hardware accelerators presented in the literature obtaining better results in speed, power and hardware resources. Experiments using different sizes for the Q-Matrix and different wordlengths for the fixed point arithmetic are presented. With a Q-Matrix of size 8 x 4 (8 bit data) we achieved a throughput of 222 MSPS (Mega Samples Per Second) and a dynamic power consumption of 37 mW, while with a Q-Matrix of size 256 x 16 (32 bit data) we achieved a throughput of 93 MSPS and a power consumption 611 mW. Due to the small amount of hardware resources required by the accelerator, our system is suitable for multi-agent IoT applications. Moreover, the architecture can be used to implement the SARSA (State-Action-Reward-State-Action) Reinforcement Learning algorithm with minor modifications.
C1 [Spano, Sergio; Cardarilli, Gian Carlo; Di Nunzio, Luca; Fazzolari, Rocco; Giardino, Daniele; Matta, Marco; Re, Marco] Univ Roma Tor Vergata, Dept Elect Engn, I-00133 Rome, Italy.
   [Nannarelli, Alberto] Danmarks Tekniske Univ, Dept Appl Math & Comp Sci, DK-2800 Lyngby, Denmark.
RP Spanò, S (corresponding author), Univ Roma Tor Vergata, Dept Elect Engn, I-00133 Rome, Italy.
EM spano@ing.uniroma2.it
CR Abed KH, 2006, PROCEEDINGS OF THE IEEE SOUTHEASTCON 2006, P279, DOI 10.1109/second.2006.1629364
   Abu-Mostafa Y. S., 2012, LEARNING FROM DATA, V4
   Cardarilli G. C., IEEE T CIRCUITS SY 2
   CHANDRAKASAN AP, 1992, IEEE J SOLID-ST CIRC, V27, P473, DOI 10.1109/4.126534
   Da Silva LMD, 2019, IEEE ACCESS, V7, P2782, DOI 10.1109/ACCESS.2018.2885950
   Deng Y, 2017, IEEE T NEUR NET LEAR, V28, P653, DOI 10.1109/TNNLS.2016.2522401
   François-Lavet V, 2018, FOUND TRENDS MACH LE, V11, P219, DOI 10.1561/2200000071
   Gan X., 2019, IEEE ACCESS, V7, P162127
   Gankidi P. R., 2017, AEROSP CONF PROC, P1
   Geva S., 1993, IEEE Control Systems Magazine, V13, P40, DOI 10.1109/37.236324
   He A, 2010, IEEE T VEH TECHNOL, V59, P1578, DOI 10.1109/TVT.2010.2043968
   Hwang KS, 2005, Proceedings of 2005 IEEE International Workshop on VLSI Design and Video Technology, P435, DOI 10.1109/IWVDVT.2005.1504643
   Ilikci B, 2019, 2019 COMPUTING, COMMUNICATIONS AND IOT APPLICATIONS (COMCOMAP), P449, DOI [10.1109/comcomap46287.2019.9018786, 10.1109/ComComAp46287.2019.9018786]
   Jang B., 2019, IEEE ACCESS, V7
   Jiang MX, 2019, IEEE ACCESS, V7, P32400, DOI 10.1109/ACCESS.2019.2901300
   Konar A, 2013, IEEE T SYST MAN CY-S, V43, P1141, DOI 10.1109/TSMCA.2012.2227719
   Levine S, 2016, J MACH LEARN RES, V17
   Li MJ, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEMS (ICISS 2019), P232, DOI 10.1145/3322645.3322693
   Lin JL, 2016, IEEE ACCESS, V4, P2439, DOI 10.1109/ACCESS.2016.2570255
   Liu Z., 2007, 50 MIDWEST S CIRCUIT, P827
   MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8
   Matta M, 2019, ELECTRON LETT, V55, P589, DOI 10.1049/el.2019.0244
   Matta M, 2019, IEEE ACCESS, V7, P124147, DOI 10.1109/ACCESS.2019.2938390
   Perez A., 1996, Proceedings of the Fifth International Conference on Microelectronics for Neural Networks and Fuzzy Systems. MicroNeuro'96, P337, DOI 10.1109/MNNFS.1996.493812
   Pillmeier MR, 2002, P SOC PHOTO-OPT INS, V4791, P436, DOI 10.1117/12.452034
   Qi H., 2017, P 5 INT C LEARN REPR
   Rummery GA, 1994, ONLINE Q LEARNING US
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Shao SY, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201702019
   Su Jiang, 2017, ACM SIGARCH COMPUTER, V44, P68, DOI 10.1145/3039902.3039915
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Wang QQ, 2019, IEEE ACCESS, V7, P73841, DOI 10.1109/ACCESS.2019.2920913
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wei C, 2015, IEEE T IND ELECTRON, V62, P6360, DOI 10.1109/TIE.2015.2420792
   Xilinx, SYNTH SIM DES GUID
   Xilinx, VIV DES SUIT US GUID
   Yuce B, 2014, IEEE T COMPUT, V63, P1868, DOI 10.1109/TC.2014.2315634
   Zhu J, 2018, IEEE INTERNET THINGS, V5, P2375, DOI 10.1109/JIOT.2017.2759728
NR 38
TC 33
Z9 33
U1 1
U2 12
PY 2019
VL 7
BP 186340
EP 186351
DI 10.1109/ACCESS.2019.2961174
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Werner, D
   Hempstead, M
   Juretus, K
   Savidis, I
AF Werner, David
   Hempstead, Mark
   Juretus, Kyle
   Savidis, Ioannis
GP IEEE
TI Machine Learning on the Thermal Side-Channel: Analysis of
   Accelerator-Rich Architectures
SO 2018 IEEE 36TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 36th IEEE International Conference on Computer Design (ICCD)
CY OCT 07-10, 2018
CL Orlando, FL
AB The thermal profiles of integrated circuits (ICs) have been leveraged as a side-channel in multiple circuit and architectural scenarios. Applications range from identifying hardware Trojans to estimating the per-core power consumption of homogeneous multicore processors. Such scenarios leverage the correlation between the on-chip location of the consumed power with some target information of interest, such as correlating the extra power consumption at a specific circuit position with the presence of a hardware Trojan. While the spatial correlation between the power consumption and thermal profiles applies to all ICs, there is a fundamental difference in the context of modern SoCs. The difference stems from the presence of hardware accelerators, in which localized power consumption corresponds to the system performing the specific task that a given accelerator executes.
   The work described in the paper demonstrates the implications of correlating the thermal and power profiles of SoCs by presenting two working case studies that determine, at runtime, 1) the activity factor of each accelerator and 2) whether or not a system is infected by malware. This work relies on preprocessing thermal images in order to obtain a spatial profile of the estimated power density and uses a modified version of a previously developed technique that is tailored for use with accelerator-rich ICs. The resulting power estimates are fed into machine learning models that predict the core activity factor with mean average errors between 3% and 5% for the highest performing core. The statistical models used for malware detection result in an AuROC score of up to 1.0 and 0.9 when the malware offsets the activity factor of a single core by 2.5% and the 3-sigma width of the workload activity factor distribution is 2.5% and 5%, respectively.
C1 [Werner, David; Hempstead, Mark] Tufts Univ, Medford, MA 02155 USA.
   [Juretus, Kyle; Savidis, Ioannis] Drexel Univ, Philadelphia, PA 19104 USA.
RP Werner, D (corresponding author), Tufts Univ, Medford, MA 02155 USA.
EM david.werner@tufts.edu; mark.hempstead@tufts.edu; kjj39@drexel.edu;
   isavidis@coe.drexel.edu
CR Brouchier J., 2009, THERMOCOMMUNICATION
   Chollet F., 2015, KERAS
   Cochran Ryan, 2010, Proceedings of the 16th ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED 2010), P331, DOI 10.1145/1840845.1840914
   Coskun AK, 2006, J LOW POWER ELECTRON, V2, P56, DOI 10.1166/jolpe.2006.007
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Hu KQ, 2013, DES AUT TEST EUROPE, P1271
   Hutter M., 2013, LECT NOTES COMPUTER
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Mao BL, 2015, ICCAD-IEEE ACM INT, P552, DOI 10.1109/ICCAD.2015.7372618
   Masti RJ, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P865
   Nazari A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P333, DOI 10.1145/3079856.3080223
   Nikovski D, 2016, IEEE IJCNN, P2811, DOI 10.1109/IJCNN.2016.7727554
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Reda S, 2018, IEEE SENS J, V18, P680, DOI 10.1109/JSEN.2017.2774704
   Reda S, 2017, DES AUT TEST EUROPE, P1739, DOI 10.23919/DATE.2017.7927274
   Schafer BC, 2008, IEEE T VLSI SYST, V16, P1475, DOI 10.1109/TVLSI.2008.2001140
   Shahzad F, 2016, SCIENCE, V353, P1137, DOI 10.1126/science.aag2421
   Singh A, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P51, DOI 10.1109/ESSCIRC.2017.8094523
   Strobel D, 2015, DES AUT TEST EUROPE, P139
NR 19
TC 2
Z9 2
U1 0
U2 3
PY 2018
BP 83
EP 91
DI 10.1109/ICCD.2018.00022
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Choudhury, R
   Ahamed, SR
   Guha, P
AF Choudhury, Rituparna
   Ahamed, Shaik Rafi
   Guha, Prithwijit
TI FPGA Implementation of Batch-Mode Depth-Pipelined Two Means Decision
   Tree
SO IEEE EMBEDDED SYSTEMS LETTERS
DT Article
DE Training; Pipeline processing; Hardware; Field programmable gate arrays;
   Computer architecture; Random access memory; Pipelines; Batch-mode
   training; field-programmable gate array (FPGA); machine learning (ML);
   training accelerator; two means decision tree (TMDT)
ID ACCELERATOR
AB Decision tree for classification tasks are learned from the input dataset and consist of split nodes and leaf nodes. This letter presents the hardware implementation of learning of two means decision tree (TMDT). To accommodate large-size datasets and hence, to increase accuracy, the training data is divided into small batches and one batch at a time is loaded into chip memory. The hardware is divided into two pipelines to optimize timing and resource consumption. The critical path of the architecture enables the field-programmable gate array (FPGA) to operate with maximum frequency of 62 MHz. Simulation results show that the proposed FPGA runs at least 27x and 26x faster than the C implementation and existing hardware, respectively.
C1 [Choudhury, Rituparna; Ahamed, Shaik Rafi; Guha, Prithwijit] IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
RP Choudhury, R (corresponding author), IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM ritup176102101@iitg.ac.in; rafiahamed@iitg.ac.in; pguha@iitg.ac.in
CR Behnke S, 1998, IEEE T NEURAL NETWOR, V9, P1352, DOI 10.1109/72.728387
   Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Choudhury R., 2021, SN COMPUT SCI, V2, P360, DOI [10.1007/s42979-021-00748-9, DOI 10.1007/S42979-021-00748-9]
   Choudhury R, 2021, IEEE T VLSI SYST, V29, P1465, DOI 10.1109/TVLSI.2021.3076081
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   Dheeru D., 2017, UCI MACHINE LEARNING
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Tong D, 2017, IEEE T PARALL DISTR, V28, P3046, DOI 10.1109/TPDS.2017.2714661
   Winterstein F, 2013, I C FIELD PROG LOGIC
NR 9
TC 0
Z9 0
U1 0
U2 0
PD MAR
PY 2023
VL 15
IS 1
BP 17
EP 20
DI 10.1109/LES.2022.3190001
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Lee, SK
   Whatmough, PN
   Donato, M
   Ko, GG
   Brooks, D
   Wei, GY
AF Lee, Sae Kyu
   Whatmough, Paul N.
   Donato, Marco
   Ko, Glenn G.
   Brooks, David
   Wei, Gu-Yeon
TI SMIV: A 16-nm 25-mm<SUP>2</SUP> SoC for IoT With Arm Cortex-A53, eFPGA,
   and Coherent Accelerators
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Programming; Throughput; Central Processing Unit; Software; Task
   analysis; Table lookup; Kernel; Deep neural networks (DNNs); embedded
   field-programmable gate array (eFPGA); hardware accelerators; Internet
   of Things (IoT); machine learning (ML); system-on-chip (SoC)
ID NEURAL-NETWORK ACCELERATOR; SRAM MACRO; CHIP; PROCESSOR; MEMORY;
   EFFICIENT; WEIGHT; TOPS
AB Emerging Internet of Things (IoT) devices necessitate system-on-chips (SoCs) that can scale from ultralow power always-on (AON) operation, all the way up to less frequent high-performance tasks at high energy efficiency. Specialized accelerators are essential to help meet these needs at both ends of the scale, but maintaining workload flexibility remains an important goal. This article presents a 25-mm(2) SoC in 16-nm FinFET technology which demonstrates targeted, flexible acceleration of key compute-intensive kernels spanning machine learning (ML), DSP, and cryptography. The SMIV SoC includes a dedicated AON sub-system, a dual-core Arm Cortex-A53 CPU cluster, an SoC-attached embedded field-programmable gate array (eFPGA) array, and a quad-core cache-coherent accelerator (CCA) cluster. Measurement results demonstrate: 1) 1236x power envelope, from 1.1 mW (only AON cluster), up to 1.36 W (whole SoC at maximum throughput); 2) 5.5-28.9x energy efficiency gain from offloading compute kernels from A53 to eFPGA; 3) 2.94x latency improvement using coherent memory access (CCA cluster); and 4) 55x MobileNetV1 energy per inference improvement on CCA compared to the CPU baseline. The overall flexibility-efficiency range on SMIV spans measured energy efficiencies of 1x (dual-core A53), 3.1x (A53 with SIMD), 16.5x (eFPGA), 54.9x (CCA), and 256x (AON) at a peak efficiency of 4.8 TOPS/W.
C1 [Lee, Sae Kyu; Whatmough, Paul N.; Ko, Glenn G.; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Lee, Sae Kyu] IBM Res, Yorktown Hts, NY 10598 USA.
   [Whatmough, Paul N.] Arm Res, Boston, MA 02451 USA.
   [Donato, Marco] Tufts Univ, Dept Elect & Comp Engn, Medford, MA 02155 USA.
RP Whatmough, PN (corresponding author), Arm Res, Boston, MA 02451 USA.
EM saekyu.lee@ibm.com; pwhatmough@eecs.harvard.edu; marco.donato@tufts.edu;
   gko@seas.harvard.edu; dbrooks@eecs.harvard.edu; gywei@g.harvard.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], 2015, INT C LEARN REPRESEN
   [Anonymous], 2017, ABS170404861 CORR
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Bratt I., 2018, P IEEE ACM SIGARCH H
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Greenhill D, 2017, ISSCC DIG TECH PAP I, P54, DOI 10.1109/ISSCC.2017.7870257
   Hinton G.E., 2012, ADV NEURAL INF PROCE, P1097
   Huang G.B., 2007, 0749 U MASSACHUSETTS
   Jia TY, 2021, IEEE J SOLID-ST CIRC, V56, P55, DOI 10.1109/JSSC.2020.3027953
   Jiao Y, 2020, ISSCC DIG TECH PAP I, P136, DOI 10.1109/ISSCC19947.2020.9062984
   Jung Kuk Kim, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC50, DOI 10.1109/VLSIC.2015.7231323
   Khailany B., 2018, ACMIEEE DAC, P1
   Kodali S, 2017, PR IEEE COMP DESIGN, P589, DOI 10.1109/ICCD.2017.102
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2019, IEEE SOLID-ST CIRC L, V2, P232, DOI 10.1109/LSSC.2019.2937440
   Lee SK, 2019, IEEE J SOLID-ST CIRC, V54, P1982, DOI 10.1109/JSSC.2019.2913098
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Lin CH, 2020, ISSCC DIG TECH PAP I, P134, DOI 10.1109/ISSCC19947.2020.9063111
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Milder P, 2012, ACM T DES AUTOMAT EL, V17, DOI 10.1145/2159542.2159547
   Moons B, 2018, IEEE CUST INTEGR CIR
   Moons B, 2016, SYMP VLSI CIRCUITS
   Oh J., 2020, P IEEE S VLSI CIRC, P1
   Price P., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P651, DOI 10.1109/ICASSP.1988.196669
   Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085
   Rovinski A, 2019, IEEE SOLID-ST CIRC L, V2, P289, DOI 10.1109/LSSC.2019.2953847
   Sadri M., 2013, 10 FPGAWORLD C ACAD, P1, DOI [10.1145/2513683.2513688, DOI 10.1145/2513683.2513688]
   Schmidt C, 2021, ISSCC DIG TECH PAP I, V64, P58, DOI 10.1109/ISSCC42613.2021.9365789
   Seelam R., 2019, IO DESIGN FLEXIBILIT
   Sinangil ME, 2021, IEEE J SOLID-ST CIRC, V56, P188, DOI 10.1109/JSSC.2020.3031290
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Stadtmann Tim, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P93, DOI 10.1109/ICMLA51294.2020.00024
   Whatmough P. N., 2019, FIXYNN EFFICIENT HAR
   Whatmough P. N., 2018, P IEEE ACM SIGARCH H
   Whatmough PN, 2020, IEEE MICRO, V40, P32, DOI 10.1109/MM.2020.2995809
   Whatmough PN, 2018, IEEE J SOLID-ST CIRC, V53, P2722, DOI 10.1109/JSSC.2018.2841824
   Whatrnough PN, 2019, SYMP VLSI CIRCUITS, pC34, DOI 10.23919/VLSIC.2019.8778002
   Xi S, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3424669
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yuan FL, 2015, IEEE J SOLID-ST CIRC, V50, P137, DOI 10.1109/JSSC.2014.2372034
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zimmer B, 2020, IEEE J SOLID-ST CIRC, V55, P920, DOI 10.1109/JSSC.2019.2960488
NR 48
TC 5
Z9 5
U1 3
U2 7
PD FEB
PY 2022
VL 57
IS 2
BP 639
EP 650
DI 10.1109/JSSC.2021.3115466
EA OCT 2021
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yu, CH
   Wei, P
   Grossman, M
   Zhang, P
   Sarker, V
   Cong, J
AF Yu, Cody Hao
   Wei, Peng
   Grossman, Max
   Zhang, Peng
   Sarker, Vivek
   Cong, Jason
GP IEEE
TI S2FA: An Accelerator Automation Framework for Heterogeneous Computing in
   Datacenters
SO 2018 55TH ACM/ESDA/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 55th ACM/ESDA/IEEE Design Automation Conference (DAC)
CY JUN 24-28, 2018
CL San Francisco, CA
AB Big data analytics using the JVM-based MapReduce framework has become a popular approach to address the explosive growth of data sizes. Adopting FPGAs in datacenters as accelerators to improve performance and energy efficiency also attracts increasing attention. However, the integration of FPGAs into such JVM-based frameworks raises the challenge of poor programmability. Programmers must not only rewrite Java/Scala programs to C/C++ or OpenCL, but, to achieve high performance, they must also take into consideration the intricacies of FPGAs. To address this challenge, we present S2FA (Spark-to-FPGA-Accelerator), an automation framework that generates FPGA accelerator designs from Apache Spark programs written in Scala. S2FA bridges the semantic gap between object-oriented languages and HLS C while achieving high performance using learning-based design space exploration. Evaluation results show that our generated FPGA designs achieve up to 49.9. performance improvement for several machine learning applications compared to their corresponding implementations on the JVM.
C1 [Yu, Cody Hao; Wei, Peng; Cong, Jason] Univ Calif Los Angeles, Los Angeles, CA 90024 USA.
   [Yu, Cody Hao; Zhang, Peng; Cong, Jason] Falcon Comp Solut Inc, Santa Clara, CA USA.
   [Sarker, Vivek] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Grossman, Max] Rice Univ, Houston, TX 77251 USA.
RP Yu, CH (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.; Yu, CH (corresponding author), Falcon Comp Solut Inc, Santa Clara, CA USA.
EM hyu@cs.ucla.edu; peng.wei.prc@cs.ucla.edu; jmg3@rice.com;
   pengzhang@falcon-computing.com; vsarkar@gatech.edu; cong@cs.ucla.edu
CR [Anonymous], 2016, FPGAS SOFTWARE PROGR
   [Anonymous], TCAD
   [Anonymous], 2015, CORR
   Ansel J., 2014, PACT
   Chen Y.-T, 2016, HOTCLOUD
   Cong J., 2016, ISLPED
   Dean J., 2008, OSDI
   Fialho A., 2010, ANN MATH ARTIF INTEL
   Huang M., 2016, SOCC
   Koeplinger D., 2016, ISCA
   Liu H. -Y., 2013, DAC
   Prabhakar R., 2016, ASPLOS
   Putnam A., 2014, ISCA
   Rodriguez R., 2012, IJIR
   Schafer B. C., 2012, IET CDT
   Shannon C. E., 2001, ACM MC2R
   Smith T. F., 1981, JMB
   Wang Z, 2016, TPDS
   Wang Z., 2016, HPCA
   Xu C., 2017, FPGA
   Xydis S., 2015, TCAD
   Zaharia M., 2010, P 2 USENIX C HOT TOP, P10
   Zhong G., 2014, ICCD
   Zuo W., 2013, THESIS
NR 24
TC 17
Z9 17
U1 0
U2 0
PY 2018
DI 10.1145/3195970.3196109
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Wan, LP
   Zheng, FY
   Li, JQ
AF Wan, Lipeng
   Zheng, Fangyu
   Li, Jingqiang
BE GarciaAlfaro, J
   Li, S
   Poovendran, R
   Debar, H
   Yung, M
TI TESLAC: Accelerating Lattice-Based Cryptography with AI Accelerator
SO SECURITY AND PRIVACY IN COMMUNICATION NETWORKS, SECURECOMM 2021, PT I
SE Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering
DT Proceedings Paper
CT 17th EAI International Conference on Security and Privacy in
   Communication Networks (SecureComm)
CY SEP 06-09, 2021
CL ELECTR NETWORK
DE Lattice-based cryptosystems; Polynomial multiplication over rings; AI
   accelerator; Tensor Core; LAC
AB In this paper, we exploit AI accelerator to implement cryptographic algorithms. To the best of our knowledge, it is the first attempt to implement quantum-safe Lattice-Based Cryptography (LBC) with AI accelerator. However, AI accelerators are designed for machine learning workloads (e.g., convolution operation), and cannot directly deliver their strong power into the cryptographic computation. Noting that polynomial multiplication over rings is a kind of time-consuming computation in LBC, we utilize a straightforward approach to make the AI accelerator fit well for polynomial multiplication over rings. Additional non-trivial optimizations are also made to minimize the overhead of transformation, such as using low-latency shared memory, coalescing memory access. Moreover, based on NVIDIA AI accelerator, Tensor Core, we have implemented a prototype system named TESLAC and give a set of comprehensive experiments to evaluate its performance. The experimental results show TESLAC can reach tens of millions of operations per second, achieving a performance speedup of two orders of magnitude from the AVX2-accelerated reference implementation. Particularly, with some techniques, TESLAC can also be scaled to other LBC with larger modulo q.
C1 [Wan, Lipeng; Zheng, Fangyu] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.
   [Wan, Lipeng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Wan, Lipeng; Zheng, Fangyu] Chinese Acad Sci, Data Assurance & Commun Secur Res Ctr, Beijing, Peoples R China.
   [Li, Jingqiang] Univ Sci & Technol China, Sch Cyber Secur, Hefei, Peoples R China.
RP Zheng, FY (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.; Zheng, FY (corresponding author), Chinese Acad Sci, Data Assurance & Commun Secur Res Ctr, Beijing, Peoples R China.
EM zhengfangyu@iie.ac.cn
CR Aguilar-Melchor C, 2016, LECT NOTES COMPUT SC, V9610, P341, DOI 10.1007/978-3-319-29485-8_20
   Akleylek Sedat, 2016, Cryptography and Information Security in the Balkans. Second International Conference, BalkanCryptSec 2015. Revised Selected Papers: LNCS 9540, P155, DOI 10.1007/978-3-319-29172-7_10
   Alkim E, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P327
   [Anonymous], 2016, INT SYMP INTEGR CIRC
   Avanzi R., CRYSTALS KYBER ALGOR
   Aysu A, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE-ORIENTED SECURITY AND TRUST (HOST), P81, DOI 10.1109/HST.2013.6581570
   BARRETT P, 1987, LECT NOTES COMPUT SC, V263, P311
   Bernstein D. J., 2009, POSTQUANTUM CRYPTOGR, P1, DOI [DOI 10.1007/978-3-540-88702-7_1, DOI 10.1007/978-3-540-88702-7]
   Dai W, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P501, DOI 10.1109/HPCSim.2016.7568376
   DAnvers J.P., SABER MLWR BASED KEM
   Hoffstein J., 1998, Algorithmic Number Theory. Third International Symposium, ANTS-III. Proceedings, P267, DOI 10.1007/BFb0054868
   Jeremy Appleyard S.Y, PROGRAMMING TENSOR C
   Lee WK, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1923, DOI 10.1109/SmartWorld.2018.00322
   Lee WJ, 2021, J INTELL MANUF, V32, P393, DOI 10.1007/s10845-020-01578-x
   Lu X., 2018, CRYPTOLOGY EPRINT AR, P1009
   MONTGOMERY PL, 1985, MATH COMPUT, V44, P519, DOI 10.1090/S0025-5718-1985-0777282-X
   Nist F, 2013, FIPS 186 4 DIGITAL S
   Poppelmann Thomas, 2012, Progress in Cryptology - LATINCRYPT 2012. Proceedings of the 2nd International Conference on Cryptology and Information Security in Latin America, P139, DOI 10.1007/978-3-642-33481-8_8
   Post-quantum cryptography project N, POSTQUANTUM CRYPTOGR
   Post-quantum cryptography project N, ROUND 2 SUBM
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Seiler G, 2018, IACR CRYPTOLOGY EPRI, V39
   SHOR PW, 1994, AN S FDN CO, P124
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
NR 24
TC 1
Z9 1
U1 1
U2 1
PY 2021
VL 398
BP 249
EP 269
DI 10.1007/978-3-030-90019-9_13
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
DA 2023-11-11
ER

PT J
AU Döpp, A
   Eberle, C
   Howard, S
   Irshad, F
   Lin, JP
   Streeter, M
AF Doepp, Andreas
   Eberle, Christoph
   Howard, Sunny
   Irshad, Faran
   Lin, Jinpu
   Streeter, Matthew
TI Data-driven science and machine learning methods in laser-plasma physics
SO HIGH POWER LASER SCIENCE AND ENGINEERING
DT Review
DE deep learning; laser-plasma interaction; machine learning
ID X-RAY SOURCES; GLOBAL OPTIMIZATION; NEURAL-NETWORKS; WAKEFIELD
   ACCELERATORS; INVERSE PROBLEMS; IMAGING THEORY; INTENSITY; ALGORITHMS;
   FUSION; MICROTOMOGRAPHY
AB Laser-plasma physics has developed rapidly over the past few decades as lasers have become both more powerful and more widely available. Early experimental and numerical research in this field was dominated by single-shot experiments with limited parameter exploration. However, recent technological improvements make it possible to gather data for hundreds or thousands of different settings in both experiments and simulations. This has sparked interest in using advanced techniques from mathematics, statistics and computer science to deal with, and benefit from, big data. At the same time, sophisticated modeling techniques also provide new ways for researchers to deal effectively with situation where still only sparse data are available. This paper aims to present an overview of relevant machine learning methods with focus on applicability to laser-plasma physics and its important sub-fields of laser-plasma acceleration and inertial confinement fusion.
C1 [Doepp, Andreas; Eberle, Christoph; Howard, Sunny; Irshad, Faran; Lin, Jinpu] Ludwig Maximilians Univ Munchen, Coulombwall 1, D-85748 Garching, Germany.
   [Doepp, Andreas; Howard, Sunny] Univ Oxford, Dept Phys, Clarendon Lab, Oxford, England.
   [Streeter, Matthew] Queens Univ Belfast, Sch Math & Phys, Belfast, North Ireland.
RP Döpp, A (corresponding author), Ludwig Maximilians Univ Munchen, Coulombwall 1, D-85748 Garching, Germany.
EM a.doepp@lmu.de
CR Abadi M., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Albert F, 2016, PLASMA PHYS CONTR F, V58, DOI 10.1088/0741-3335/58/10/103001
   Barata JCA, 2012, BRAZ J PHYS, V42, P146, DOI 10.1007/s13538-011-0052-z
   Amorin C, 2019, STAT ANAL DATA MIN, V12, P505, DOI 10.1002/sam.11437
   Anirudh R., 2022, ARXIV
   [Anonymous], 1995, INTRO KALMAN FILTER
   Ardizzone L, 2019, Arxiv, DOI arXiv:1808.04730
   Ardizzone L, 2019, Arxiv, DOI [arXiv:1907.02392, 10.48550/arXiv.1907.02392]
   Arridge S, 2019, ACTA NUMER, V28, P1, DOI 10.1017/S0962492919000059
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Auger F, 2013, IEEE T IND ELECTRON, V60, P5458, DOI 10.1109/TIE.2012.2236994
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Balandat M., 2020, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1910.06403
   Balduzzi D, 2018, Arxiv, DOI arXiv:1702.08591
   Bartels R, 2000, NATURE, V406, P164, DOI 10.1038/35018029
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bedolla E, 2021, J PHYS-CONDENS MAT, V33, DOI 10.1088/1361-648X/abb895
   Beier NF, 2022, PHYS REV LETT, V129, DOI 10.1103/PhysRevLett.129.135001
   Ben Soltane I, 2022, J OPT SOC AM A, V39, P1881, DOI 10.1364/JOSAA.462367
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bermeitinger B, 2019, Arxiv, DOI arXiv:1906.11755
   Bethke F., 2021, ARXIV
   Betti R, 2016, NAT PHYS, V12, P435, DOI [10.1038/NPHYS3736, 10.1038/nphys3736]
   Betti R, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.155001
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Biscani F., 2020, J OPEN SOURCE SOFTW, V5, P2338, DOI DOI 10.21105/JOSS.02338
   Blackburn T. G., 2020, Reviews of Modern Plasma Physics, V4, DOI 10.1007/s41614-020-0042-0
   Blank J, 2020, IEEE ACCESS, V8, P89497, DOI 10.1109/ACCESS.2020.2990567
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Brehmer J, 2018, PHYS REV D, V98, DOI 10.1103/PhysRevD.98.052004
   Bruchon N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050781
   Brunton SL, 2016, P NATL ACAD SCI USA, V113, P3932, DOI 10.1073/pnas.1517384113
   Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]
   Burnham K. P., 2002, MODEL SELECTION MULT, DOI [DOI 10.1007/B97636, 10.1007/b97636]
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Cassou K., 2022, LPA ONL WORKSH CONTR
   Chagovets T, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041680
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chu XK, 2019, HIGH POWER LASER SCI, V7, DOI 10.1017/hpl.2019.52
   Clayton CE, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.105003
   Cole JM, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.011020
   Cole JM, 2015, SCI REP-UK, V5, DOI 10.1038/srep13244
   Cole JM, 2018, P NATL ACAD SCI USA, V115, P6335, DOI 10.1073/pnas.1802314115
   Commandeur J. J., 2007, INTRO STATE SPACE TI
   Condamine FP, 2021, REV SCI INSTRUM, V92, DOI 10.1063/5.0053281
   Cranmer K, 2020, P NATL ACAD SCI USA, V117, P30055, DOI 10.1073/pnas.1912789117
   Craxton RS, 2015, PHYS PLASMAS, V22, DOI 10.1063/1.4934714
   Cuomo S, 2022, J SCI COMPUT, V92, DOI 10.1007/s10915-022-01939-z
   CURRIN C, 1991, J AM STAT ASSOC, V86, P953, DOI 10.2307/2290511
   D. Bui Thang, 2017, Arxiv, DOI arXiv:1705.07131
   Daido H, 2012, REP PROG PHYS, V75, DOI 10.1088/0034-4885/75/5/056401
   Dann SJD, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.041303
   Danson C, 2015, HIGH POWER LASER SCI, V3, DOI 10.1017/hpl.2014.52
   Danson CN, 2019, HIGH POWER LASER SCI, V7, DOI 10.1017/hpl.2019.36
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dinh L, 2015, Arxiv, DOI arXiv:1410.8516
   Dixon L. C. W., 1978, GLOBAL OPTIMIZATION, V2, P1
   Djordjevic BZ, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0045449
   Döpp A, 2016, NUCL INSTRUM METH A, V830, P515, DOI 10.1016/j.nima.2016.01.086
   Dolier EJ, 2022, NEW J PHYS, V24, DOI 10.1088/1367-2630/ac7db4
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Döpp A, 2018, OPTICA, V5, P199, DOI 10.1364/OPTICA.5.000199
   Drake RP, 2009, PHYS PLASMAS, V16, DOI 10.1063/1.3078101
   Dunjko V, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aab406
   Ede JM, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/abd614
   Emma C, 2022, Arxiv, DOI arXiv:2203.09094
   Englesbe A, 2021, APPL OPTICS, V60, pG113, DOI 10.1364/AO.426240
   Esarey E, 2009, REV MOD PHYS, V81, P1229, DOI 10.1103/RevModPhys.81.1229
   Faure J, 2019, PLASMA PHYS CONTR F, V61, DOI 10.1088/1361-6587/aae047
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Finney LA, 2021, OPT COMMUN, V490, DOI 10.1016/j.optcom.2021.126902
   Fourmaux S, 2011, OPT LETT, V36, P2426, DOI 10.1364/OL.36.002426
   Fraga RAC, 2012, REV SCI INSTRUM, V83, DOI 10.1063/1.3681940
   Frazier P, 2009, INFORMS J COMPUT, V21, P599, DOI 10.1287/ijoc.1080.0314
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Gao Y, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.014601
   Garcia S., 2016, BIG DATA ANAL, V1, P9, DOI [10.1186/s41044-016-0014-0, DOI 10.1186/S41044-016-0014-0]
   Gauthier M, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4961270
   Gawlikowski J., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.03342
   Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013
   Genton MG, 2002, J MACH LEARN RES, V2, P299, DOI 10.1162/15324430260185646
   Genty G, 2021, NAT PHOTONICS, V15, P91, DOI 10.1038/s41566-020-00716-4
   George KM, 2019, HIGH POWER LASER SCI, V7, DOI 10.1017/hpl.2019.35
   GEYER CJ, 1991, COMPUTING SCIENCE AND STATISTICS, P156
   Gilks WR, 1995, MARKOV CHAIN MONTE C
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Glinec Y, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.025003
   Götzfried J, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.041015
   Götzfried J, 2018, NUCL INSTRUM METH A, V909, P286, DOI 10.1016/j.nima.2018.02.110
   Gonoskov A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43465-3
   Gonsalves AJ, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.084801
   Goodfellow I. J., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1406.2661
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Griffiths RR, 2020, CHEM SCI, V11, P577, DOI 10.1039/c9sc04026a
   Grondman I, 2012, IEEE T SYST MAN CY C, V42, P1291, DOI 10.1109/TSMCC.2012.2218595
   Guénot D, 2022, PHYS REV APPL, V17, DOI 10.1103/PhysRevApplied.17.064056
   Gutmann MU, 2016, J MACH LEARN RES, V17
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   Hah J, 2017, OPT EXPRESS, V25, P17271, DOI 10.1364/OE.25.017271
   Hatfield PW, 2021, NATURE, V593, P351, DOI 10.1038/s41586-021-03382-w
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZH, 2015, PHYS PLASMAS, V22, DOI 10.1063/1.4921159
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   He ZH, 2013, NEW J PHYS, V15, DOI 10.1088/1367-2630/15/5/053016
   Henig A, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.245003
   Hennig P, 2012, J MACH LEARN RES, V13, P1809
   Herzen J., 2022, J MACH LEARN RES, V23, P1
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Hochreiter S., 1991, UNTERSUCHUNGEN DYNAM, V91
   Hooker SM, 2013, NAT PHOTONICS, V7, P775, DOI [10.1038/nphoton.2013.234, 10.1038/NPHOTON.2013.234]
   Horn J., 1994, P 1 IEEE C EVOLUTION, P82, DOI 10.1109/ICEC.1994.350037
   Howard S, 2023, HIGH POWER LASER SCI, V11, DOI 10.1017/hpl.2022.35
   Hsu A, 2020, PHYS PLASMAS, V27, DOI 10.1063/1.5130585
   Hu LJ, 2020, OPT LETT, V45, P3741, DOI 10.1364/OL.395579
   Huang YB, 2014, COMPUT PHYS COMMUN, V185, P459, DOI 10.1016/j.cpc.2013.08.024
   Hüllermeier E, 2021, MACH LEARN, V110, P457, DOI 10.1007/s10994-021-05946-3
   Huh M, 2016, Arxiv, DOI [arXiv:1608.08614, 10.48550/arxiv.1608.08614, DOI 10.48550/ARXIV.1608.08614]
   Humbird KD, 2020, IEEE T PLASMA SCI, V48, P61, DOI 10.1109/TPS.2019.2955098
   Humbird KD, 2019, IEEE T NEUR NET LEAR, V30, P1286, DOI 10.1109/TNNLS.2018.2869694
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   Irshad F, 2023, Arxiv, DOI arXiv:2303.15825
   Irshad F, 2023, PHYS REV APPL, V19, DOI 10.1103/PhysRevResearch.5.013063
   Irshad F, 2023, Arxiv, DOI arXiv:2112.13901
   Jalas S, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.104801
   Rezende DJ, 2016, Arxiv, DOI [arXiv:1505.05770, DOI 10.48550/ARXIV.1505.05770]
   John J. St., 2021, PHYS REV ACCEL BEAMS, V24
   Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147
   Jourdain N, 2021, MATTER RADIAT EXTREM, V6, DOI 10.1063/5.0022120
   Kain V, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.124801
   Kalman R.E., 1960, T ASME J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kambara M, 2023, JPN J APPL PHYS, V62, DOI 10.35848/1347-4065/ac9189
   Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5
   Kassubeck M., 2018, IS T INT S EL IM SOC, P1331
   Kawaguchi S, 2022, JPN J APPL PHYS, V61, DOI 10.35848/1347-4065/ac7afb
   Kettle B, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.254801
   Khrennikov K, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.195003
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kirchen M, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.174801
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kluth G, 2020, PHYS PLASMAS, V27, DOI 10.1063/5.0006784
   Kneip S, 2011, APPL PHYS LETT, V99, DOI 10.1063/1.3627216
   Kneip S, 2010, NAT PHYS, V6, P980, DOI 10.1038/NPHYS1789
   Kneip S, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.035002
   Kodama R, 2001, NATURE, V412, P798, DOI 10.1038/35090525
   KOHLENBERG A, 1953, J APPL PHYS, V24, P1432, DOI 10.1063/1.1721195
   Kollig T, 2002, COMPUT GRAPH FORUM, V21, P557, DOI 10.1111/1467-8659.00706
   Kraft SD, 2018, PLASMA PHYS CONTR F, V60, DOI 10.1088/1361-6587/aaae38
   Kristiadi A, 2020, Arxiv, DOI [arXiv:2002.10118, DOI 10.48550/ARXIV.2002.10118, 10.48550/arXiv.2002.10118]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krumbugel MA, 1996, OPT LETT, V21, P143, DOI 10.1364/OL.21.000143
   Kutz JN, 2017, J FLUID MECH, V814, P1, DOI 10.1017/jfm.2016.803
   Labat M, 2023, NAT PHOTONICS, V17, P150, DOI 10.1038/s41566-022-01104-w
   Nguyen-Meidine LT, 2017, INT CONF IMAG PROC
   Leemans W., 2017, WORKSH LAS TECHN K B
   Leemans WP, 2006, NAT PHYS, V2, P696, DOI 10.1038/nphys418
   Leemans WP, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.245002
   Lehe R., 2017, GPU TECHN C
   Li HY, 2021, COMPUT PHYS COMMUN, V259, DOI 10.1016/j.cpc.2020.107644
   Li HS, 2020, INVERSE PROBL, V36, DOI 10.1088/1361-6420/ab6d57
   Li Z, 2020, OPT EXPRESS, V28, P10165, DOI 10.1364/OE.387987
   Liang JM, 2021, COMPUT OPTIM APPL, V79, P649, DOI 10.1007/s10589-021-00280-9
   Lim B, 2021, INT J FORECASTING, V37, P1748, DOI 10.1016/j.ijforecast.2021.03.012
   Lim B, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0209
   Lin J, 2019, OPT EXPRESS, V27, P10912, DOI 10.1364/OE.27.010912
   Lin JP, 2023, HIGH POWER LASER SCI, V11, DOI 10.1017/hpl.2023.1
   Lin JP, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0047940
   Lin JP, 2018, OPT COMMUN, V421, P79, DOI 10.1016/j.optcom.2018.03.075
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long ZC, 2018, Arxiv, DOI arXiv:1710.09668
   Loughran B, 2023, Arxiv, DOI arXiv:2303.00823
   Ma T, 2021, PLASMA PHYS CONTR F, V63, DOI 10.1088/1361-6587/ac1f67
   Ma Y, 2020, MATTER RADIAT EXTREM, V5, DOI 10.1063/5.0016034
   Macchi A, 2013, REV MOD PHYS, V85, P751, DOI 10.1103/RevModPhys.85.751
   MacKay D. J., 1998, NATO ASI SERIES F CO, V168, P133
   Mahieu B, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05791-4
   Maier AR, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.031039
   Malka V, 2012, PHYS PLASMAS, V19, DOI 10.1063/1.3695389
   Marco Alonso, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1557, DOI 10.1109/ICRA.2017.7989186
   Marklund M, 2006, REV MOD PHYS, V78, P591, DOI 10.1103/RevModPhys.78.591
   McClarren RG, 2021, PHYS LETT A, V396, DOI 10.1016/j.physleta.2021.127243
   Monga Vishal, 2020, Arxiv, DOI arXiv:1912.10557
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Moore AS, 2005, APPL PHYS B-LASERS O, V80, P101, DOI 10.1007/s00340-004-1672-6
   Moses EI, 2009, NUCL FUSION, V49, DOI 10.1088/0029-5515/49/10/104022
   MURAKAMI M, 1991, NUCL FUSION, V31, P1315, DOI 10.1088/0029-5515/31/7/007
   Nakamura K, 2017, IEEE J QUANTUM ELECT, V53, DOI 10.1109/JQE.2017.2708601
   Nayuki T, 2005, REV SCI INSTRUM, V76, DOI 10.1063/1.1942527
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Noaman-ul-Haq M, 2018, NUCL INSTRUM METH A, V883, P191, DOI 10.1016/j.nima.2017.11.075
   Nocedal J., 2007, SPRINGER SERIES OPER, V2nd
   O'Shea FH, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.122802
   Oliveri G, 2017, IEEE ANTENN PROPAG M, V59, P34, DOI 10.1109/MAP.2017.2731204
   Pascu T., 2022, LPA ONL WORKSH CONTR
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Peceli D., 2022, LPA ONL WORKSH CONTR
   Peng P, 2019, Arxiv, DOI arXiv:1901.05045
   Phuoc KT, 2012, NAT PHOTONICS, V6, P308, DOI [10.1038/NPHOTON.2012.82, 10.1038/nphoton.2012.82]
   Pilar J, 2018, PROC SPIE, V10511, DOI 10.1117/12.2290290
   Poder K, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.031004
   Pousa A. F., 2022, P 13 INT PART ACC C, P1761
   Powers ND, 2014, NAT PHOTONICS, V8, P29, DOI [10.1038/NPHOTON.2013.314, 10.1038/nphoton.2013.314]
   Poyneer LA, 2010, J OPT SOC AM A, V27, pA223, DOI 10.1364/JOSAA.27.00A223
   Prencipe I, 2017, HIGH POWER LASER SCI, V5, DOI 10.1017/hpl.2017.18
   Pukhov A, 2003, REP PROG PHYS, V66, P47, DOI 10.1088/0034-4885/66/1/202
   Quéré F, 2021, HIGH POWER LASER SCI, V9, DOI 10.1017/hpl.2020.46
   Radford A., US
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Raissi M, 2017, ARXIV
   Raissi M, 2017, Arxiv, DOI [arXiv:1711.10561, DOI 10.48550/ARXIV.1711.10561]
   Raissi M, 2020, SCIENCE, V367, P1026, DOI 10.1126/science.aaw4741
   Rasheed A, 2020, IEEE ACCESS, V8, P21980, DOI 10.1109/ACCESS.2020.2970143
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rechatin C, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/4/045023
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rehwald M., 2023, J PHYS C SER, V2420
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, 10.48550/ARXIV.1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Ristic B., 2003, KALMAN FILTER PARTIC
   Robinson APL, 2008, NEW J PHYS, V10, DOI 10.1088/1367-2630/10/1/013021
   Rodimkov Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21216982
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, 10.48550/arXiv.1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Roso Luis, 2018, EPJ Web of Conferences, V167, DOI 10.1051/epjconf/201816701001
   Rousse A, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.135005
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Rovige L, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.093401
   Salehi F, 2021, PHYS REV X, V11, DOI 10.1103/PhysRevX.11.021055
   Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Schumacher DW, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/04/C04023
   Schutt K. T., 2020, LECT NOTES PHYS
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sidky EY, 2005, J APPL PHYS, V97, DOI 10.1063/1.1928312
   Simpson RA, 2021, REV SCI INSTRUM, V92, DOI 10.1063/5.0043835
   Sisson SA, 2019, CH CRC HANDB MOD STA, P3
   Sistrunk E., 2017, CLEO SCI INNOVATIONS
   Smith JR, 2020, NEW J PHYS, V22, DOI 10.1088/1367-2630/abbfce
   Spears BK, 2018, PHYS PLASMAS, V25, DOI 10.1063/1.5020791
   Stiller P., 2020, ARXIV
   Stiller P., 2022, ARXIV
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Streeter MJV, 2023, HIGH POWER LASER SCI, V11, DOI 10.1017/hpl.2022.47
   Streeter MJV, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5027297
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842, 10.48550/arXiv.1409.4842]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tarantola A., 2005, INVERSE PROBLEM THEO, DOI [10.1137/1.9780898717921, DOI 10.1137/1.9780898717921]
   Thanh-Tung H, 2020, Arxiv, DOI arXiv:1807.04015
   Tyson R. K., 2022, PRINCIPLES ADAPTIVE, V5th
   Ushakov A., 2017, 8 INT PART ACC C, P3938
   Vaswani A, 2017, ADV NEUR IN, V30
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wager S., 2013, DROPOUT TRAINING ADA
   Wang WT, 2021, NATURE, V595, P516, DOI 10.1038/s41586-021-03678-x
   Wang XM, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2988
   Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039
   Watt R. A., 2021, THESIS IMPERIAL COLL
   Weisse N, 2023, HIGH POWER LASER SCI, V11, DOI 10.1017/hpl.2023.17
   Wenz J, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8568
   Willmann A., 2021, ARXIV
   Wu TL, 2019, PHYS REV E, V100, DOI 10.1103/PhysRevE.100.033311
   WYTHOFF BJ, 1993, CHEMOMETR INTELL LAB, V18, P115, DOI 10.1016/0169-7439(93)80052-J
   Yang KF, 2019, SWARM EVOL COMPUT, V44, P945, DOI 10.1016/j.swevo.2018.10.007
   Yoshitomi D, 2004, APPL PHYS B-LASERS O, V78, P275, DOI 10.1007/s00340-003-1400-7
   Yu HY, 2009, PHYS MED BIOL, V54, P2791, DOI 10.1088/0031-9155/54/9/014
   Yuan X, 2021, IEEE SIGNAL PROC MAG, V38, P65, DOI 10.1109/MSP.2020.3023869
   Zahavy T, 2018, OPTICA, V5, P666, DOI 10.1364/OPTICA.5.000666
   Zamith S, 2004, PHYS REV A, V70, DOI 10.1103/PhysRevA.70.011201
   Zhang H, 2018, MED PHYS, V45, pE886, DOI 10.1002/mp.13123
   Zliobaite I, 2016, STUD BIG DATA, V16, P91, DOI 10.1007/978-3-319-26989-4_4
   Zucchini W, 2009, MONOGR STAT APPL PRO, V110, P3
   Zylstra AB, 2022, NATURE, V601, P542, DOI 10.1038/s41586-021-04281-w
NR 287
TC 0
Z9 0
U1 12
U2 12
PD MAY 30
PY 2023
VL 11
AR e55
DI 10.1017/hpl.2023.47
WC Optics
DA 2023-11-11
ER

PT J
AU Zhou, TY
   Scalzo, F
   Jalali, B
AF Zhou, Tingyi
   Scalzo, Fabien
   Jalali, Bahram
TI Nonlinear Schrodinger Kernel for Hardware Acceleration of Machine
   Learning
SO JOURNAL OF LIGHTWAVE TECHNOLOGY
DT Article
DE Stimulated emission; Data acquisition; Optical imaging; Adaptive optics;
   Ultrafast optics; Optical sensors; Optical modulation; Machine learning;
   nonlinear optics; photonic hardware accelerator; physics-AI
ID REGRESSION; INFERENCE; OPTICS
AB Alternative machine learning approaches that have extremely low latency and can work with only a small training dataset are needed for applications where the insatiable demands of deep learning methods for computing power and large training data cannot be met. Here we report a new optical accelerator for AI that exploits femtosecond pulses for both data acquisition and computing enabling classification at short time scales for fast optical imaging, sensing, and metrology without increasing data dimensions. Modulation of data onto the spectrum of femtosecond optical pulses followed by projection into a new space using nonlinear optics reduces the latency in the nonlinear classification of certain data by orders of magnitude. This Femtocomputing approach is validated by the classification of various datasets, including brain intracranial pressure, cancer cell imaging, spoken digit recognition, and the classic exclusive OR benchmark for nonlinear operation. The concept is demonstrated by seeding the nonlinear effect that is responsible for many fascinating natural phenomena, such as optical rogue waves. Stimulation of nonlinear optical interactions with spectrally modulated data transforms the data such that a computationally-light linear algorithm can learn a nonlinear decision boundary that separates the data into the correct classes. Since the optical kernel is not trained, its performance is inevitably data-dependent. Quantitative comparison with a popular numerical kernel offers insights into how this physical technique accelerates inference. Single-shot operation is demonstrated using time stretch data acquisition.
C1 [Zhou, Tingyi; Jalali, Bahram] UCLA, Dept Elect & Comp Engn, Los Angeles, CA 90095 USA.
   [Scalzo, Fabien] UCLA, Dept Neurol & Comp Sci, Los Angeles, CA 90095 USA.
RP Jalali, B (corresponding author), UCLA, Dept Elect & Comp Engn, Los Angeles, CA 90095 USA.
EM tingyizhou@ucla.edu; fab@cs.ucla.edu; jalali@ucla.edu
CR Agrawal GP, 2000, LECT NOTES PHYS, V542, P195
   [Anonymous], 2014, INNOVATORS GROUP HAC
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boyraz O, 2004, OPT EXPRESS, V12, P5269, DOI 10.1364/OPEX.12.005269
   Cai D, 2007, IEEE I CONF COMP VIS, P214
   Cai D, 2011, VLDB J, V20, P21, DOI 10.1007/s00778-010-0189-3
   Chen CL, 2016, SCI REP-UK, V6, DOI 10.1038/srep21471
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Estakhri NM, 2019, SCIENCE, V363, P1333, DOI 10.1126/science.aaw2498
   Estebanez I, 2022, J LIGHTWAVE TECHNOL, V40, P55, DOI 10.1109/JLT.2021.3117921
   George JK, 2019, OPT EXPRESS, V27, P5181, DOI 10.1364/OE.27.005181
   Goda K, 2012, P NATL ACAD SCI USA, V109, P11630, DOI 10.1073/pnas.1204718109
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Jackson Z., 2018, JAKOBOVSKI FREE SPOK
   Kelkar PV, 1999, ELECTRON LETT, V35, P1661, DOI 10.1049/el:19991116
   Lacava C, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010103
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Mahjoubfar A, 2017, NAT PHOTONICS, V11, P341, DOI [10.1038/NPHOTON.2017.76, 10.1038/nphoton.2017.76]
   Minsky M., 1969, PERCEPTRONS INTRO CO
   Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458
   Scalzo F, 2013, IEEE T BIO-MED ENG, V60, P235, DOI 10.1109/TBME.2012.2210042
   Solli DR, 2007, NATURE, V450, P1054, DOI 10.1038/nature06402
   Solli DR, 2015, NAT PHOTONICS, V9, P704, DOI 10.1038/nphoton.2015.208
   Tan DTH, 2018, PHOTONICS RES, V6, pB50, DOI 10.1364/PRJ.6.000B50
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Thompson N. C., 2020, ARXIV200705558
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
NR 29
TC 7
Z9 7
U1 3
U2 13
PD MAR 1
PY 2022
VL 40
IS 5
BP 1308
EP 1319
DI 10.1109/JLT.2022.3146131
WC Engineering, Electrical & Electronic; Optics; Telecommunications
DA 2023-11-11
ER

PT C
AU Zhou, X
   Xu, ZL
   Wang, C
   Gao, MY
AF Zhou, Xing
   Xu, Zhilei
   Wang, Cong
   Gao, Mingyu
GP ACM
TI PPMLAC: High Performance Chipset Architecture for Secure Multi-Party
   Computation
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
DE MPC; Secret Sharing; Security; Privacy; Privacy-preserving Machine
   Learning; Hardware Accelerator; Side-channel Protection
ID RANDOM NUMBER GENERATOR
AB Privacy issue is a main concern restricting data sharing and cross-organization collaborations. While Privacy-Preserving Machine Learning techniques such as Multi-Party Computations (MPC), Homomorphic Encryption, and Federated Learning are proposed to solve this problem, no solution exists with both strong security and high performance to run large-scale, complex machine learning models. This paper presents PPMLAC, a novel chipset architecture to accelerate MPC, which combines MPC's strong security and hardware's high performance, eliminates the communication bottleneck from MPC, and achieves several orders of magnitudes speed up over software-based MPC. It is carefully designed to only rely on a minimum set of simple hardware components in the trusted domain, thus is robust against side-channel attacks and malicious adversaries. Our FPGA prototype can run mainstream large-scale ML models like ResNet in near real-time under a practical network environment with non-negligible latency, which is impossible for existing MPC solutions.
C1 [Zhou, Xing; Xu, Zhilei; Wang, Cong] Shanghai ZiXian Technol, Shanghai, Peoples R China.
   [Xu, Zhilei] Shanghai Jiao Tong Univ, Qing Yuan Res Inst, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Gao, Mingyu] Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing, Peoples R China.
RP Xu, ZL (corresponding author), Shanghai Jiao Tong Univ, Qing Yuan Res Inst, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM zhouxing@msn.cn; timxu@sjtu.edu.cn; wcon006@gmail.com;
   gaomy@tsinghua.edu.cn
CR ACM CCS, 2021, PRIV PRES MACH LEARN
   Al-Rubaie M, 2019, IEEE SECUR PRIV, V17, P49, DOI 10.1109/MSEC.2018.2888775
   Anati Ittai, 2013, P 2 INT WORKSH HARDW, V13
   [Anonymous], 1987, P 19 ANN ACM S THEOR, DOI DOI 10.1145/28395.28420
   ARM, 2022, TRUSTZONE
   Bao Y., 2020, ARXIV
   BEAVER D, 1992, LECT NOTES COMPUT SC, V576, P420
   BEAVER D, 1990, PROCEEDINGS OF THE TWENTY SECOND ANNUAL ACM SYMPOSIUM ON THEORY OF COMPUTING, P503, DOI 10.1145/100216.100287
   Bendlin R, 2011, LECT NOTES COMPUT SC, V6632, P169, DOI 10.1007/978-3-642-20465-4_11
   Bogdanov D, 2008, LECT NOTES COMPUT SC, V5283, P192
   Boyd Colin, 2019, 20191362 CRYPT EPR
   Brederlow R., 2006, IEEE INT SOLID STATE, P536, DOI [10.1109/ISSCC.2006.1696222, DOI 10.1109/ISSCC.2006.1696222]
   BRICKELL EF, 1990, LECT NOTES COMPUT SC, V434, P468
   Canella C, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P769, DOI 10.1145/3319535.3363219
   Catrina O, 2010, LECT NOTES COMPUT SC, V6052, P35, DOI 10.1007/978-3-642-14577-3_6
   Chang J.M., 2022, PRIVACY PRESERVING M
   Chen G., 2018, ARXIV
   Cock M.d., 2015, P 8 ACM WORKSHOP ART, P3, DOI [10.1145/2808769.2808774, DOI 10.1145/2808769.2808774]
   Costan V, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P857
   Costan Victor, 2016, 2016086 CRYPT EPR
   Cramer R, 2005, LECT NOTES COMPUT SC, V3378, P342
   Cramer R, 2000, LECT NOTES COMPUT SC, V1807, P316
   Dahl M., 2018, ARXIV
   Damgard Ivan, 2012, Security and Cryptography for Networks. Proceedings of the 8th International Conference (SCN 2012), P241, DOI 10.1007/978-3-642-32928-9_14
   Damgård I, 2012, LECT NOTES COMPUT SC, V7417, P643
   Demmler D, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23113
   Demmler D, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P893
   Dugan T, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P173, DOI 10.1109/CHASE.2016.71
   Feng EH, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P275
   Ferraiuolo A, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P287, DOI 10.1145/3132747.3132782
   Gandolfi K., 2001, Cryptographic Hardware and Embedded Systems - CHES 2001. Third International Workshop. Proceedings (Lecture Notes in Computer Science Vol.2162), P251
   Gentry Craig, 2009, FULLY HOMOMORPHIC EN
   Gordon S.D., 2012, CCS 2012, P513, DOI DOI 10.1145/2382196.2382251.AVAILABLE
   Hao Chen, 2020, Advances in Cryptology - ASIACRYPT 2020. 26th International Conference on the Theory and Application of Cryptology and Information Security. Proceedings. Lecture Notes in Computer Science (LNCS 12393), P31, DOI 10.1007/978-3-030-64840-4_2
   Hastings M, 2019, P IEEE S SECUR PRIV, P1220, DOI 10.1109/SP.2019.00028
   Hazay Carmit, 2018, Advances in Cryptology - ASIACRYPT 2018. 24th International Conference on the Theory and Application of Cryptology and Information Security. Proceedings: Lecture Notes in Computer Science (LNCS 11274), P86, DOI 10.1007/978-3-030-03332-3_4
   Hazay C, 2018, LECT NOTES COMPUT SC, V10993, P3, DOI 10.1007/978-3-319-96878-0_1
   He K., 2016, P IEEE C COMPUTER VI
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keller M., 2013, P 2013 ACM SIGSAC C, P549, DOI DOI 10.1145/2508859.2516744.7
   Keller M, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1575, DOI 10.1145/3372297.3417872
   Keller M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P830, DOI 10.1145/2976749.2978357
   Knott Brian, 2021, ARXIV
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Kreuter B., 2016, ARXIV161104482
   Kumar N, 2020, P IEEE S SECUR PRIV, P336, DOI 10.1109/SP40000.2020.00092
   Lapets A, 2016, 2016 IEEE CYBERSECURITY DEVELOPMENT (IEEE SECDEV 2016), P73, DOI [10.1109/SecDev.2016.027, 10.1109/SecDev.2016.46]
   Lee D, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387532
   Li MY, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P717
   Li X, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P109
   Li Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1299, DOI 10.1145/3292500.3330920
   Lipp M, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P973
   Liu C, 2015, P IEEE S SECUR PRIV, P359, DOI 10.1109/SP.2015.29
   Liu Z, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00708-7
   Lyu L., 2020, ARXIV
   Mathew SK, 2012, IEEE J SOLID-ST CIRC, V47, P2807, DOI 10.1109/JSSC.2012.2217631
   Microsoft, 2021, AZ NETW ROUND TRIP L
   Mohassel P, 2017, P IEEE S SECUR PRIV, P19, DOI [10.1109/SP.2017.12, 10.1145/3132747.3132768]
   Mohassel P, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P35, DOI 10.1145/3243734.3243760
   Nielsen JB, 2012, LECT NOTES COMPUT SC, V7417, P681
   NVIDIA, 2022, CUDA GPUS
   Paszke A, 2019, ADV NEUR IN, V32
   Ragab Hany, 2021 IEEE S SEC PRIV, P1852, DOI [10.1109/SP40001.2021.00020, DOI 10.1109/SP40001.2021.00020]
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Riazi MS, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P707, DOI 10.1145/3196494.3196522
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Ruehle V., 2021, PRIVACY PRESERVING M
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samardzic N., 2021, MICRO2021, P238
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Schwarz Michael, 2019, CCS '19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, P753, DOI 10.1145/3319535.3354252
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shi E, 2011, LECT NOTES COMPUT SC, V7073, P197, DOI 10.1007/978-3-642-25385-0_11
   Sijun Tan, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P1021, DOI 10.1109/SP40001.2021.00098
   Skarlatos D, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P318, DOI 10.1145/3307650.3322228
   Tanenbaum, 1989, COMPUT NETW, P51
   Tiwari M, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P189
   Tokunaga C, 2008, IEEE J SOLID-ST CIRC, V43, P78, DOI 10.1109/JSSC.2007.910965
   v Gleissenthall K, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1411
   Van Bulck J, 2020, P IEEE S SECUR PRIV, P54, DOI 10.1109/SP40000.2020.00089
   Van Bulck J, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P991
   van Schaik S, 2019, P IEEE S SECUR PRIV, P88, DOI 10.1109/SP.2019.00087
   Wagh Sameer, 2018, 2018442 CRYPT EPR
   Yao AC., 1982, P 23 IEEE S FDN COMP, P160, DOI DOI 10.1109/SFCS.1982.38
   Yin XF, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3460427
   Ypma TJ, 1995, SIAM REV, V37, P531, DOI 10.1137/1037125
   Zahur Samee, 2015, IACR CRYPTOLOGY EPRI, P1153
   Zhang DF, 2015, ACM SIGPLAN NOTICES, V50, P503, DOI 10.1145/2694344.2694372
   Zhang Y, 2013, ACM C COMP COMM SEC, P813, DOI [10.1145/2508859.2516752, DOI 10.1145/2508859.2516752]
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhao Shijun, 2014, P 4 INT WORKSHOP TRU, P25, DOI [10.1145/2666141.2666145, DOI 10.1145/2666141.2666145]
NR 92
TC 5
Z9 5
U1 6
U2 10
PY 2022
BP 87
EP 101
DI 10.1145/3470496.3527392
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Motaman, S
   Ghosh, S
   Park, J
AF Motaman, Seyedhamidreza
   Ghosh, Swaroop
   Park, Jongsun
TI A Perspective on Test Methodologies for Supervised Machine Learning
   Accelerators
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article; Proceedings Paper
CT 1st AI Compute Symposium (AICS)
CY OCT 25, 2018
CL Yorktown Heights, NY
DE DFT; stuck at fault; neural network; hardware accelerator
ID FAULT-TOLERANCE
AB Neural Network (NN) accelerators are essential in many emerging applications e.g., autonomous systems in making mission-critical decisions, health-care solutions to assist with diagnoses, etc. Any soft or hard failure during operation can potentially have catastrophic consequences in many of these applications. For instance, inaccurate classification during object recognition and tracking in autonomous vehicles can lead to crashes and subsequent injuries to the passengers. Therefore, testing Neural Network accelerators to ensure reliability and integrity of the underlying hardware is a crucial task to ensure the functionality, especially the ones that are used in mission-critical applications. Conventional functional, stuck-at and delay tests are not sufficient to characterize the ML systems since they face new test and validation challenges. This paper is aimed to provide a perspective on new test requirements and design for test techniques to cover ML features and detect various type of faults in NN accelerator. We discuss First-In-First-Out (FIFO) and Scratchpad based neural network hardware accelerators and propose test methods to detect the faults as well as fault location in different modules of the accelerator including MAC unit, Activation function module, and Processing Element (PE) registers.
C1 [Motaman, Seyedhamidreza] Intel Inc, Santa Clara, CA 95054 USA.
   [Ghosh, Swaroop] Penn State Univ, Sch Elect Engn & Comp Sci, University Pk, PA 16802 USA.
   [Park, Jongsun] Korea Univ, Sch Elect Engn, Seoul 136701, South Korea.
RP Motaman, S (corresponding author), Intel Inc, Santa Clara, CA 95054 USA.
EM sxm844@psu.edu; szg212@psu.edu; jongsun@korea.ac.kr
CR Anghel L, 2018, J ELECTRON TEST, V34, P375, DOI 10.1007/s10836-018-5734-9
   [Anonymous], 2017, 2017 IEEE ACM INT S
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Choi W., 2019, P DESIGN AUTOMATION, P204
   Dixit VV, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168054
   EMMERSON MD, 1993, IEEE T NEURAL NETWOR, V4, P788, DOI 10.1109/72.248456
   Ho KIJ, 2010, IEEE T NEURAL NETWOR, V21, P938, DOI 10.1109/TNN.2010.2046179
   KHUNASARAPHAN C, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P1513, DOI 10.1109/ICNN.1994.374512
   Salami B., 2018, ARXIV180609679
   Torres-Huitzil C, 2017, IEEE ACCESS, V5, P17322, DOI 10.1109/ACCESS.2017.2742698
   Wang SH, 2017, DES AUT TEST EUROPE, P1032, DOI 10.23919/DATE.2017.7927142
   Wei NH, 1996, IEEE IJCNN, P247, DOI 10.1109/ICNN.1996.548899
NR 12
TC 7
Z9 7
U1 0
U2 6
PD SEP
PY 2019
VL 9
IS 3
BP 562
EP 569
DI 10.1109/JETCAS.2019.2933678
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Shetty, S
   Sundaram, R
   Achuthan, K
AF Shetty, Snehal
   Sundaram, Ranjany
   Achuthan, Krishnashree
TI Assessing and Comparing Top Accelerators in Brazil, India, and the USA:
   Through the Lens of New Ventures' Performance
SO ENTREPRENEURIAL BUSINESS AND ECONOMICS REVIEW
DT Article
DE accelerators; Resource Based View; start-ups; funding; performance
ID FIRM PERFORMANCE; START-UPS; ENTREPRENEURSHIP; FOUNDERS; SURVIVAL;
   IMPACT; GROWTH; GEM
AB Objective: The objective of this article is to assess and compare the factors influencing the performance of new ventures within top business accelerators across three countries using the Resource Based View (RBV) theory.
   Research Design & Methods: The key analysed parameters are funding dimensions, survivability, acquisition, and growth of 1286 new ventures that graduated from the top two accelerators in Brazil, India, and the USA, i.e. countries from developed and emerging economies. Methods we used were machine learning and two independent sample t-tests.
   Findings: Input seed funding by accelerators played a dominant role and improved funding trajectories. The external ecosystem was an important differentiator and impacted new ventures' survivability, growth, and funding outcomes. Capabilities and competencies of accelerators differentiated outcomes within the same ecosystem while external environment dampened accelerator outcomes in emerging economies.
   Implications & Recommendations: Accelerators from emerging ecosystems should strive to augment their human capital and network capabilities, including seed funding, while policy-makers should improve ecosystem index values mentioned in this study.
   Contribution & Value Added: This is the first of its kind study that extended the RBV theory to accelerators and disentangled the effect of the external environment and RBV on accelerators across three ecosystems with a comprehensive framework of measures. It provides value to practitioners in India and Brazil by highlighting lacunae in their accelerator programs and possible approaches to address them successfully.
C1 [Shetty, Snehal; Sundaram, Ranjany; Achuthan, Krishnashree] Amrita Vishwa Vidyapeetham, Kollam, Kerala, India.
   [Shetty, Snehal] Amrita TBI, Accelerator Program, Kollam, Kerala, India.
   [Sundaram, Ranjany] Amrita TBI, Accelerator Cohorts, Kollam, Kerala, India.
   [Achuthan, Krishnashree] Amrita Technol Business Incubator Amrita TBI, Kollam, Kerala, India.
RP Shetty, S; Sundaram, R; Achuthan, K (corresponding author), Amrita TBI, Kollam, Kerala, India.
EM snehal@amritatbi.com; ranjany@amritatbi.com; krishsnashree@amritatbi.com
CR Acs ZJ, 2004, REG STUD, V38, P911, DOI 10.1080/0034340042000280938
   Amezcua AS, 2013, ACAD MANAGE J, V56, P1628, DOI 10.5465/amj.2011.0652
   AMIT R, 1993, STRATEGIC MANAGE J, V14, P33, DOI 10.1002/smj.4250140105
   Battistella C, 2017, EUR J INNOV MANAG, V20, P80, DOI 10.1108/EJIM-10-2015-0113
   Besley T, 2015, J ECON PERSPECT, V29, P99, DOI 10.1257/jep.29.3.99
   Block J, 2009, VENTUR CAP, V11, P295, DOI 10.1080/13691060903184803
   Bloom N, 2012, ACAD MANAGE PERSPECT, V26, P12, DOI 10.5465/amp.2011.0077
   Bollingtoft A, 2012, TECHNOVATION, V32, P304, DOI 10.1016/j.technovation.2011.11.005
   Bosma Niels, 2013, Foundations and Trends in Entrepreneurship, V9, P143, DOI 10.1561/0300000033
   Bryl L, 2017, ENTREPR BUS ECON REV, V5, P195, DOI 10.15678/EBER.2017.050211
   Business D., 2013, DOING BUS 2014 UND R
   Cacciolatti L, 2020, J BUS RES, V106, P106, DOI 10.1016/j.jbusres.2019.08.047
   Cohen S., 2014, SSRN J, P1, DOI [10.2139/ssrn.2418000, DOI 10.2139/SSRN.2418000]
   Cohen S, 2019, RES POLICY, V48, P1781, DOI 10.1016/j.respol.2019.04.003
   Dahms S, 2016, ENTREPR BUS ECON REV, V4, P41, DOI 10.15678/EBER.2016.040304
   De Toni A, 2003, INT J OPER PROD MAN, V23, P947, DOI 10.1108/01443570310491729
   Eugene LY, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P158, DOI 10.1109/ASONAM.2012.36
   Eveleens CP, 2017, J TECHNOL TRANSFER, V42, P676, DOI 10.1007/s10961-016-9510-7
   Gonzalez-Uribe J, 2018, REV FINANC STUD, V31, P1566, DOI 10.1093/rfs/hhx103
   Goswami K, 2018, STRATEG ENTREP J, V12, P117, DOI 10.1002/sej.1281
   GRANT RM, 1991, CALIF MANAGE REV, V33, P114, DOI 10.2307/41166664
   Hallen B., 2014, ACAD MANAGEMENT ANN, V2014, P12955, DOI [https://doi.org/10.5465/ambpp.2014.185, 10.5465/ambpp.2014.185, DOI 10.5465/AMBPP.2014.185]
   Hart S. L., 1995, ACAD MANAGE REV, V20, P986, DOI [DOI 10.2307/258963, 10.5465/amr.1995.9512280033]
   Hochberg YV., 2016, INNOVATION POLICY EC, V16, P25
   Hoffman D., 2012, SMALL BUSINESS I J, V8, P54
   Hsu DH, 2007, RES POLICY, V36, P722, DOI 10.1016/j.respol.2007.02.022
   Kanbach D. K., 2016, J OFAPPLIED BUSINESS, V32, P1761, DOI 10.19030/jabr.v32i6.9822
   Kim JH, 2014, J CORP FINANC, V29, P520, DOI 10.1016/j.jcorpfin.2014.10.017
   Klyver Kim, 2008, International Journal of Entrepreneurship and Small Business, V6, P583, DOI 10.1504/IJESB.2008.019503
   Ko EJ, 2018, J BUS VENTURING, V33, P438, DOI 10.1016/j.jbusvent.2018.03.001
   Lisowska R, 2016, ENTREPR BUS ECON REV, V4, P85, DOI 10.15678/EBER.2016.040307
   Lyles MA, 2004, J MANAGE, V30, P351, DOI 10.1016/j.jm.2003.03.001
   Mansoori Y, 2019, TECHNOVATION, V84-85, P37, DOI 10.1016/j.technovation.2019.03.001
   Mayer-Haug K, 2013, RES POLICY, V42, P1251, DOI 10.1016/j.respol.2013.03.001
   Meschi PX, 2008, INT BUS REV, V17, P250, DOI 10.1016/j.ibusrev.2007.11.001
   Murphy GB, 1996, J BUS RES, V36, P15, DOI 10.1016/0148-2963(95)00159-X
   Pauwels C, 2016, TECHNOVATION, V50-51, P13, DOI 10.1016/j.technovation.2015.09.003
   Penrose Edith., 2009, THEORY GROWTH FIRM, DOI DOI 10.1093/0198289774.001.0001
   PORTER ME, 1991, STRATEGIC MANAGE J, V12, P95, DOI 10.1002/smj.4250121008
   Smith S.W., 2015, DRUID
   Sundaram, 2019, PROBLEMS PERSPECTIVE, V17, P78, DOI DOI 10.21511/PPM.17(1).2019.08
   Uhm CH, 2018, ASIA PAC J INNOV ENT, V12, P258, DOI 10.1108/APJIE-01-2018-0001
   van Stel A, 2007, SMALL BUS ECON, V28, P171, DOI 10.1007/s11187-006-9014-1
   Wise S, 2014, J PRIV EQUITY, V18, P9, DOI 10.3905/jpe.2014.18.1.009
   Wong PX, 2005, SMALL BUS ECON, V24, P335, DOI 10.1007/s11187-005-2000-1
   Xu SQ, 2020, INFORM SCIENCES, V515, P103, DOI 10.1016/j.ins.2019.11.045
   Yang S, 2018, ENTREP RES J, V8, DOI 10.1515/erj-2017-0140
   Yin BQ, 2018, IEEE T ENG MANAGE, V65, P574, DOI 10.1109/TEM.2018.2791501
   Zur A, 2013, ENTREPR BUS ECON REV, V1, P7
NR 49
TC 7
Z9 7
U1 2
U2 14
PD JUN
PY 2020
VL 8
IS 2
BP 153
EP 177
DI 10.15678/EBER.2020.080209
WC Economics
DA 2023-11-11
ER

PT C
AU Li, YH
   Ma, S
   Guo, Y
   Chen, GL
   Xu, R
AF Li, Yihuang
   Ma, Sheng
   Guo, Yang
   Chen, Guilin
   Xu, Rui
BE Xu, B
TI Single-Channel Dataflow for Convolutional Neural Network Accelerator
SO PROCEEDINGS OF 2018 IEEE 4TH INFORMATION TECHNOLOGY AND MECHATRONICS
   ENGINEERING CONFERENCE (ITOEC 2018)
DT Proceedings Paper
CT IEEE 4th Information Technology and Mechatronics Engineering Conference
   (ITOEC)
CY DEC 14-16, 2018
CL Chongqing, PEOPLES R CHINA
DE CNN; High Utilization; Single-Channel Dataflow
AB Convolutional Neural Networks (CNNs) are popular in Machine Learning and CNNs have rich parallelism. Many efficient CNN accelerators have been designed recently. Especially, the Tiling structure accelerators are widely used. However, we observe that the Tiling architecture may not be efficient when the network layers change. This situation will result in a waste of processing elements (PEs). In order to achieve a high-utilization of PEs, we propose a new architecture called Single-Channel to 1) ameliorate the Tiling architecture without increasing the hardware complexity while 2) improve the utilization of PEs. We evaluate the Single-Channel architecture with four typical CNN networks. The hardware achieves the 1.2-5x speedup and the 40%-60% utilization improvement compared with the Tiling architectures.
C1 [Li, Yihuang; Ma, Sheng; Guo, Yang; Chen, Guilin; Xu, Rui] Natl Univ Def Technol, Coll Comp, Changsha, Hunan, Peoples R China.
RP Li, YH (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha, Hunan, Peoples R China.
EM liyihuang@qq.com
CR Albericio J., 2016, BIT PRAGMATIC DEEP N, P382
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2013, P INT S COMPUTER ARC, DOI [DOI 10.1145/2508148.2485923), DOI 10.1145/2485922.2485923]
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   He K., 2015, ARXIV
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   TEMAM O, 2012, ACM SIGARCH COMPUTER, P356
NR 15
TC 0
Z9 0
U1 0
U2 0
PY 2018
BP 966
EP 970
WC Automation & Control Systems; Engineering, Electrical & Electronic;
   Engineering, Mechanical
DA 2023-11-11
ER

PT J
AU Arredondo-Velázquez, M
   Diaz-Carmona, J
   Barranco-Gutiérrez, AI
   Torres-Huitzil, C
AF Arredondo-Velazquez, Moises
   Diaz-Carmona, Javier
   Barranco-Gutierrez, Alejandro-Israel
   Torres-Huitzil, Cesar
TI Review of prominent strategies for mapping CNNs onto embedded systems
SO IEEE LATIN AMERICA TRANSACTIONS
DT Review
DE Convolutional Neural Networks (CNN); Deep Learning; Embedded systems;
   Field Programmable Gate Arrays (FPGAs); Hardware accelerators; Layer
   Operation Chaining; Machine Learning; Single computation engine;
   Streaming architectures
ID DEEP; NETWORKS; FEATURES; CLASSIFICATION; ACCELERATOR; CONVOLUTION;
   RECOGNITION; COPROCESSOR; DESCRIPTOR
AB Convolutional neural networks (CNN) have turned into one of the key algorithms in machine learning for content classification of digital images. Nevertheless, the CNN computational complexity is considerable larger than classic algorithms, thus, CPU- or GPU-based platforms are generally used for CNN implementations in many applications, but often do not fulfill portable requirements due to resources, energy and real-time constrains. Therefore, there is a growing interest on real time processing solutions for object recognition using CNNs mainly implemented on embedded systems, which are limited both in resources and energy consumption. An updated review of prominent reported approaches for mapping CNNs onto embedded systems is described in this paper. Two main solutions trends for reducing the hardware CNN workload are distinguished through a deduced taxonomy. One is focused on algorithm level solutions to reduce the number of multiplications and CNN coefficients. On the other hand, hardware level solutions goal is to achieve processing time, power consumption and hardware resources reduction. Two dominant hardware level design strategies are pointed out as oriented to either reducing the energy consumption and resources utilization meeting real-time requirements or increasing the throughput at the expense of resources utilization. Finally, two identified design strategies for CNN hardware accelerators are proposed as opportunity research areas.
C1 [Arredondo-Velazquez, Moises; Diaz-Carmona, Javier; Barranco-Gutierrez, Alejandro-Israel] Inst Tecnol Celaya, Tecnol Nacl Mexico, Ave Tecnol G Cubas S-N, Celaya 38010, Gto, Mexico.
   [Torres-Huitzil, Cesar] Tecnol Monterrey, Escuela Ingn & Ciencias, Campus Puebla,Ave Atlixcayotl 5718, Puebla 72453, Mexico.
RP Arredondo-Velázquez, M (corresponding author), Inst Tecnol Celaya, Tecnol Nacl Mexico, Ave Tecnol G Cubas S-N, Celaya 38010, Gto, Mexico.
EM D1603003@itcelaya.edu.mx; javier.diaz@itcelaya.edu.mx;
   israel.barranco@itcelaya.edu.mx; torresc@tec.mx
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], 2019, ARXIV190101965
   [Anonymous], OXF 1993 INT WORKSH
   [Anonymous], 2016, ARXIV161106473
   [Anonymous], 1980, ARITHMETIC COMPLEXIT
   [Anonymous], 2016, BITWISE NEURAL NETWO
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], COMPUTATIONAL INTELL
   [Anonymous], IEICE ELECT EXPRESS
   [Anonymous], CLIN RADIOLOGY
   [Anonymous], 2013, NIPS
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 2017, IEEE T VERY LARGE SC
   [Anonymous], 2017, IEEE EMBEDDED SYSTEM
   [Anonymous], SENSORS
   [Anonymous], 1989, ADV NEURAL INFORM PR
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, CORR
   [Anonymous], J INFORM COMPUTATION
   [Anonymous], IEEE EMBEDDED SYSTEM
   [Anonymous], 2017, ARXIV170309039
   Anthimopoulos M, 2010, IMAGE VISION COMPUT, V28, P1413, DOI 10.1016/j.imavis.2010.03.004
   Ardakani A, 2018, IEEE T CIRCUITS-I, V65, P1349, DOI 10.1109/TCSI.2017.2757036
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Balasubramanian R., 1994, Journal of Electronic Imaging, V3, P45, DOI 10.1117/12.165065
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Cong J, 2019, P IEEE, V107, P185, DOI 10.1109/JPROC.2018.2876372
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   DUNDAR A, 2017, IEEE T NEURAL NETWOR
   Erickson BJ, 2017, J DIGIT IMAGING, V30, P400, DOI 10.1007/s10278-017-9965-6
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Fidalgo E, 2016, NEUROCOMPUTING, V197, P119, DOI 10.1016/j.neucom.2016.02.045
   Gong Y., 2014, COMPRESSING DEEP CON
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Hailesellasie MT, 2019, IEEE ACCESS, V7, P47509, DOI 10.1109/ACCESS.2019.2907865
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hu H., 2016, ARXIV160703250
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jafari Ali, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348376
   Khammari M, 2015, INT J KNOWL-BASED IN, V19, P117, DOI 10.3233/KES-150313
   Khokher R, 2015, MACROMOL SYMP, V347, P16, DOI 10.1002/masy.201400045
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Lacey G., 2016, CORR
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   LeCun Y., 2013, ARXIV PREPRINT ARXIV
   Lee H, 2019, J ELECTROMAGN ENG SC, V19, P1, DOI 10.26866/jees.2019.19.1.1
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Li N, 2016, IEEE SW SYMP IMAG, P165, DOI 10.1109/SSIAI.2016.7459201
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu B, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030281
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Molchanov P., 2016, 5 INT C LEARNING REP
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Nakahara H, 2015, I C FIELD PROG LOGIC
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Peng TQ, 2017, INT CONF ACOUST SPEE, P1742, DOI 10.1109/ICASSP.2017.7952455
   Perlin HA, 2015, PATTERN RECOGN LETT, V68, P250, DOI 10.1016/j.patrec.2015.07.012
   Qi XB, 2016, NEUROCOMPUTING, V171, P1230, DOI 10.1016/j.neucom.2015.07.071
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi BG, 2016, PATTERN RECOGN, V52, P448, DOI 10.1016/j.patcog.2015.11.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Song LL, 2016, DES AUT CON, DOI 10.1145/2897937.2897995
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sullivan GJ, 1996, IEEE T INFORM THEORY, V42, P1365, DOI 10.1109/18.532878
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Wen W, 2016, ADV NEUR IN, V29
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Xie LL, 2018, IEEE T INTELL TRANSP, V19, P507, DOI 10.1109/TITS.2017.2784093
   Zang D, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033001
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhao Z Q, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI [DOI 10.1109/TNNLS.2018.2876865, 10.11091NNES.2018.2876865.]
   Zheng S, 2016, NEW ASTRON, V45, P54, DOI 10.1016/j.newast.2015.11.001
   Zunic D, 2014, APPL MATH COMPUT, V226, P406, DOI 10.1016/j.amc.2013.10.062
NR 113
TC 8
Z9 8
U1 6
U2 42
PD MAY
PY 2020
VL 18
IS 5
BP 971
EP 982
DI 10.1109/TLA.2020.9082927
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Gupta, L
   Edelen, A
   Neveu, N
   Mishra, A
   Mayes, C
   Kim, YK
AF Gupta, Lipi
   Edelen, Auralee
   Neveu, Nicole
   Mishra, Aashwin
   Mayes, Christopher
   Kim, Young-Kee
TI Improving surrogate model accuracy for the LCLS-II injector frontend
   using convolutional neural networks and transfer learning
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
DT Article
DE convolutional neural network; transfer learning; particle accelerator
   physics; surrogate modeling
AB Machine learning (ML) models of accelerator systems ('surrogate models') are able to provide fast, accurate predictions of accelerator physics phenomena. However, approaches to date typically do not include measured input diagnostics, such as the initial beam distributions, which are critical for accurately representing the beam evolution through the system. In addition, these inputs often vary over time, and models that can account for these changing conditions are needed. As beam time for measurements is often limited, simulations are in some cases needed to provide sufficient training data. These typically represent the designed machine before construction; however, the behavior of the installed components may be quite different due to changes over time or static differences that were not modeled. Therefore, surrogate models that can leverage both simulation and measured data successfully are needed. We introduce an approach based on convolutional neural networks that uses the drive laser distribution and scalar settings as inputs for a photoinjector system model (here, the linac coherent light source II, LCLS-II, injector frontend). The model is able to predict scalar beam parameters and the transverse beam distribution downstream, taking into account the impact of time-varying non-uniformities in the initial transverse laser distribution. We also introduce and evaluate a transfer learning procedure for adapting the surrogate model from the simulation domain to the measurement domain, to account for differences between the two. Applying this approach to our test case results in a model that can predict test sample outputs within a mean absolute percent error of 9%. This is a substantial improvement over the model trained only on simulations, which has an error of 261% when applied to measured data. While we focus on the LCLS-II Injector frontend, these approaches for improving ML-based online modeling of injector systems could be easily adapted to other accelerator facilities.
C1 [Gupta, Lipi; Kim, Young-Kee] Univ Chicago, Phys Dept, Chicago, IL 60637 USA.
   [Edelen, Auralee; Neveu, Nicole; Mishra, Aashwin; Mayes, Christopher] SLAC Natl Accelerator Lab, Menlo Pk, CA USA.
RP Gupta, L (corresponding author), Univ Chicago, Phys Dept, Chicago, IL 60637 USA.
EM lipigupta@uchicago.edu
CR [Anonymous], 2019, MACH LEARN PHYS SCI
   [Anonymous], 2019, NEURIPS MACHINE LEAR
   Bartnik A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.083401
   Brent R. P., 1973, ALGORITHMS MINIMIZAT
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chollet F., 2015, KERAS
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A., 2018, 1 ICFA MACH LEARN WO
   Edelen A., 2018, PROC IPAC, pP THYGBE2
   Edelen A., 2016, P NAPAC, pP TUOA51
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Emma C., 2019, P IBIC
   Floettmann K., 1997, ASTRA SPACE CHARGE T
   Gulliford C., 2019, DISTGEN PARTICLE DIS
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Komkov H., 2019, NEURIPS MACH LEARN P
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Mayes C., LUME ASTRA
   Nam J, 2018, IEEE T SOFTWARE ENG, V44, P874, DOI 10.1109/TSE.2017.2720603
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pratt L.Y., 1992, ADV NEURAL INFORM PR, V5, P204, DOI DOI 10.5555/645753.668046
   Sannibale F, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.103501
   Scheinker A., 2020, ADV CONTROL METHODS
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thrun S., 1998, LEARNING LEARN, DOI [10.1007/978-1-4615-5529-2_8, DOI 10.1007/978-1-4615-5529-2_8, 10.1007/978-1-4615-5529-2]
   Wang C., 2011, IJCAI P INT C ART IN, Vvol 22, pP 1541
   Zhou F, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.090701
NR 31
TC 5
Z9 5
U1 2
U2 5
PD DEC
PY 2021
VL 2
IS 4
AR 045025
DI 10.1088/2632-2153/ac27ff
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Yen, J
   Chen, B
   Wu, KZ
   Yen, J
AF Yen, Jerome
   Chen, Bangren
   Wu, KangZhang
   Yen, Joseph
TI Fast generation of implied volatility surface: Optimize the traditional
   numerical analysis and machine learning
SO INTERNATIONAL JOURNAL OF FINANCIAL ENGINEERING
DT Article
DE Implied volatility; machine learning; Newton-Raphson; polynomial
   regression
AB Machine learning has been used in financial markets in supporting many tasks, such as, asset movement forecasting and trading signal generation. Monte Carlo simulation and traditional numerical methods like Newton-Raphson have also been widely applied in financial markets, such as calculation for implied volatility (IV) and pricing of financial products. Is it possible to combine such approaches to more efficiently calculate the IVs to support the generation of IV surface, term structure, and smile? In this paper, we propose a framework that combines the traditional approaches and modern machine learning to support such calculation. In addition, we also propose an adaptive Newton-Raphson to reduce the number of iterations and the possibility of falling into local minimal over the traditional Newton-Raphson. Combining the superiorities of modern machine learning and adaptive Newton-Raphson, an improvement on computation efficiency over pure traditional numerical approaches was achieved. In addition, we also take into consideration of migrating such computation to hardware accelerators such as Graphics cards (GPU) and Field Programmable Gate Arrays (FPGA), to further speed up the computation. Therefore, polynomial regression has also been tested to generate the initial guess of IVs to pave the road of such migration.
C1 [Yen, Jerome] Univ Macau, Comp & Informat Sci, Macau, Peoples R China.
   [Chen, Bangren] Univ Hong Kong, Comp Sci, Hong Kong, Peoples R China.
   [Wu, KangZhang] Univ Hong Kong, Elect & Elect Engn, Hong Kong, Peoples R China.
   [Yen, Joseph] Univ Macau, Elect Mech Engn, Macau, Peoples R China.
RP Yen, J (corresponding author), Univ Macau, Elect Mech Engn, Macau, Peoples R China.
EM jeromeyen@um.edu.mo; bangrenc@connect.hku.hk; kenecho@connect.hku.hk;
   yb87412@umac.mo
CR ackel P. J, 2006, WILMOTT, V26, P60
   [Anonymous], 2016, KDD16 P 22 ACM, DOI DOI 10.1145/2939672.2939785
   Audrinoa F., 2008, 200742 U ST GALL DEP
   BLACK F, 1973, J POLIT ECON, V81, P637, DOI 10.1086/260062
   Brenner Menachem, 1988, FINANCIAL ANAL J, V44, P80
   Corrado CJ, 1996, J BANK FINANC, V20, P595, DOI 10.1016/0378-4266(95)00014-3
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Glau K, 2019, J COMPUT FINANC, V23, P1, DOI 10.21314/JCF.2019.375
   Hagan P. S., 2002, MANAGING SMILE RISK, V1, P249
   Hallerback W, 2004, ERIM REPORT SERIES
   Jackel P, 2015, WILMOTT, V2015, P40, DOI [DOI 10.1002/WILM.10395, 10.1002/wilm.10395]
   Li M., 2006, YOU DONT HAVE BOTHER
   Liu SQ, 2019, RISKS, V7, DOI 10.3390/risks7010016
   Lorig M, 2014, J RISK, V17, P3, DOI 10.21314/JOR.2014.297
   Matic I, 2020, QUANT FINANC, V20, P393, DOI 10.1080/14697688.2019.1675898
   MERTON RC, 1973, BELL J ECON, V4, P141, DOI 10.2307/3003143
   NAVON IM, 1990, COMPUT CHEM, V14, P305, DOI 10.1016/0097-8485(90)80037-3
   Saab K., 2016, APPL OPTIMAL STOCHAS
   Wikimedia Commons contributors, 2021, FILE SVM MARG PNG
   Yetayew TT, 2015, 2015 IEEE POWER, COMMUNICATION AND INFORMATION TECHNOLOGY CONFERENCE (PCITC-2015), P229, DOI 10.1109/PCITC.2015.7438166
   Zeng YX, 2019, KNOWL-BASED SYST, V163, P376, DOI 10.1016/j.knosys.2018.08.039
NR 21
TC 1
Z9 1
U1 2
U2 3
PD JUN
PY 2021
VL 8
IS 2
SI SI
AR 2150037
DI 10.1142/S2424786321500377
WC Business, Finance
DA 2023-11-11
ER

PT J
AU Scheinker, A
AF Scheinker, A.
TI Adaptive machine learning for time-varying systems: low dimensional
   latent space tuning
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Accelerator Applications; Analysis and statistical methods; Beam
   dynamics; Data reduction methods
ID EXTREMUM SEEKING
AB Machine learning (ML) tools such as encoder-decoder convolutional neural networks (CNN) can represent incredibly complex nonlinear functions which map between combinations of images and scalars. For example, CNNs can be used to map combinations of accelerator parameters and images which are 2D projections of the 6D phase space distributions of charged particle beams as they are transported between various particle accelerator locations. Despite their strengths, applying ML to time-varying systems, or systems with shifting distributions, is an open problem, especially for large systems for which collecting new data for re-training is impractical or interrupts operations. Particle accelerators are one example of large time-varying systems for which collecting detailed training data requires lengthy dedicated beam measurements which may no longer be available during regular operations. We present a novel method of adaptive ML for time-varying systems. Our approach is to map very high (N approximate to 100k) dimensional inputs (a combination of scalar parameters and images) into the low dimensional (N approximate to 2) latent space at the output of the encoder section of an encoder-decoder CNN. We then actively tune the low dimensional latent space-based representation of complex system dynamics by the addition of an adaptively tuned feedback vector directly before the decoder sections builds back up to our image-based high-dimensional phase space density representations. This method allows us to learn correlations within and to quickly tune the characteristics of incredibly large parameter space systems and to track their evolution in real time based on feedback without massive new data sets for re-training. We demonstrate that our method can accurately predict and track the phase space of charged particle beams at various locations in a particle accelerator by adaptively adjusting in real-time while the unknown input beam distribution of the accelerator is changing in shape, charge, and offset and while the RF system of the accelerator itself is also changing in an unpredictable way. For FACET-II we demonstrate that such an approach has the potential to use transverse deflecting cavity and energy spread spectrum beam measurements to accurately predict 2D projections of the 6D phase space of the electron beam at the plasma wakefield acceleration interaction point where such diagnostics are unavailable.
C1 [Scheinker, A.] Los Alamos Natl Lab, Los Alamos, NM 87545 USA.
RP Scheinker, A (corresponding author), Los Alamos Natl Lab, Los Alamos, NM 87545 USA.
EM ascheink@lanl.gov
CR Adelmann A, 2019, SIAM-ASA J UNCERTAIN, V7, P383, DOI 10.1137/16M1061928
   Adli E, 2018, NATURE, V561, P363, DOI 10.1038/s41586-018-0485-4
   An J., 2015, SPECIAL LECT IE, V2, P1, DOI DOI 10.1007/BF00758335
   [Anonymous], 2019, NEURIPS MACHINE LEAR
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Behrens C, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4762
   Caterini AL, 2018, ADV NEUR IN, V31
   Convery O, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.074602
   Decking W, 2020, NAT PHOTONICS, V14, P391, DOI 10.1038/s41566-020-0607-z
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Fol E., 2019, P 10 INT PART ACC C, P2668
   Fol E., 2019, P 10 INT PARTICLE AC, P3990, DOI DOI 10.18429/JACOW-IPAC2019-THPRB077
   Gupta L., ARXIV210307540
   Hanuka A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82473-0
   Hanuka A., ARXIV191101538
   Hao Y., ARXIV190211157
   Hirlaender S., ARXIV201209737
   Ioannou P, 2006, ADV DES CONTROL, P1, DOI 10.1137/1.9780898718652
   Ioannou P., 2012, ROBUST ADAPTIVE CONT
   Khalil H. K, 2002, NONLINEAR SYSTEMS, V115
   Kranjcevic M, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.014601
   Krizhevsky A, 2012, ADV NEURAL INFORM PR
   Li S., INFORMATION, V12, P121
   Li Y., 2019, 3 N AM PART ACC C NA, P4
   Li YJ, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.012804
   Lutman AA, 2016, NAT PHOTONICS, V10, P745, DOI [10.1038/NPHOTON.2016.201, 10.1038/nphoton.2016.201]
   Malyzhenkov A, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.042018
   Maulik R, 2020, PHYSICA D, V405, DOI 10.1016/j.physd.2020.132368
   McIntire M., 2016, P 7 INT PART ACC C
   Pu Y, 2016, ADV NEURAL INFORM PR, V29, P2352, DOI DOI 10.3758/S13423-016-1015-8
   Roussel R., ARXIV201009824
   Scheinker A., 2013, P 2013 INT PART ACC, P1862
   Scheinker A., ARXIV210503584, V3584
   Scheinker A., ARXIV210210510
   Scheinker A, 2021, INFORMATION, V12, DOI 10.3390/info12040161
   Scheinker A, 2020, NUCL INSTRUM METH A, V967, DOI 10.1016/j.nima.2020.163902
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2016, AUTOMATICA, V69, P250, DOI 10.1016/j.automatica.2016.02.023
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Scheinker A, 2014, SYST CONTROL LETT, V63, P25, DOI 10.1016/j.sysconle.2013.10.004
   Scheinker A, 2013, P AMER CONTR CONF, P2637
   Scheinker A, 2013, IEEE T AUTOMAT CONTR, V58, P1107, DOI 10.1109/TAC.2012.2225514
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Tenenbaum P., 2005, P 2005 PART ACC C, P4197, DOI [10.1109/PAC.2005.1591763, DOI 10.1109/PAC.2005.1591763]
   Tripp A., 2020, ADV NEURAL INF PROCE, V33, P1
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yakimenko V, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.101301
   Zhu J, 2021, PHYS REV APPL, V16, DOI 10.1103/PhysRevApplied.16.024005
NR 50
TC 7
Z9 7
U1 3
U2 6
PD OCT
PY 2021
VL 16
IS 10
AR P10008
DI 10.1088/1748-0221/16/10/P10008
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT J
AU Wang, SQ
   Sun, Z
   Liu, YH
   Bao, SY
   Cai, YM
   Ielmini, D
   Huang, R
AF Wang, Shiqing
   Sun, Zhong
   Liu, Yuheng
   Bao, Shengyu
   Cai, Yimao
   Ielmini, Daniele
   Huang, Ru
TI Optimization Schemes for In-Memory Linear Regression Circuit With
   Memristor Arrays
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Memristors; Linear regression; Mathematical models; Eigenvalues and
   eigenfunctions; Optimization; Integrated circuit modeling; Computational
   modeling; Analog computing; in-memory computing; linear regression;
   machine learning; memristor
ID DESIGN
AB Recently, an in-memory analog circuit based on crosspoint memristor arrays was reported, which enables solving linear regression problems in one step and can be used to train many other machine learning algorithms. To explore its potential for computing accelerator applications, it is of fundamental importance to improve the computing speed of the circuit, i.e., the circuit response towards correct outputs. In this work, we comprehensively studied the transfer function of this circuit, resulting in a quadratic eigenvalue problem that describes the distribution of poles. The minimal real part of non-zero eigenvalues defines the dominant pole, which in turn dominates the response time. Simulations for multiple linear regression solutions with different datasets evidence that, the computing time does not necessarily increase with problem size. The dominant pole is related to parameters in the circuit, including feedback conductance, and gain bandwidth products of operational amplifiers. By optimizing these parameters synergistically, the dominant pole shifts to higher frequencies and the computing speed is consequently optimized. Our results provide a guideline for design and optimization of in-memory machine learning accelerators with analog memristor arrays. Also, issues including power consumption, impact of noise and variation of sources and memristors are investigated to offer a comprehensive evaluation of the circuit performance.
C1 [Wang, Shiqing; Sun, Zhong; Cai, Yimao; Huang, Ru] Peking Univ, Inst Artificial Intelligence, Beijing 100871, Peoples R China.
   [Wang, Shiqing] Nanjing Univ, Kuang Yaming Honors Sch, Nanjing 210023, Peoples R China.
   [Sun, Zhong; Liu, Yuheng; Bao, Shengyu; Cai, Yimao; Huang, Ru] Peking Univ, Sch Integrated Circuits, Beijing 100871, Peoples R China.
   [Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
RP Sun, Z (corresponding author), Peking Univ, Inst Artificial Intelligence, Beijing 100871, Peoples R China.
EM zhong.sun@pku.edu.cn
CR Ascoli A, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.651452
   Ascoli A, 2020, IEEE T CIRCUITS-I, V67, P2753, DOI 10.1109/TCSI.2020.2978460
   Astrom K.J., 2008, FEEDBACK SYSTEMS INT
   Banbury Colby R., 2020, ARXIV200304821
   Carter B., 2009, OP AMPS FOR EVERYONE
   Chang TC, 2016, MATER TODAY, V19, P254, DOI 10.1016/j.mattod.2015.11.009
   Cox J. F., 2002, FUNDAMENTALS LINEAR
   Esparza-Alfaro F, 2014, IEEE T CIRCUITS-II, V61, P574, DOI 10.1109/TCSII.2014.2327390
   Giannopoulos I, 2018, INT EL DEVICES MEET
   Giusi G, 2015, INT J CIRC THEOR APP, V43, P1455, DOI 10.1002/cta.2015
   He ZZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317870
   Hogervorst R., 2010, DESIGN LOW VOLTAGE L
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Ielmini D, 2016, RESISTIVE SWITCHING: FROM FUNDAMENTALS OF NANOIONIC REDOX PROCESSES TO MEMRISTIVE DEVICE APPLICATIONS, P1
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Kay A., 2012, OPERATIONAL AMPLIFIE
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Magnelli L, 2014, INT J CIRC THEOR APP, V42, P967, DOI 10.1002/cta.1898
   Mehonic A, 2018, ADV MATER, V30, DOI 10.1002/adma.201801187
   Park J, 2016, IEEE ELECTR DEVICE L, V37, P1559, DOI 10.1109/LED.2016.2622716
   Penrose R., 1955, MATH PROC CAMBRIDGE, V51, P406, DOI [DOI 10.1017/S0305004100030401, 10.1017/S0305004100030401]
   Rahaman A, 2020, IEEE T ELECTRON DEV, V67, P524, DOI 10.1109/TED.2019.2958053
   Razavi B., 2005, DESIGN ANALOG CMOS I
   Rojas R, 1996, NEURAL NETWORKS SYST
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693
   Sun Z, 2021, IEEE T CIRCUITS-II, V68, P2785, DOI 10.1109/TCSII.2021.3068764
   Sun Z, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000042
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P2945, DOI 10.1109/TED.2020.2992435
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Tang JS, 2018, INT EL DEVICES MEET
   Tisseur F, 2001, SIAM REV, V43, P235, DOI 10.1137/S0036144500381988
   Weiher M, 2021, IEEE T CIRCUITS-I, V68, P2082, DOI 10.1109/TCSI.2021.3061973
   Yang X, 2016, NANOSCALE, V8, P18897, DOI 10.1039/c6nr04142f
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Zhang SY, 2017, P ROY SOC A-MATH PHY, V473, DOI 10.1098/rspa.2017.0457
   Zumbahlen H, 2008, LINEAR CIRCUIT DESIGN HANDBOOK, P1
NR 42
TC 4
Z9 4
U1 4
U2 24
PD DEC
PY 2021
VL 68
IS 12
BP 4900
EP 4909
DI 10.1109/TCSI.2021.3122327
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Qian, C
   Einhaus, L
   Schiele, G
AF Qian, Chao
   Einhaus, Lukas
   Schiele, Gregor
GP ACM
TI ElasticAI-Creator: Optimizing Neural Networks for Time-Series-Analysis
   for On-Device Machine Learning in IoT Systems
SO PROCEEDINGS OF THE TWENTIETH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR
   SYSTEMS, SENSYS 2022
DT Proceedings Paper
CT 20th ACM Conference on Embedded Networked Sensor Systems (SenSys)
CY NOV 06-09, 2022
CL Boston, MA
DE Code Generator; IoT; embedded FPGA; Energy-efficiency; Machine Learning
AB Deep learning (DL) is quickly becoming a core technology to process sensor data from IoT devices. Nowadays, data is usually sent to remote Cloud services where GPU-based ML platforms process it. In contrast, our vision is to have IoT devices with local, on-device DL. This can increase privacy and accessibility as well as reduce processing costs. To do so, specialized hardware accelerators are needed to perform ML operations efficiently without high performance CPUs. In this paper we introduce our approach for a generator for ML hardware accelerators in the IoT. We focus specifically on the inference of ML algorithms for a typical class of IoT use cases, i.e., processing time-series data under real-time constraints. Additionally our optimization techniques rely on the co-design of hardware and ML algorithms to explore the most specialized and efficient corners of the design space. In this work we analyze the requirements for our generator, discuss optimization stages and techniques and show a case study based on an LSTM model for traffic flow prediction.
C1 [Qian, Chao; Einhaus, Lukas; Schiele, Gregor] Univ Duisburg Essen, Duisburg, Germany.
RP Qian, C (corresponding author), Univ Duisburg Essen, Duisburg, Germany.
EM chao.qian@uni-due.de; lukas.einhaus@uni-due.de;
   gregor.schiele@uni-due.de
CR Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Cyphers S, 2018, Arxiv, DOI [arXiv:1801.08058, 10.48550/arXiv.1801.08058arXiv:1801.08058]
   David Robert, 2021, PROC MACHINE LEARNIN, V3, P800
   Einhaus L, 2021, COMM COM INF SC, V1524, P327, DOI 10.1007/978-3-030-93736-2_25
   Fahim Farah, 2021, HLS4ML OPEN SOURCE C
   Fu R, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P324, DOI 10.1109/YAC.2016.7804912
   Ghasemzadeh M, 2018, ANN IEEE SYM FIELD P, P57, DOI 10.1109/FCCM.2018.00018
   Google, 2022, XLA OPT COMP MACH LE
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Venieris SI, 2017, Arxiv, DOI [arXiv:1711.08740, 10.48550/ARXIV.1711.08740, DOI 10.48550/ARXIV.1711.08740]
   Luan Zhongzhi, 2020, ARXIV, DOI [10.1109/TPDS.2020.3030548, DOI 10.1109/TPDS.2020.3030548]
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Qian Chao, 2022, IOT STREAMS DATA DRI
   Rotem N, 2019, Arxiv, DOI arXiv:1805.00907
   Schiele G, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING (ICAC 2019), P84, DOI 10.1109/ICAC.2019.00020
   Sharma H, 2016, INT SYMP MICROARCH
   Vasilache N, 2018, Arxiv, DOI arXiv:1802.04730
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Xilinx, 2022, XIL VIT AI
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 941
EP 946
DI 10.1145/3560905.3568296
DA 2023-11-11
ER

PT C
AU Ravichandiran, PP
   Franzon, PD
AF Ravichandiran, Prasanth Prabu
   Franzon, Paul D.
GP IEEE
TI A Review of 3D-Dynamic Random-Access Memory based Near-Memory
   Computation
SO 2021 IEEE INTERNATIONAL 3D SYSTEMS INTEGRATION CONFERENCE (3DIC)
SE IEEE International 3D Systems Integration Conference
DT Proceedings Paper
CT IEEE International 3D Systems Integration Conference (3DIC)
CY NOV 15-18, 2021
CL Raleigh, NC
DE near-memory computation; hardware accelerators; neural network;
   processing-in-memory; survey; 3D-IC; memory accelerator; comparison;
   hybrid-memory-cube
AB The growth of Neural Networks (NNs) and Machine Learning (ML) usage has rapidly increased over the last decade. Traditional dynamic random-access memory (DRAM) is struggling to meet the computational, throughput demands of these NNs and has become a bottleneck in the system. One of the commonly proposed solutions is Near-Memory Computation (NMC) hardware accelerators to move the computation closer to the data resulting in improved throughput and reduced power consumption. In this paper, we analyze a few critical NMC architecture implementations, specifically those with 3D-Stacked DRAM memory. We have organized a literature review across structures, configuration, application, performance metrics, and present challenges and opportunities.
C1 [Ravichandiran, Prasanth Prabu; Franzon, Paul D.] North Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA.
RP Ravichandiran, PP (corresponding author), North Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA.
EM pravich2@ncsu.edu; paulf@ncsu.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], 2015, DIRAM4 64CXX CACH ME
   [Anonymous], 2014, HYBRID MEMORY CUBE S
   Azarkhish E, 2018, IEEE T PARALL DISTR, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Baker LB, 2018, IEEE SOI3DSUB MICRO
   Bavikadi S., 2020, P 2020 GREAT LAK S V, P89
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dey S, 2019, INT SYM QUAL ELECT, P183, DOI 10.1109/ISQED.2019.8697413
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fan D, 2017, PR IEEE COMP DESIGN, P609, DOI 10.1109/ICCD.2017.107
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Gu P, 2020, ANN I S COM, P804, DOI 10.1109/ISCA45697.2020.00071
   Hsieh K, 2016, PR IEEE COMP DESIGN, P25, DOI 10.1109/ICCD.2016.7753257
   Ikeda H., 2012, 2012 3rd IEEE International Workshop on Low Temperature Bonding for 3D Integration, DOI 10.1109/LTB-3D.2012.6238067
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jun HS, 2017, IEEE DES TEST, V34, P16, DOI 10.1109/MDAT.2016.2624283
   Khan K, 2020, J LOW POWER ELECT AP, V10, DOI 10.3390/jlpea10040030
   Kim BH, 2020, IEEE ACCESS, V8, P61631, DOI 10.1109/ACCESS.2020.2983432
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Lee W. J., 2019, IEEE ACCESS, V7, p82 633
   Lin SC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS-TAIWAN (ICCE-TW), P149, DOI 10.1109/ICAUMS.2016.8479919
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Nai LF, 2018, INT PARALL DISTRIB P, P680, DOI 10.1109/IPDPS.2018.00077
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nair R, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2409732
   Pan Y, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2018.2848625
   Sadi F., 2014, C 2 WORKSH NEAR DAT
   Schawe JEK, 2016, AIP CONF PROC, V1713, DOI 10.1063/1.4942287
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Singh G, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P608, DOI 10.1109/DSD.2018.00106
   Zhu QL, 2013, IEEE HIGH PERF EXTR
NR 36
TC 1
Z9 1
U1 3
U2 8
PY 2021
DI 10.1109/3DIC52383.2021.9687615
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Manufacturing; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Agrawal, A
   Mueller, SM
   Fleischer, BM
   Choi, J
   Wang, NG
   Sun, X
   Gopalakrishnan, K
AF Agrawal, Ankur
   Mueller, Silvia M.
   Fleischer, Bruce M.
   Choi, Jungwook
   Wang, Naigang
   Sun, Xiao
   Gopalakrishnan, Kailash
BE Takagi, N
   Boldo, S
   Langhammer, M
TI DLFloat: A 16-b Floating Point format designed for Deep Learning
   Training and Inference
SO 2019 IEEE 26TH SYMPOSIUM ON COMPUTER ARITHMETIC (ARITH)
SE Proceedings Symposium on Computer Arithmetic
DT Proceedings Paper
CT 26th IEEE Symposium on Computer Arithmetic (ARITH)
CY JUN 10-12, 2019
CL Kyoto, JAPAN
DE reduced precision computation; floating point; machine learning; deep
   learning
AB The resilience of Deep Learning (DL) training and inference workloads to low-precision computations, coupled with the demand for power- and area-efficient hardware accelerators for these workloads, has led to the emergence of 16-bit floating point formats as the precision of choice for DL hardware accelerators. This paper describes our optimized 16-bit format that has 6 exponent bits and 9 fraction bits, derived from a study of the range of values encountered in DL applications. We demonstrate that our format preserves the accuracy of DL networks, and we compare its ease-of-use for DL against IEEE-754 half-precision (5 exponent bits and 10 fraction bits) and bfloat16 (8 exponent bits and 7 fraction bits). Further, our format eliminated sub-normals and simplifies rounding modes and handling of corner cases. This streamlines floating-point unit logic and enables realization of a compact power-efficient computation engine.
C1 [Agrawal, Ankur; Fleischer, Bruce M.; Choi, Jungwook; Wang, Naigang; Sun, Xiao; Gopalakrishnan, Kailash] IBM Res, Yorktown Hts, NY 10598 USA.
   [Mueller, Silvia M.] IBM Syst, Boblingen, Germany.
RP Agrawal, A (corresponding author), IBM Res, Yorktown Hts, NY 10598 USA.
EM ankuragr@usibm.com; smm@de.ibm.com; fleischr@us.ibm.com;
   choij@us.ibm.com; nwang@us.ibm.com; xsun@us.ibm.com; kailash@us.ibm.com
CR [Anonymous], 2018, IEEE S VLSI CIRCU
   [Anonymous], TREEBANKS
   Boersma M, 2011, P S COMP ARITHM, P87, DOI 10.1109/ARITH.2011.21
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Intel, 2018, BFLOAT16 HARDW NUM D
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Micikevicius P., 2017, ARXIV171003740
   Tagliavini G., 2016, ARXIV171110374
   van den Berg E, 2017, INT CONF ACOUST SPEE, P2287, DOI 10.1109/ICASSP.2017.7952564
   Vaswani A., 2017, PROC INT C NEURAL IN, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Wang N., 2018, TRAINING DEEP NEURAL
   Wu Y, 2016, ARXIV
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
NR 13
TC 35
Z9 35
U1 0
U2 0
PY 2019
BP 92
EP 95
DI 10.1109/ARITH.2019.00023
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Information Systems; Computer Science,
   Software Engineering; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Baran, M
   Tabor, Z
   Rzecki, K
   Ziaja, P
   Szumlak, T
   Kalecinska, K
   Michczynski, J
   Rachwal, B
   Waligórski, MPR
   Sarrut, D
AF Baran, Mateusz
   Tabor, Zbislaw
   Rzecki, Krzysztof
   Ziaja, Przemyslaw
   Szumlak, Tomasz
   Kalecinska, Kamila
   Michczynski, Jakub
   Rachwal, Bartlomiej
   Waligorski, Michael P. R.
   Sarrut, David
TI Application of Conditional Generative Adversarial Networks to
   Efficiently Generate Photon Phase Space in Medical Linear Accelerators
   of Different Primary Beam Parameters
SO APPLIED SCIENCES-BASEL
DT Article
DE cancer; machine learning; medical simulations; neural networks;
   radiation therapy
ID MONTE-CARLO-SIMULATION
AB Successful application of external photon beam therapy in oncology requires that the dose delivered by a medical linear accelerator and distributed within the patient's body is accurately calculated. Monte Carlo simulation is currently the most accurate method for this purpose but is computationally too extensive for routine clinical application. A very elaborate and time-consuming part of such Monte Carlo simulation is generation of the full set (phase space) of ionizing radiation components (mainly photons) to be subsequently used in simulating dose delivery to the patient. We propose a method of generating phase spaces in medical linear accelerators through learning, by artificial intelligence models, the joint multidimensional probability density distribution of the photon properties (their location in space, energy, and momentum). The models are conditioned with respect to the parameters of the primary electron beam (unique to each medical accelerator), which, through Bremsstrahlung, generates the therapeutical beam of ionizing radiation. Two variants of conditional generative adversarial networks are chosen, trained, and compared. We also present the second-best type of deep learning architecture that we studied: a variational autoencoder. Differences between dose distributions obtained in a water phantom, in a test phantom, and in real patients using generative-adversarial-network-based and Monte-Carlo-based phase spaces are very close to each other, as indicated by the values of standard quality assurance tools of radiotherapy. Particle generation with generative adversarial networks is three orders of magnitude faster than with Monte Carlo. The proposed GAN model, together with our earlier machine-learning-based method of tuning the primary electron beam of an MC simulator, delivers a complete solution to the problem of tuning a Monte Carlo simulator against a physical medical accelerator.
C1 [Baran, Mateusz; Tabor, Zbislaw; Rzecki, Krzysztof; Ziaja, Przemyslaw; Szumlak, Tomasz; Kalecinska, Kamila; Michczynski, Jakub; Rachwal, Bartlomiej] AGH Univ Krakow, 30 Mickiewicz Ave, PL-30059 Krakow, Poland.
   [Baran, Mateusz; Tabor, Zbislaw; Rzecki, Krzysztof; Rachwal, Bartlomiej; Waligorski, Michael P. R.] Cracow Univ Technol, Fac Mat Sci & Phys, Podchorazych 1, PL-30084 Krakow, Poland.
   [Waligorski, Michael P. R.] Polish Acad Sci, Inst Nucl Phys, Radzikowskiego 152, PL-31342 Krakow, Poland.
   [Sarrut, David] Ctr Leon Berard, CREATIS, 28 Rue Laennec, F-69373 Lyon, France.
RP Rzecki, K (corresponding author), AGH Univ Krakow, 30 Mickiewicz Ave, PL-30059 Krakow, Poland.; Rzecki, K (corresponding author), Cracow Univ Technol, Fac Mat Sci & Phys, Podchorazych 1, PL-30084 Krakow, Poland.
EM mbaran@agh.edu.pl; ztabor@agh.edu.pl; krz@agh.edu.pl;
   prz.ziaja@gmail.com; szumlak@agh.edu.pl; kamila.kalecinska@agh.edu.pl;
   kubamichcz@gmail.com; brachwal@agh.edu.pl; z5waligo@cyf-kr.edu.pl;
   david.sarrut@creatis.insa-lyon.fr
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Atienza R., 2020, ADV DEEP LEARNING TE, V2nd ed.
   Baran M, 2021, MED PHYS, V48, P4743, DOI 10.1002/mp.15142
   Burkhardt J., 2020, INT J MATH SCI COMPU, V6, P1, DOI [10.5815/ijmsc.2020.02.01, DOI 10.5815/IJMSC.2020.02.01]
   Chetty IJ, 2007, MED PHYS, V34, P4818, DOI 10.1118/1.2795842
   Chrysos GG, 2020, INT J COMPUT VISION, V128, P2665, DOI 10.1007/s11263-020-01348-5
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   DRZYMALA RE, 1991, INT J RADIAT ONCOL, V21, P71, DOI 10.1016/0360-3016(91)90168-4
   Ezzell GA, 2009, MED PHYS, V36, P5359, DOI 10.1118/1.3238104
   Failla G., 2010, ACUROS XB ADV DOSE C
   Foster I, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074548
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Husaini N., 2020, INT J INTELL SYST AP, V12, P52, DOI [10.5815/ijisa.2020.05.05, DOI 10.5815/IJISA.2020.05.05]
   Izonin Ivan, 2021, Advances in Artificial Systems for Logistics Engineering. Lecture Notes on Data Engineering and Communication Technologies (82), P23, DOI 10.1007/978-3-030-80475-6_3
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Kingma DP, 2014, Arxiv, DOI [arXiv:1312.6114, DOI 10.48550/ARXIV.1312.6114]
   Rodriguez M, 2013, STRAHLENTHER ONKOL, V189, P881, DOI 10.1007/s00066-013-0415-1
   Rodriguez M, 2012, PHYS MED BIOL, V57, P3013, DOI 10.1088/0031-9155/57/10/3013
   Santoro M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073223
   Sarrut D, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab3fc1
   Seco J., 2013, MONTE CARLO TECHNIQU
   Stevens E., 2020, DEEP LEARNING PYTORC
   Storchi P, 1996, PHYS MED BIOL, V41, P637, DOI 10.1088/0031-9155/41/4/005
   Tabor Z, 2021, RADIAT ONCOL, V16, DOI 10.1186/s13014-021-01847-w
   Tian Z, 2015, PHYS MED BIOL, V60, P7941, DOI 10.1088/0031-9155/60/20/7941
   Ulmer W, 2005, PHYS MED BIOL, V50, P1767, DOI 10.1088/0031-9155/50/8/010
   Vallières M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10371-5
   Wang QX, 2020, BIOMED PHYS ENG EXPR, V6, DOI 10.1088/2057-1976/ab7152
   Zhao SJ, 2018, Arxiv, DOI [arXiv:1706.02262, DOI 10.48550/ARXIV.1706.02262]
NR 29
TC 0
Z9 0
U1 2
U2 2
PD JUN
PY 2023
VL 13
IS 12
AR 7204
DI 10.3390/app13127204
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT J
AU Leon, V
   Mouselinos, S
   Koliogeorgi, K
   Xydis, S
   Soudris, D
   Pekmestzi, K
AF Leon, Vasileios
   Mouselinos, Spyridon
   Koliogeorgi, Konstantina
   Xydis, Sotirios
   Soudris, Dimitrios
   Pekmestzi, Kiamal
TI A TensorFlow Extension Framework for Optimized Generation of Hardware
   CNN Inference Engines
SO TECHNOLOGIES
DT Article
DE machine learning; convolutional neural networks; model optimizations;
   weight quantization; inference engine optimizations; dataflow
   optimizations; tensorflow; FPGA; ASIC
AB The workloads of Convolutional Neural Networks (CNNs) exhibit a streaming nature that makes them attractive for reconfigurable architectures such as the Field-Programmable Gate Arrays (FPGAs), while their increased need for low-power and speed has established Application-Specific Integrated Circuit (ASIC)-based accelerators as alternative efficient solutions. During the last five years, the development of Hardware Description Language (HDL)-based CNN accelerators, either for FPGA or ASIC, has seen huge academic interest due to their high-performance and room for optimizations. Towards this direction, we propose a library-based framework, which extends TensorFlow, the well-established machine learning framework, and automatically generates high-throughput CNN inference engines for FPGAs and ASICs. The framework allows software developers to exploit the benefits of FPGA/ASIC acceleration without requiring any expertise on HDL development and low-level design. Moreover, it provides a set of optimization knobs concerning the model architecture and the inference engine generation, allowing the developer to tune the accelerator according to the requirements of the respective use case. Our framework is evaluated by optimizing the LeNet CNN model on the MNIST dataset, and implementing FPGA- and ASIC-based accelerators using the generated inference engine. The optimal FPGA-based accelerator on Zynq-7000 delivers 93% less memory footprint and 54% less Look-Up Table (LUT) utilization, and up to 10x speedup on the inference execution vs. different Graphics Processing Unit (GPU) and Central Processing Unit (CPU) implementations of the same model, in exchange for a negligible accuracy loss, i.e., 0.89%. For the same accuracy drop, the 45 nm standard-cell-based ASIC accelerator provides an implementation which operates at 520 MHz and occupies an area of 0.059 mm2, while the power consumption is similar to 7.5 mW.
C1 [Leon, Vasileios; Mouselinos, Spyridon; Koliogeorgi, Konstantina; Xydis, Sotirios; Soudris, Dimitrios; Pekmestzi, Kiamal] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
RP Leon, V (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
EM vleon@microlab.ntua.gr; mouselinos.spur.kw@gmail.com;
   konstantina@microlab.ntua.gr; sxydis@microlab.ntua.gr;
   dsoudris@microlab.ntua.gr; pekmes@microlab.ntua.gr
CR Abadi M., 2016, P 12 USENIX S OPERAT
   Abdelouahab K, 2017, IEEE EMBED SYST LETT, V9, P113, DOI 10.1109/LES.2017.2743247
   [Anonymous], 2016, MICRO
   [Anonymous], IEEE T COMPUT AIDED
   [Anonymous], 2013, P 40 ANN INT S COMPU
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2014, ARXIV LEARNING
   [Anonymous], 2013, ARXIV13126184
   Chellappa R, 1998, IEEE T IMAGE PROCESS, V7, P1093, DOI 10.1109/TIP.1998.704303
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Del Sozzo E, 2016, IEEE SYM PARA DISTR, P217, DOI 10.1109/IPDPSW.2016.153
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Hinton Geoffrey, 2015, NIPS, DOI DOI 10.1063/1.4931082
   Kim JH, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P268, DOI 10.1109/SOCC.2017.8226056
   Krishnamoorthi R., 2018, ARXIV180608342, V8, P667
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leon V, 2018, IEEE MICRO, V38, P40, DOI 10.1109/MM.2018.043191124
   Leon V, 2018, IEEE T VLSI SYST, V26, P421, DOI 10.1109/TVLSI.2017.2767858
   Li SC, 2017, ANN IEEE SYM FIELD P, P28, DOI 10.1109/FCCM.2017.21
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Mouselinos Spyridon, 2019, 2019 8th International Conference on Modern Circuits and Systems Technologies (MOCAST), DOI 10.1109/MOCAST.2019.8741940
   Noronha D. H., 2018, FSP WORKSH 2018 5 IN, P1
   Redmon J., 2016, ARXIV160207360, P779
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Xing Y, 2020, IEEE T COMPUT AID D, V39, P2668, DOI 10.1109/TCAD.2019.2930577
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zisserman A., 2014, 14091556 ARXIV
NR 34
TC 4
Z9 4
U1 1
U2 4
PD MAR
PY 2020
VL 8
IS 1
AR 6
DI 10.3390/technologies8010006
WC Engineering, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Kim, K
   Park, J
   Lee, J
AF Kim, Kibok
   Park, Jinil
   Lee, Jonghwa
TI Fuel Economy Improvement of Urban Buses with Development of an Eco-Drive
   Scoring Algorithm Using Machine Learning
SO ENERGIES
DT Article
DE urban buses; fuel economy; eco-drive system; machine learning
ID STYLE
AB Eco-drive is a widely used concept. It can improve fuel economy for different driving behaviors such as vehicle acceleration or accelerator pedal operation, deceleration or coasting while slowing down, and gear shift timing difference. The feasibility of improving the fuel economy of urban buses by applying eco-drive was verified by analyzing data from drivers who achieved high fuel efficiencies in urban buses with a high frequency of acceleration/deceleration and frequent operation. The items that were monitored for eco-drive were: rapid take-off/acceleration/deceleration, accelerator pedal gradient, coasting rate, shift indicator violation, average engine speed, over speed, and gear shifting under low-end engine speed. The monitoring method for each monitored item was set up, and an index was produced using driving data. A fuel economy prediction model was created using machine learning to determine the contribution of each index to the fuel economy. Furthermore, the contribution of each monitoring item was analyzed using the prediction model explainer. Accordingly, points (defined as the eco-drive score) were allocated for each monitoring item. It was verified that this score can represent the eco-drive characteristics based on the relationship between the score and fuel economy. In addition, it resulted in an average annual fuel economy improvement of 12.1%.
C1 [Kim, Kibok; Park, Jinil; Lee, Jonghwa] Ajou Univ, Dept Mech Engn, 206 World Cup Ro, Suwon 16499, South Korea.
   [Kim, Kibok] Tenergy, Vehicle Calibrat Team, 145 Gwanggyo Ro, Suwon 16229, South Korea.
RP Park, J; Lee, J (corresponding author), Ajou Univ, Dept Mech Engn, 206 World Cup Ro, Suwon 16499, South Korea.
EM sbkim36@tenergy.co.kr; jpark@ajou.ac.kr; jlee@ajou.ac.kr
CR Al-kasassbeh Mouhammd, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1230), P391, DOI 10.1007/978-3-030-52243-8_28
   [Anonymous], 2010, 2009 AVERAGE MILEAGE, P13
   Azmin F.M., 2014, SAE TECHNICAL PAPER
   Brundell-Freij K, 2005, TRANSPORT RES D-TR E, V10, P213, DOI 10.1016/j.trd.2005.01.001
   Choi D, 2020, ENERGIES, V13, DOI 10.3390/en13205301
   Chung Namhoon, 2002, [Transactions of KSAE, 한국자동차공학회 논문집], V10, P55
   Daoud E.A., 2019, WORLD ACAD SCI ENG T, V13, P1
   Fafoutellis P, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010226
   Geurkink Y, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052378
   Gibert K, 2016, AI COMMUN, V29, P627, DOI 10.3233/AIC-160710
   Guo Q., 2019, P INT C BIG DAT EL C P INT C BIG DAT EL C, V94
   HAMEED SS, 2019, SAE TECHNICAL PAPER
   He R., 2020, SAE TECHNICAL PAPER
   Imaizumi H., 2013, SAE TECHNICAL PAPER
   Jo Jun-Mo, 2019, [The Journal of The Korea Institute of Electronic Communication Sciences, 한국전자통신학회 논문지], V14, P547, DOI 10.13067/JKIECS.2019.14.3.547
   Kamal MAS, 2010, IEEE INTL CONF CONTR, P1636, DOI 10.1109/CCA.2010.5611196
   Ke G., 2017, ADV NEURAL INF PROCE, V30, P3146
   Koch-Groeber H., 2014, SAE TECHNICAL PAPER
   Korea Transportation Safety Authority, GREENHOUSE GAS EMISS
   Lee Hyunmi, 2020, [The Journal of The Korea Institute of Electronic Communication Sciences, 한국전자통신학회 논문지], V15, P1123
   Lee T., 2011, SAE TECHNICAL PAPER
   Lundberg S, 2017, Arxiv, DOI [arXiv:1705.07874, DOI 10.48550/ARXIV.1705.07874]
   Lundberg Scott M, 2018, ARXIV
   Ma H., 2014, SAE TECHNICAL PAPER
   Ma HJ, 2015, TRANSPORT RES D-TR E, V41, P205, DOI 10.1016/j.trd.2015.10.003
   Machado MR, 2019, INT CONF COMP SCI ED, P1111, DOI [10.1109/iccse.2019.8845529, 10.1109/ICCSE.2019.8845529]
   Mahajan V, 2021, EUR TRANSP RES REV, V13, DOI 10.1186/s12544-021-00485-3
   Ministry of Land Infrastructure and Transport Statistics System, TOT REG MOT VEH TOT REG MOT VEH
   Muthusamy A., 2018, SAE TECHNICAL PAPER
   Nawi NM, 2013, PROC TECH, V11, P32, DOI 10.1016/j.protcy.2013.12.159
   Obaid Hadeel S., 2019, 2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON), P279, DOI 10.1109/IEMECONX.2019.8877011
   염시호, 2013, [Transactions of KSAE, 한국자동차공학회 논문집], V21, P34, DOI 10.7467/KSAE.2013.21.5.034
   Pedrozo V., 2020, SAE TECHNICAL PAPER
   President of Greenhouse Gas Inventory and Research Center, 2020, NATL GREENHOUSE GAS, P97
   Radmilovic Z., 2014, SAE TECHNICAL PAPER
   Saito A., 2008, SAE TECHNICAL PAPER
   Salay R., 2018, 2018011075 SAE SAE I 2018011075 SAE SAE I
   Sato S., 2010, SAE TECHNICAL PAPER
   Shahverdy M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113240
   Shin D.J., 2011, SAE TECHNICAL PAPER
   Son J, 2016, INT J AUTO TECH-KOR, V17, P175, DOI 10.1007/s12239-016-0017-x
   Szumska EM, 2020, ENERGIES, V13, DOI 10.3390/en13246675
   Takada Y, 2007, SAE TECHNICAL PAPER
   Ueki S., 2011, SAE TECHNICAL PAPER
   Van Mierlo J, 2004, P I MECH ENG D-J AUT, V218, P43, DOI 10.1243/095440704322829155
   Wang D, 2017, P 2017 INT C COMPUTA, P7, DOI [10.1145/3155077.3155079, DOI 10.1145/3155077.3155079]
   Yamaguchi T., 2020, SAE TECHNICAL PAPER
   Zacharof N., 2020, SAE TECHNICAL PAPER
NR 48
TC 3
Z9 3
U1 4
U2 17
PD AUG
PY 2021
VL 14
IS 15
AR 4471
DI 10.3390/en14154471
WC Energy & Fuels
DA 2023-11-11
ER

PT C
AU Alwani, M
   Chen, H
   Ferdman, M
   Milder, P
AF Alwani, Manoj
   Chen, Han
   Ferdman, Michael
   Milder, Peter
GP IEEE
TI Fused-Layer CNN Accelerators
SO 2016 49TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
SE International Symposium on Microarchitecture Proceedings
DT Proceedings Paper
CT 49th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 15-19, 2016
CL Taipei, TAIWAN
AB Deep convolutional neural networks (CNNs) are rapidly becoming the dominant approach to computer vision and a major component of many other pervasive machine learning tasks, such as speech recognition, natural language processing, and fraud detection. As a result, accelerators for efficiently evaluating CNNs are rapidly growing in popularity. The conventional approaches to designing such CNN accelerators is to focus on creating accelerators to iteratively process the CNN layers. However, by processing each layer to completion, the accelerator designs must use off-chip memory to store intermediate data between layers, because the intermediate data are too large to fit on chip.
   In this work, we observe that a previously unexplored dimension exists in the design space of CNN accelerators that focuses on the dataflow across convolutional layers. We find that we are able to fuse the processing of multiple CNN layers by modifying the order in which the input data are brought on chip, enabling caching of intermediate data between the evaluation of adjacent CNN layers. We demonstrate the effectiveness of our approach by constructing a fused-layer CNN accelerator for the first five convolutional layers of the VGGNet-E network and comparing it to the state-of-the-art accelerator implemented on a Xilinx Virtex-7 FPGA. We find that, by using 362KB of on-chip storage, our fused-layer accelerator minimizes off-chip feature map data transfer, reducing the total transfer by 95%, from 77MB down to 3.6MB per image.
C1 [Alwani, Manoj; Chen, Han; Ferdman, Michael; Milder, Peter] SUNY Stony Brook, Stony Brook, NY 11794 USA.
RP Alwani, M (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
EM malwani@cs.stonybrook.edu; han.chen.2@stonybrook.edu;
   mferdman@cs.stonybrook.edu; peter.milder@stonybrook.edu
CR [Anonymous], 2011, BIGL NIPS WORKSH
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Farabet C., 2011, P EMB COMP VIS WORKS
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Hauswald J., 2015, P 42 ANN INT S COMP
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Liu D., 2015, P 20 INT C ARCH SUPP
   Peemen M., 2013, P 31 INT C COMP DES
   Peemen M., 2011, P 13 INT C ADV CONC
   Peemen M., 2015, P 2015 DES AUT TEST
   Putnam A., 2014, P 41 ANN INT S COMP
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI DOI 10.1145/2485922.2485925
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M., 2009, P 20 IEEE INT C APPL
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 19
TC 226
Z9 232
U1 3
U2 12
PY 2016
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Hartmann, M
   Weber, L
   Wirth, J
   Sommer, L
   Koch, A
AF Hartmann, Marco
   Weber, Lukas
   Wirth, Johannes
   Sommer, Lukas
   Koch, Andreas
GP IEEE Comp Soc
TI Optimizing a Hardware Network Stack to Realize an In-Network ML
   Inference Application
SO PROCEEDINGS OF SEVENTH INTERNATIONAL WORKSHOP ON HETEROGENEOUS
   HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC 2021)
DT Proceedings Paper
CT IEEE/ACM 7th International Workshop on Heterogeneous High- Performance
   Reconfigurable Computing (H2RC) Part of International Conference for
   High Performance Computing, Networking, Storage and Analysis (SC)
CY NOV 14-19, 2021
CL St Louis, MO
DE In-Network Processing; 100G; Network; TCP/IP
AB FPGAs are an interesting platform for the implementation of network-attached accelerators, either in the form of smart network interface cards or as In-Network Processing accelerators.
   Both application scenarios require a high-throughput hardware network stack. In this work, we integrate such a stack into the open-source TaPaSCo framework and implement a library of easy-to-use design primitives for network functionality in modern HDLs. To further facilitate the development of network-attached FPGA accelerators, the library is complemented by a handy simulation framework.
   In our evaluation, we demonstrate that the integrated and extended stack can operate at or close to the theoretical maximum, both for the stack itself as well as an network-attached machine learning inference appliance.
C1 [Hartmann, Marco; Weber, Lukas; Wirth, Johannes; Sommer, Lukas; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
RP Hartmann, M (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM hartmann@esa.tu-darmstadt.de; weber@esa.tu-darmstadt.de;
   wirth@esa.tu-darmstadt.de; sommer@esa.tu-darmstadt.de;
   koch@esa.tu-darmstadt.de
CR [Anonymous], 2014, AURORA 64B66B PROTOC
   [Anonymous], 2020, AURORA 64B66B V120 P
   Boutros A., 2017, PROC INT CONF RECON
   Choi Young-kyu, 2020, HLS MEETS FPGA HBM B
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Dua D, 2020, UCI MACHINE LEARNING
   Firestone D, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P51
   Hilprecht B, 2020, PROC VLDB ENDOW, V13, P992, DOI 10.14778/3384345.3384349
   Hock M, 2019, C LOCAL COMPUT NETW, P1, DOI 10.1109/LCN44214.2019.8990842
   Hofmann J., 2019, INT WORKSH ACC AN DA
   Ji Yong., 2011, P 2011 IEEE INT C WI, P1
   Korinth Jens, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P214, DOI 10.1007/978-3-030-17227-5_16
   Muhlbach S., 2010, IEEE P INT C FIELD P
   Poon H, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Rathke Fabian, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P177, DOI 10.1007/978-3-319-66182-7_21
   Ruiz M, 2019, I C FIELD PROG LOGIC, P286, DOI 10.1109/FPL.2019.00053
   Sanchez-Cauce R., 2021, IEEE T PATTERN ANAL, P1
   Sapio A, 2017, HOTNETS-XVI: PROCEEDINGS OF THE 16TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P150, DOI 10.1145/3152434.3152461
   Sidler D, 2015, ANN IEEE SYM FIELD P, P36, DOI 10.1109/FCCM.2015.12
   Sommer L, 2020, ANN IEEE SYM FIELD P, P75, DOI 10.1109/FCCM48280.2020.00020
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Sutter G., 2018, P 2018 IEEE INT C RE, P1
   Tokusashi Y, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303979
   Weerasinghe J, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P36, DOI 10.1109/FPT.2016.7929186
   Wirth J., APPL RECONFIGURABLE, V2021, P18
   Wu ZZ, 2006, IEEE IC COMP COM NET, P245
   Zhao ZP, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P1083
   ZIMMERMANN H, 1980, IEEE T COMMUN, V28, P425, DOI 10.1109/TCOM.1980.1094702
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 21
EP 32
DI 10.1109/H2RC54759.2021.00008
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Awais, M
   Platzner, M
AF Awais, Muhammad
   Platzner, Marco
GP IEEE Comp Soc
TI MCTS-based Synthesis Towards Efficient Approximate Accelerators
SO 2021 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2021)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 20th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 07-09, 2017-2021
CL ELECTR NETWORK
DE Approximate computing; Design Space Exploration; Synthesis; Monte Carlo
   Tree Search
AB Approximate computing (AC) has acquired significant maturity in recent years as a promising approach to obtain energy and area-efficient hardware. Automated approximate accelerator synthesis involves a great deal of complexity on the size of design space which exponentially grows with the number of possible approximations. Design space exploration of approximate accelerator synthesis is usually targeted via heuristic-based search methods. The majority of existing frameworks prune a large part of the design space using a greedy-based approach to keep the problem tractable. Therefore, they result in inferior solutions since many potential solutions are neglected in the pruning process without the possibility of backtracking of removed approximate instances. In this paper, we address the aforementioned issue by adopting Monte Carlo Tree Search (MCTS), as an efficient stochastic learning-based search algorithm, in the context of automated synthesis of approximate accelerators. This enables the synthesis frameworks to deeply subsample the design space of approximate accelerator synthesis toward most promising approximate instances based on the required performance goals, i.e., power consumption, area, or/and delay. We investigated the challenges of providing an efficient open-source framework that benefits analytical and search-based approximation techniques simultaneously to both speed up the synthesis runtime and improve the quality of obtained results. Besides, we studied the utilization of machine learning algorithms to improve the performance of several critical steps, i.e., accelerator quality testing, in the synthesis framework. The proposed framework can help the community to rapidly generate efficient approximate accelerators in a reasonable runtime.
C1 [Awais, Muhammad; Platzner, Marco] Paderborn Univ, Dept Comp Sci, Paderborn, Germany.
RP Awais, M (corresponding author), Paderborn Univ, Dept Comp Sci, Paderborn, Germany.
EM mawais@mail.upb.de; platzner@upb.de
CR Awais M., 2018, IEEE VLSI SOC
   Awais M., 2020, ACM GLSVLSI
   Barbareschi M., 2016, WAINA
   Browne CB, 2012, IEEE T COMP INTEL AI, V4, P1, DOI 10.1109/TCIAIG.2012.2186810
   Castro-Godinez J., 2018, IEEE DATE
   Chandrasekharan A, 2016, ICCAD
   Liu G., 2017, IEEE ACM ICCAD
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mrazek V., 2017, IEEE DATE
   Mrazek V., 2019, ACM DAC
   Nepal K., 2014, IEEE DATE
   Nepal K., 2016, JEFF T EMERGING TOPI, V7, P18
   Ozer E., 2004, INT C COMP CONSTR
   Salamat S., 2017, IEEE ISQED
   Sampson A, 2011, ACM SIGPLAN NOTICES, V46, P164, DOI 10.1145/1993316.1993518
   Scarabottolo I., 2018, IEEE DATE
   Scarabottolo I, 2020, P IEEE, V108, P2195, DOI 10.1109/JPROC.2020.3014430
   Venkataramani S., 2012, IEEE DAC
   Witschen L., MICROELECTRONICS REL, V99, P277
   Witschen L., 2019, ACM GLSVLSI
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 384
EP 389
DI 10.1109/ISVLSI51109.2021.00076
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Chen, PY
   Hsu, YW
   Lee, MC
   Perng, JW
AF Chen, Po-Yang
   Hsu, Ya-Wen
   Lee, Ming-Chan
   Perng, Jau-Woei
GP IEEE
TI Intelligent Manufacturing Monitoring and Surface Roughness Prediction
   System - A Case Study of Aluminum Parts Milling
SO 2020 INTERNATIONAL AUTOMATIC CONTROL CONFERENCE (CACS)
SE CACS International Automatic Control Conference
DT Proceedings Paper
CT International Automatic Control Conference (CACS)
CY NOV 04-07, 2020
CL Hsinchu, TAIWAN
DE neural network; deep learning; machine learning; intelligent systems
ID NEURAL-NETWORKS
AB The aim of this study is to create an economical automatic machining system to predict surface roughness during processing, which is an important quality criterion. Complex network accelerators and software acceleration are used to achieve real-time calculations. When the expected results are not obtained, the turning tool is changed or processing is halted. The system can maximize the processing efficiency. In this study, a deep neural network is used to predict the roughness of the plane, and sensors are installed at different positions to study the effects of different positions and numbers on accuracy. The accuracy obtained is 92.3%.
C1 [Chen, Po-Yang; Hsu, Ya-Wen; Lee, Ming-Chan; Perng, Jau-Woei] Natl Sun Yat Sen Univ, Dept Mech & Electromech Engn, Kaohsiung, Taiwan.
RP Chen, PY (corresponding author), Natl Sun Yat Sen Univ, Dept Mech & Electromech Engn, Kaohsiung, Taiwan.
EM B063022062@student.nsysu.edu.tw; d043020006@student.nsysu.edu.tw;
   mclee@mail.nsysu.edu.tw; ejwperng@faculty.nsysu.edu.tw
CR BARSCHDORFF D, 1991, COMPUT IND, V17, P101, DOI 10.1016/0166-3615(91)90024-4
   Benardos PG, 2003, INT J MACH TOOL MANU, V43, P833, DOI 10.1016/S0890-6955(03)00059-2
   Benardos PG, 2002, ROBOT CIM-INT MANUF, V18, P343, DOI 10.1016/S0736-5845(02)00005-4
   Davim JP., 2008, MACHINING
   Hossain MI, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P1321, DOI 10.1109/ICCCE.2008.4580819
   Kamguem R, 2013, INT J PRECIS ENG MAN, V14, P183, DOI 10.1007/s12541-013-0026-x
   Shaw M.C., 2004, METAL CUTTING PRINCI
   Tsai YH, 1999, INT J MACH TOOL MANU, V39, P583, DOI 10.1016/S0890-6955(98)00053-4
   Vallavi A., 2015, INT J APPL ENG RES, V10, P15207
   VARGHESE S, 1994, J MATER PROCESS TECH, V44, P353, DOI 10.1016/0924-0136(94)90449-9
   Wang X, 2009, 5 INT C NAT COMP 5 INT C NAT COMP
NR 11
TC 0
Z9 0
U1 0
U2 1
PY 2020
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
DA 2023-11-11
ER

PT C
AU Zhu, HY
   Wu, RF
   Diao, YJ
   Ke, SB
   Li, HY
   Zhang, C
   Xue, JL
   Ma, LX
   Xia, YQ
   Cui, W
   Yang, F
   Yang, M
   Zhou, LD
   Cidon, A
   Pekhimenko, G
AF Zhu, Hongyu
   Wu, Ruofan
   Diao, Yijia
   Ke, Shanbin
   Li, Haoyu
   Zhang, Chen
   Xue, Jilong
   Ma, Lingxiao
   Xia, Yuqing
   Cui, Wei
   Yang, Fan
   Yang, Mao
   Zhou, Lidong
   Cidon, Asaf
   Pekhimenko, Gennady
GP USENIX Association
TI ROLLER: Fast and Efficient Tensor Compilation for Deep Learning
SO PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND
   IMPLEMENTATION, OSDI 2022
DT Proceedings Paper
CT 16th USENIX Symposium on Operating Systems Design and Implementation
   (OSDI)
CY JUL 11-13, 2022
CL Carlsbad, CA
AB Despite recent advances in tensor compilers, it often takes hours to generate an efficient kernel for an operator, a compute-intensive sub-task in a deep neural network (DNN), on various accelerators (e.g., GPUs). This significantly slows down DNN development cycles and incurs heavy burdens on the development of general kernel libraries and custom kernels, especially for new hardware vendors. The slow compilation process is due to the large search space formulated by existing DNN compilers, which have to use machine learning algorithms to find good solutions.
   In this paper, we present ROLLER, which takes a different construction-based approach to generate kernels. At the core of ROLLER is rTile, a new tile abstraction that encapsulates tensor shapes that align with the key features of the underlying accelerator, thus achieving efficient execution by limiting the shape choices. ROLLER then adopts a recursive rTile-based construction algorithm to generate rTile-based programs (rProgram), whose performance can be evaluated efficiently with a micro-performance model without being evaluated in a real device. As a result, ROLLER can generate efficient kernels in seconds, with comparable performance to the state-of-the-art solutions on popular accelerators like GPUs, while offering better kernels on newer accelerators like IPUs.
C1 [Zhu, Hongyu; Pekhimenko, Gennady] Univ Toronto, Toronto, ON, Canada.
   [Wu, Ruofan] Renmin Univ China, Beijing, Peoples R China.
   [Diao, Yijia] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Ke, Shanbin] UCSD, La Jolla, CA USA.
   [Cidon, Asaf] Columbia Univ, New York, NY USA.
   [Zhang, Chen] Tsinghua Univ, Beijing, Peoples R China.
   [Zhu, Hongyu; Wu, Ruofan; Diao, Yijia; Ke, Shanbin; Li, Haoyu; Zhang, Chen; Xue, Jilong; Ma, Lingxiao; Xia, Yuqing; Cui, Wei; Yang, Fan; Yang, Mao; Zhou, Lidong] Microsoft Res, Redmond, WA 98052 USA.
RP Zhu, HY (corresponding author), Univ Toronto, Toronto, ON, Canada.; Zhu, HY (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], NVIDIA CUDNN
   [Anonymous], CUDA BAS LIN ALG SUB
   [Anonymous], NVIDIA CUTL
   [Anonymous], AMD ROCM PLATF
   [Anonymous], AMD RAD INSTINCTT MI
   Baghdadi R, 2019, INT SYM CODE GENER, P193, DOI [10.5281/zenodo.2375075, 10.1109/CGO.2019.8661197]
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TQ, 2018, ADV NEUR IN, V31
   CUDA NVCC, US
   Devlin J., 2018, PREPRINT
   Georganas Evangelos, 2021, CORR
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   IPU PROGRAMMER'S GUIDE, US
   Jia Z, 2019, Arxiv, DOI arXiv:1912.03413
   Jia Z, 2018, Arxiv, DOI [arXiv:1804.06826, 10.48550/ARXIV.1804.06826]
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li R, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P928, DOI 10.1145/3445814.3446759
   Liang Rendong, 2022, 28 ANN INT C MOB COM
   Ma LX, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P881
   MLIR, US
   NVIDIA TRITON INFERENCE SERVER, US
   ONNX, US
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   TensorIR, US
   Tillet P, 2019, PROCEEDINGS OF THE 3RD ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES (MAPL '19), P10, DOI 10.1145/3315508.3329973
   Vasilache N, 2018, Arxiv, DOI arXiv:1802.04730
   Wu RF, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P1807, DOI 10.1145/3485447.3511985
   XLA, US
   Zhang F, 2022, IEEE T PARALL DISTR, V33, P459, DOI 10.1109/TPDS.2021.3093234
   Zhao J, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P1233, DOI 10.1145/3453483.3454106
   Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863
   Zheng Ningxin, 2022, P 16 USENIX S OP SYS
   Zheng SZ, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P859, DOI 10.1145/3373376.3378508
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 36
TC 8
Z9 8
U1 0
U2 0
PY 2022
BP 233
EP 248
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ding, LC
   Huang, ZZ
   Chen, GS
AF Ding, Luchang
   Huang, Zhize
   Chen, Gengsheng
BE Ye, F
   Tang, TA
TI An FPGA Implementation of GCN with Sparse Adjacency Matrix
SO 2019 IEEE 13TH INTERNATIONAL CONFERENCE ON ASIC (ASICON)
SE International Conference on ASIC
DT Proceedings Paper
CT 13th IEEE International Conference on ASIC
CY OCT 29-NOV 01, 2019
CL Chongqing, PEOPLES R CHINA
AB Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has approaches for graph data have emerged.
   Graph convolution networks (GCNs) in particular, try to replicate the success of CNN in graph data by defining graph convolutions via graph spectral theory or spatial locality. This paper presents a new GCN accelerator for the graph convolution layers of ST-GCN [1], which is successfully applied in action recognition. The accelerator breaks down the graph convolution into convolution and matrix multiplication with adjacency matrix. To optimize the power efficiency, the dataflow of the convolution is designed properly and a sparse matrix-vector multiplication is proposed to make use of the sparsity of the adjacency matrix. The accelerator is implemented on NSA.241 accelerator and can reach its peak performance of 46.0GOP/s under 188MHz with about 220 DSP, which achieves high DSP efficiency.
C1 [Ding, Luchang; Huang, Zhize; Chen, Gengsheng] Fudan Univ, State Key Lab ASIC & Syst, Shanghai 200433, Peoples R China.
RP Chen, GS (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai 200433, Peoples R China.
EM gschen@fudan.edu.cn
CR [Anonymous], 2016, P 2016 ACM SIGDA INT
   [Anonymous], 2016, CORR
   [Anonymous], 2018, SPATIAL TEMPORAL GRA
   Huang Chao, 2017, 2017 IEEE 12 INT C A
   Li X, 2017, 2017 IEEE 12 INT C A
NR 5
TC 0
Z9 0
U1 0
U2 7
PY 2019
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Lee, CH
   Hsu, YT
   Liu, TT
   Chiueh, TD
AF Lee, Chia-Heng
   Hsu, Ying-Tuan
   Liu, Tsung-Te
   Chiueh, Tzi-Dar
BE Tran, XT
   Bui, DH
TI Design of an 45nm NCFET Based Compute-in-SRAM for Energy-Efficient
   Machine Learning Applications
SO APCCAS 2020: PROCEEDINGS OF THE 2020 IEEE ASIA PACIFIC CONFERENCE ON
   CIRCUITS AND SYSTEMS (APCCAS 2020)
DT Proceedings Paper
CT 16th IEEE Asia Pacific Conference on Circuits and Systems (IEEE APCCAS)
   / IEEE Asia Pacific Conference on Postgraduate Research in
   Microelectronics and Electronics (PrimeAsia)
CY DEC 08-10, 2020
CL Halong, VIETNAM
DE neural networks; compute in memory; negative capacitance field effect
   transistor
AB In memory computation for machine learning (ML) applications is a novel technique for neural-network computation accelerators, since it is highly parallel and can save a great amount of computation and memory access power. In this paper, we propose a compute in memory (CIM) design based on a new type of high-performance transistor, called Negative Capacitance Field Effect Transistor (NCFET). The proposed design demonstrates much higher energy efficiency than the CIM designs based on traditional CMOS transistors. Simulation results show that the proposed NCFET CIM achieves 3X energy reduction or 18X speed enhancement than the CMOS based CIM design.
C1 [Lee, Chia-Heng; Hsu, Ying-Tuan; Liu, Tsung-Te; Chiueh, Tzi-Dar] Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
RP Lee, CH (corresponding author), Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
CR [Anonymous], 2018, GEFORCE RTX 2080 TI
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Dutta T, 2017, IEEE ELECTR DEVICE L, V38, P1161, DOI 10.1109/LED.2017.2712365
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Herculano-Houzel S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017514
   Mandavi S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P163, DOI 10.1109/ICPCSI.2017.8392025
   Radhakrishna U., 2017, VIRTUAL SOURCE NEGAT
   Strohmaier E., 2019, TOP500 LIST JUNE 201
   Van der Plas G, 2008, DIG IEEE ISSCC, P242
   Wahab M. Abdul, 2017, VERILOG A COMPACT MO
   Waldrop MM, 2012, NATURE, V482, P456, DOI 10.1038/482456a
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 12
TC 4
Z9 4
U1 0
U2 1
PY 2020
BP 193
EP 196
DI 10.1109/apccas50809.2020.9301709
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, BL
   Gadepally, V
   Samsi, S
   Veillette, M
   Tiwari, D
AF Li, Baolin
   Gadepally, Vijay
   Samsi, Siddharth
   Veillette, Mark
   Tiwari, Devesh
GP IEEE
TI Serving Machine Learning Inference Using Heterogeneous Hardware
SO 2021 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 20-24, 2021
CL ELECTR NETWORK
AB The growing popularity of machine learning algorithms and the wide availability of hardware accelerators have brought up new challenges on inference serving. This paper explores the opportunity to serve inference queries with a heterogeneous system. The system has a central optimizer that allocates heterogeneous hardware resources to cooperatively serve queries. The optimizer supports both energy minimization and throughput maximization while satisfying a latency target. The optimized heterogeneous serving system is evaluated against a homogeneous system, on two representative real-world applications of radar nowcasting and object detection. Our evaluation results show that the power-optimized heterogeneous system can achieve up to 36% of power saving, and the throughput-optimized heterogeneous system can increase query throughput by up to 53%.
C1 [Li, Baolin; Tiwari, Devesh] Northeastern Univ, Boston, MA 02115 USA.
   [Gadepally, Vijay; Samsi, Siddharth; Veillette, Mark] MIT, Lincoln Lab, Cambridge, MA 02139 USA.
RP Li, BL (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
CR Agrawal Akshay, 2018, Journal of Control and Decision, V5, P42, DOI 10.1080/23307706.2017.1397554
   Ali A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00073
   Alipourfard O, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P469
   Ashraf MI, 2017, EUR CONF NETW COMMUN
   Chen L, 2020, EARTH SPACE SCI, V7, DOI 10.1029/2019EA000812
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Cui WH, 2019, PR IEEE COMP DESIGN, P497, DOI 10.1109/ICCD46524.2019.00075
   De Matteis T, 2017, EUROMICRO WORKSHOP P, P61, DOI 10.1109/PDP.2017.31
   Dhakal Aditya, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P492, DOI 10.1145/3419111.3421284
   Diamond S, 2016, J MACH LEARN RES, V17
   DIXON M, 1993, J ATMOS OCEAN TECH, V10, P785, DOI 10.1175/1520-0426(1993)010<0785:TTITAA>2.0.CO;2
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu JC, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P485
   Gueyoung Jung, 2013, 2013 IEEE Ninth World Congress on Services (SERVICES), P456, DOI 10.1109/SERVICES.2013.55
   Gunasekaran J.R., 2021, ARXIV PREPRINT ARXIV
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Hanafy Walid A., 2021, e-Energy '21: Proceedings of the Twelfth International Conference on Future Energy Systems, P302, DOI 10.1145/3447555.3465326
   Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079
   Jeon M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P947
   Jiang NJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6086
   Jocher G., 2019, **DATA OBJECT**, DOI 10.5281/zenodo.2628754
   KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703, DOI 10.1137/0108053
   Khan AI, 2020, PROCEDIA COMPUT SCI, V167, P1444, DOI 10.1016/j.procs.2020.03.355
   Kim YG, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P1082, DOI 10.1109/MICRO50266.2020.00090
   Lam D., 2018, XVIEW OBJECTS CONTEX
   Le TN, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387547
   Li Y, 2020, IEEE INFOCOM SER, P1668, DOI [10.1109/INFOCOM41043.2020.9155267, 10.1109/infocom41043.2020.9155267]
   Mahajan K, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P289
   Narayanan D, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P481
   Park JH, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P307
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun JZ, 2014, B AM METEOROL SOC, V95, P409, DOI 10.1175/BAMS-D-11-00263.1
   Sun X, 2017, IEEE INT CONF MOB, P1, DOI 10.1109/MASS.2017.35
   Turner BJ, 2004, J APPL METEOROL, V43, P231, DOI 10.1175/1520-0450(2004)043<0231:POPFCR>2.0.CO;2
   Veillette M., 2020, ADV NEURAL INFORM PR, V33, p22 009
   Wan CC, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P353
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   WOLSEY LA, 1980, MATH PROGRAM STUD, V13, P121, DOI 10.1007/BFb0120913
   Xiao WC, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P595
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   You J., NSDI, V2021, P633
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhou GR, 2019, AAAI CONF ARTIF INTE, P5941
NR 47
TC 0
Z9 0
U1 0
U2 1
PY 2021
DI 10.1109/HPEC49654.2021.9622863
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Yen, J
   Qi, YY
   Wong, SF
   Zhou, JT
AF Yen, Joseph
   Qi, Yuan Yuan
   Wong, Seng Fat
   Zhou, Jiantao
TI Symbolic regression-based adaptive generation of implied volatility
SO INTERNATIONAL JOURNAL OF FINANCIAL ENGINEERING
DT Article
DE Implied volatility; FPGA; finance; machine learning; symbolic regression
ID STOCHASTIC VOLATILITY; OPTIONS; FORMULA
AB This research paper introduces a new form of Implied Volatility calculation with Symbolic Regression suited for high-frequency trading. The solutions are easily migratable to hardware accelerators like Field Programmable Gate Arrays. This machine learning approach is flexible, and configurable for either high precision, lower latency, or energy efficiency. The model evaluates each mathematical operator in terms of cycles, which then generates highly parallel yet low depth formulas. From testing with C++, the formulas achieved higher accuracy and less than a sixth the time of traditional Implied Volatility models. The data were tested on the SPX dataset to validate accuracy.
C1 [Yen, Joseph; Wong, Seng Fat] Univ Macau, Elect Mech Engn, Macau, Peoples R China.
   [Qi, Yuan Yuan; Zhou, Jiantao] Univ Macau, Comp & Informat Sci, Macau, Peoples R China.
RP Yen, J (corresponding author), Univ Macau, Elect Mech Engn, Macau, Peoples R China.
EM yb87412@um.edu.mo; yc17471@um.edu.mo; fstsfw@um.edu.mo; jtzhou@um.edu.mo
CR ackel P. J, 2006, WILMOTT, V26, P60
   Anjum A, 2019, LECT NOTES COMPUT SC, V11728, P373, DOI 10.1007/978-3-030-30484-3_31
   [Anonymous], 2013, IMPL FPGA DES OPENCL
   Bernemann A, 2011, SSRN ELECT J
   BLACK F, 1973, J POLIT ECON, V81, P637, DOI 10.1086/260062
   Boutros A., 2017, PROC INT CONF RECON
   Brugger C, 2014, FPL, P1
   Corrado CJ, 1996, J BANK FINANC, V20, P595, DOI 10.1016/0378-4266(95)00014-3
   Ewing J, 2010, ALL THESES, P868
   Glau K, 2019, J COMPUT FINANC, V23, P1, DOI 10.21314/JCF.2019.375
   GOLDBERG D, 1991, COMPUT SURV, V23, P5, DOI 10.1145/103162.103163
   Hallerback W, 2004, ERIM REPORT SERIES
   HESTON SL, 1993, REV FINANC STUD, V6, P327, DOI 10.1093/rfs/6.2.327
   HULL J, 1987, J FINANC, V42, P281, DOI 10.1111/j.1540-6261.1987.tb02568.x
   Intel, 2021, FLOAT POINT IP COR U
   Isengildina, 2007, SO AGR EC ASS M
   Jackel P, 2015, WILMOTT, V2015, P40, DOI [DOI 10.1002/WILM.10395, 10.1002/wilm.10395]
   KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355
   Li MQ, 2008, EUR J OPER RES, V185, P743, DOI 10.1016/j.ejor.2006.12.028
   Liebig, 2014, INT C FIELD PROGRAMM, P107
   Liu S., 2020, MULTIDISCIPLINARY DI, V54, P61
   Liu SQ, 2019, RISKS, V7, DOI 10.3390/risks7010016
   Lockwood J. W., 2012, 2012 IEEE 20th Annual Symposium on High-Performance Interconnects (HOTI), P9, DOI 10.1109/HOTI.2012.15
   Lorig M, 2014, J RISK, V17, P3, DOI 10.21314/JOR.2014.297
   MANASTER S, 1982, J FINANC, V37, P227, DOI 10.2307/2327127
   Matic I, 2020, QUANT FINANC, V20, P393, DOI 10.1080/14697688.2019.1675898
   McConaghy T, 2011, GENET EVOL COMPUT, P235
   MERTON RC, 1973, BELL J ECON, V4, P141, DOI 10.2307/3003143
   Orlando G, 2017, J COMPUT APPL MATH, V320, P202, DOI 10.1016/j.cam.2017.02.002
   Orzechowski P, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1183, DOI 10.1145/3205455.3205539
   Poli R., 2008, FIELD GUIDE GENETIC
   Pottathuparambil R, 2011, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2011.50
   Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893
   Searson D.P., 2015, HDB GENETIC PROGRAMM, P551, DOI DOI 10.1007/978-3-319-20883-1_22
   Vanderbauwhede W., 2013, HIGH PERFORMANCE COM
   Wikimedia, 2020, IEEE 754 DOUBL FLOAT
   Wikimedia, 2020, FLOAT EX
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Zegklitz J, 2021, GENET PROGRAM EVOL M, V22, P5, DOI 10.1007/s10710-020-09387-0
NR 39
TC 0
Z9 0
U1 1
U2 2
PD SEP
PY 2022
VL 09
IS 03
AR 2250018
DI 10.1142/S2424786322500189
EA AUG 2022
WC Business, Finance
DA 2023-11-11
ER

PT J
AU Mosses, A
   Prathap, PMJ
AF Mosses, A.
   Prathap, P. M. Joe
TI Design and analysis of on-chip reconfigurable photonic components for
   photonic multiply and accumulate operation
SO OPTICAL AND QUANTUM ELECTRONICS
DT Article
DE Reconfigurable photonic components; Fabrication sensitivity; Photonic
   MAC; Machine learning; Complex photonic operations
ID CRYSTAL; LAYER
AB Photonic computing plays a significant role in high-performance computing applications. The high speed and capacity of processing larger information by photonic signals assist the high-performance computing applications such as hardware accelerators, machine learning application and deep learning applications. In this work, we propose a photonic MAC (PMAC) based on reconfigurable photonic components such as reconfigurable Mach-Zehnder interferometer (RMZI), reconfigurable directional coupler (RDC) and reconfigurable micro-ring resonator (RMRR). Theoretical analysis and simulations are carried out based on MATLAB R2023a software package and Ansys Lumerical 2018a software suits. Based on the analysis it is evident that the PMAC realization, based on RDC is more suitable for MAC operations due to its smaller footprint and less sensitive (2%) to fabrication variations. Comparatively RMZI results in larger footprint and RMRR shows more sensitive (11%) to fabrication variations. The photonic MAC proposed in this work acts as the key component for machine learning and deep learning applications.
C1 [Mosses, A.] Madha Inst Engn & Technol, Dept Elect & Commun Engn, Chennai, India.
   [Prathap, P. M. Joe] RMD Engn Coll, Dept Comp Sci & Engn, Kavaraipettai, India.
RP Mosses, A (corresponding author), Madha Inst Engn & Technol, Dept Elect & Commun Engn, Chennai, India.
EM mossesleojohnson@gmail.com; drjoeprathap@rmd.ac.in
CR Al-Qadasi MA, 2022, APL PHOTONICS, V7, DOI 10.1063/5.0070992
   Bai BW, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-2872-3
   Bogaerts W, 2014, IEEE J SEL TOP QUANT, V20, DOI 10.1109/JSTQE.2013.2295882
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   De Marinis L, 2022, IEEE J QUANTUM ELECT, V58, DOI 10.1109/JQE.2022.3177793
   Feng CH, 2022, Arxiv, DOI arXiv:2111.06705
   Hamerly R, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993624
   Huang C, 2022, ADV PHYS-X, V7, DOI 10.1080/23746149.2021.1981155
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562
   Liu S., 2019, SCI CHINA INFORM SCI, V62, P1, DOI [10.1007/s11427-018-9402-9, DOI 10.1007/S11427-018-9402-9]
   Marquez BA., 2020, PHOTONIQUES, V104, P40, DOI 10.1051/photon/202010440
   Meerasha MA, 2022, OPT QUANT ELECTRON, V54, DOI 10.1007/s11082-022-04168-8
   Mourgias-Alexandris G, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33259-z
   Mubarak Ali M., 2021, MICROELECTRONIC DEVI
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Ohno S, 2022, ACS PHOTONICS, DOI 10.1021/acsphotonics.1c01777
   Paolini E, 2022, NEURAL COMPUT APPL, V34, P15589, DOI 10.1007/s00521-022-07243-z
   Shaheen SA, 2017, CHINESE J PHYS, V55, P571, DOI 10.1016/j.cjph.2016.12.005
   Stark P, 2020, NANOPHOTONICS-BERLIN, V9, P4221, DOI 10.1515/nanoph-2020-0297
   Sunny FP, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3459009
   Sunny FP, 2021, SILICON PHOTONICS HI, P367
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Taya SA, 2018, OPTO-ELECTRON REV, V26, P236, DOI 10.1016/j.opelre.2018.05.002
   Taya SA, 2018, INDIAN J PHYS, V92, P519, DOI 10.1007/s12648-017-1130-z
   Taya SA, 2021, OPTIK, V243, DOI 10.1016/j.ijleo.2021.167505
   Taya SA, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-020-02669-y
   Waldrop MM, 2016, NATURE, V530, P144, DOI 10.1038/530144a
   Xu B, 2022, PHOTONICS-BASEL, V9, DOI 10.3390/photonics9100698
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
NR 29
TC 0
Z9 0
U1 8
U2 8
PD OCT
PY 2023
VL 55
IS 10
AR 934
DI 10.1007/s11082-023-05200-1
WC Engineering, Electrical & Electronic; Quantum Science & Technology;
   Optics
DA 2023-11-11
ER

PT J
AU Struharik, RJR
   Vukobratovic, BZ
   Erdeljan, AM
   Rakanovic, DM
AF Struharik, Rastislav J. R.
   Vukobratovic, Bogdan Z.
   Erdeljan, Andrea M.
   Rakanovic, Damjan M.
TI CoNNa-Hardware accelerator for compressed convolutional neural networks
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Machine learning; Convolutional neural network; CNN pruning compressed
   CNN; Hardware acceleration; FPGA
AB In this paper, we propose a novel Convolutional Neural Network hardware accelerator called CoNNA, capable of accelerating pruned, quantized CNNs. In contrast to most existing solutions, CoNNA offers a complete solution to the compressed CNN acceleration, being able to accelerate all layer types commonly found in contemporary CNNs. CoNNA is designed as a coarse-grained reconfigurable architecture, which uses rapid, dynamic reconfiguration during CNN layer processing. The CoNNA architecture enables the on-the-fly selection of the CNN network that should be accelerated and also supports the acceleration of CNN networks with dynamic topology. Furthermore, by being able to directly process compressed feature and kernel maps, and skip all ineffectual computations during CNN layer processing, the CoNNA CNN accelerator is able to achieve higher CNN processing rates than some of the previously proposed solutions. The CoNNA architecture has been implemented using Xilinx ZynqUtrascale+ FPGA family and compared with seven previously proposed CNN hardware accelerators. Results of the experiments seem to indicate that the CoNNA architecture is up to 14.10, 6.05, 4.91, 2.67, 11.30, 3.08 and 3.58 times faster than previously proposed MIT's Eyeriss, NullHop, NVIDIA's Deep Learning Accelerator (NVDLA), NEURAghe, CNN_A1, fpgaConvNet, and Deephi's Aristotle CNN accelerators respectively, while using identical number of computing units and operating at the same clock frequency. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Struharik, Rastislav J. R.; Erdeljan, Andrea M.; Rakanovic, Damjan M.] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
   [Vukobratovic, Bogdan Z.] Kortiq GmbH, Gebrilder Eicher Ring 45, Forstern, Germany.
RP Struharik, RJR (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
EM rasti@uns.ac.rs; bogdan.vukobratovic@kortiq.com;
   andrea.erdeljan@uns.ac.rs; rdamjan@uns.ac.rs
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   ALRAHHAL M, 2018, REMOTE SENS, V10, P1
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen TH, 2019, IEEE T CONTR SYST T, V27, P2757, DOI 10.1109/TCST.2018.2862865
   Chen XB, 2018, IEEE T VLSI SYST, V26, P1408, DOI 10.1109/TVLSI.2018.2810831
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng J, 2018, IEEE T NEUR NET LEAR, V29, P4730, DOI 10.1109/TNNLS.2017.2774288
   Choi Y, 2017, IEEE T CIRCUITS-II, V64, P1332, DOI 10.1109/TCSII.2017.2691771
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   ERDELJAN A, 2017, 25 TEL FOR TELFOR 20, P44
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo KY, 2017, IEEE MICRO, V37, P18, DOI 10.1109/MM.2017.39
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   *INT, 2017, INT STRAT 10 VAR PRE
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li H., 2016, 5 INT C LEARNING REP, P1
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu YT, 2018, INT J PARALLEL PROG, V46, P648, DOI 10.1007/s10766-017-0528-8
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Meloni P, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3284357
   Motamedi M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3131289
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   *NVIDIA, 2017, NVIDIA JETSON TX2 DE
   *NVIDIA, 2018, WP08608001V11 NVIDIA
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shah NH, 2020, INT J SYST SCI-OPER, V7, P34, DOI [10.1080/23302674.2018.1487606, 10.1109/TNNLS.2018.2815085]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Zhang SJ, 2016, INT SYMP MICROARCH
   ZHU A, 2018, AIP ADV, V8, P1
   2019, NVIDIA DEEP LEARNING
NR 52
TC 10
Z9 10
U1 5
U2 26
PD MAR
PY 2020
VL 73
AR 102991
DI 10.1016/j.micpro.2020.102991
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Schuiki, F
   Schaffner, M
   Benini, L
AF Schuiki, Fabian
   Schaffner, Michael
   Benini, Luca
GP IEEE
TI NTX: An Energy-efficient Streaming Accelerator for Floating-point
   Generalized Reduction Workloads in 22 nm FD-SOI
SO 2019 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 22nd Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 25-29, 2019
CL Florence, ITALY
DE Processor Architecture; Accelerator; Deep Learning; VLSI; Linear Algebra
AB Specialized coprocessors for Multiply-Accumulate (MAC) intensive workloads such as Deep Learning are becoming widespread in SoC platforms, from GPUs to mobile SoCs. In this paper we revisit NTX (an efficient accelerator developed for training Deep Neural Networks at scale) as a generalized MAC and reduction streaming engine. The architecture consists of a set of 32 bit floating-point streaming co-processors that are loosely coupled to a RISC-V core in charge of orchestrating data movement and computation. Post-layout results of a recent silicon implementation in 22nm FD-SOI technology show the accelerator's capability to deliver up to 20 Gflop/s at 1.25 GHz and 168mW. Based on these results we show that a version of NTX scaled down to 14nm can achieve a 3x energy efficiency improvement over contemporary GPUs at 10.4x less silicon area, and a compute performance of 1.4 Tflop/s for training large state-of-the-art networks with full floating-point precision. An extended evaluation of MAC-intensive kernels shows that NTX can consistently achieve up to 87% of its peak performance across general reduction workloads beyond machine learning. Its modular architecture enables deployment at different scales ranging from high-performance GPU-class to low-power embedded scenarios.
C1 [Schuiki, Fabian; Schaffner, Michael; Benini, Luca] Swiss Fed Inst Technol, IIS, Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, DEI, Bologna, Italy.
RP Schuiki, F (corresponding author), Swiss Fed Inst Technol, IIS, Zurich, Switzerland.
EM fschuiki@iis.ee.ethz.ch; schaffner@iis.ee.ethz.ch;
   lbenini@iis.ee.ethz.ch
CR [Anonymous], 2017, TENSORFLOW BENCHMARK
   Azarkhish E., 2017, IEEE TPDS, VPP
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gautschi M., 2017, TVLSI
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gysi T, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P177, DOI 10.1145/2751205.2751223
   Johnson Justin, CNN BENCHMARKS
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kerl C., 2013, IEEE IROS
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Koutis I, 2011, COMPUT VIS IMAGE UND, V115, P1638, DOI 10.1016/j.cviu.2011.05.013
   Krishnan D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024211
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krueger J., 2011, P 2011 INT C HIGH PE, P73
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   NVidia, 2017, ART INT ARCH NVIDIA
   Schuiki F., 2018, IEEE T COMPUTERS
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wardetzky M., 2007, P 5 EUR S GEOM PROC, P33, DOI DOI 10.2312/SGP/SGP07/033-037
NR 24
TC 6
Z9 6
U1 0
U2 2
PY 2019
BP 662
EP 667
DI 10.23919/date.2019.8715007
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Peng, CH
   Lin, PC
   Barma, S
   Wang, JF
   Peng, HY
   Bharanitharan, K
   Kuan, TW
AF Peng, Chih-Hsiang
   Lin, Po-Chuan
   Barma, Shovan
   Wang, Jhing-Fa
   Peng, Hong-Yuan
   Bharanitharan, Karunanithi
   Kuan, Ta-Wen
TI Low-power enhanced system-on-chip design for sequential minimal
   optimisation learning core with tri-layer bus and butterfly-path
   accelerator
SO IET COMPUTERS AND DIGITAL TECHNIQUES
DT Article
DE system-on-chip; optimisation; low-power enhanced system-on-chip design;
   sequential minimal optimisation learning core; butterfly-path
   accelerator; system-level performance; tri-layer bus architecture;
   linear prediction cepstral coefficients extraction; SoC; clock
   down-sampling; voltage scaling
ID SUPPORT VECTOR MACHINES; SPEECH RECOGNITION; PARALLEL; ARCHITECTURE;
   IMPLEMENTATION; FEATURES
AB A tri-layer bus system-on-chip (SoC) and a butterfly-path accelerator are used to enhance system-level performance in a sequential minimal optimisation learning core. The tri-layer bus architecture is used to obtain an adequate transfer rate. The butterfly-path accelerator also uses symmetrical access to resolve bottlenecks during linear prediction cepstral coefficients extraction. This novel design increases speed and flexibility without substantially increasing area. For implementation in chip manufacturing, the SoC is synthesised, placed and routed using the TSMC 90 nm technology library. The die size is 2.09 mm x 2.09 mm, and the power consumption is 8.9 mW. Compared with the non-butterfly-path design, the simulation results show that the proposed architecture provides a 2.4-fold speed increase. In addition, clock down-sampling and voltage scaling reduce the power consumed by the proposed chip by a factor of 8.5. The experimental results confirm the improved speed and power that are provided by the proposed architecture and methods.
C1 [Peng, Chih-Hsiang; Barma, Shovan; Wang, Jhing-Fa; Peng, Hong-Yuan; Kuan, Ta-Wen] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
   [Lin, Po-Chuan] Tung Fang Design Inst, Dept Digital Game & Animat Design, Multimedia & Digital Syst Design Lab, Kaohsiung 82941, Taiwan.
   [Bharanitharan, Karunanithi] Feng Chia Univ, Dept Elect Engn, Taichung 40724, Taiwan.
RP Peng, CH (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 70101, Taiwan.
EM tony178.lin@gmail.com
CR Alhussien A, 2012, IET COMPUT DIGIT TEC, V6, P173, DOI 10.1049/iet-cdt.2011.0082
   Campbell WM, 2007, IEEE T AUDIO SPEECH, V15, P2085, DOI 10.1109/TASL.2007.902874
   Cao KK, 2010, J ZHEJIANG U-SCI C, V11, P620, DOI 10.1631/jzus.C0910500
   Cao LJ, 2006, IEEE T NEURAL NETWOR, V17, P1039, DOI 10.1109/TNN.2006.875989
   Chakrabartty S, 2007, IEEE J SOLID-ST CIRC, V42, P1169, DOI 10.1109/JSSC.2007.894803
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   DURBIN J, 1959, BIOMETRIKA, V46, P306, DOI 10.1093/biomet/46.3-4.306
   Genov R, 2003, IEEE T NEURAL NETWOR, V14, P1426, DOI 10.1109/TNN.2003.816345
   Hansson A, 2009, IET COMPUT DIGIT TEC, V3, P398, DOI 10.1049/iet-cdt.2008.0093
   Kang K, 2010, IEEE T CIRCUITS-I, V57, P1513, DOI 10.1109/TCSI.2009.2034234
   Kim SN, 1996, IEEE T CONSUM ELECTR, V42, P458, DOI 10.1109/30.536143
   Kondo H, 2008, IEEE J SOLID-ST CIRC, V43, P892, DOI 10.1109/JSSC.2008.917528
   Kuan TW, 2012, IEEE T VLSI SYST, V20, P673, DOI 10.1109/TVLSI.2011.2107533
   Lee CH, 2013, IEEE T MULTIMEDIA, V15, P454, DOI 10.1109/TMM.2012.2229969
   Lin PC, 2007, IET SIGNAL PROCESS, V1, P139, DOI 10.1049/iet-spr:20060326
   Peng CH, 2014, IEEE T VLSI SYST, V22, P1791, DOI 10.1109/TVLSI.2013.2278706
   Platt J. C., 1999, ADV KERNEL METHODSUP
   Pomante L, 2013, IET COMPUT DIGIT TEC, V7, P246, DOI 10.1049/iet-cdt.2013.0026
   Srinivasan S, 2008, IET COMPUT DIGIT TEC, V2, P347, DOI 10.1049/iet-cdt:20070063
   Takahashi N, 2008, IEEE T NEURAL NETWOR, V19, P971, DOI 10.1109/TNN.2007.915116
   Vitkovski A, 2008, IET COMPUT DIGIT TEC, V2, P483, DOI 10.1049/iet-cdt:20050060
   Wang JF, 2008, IEEE T CONSUM ELECTR, V54, P870, DOI 10.1109/TCE.2008.4560173
   Wang N, 2007, IET COMPUT DIGIT TEC, V1, P1, DOI 10.1049/iet-cdt:20060080
   Wu GD, 2010, J INF SCI ENG, V26, P1073
   Zhang L, 2009, IEEE T VLSI SYST, V17, P1173, DOI 10.1109/TVLSI.2008.2002108
NR 25
TC 1
Z9 1
U1 0
U2 4
PD MAR
PY 2015
VL 9
IS 2
BP 93
EP 100
DI 10.1049/iet-cdt.2013.0153
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Birke, S
   Hartmann, B
   Auras, D
   Wloka, M
   Ascheid, G
   Leupers, R
AF Birke, Sebastian
   Hartmann, Bjoern
   Auras, Dominik
   Wloka, Markus
   Ascheid, Gerd
   Leupers, Rainer
BE Nurmi, J
   Wisland, DT
   Aunet, S
   Kjelgaard, K
TI Design and Exploration of an ARC-Coprocessor for LSTM Based Audio
   Applications
SO 2022 IEEE NORDIC CIRCUITS AND SYSTEMS CONFERENCE (NORCAS)
DT Proceedings Paper
CT 8th IEEE Nordic Circuits and Systems Conference (NorCAS)
CY OCT 25-26, 2022
CL Oslo, NORWAY
AB Machine Learning (ML) techniques are applied to solve automation tasks in more and more scenarios of our daily life. For instance, Keyword Spotting applications are of interest for Internet-of-things devices in a smart home or for human-machine interaction. Different ML techniques, such as Neural Networks including Long-Short Term Memories, recently achieve reasonable accuracy above 95 % In Therefore, we propose an accelerator for the Keyword spotter as a specialized coprocessor in order to retain the flexibility to fit different network structures, while the energy efficiency is increased.
C1 [Birke, Sebastian; Ascheid, Gerd; Leupers, Rainer] Inst Commun Technol & Embedded Syst, Aachen, Germany.
   [Birke, Sebastian; Hartmann, Bjoern; Ascheid, Gerd; Leupers, Rainer] Rhein Westfal TH Aachen, Aachen, Germany.
   [Auras, Dominik; Wloka, Markus] Synopsys GmbH, Aschheim, Germany.
RP Birke, S (corresponding author), Inst Commun Technol & Embedded Syst, Aachen, Germany.; Birke, S (corresponding author), Rhein Westfal TH Aachen, Aachen, Germany.
CR [Anonymous], DESIGNWARE ARC EM9D
   [Anonymous], GITHUB TENSORFLOW DO
   [Anonymous], GITHUB EMBARC MACHIN
   [Anonymous], DESIGNWARE PROCESSOR
   [Anonymous], GITHUB EMBARC MLI KE
   [Anonymous], SPECTRAL AUDIO SIGNA
   [Anonymous], ASIP DESIGNER APPL S
   Bytyn A, 2021, IEEE OJCAS, V2
   Chen CX, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P259, DOI 10.1109/ESSCIRC.2017.8094575
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dharmale G., 2019, IJACSA, DOI [10.14569/IJACSA.2019.0100212, DOI 10.14569/IJACSA.2019.0100212]
   Giraldo JSP, 2018, PROC EUR SOLID-STATE, P166, DOI 10.1109/ESSCIRC.2018.8494342
   Li P, 2011, IEEE T CIRCUITS-I, V58, P961, DOI 10.1109/TCSI.2010.2090569
   Noll T, 2004, IET C PROC, DOI [10.1049/cp20040506, DOI 10.1049/CP20040506]
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/344188
   Tian D., 2020, ICIT IOT SMART CITY, DOI [10.1145/3446999.3447008, DOI 10.1145/3446999.3447008]
   Wang J.-C., IEEE ICECS 2001, V1, P477
   Warden P, 2018, SPEECH COMMANDS DATA
   Wu L., 2021, IEEE ISCAS
   Yang H., 2008, ICALIP
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/NORCAS57515.2022.9934553
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Wudenhe, A
   Tseng, HW
AF Wudenhe, Abenezer
   Tseng, Hung-Wei
GP IEEE
TI TPUPoint: Automatic Characterization of Hardware-Accelerated
   Machine-Learning Behavior for Cloud Computing
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE (ISPASS 2021)
SE IEEE International Symposium on Performance Analysis of Systems and
   Software-ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY MAR 28-30, 2021
CL ELECTR NETWORK
ID BENCHMARK SUITE; SCALE
AB With the share of machine learning (ML) workloads in data centers rapidly increasing, cloud providers are beginning to incorporate accelerators such as tensor processing units (TPUs) to improve the energy-efficiency of applications. However, without optimizing application parameters, users may underutilize accelerators and end up wasting energy and money.
   This paper presents TPUPoint to facilitate the development of efficient applications on TPU-based cloud platforms. TPUPoint automatically classifies repetitive patterns into phases and identifies the most timing-critical operations in each phase. Further, TPUPoint can associate phases with checkpoints to allow fast-forwarding in applications, thereby significantly reducing the time and money spent optimizing applications.
   By running TPUPoint on a wide array of representative ML workloads, we found that computation is no longer the most time-consuming operation; instead, the infeed and reshape operations, which exchange and realign data, become most significant. TPUPoints advantages significantly increase the potential for discovering optimal parameters to quickly balance the complex workload pipeline of feeding data into a system, reformatting the data, and computing results.
C1 [Wudenhe, Abenezer; Tseng, Hung-Wei] Univ Calif Riverside, Riverside, CA 92521 USA.
RP Wudenhe, A (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM awude001@ucr.edu; htseng@ucr.edu
CR Adolf R, 2016, I S WORKL CHAR PROC, P148
   Alibaba, 2018, MATRIX
   amerly G., 2006, 2006 IEEE INT S PERF, P131
   [Anonymous], 2017, TRAINING
   [Anonymous], 2015, P ADV NEUR INF PROC
   [Anonymous], 2019, INTRO EEMBC MLMARK B
   [Anonymous], 2020, TENSORFLOW RES CLOUD
   Baidu,, 2017, DEEPBENCH BENCHM DEE
   Bhowmick S., 2010, APPL ALTERNATING DEC, P153
   Caulfield AM, 2016, INT SYMP MICROARCH
   Chen T., 2014, ASPLOS 14
   Chen Y.-H., 2016, ISCA 16
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi J. W., 2010, PPOPP 10
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Demmel J, 2005, P IEEE, V93, P293, DOI 10.1109/JPROC.2004.840848
   Deng Y, 2017, IEEE T NEUR NET LEAR, V28, P653, DOI 10.1109/TNNLS.2016.2522401
   Ding X., 2015, ITCAI 15
   Durant L., 2017, INSIDE VOLTA WORLDS
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Google Cloud, 2020, MACH TYP COMP ENG DO
   Google Cloud, 2020, SYSTEM ARCHITECTURE
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hasabnis N, 2018, PROCEEDINGS OF 2018 IEEE/ACM MACHINE LEARNING IN HPC ENVIRONMENTS (MLHPC 2018), P14, DOI [10.1109/MLHPC.2018.000-7, 10.1109/MLHPC.2018.8638636]
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ignatov A, 2019, IEEE INT CONF COMP V, P3617, DOI 10.1109/ICCVW.2019.00447
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaufman S. J., 2020, LEARNED PERFORMANCE
   Kipf T.N., 2017, P INT C LEARNING REP
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Linghao Song, 2019, ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). Proceedings, P3882, DOI 10.1109/ICASSP.2019.8683736
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Xin, 2019, DPATCH ADVERSARIAL P
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Luszczek P, 2017, IEEE HIGH PERF EXTR
   MacQueen J.B., 1967, PROC 5 BERKELEY S MA, V1, P281
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Mattson Peter, 2020, MLSYS, V2, P336
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Pati S, 2020, INT SYM PERFORM ANAL, P69, DOI 10.1109/ISPASS48437.2020.00017
   Pelleg D, 2000, P 17 INT C MACH LEAR
   Perelman E., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Perozzi B., 2014, P 20 ACM SIGKDD INT
   Radford Alec, 2016, ICLR
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Schubert E, 2017, ACM T DATABASE SYST, V42, DOI 10.1145/3068335
   Shao Y.S., 2019, MICRO 52, P1427
   Sherwood T, 2002, ACM SIGPLAN NOTICES, V37, P45, DOI 10.1145/605432.605403
   Song LH, 2020, INT S HIGH PERF COMP, P342, DOI 10.1109/HPCA47549.2020.00036
   Sriraman A, 2018, I S WORKL CHAR PROC, P1, DOI 10.1109/IISWC.2018.8573515
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   TensorFiow, 2020, XLA OPT COMP MACH LE
   TensorFlow, 2019, TENSORFLOW TPU MOD
   Thomdike R. L., 1953, PSYCHOMETRIKA, V18, P267
   Torelli P., CISC VIS NETW IND GL
   Turc, 2019, WELL READ STUDENTS L
   Venkataramani S., 2017, SER ISCA 17, P1326
   Wang GL, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P586, DOI [10.1109/HPCC-SmartCity-DSS.2016.0088, 10.1109/HPCC-SmartCity-DSS.2016.45]
   Wang L, 2014, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA.2014.6835958
   Wang Y.E., 2020, 3 C MACH LEARN SYST
   Wenisch T. F., 2005, SIGMETRICS 05
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
   Yu Adams Wei, 2018, QANET COMBINING LOCA
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang JP, 2020, INT PARALL DISTRIB P, P244, DOI 10.1109/IPDPS47924.2020.00034
   Zheng B., 2019, ECHO COMPILER BASED
   Zhu HY, 2018, I S WORKL CHAR PROC, P88, DOI 10.1109/IISWC.2018.8573476
NR 75
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 254
EP 264
DI 10.1109/ISPASS51385.2021.00048
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Wang, XB
   Zhao, BY
   Hou, R
   Awad, A
   Tian, ZH
   Meng, D
AF Wang, Xingbin
   Zhao, Boyan
   Hou, Rui
   Awad, Amro
   Tian, Zhihong
   Meng, Dan
GP IEEE Comp Soc
TI NASGuard: A Novel Accelerator Architecture for Robust Neural
   Architecture Search (NAS) Networks
SO 2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2021)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT ACM/IEEE 48th Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 14-19, 2021
CL ELECTR NETWORK
DE Robust NAS network; adversarial example; DNN accelerator
AB Due to the wide deployment of deep learning applications in safety-critical systems, robust and secure execution of deep learning workloads is imperative. Adversarial examples, where the inputs are carefully designed to mislead the machine learning model is among the most challenging attacks to detect and defeat. The most dominant approach for defending against adversarial examples is to systematically create a network architecture that is sufficiently robust. Neural Architecture Search (NAS) has been heavily used as the de facto approach to design robust neural network models, by using the accuracy of detecting adversarial examples as a key metric of the neural network's robustness. While NAS has been proven effective in improving the robustness (and accuracy in general), the NAS-generated network models run noticeably slower on typical DNN accelerators than the hand-crafted networks, mainly because DNN accelerators are not optimized for robust NAS-generated models. In particular, the inherent multi-branch nature of NAS-generated networks causes unacceptable performance and energy overheads.
   To bridge the gap between the robustness and performance efficiency of deep learning applications, we need to rethink the design of AI accelerators to enable efficient execution of robust (auto-generated) neural networks. In this paper, we propose a novel hardware architecture, NASGuard, which enables efficient inference of robust NAS networks. NASGuard leverages a heuristic multi-branch mapping model to improve the efficiency of the underlying computing resources. Moreover, NASGuard addresses the load imbalance problem between the computation and memory-access tasks from multi-branch parallel computing. Finally, we propose a topology-aware performance prediction model for data prefetching, to fully exploit the temporal and spatial localities of robust NAS-generated architectures. We have implemented NASGuard with Verilog RTL. The evaluation results show that NASGuard achieves an average speedup of 1.74x over the baseline DNN accelerator.
C1 [Wang, Xingbin; Zhao, Boyan; Hou, Rui; Meng, Dan] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.
   [Wang, Xingbin] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Awad, Amro] NC State Univ, Raleigh, NC USA.
   [Tian, Zhihong] Guangzhou Univ, Guangzhou, Peoples R China.
RP Hou, R (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.
EM wangxingbin@iie.ac.cn; zhaoboyan@iie.ac.cn; hourui@iie.ac.cn;
   ajawad@ncsu.edu; tianzhihong@gzhu.edu.cn; mengdan@iie.ac.cn
CR Abdelfattah Mohamed S, 2020, ARXIV PREPRINT ARXIV
   Ahn B. H., 2020, P MACHINE LEARNING S, V2, P44
   Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   [Anonymous], 2018, PR MACH LEARN RES
   Azizimazreah A, 2019, INT S HIGH PERF COMP, P94, DOI 10.1109/HPCA.2019.00030
   Baluja S., ARXIV PREPRINT ARXIV
   Berkeley, 2018, PHYS ADV EX DEEP NEU
   Cai H., 2018, ARXIV181200332
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen Pin-Yu, 2017, ARXIV170904114
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WW, 2020, DES AUT TEST EUROPE, P1283, DOI 10.23919/DATE48585.2020.9116474
   Chen X., 2020, ICML
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng M., 2020, ARXIV200206789
   Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027
   Devaguptapu C., 2020, ARXIV PREPRINT ARXIV
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Dong Minjing, 2020, ARXIV200900902
   Dong Yinpeng, 2017, CORR
   Fang Jingzhi, 2020, PROC VLDB ENDOW, V13, P2734, DOI [DOI 10.14778/3407790.3407857, 10.14778/3407790.3407857]
   Gao Ruiqi, 2019, ADV NEURAL INFORM PR, V32
   Goodfellow I. J., 2015, P 3 INT C LEARN REPR, P1
   Guan YJ, 2020, IEEE T COMPUT, V69, P931, DOI 10.1109/TC.2020.2981080
   Guo MH, 2020, PROC CVPR IEEE, P628, DOI 10.1109/CVPR42600.2020.00071
   Gupta Suyog, 2020, ARXIV PREPRINT ARXIV
   Hanlin Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P70, DOI 10.1007/978-3-030-58601-0_5
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P933, DOI [10.1109/MICR0.2018.00080, 10.1109/MICRO.2018.00080]
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Hu X., SYSTEMATIC VIEW LEAK, P2021
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia Z., 2019, P 2 C SYST MACH LEAR
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaidi Xu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P665, DOI 10.1007/978-3-030-58558-7_39
   Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058
   Kotyan Shashank, 2020, GECCO'20. Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion, P135, DOI 10.1145/3377929.3389962
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, P INT C LEARN REPR
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lei Yang, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P85, DOI 10.1109/ASP-DAC47756.2020.9045595
   Li Bai, 2020, ARXIV200603089
   Li J, 2018, PROCEEDINGS OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '18), P229, DOI 10.1145/3184407.3184410
   Lin XH, 2018, DES AUT CON, DOI 10.1145/3195970.3196067
   Lym Sangkug, 2020, ARXIV PREPRINT ARXIV
   Madry A., 2018, INT C LEARNING REPRE
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Nandy J, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207312
   NVIDIA, 2018, HARDW ARCH SPEC
   Qiu H., 2019, ARXIV190408270
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Sah Sudhakar, 2014, 2014 IEEE/ACIS 13th International Conference on Computer and Information Science (ICIS), P337, DOI 10.1109/ICIS.2014.6912156
   Samajdar Ananda, 2018, SCALE SIM SYSTOLIC C
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sharma H, 2016, INT SYMP MICROARCH
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tsai T, 2020, AAAI CONF ARTIF INTE, V34, P954
   Vargas D. V., 2019, CORR
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang XB, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P19, DOI 10.1145/3373376.3378532
   Wei XC, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317875
   Wu D., 2020, ARXIV PREPRINT ARXIV
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang, 2018, ARXIV181005206
   Yang C., 2020, ECCV
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yiming Gan, 2020, 2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P241, DOI 10.1109/MICRO50266.2020.00031
   Yin D, 2019, PR MACH LEARN RES, V97
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Zela Arber, 2019, ARXIV190909656
   Zhong Y., 2020, ARXIV PREPRINT ARXIV
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 84
TC 0
Z9 0
U1 0
U2 6
PY 2021
BP 776
EP 789
DI 10.1109/ISCA52012.2021.00066
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Gui, CY
   Zheng, L
   He, BS
   Liu, C
   Chen, XY
   Liao, XF
   Jin, H
AF Gui, Chuang-Yi
   Zheng, Long
   He, Bingsheng
   Liu, Cheng
   Chen, Xin-Yu
   Liao, Xiao-Fei
   Jin, Hai
TI A Survey on Graph Processing Accelerators: Challenges and Opportunities
SO JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY
DT Article
DE graph processing accelerator; domain-specific architecture; performance;
   energy efficiency
ID ANALYTICS; FRAMEWORK; SYSTEM; EFFICIENT; DESIGN
AB Graph is a well known data structure to represent the associated relationships in a variety of applications, e.g., data science and machine learning. Despite a wealth of existing efforts on developing graph processing systems for improving the performance and/or energy efficiency on traditional architectures, dedicated hardware solutions, also referred to as graph processing accelerators, are essential and emerging to provide the benefits significantly beyond what those pure software solutions can offer. In this paper, we conduct a systematical survey regarding the design and implementation of graph processing accelerators. Specifically, we review the relevant techniques in three core components toward a graph processing accelerator: preprocessing, parallel graph computation, and runtime scheduling. We also examine the benchmarks and results in existing studies for evaluating a graph processing accelerator. Interestingly, we find that there is not an absolute winner for all three aspects in graph acceleration due to the diverse characteristics of graph processing and the complexity of hardware configurations. We finally present and discuss several challenges in details, and further explore the opportunities for the future research.
C1 [Gui, Chuang-Yi; Zheng, Long; Liao, Xiao-Fei; Jin, Hai] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Wuhan 430074, Hubei, Peoples R China.
   [Gui, Chuang-Yi; Zheng, Long; Liao, Xiao-Fei; Jin, Hai] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Wuhan 430074, Hubei, Peoples R China.
   [Gui, Chuang-Yi; Zheng, Long; Liao, Xiao-Fei; Jin, Hai] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Cluster & Grid Comp Lab, Wuhan 430074, Hubei, Peoples R China.
   [He, Bingsheng; Liu, Cheng; Chen, Xin-Yu] Natl Univ Singapore, Sch Comp, Singapore 117418, Singapore.
   [Liu, Cheng] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
RP Zheng, L (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Wuhan 430074, Hubei, Peoples R China.; Zheng, L (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Wuhan 430074, Hubei, Peoples R China.; Zheng, L (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Cluster & Grid Comp Lab, Wuhan 430074, Hubei, Peoples R China.
EM chygui@hust.edu.cn; longzh@hust.edu.cn; hebs@comp.nus.edu.sg;
   liucheng@ict.ac.cn; xinyuc@comp.nus.edu.sg; xfliao@hust.edu.cn;
   hjin@hust.edu.cn
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], 2013, ARXIV13123018
   [Anonymous], 2008, DESIGNERS GUIDE VHDL
   [Anonymous], 2013, P 6 WORKSHOP GEN PUR, DOI DOI 10.1145/2458523.2458531
   Attia OG, 2015, P 2015 INT C REC COM
   Attia OG, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P228, DOI 10.1109/IPDPSW.2014.30
   Avery Ching, 2011, P HADOOP SUMMIT SANT, V11, P5
   Ayupov A, 2018, IEEE T COMPUT AID D, V37, P420, DOI 10.1109/TCAD.2017.2706562
   Battaglia P. W., 2018, ARXIV PREPRINT ARXIV
   Beamer S., 2015, ARXIV150803619
   Beamer S, 2012, INT CONF HIGH PERFOR
   Beamer S, 2015, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2015.12
   Ben-Nun T, 2017, ACM SIGPLAN NOTICES, V52, P235, DOI [10.1145/3155284.3018756, 10.1145/3018743.3018756]
   Betkaoui B., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P99, DOI 10.1109/FPL.2012.6339247
   Betkaoui B, 2011, P 2011 INT C FIELD P
   Betkaoui B, 2012, IEEE INT CONF ASAP, P8, DOI 10.1109/ASAP.2012.30
   Caulfield AM, 2016, INT SYMP MICROARCH
   Ceze L, 2017, ARXIV170608597
   Chen C, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-0050-9
   Chen R, 2018, ACM TRANS PARALLEL C, V5, DOI 10.1145/3298989
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chi YZ, 2016, PROC INT CONF DATA, P409, DOI 10.1109/ICDE.2016.7498258
   Dai GH, 2019, IEEE T COMPUT AID D, V38, P640, DOI 10.1109/TCAD.2018.2821565
   Dai GH, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P217, DOI 10.1145/3020078.3021739
   Dai GH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P105, DOI 10.1145/2847263.2847339
   Davidson A, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.45
   deLorimier M, 2006, ANN IEEE SYM FIELD P, P143
   Do Jaeyoung, 2013, P 2013 ACM SIGMOD IN, P1221
   Engelhardt N, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577360
   Faloutsos M, 1999, COMP COMM R, V29, P251, DOI 10.1145/316194.316229
   Fu Zhisong, 2014, P WORKSH GRAPH DAT M, P1, DOI DOI 10.1145/2621934.2621936
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Gonzalez Joseph E, 2012, 10 USENIX S OP SYST, P17, DOI DOI 10.1145/74850.74870
   Gonzalez Joseph E, 2014, P 11 USENIX S OPERAT, P599
   Gu B, 2016, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA.2016.23
   Ham TJ, 2016, INT SYMP MICROARCH
   Han L, 2018, ACM T STORAGE, V14, DOI 10.1145/3177916
   Han L, 2017, IEEE NON-VOLATILE ME
   Han WS, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P77
   Heidari S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3199523
   Hennessy J, 2017, COMPUTER ARCHITECTUR, P540
   Hong S, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P349
   Huang TH, 2018, DES AUT TEST EUROPE, P973, DOI 10.23919/DATE.2018.8342150
   Jin H, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9226-8
   Jin H, 2017, INT CON DISTR COMP S, P1981, DOI 10.1109/ICDCS.2017.150
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jun SW, 2018, CONF PROC INT SYMP C, P411, DOI 10.1109/ISCA.2018.00042
   Jun SW, 2015, I C FIELD PROG LOGIC
   Junghoon Kim, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P19, DOI 10.1109/ICCE.2014.6775890
   Kapre N, 2015, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2015.7245698
   Khayyat Zuhair, 2013, P 8 ACM EUR C COMP S, P169, DOI DOI 10.1145/2465351.2465369
   Khoram S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P239, DOI 10.1145/3174243.3174260
   Khorasani Farzad, 2014, P 23 INT S HIGH PERF, P239, DOI DOI 10.1145/2600212.2600227
   Kim G, 2013, INT CONFER PARA, P145, DOI 10.1109/PACT.2013.6618812
   Kim MS, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P447, DOI 10.1145/2882903.2915204
   Kyrola Aapo, 2012, OSDI, P31
   Lee J, 2017, PROC VLDB ENDOW, V10, P1706, DOI 10.14778/3137765.3137776
   Lee Y, 2016, IEEE MICRO, V36, P8, DOI 10.1109/MM.2016.11
   Li ZS, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P575, DOI 10.1145/3079856.3080228
   Liu H, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P403, DOI 10.1145/2882903.2882959
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Ma XY, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P227, DOI 10.1145/3020078.3021743
   Maass S, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P527, DOI 10.1145/3064176.3064191
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167, DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184]
   Malicevic J, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P631
   Matsumoto K, 2011, IEEE INT CONF EMBED, P16, DOI 10.1109/RTCSA.2011.77
   McCune RR, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2818185
   McLaughlin A, 2014, INT CONF HIGH PERFOR, P572, DOI 10.1109/SC.2014.52
   Milenkovic T, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-70
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nai LF, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807626
   Narayanan Annamalai, 2017, ARXIV170705005
   Nguyen D, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P456, DOI 10.1145/2517349.2522739
   Nurvitadhi E, 2014, ANN IEEE SYM FIELD P, P25, DOI 10.1109/FCCM.2014.15
   Oguntebi T, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P111, DOI 10.1145/2847263.2847337
   Ozdal MM, 2018, IEEE DES TEST, V35, P47, DOI 10.1109/MDAT.2017.2779742
   Ozdal MM, 2017, IEEE MICRO, V37, P42, DOI 10.1109/MM.2017.7
   Ozdal MM, 2016, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2016.24
   Ozdal MM, 2015, ICCAD-IEEE ACM INT, P676, DOI 10.1109/ICCAD.2015.7372635
   Page L, 1999, TECHNICAL REPORT
   Pawlowski JT., 2011, P 23 IEEE HOT CHIPS
   Qingbo Wang, 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P70, DOI 10.1109/FPT.2010.5681757
   Randles Martin, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P551, DOI 10.1109/WAINA.2010.85
   Ribeiro LFR, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P385, DOI 10.1145/3097983.3098061
   Rodeh Ohad, 2008, ACM Transaction on Storage, V3, p15:1, DOI 10.1145/1326542.1326544
   Roy A, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P472, DOI 10.1145/2517349.2522740
   Satish N, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P979, DOI 10.1145/2588555.2610518
   Scarpazza DP, 2008, IEEE T PARALL DISTR, V19, P1381, DOI 10.1109/TPDS.2007.70811
   Sengupta D, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807655
   Seo H, 2015, ACM SIGPLAN NOTICES, V50, P253, DOI [10.1145/2858788.2688526, 10.1145/2688500.2688526]
   Sha M, 2017, PROC VLDB ENDOW, V11, P107, DOI 10.14778/3151113.3151122
   SHI X, 2018, TKDE, V30, P29, DOI DOI 10.1109/TKDE.2017.2745562
   Shi XG, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P417, DOI 10.1145/2882903.2882950
   Shi XH, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3128571
   Shun JL, 2013, ACM SIGPLAN NOTICES, V48, P135, DOI 10.1145/2517327.2442530
   Siek J. G., 2001, BOOST GRAPH LIB USER
   Soman J, 2010, P 24 IEEE INT S PAR
   Son Y, 2017, PROC INT CONF DATA, P285, DOI 10.1109/ICDE.2017.88
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song WS, 2016, IEEE HIGH PERF EXTR
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Sungpack Hong, 2011, Proceedings 2011 International Conference on Parallel Architectures and Compilation Techniques (PACT), P78, DOI 10.1109/PACT.2011.14
   Teixeira CHC, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P425, DOI 10.1145/2815400.2815410
   Thomas Donald., 2002, VERILOG HARDWARE DES, VEdition Number 5, DOI 10.1007/978-0-387-85344-4
   Umuroglu Y, 2015, I C FIELD PROG LOGIC
   Wang L, 2013, CHINESE CHEM LETT, V24, P351, DOI 10.1016/j.cclet.2013.03.018
   Wang P, 2014, I C DEPEND SYS NETWO, P562, DOI 10.1109/DSN.2014.58
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Weisz G, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P264, DOI 10.1145/2847263.2847269
   Windh S, 2015, ICCAD-IEEE ACM INT, P331, DOI 10.1109/ICCAD.2015.7372588
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Xie CN, 2015, ACM SIGPLAN NOTICES, V50, P194, DOI [10.1145/2858788.2688508, 10.1145/2688500.2688508]
   Xu C, 2015, INT S HIGH PERF COMP, P476, DOI 10.1109/HPCA.2015.7056056
   Yao PC, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243201
   Yuan PP, 2014, INT CONF HIGH PERFOR, P401, DOI 10.1109/SC.2014.38
   Zhang JL, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P229, DOI 10.1145/3174243.3174245
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P207, DOI 10.1145/3020078.3021737
   Zhang JX, 2018, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION ENGINEERING (RAE 2018) AND INTERNATIONAL CONFERENCE ON ADVANCED MECHANICAL AND ELECTRICAL ENGINEERING (AMEE 2018), P15, DOI 10.1145/3303714.3303742
   Zhang KY, 2015, ACM SIGPLAN NOTICES, V50, P183, DOI [10.1145/2688500.2688507, 10.1145/2858788.2688507]
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhang MX, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P285
   Zhang T, 2015, J SUPERCOMPUT, V71, P1563, DOI 10.1007/s11227-015-1378-z
   Zhao Y, 2014, IEEE INT CONGR BIG, P717, DOI 10.1109/BigData.Congress.2014.106
   Zheng Da, 2015, P 13 USENIX C FIL ST, P45
   Zheng L, 2018, INT SYM CODE GENER, P188, DOI 10.1145/3168817
   Zheng L, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3170434
   Zhong JL, 2014, SIGMOD REC, V43, P35
   Zhou JH, 2017, IEEE ACM INT SYMP, P731, DOI 10.1109/CCGRID.2017.114
   Zhou SJ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P259, DOI 10.1145/3174243.3174252
   Zhou SJ, 2017, INT SYM COMP ARCHIT, P137, DOI 10.1109/SBAC-PAD.2017.25
   Zhou SJ, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P129, DOI 10.1109/IPDPSW.2015.130
   Zhou SJ, 2016, ANN IEEE SYM FIELD P, P103, DOI 10.1109/FCCM.2016.35
   Zhou SJ, 2015, PROC INT CONF RECON
   Zhu XW, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P301
   Zhu Xiaowei, 2015, USENIX ANN TECHN C, P375
   Zhu ZM, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2424402
NR 136
TC 32
Z9 38
U1 4
U2 30
PD APR
PY 2019
VL 34
IS 2
BP 339
EP 371
DI 10.1007/s11390-019-1914-z
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Zha, Y
   Nowak, E
   Li, J
AF Zha, Yue
   Nowak, Etienne
   Li, Jing
GP IEEE
TI Liquid Silicon: A Nonvolatile Fully Programmable Processing -In -Memory
   Processor with Monolithically Integrated Re' M for Big Data/Machine
   Learning Applications
SO 2019 SYMPOSIUM ON VLSI CIRCUITS
SE Symposium on VLSI Circuits-Digest of Papers
DT Proceedings Paper
CT 39th Symposium on VLSI Technology / 33rd Symposium on VLSI Circuits
CY JUN 09-14, 2019
CL Kyoto, JAPAN
AB A nonvolatile fully programmable processing -in -memory (PIM) processor named Liquid Silicon (L-Si) is demonstrated, which combines the superior programmability of general-purpose cornputing devices (e.g. FPGA) and the high power efficiency of domain -specific accelerators. Besides the general computing applications, L-Si is particularly well suited for AI/machine learning and big data applications, which not only pose high computational/memory demand but also evolves rapidly. L -Si is fabricated by monolithically integrating H10, resistive RAM on top of commercial 130nm Si CMOS. Our measurement confirmed the fabricated chip operates reliably at low voltage of 650 mV. It achieves 60.9 TOPS/W in performing neural network inferences and 480 GOPS/W in performing content -based similarity search (a key big data application) at nominal voltage supply of 1.2V, showing >3x and 100x power efficiency improvement over the state-of-the-art domain -specific CMOS-/RRAM-based accelerators. In addition, it outperforms the latest nonvolatile FPGA in energy efficiency by 3x in general compute -intensive applications.
C1 [Zha, Yue; Li, Jing] Univ Wisconsin, Madison, WI 53706 USA.
   [Nowak, Etienne] CEA, LETI, Minatec Campus, Grenoble, France.
RP Zha, Y (corresponding author), Univ Wisconsin, Madison, WI 53706 USA.
CR [Anonymous], 2016, ICCAD
   Grossi A., 2016, IEDM
   Li J., 2014, JSSC
   Suzuki D., 2015, VLSIT
   Yin S., 2018, VLSI
NR 5
TC 8
Z9 8
U1 0
U2 2
PY 2019
BP C206
EP C207
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Taj, I
   Farooq, U
AF Taj, Imran
   Farooq, Umer
TI Towards Machine Learning-Based FPGA Backend Flow: Challenges and
   Opportunities
SO ELECTRONICS
DT Article
DE FPGA backend flow; machine learning; CAD design steps; synthesis;
   placement; routing
ID SPACE EXPLORATION; PLACEMENT; ALGORITHM; GRAPH
AB Field-Programmable Gate Array (FPGA) is at the core of System on Chip (SoC) design across various Industry 5.0 digital systems-healthcare devices, farming equipment, autonomous vehicles and aerospace gear to name a few. Given that pre-silicon verification using Computer Aided Design (CAD) accounts for about 70% of the time and money spent on the design of modern digital systems, this paper summarizes the machine learning (ML)-oriented efforts in different FPGA CAD design steps. With the recent breakthrough of machine learning, FPGA CAD tasks-high-level synthesis (HLS), logic synthesis, placement and routing-are seeing a renewed interest in their respective decision-making steps. We focus on machine learning-based CAD tasks to suggest some pertinent research areas requiring more focus in CAD design. The development of open-source benchmarks optimized for an end-to-end machine learning experience, intra-FPGA optimization, domain-specific accelerators, lack of explainability and federated learning are the issues reviewed to identify important research spots requiring significant focus. The potential of the new cloud-based architectures to understand the application of the right ML algorithms in FPGA CAD decision-making steps is discussed, together with visualizing the scenario of incorporating more intelligence in the cloud platform, with the help of relatively newer technologies such as CAD as Adaptive OpenPlatform Service (CAOS). Altogether, this research explores several research opportunities linked with modern FPGA CAD flow design, which will serve as a single point of reference for modern FPGA CAD flow design.
C1 [Taj, Imran] Zayed Univ, Coll Interdisciplinary Studies, POB 144534, Abu Dhabi, U Arab Emirates.
   [Farooq, Umer] Univ Sunderland, Sch Engn, Sunderland SR6 0DD, England.
RP Farooq, U (corresponding author), Univ Sunderland, Sch Engn, Sunderland SR6 0DD, England.
EM umer.farooq@sunderland.ac.uk
CR Ababei C, 2005, IEEE DES TEST COMPUT, V22, P520, DOI 10.1109/MDT.2005.150
   Accelerator N., 2022, US
   Al-Hyari A., 2017, J COMPUT VIS IMAGING, V3, DOI [10.15353/vsnl.v3i1.162, DOI 10.15353/VSNL.V3I1.162]
   Al-Hyari A, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3337930
   ALHYARI A, 2021, I C FIELD PROG LOGIC, V14, P1, DOI DOI 10.1145/3465373
   Alibaba, 2022, US
   [Anonymous], US
   [Anonymous], 2004, P INT S PHYS DESIGN
   [Anonymous], 2022, EC2
   Arora Aman, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P23, DOI 10.1145/3431920.3439282
   Baig I, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142240
   Betz V., 1997, Field-programmable Logic and Applications. 7th International Workshop, FPL '97. Proceedings, P213
   Boutros A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P10, DOI 10.1109/ICFPT51103.2020.00011
   Brayton R. K., 1982, 1982 International Symposium on Circuits and Systems, P49
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BUI TN, 1987, COMBINATORICA, V7, P171, DOI 10.1007/BF02579448
   Chan WTJ, 2016, PR IEEE COMP DESIGN, P41, DOI 10.1109/ICCD.2016.7753259
   CHAVEZ J, 1994, 1994 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 1, pA367
   Chen SC, 2017, ICCAD-IEEE ACM INT, P914, DOI 10.1109/ICCAD.2017.8203878
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chhabria Vidya A., 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P44, DOI 10.1109/ASP-DAC47756.2020.9045303
   Chtourou S, 2017, 2017 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P572, DOI 10.1109/HPCS.2017.91
   Cong J., 1995, FPGA '95. 1995 ACM Third International Symposium on Field-Programmable Gate Arrays, P68, DOI 10.1145/201310.201322
   CONG J, 1994, IEEE T COMPUT AID D, V13, P1, DOI 10.1109/43.273754
   Cong J, 2000, ACM T DES AUTOMAT EL, V5, P193, DOI 10.1145/335043.335045
   CONG J, 1993, ACM IEEE D, P213
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Ding D, 2011, DES AUT CON, P795
   Doran D., 2017, ARXIV
   Elgammal MA, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P85, DOI 10.1109/ICFPT51103.2020.00021
   Farahmand F, 2017, PROC INT CONF RECON
   Farooq U, 2021, INT CONF INFORM COMM, P106, DOI 10.1109/ICICS52457.2021.9464626
   Farooq U, 2020, COMPUTING, V102, P2361, DOI 10.1007/s00607-020-00834-5
   Farooq U, 2018, MICROPROCESS MICROSY, V56, P169, DOI 10.1016/j.micpro.2017.12.006
   Feiyu Xu, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P563, DOI 10.1007/978-3-030-32236-6_51
   Fiduccia C., 1982, P 19 DES AUT C JUN, P175, DOI DOI 10.1109/DAC.1982.1585498
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Goswami P, 2022, 2022 IEEE 13TH LATIN AMERICAN SYMPOSIUM ON CIRCUITS AND SYSTEMS (LASCAS), P176, DOI 10.1109/LASCAS53948.2022.9789084
   Goswami P, 2023, INTEGRATION, V88, P116, DOI 10.1016/j.vlsi.2022.09.006
   He YW, 2022, IEEE INT ULTRA SYM, DOI 10.1109/IUS54386.2022.9957431
   Interacoustics, 2022, US
   Jain S.R., 2017, ARXIV
   Khadilkar S., 2022, P 2022 IEEE HIGH PER, P1
   Kim RG, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243483
   KLEINHANS JM, 1991, IEEE T COMPUT AID D, V10, P356, DOI 10.1109/43.67789
   Koeplinger D, 2016, CONF PROC INT SYMP C, P115, DOI 10.1109/ISCA.2016.20
   LIAO H, 2020, J MECH DES-T ASME, V142, DOI DOI 10.48550/ARXIV.1906.08809
   Liu D, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577370
   Lou J., 2001, Proceedings of ISPD'01. 2001 International Symposium on Physical Design, P112, DOI 10.1145/369691.369749
   Ludwin A, 2008, FPGA 2008: SIXTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P14
   Ma YZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317838
   Maarouf D, 2018, I C FIELD PROG LOGIC, P427, DOI 10.1109/FPL.2018.00079
   Mahapatra A., 2014, P 2014 EL SYST LEV S, P1, DOI DOI 10.1109/ESLSYN.2014.6850383
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   Marquardt A., 2000, FPGA'00. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P203, DOI 10.1145/329166.329208
   Marquardt A., 1999, FPGA'99. AGM/SIGDA International Symposium on Field Programmable Gate Arrays, P37, DOI 10.1145/296399.296426
   Martin T., 2021, 2021 ACMIEEE 3 WORKS, P1
   Matsuba Teruki, 2018, 2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS), P131, DOI 10.1109/ISPACS.2018.8923544
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   McMurchie L., 1995, FPGA '95. 1995 ACM Third International Symposium on Field-Programmable Gate Arrays, P111, DOI 10.1145/201310.201328
   microresist, 2022, US
   Minh D, 2022, ARTIF INTELL REV, V55, P3503, DOI 10.1007/s10462-021-10088-y
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Murray KE, 2015, ACM T RECONFIG TECHN, V8, DOI 10.1145/2629579
   Platforms X.V., 2022, US
   Pui CW, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2980084
   Pui CW, 2017, ICCAD-IEEE ACM INT, P929, DOI 10.1109/ICCAD.2017.8203880
   Qi ZD, 2014, PR IEEE COMP DESIGN, P97, DOI 10.1109/ICCD.2014.6974668
   Que YH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P169, DOI 10.1145/2847263.2847336
   Que YH, 2016, ANN IEEE SYM FIELD P, P80, DOI 10.1109/FCCM.2016.28
   Rabozzi M., 2019, IFIP ADV INF COMM TE, DOI [10.1007/978-3-030-32094-2_8, DOI 10.1007/978-3-030-32094-2_8]
   de Bulnes DRF, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/7095048
   Roorda Esther, 2022, ACM T RECONFIG TECHN, V15, P1
   Schafer BC, 2020, IEEE T COMPUT AID D, V39, P2628, DOI 10.1109/TCAD.2019.2943570
   Shah D, 2019, ANNU IEEE IND CONF, DOI [10.1109/indicon47234.2019.9029064, 10.1109/FCCM.2019.00010]
   Siozios K, 2008, INT J RECONFIGURABLE, V2008, DOI 10.1155/2008/764942
   Stratix, 2022, US
   Swartz J. S., 1998, FPGA'98. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P140, DOI 10.1145/275107.275134
   Taj I., 2022, INT J COMPUT DIGIT S, V12, P295, DOI [10.12785/ijcds/120128, DOI 10.12785/IJCDS/120128]
   Tang YM, 2022, IRAN J FUZZY SYST, V19, P27
   Ustun E, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415657
   Utyamishev Dmitry, 2020, 57 ACMIEEE DESIGN AU, P1
   Vorwerk K, 2009, IEEE T COMPUT AID D, V28, P179, DOI 10.1109/TCAD.2008.2009167
   Wang H-W, 2018, ARXIV
   Wang Z., 2020, 2020 IEEE 91 VEHICUL, P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9128938
   Wang Z, 2022, ACM T DES AUTOMAT EL, V27, DOI 10.1145/3495531
   Ward S, 2012, DES AUT CON, P756
   Xu C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P157, DOI 10.1145/3020078.3021747
   Yang HY, 2017, J MICRO-NANOLITH MEM, V16, DOI 10.1117/1.JMM.16.3.033504
   Yang S, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'16), P139, DOI 10.1145/2872334.2886419
   Yang Z., 2020, ARXIV
   Zhang YX, 2019, IEEE T FUZZY SYST, V27, P185, DOI 10.1109/TFUZZ.2018.2883033
   Zhang ZM, 2019, IEEE T VLSI SYST, V27, P665, DOI 10.1109/TVLSI.2018.2879878
   Zhou Q, 2015, PROCEEDINGS OF THE SIXTH ASIA SYMPOSIUM ON QUALITY ELECTRONIC DESIGN ASQED 2015, P119, DOI 10.1109/ACQED.2015.7274019
   Zhuo C, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P227, DOI 10.1109/SOCC.2017.8226046
NR 95
TC 0
Z9 0
U1 10
U2 13
PD FEB
PY 2023
VL 12
IS 4
AR 935
DI 10.3390/electronics12040935
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Hsiao, PY
   Lin, SY
   Chen, CY
AF Hsiao, Pei-Yung
   Lin, Shih-Yu
   Chen, Chuen-Yau
GP IEEE
TI A Real-Time FPGA Based Human Detector
SO 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C)
DT Proceedings Paper
CT 3rd International Symposium on Computer, Consumer and Control (IS3C)
CY JUL 04-06, 2016
CL Natl Chin Yi Univ Technol, Xian, PEOPLES R CHINA
HO Natl Chin Yi Univ Technol
DE HOG; FPGA Accelerator; Machine Learning; Human Detection; Real-Time
   Embedded System
ID HOG FEATURE-EXTRACTION; HARDWARE; DESIGN; SYSTEM
AB An ARM-platform and FPGA-based accelerator rather than PC-based system is utilized in this study for completing a real-time FPGA-based human detector. The system presents the advantages of small size, low cost, high computing speed, and being portable and could be built in small cameras for surveillance applications. When background segmentation is introduced, the computing efficiency could reach about 15 fps. Moreover, this study has proven that the reduction on the total detection rate is less than 0.3% while changing HOG algorithm into the presented FPGA hardware implementation.
C1 [Hsiao, Pei-Yung; Lin, Shih-Yu; Chen, Chuen-Yau] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
RP Hsiao, PY (corresponding author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
EM pyhsiao@nuk.edu.tw
CR [Anonymous], 2009, INTELLIGENT INFORM H, DOI [10.1109/IIH-MSP.2009.216, DOI 10.1109/IIH-MSP.2009.216]
   [Anonymous], WORKSH SYNTH SYST IN
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chai ZL, 2014, MICROPROCESS MICROSY, V38, P458, DOI 10.1016/j.micpro.2014.03.011
   Chen PY, 2014, IEEE T INTELL TRANSP, V15, P656, DOI 10.1109/TITS.2013.2284666
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding Z, 2012, MICROPROCESS MICROSY, V36, P315, DOI 10.1016/j.micpro.2012.01.002
   Garcia-Bunster G, 2012, IET COMPUT VIS, V6, P296, DOI 10.1049/iet-cvi.2011.0138
   Genovese M, 2013, J REAL-TIME IMAGE PR, V8, P389, DOI 10.1007/s11554-011-0238-1
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gu QY, 2013, IEEE T CIRC SYST VID, V23, P30, DOI 10.1109/TCSVT.2012.2202195
   Gultekin GK, 2013, MICROPROCESS MICROSY, V37, P270, DOI 10.1016/j.micpro.2013.01.001
   Hemmati M, 2014, 2014 17TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P543, DOI 10.1109/DSD.2014.60
   Hsiao PY, 2006, IEE P-COMPUT DIG T, V153, P261, DOI 10.1049/ip-cdt:20050199
   Hsiao PY, 2009, IEEE T VEH TECHNOL, V58, P2089, DOI 10.1109/TVT.2008.2006618
   Jain-Mendon S, 2014, MICROPROCESS MICROSY, V38, P873, DOI 10.1016/j.micpro.2014.02.004
   Mizuno K, 2012, IEEE WORKSHOP SIG, P197, DOI 10.1109/SiPS.2012.57
   Shende A, 2011, IEEE T INTELL TRANSP, V12, P1167, DOI 10.1109/TITS.2011.2146251
   Shih-Li Lin, 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7356113
   Suleiman A, 2014, IEEE WRK SIG PRO SYS, P256
   Takagi K, 2013, INT CONF ACOUST SPEE, P2533, DOI 10.1109/ICASSP.2013.6638112
   Wang JH, 2014, IEEE T CIRC SYST VID, V24, P525, DOI 10.1109/TCSVT.2013.2280040
   Zhang GH, 2011, IEEE T INTELL TRANSP, V12, P164, DOI 10.1109/TITS.2010.2070795
   Zhu Q., 2006, IEEE COMP SOC C COMP, V2, P1491, DOI DOI 10.1109/CVPR.2006.119
NR 24
TC 12
Z9 12
U1 0
U2 1
PY 2016
BP 1014
EP 1017
DI 10.1109/IS3C.2016.256
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Liu, YT
   Kung, C
   Hsieh, MH
   Wang, HW
   Lin, CP
   Yu, CY
   Chen, CS
   Chiueh, TD
AF Liu, Yu-Tung
   Kung, ChuKing
   Hsieh, Ming-Hang
   Wang, Hsiu-Wen
   Lin, Chun-Pin
   Yu, Chao-Yang
   Chen, Chi-Shi
   Chiueh, Tzi-Dar
GP IEEE
TI A 1.625 TOPS/W SOC for Deep CNN Training and Inference in 28nm CMOS
SO IEEE 51ST EUROPEAN SOLID-STATE DEVICE RESEARCH CONFERENCE (ESSDERC 2021)
SE Proceedings of the European Solid-State Device Research Conference
DT Proceedings Paper
CT IEEE 51st European Solid-State Device Research Conference (ESSDERC)
CY SEP 06-09, 2021
CL ELECTR NETWORK
DE machine learning; low-precision neural network; SOC; AI accelerator
ID ACCELERATOR
AB This work presents a FloatSD8-based system on chip (SOC) for the inference as well as the training of a convolutional neural networks (CNNs). A novel number format (FloatSD8) is employed to reduce the computational complexity of the convolution circuit. By co-designing data representation and circuit, we demonstrate that the AISOC can achieve high convolution performance and optimal energy efficiency without sacrificing the quality of training. At its normal operating condition (200MHz), the AISOC prototype is capable of 0.69 TFLOPS peak performance and 1.625 TOPS/W in 28nm CMOS.
C1 [Liu, Yu-Tung; Kung, ChuKing; Hsieh, Ming-Hang; Chiueh, Tzi-Dar] Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
   [Wang, Hsiu-Wen; Lin, Chun-Pin; Yu, Chao-Yang; Chen, Chi-Shi] Taiwan Semicond Res Inst, Hsinchu, Taiwan.
RP Liu, YT (corresponding author), Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
CR Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choi S, 2020, IEEE J SOLID-ST CIRC, V55, P2691, DOI 10.1109/JSSC.2020.3005786
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Lin PC, 2019, IEEE J EM SEL TOP C, V9, P267, DOI 10.1109/JETCAS.2019.2911999
   Lu CH, 2019, IEEE ASIAN SOLID STA, P65, DOI [10.1109/a-sscc47793.2019.9056967, 10.1109/A-SSCC47793.2019.9056967]
   Wang Naigang, 2018, ARXIV181208011, P7686
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Zhao WL, 2016, IEEE INT CONF ASAP, P107, DOI 10.1109/ASAP.2016.7760779
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 107
EP 110
DI 10.1109/ESSDERC53440.2021.9631821
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Liu, YT
   Kung, CK
   Hsieh, MH
   Wang, HW
   Lin, CP
   Yu, CY
   Chen, CS
   Chiueh, TD
AF Yu-Tung Liu
   Kung, ChuKing
   Ming-Hang Hsieh
   Hsiu-Wen Wang
   Chun-Pin Lin
   Chao-Yang Yu
   Chi-Shi Chen
   Tzi-Dar Chiueh
GP IEEE
TI A 1.625 TOPS/W SOC for Deep CNN Training and Inference in 28nm CMOS
SO ESSCIRC 2021 - IEEE 47TH EUROPEAN SOLID STATE CIRCUITS CONFERENCE
   (ESSCIRC)
SE Proceedings of the European Solid-State Circuits Conference
DT Proceedings Paper
CT 47th IEEE European Solid State Circuits Conference (ESSCIRC)
CY SEP 06-09, 2021
CL ELECTR NETWORK
DE machine learning; low-precision neural network; SOC; AI accelerator
ID ACCELERATOR
AB This work presents a FloatSD8-based system on chip (SOC) for the inference as well as the training of a convolutional neural networks (CNNs). A novel number format (FloatSD8) is employed to reduce the computational complexity of the convolution circuit. By co-designing data representation and circuit, we demonstrate that the AISOC can achieve high convolution performance and optimal energy efficiency without sacrificing the quality of training. At its normal operating condition (200MHz), the AISOC prototype is capable of 0.69 TFLOPS peak performance and 1.625 TOPS/W in 28nm CMOS.
C1 [Yu-Tung Liu; Kung, ChuKing; Ming-Hang Hsieh; Tzi-Dar Chiueh] Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
   [Hsiu-Wen Wang; Chun-Pin Lin; Chao-Yang Yu; Chi-Shi Chen] Taiwan Semicond Res Inst, Hsinchu, Taiwan.
RP Liu, YT (corresponding author), Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Choi S, 2020, IEEE J SOLID-ST CIRC, V55, P2691, DOI 10.1109/JSSC.2020.3005786
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Lin PC, 2019, IEEE J EM SEL TOP C, V9, P267, DOI 10.1109/JETCAS.2019.2911999
   Lu CH, 2019, IEEE ASIAN SOLID STA, P65, DOI [10.1109/a-sscc47793.2019.9056967, 10.1109/A-SSCC47793.2019.9056967]
   Wang Naigang, 2018, ARXIV181208011, P7686
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Zhao WL, 2016, IEEE INT CONF ASAP, P107, DOI 10.1109/ASAP.2016.7760779
NR 11
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 107
EP 110
DI 10.1109/ESSCIRC53450.2021.9567756
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yang, Y
   Kuppannagari, SR
   Kannan, R
   Prasanna, VK
AF Yang, Yang
   Kuppannagari, Sanmukh R.
   Kannan, Rajgopal
   Prasanna, Viktor K.
GP IEEE
TI Bandwidth Efficient Homomorphic Encrypted Matrix Vector Multiplication
   Accelerator on FPGA
SO 2022 21ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY
   (ICFPT 2022)
DT Proceedings Paper
CT 21st International Conference on Field-Programmable Technology (ICFPT)
CY DEC 05-09, 2022
CL Hong Kong Univ Sci & Technol, Hong Kong, HONG KONG
HO Hong Kong Univ Sci & Technol
DE FPGA acceleration; homomorphic encryption; matrix vector multiplication;
   parallel computing
AB Homomorphic Encryption (HE) is a promising solution to the increasing concerns of privacy in Machine Learning (ML) as it enables computations directly on encrypted data. However, it imposes significant overhead on the compute system and remains impractically slow. Prior works have proposed efficient FPGA implementations of basic HE primitives such as number theoretic transform (NTT), key switching, etc. Composing the primitives together to realize higher level ML computation is still a challenge due to the large data transfer overhead. In this work, we propose an efficient FPGA implementation of HE Matrix Vector Multiplication (MxV), a key kernel in HE-based Machine Learning applications. By analyzing the data reuse characteristics and the encryption overhead of HE MxV, we show that simply using the principles of unencrypted MxV to design accelerators for HE MxV can lead to a significant amount of DRAM data transfers. We tackle the computation and data transfer challenges by proposing a bandwidth efficient dataflow that is specially optimized for HEMxV. We identify highly reused data entities in HE MxV and efficiently utilize the on-chip SRAM to reduce the DRAM data transfers. To speed up the computation of HE MxV, we exploit three types of parallelism: partial sum parallelism, residual polynomial parallelism and coefficient parallelism. Leveraging these innovations, we demonstrate the first FPGA accelerator for HE matrix vector multiplication. Evaluation on 7 HE MxV benchmarks shows that our FPGA accelerator is up to 3.8x (GeoMean 2.8x) faster compared to the 64-thread CPU implementation.
C1 [Yang, Yang; Prasanna, Viktor K.] Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90089 USA.
   [Kuppannagari, Sanmukh R.] Case Western Reserve Univ, Dept Comp & Data Sci, Cleveland, OH 44106 USA.
   [Kannan, Rajgopal] US Army, Res Lab, DEVCOM, Adelphi, MD USA.
RP Yang, Y (corresponding author), Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90089 USA.
EM yyang172@usc.edu; sanmukh.kuppannagari@case.edu;
   rajgopal.kannan.civ@army.mil; prasanna@usc.edu
CR Albrecht M., 2018, HOMOMORPHIC ENCRYPTI
   [Anonymous], 2020, MICROSOFT SEAL RELEA
   Benaissa A., 2021, TENSEAL LIB ENCRYPTE
   BENES VE, 1964, AT&T TECH J, V43, P1641, DOI 10.1002/j.1538-7305.1964.tb04103.x
   Boemer F, 2019, PROCEEDINGS OF THE 7TH ACM WORKSHOP ON ENCRYPTED COMPUTING & APPLIED HOMOMORPHIC CRYPTOGRAPHY (WAHC'19), P45, DOI 10.1145/3338469.3358944
   Cheon Jung Hee, 2018, Sel Areas Cryptogr, V11349, P347, DOI 10.1007/978-3-030-10970-7_16
   Chou Edward, 2018, ABS181109953 CORR
   Dathathri R, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P546, DOI 10.1145/3385412.3386023
   Dathathri R, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P142, DOI 10.1145/3314221.3314628
   de Castro L., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2112.06396
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Gentry C., 2009, FULLY HOMOMORPHIC EN, V20
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Halevi S, 2014, LECT NOTES COMPUT SC, V8616, P554, DOI 10.1007/978-3-662-44371-2_31
   Han, 2016, 4 INT C LEARNING REP
   Hankerson D.R., 2010, GUIDE ELLIPTIC CURVE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hesamifard E., ANN COMPUTER SECURIT
   Jung W., 2021, IACR T CRYPTOGRAPH H, V2021, P114, DOI DOI 10.46586/TCHES.V2021.I4.114
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Kim S., 2019, 2019 INT C RECONFIGU
   Kim S, 2022, Arxiv, DOI arXiv:2112.15479
   Kim S, 2020, I S WORKL CHAR PROC, P264, DOI 10.1109/IISWC50251.2020.00033
   Mishra P, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2505
   QaisarAhmadAlBadawi A., IEEE T EMERG TOP COM
   Reagen B, 2021, INT S HIGH PERF COMP, P26, DOI 10.1109/HPCA51647.2021.00013
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Ren Chen, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293944
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Roy S. S., 2021, CRYPTOLOGY EPRINT AR
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Samardzic N., 2021, F1 FAST PROGRAMMABLE
   Xilinx, XIL ULTRASCALE FPGAS
   Yang Y, 2022, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2022 (CF 2022), P30, DOI 10.1145/3528416.3530225
   Ye T., 2021, 2021 INT C FIELD PRO
   Ye T, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286219
   Zhai Y., 2021, ARXIV
NR 40
TC 2
Z9 2
U1 1
U2 1
PY 2022
BP 1
EP 9
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, LF
   Wang, Y
AF Zhang Lufei
   Wang Yu
GP IEEE
TI Exploiting Heterogeneity in Grid for Deformable Part Models
SO CONFERENCE PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON
   CONTROL SCIENCE AND SYSTEMS ENGINEERING (ICCSSE)
DT Proceedings Paper
CT 3rd IEEE International Conference on Control Science and Systems
   Engineering (ICCSSE)
CY AUG 17-19, 2017
CL Beijing, PEOPLES R CHINA
DE object detection; deformable part models (DPM); GPU; sunway processor;
   grid computing
AB Deformable part models (DPM) is a typical machine-learning based detection technique. It can achieve great success in detecting accuracy, but have compute-intensive tasks which severely restricts its utilization in many real world applications. In order to get high frame-rate for practical use, accelerators and grid computing infrastructure are needed. This paper propose a grid scheduling scheme which maintain two queues for GPUs and SW processors. The scheme obtain good scalability results through a lot of experiment. The experimental result on single processor node indicates that the parallel implementation on accelerators can achieve speedup up to 3x.
C1 [Zhang Lufei; Wang Yu] Jiangnan Inst Comp Technol, Wuxi, Peoples R China.
RP Zhang, LF (corresponding author), Jiangnan Inst Comp Technol, Wuxi, Peoples R China.
EM zhanglf04@126.com; aswywy@126.com
CR [Anonymous], 2008, P 9 ACM IFIP USENIX
   Arun B P, 2015, SIGN PROC COMM NETW, P1
   BODE B, 2000, P 4 ANN LIN SHOWC C
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elyada A, 2008, IEEE T VLSI SYST, V16, P1243, DOI 10.1109/TVLSI.2008.2000867
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Frey J., 2002, Cluster Computing, V5, P237, DOI 10.1023/A:1015617019423
   Hofmann Johannes, 2014, ARCS 2014 2014WORKSH, P1
   Huedo E, 2004, SOFTWARE PRACT EXPER, V34, P631, DOI 10.1002/spe.584
   Khemka J, 2013, INT C HIGH PERFORM, P396, DOI 10.1109/HiPC.2013.6799121
   Kim KH, 2007, P 7 IEEE INT S CLUST
   Niknejad H., 2000, P IEEE INT VEH S, P766
   NVIDIA, 2017, CUDA DOC
   Salapura V., 2005, P 2 C COMP FRONT ISC
   Shuai Tang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P525, DOI 10.1007/978-3-642-37444-9_41
   Teodoro G, 2012, INT PARALL DISTRIB P, P1093, DOI 10.1109/IPDPS.2012.101
   Venugopal S, 2008, SOFTWARE PRACT EXPER, V38, P793, DOI 10.1002/spe.849
   Wang L., 2008, P 2008 REAL TIM SYST
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
NR 19
TC 0
Z9 0
U1 0
U2 0
PY 2017
BP 587
EP 592
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Cardarilli, GC
   Di Nunzio, L
   Fazzolari, R
   Giardino, D
   Matta, M
   Nannarelli, A
   Re, M
   Spanò, S
AF Cardarilli, Gian Carlo
   Di Nunzio, Luca
   Fazzolari, Rocco
   Giardino, Daniele
   Matta, Marco
   Nannarelli, Alberto
   Re, Marco
   Spano, Sergio
BE Matthews, MB
TI FPGA Implementation of Q-RTS for Real-Time Swarm Intelligence Systems
SO 2020 54TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS, AND COMPUTERS
SE Conference Record of the Asilomar Conference on Signals Systems and
   Computers
DT Proceedings Paper
CT 54th Asilomar Conference on Signals, Systems, and Computers
CY NOV 01-05, 2020
CL ELECTR NETWORK
DE Machine Learning; Q-Learning; FPGA; Accelerator Architecture; Swarm
   Reinforement Learning; Robotics
AB We propose an architectural blueprint to implement Q-RTS, Q-Learning Real-Time Swarm Reinforcement Learning algorithm, on FPGA. The design solution is built on FPGA-based Centralized RL Processing Units (CRLPU). A CRLPU processes local and global state-action matrices and exchanges information frames with low-power Microcontroller-based Agents. The novel architecture implementation, for up to 32 Agents with up to 512 states, on a Xilinx Ultrascale device shows low resource requirements in terms of CLB (7%) and memory (2% FF and 22% BRAM). Performance metrics show that the required energy per generated action is always lower than 1 mu J.
C1 [Cardarilli, Gian Carlo; Di Nunzio, Luca; Fazzolari, Rocco; Giardino, Daniele; Matta, Marco; Re, Marco; Spano, Sergio] Univ Roma Tor Vergata, Dept Elect, Rome, Italy.
   [Nannarelli, Alberto] Tech Univ Denmark, DTU Compute, Lyngby, Denmark.
RP Cardarilli, GC (corresponding author), Univ Roma Tor Vergata, Dept Elect, Rome, Italy.
EM g.cardarilli@uniroma2.it
CR Botvinick M, 2019, TRENDS COGN SCI, V23, P408, DOI 10.1016/j.tics.2019.02.006
   Capizzi G, 2020, IEEE T FUZZY SYST, V28, P1178, DOI 10.1109/TFUZZ.2019.2952831
   Da Silva LMD, 2019, IEEE ACCESS, V7, P2782, DOI 10.1109/ACCESS.2018.2885950
   Drugan MM, 2019, SWARM EVOL COMPUT, V44, P228, DOI 10.1016/j.swevo.2018.03.011
   Hüttenrauch M, 2019, J MACH LEARN RES, V20
   Matta M, 2019, ELECTRON LETT, V55, P589, DOI 10.1049/el.2019.0244
   Matta M, 2019, IEEE ACCESS, V7, P124147, DOI 10.1109/ACCESS.2019.2938390
   Mohri M., 2018, FDN MACHINE LEARNING, P6
   Nunzio Luca, 2020, Robotics and Mechatronics. Proceedings of the 6th IFToMM International Symposium on Robotics and Mechatronics (ISRM 2019). Mechanisms and Machine Science (MMS 78), P277, DOI 10.1007/978-3-030-30036-4_25
   Spanò S, 2019, IEEE ACCESS, V7, P186340, DOI 10.1109/ACCESS.2019.2961174
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
NR 11
TC 0
Z9 0
U1 1
U2 3
PY 2020
BP 116
EP 120
DI 10.1109/IEEECONF51394.2020.9443368
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Telecommunications
DA 2023-11-11
ER

PT J
AU Kang, MG
   Gonugondla, SK
   Lim, S
   Shanbhag, NR
AF Kang, Mingu
   Gonugondla, Sujan K.
   Lim, Sungmin
   Shanbhag, Naresh R.
TI A 19.4-nJ/Decision, 364-K Decisions/s, In-Memory Random Forest
   Multi-Class Inference Accelerator
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Accelerator; analog processing; in-memory computing; machine learning
   (ML); random forest (RF)
AB This paper presents an integrated circuit (IC) realization of a random forest (RF) machine learning classifier in a 65-nm CMOS. Algorithm, architecture, and circuits are co-optimized to achieve aggressive energy and delay benefits by taking advantage of the inherent error resiliency derived from the ensemble nature of an RF classifier. Deterministic sub-sampling (DSS) and regularized decision trees reduce interconnect complexity, and avoid irregular memory access patterns and computations, thereby reducing the energy-delay product (EDP). The prototype IC also employs low-swing analog in-memory computations embedded in a standard 6T SRAM to enable massively parallel tree node comparisons, thereby minimizing the memory fetches and reducing the EDP further. The 65-nm CMOS prototype IC achieves a 3.1x and 2.2x improved energy efficiency and throughput leading to 6.8x lower EDP compared to a conventional digital system at the same accuracies of 94% and 97.5% for two tasks: 1) eight-class traffic sign recognition and 2) face detection, respectively.
C1 [Kang, Mingu; Gonugondla, Sujan K.; Lim, Sungmin; Shanbhag, Naresh R.] Univ Illinois, Coordinated Sci Lab, Champaign, IL 61801 USA.
RP Kang, MG (corresponding author), Univ Illinois, Coordinated Sci Lab, Champaign, IL 61801 USA.
EM mkang17@illinois.edu; gonugon2@illinois.edu; sungmin3@illinois.edu;
   shanbhag@illinois.edu
CR [Anonymous], 2000, CTR BIOL COMPUTATION
   Bong K, 2017, ISSCC DIG TECH PAP I, P248, DOI 10.1109/ISSCC.2017.7870354
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen TW, 2012, IEEE T VLSI SYST, V20, P2329, DOI 10.1109/TVLSI.2011.2170203
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   KOBAYASHI T, 1993, IEICE T ELECTRON, VE76C, P863
   Lee KJ, 2015, IEEE J SOLID-ST CIRC, V50, P1059, DOI 10.1109/JSSC.2014.2380790
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Park SK, 2015, IEEE INT MEM WORKSH, P1
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Prisacariu Victor Adrian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3344, DOI 10.1109/ICPR.2010.816
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 24
TC 30
Z9 30
U1 0
U2 3
PD JUL
PY 2018
VL 53
IS 7
SI SI
BP 2126
EP 2135
DI 10.1109/JSSC.2018.2822703
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Andri, R
   Cavigelli, L
   Rossi, D
   Benini, L
AF Andri, Renzo
   Cavigelli, Lukas
   Rossi, Davide
   Benini, Luca
GP IEEE
TI Hyperdrive: A Systolically Scalable Binary-Weight CNN Inference Engine
   for mW IoT End-Nodes
SO 2018 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 17th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 09-11, 2018
CL Hong Kong Polytechn Univ, Hong Kong, HONG KONG
HO Hong Kong Polytechn Univ
DE Hardware Accelerator; Binary Weights Neural Networks; IoT
AB Deep neural networks have achieved impressive results in computer vision and machine learning. Unfortunately, state-of-the-art networks are extremely compute- and memory intensive which makes them unsuitable for mW-devices such as IoT end-nodes. Aggressive quantization of these networks dramatically reduces the computation and memory footprint. Binary-weight neural networks (BWNs) follow this trend, pushing weight quantization to the limit. Hardware accelerators for BWNs presented up to now have focused on core efficiency, disregarding I/O bandwidth and system-level efficiency that are crucial for deployment of accelerators in ultra-low power devices. We present Hyperdrive: a BWN accelerator dramatically reducing the I/O bandwidth exploiting a novel binary-weight streaming approach, and capable of handling high-resolution images by virtue of its systolic-scalable architecture. We achieve a 5.9 TOp/s/W system-level efficiency (i.e. including I/Os)-2.2x higher than state-of-the-art BNN accelerators, even if our core uses resource-intensive FP16 arithmetic for increased robustness.
C1 [Andri, Renzo; Cavigelli, Lukas; Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab, Zurich, Switzerland.
   [Rossi, Davide; Benini, Luca] Univ Bologna, DEI, Bologna, Italy.
RP Andri, R (corresponding author), Swiss Fed Inst Technol, Integrated Syst Lab, Zurich, Switzerland.
CR Aimar A., 2017, ARXIV170601406, P6
   Al Bahou A., 2018, ARXIV180305849
   Andrae R, 2017, INT CONF ENG DES, P1
   [Anonymous], 2018, EE TIMES
   Baraniuk RG, 2011, SCIENCE, V331, P717, DOI 10.1126/science.1197448
   Cavigelli L., 2016, P SPIE SECURITY DEFE, V9997
   Cavigelli L., 2017, P ACM ICDSC
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Conti F, 2017, IEEE T CIRCUITS-I, V64, P2481, DOI 10.1109/TCSI.2017.2698019
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Courbariaux M., 2015, ADV NIPS
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dreslinski RG, 2010, P IEEE, V98, P253, DOI 10.1109/JPROC.2009.2034764
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Gysel P., 2016, ICLR WORKSHOPS
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2015, ARXIV
   Jouppi N. P., 2017, P ACM ISCA
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nvidia Inc, NVID TESL V100 GPU A
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusci M, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351807
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scheidegger F, 2017, EUR SIGNAL PR CONF, P996, DOI 10.23919/EUSIPCO.2017.8081357
   Schulz P, 2017, IEEE COMMUN MAG, V55, P70, DOI 10.1109/MCOM.2017.1600435CM
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Vasilache Nicolas, 2014, ARXIV14127580
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   VentureBeat. com, 2018, GREENWAVES TECHN UNV
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Weddell A. S., 2013, P ACM IEEE DATE, P4
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zhou  A., 2017, ARXIV170203044
NR 44
TC 10
Z9 10
U1 0
U2 5
PY 2018
BP 509
EP 515
DI 10.1109/ISVLSI.2018.00099
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zhuang, JW
   Kochkov, D
   Bar-Sinai, Y
   Brenner, MP
   Hoyer, S
AF Zhuang, Jiawei
   Kochkov, Dmitrii
   Bar-Sinai, Yohai
   Brenner, Michael P.
   Hoyer, Stephan
TI Learned discretizations for passive scalar advection in a
   two-dimensional turbulent flow
SO PHYSICAL REVIEW FLUIDS
DT Article
ID NUMERICAL-SIMULATION; NEURAL-NETWORKS; TRANSPORT; RESOLUTION; SCHEMES;
   ALGORITHMS; MODELS; AGE
AB The computational cost of fluid simulations increases rapidly with grid resolution. This has given a hard limit on the ability of simulations to accurately resolve small-scale features of complex flows. Here we use a machine learning approach to learn a numerical discretization that retains high accuracy even when the solution is under-resolved with classical methods. We apply this approach to passive scalar advection in a two-dimensional turbulent flow. The method maintains the same accuracy as traditional high-order flux-limited advection solvers, while using 4x lower grid resolution in each dimension. The machine learning component is tightly integrated with traditional finite-volume schemes and can be trained via an end-to-end differentiable programming framework. The solver can achieve near-peak hardware utilization on CPUs and accelerators via convolutional filters.
C1 [Zhuang, Jiawei; Bar-Sinai, Yohai; Brenner, Michael P.] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Zhuang, Jiawei; Kochkov, Dmitrii; Brenner, Michael P.; Hoyer, Stephan] Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.
   [Bar-Sinai, Yohai] Google Res, IL-67891 Tel Aviv, Israel.
   [Bar-Sinai, Yohai] Tel Aviv Univ, Sch Phys & Astron, IL-69978 Tel Aviv, Israel.
RP Zhuang, JW (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.; Zhuang, JW (corresponding author), Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agrawal A., 2019, P 2 SYSML C PAL ALT
   [Anonymous], ARXIV171009282
   [Anonymous], 2018, SWIFT DIFFERENTIABLE
   Bar-Sinai Y, 2019, P NATL ACAD SCI USA, V116, P15344, DOI 10.1073/pnas.1814058116
   Bauer P, 2015, NATURE, V525, P47, DOI 10.1038/nature14956
   Baydin AG, 2018, J MACH LEARN RES, V18
   Bischof C, 1996, IEEE COMPUT SCI ENG, V3, P18, DOI 10.1109/99.537089
   Book D. L, 2012, CONCEPTION GESTATION, P1
   BORIS JP, 1973, J COMPUT PHYS, V11, P38, DOI 10.1016/0021-9991(73)90147-2
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bradbury J., JAX COMPOSABLE TRANS
   Brenowitz ND, 2018, GEOPHYS RES LETT, V45, P6289, DOI 10.1029/2018GL078510
   Breuer A, 2019, LECT NOTES COMPUT SC, V11501, P167, DOI 10.1007/978-3-030-20656-7_9
   Carman J., 2017, NATL EARTH SYSTEM PR, DOI [10.7289/V5862DH3, DOI 10.7289/V5862DH3]
   Colella P, 2008, J COMPUT PHYS, V227, P7069, DOI 10.1016/j.jcp.2008.03.034
   de Bézenac E, 2019, J STAT MECH-THEORY E, V2019, DOI 10.1088/1742-5468/ab3195
   Dean J., ARXIV191105289
   Duraisamy K, 2019, ANNU REV FLUID MECH, V51, P357, DOI 10.1146/annurev-fluid-010518-040547
   Eastham SD, 2017, ATMOS CHEM PHYS, V17, P2543, DOI 10.5194/acp-17-2543-2017
   Frezat H, 2021, PHYS REV FLUIDS, V6, DOI 10.1103/PhysRevFluids.6.024607
   Hassanzadeh H, 2009, COMPUT CHEM ENG, V33, P133, DOI 10.1016/j.compchemeng.2008.07.010
   Hatfield S., 2019, P PLATF ADV SCI COMP, P1
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Innes M., 2018, J OPEN SOURCE SOFTW, DOI [DOI 10.21105/JOSS.00602, 10.21105/joss.00602]
   JAX M.D., ARXIV191204232
   Jiménez J, 2020, EUR J MECH B-FLUID, V79, P1, DOI 10.1016/j.euromechflu.2019.06.010
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kulkarni CS, 2019, J COMPUT PHYS, V398, DOI 10.1016/j.jcp.2019.108859
   Kutz JN, 2017, J FLUID MECH, V814, P1, DOI 10.1017/jfm.2016.803
   Lauritzen PH, 2014, GEOSCI MODEL DEV, V7, P105, DOI 10.5194/gmd-7-105-2014
   Lauritzen PH, 2010, J COMPUT PHYS, V229, P1401, DOI 10.1016/j.jcp.2009.10.036
   Leveque RJ, 1996, SIAM J NUMER ANAL, V33, P627, DOI 10.1137/0733033
   LIN SJ, 1994, MON WEATHER REV, V122, P1575, DOI 10.1175/1520-0493(1994)122<1575:ACOTVL>2.0.CO;2
   Lin SJ, 1996, MON WEATHER REV, V124, P2046, DOI 10.1175/1520-0493(1996)124<2046:MFFSLT>2.0.CO;2
   Ling J, 2016, J FLUID MECH, V807, P155, DOI 10.1017/jfm.2016.615
   MCWILLIAMS JC, 1984, J FLUID MECH, V146, P21, DOI 10.1017/S0022112084001750
   Methven J, 1999, J ATMOS SCI, V56, P3262, DOI 10.1175/1520-0469(1999)056<3262:TAOHRT>2.0.CO;2
   Nair RD, 2010, J COMPUT PHYS, V229, P8868, DOI 10.1016/j.jcp.2010.08.014
   Neumann P, 2019, PHILOS T R SOC A, V377, DOI 10.1098/rsta.2018.0148
   Odman MT, 1997, ATMOS ENVIRON, V31, P1933, DOI 10.1016/S1352-2310(96)00354-8
   Pathak J., ARXIV201000072
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Raissi M, 2018, J COMPUT PHYS, V357, P125, DOI 10.1016/j.jcp.2017.11.039
   Rasp S, 2018, P NATL ACAD SCI USA, V115, P9684, DOI 10.1073/pnas.1810286115
   Rastigejev Y, 2010, J GEOPHYS RES-ATMOS, V115, DOI 10.1029/2009JD012568
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Saad T., 2016, PHYS FLUIDS, V13, P22
   Schneider T, 2017, GEOPHYS RES LETT, V44, P12396, DOI 10.1002/2017GL076101
   Schneider T, 2017, NAT CLIM CHANGE, V7, P3, DOI 10.1038/nclimate3190
   Schulthess TC, 2019, COMPUT SCI ENG, V21, P30, DOI 10.1109/MCSE.2018.2888788
   Semakin AN, 2016, MON WEATHER REV, V144, P1469, DOI 10.1175/MWR-D-15-0200.1
   Shalf J, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0061
   Shraiman BI, 2000, NATURE, V405, P639, DOI 10.1038/35015000
   Smaoui H, 2001, ENVIRON FLUID MECH, V1, P361, DOI 10.1023/A:1015764813423
   Stohl A, 2005, ATMOS CHEM PHYS, V5, P2461, DOI 10.5194/acp-5-2461-2005
   SWEBY PK, 1984, SIAM J NUMER ANAL, V21, P995, DOI 10.1137/0721062
   Tebbutt W., ARXIV190707587
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Ullrich PA, 2010, J COMPUT PHYS, V229, P6104, DOI 10.1016/j.jcp.2010.04.044
   Um K., ARXIV200700016
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhuang JW, 2018, ATMOS CHEM PHYS, V18, P6039, DOI 10.5194/acp-18-6039-2018
NR 64
TC 18
Z9 21
U1 0
U2 8
PD JUN 14
PY 2021
VL 6
IS 6
AR 064605
DI 10.1103/PhysRevFluids.6.064605
WC Physics, Fluids & Plasmas
DA 2023-11-11
ER

PT J
AU Fessia, P
   Rossi, L
   Krog-Pedersen, SS
AF Fessia, P.
   Rossi, L.
   Krog-Pedersen, S. Stine
TI Application of the learning curve analysis to the LHC main dipole
   production: First assessment
SO IEEE TRANSACTIONS ON APPLIED SUPERCONDUCTIVITY
DT Article; Proceedings Paper
CT 19th International Conference on Magnet Technology
CY SEP 18-23, 2005
CL Geneva, ITALY
DE accelerator magnets; large scale superconductivity; production
   management
AB About two third of the LHC main dipoles have been delivered by the three suppliers charged of the production. The training of the staff, mostly hired just for this manufacture, and the natural improvement of the procedures with the acquired experience, decrease naturally the time necessary for the assembly of a unit. The aim of this paper,is to apply methodologies like the cost-based learning curves and the time-based learning curves to the LHC Main Dipole comparing the estimated learning percentage to the ones experienced in other industries. This type of analysis, still in a preliminary phase and here applied to about 40% of the total production of the LHC magnets that will end by 2006, shows that our production has a relatively high learning percentage and it is similar to aerospace and complex machine tools for new models. Therefore with the LHC project, accelerator magnets seem to have reached industrial maturity and this production can be used as bench mark for other large scientific projects implying series production.
C1 CERN, Accelerator Technol Dept, CH-1211 Geneva 23, Switzerland.
   CERN, AT Dept, CH-1211 Geneva, Switzerland.
RP Fessia, P (corresponding author), CERN, Accelerator Technol Dept, CH-1211 Geneva 23, Switzerland.
EM paolo.fessia@cern.ch; lucio.rossi@cern.ch
CR ANERELLA MD, 1996, IEEE T MAGN, V32
   [Anonymous], CERN2004003, V1
   de Rijk G, 2005, IEEE T APPL SUPERCON, V15, P1078, DOI 10.1109/TASC.2005.849500
   FISCHER D, 2000, IEEE T SUPERCOND, V10
   GOLDBERG MS, 2003, STAT METHODS LEARNIN
   Li G., 1997, Journal of Operations Management, V15, P181, DOI 10.1016/S0272-6963(97)00003-X
   Ross KE, 2002, TRENDS CELL BIOL, V12, P1, DOI 10.1016/S0962-8924(01)02202-4
   Rossi L, 2003, IEEE T APPL SUPERCON, V13, P1221, DOI 10.1109/TASC.2003.812639
   RUSSEL RS, 2003, OPER MANAGE
   TAVIAN L, 2005, 20 NAT S CRYOG 2005
NR 10
TC 1
Z9 1
U1 0
U2 3
PD JUN
PY 2006
VL 16
IS 2
BP 242
EP 247
DI 10.1109/TASC.2006.869992
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Bhardwaj, K
   Havasi, M
   Yao, Y
   Brooks, DM
   Lobato, JMH
   Wei, GY
AF Bhardwaj, Kshitij
   Havasi, Marton
   Yao, Yuan
   Brooks, David M.
   Hernandez Lobato, Jose Miguel
   Wei, Gu-Yeon
TI Determining Optimal Coherency Interface for Many-Accelerator SoCs Using
   Bayesian Optimization
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE System-on-chip (SoC); hardware accelerators; coherence protocols;
   Bayesian optimization
AB The modern system-on-chip (SoC) of the current exascale computing era is complex. These SoCs not only consist of several general-purpose processing cores but also integrate many specialized hardware accelerators. Three common coherency interfaces are used to integrate the accelerators with the memory hierarchy: non-coherent, coherent with the last-level cache (LLC), and fully-coherent. However, using a single coherence interface for all the accelerators in an SoC can lead to significant overheads: in the non-coherent model, accelerators directly access the main memory, which can have considerable performance penalty; whereas in the LLC-coherent model, the accelerators access the LLC but may suffer from performance bottleneck due to contention between several accelerators; and the fully-coherent model, that relies on private caches, can incur non-trivial power/area overheads. Given the limitations of each of these interfaces, this paper proposes a novel performance-aware hybrid coherency interface, where different accelerators use different coherency models, decided at design time based on the target applications so as to optimize the overall system performance. A new Bayesian optimization based framework is also proposed to determine the optimal hybrid coherency interface, i.e., use machine learning to select the best coherency model for each of the accelerators in the SoC in terms of performance. For image processing and classification workloads, the proposed framework determined that a hybrid interface achieves up to 23 percent better performance compared to the other 'homogeneous' interfaces, where all the accelerators use a single coherency model.
C1 [Bhardwaj, Kshitij; Yao, Yuan; Brooks, David M.; Wei, Gu-Yeon] Harvard Univ, Cambridge, MA 02138 USA.
   [Havasi, Marton; Hernandez Lobato, Jose Miguel] Univ Cambridge, Cambridge CB2 1TW, England.
RP Bhardwaj, K (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM kbhardwaj@g.harvard.edu; mh740@cam.ac.uk; yuanyao@seas.harvard.edu;
   dbrooks@eecs.harvard.edu; jmh233@cam.ac.uk; guyeon@eecs.harvard.edu
CR Alsop J, 2018, CONF PROC INT SYMP C, P261, DOI 10.1109/ISCA.2018.00031
   [Anonymous], P 52 ANN DES AUT C
   [Anonymous], 2017, P IEEE ACM INT S LOW
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Giri D., 2018, P 12 IEEE ACM INT S
   Giri D, 2018, IEEE MICRO, V38, P36, DOI 10.1109/MM.2018.2877288
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Powell Andrew, 2015, 2015 International Conference on Reconfigurable Computing and FPGAs (ReConFig), P1, DOI 10.1109/ReConFig.2015.7393362
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Shao Y. S., 2016, P 49 ANN IEEE ACM IN
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Srinivas N., 2010, P 27 INT C INT C MAC, P1015, DOI DOI 10.1109/TIT.2011.2182033
NR 13
TC 3
Z9 3
U1 0
U2 3
PD JUL-DEC
PY 2019
VL 18
IS 2
BP 119
EP 123
DI 10.1109/LCA.2019.2910521
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Peccerillo, B
   Mannino, M
   Mondelli, A
   Bartolini, S
AF Peccerillo, Biagio
   Mannino, Mirco
   Mondelli, Andrea
   Bartolini, Sandro
TI A survey on hardware accelerators: Taxonomy, trends, challenges, and
   perspectives
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Accelerators; Domain-Specific Architectures; Survey; Taxonomy;
   Classification; Data-parallel; Machine Learning; PIM; CGRA; Open
   challenges; Future research directions
ID DEEP NEURAL-NETWORKS; IN-MEMORY; EFFICIENT; ARCHITECTURE; AWARE;
   COMPRESSION; DIANNAO; GPUS; Q100
AB In recent years, the limits of the multicore approach emerged in the so-called "dark silicon" issue and diminishing returns of an ever-increasing core count. Hardware manufacturers, out of necessity, switched their focus to accelerators, a new paradigm that pursues specialization and heterogeneity over generality and homogeneity. They are special-purpose hardware structures separated from the CPU with aspects that exhibit a high degree of variability. We define a taxonomy based on fourteen of these aspects, grouped in four macro categories: general aspects, host coupling, architecture, and software aspects. According to it, we categorize around 100 accelerators of the last decade from both industry and academia, and critically analyze emerging trends. We complete our discussion with throughput and efficiency figures. Then, we discuss some prominent open challenges that accelerators are facing, analyzing state-of-the-art solutions, and suggesting prospective research directions for the future.
C1 [Peccerillo, Biagio; Mannino, Mirco; Bartolini, Sandro] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Mondelli, Andrea] Huawei Technol Res & Dev UK Ltd, Cambridge, England.
RP Peccerillo, B (corresponding author), Univ Siena, Dept Informat Engn & Math, Siena, Italy.
EM peccerillo@diism.unisi.it
CR Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Addazi Lorenzo, 2019, P 22 INT C MOD DRIV
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Akbari O, 2020, IEEE T COMPUT AID D, V39, P2558, DOI 10.1109/TCAD.2019.2937738
   Akbari O, 2018, DES AUT TEST EUROPE, P413, DOI 10.23919/DATE.2018.8342045
   AMD, 2016, ROCM NEW ER OP GPU C
   AMD, 2021, AMD RDNA 2
   AMD, 2019, RDNA ARCH
   AMD, 2021, AMD MICR DIRECTX 12
   AMDAHL GM, 1967, P APR 18 20 1967 SPR, P483, DOI DOI 10.1145/1465482.1465560
   Andión JM, 2013, PARALLEL COMPUT, V39, P442, DOI 10.1016/j.parco.2013.04.003
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Angstadt K, 2016, ACM SIGPLAN NOTICES, V51, P593, DOI 10.1145/2954679.2872393
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], INT QUART PRIM SOFTW
   [Anonymous], 2018, CORR
   [Anonymous], 2018, ARXIV
   [Anonymous], 2015, MISCELLANEOUS
   [Anonymous], 2019, USB ACCELERATOR
   [Anonymous], 2016, INTEL XEON PHI PROCE
   [Anonymous], 2013, QUALCOMM HEXAGON DSP
   [Anonymous], 2013, HYBRID MEMORY CUBE S
   [Anonymous], 2010, SCI COMPUTING MULTIC
   [Anonymous], 2019, P IEEE HOT CHIPS 31, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875628
   [Anonymous], 2014, HMC SPEC 2 0
   [Anonymous], INT NERV NEUR NETW P
   Apache Incubator, 2018, FLEX EFF LIB DEEP LE
   Apache Software Foundation, 2021, APACHE HADOOP
   Apalkov D, 2013, ACM J EMERG TECH COM, V9, DOI 10.1145/2463585.2463589
   Apostolakis S, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P351, DOI 10.1145/3373376.3378458
   Apple, 2020, M1, pM1
   Apple, 2021, MET ACC GRAPH MUCH M
   Apple Inc, COR ML
   Arm, 2019, MAL G77
   Arm, 2020, MAL G78
   Arm, 2016, LOOKING METAL ORGANI
   Arm, 2021, ARM MAL GPU DAT
   Arm, 2017, MIRACLE WORKER
   Arm, 2018, MAL G76
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Bartolini S., 2020, FUNDAMENTALS STANDAR
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Bohr Mark, 2007, IEEE SOLID STATE CIR, V12, P11, DOI [DOI 10.1109/N-SSC.2007.4785534, 10.1109/N-SSC.2007.4785534]
   Bonshor, 2022, AMD RELEASES MILAN X
   Boroumand A, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P629, DOI 10.1145/3307650.3322266
   Boudier, 2011, AMD FUSION DEVELOPER
   Brett, 2016, JESD235A JED
   Buchty R, 2012, CONCURR COMP-PRACT E, V24, P663, DOI 10.1002/cpe.1904
   Bueno J, 2011, LECT NOTES COMPUT SC, V6852, P555, DOI 10.1007/978-3-642-23400-2_52
   Businesswire, 2014, BUSINESSWIRE
   Businesswire, 2015, BUSINESSWIRE
   Cardoso J. M. P., 2017, EMBEDDED COMPUTING H
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Cascaval C, 2010, IBM J RES DEV, V54, DOI 10.1147/JRD.2010.2059721
   Caulfield A.M., 2016, MICR MICRO 2016 49 A
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   CBC News, 2020, CBC NEWS
   CCIX Consortium, 2021, 209 WEBS
   CCIX Consortium, 2019, INTR CCIX WHIT PAP
   Cerebras, FUT AI IS HER
   Chattopadhyay A, 2013, VLSI DES, DOI 10.1155/2013/683615
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng M, 2019, IEEE T COMPUT AID D, V38, P834, DOI 10.1109/TCAD.2018.2824304
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chollet F., 2015, KERAS
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   Chromczak J, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P140, DOI 10.1145/3373087.3375308
   Comtech EF Data Corporation, 2015, AHA374 AHA378 PCI EX
   Comtech EF Data Corporation, 2016, AHA604 AHA605 RSA KE
   Comtech EF Data Corporation, 2014, AHA371 AHA372 PCI EX
   Cong J, 2017, INT S HIGH PERF COMP, P37, DOI 10.1109/HPCA.2017.19
   Cong J, 2014, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2014.12
   Coral, 2020, PYCORAL API OV
   Cota EG, 2015, DES AUT CON, DOI 10.1145/2744769.2744794
   Cross, 2019, INSIDE APPLES A13 BI
   Cutress Ian, 2019, HOT CHIPS 31 LIVE BL
   CXL Consortium, 2022, COMP EXPR LINK BREAK
   Cyphers S., 2018, ARXIV PREPRINTARXIV1
   Dai GH, 2019, IEEE T COMPUT AID D, V38, P640, DOI 10.1109/TCAD.2018.2821565
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Dashti M, 2017, ACM SIGPLAN NOTICES, V52, P59, DOI 10.1145/3156685.3092256
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Davidson, NEW FPGA ARCHITECTUR
   Davies J, 2016, IEEE HOT CHIP SYMP
   DeHon A, 2015, P IEEE, V103, P355, DOI 10.1109/JPROC.2014.2387696
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Dennis, 1974, PRELIMINARY ARCHITEC, P402
   Dennis J. B., 1974, Programming Symposium, P362
   Dennis J. B., 1975, 2nd Annual Symposium on Computer Architecture, P126
   Devaux F., 2019, PROC 31 S HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875680
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Donovan Alan AA, 2015, GO PROGRAMMING LANGU
   Du ZD, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P494, DOI 10.1145/2830772.2830789
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Duch L, 2019, IEEE EMBED SYST LETT, V11, P50, DOI 10.1109/LES.2018.2849267
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Edwards H. Carter, 2013, 2013 Extreme Scaling Workshop (xsw 2013), P18, DOI 10.1109/XSW.2013.7
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fan, 2018, COMMUNICATE, P36
   Fang J, 2017, INT SYMP DISTR COMPU, P19, DOI 10.1109/DCABES.2017.12
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Fowers J, 2015, ANN IEEE SYM FIELD P, P52, DOI 10.1109/FCCM.2015.46
   Frumusanu, 2020, HUAWEI ANNOUNCES MAT
   Frumusanu, 2020, QUALCOMM DETAILS SNA
   Frumusanu, 2019, SNAPDRAGON 855 PERFO
   Frumusanu, 2019, HUAWEI MATE 30 PRORE
   Frumusanu, 2019, APPLE IPHONE 11 11 P
   Frumusanu A., 2020, APPLE ANNOUNCES APPL
   Fujii D, 2021, INT PSYCHOGERIATR, V33, P1115, DOI 10.1017/S104161022100051X
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   G.B. Team, TENSORFLOW MOB IOT
   Gaide B, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P84, DOI 10.1145/3289602.3293906
   Gaillardon PE, 2016, DES AUT TEST EUROPE, P427
   Gailly J.-l., 2006, GNU GZIP SUMMARY
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   García-Guirado A, 2014, CONCURR COMP-PRACT E, V26, P2530, DOI 10.1002/cpe.3332
   Garg A., 2019, 26 INT C HIGH PERF C, P395, DOI DOI 10.1109/HIPC.2019.00054
   Gerangelos S, 2017, IEEE SYM PARA DISTR, P1333, DOI 10.1109/IPDPSW.2017.110
   Gillani GA, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P358, DOI 10.1145/3310273.3323161
   Giri D, 2018, IEEE MICRO, V38, P36, DOI 10.1109/MM.2018.2877288
   Gong S., 2019, 56 ACM IEEE DES AUT, P1
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Google, 2021, CAM API
   Google, CLOUD TENS PROC UN T
   Google, 2021, NEUR NETW API
   Google, 2020, EDG TPU PERF BENCHM
   Google, EDG TPU
   Google Brain Team, 2015, TENSORFLOW
   Govindarajan S., 2020, 2020 IEEE EL DES ADV, P1
   Graphcore, 2020, C2 IPU PCIE CARD
   Graphcore, POPL GRAPH FRAM SOFT
   Graphcore, 2020, IPU MACH M2000 DAT
   Graphcore, IPU MACH IPU M2000
   Greengard S, 2016, COMMUN ACM, V59, P14, DOI 10.1145/2967979
   Groq Groq, GROQ
   Gui CY, 2019, J COMPUT SCI TECH-CH, V34, P339, DOI 10.1007/s11390-019-1914-z
   Gupta S, 2019, I SYMPOS LOW POWER E, DOI 10.1109/irps.2019.8720595
   Gwennap L., 2020, UNTETHER DELIVERS AT
   H. Labs, 2019, GOYA INF PLATF WHIT
   Haensch W, 2006, IBM J RES DEV, V50, P339, DOI 10.1147/rd.504.0339
   Hailo, HAIL 8 AI PROC
   Hailo, DAT COMP COMPL SCAL
   Ham TJ, 2016, INT SYMP MICROARCH
   Haria S, 2018, ACM SIGPLAN NOTICES, V53, P637, DOI [10.1145/3296957.3173194, 10.1145/3173162.3173194]
   Hawick, 2014, P 12 AUSTRALASIAN S, V152, P21
   Hennessy J., 2017, COMPUTER ARCHITECTUR
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hickmann B, 2020, P S COMP ARITHM, P133, DOI 10.1109/ARITH48897.2020.00029
   Hightower K, 2017, KUBERNETES RUNNING D
   HiSilicon, KIR 990 5G
   HiSilicon, KIR 9000
   Hong K, 2014, I C INF COMM TECH CO, P472, DOI 10.1109/ICTC.2014.6983183
   Hong-Soog Kim, 2000, Proceedings Fourth International Conference/Exhibition on High Performance Computing in the Asia-Pacific Region, P243, DOI 10.1109/HPC.2000.846552
   HP, MACH NEW KIND COMP
   HSA Foundation, 2017, HSA FDN
   Huang TS, 1996, CERN REPORT, V96, P21
   Huang YP, 2016, CONF PROC INT SYMP C, P570, DOI 10.1109/ISCA.2016.56
   Huangfu WQ, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415724
   Huangfu WQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196098
   Huawei, CANN CHIP EN IMPR DE
   Huawei, ATL 300T TRAIN CARD
   Huawei, ATL 300I INF CARD
   Huawei, ATL 200 AI ACC MOD
   Huawei, 2020, 200912942 ARXIV
   Huawei, 2020, HUAW HIAI DDK QUICK
   Huawei, MINDX SDK
   Huawei, 2020, ATL AI COMP SOL
   Hughes J. F., 2014, COMPUTER GRAPHICS PR
   Hwang SW, 2016, ACM T WEB, V10, DOI 10.1145/2943784
   Imani M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P356, DOI 10.1109/MICRO50266.2020.00039
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Iniewski K., 2012, EMBEDDED SYSTEMS HAR
   Innes M., 2018, J OPEN SOURCE SOFTW, DOI [DOI 10.21105/JOSS.00602, 10.21105/joss.00602]
   Intel, ARR 10 FPGAS SOCS
   Intel, 2021, SUPP APIS INT GRAPH
   Intel, INT STRAT 10 FPGAS S
   Intel, 2020, ARR 10 DEV DAT
   Intel, 2021, INT STRAT 10 DEV DAT
   Intel, 2019, INT PROC GRAPH GEN11
   Intel, DSP BUILD INT FPGAS
   Intel, 2021, OPENVINO DEPL HIGH P
   Intel, INT MAX 10 FPGA
   Intel, 2019, INT ARRIA V FPGAS
   Intel, 1989, 8087 MATH COPR
   Intel, INT STRAT 10 GX SX P
   Intel, INT HIGH LEV SYNTH C
   Intel, 2018, INT CYCL 10 GX DEV O
   Intel, 2017, INTEL XEON PHI PROCE
   Intel, ARR 10 PROD TABL
   Intel, 2019, CYCL V DEV DAT
   Intel, INT AG F SER FPGAS S
   Intel, INT STRAT 10NX FPGAS
   Intel, ARR V FPGAS SOC FPGA
   Intel, CYCL V FPGAS SOC FPG
   Intel, NGRAPH
   Intel, 2021, INT AG DEV DAT
   Intel, CYCL 10 FPGA
   ISO/IEC, 2017, PROGRAMMING LANGUAGE
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jedec Solid State Technology Association, 2015, JESD235A JEDEC
   Ji Y, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P733, DOI 10.1145/3297858.3304048
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Johns CR, 2007, IBM J RES DEV, V51, P503, DOI 10.1147/rd.515.0503
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kachris C., 2018, HARDWARE ACCELERATOR
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kaplan R, 2020, PROCEEDINGS OF THE 13TH ACM INTERNATIONAL SYSTEMS AND STORAGE CONFERENCE (SYSTOR 2020), P36, DOI 10.1145/3383669.3398279
   Karandikar Sagar, 2021, MICRO54 54 ANN IEEEA, P462
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Khronos Group, 2021, VULK IND FORG
   Khronos OpenCL Working Group, 2019, SYCL PROV SPEC VERS
   Khronos OpenCL Working Group, 2015, OPENCL SPECIFICATION
   Khronos OpenCL Working Group, 2012, OPENCL SPEC VERS 1 2
   Khronos OpenCL Working Group, 2018, OPENCL SPECIFICATION
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim H, 2019, INT S HIGH PERF COMP, P661, DOI 10.1109/HPCA.2019.00017
   Kim JS, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4460-0
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Koeplinger D, 2016, CONF PROC INT SYMP C, P115, DOI 10.1109/ISCA.2016.20
   Komatsu K, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Kumar SD, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P555, DOI [10.1109/ICICCS48265.2020.9120991, 10.1109/iciccs48265.2020.9120991]
   Kung J, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P403, DOI 10.1145/3079856.3080252
   Kurkure U, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P887, DOI 10.1109/HPCS.2018.00142
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Labs, 2019, GAUD TRAIN PLATF WHI
   Langhammer Martin, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P57, DOI 10.1145/3431920.3439293
   Ledwon M, 2020, IEEE ACCESS, V8, P62207, DOI 10.1109/ACCESS.2020.2984191
   Lee C, 2016, IEEE T IND INFORM, V12, P277, DOI 10.1109/TII.2015.2509441
   Lee D, 1996, P IEEE, V84, P1090, DOI 10.1109/5.533956
   Lee J, 2012, INT S HIGH PERF COMP, P91
   Lee J, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1408
   Lee Y, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P129
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Li XZ, 2004, 4TH IEEE INTERNATIONAL WORKSHOP ON SYSTEM-ON-CHIP FOR REAL-TIME APPLICATIONS, PROCEEDINGS, P291, DOI 10.1109/IWSOC.2004.1319896
   Li Z, 2017, FRONT COMPUT SCI-CHI, V11, P746, DOI 10.1007/s11704-016-6159-1
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Liu L, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P824, DOI 10.1109/3PGCIC.2015.103
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Liu LB, 2018, IEEE T CIRCUITS-II, V65, P381, DOI 10.1109/TCSII.2017.2728814
   Liu SF, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P1, DOI 10.1109/GSIS.2013.6714728
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma Y., 2019, FRONT DATA COMPUT, V1, P105, DOI [DOI 10.11871/JFDC.ISSN.2096.742X.2019.01.011, 10.11871/jfdc.issn.2096.742X.2019.01.011]
   Mao HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P669, DOI [10.1109/MICRO.2018.00060, 10.1109/MICR0.2018.00060]
   Margerm S, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P245, DOI 10.1109/MICRO.2018.00028
   Martin D, 2021, STEEL RES INT, V92, DOI 10.1002/srin.202000381
   MathWorks, 2021, MATLAB GPU COMP SUPP
   MathWorks, 2021, XIL FPGAS ZYNQ SOCS
   McKee S.A., 2011, ENCY PARALLEL COMPUT, P1110
   MENCHINI PJ, 1993, NATO ADV SCI INST SE, V249, P359
   Microsoft, 2018, FEASIBILITY IMMERSIV
   MindSpore, 2021, PROGR GUID
   Mittal S, 2021, J SYST ARCHITECT, V119, DOI 10.1016/j.sysarc.2021.102276
   Mittal S, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102041
   Mittal S, 2021, J SYST ARCHITECT, V112, DOI 10.1016/j.sysarc.2020.101839
   Mittal S, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5742
   Mittal S, 2019, J SYST ARCHITECT, V98, P135, DOI 10.1016/j.sysarc.2019.07.006
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Mohammedali N, 2018, ISCSIC'18: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND INTELLIGENT CONTROL, DOI 10.1145/3284557.3284563
   Moolchandani D, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101887
   Moore SK, 2020, IEEE SPECTRUM, V57, P24, DOI 10.1109/MSPEC.2020.8946303
   Morris, 2020, UNTETHER AI PADDLING
   Moyer, 2013, REAL WORLD MULTICORE, P447, DOI DOI 10.1016/B978-0-12-416018-7.00013-4
   Munshi A., 2011, OPENCL PROGRAMMING G
   Nag A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P334, DOI 10.1145/3352460.3358308
   Nasiri H, 2016, 2016 IEEE E W DESIGN, P1
   NEC Corporation, 2020, NEC VECT SUP SX AUR
   NEC Corporation, 2018, SX AUR TSUBASA ARCH
   NEC Corporation, NEC SX AUR TSUBASA V
   NEC Corporation, 2021, NEC SX AUR TSUBASA C
   NEC Corporation-AI Platform Division, 2020, EV BRAND NEW TECHN S
   Nicol, 2017, COARSE GRAIN RECONFI
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   NVIDIA, 2021, GEFORCE RTX 3070 FAM
   NVIDIA, 2021, GEFORCE RTX 3060 FAM
   NVIDIA, 2021, DIRECTX 12
   NVIDIA, 2021, GEFORCE RTX 3090
   NVIDIA, 2020, NVIDIA AMP GA102 GPU
   Nvidia C., 2011, CUDA C PROGRAMMING G, V120
   NVIDIA Corporation, 2017, NVIDIA TESLA V100 GP
   OpenACC-Standard.org, 2019, OPENACC APPL PROGR I
   OpenMP Architecture Review Board, 2021, OPENMP APPL PROGR IN
   Optalysys, 2020, MULT FOUR TRANSF UN
   Oracle, 2022, WHAT IS DAT
   Ouyang J., 2020, 2020 IEEE HOT CHIPS, P1, DOI [10.1109/HCS49909.2020.9220641, DOI 10.1109/HCS49909.2020.9220641]
   Ouyang J, 2021, ISSCC DIG TECH PAP I, V64, P50, DOI 10.1109/ISSCC42613.2021.9366056
   Palnitkar S., 1996, VERILOG HDL GUIDE DI
   Papadimitriou K, 2011, ACM T RECONFIG TECHN, V4, DOI 10.1145/2068716.2068722
   Parris, 2013, EXTENDED SYSTEM CO 1
   Paszke A, 2019, P 33 INT C NEURAL IN
   Patel S, 2008, IEEE MICRO, V28, P4, DOI 10.1109/MM.2008.50
   Patterson D., 2019, DOMAIN SPECIFIC ARCH
   Patterson D.A., 2017, COMPUTER ORG DESIGN, V1st
   Peccerillo B, 2019, IEEE T PARALL DISTR, V30, P174, DOI 10.1109/TPDS.2018.2855182
   Pfister G., 2009, WHY ACCELERATORS NOW
   Power Jason, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P457, DOI 10.1145/2540708.2540747
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Promberger Laura, 2020, ICPP Workshops '20: Proceedings of the 49th International Conference on Parallel Processing - ICPP : Workshops, DOI 10.1145/3409390.3409405
   PYEON C. H., 2021, ACC DRIV SYST KYOT U, DOI [http://dx.doi.org/10.1007/978-981-16-0344-0, DOI 10.1007/978-981-16-0344-0]
   Q-engineering, 2021, GOOGL COR EDG TPU EX
   Qualcomm, SNAPDR 865
   Qualcomm, 2021, QUALC NEUR PROC SDK
   Qualcomm, SNAPDR 888
   Qualcomm, 2021, WIRELESS TECHNOLOGY
   Quraishi MH, 2021, IEEE T PARALL DISTR, V32, P2216, DOI 10.1109/TPDS.2021.3063670
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redgrave J., 2018, PROC IEEE HOT CHIPS
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Rivest, 2003, ENCY COMPUTER SCI, P468
   Roelofs G., 2017, ZLIB
   Roy I, 2016, PROC INT CONF PARAL, P205, DOI 10.1109/ICPP.2016.30
   Samsung, SAMS NEUR SDK
   Samsung, 2019, SAMS EX
   Samsung, 2020, MOB PROC EX 990
   Sanders J., 2010, CUDA EXAMPLE INTRO G
   Selig J., 2022, CEREBRAS SOFTWARE DE
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Siegl P, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P295, DOI 10.1145/2989081.2989087
   SiSoft, 2022, INT ARC ALCH GRAPH C
   Skliarova, 2019, LECT NOTES ELECT ENG, V566, P245, DOI DOI 10.1007/978-3-030-20721-2
   Smith, 2018, NVIDIA UNVEILS TITAN
   Smith, 2020, INTEL XE LP GPU ARCH
   Smith, 2019, NVIDIA GEFORCE RTX 2
   Sodani A, 2016, IEEE MICRO, V36, P34, DOI 10.1109/MM.2016.25
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Spinellis D, 2020, IEEE WORK CONF MIN S, P523, DOI 10.1145/3379597.3387496
   Spiridonov, 2021, NEW CLOUD TPU VMS MA
   Srivastava P, 2018, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA.2018.00015
   Stamoulias I., 2017, P 8 INT S HIGHL EFF
   Steuwer M., 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, P1176, DOI 10.1109/IPDPS.2011.269
   STONE HS, 1970, IEEE T COMPUT, VC 19, P73, DOI 10.1109/TC.1970.5008902
   Subramaniyan A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P600, DOI [10.1145/3079856.3080207, 10.1145/3140659.3080207]
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Synario, 1997, VHDL REF MAN
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talbot Justin, 2011, MAPREDUCE 11, P9
   Taranco R, 2021, INT SYM COMP ARCHIT, P11, DOI 10.1109/SBAC-PAD53543.2021.00013
   TechPowerUp, 2019, NVIDIA GEFORCE RTX 2
   TechPowerUp, 2020, AMD RAD RX 6800 XT
   TechPowerUp, 2020, AMD RAD RX 6900 XT
   TechPowerUp, 2020, INT IR XE GRAPH G7 9
   TechPowerUp, 2019, INT UHD GRAPH G1
   TechPowerUp, 2020, AMD RADEON INSTINCT
   TechPowerUp, 2020, AMD RAD RX 5600 XT
   TechPowerUp, 2019, AMD RAD RX 5700 XT
   TechPowerUp, 2021, INT UHD GRAPH 730
   TechPowerUp, 2019, INT UHD GRAPH G7
   Teich P., 2018, TEARING APART GOOGLE
   Tessier R, 2015, P IEEE, V103, P332, DOI 10.1109/JPROC.2014.2386883
   The OpenSSL Project, 1999, OPENSSL CRYPT SSL TL
   Trimberger SM, 2015, P IEEE, V103, P318, DOI 10.1109/JPROC.2015.2392104
   Turakhia Y, 2019, INT S HIGH PERF COMP, P359, DOI 10.1109/HPCA.2019.00050
   Turakhia Y, 2018, ACM SIGPLAN NOTICES, V53, P199, DOI [10.1145/3173162.3173193, 10.1145/3296957.3173193]
   Turing, 2019, NVIDIA TURING GPU AR
   U.A. I, 2021, UNT AI USH PETAOPS E
   Umesh S, 2019, J SYST ARCHITECT, V97, P349, DOI 10.1016/j.sysarc.2018.11.005
   UPMEM, UPMEM SDK
   UPMEM, COMP DAT IS INT TRAN
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Varbanescu AL, 2016, 2016 FORUM ON SPECIFICATION AND DESIGN LANGUAGES (FDL)
   Varghese B, 2018, IEEE CLOUD COMPUT, V5, P28, DOI 10.1109/MCC.2018.064181118
   Vasilas D, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P637, DOI 10.1109/HPCSim.2016.7568395
   Vogel P, 2015, 2015 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), P45, DOI 10.1109/CODESISSS.2015.7331367
   Wang K., 2016, 2016 INT C HARDW SOF, P1
   Wang X., 2016, P IEEE 35 INT PERF C, P1
   Wang XL, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P413, DOI 10.1109/HPCC.2014.70
   Wechsler Ofri, 2019, 2019 IEEE Hot Chips 31 Symposium (HCS), DOI 10.1109/HOTCHIPS.2019.8875671
   Wenshuan, 2018, DRIVING NEW HORIZONS, P4
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   WikiChip, PIX VIS COR PVC GOOG
   WikiChip, NEUR NETW PROC NNP I
   WikiChip, NNP T 1400 INT NERV
   WikiChip, FSD CHIP TESL
   WikiChip, NNP I 1300 INT NERV
   WikiChip, NNP I 1100 INT NERV
   WikiChip, A14 BION APPL
   WikiChip, A13 BION APPL
   WikiChip, NNP T 1300 INT NERV
   Wolfe M, 1996, ACM COMPUT SURV, V28, P261, DOI 10.1145/234313.234417
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Woo M., 1999, OPENGL PROGRAMMING G
   Wu LS, 2014, ACM SIGPLAN NOTICES, V49, P255, DOI 10.1145/2541940.2541961
   Wu LS, 2015, IEEE MICRO, V35, P34, DOI 10.1109/MM.2015.51
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xilinx, 2020, 7 SER PROD SEL GUID
   Xilinx, 2019, VIVADO DESIGN SUITE
   Xilinx, 2018, VIRT ULTR FPGAS
   Xilinx, 1999, VER REF GUID
   Xilinx, 2021, VERS ARCH PROD DAT S
   Xilinx, 2018, XIL DES FLOW INT FPG
   Xilinx, 2021, XIL VIT UN SOFTW PLA
   Xilinx, 2020, SPART 7 FPGAS M COST
   Xilinx, 2015, TECHNICAL REPORT
   Xilinx, 2020, VERS 1 AD COMP ACC P
   Xilinx, 2018, SPART 7
   Xilinx, 2020, ULTRASCALE FPGAS PRO
   Xilinx, 2021, ULTRASCALE ARCHITECT
   Xilinx, 2018, 7 SERIES FPGAS CLOCK
   Xilinx, 2017, WP488 V1 0
   Xilinx, 2020, ULTRASCALE ARCHITECT
   Xin X, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317900
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Xue Y., 2015, INT C VER LARG SCAL, P92
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Yesil S, 2015, ICCAD-IEEE ACM INT, P770, DOI 10.1109/ICCAD.2015.7372648
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Yu HC, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P58, DOI 10.1145/3317550.3321423
   Yu Ji, 2018, ACM SIGPLAN Notices, V53, P448, DOI 10.1145/3296957.3173205
   Zahran M, 2017, COMMUN ACM, V60, P42, DOI 10.1145/3024918
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhao, 2019, OPEN COMPUTE PROJECT
   Zhao Q., 2017, ETCD 17
   Zhu CY, 2020, IEEE T VLSI SYST, V28, P1953, DOI 10.1109/TVLSI.2020.3002779
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
NR 436
TC 11
Z9 11
U1 4
U2 9
PD AUG
PY 2022
VL 129
AR 102561
DI 10.1016/j.sysarc.2022.102561
EA JUN 2022
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Salami, B
   Unsal, OS
   Kestelman, AC
AF Salami, Behzad
   Unsal, Osman S.
   Cristal Kestelman, Adrian
GP IEEE
TI On the Resilience of RTL NN Accelerators: Fault Characterization and
   Mitigation
SO 2018 30TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH
   PERFORMANCE COMPUTING (SBAC-PAD 2018)
SE International Symposium on Computer Architecture and High Performance
   Computing
DT Proceedings Paper
CT 30th International Symposium on Computer Architecture and High
   Performance Computing (SBAC-PAD)
CY SEP 24-27, 2018
CL Lyon, FRANCE
AB Machine Learning (ML) is making a strong resurgence in tune with the massive generation of unstructured data which in turn requires massive computational resources. Due to the inherently compute-and power-intensive structure of Neural Networks (NNs), hardware accelerators emerge as a promising solution. However, with technology node scaling below 10nm, hardware accelerators become more susceptible to faults, which in turn can impact the NN accuracy. In this paper, we study the resilience aspects of Register-Transfer Level (RTL) model of NN accelerators, in particular, fault characterization and mitigation. By following a High-Level Synthesis (HLS) approach, first, we characterize the vulnerability of various components of RTL NN. We observed that the severity of faults depends on both i) application-level specifications, i.e., NN data (inputs, weights, or intermediate) and NN layers and ii) architectural-level specifications, i.e., data representation model and the parallelism degree of the underlying accelerator. Second, motivated by characterization results, we present a low-overhead fault mitigation technique that can efficiently correct bit flips, by 47.3% better than state-of-the-art methods.
C1 [Salami, Behzad; Unsal, Osman S.; Cristal Kestelman, Adrian] BSC, Barcelona, Spain.
   [Salami, Behzad; Cristal Kestelman, Adrian] UPC, Barcelona, Spain.
   [Cristal Kestelman, Adrian] CSIC Spanish Natl Res Council, IIIA Artificial Intelligence Res Inst, Madrid, Spain.
RP Salami, B (corresponding author), BSC, Barcelona, Spain.; Salami, B (corresponding author), UPC, Barcelona, Spain.
EM behzad.salami@bsc.es; osman.unsal@bsc.es; adrian.cristal@bsc.es
CR Andri Renzo, 2018, IEEE T COMPUTER AIDE
   Blackard J.A., 1998, THESIS
   Cardoso-Cachopo A., 2007, THESIS
   Chang K. K., 2017, MEASUREMENT ANAL COM
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   dos Santos A. F., 2017, ARC
   Ernst D., 2003, MICRO
   Guo K, 2017, ARXIV171208934
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   LeCun Y., 1998, IEEE P
   Lee G., 2017, FCCM
   Leveugle R., 2009, DATE
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Miller G., 2007, SINGLE EVENT UPSET M
   Nane R., 2016, IEEE T COMPUTER AIDE
   Phatak D. S., 1995, IEEE T NEURAL NETWOR
   Reagen B., 2016, ACM SIGARCH COMPUTER
   Salami B, 2018, I C FIELD PROG LOGIC, P451, DOI 10.1109/FPL.2018.00085
   Salami B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P724, DOI [10.1109/MICR0.2018.00064, 10.1109/MICRO.2018.00064]
   Stott E., 2014, FCCM
   Sung K., 2018, DATE
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tambara L. A., 2017, IEEE T NUCL SCI
   Tchernev E. B., 2005, NEURAL COMPUTATION
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Tonfat J., 2017, MICPRO
   Torres-Huitzil C., 2017, RECONFIG
   Torres-Huitzil C., 2017, IEEE ACCESS
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Wirthlin M., 2003, FCCM
   Wirthlin M. J., 2004, FPGA
   Yalcin G., 2013, DATE
   Yang L., 2017, ISVLSI
   Yang LT, 2017, INT SYM QUAL ELECT, P7, DOI 10.1109/ISQED.2017.7918284
   Zhang J.J., 2018, P VLSI TEST S VTS 20, P1, DOI 10.1109/VTS.2018.8368656
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
NR 37
TC 44
Z9 44
U1 0
U2 1
PY 2018
BP 322
EP 329
DI 10.1109/SBAC-PAD.2018.00059
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Steffl, S
   Reda, S
AF Steffl, Samuel
   Reda, Sherief
GP IEEE
TI LACore: A Supercomputing-Like Linear Algebra Accelerator for SoC-Based
   Designs
SO 2017 IEEE 35TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 35th IEEE International Conference on Computer Design (ICCD)
CY NOV 05-08, 2017
CL Boston, MA
DE Linear Algebra; Heterogeneous Computing; Accelerator Architectures
ID ARCHITECTURE
AB Linear algebra operations are at the heart of scientific computing solvers, machine learning and artificial intelligence. In this paper, LACore, a novel, programmable accelerator architecture for general-purpose linear algebra applications, is presented. LACore enables many of the architectural features typically available in custom supercomputing machines in an accelerator form factor that can be deployed in System-On-a-Chip (SoC) based designs. LACore has several architectural features including heterogeneous data-streaming LAMemUnits, a configurable systolic datapath that supports scalar, vector and multi-stream output modes, and a decoupled architecture that overlap memory transfer and execution. To evaluate LACore, we implemented its architecture as an extension to the RISC-V ISA in the gem5 cycle-accurate simulator. The LACore ISA was implemented in gcc, and a C-programming software framework, the LACoreAPI, has been developed for high-level programming of the LACore. Using the HPCC benchmark suite, we compare our LACore architecture against three other platforms: an in-order RISC-V CPU, a superscalar x86 CPU with SSE2, and a scaled NVIDIA Fermi GPU. The LACore outperforms the superscalar x86 processor in the benchmark suite by an average of 3.43x, and outperforms the scaled Fermi GPU by an average of 12.04x, within the same or less design area.
C1 [Steffl, Samuel; Reda, Sherief] Brown Univ, Dept CE, Providence, RI 02912 USA.
RP Steffl, S (corresponding author), Brown Univ, Dept CE, Providence, RI 02912 USA.
EM samuel_steffl@brown.edu; sherief_reda@brown.edu
CR Akkas A, 2008, J SYST ARCHITECT, V54, P1129, DOI 10.1016/j.sysarc.2008.05.004
   [Anonymous], 2005, INTRO HPC CHALLENGE
   [Anonymous], 1972, AFIPS 72 1
   [Anonymous], 2006, HPL200686
   Banakar R, 2002, CODES 2002: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON HARDWARE/SOFTWARE CODESIGN, P73, DOI 10.1109/CODES.2002.1003604
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Ciricescu Silviu, 2003, P 36 ANN IEEE ACM IN, P141
   Corbal J., 1999, ACM IEEE C SUP, P15
   Frigo M, 1998, INT CONF ACOUST SPEE, P1381, DOI 10.1109/ICASSP.1998.681704
   Gough B., 2009, GNU SCI LIB REFERENC, V3rd
   Guennebaud G., 2010, EIGEN V3
   Jaiswal MK, 2017, IEEE T CIRCUITS-I, V64, P386, DOI 10.1109/TCSI.2016.2607227
   Jaiswal MK, 2015, IEEE INT CONF VLSI, P213, DOI 10.1109/VLSI-SoC.2015.7314418
   Keller B, 2016, PROC EUR SOLID-STATE, P269, DOI 10.1109/ESSCIRC.2016.7598294
   Lee Yunsup, 2015, UCBEECS2015263
   NVIDIA, 2016, NVID TESL P100
   Power J, 2015, IEEE COMPUT ARCHIT L, V14, P34, DOI 10.1109/LCA.2014.2299539
   Purcell C. J., 1974, P MAY 6 10 1974 NAT, P385
   RUSSELL RM, 1978, COMMUN ACM, V21, P63, DOI 10.1145/359327.359336
   Smith J. E., 1982, 9th Annual Symposium on Computer Architecture, P112
NR 20
TC 6
Z9 6
U1 0
U2 5
PY 2017
BP 137
EP 144
DI 10.1109/ICCD.2017.29
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU De Silva, U
   Mandal, S
   Madanayake, A
   Wei-Kocsis, J
   Belostotski, L
AF De Silva, Udara
   Mandal, Soumyajit
   Madanayake, Arjuna
   Wei-Kocsis, Jin
   Belostotski, Leonid
GP IEEE
TI RF-Rate Hybrid CNN Accelerator based on Analog-CMOS and Xilinx RFSoC
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
AB The superior performance of deep learning (DL) has sent shock waves in the machine learning community. The high adoption rate of DL has set new demands on computational throughput, latency, and power efficiency of the computing infrastructure. In addition to conventional approaches to acceleration of the inference component of DL systems based on GPUs, cloud computing, ASIC/FPGAs and custom vector processors (such as tensor processing units), there is renewed interest in high-frequency analog circuits for DL inference. Analog computing is a potential candidate for meeting challenging requirements in throughput, latency and power efficiency. Because DL inference has superior noise resilience and relatively low accuracy needs (typically less than 8 bits), analog circuits can provide a promising alternative to all-digital accelerators. This paper presents early work on the design of an analog CMOS accelerator that performs analog convolution and decision operations in parallel and in real-time by pairing a high frequency operational amplifier-based CNN filtering kernel with a rectified linear unit (ReLu) non-linearity based on an active precision rectifier circuit. The analog accelerator was designed in a 45 nm CMOS process and simulated in Cadence Spectre. Image convolution results are presented and compared with MATLAB simulations. The proposed solution also employs Xilinx RF System-on-Chip (SoC) devices based on the Xilinx ZCU1285 RFSoC platform to interface digital inputs and outputs with the proposed RF-rate analog inference accelerator.
C1 [De Silva, Udara; Madanayake, Arjuna] Florida Int Univ, Elect & Comp Engn, Miami, FL 33199 USA.
   [Mandal, Soumyajit] Case Western Reserve Univ, Elect Engn & Comp Sci, Cleveland, OH 44106 USA.
   [Wei-Kocsis, Jin] Purdue Univ, Comp & Informat Technol, W Lafayette, IN 47907 USA.
   [Belostotski, Leonid] Univ Calgary, Elect & Comp Engn, Calgary, AB, Canada.
RP Mandal, S (corresponding author), Case Western Reserve Univ, Elect Engn & Comp Sci, Cleveland, OH 44106 USA.
EM sxm833@case.edu; amadanay@fiu.edu; kocsis0@purdue.edu;
   lbelosto@ucalgary.ca
CR ANNEMA AJ, 1994, ELECTRON LETT, V30, P576, DOI 10.1049/el:19940375
   Chen F, 2019, PR GR LAK SYMP VLSI, P423, DOI 10.1145/3299874.3319482
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Gonzalez RC, 2018, IEEE SIGNAL PROC MAG, V35, P79, DOI 10.1109/MSP.2018.2842646
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Mendis GJ, 2019, IEEE T AERO ELEC SYS, V55, P2516, DOI 10.1109/TAES.2019.2891155
   Nagel T. B. Markus, 2019, DATA FREE QUANTIZATI
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/344188
   Raihan MA, 2019, INT SYM PERFORM ANAL, P79, DOI 10.1109/ISPASS.2019.00016
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Stanley W. D., 2002, OPERATIONAL AMPLIFIE
   Sun YA, 2020, IEEE T EVOLUT COMPUT, V24, P394, DOI 10.1109/TEVC.2019.2916183
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Wijenayake C, 2013, IEEE INT SYMP CIRC S, P1276, DOI 10.1109/ISCAS.2013.6572086
   Xie HT, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON PREDICTIVE CONTROL OF ELECTRICAL DRIVES AND POWER ELECTRONICS (PRECEDE 2019), P1, DOI 10.1109/precede.2019.8753190
   Xilinx Inc., ZYNQ ULTR RFSOC DAT
   Yang L, 2018, I SYMPOS LOW POWER E, P285, DOI 10.1145/3218603.3218615
NR 23
TC 0
Z9 0
U1 2
U2 4
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Indirli, F
   Erdem, A
   Silvano, C
AF Indirli, Fabrizio
   Erdem, Ahmet
   Silvano, Cristina
GP IEEE
TI A Tile-based Fused-layer CNN Accelerator for FPGAs
SO 2020 27TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND
   SYSTEMS (ICECS)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 27th IEEE International Conference on Electronics, Circuits and Systems
   (IEEE ICECS)
CY NOV 23-25, 2020
CL ELECTR NETWORK
DE Neural Network hardware accelerators; FPGAs
AB The acceleration of Convolutional Neural Networks (CNNs) on FPGAs is becoming increasingly popular for computer vision tasks. However, the limited memory and bandwidth of these devices pose some challenges to the design of conventional CNN accelerators, which use external DRAM to store the intermediate results of each layer. To mitigate these criticalities, researchers have proposed the fused-layer methodology, which diminishes the accesses to the external DRAM by accelerating simultaneously multiple subsequent layers on the same chip. In this work, we propose a configurable fused-layer accelerator that exploits output tiling and the half-precision float datatype to reduce resource utilization. We assessed its effectiveness with experiments on VGG-16 and Yolo-Lite CNNs, targeting a Xilinx Zynq ZU6EG FPGA. Our design achieved up to 42% speedup and up to 95% fewer transfers from external memory compared to a single-layer baseline solution. Moreover, to ease and quicken the design space exploration, we developed a Machine Learning model that predicts the performance and the resource utilization of our accelerator with an accuracy > 90% on the reported dataset.
C1 [Indirli, Fabrizio; Erdem, Ahmet; Silvano, Cristina] Politecn Milan, Milan, Italy.
RP Indirli, F (corresponding author), Politecn Milan, Milan, Italy.
EM fabrizio.indirli@polimi.it; ahmet.erdem@polimi.it;
   cristina.silvano@polimi.it
CR Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2016, ARXIV160201528
   [Anonymous], 2018, ARXIV180601683
   Erdem A, 2019, IEEE I C ELECT CIRC, P37, DOI [10.1109/icecs46596.2019.8964870, 10.1109/ICECS46596.2019.8964870]
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Simonyan K., 2014, ARXIV180601683
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao ZR, 2018, IEEE T COMPUT AID D, V37, P2348, DOI 10.1109/TCAD.2018.2858384
NR 9
TC 2
Z9 2
U1 0
U2 0
PY 2020
DI 10.1109/icecs49266.2020.9294981
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Alaeddine, H
   Jihene, M
   Khemaja, M
AF Alaeddine, Hmidi
   Jihene, Malek
   Khemaja, Maha
BE Sourin, A
   Rosenberger, C
   Sourina, O
TI An Efficient Deep Network in Network Architecture for Image
   Classification on FPGA Accelerator.
SO 2021 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2021)
DT Proceedings Paper
CT 20th International Conference on Cyberworlds (CW)
CY SEP 28-30, 2021
CL Caen, FRANCE
DE Acceleration; Inference; Profiling; Pynq-Z1; Python; Machine Learning;
   Tensorflow; Classification; CNN; Pre-trained model; Deep Network in
   Network
AB Image recognition and classification apps are considered to be one of the most popular apps in recent times due to its extremely important role in daily life. To improve the energy efficiency and performance of compute-demanding CNN, FPGA-based acceleration appears to be the best solution. In this article, we design and implement a hardware / software accelerator to efficiently accelerate the entificient and reusable FPGA-based accelerator that maximizes the FPGA compute capacity by exploiting the reorganization and parallelism of weights is proposed. The accelerator also supports computation of 3x3 convolutional layers and MLPs layers without interaction with the CPU. This accelerator is integrated into the tensorflow deep learning framework to provide software programmers with an easy-to-use interface so that they can declare a network definition while taking advantage of an FPGA engine. This system implemented on a Xilinx Zynq SoC using the PYNQZ1 platform achieves a frame rate equivalent to 5.91 fps using 16-bit fixed point and an energy efficiency of 186.25x the Intel (R) Xeon (R) processre CNN on FPGAs. First, we use tiling techniques to partition the input data. Second, we integrate the proposed accelerator into the tensorflow deep learning framework. We are evaluating the proposed hardware/software system and its integration with tensorflow by implementing the Deep Network In Network. The proposed accelerator achieves peak performance of 57.6 GOPS on a Xilinx PYNQ-Z1 FPGA board. End-to-end evaluation shows performance and power savings of up to 105.91x compared to an Intel (R) Xeon (R) CPU E5-2620 V4 under the working frequency of 200 MHz and a frame rate equivalent to 3.42 fps using 16-bit fixed point. Using the system with a high-end FPGA shows even higher gains and performance.
C1 [Alaeddine, Hmidi] Monastir Univ, Fac Sci Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
   [Jihene, Malek] Sousse Univ, Higher Inst Appl Sci & Technol Sousse, Sousse 4000, Tunisia.
   [Khemaja, Maha] ISITC, PRINCE Res Grp, Hammam Sousse 4011, Gpi Hammam Sous, Tunisia.
RP Alaeddine, H (corresponding author), Monastir Univ, Fac Sci Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
EM Tunisia.alaeddine.hmidi@fsm.rnu.tn; Tunisia.jihenemalek14@gmail.com;
   mahakhemaja@yahoo.fr
CR Alaeddine H, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON DESIGN & TEST OF INTEGRATED MICRO & NANO-SYSTEMS (DTS), DOI 10.1109/dtss.2019.8915295
   Alaeddine H, 2021, NEURAL COMPUT APPL, V33, P1453, DOI 10.1007/s00521-020-05008-0
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Kiningham Kevin, 2017, DESIGN ANAL HARDWARE, P15
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   VENIERIS SI, 2017, I C FIELD PROG LOGIC, DOI DOI 10.23919/FPL.2017.8056828
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Xilinx, 2018, XIL ML SUIT TOOL DES, P15
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
NR 21
TC 0
Z9 0
U1 0
U2 5
PY 2021
BP 72
EP 77
DI 10.1109/CW52790.2021.00018
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Hubregtsen, T
   Segler, C
   Pichlmeier, J
   Sarkar, A
   Gabor, T
   Bertels, K
AF Hubregtsen, Thomas
   Segler, Christoph
   Pichlmeier, Josef
   Sarkar, Aritra
   Gabor, Thomas
   Bertels, Koen
GP IEEE
TI Integration and Evaluation of Quantum Accelerators for Data-Driven User
   Functions
SO PROCEEDINGS OF THE TWENTYFIRST INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2020)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 21st International Symposium on Quality Electronic Design (ISQED)
CY MAR 25-26, 2020
CL Santa Clara, CA
DE Quantum machine learning; quantum architectures; quantum devices;
   quantum modelling; hybrid quantum/classical algorithms
AB Quantum computers hold great promise for accelerating computationally challenging algorithms on noisy intermediate-scale quantum (NISQ) devices in the upcoming years. Much attention of the current research is directed towards algorithmic research on artificial data that is disconnected from live systems, such as optimization of systems or training of learning algorithms. In this paper we investigate the integration of quantum systems into industry-grade system architectures. In this work we propose a system architecture for the integration of quantum accelerators. In order to evaluate our proposed system architecture we investigated various data-driven functions for various accelerators, including a classical system, a gate-based quantum accelerator and a quantum annealer. The data-driven function predict user preference and is trained on real-world data. This work also includes an evaluation of the quantum enhanced kernel, that previously was only evaluated on artificial data. In our evaluation, we showed that the quantum-enhanced kernel performs at least equally well to a classical state-of-the-art kernel when simulated. We also showed a low reduction in accuracy and latency numbers within acceptable bounds when running on the gate-based IBM quantum accelerator. We therefore conclude it is feasible to integrate NISQ-era devices in industry-grade system architectures in preparation for future advancements in quantum hardware.
C1 [Hubregtsen, Thomas; Segler, Christoph] BMW Grp Res, New Technol, Innovat, Garching, Germany.
   [Hubregtsen, Thomas; Pichlmeier, Josef; Sarkar, Aritra; Bertels, Koen] Delft Univ Technol, Delft, Netherlands.
   [Segler, Christoph] Tech Univ Munich, Dept Informat, Garching, Germany.
   [Gabor, Thomas] Ludwig Maximilians Univ Munchen, Munich, Germany.
RP Hubregtsen, T (corresponding author), BMW Grp Res, New Technol, Innovat, Garching, Germany.; Hubregtsen, T (corresponding author), Delft Univ Technol, Delft, Netherlands.
CR Aaronson S, 2017, LEIBNIZ INT PR INFOR, V79, DOI 10.4230/LIPIcs.CCC.2017.22
   Aleksandrowic Gadi, 2019, QISKIT OPEN SOURCE F
   Almudever Carmen G, 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2010, DYNAMIC PROGRAMMING
   [Anonymous], 2001, PATTERN CLASSIFICATI
   Aramon M, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00048
   Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5
   Bartkiewicz Karol, 2019, EXPT KERNEL BASED QU
   Bertels K., 2019, ARXIV PREPRINT ARXIV
   Booth M, 2016, IEEE HIGH PERF EXTR
   Broy Manfred, P 28 INT C SOFTW ENG, P33
   Chong Frederic, 2018, APS MARCH M ABSTRACT
   Ding Yongcheng, 2019, PREDICTION FINANCIAL
   Fingerhuth M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208561
   Fu X, 2019, MICROPROCESS MICROSY, V70, P21, DOI 10.1016/j.micpro.2019.06.011
   Fu X, 2019, INT S HIGH PERF COMP, P224, DOI 10.1109/HPCA.2019.00040
   Havlicek Vojtech, 2018, SUPERVISED LEARNING
   Huang C., 2019, ARXIV PREPRINT ARXIV
   Ikeda Kazuki, 2019, APPL QUANTUM ANNEALI
   Jung Martin, 2018, FLIGHT GATE ASSIGNME
   Khammassi N, 2017, DES AUT TEST EUROPE, P464, DOI 10.23919/DATE.2017.7927034
   Khammassi Nader, 2018, CQASM V10 COMMON QUA
   Martonosi Margaret, 2019, ARXIV PREPRINT ARXIV
   McGeoch CC, 2019, COMPUTER, V52, P38, DOI 10.1109/MC.2019.2908836
   McKay David C., 2018, ARXIV PREPRINT ARXIV
   Neukart Florian, 2017, TRAFFIC FLOW OPTIMIZ
   Orus Roman, 2019, Reviews in Physics, V4, P115, DOI 10.1016/j.revip.2019.100028
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Pirandola Stefano, 2018, ADV PHOTONIC QUANTUM
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Research and Ltd. Development Group Hitachi, 2019, RES TEAM LED HITACHI
   Riesebos L, 2019, IEEE INT SYMP CIRC S
   Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011
   Van Meter Rodney, 2013, Communications of the ACM, V56, P73, DOI 10.1145/2494568
   Willsch Dennis, 2019, ARXIV PREPRINT ARXIV
   Wright K, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13534-2
NR 36
TC 0
Z9 0
U1 0
U2 1
PY 2020
BP 329
EP 334
DI 10.1109/isqed48828.2020.9137029
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Jia, HY
   Verma, N
AF Jia, Hongyang
   Verma, Naveen
TI Exploiting Approximate Feature Extraction via Genetic Programming for
   Hardware Acceleration in a Heterogeneous Microprocessor
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article; Proceedings Paper
CT 31st Symposium on VLSI Circuits
CY JUN 05-09, 2017
CL Kyoto, JAPAN
DE Approximate computation; feature extraction; machine learning;
   programmable accelerator; sensor inference
ID PROCESSOR
AB This paper presents a heterogeneous microprocessor for low-energy sensor-inference applications. Hardware acceleration has shown to enable substantial energy-efficiency and throughput gains, but raises significant challenges where programmable computations are required, as in the case of feature extraction. To overcome this, a programmable feature-extraction accelerator (FEA) is presented that exploits genetic programming for automatic program synthesis. This leads to approximate, but highly structured, computations, enabling: 1) a high degree of specialization; 2) systematic mapping of programs to the accelerator; and 3) energy scalability via user-controllable approximation knobs. A microprocessor integrating a CPU with feature-extraction and classification accelerators is prototyped in 130-nm CMOS. Two medical-sensor applications (electroencephalogram-based seizure detection and electrocardiogram-based arrhythmia detection) demonstrate 325x and 156x energy reduction, respectively, for programmable feature extraction implemented on the accelerator versus a CPU-only architecture, and 7.6x and 6.5x energy reduction, respectively, versus a CPU-with-coprocessor architecture. Furthermore, 20x and 9x energy scalability, respectively, is demonstrated via the approximation knobs. The energy-efficiency of the programmable FEA is 220 GOPS/W, near that of fixed-function accelerators in the same technology, exceeding typical programmable accelerators.
C1 [Jia, Hongyang; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Jia, HY (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM hjia@princeton.edu; nverma@princeton.edu
CR [Anonymous], 2016, VLSI CIRCUITS 2016 I
   [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jia HY, 2017, SYMP VLSI CIRCUITS, pC28, DOI 10.23919/VLSIC.2017.8008535
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Koopman P. J., 1989, STACK COMPUTERS NEW, P171
   KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355
   Kwong J, 2009, IEEE J SOLID-ST CIRC, V44, P115, DOI 10.1109/JSSC.2008.2007160
   Langdon WB, 2008, LECT NOTES COMPUT SC, V4971, P73, DOI 10.1007/978-3-540-78671-9_7
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Lu J, 2018, IEEE T COMPUT, V67, P222, DOI 10.1109/TC.2017.2738642
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Searson D. P., 2010, P INT MULTICONF ENG, P551
   Shoeb A. H., 2013, P 27 INT C MACH LEAR, P975
   Sridhara SR, 2010, SYMP VLSI CIRCUITS, P15, DOI 10.1109/VLSIC.2010.5560251
   Übeyli ED, 2007, DIGIT SIGNAL PROCESS, V17, P675, DOI 10.1016/j.dsp.2006.11.009
   Walther J.S., 1971, P SPRING JOINT COMP, P379, DOI [10.1145/1478786.1478840, DOI 10.1145/1478786.1478840]
   Wang Z, 2015, IEEE T VLSI SYST, V23, P1459, DOI 10.1109/TVLSI.2014.2342153
NR 21
TC 7
Z9 7
U1 0
U2 6
PD APR
PY 2018
VL 53
IS 4
SI SI
BP 1016
EP 1027
DI 10.1109/JSSC.2017.2787762
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhao, J
   Zhao, YQ
   Li, HB
   Zhang, Y
   Wu, LW
AF Zhao, Jian
   Zhao, Yaqin
   Li, Hongbo
   Zhang, Yun
   Wu, Longwen
GP IEEE
TI HLS-BASED FPGA IMPLEMENTATION OF CONVOLUTIONAL DEEP BELIEF NETWORK FOR
   SIGNAL MODULATION RECOGNITION
SO IGARSS 2020 - 2020 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING
   SYMPOSIUM
SE IEEE International Symposium on Geoscience and Remote Sensing IGARSS
DT Proceedings Paper
CT IEEE International Geoscience and Remote Sensing Symposium (IGARSS)
CY SEP 26-OCT 02, 2020
CL ELECTR NETWORK
DE FPGA; HLS; CDBN; SMR
AB Deep learning method is widely applied in modern artificial intelligence technology for Signal Modulation Recognition (SMR). Compared to CPUs and GPUs, FPGAs are highly energy-efficient and have low-latency streaming capabilities, which are more suitable for energy-sensitive or real-time machine learning projects. High-level synthesis (HLS) can automatically convert the logical structure described by a high-level language into a description by a low-level abstraction language. In this paper, we propose a system to optimize Deep Confidence Network (CDBN) by loops pipelining and unroll, memory buffering and partitioning, and implement an energy-efficient HLS-based FPGA Convolutional CDBN accelerator for SMR based on Virtex-7 platform. The accelerator system run at 150MHz and has 28% higher throughput and 80.5% less power consumption than a GPU implementation.
C1 [Zhao, Jian; Zhao, Yaqin; Li, Hongbo; Zhang, Yun; Wu, Longwen] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
RP Zhao, J (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
CR Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   Mason E, 2017, IEEE RAD CONF, P1703, DOI 10.1109/RADAR.2017.7944481
   Port O., 2017, 27 IEEE INT C FIELD, P1
   Qi Zhang, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1605, DOI 10.1109/ICCT46805.2019.8947168
   Schewior G, 2014, CONF DESIGN ARCHIT, DOI 10.1109/DASIP.2014.7115633
   Shao HD, 2018, IEEE T IND ELECTRON, V65, P2727, DOI 10.1109/TIE.2017.2745473
NR 6
TC 4
Z9 4
U1 0
U2 4
PY 2020
BP 6985
EP 6988
DI 10.1109/IGARSS39084.2020.9324385
WC Computer Science, Artificial Intelligence; Environmental Sciences;
   Geosciences, Multidisciplinary; Remote Sensing; Optics
DA 2023-11-11
ER

PT J
AU Kim, S
   Howe, P
   Moreau, T
   Alaghi, A
   Ceze, L
   Sathe, VS
AF Kim, Sung
   Howe, Patrick
   Moreau, Thierry
   Alaghi, Armin
   Ceze, Luis
   Sathe, Visvesh S.
TI Energy-Efficient Neural Network Acceleration in the Presence of
   Bit-Level Memory Errors
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Neural networks; deep learning; voltage scaling; SRAM; machine learning
   acceleration
AB As a result of the increasing demand for deep neural network (DNN)-based services, efforts to develop hardware accelerators for DNNs are growing rapidly. However, while highly efficient accelerators on convolutional DNNs (Conv-DNNs) have been developed, less progress has been made with regards to fully-connected DNNs. Based on analysis of bit-level SRAM errors, we propose memory adaptive training with in-situ canaries (MATIC), a methodology that enables aggressive voltage scaling of accelerator weight memories to improve the energy-efficiency of DNN accelerators. To enable accurate operation with voltage overscaling, MATIC combines characteristics of SRAM bit failures with the error resilience of neural networks in a memory-adaptive training (MAT) process. Furthermore, PVT-related voltage margins are eliminated using bit-cells from synaptic weights as in-situ canaries to track runtime environmental variation. Demonstrated on a low-power DNN accelerator fabricated in 65 nm CMOS, MATIC enables up to 3.3x energy reduction versus the nominal voltage, or 18.6x application error reduction. We also perform a simulation study that extends MAT to Conv-DNNs, and characterize the accuracy impact of bit failure statistics. Finally, we develop a weight refinement algorithm to improve the performance of MAT, and show that it improves absolute accuracy by 0.8-1.3% or reduces training time by 5-10x.
C1 [Kim, Sung; Howe, Patrick; Sathe, Visvesh S.] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   [Moreau, Thierry; Alaghi, Armin; Ceze, Luis] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
RP Kim, S (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
EM sungk9@uw.edu; pdh4@uw.edu; moreau@cs.washington.edu;
   armin@cs.washington.edu; luisceze@cs.washington.edu; sathe@uw.edu
CR [Anonymous], P DAC
   [Anonymous], OPENMSP430
   [Anonymous], P DAC
   [Anonymous], 2003, TECH REP
   [Anonymous], IEEE INT SOL STAT CI
   [Anonymous], AIM2001004 DEP EL EN
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2007, PATTERN RECOGN, V16
   [Anonymous], 2013, P 30 INT C MACH LEAR
   [Anonymous], 2016, WACV
   Ardakani A, 2018, IEEE T CIRCUITS-I, V65, P1349, DOI 10.1109/TCSI.2017.2757036
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Cannon EH, 2008, IEEE T DEVICE MAT RE, V8, P145, DOI 10.1109/TDMR.2007.912983
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Das S, 2006, IEEE J SOLID-ST CIRC, V41, P792, DOI 10.1109/JSSC.2006.870912
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Grossar E, 2006, IEEE J SOLID-ST CIRC, V41, P2577, DOI 10.1109/JSSC.2006.883344
   Guo Z, 2009, IEEE J SOLID-ST CIRC, V44, P3174, DOI 10.1109/JSSC.2009.2032698
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim S, 2018, DES AUT TEST EUROPE, P1, DOI 10.23919/DATE.2018.8341970
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee EH, 2016, ISSCC DIG TECH PAP I, V59, P418, DOI 10.1109/ISSCC.2016.7418085
   Lin YJ, 2018, IEEE T CIRCUITS-I, V65, P1642, DOI 10.1109/TCSI.2017.2759803
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Qazi M, 2011, IEEE DES TEST COMPUT, V28, P32, DOI 10.1109/MDT.2010.115
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Simonyan K., 2014, VERY DEEP CONVOLUTIO
   Srinivasan G, 2016, DES AUT TEST EUROPE, P151
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Torrey L., 2009, HDB RES MACHINE LEAR, V1, P242, DOI DOI 10.1016/J.JBI.2011.04.009
   Wang JJ, 2007, IEEE CUST INTEGR CIR, P29
   Wang SH, 2017, DES AUT TEST EUROPE, P1032, DOI 10.23919/DATE.2017.7927142
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Yang LT, 2017, INT SYM QUAL ELECT, P7, DOI 10.1109/ISQED.2017.7918284
   Zhang J., 2016, PROC VLSIC, P1
NR 48
TC 27
Z9 27
U1 2
U2 7
PD DEC
PY 2018
VL 65
IS 12
BP 4285
EP 4298
DI 10.1109/TCSI.2018.2839613
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Mittal, S
AF Mittal, Sparsh
TI A survey of FPGA-based accelerators for convolutional neural networks
SO NEURAL COMPUTING & APPLICATIONS
DT Review
DE Deep learning; Neural network (NN); Convolutional NN (CNN); Binarized
   NN; Hardware architecture for machine learning; FPGA; Reconfigurable
   computing; Parallelization; Low power
AB Deep convolutional neural networks (CNNs) have recently shown very high accuracy in a wide range of cognitive tasks, and due to this, they have received significant interest from the researchers. Given the high computational demands of CNNs, custom hardware accelerators are vital for boosting their performance. The high energy efficiency, computing capabilities and reconfigurability of FPGA make it a promising platform for hardware acceleration of CNNs. In this paper, we present a survey of techniques for implementing and optimizing CNN algorithms on FPGA. We organize the works in several categories to bring out their similarities and differences. This paper is expected to be useful for researchers in the area of artificial intelligence, hardware architecture and system design.
C1 [Mittal, Sparsh] Indian Inst Technol, Dept Comp Sci & Engn, Hyderabad, India.
RP Mittal, S (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Hyderabad, India.
EM sparsh@iith.ac.in
CR Abdelouahab K, 2017, IEEE EMBED SYST LETT, V9, P113, DOI 10.1109/LES.2017.2743247
   Abdelouahab K, 2016, ICDSC 2016: 10TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERA, P69, DOI 10.1145/2967413.2967430
   Alwani M., 2016, MICROPAGE, P1
   [Anonymous], ARXIV161102450
   [Anonymous], 2017, ANN IEEE SYM FIELD P, DOI DOI 10.1109/FCCM.2017.43
   [Anonymous], INT C FIELD PROGR LO
   [Anonymous], FPGA
   [Anonymous], ACM COMPUTING SURVEY
   [Anonymous], 2017, TECHNICAL REPORT
   [Anonymous], ARXIV170800052
   [Anonymous], 2017, FPL
   [Anonymous], 2016, 2016 IEEE INT, DOI DOI 10.1109/SiPS.2016.48
   [Anonymous], 2017, 2017 IEEE AER C, DOI DOI 10.1109/AERO.2017.7943929
   [Anonymous], 2015, TECHNICAL REPORT
   [Anonymous], COMP VIS PATT RE WOR
   [Anonymous], 2015, ACCELERATING DEEP CO
   [Anonymous], 2017, P 8 WORKSH 6 WORKSH, DOI DOI 10.1145/3029580.3029586
   [Anonymous], INT S FIELD PROG CUS
   [Anonymous], 2017, ARXIV170800117
   [Anonymous], IEEE SOCC
   Bao SX, 2017, INT CONF CLOUD ENG, P13, DOI 10.1109/IC2E.2017.47
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Courbariaux M., 2016, C NEUR INF PROC SYST
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Feng G, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P624, DOI 10.1109/ICSICT.2016.7998996
   Guan YJ, 2017, LECT NOTES COMPUT SC, V10561, P14, DOI 10.1007/978-3-319-67952-5_2
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Jiao L, 2019, INT J BILINGUAL, V23, P102, DOI 10.1177/1367006917709097
   Li HY, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/6786184
   Li YX, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3154839
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu ZQ, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P61, DOI 10.1109/FPT.2016.7929190
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma Y., 2016, IEEE MTT S INT MICR, P1
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Maguire LP, 2007, NEUROCOMPUTING, V71, P13, DOI 10.1016/j.neucom.2006.11.029
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Meloni P, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P376, DOI 10.1145/2903150.2911715
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Mittal S, 2014, J CIRCUIT SYST COMP, V23, DOI 10.1142/S0218126614300025
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Motamedi M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3131289
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Natale Giuseppe, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P639, DOI 10.1109/ISVLSI.2017.126
   Numata Y, 2017, 2017 24TH INTERNATIONAL WORKSHOP ON ACTIVE-MATRIX FLATPANEL DISPLAYS AND DEVICES (AM-FPD), P1
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Qiao YR, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3850
   Qingcheng Xiao, 2017, 2017 54th ACM/EDAC/IEEE Design Automation Conference (DAC), DOI 10.1145/3061639.3062244
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rahman A, 2017, DES AUT TEST EUROPE, P1147, DOI 10.23919/DATE.2017.7927162
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Shariatmadari H, 2016, 2016 IEEE 27TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P188
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Wang Y, 2016, ACSR ADV COMPUT, V43, P1
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Winograd Shmuel, 1980, SOC IND APPL MATH, P71, DOI DOI 10.1137/1.9781611970364
   Yonekawa H, 2017, IEEE SYM PARA DISTR, P98, DOI 10.1109/IPDPSW.2017.95
   Zhang C, 2016, INT C COMPUTER AIDED, P1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang Xiaofan, 2017, 2017 27 INT C FIELD, P1
   Zhang YW, 2017, IEEE INT C CL COMP, P629, DOI 10.1109/CLUSTER.2017.45
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhao WL, 2016, IEEE INT CONF ASAP, P107, DOI 10.1109/ASAP.2016.7760779
NR 82
TC 166
Z9 173
U1 113
U2 756
PD FEB
PY 2020
VL 32
IS 4
SI SI
BP 1109
EP 1139
DI 10.1007/s00521-018-3761-1
WC Computer Science, Artificial Intelligence
HC Y
HP N
DA 2023-11-11
ER

PT C
AU Bakar, A
   Goel, R
   de Winkel, J
   Huang, J
   Ahmed, S
   Islam, B
   Pawelczak, P
   Yildirim, KS
   Hester, J
AF Bakar, Abu
   Goel, Rishabh
   de Winkel, Jasper
   Huang, Jason
   Ahmed, Saad
   Islam, Bashima
   Pawelczak, Przemyslaw
   Yildirim, Kasim Sinan
   Hester, Josiah
GP ACM
TI Protean: An Energy-Efficient and Heterogeneous Platform for Adaptive and
   Hardware-Accelerated Battery-free Computing
SO PROCEEDINGS OF THE TWENTIETH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR
   SYSTEMS, SENSYS 2022
DT Proceedings Paper
CT 20th ACM Conference on Embedded Networked Sensor Systems (SenSys)
CY NOV 06-09, 2022
CL Boston, MA
DE Protean; Intermittent Computing; Energy Harvesting Platform
ID INTERMITTENT; ARCHITECTURE; POWER; MODEL
AB Battery-free and intermittently powered devices offer long lifetimes and enable deployment in new applications and environments. Unfortunately, developing sophisticated inference-capable applications is still challenging due to the lack of platform support for more advanced (32-bit) microprocessors and specialized accelerators-which can execute data-intensive machine learning tasks, but add complexity across the stack when dealing with intermittent power. We present Protean to bridge the platform gap for inference-capable battery-free sensors. Designed for runtime scalability, meeting the dynamic range of energy harvesters with matching heterogeneous processing elements like neural network accelerators. We develop a modular "plug-and-play" hardware platform, SuperSensor, with a reconfigurable energy storage circuit that powers a 32-bit ARM-based microcontroller with a convolutional neural network accelerator. An adaptive task-based runtime system, Chameleon, provides intermittency-proof execution of machine learning tasks across heterogeneous processing elements. The runtime automatically scales and dispatches these tasks based on incoming energy, current state, and programmer annotations. A code generator, Metamorph, automates conversion of ML models to intermittent safe execution across heterogeneous compute elements. We evaluate Protean with audio and image workloads and demonstrate up to 666x improvement in inference energy efficiency by enabling usage of modern computational elements within intermittent computing. Further, Protean provides up to 166% higher throughput compared to non-adaptive baselines.
C1 [Bakar, Abu; Goel, Rishabh; Ahmed, Saad; Hester, Josiah] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Huang, Jason] Northwestern Univ, Evanston, IL 60208 USA.
   [de Winkel, Jasper; Pawelczak, Przemyslaw] Delft Univ Technol, Delft, Netherlands.
   [Yildirim, Kasim Sinan] Univ Trento, Trento, Italy.
   [Islam, Bashima] Worcester Polytech Inst, Worcester, MA 01609 USA.
RP Bakar, A (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
CR Adkins J, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P188, DOI 10.1109/IPSN.2018.00047
   Afanasov Mikhail, 2020, P 18 C EMB NETW SENS
   Ahmed Saad, 2020, EWSN, P97
   Ahmed Saad, 2019, P 20 ACM SIGPLAN SIG, P70
   Akhunov Khakim, 2022, P ACM INT MOB WEAR U, V6, P1
   Analog Devices, 2020, ARTIF INTELL
   ARM, 2019, UPD ARMS AI JOURN TR
   Bakar A, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3478077
   Bakar A, 2022, PROCEEDINGS OF THE 2022 THE 23RD ANNUAL INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE '22), P22, DOI 10.1145/3508396.3512870
   Bakar A, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL WORKSHOP ON ENERGY HARVESTING & ENERGY-NEUTRAL SENSING SYSTEMS (ENSSYS '18), P32, DOI 10.1145/3279755.3279762
   Balsamo D, 2015, IEEE EMBED SYST LETT, V7, P15, DOI 10.1109/LES.2014.2371494
   Bandara TK, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P918, DOI 10.1145/3503222.3507772
   Colin A, 2018, ACM SIGPLAN NOTICES, V53, P767, DOI [10.1145/3296957.3173210, 10.1145/3173162.3173210]
   Colin A, 2016, ACM SIGPLAN NOTICES, V51, P514, DOI 10.1145/3022671.2983995
   Colin A, 2016, ACM SIGPLAN NOTICES, V51, P577, DOI 10.1145/2954679.2872409
   de Winkel J, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411839
   de Winkel J, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P53, DOI 10.1145/3373376.3378464
   Desai H, 2022, ACM T EMBED COMPUT S, V21, DOI 10.1145/3510850
   Desai H, 2020, IEEE COMPUT ARCHIT L, V19, P68, DOI 10.1109/LCA.2020.2989440
   Durmaz Ç, 2022, IEEE INTERNET THINGS, V9, P20869, DOI 10.1109/JIOT.2022.3176587
   Dutta P, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P267
   Fan Yang, 2021, SenSys '21: Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems, P248, DOI 10.1145/3485730.3485947
   Fraternali F, 2018, BUILDSYS'18: PROCEEDINGS OF THE 5TH CONFERENCE ON SYSTEMS FOR BUILT ENVIRONMENTS, P168, DOI 10.1145/3276774.3282822
   Geissdoerfer K, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P439
   Geissdoerfer K, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P83, DOI 10.1145/3356250.3360042
   Geissdoerfer K, 2019, IPSN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P109, DOI 10.1145/3302506.3310393
   Gobieski G, 2021, CONF PROC INT SYMP C, P1027, DOI 10.1109/ISCA52012.2021.00084
   Gobieski G, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P670, DOI 10.1145/3352460.3358277
   Gobieski G, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P199, DOI 10.1145/3297858.3304011
   Gomez A, 2016, DES AUT TEST EUROPE, P349
   Hester J, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3131673
   Hester J, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3131674
   Hester J, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3131699
   Hester J, 2016, ACM T EMBED COMPUT S, V15, DOI 10.1145/2903140
   Hester J, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P5, DOI 10.1145/2809695.2809707
   Hester Josiah, 2014, P 12 ACM C EMB NETW, P1, DOI 10.1145/2668332.2668336
   Hicks M, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P228, DOI 10.1145/3079856.3080238
   Howe Christopher, 2022, POWERING MICROPROCES
   Infineon, 2020, 8MB EXCELON LP FERR
   Islam B, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411808
   Jackson N, 2019, IPSN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P193, DOI 10.1145/3302506.3310400
   Jagtap D, 2021, IPSN'21: PROCEEDINGS OF THE 20TH ACM/IEEE CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P357, DOI 10.1145/3412382.3458277
   Jayakumar H, 2014, I CONF VLSI DESIGN, P330, DOI 10.1109/VLSID.2014.63
   Kang CK, 2020, IEEE T COMPUT AID D, V39, P3479, DOI 10.1109/TCAD.2020.3012217
   Kirkpatrick Keith, 2014, WORLD WIRES
   Kortbeek V, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P777, DOI 10.1145/3519939.3523454
   Kortbeek V, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3432191
   Kortbeek V, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P85, DOI 10.1145/3373376.3378476
   Kraemer Christopher, 2022, P ACM INT MOB WEAR U, V1, P1
   Krizhevsky Alex, 2009, TECH REP
   Lee S, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P138, DOI 10.1145/3356250.3360030
   Liu V, 2013, ACM SIGCOMM COMP COM, V43, P39, DOI 10.1145/2534169.2486015
   Lucia B, 2021, GETMOBILE-MOB COMPU, V25, P16, DOI 10.1145/3471440.3471446
   Lucia B, 2015, ACM SIGPLAN NOTICES, V50, P575, DOI [10.1145/2813885.2737978, 10.1145/2737924.2737978]
   Lucia Brandon, 2017, 2 SUMM ADV PROGR LAN, V8, P1
   Maeng K, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P129
   Maeng K, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P1005, DOI 10.1145/3385412.3385998
   Maeng K, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133920
   Majid AY, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3360285
   Marcano Gabriel, 2022, LP-IoT'21: Proceedings of the 1st ACM Workshop on No Power and Low Power Internet-of-Things, P8, DOI 10.1145/3477085.3478989
   MATRIX Industries, 2020, NAN EN HARV SYNCHR B
   Maxim Integrated, 2004, 256 TAP NONV SPI INT
   MaximAI, 2022, MAX78000 SDK
   MaximAI, 2020, FAC ID US MAX78000
   Molex, 2020, MOL SLIMSTACK REC
   Mone G, 2017, COMMUN ACM, V60, P12, DOI 10.1145/3048380
   Montanari Alessandro, 2020, SenSys '20: Proceedings of the 18th Conference on Embedded Networked Sensor Systems, P382, DOI 10.1145/3384419.3430782
   Myers James, 2020, PROJECT TRIFFID BILL
   Paradiso JA, 2020, COMMUN ACM, V63, P91, DOI 10.1145/3429952
   Powercast, 2018, POW TX91501B POW
   Powercast, 2016, POW P2110B POW
   PyTorch, 2020, US
   Qoitech, 2020, OT ARC
   Rahmati Amir, 2012, P SEC AUG 8 10, P1
   Ransford B, 2011, ACM SIGPLAN NOTICES, V46, P159, DOI [10.1145/1961296.1950386, 10.1145/1961295.1950386]
   Ruppel E, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P1085, DOI 10.1145/3314221.3314583
   Sample AP, 2008, IEEE T INSTRUM MEAS, V57, P2608, DOI 10.1109/TIM.2008.925019
   Shein E, 2021, COMMUN ACM, V64, P16, DOI 10.1145/3464937
   Sparkfun, 2020, WHAT IS MICROMOD
   Sparkfun, 2020, QWIIC CONN SYST
   Surbatovich M, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P851, DOI 10.1145/3453483.3454081
   Talla V, 2017, COMMUN ACM, V60, P83, DOI 10.1145/3041059
   TensorFlow, 2020, TENSORFLOW LIT MICR
   Texas Instruments, 2020, ULTR POW HARV POW MA
   Texas Instruments Inc, 2017, MSP430FR59XX MIX SIG
   Warden P, 2018, Arxiv, DOI arXiv:1804.03209
   Wu YW, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218526
   Yildirim KS, 2018, SENSYS'18: PROCEEDINGS OF THE 16TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P41, DOI 10.1145/3274783.3274837
   Yildiz E, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P339
   Yildiz Eren, 2020, P 8 INT WORKSH EN HA, P36
   Zhang Hong, 2011, UMCS2011020
NR 91
TC 5
Z9 5
U1 0
U2 0
PY 2022
BP 207
EP 221
DI 10.1145/3560905.3568561
DA 2023-11-11
ER

PT C
AU Aga, S
   Jayasena, N
   Ignatowski, M
AF Aga, Shaizeen
   Jayasena, Nuwan
   Ignatowski, Mike
GP Assoc Comp Machinery
TI Co-ML: A Case for Collaborative ML Acceleration using Near-data
   Processing
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
DE GPU; HBM; machine learning; near-data processing
AB The growing importance of Machine Learning (ML) has led to a proliferation of accelerator designs that target ML workloads. The majority of these designs focus on accelerating compute-intensive regions of ML workloads such as general matrix multiplications (GEMMs) and convolutions. While this is a legitimate approach, we observe in this work that ML workloads also comprise data-intensive computations that manifest low compute-to-byte ratios and can often contribute considerably to the total execution time. Further, we also observe that, the presence of such computations opens up an exciting opportunity for near-data processing (NDP) architectures as they often provision for higher memory bandwidth that can benefit such computations.
   Based on the above observations, in this work we make a case for a more collaborative approach to ML acceleration, termed Co-ML, in which memory plays an active role and is responsible for NDP-amenable computations while the compute-intensive computations are executed on the host accelerator as before. We demonstrate how even a relatively simple NDP design can increase performance of data-intensive computations in ML by up to 20x. Further, for a suite of ML workloads we demonstrate that Co-ML can deliver speedups as high as 20% with average speedups of 14%. Finally, we show that with increasing efforts to build better accelerators for compute-intensive computations, these benefits will likely increase.
C1 [Aga, Shaizeen; Jayasena, Nuwan; Ignatowski, Mike] Adv Micro Devices Inc, AMD Res, Sunnyvale, CA 94088 USA.
RP Aga, S (corresponding author), Adv Micro Devices Inc, AMD Res, Sunnyvale, CA 94088 USA.
EM shaizeen.aga@amd.com; nuwan.jayasena@amd.com; mike.ignatowski@amd.com
CR Abadi Martin, 2016, arXiv
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2019, THE CIFAR 10 DATASET
   [Anonymous], 2019, ROCM NEW ERA OPEN GP
   [Anonymous], 2019, SAMSUNG ELECT INTRO
   [Anonymous], 2019, HIP C HETEROGENEOUS
   [Anonymous], 2014, HYBRID MEMORY CUBE S
   [Anonymous], 2017, LOW POWER ELECT DESI, DOI DOI 10.1109/ISLPED.2017.8009163
   [Anonymous], 2019, RADEON VEGA FRONTIER
   [Anonymous], 2019, HIGH BANDWIDTH MEMOR
   [Anonymous], 2019, AMD RYZENT THREADRIP
   [Anonymous], 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1511.06435
   Bjorck Johan, 2018, P 32 INT C NEUR INF
   Chellapilla Kumar, 2006, 10 INT WORKSH FRONT
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cho J, 2018, PROCEEDINGS OF THE ASME TURBO EXPO: TURBOMACHINERY TECHNICAL CONFERENCE AND EXPOSITION, 2018, VOL 9
   Deng Quan, 2018, P 55 ANN DES AUT C D
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Han Song, 2016, P 43 INT S COMP ARCH
   Han Song, 2015, P 28 INT C NEUR INF, V1
   He K., 2016, P IEEE C COMPUTER VI
   He K., 2015, ARXIV
   Howard A. G., 2017, ARXIV
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim Duckhwan, 2016, P 43 INT S COMP ARCH
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liu J., 2018, 2018 51 ANN IEEE ACM
   Min L., 2014, ICLR
   Nair R, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2409732
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salehinejad H., 2018, RECENT ADV RECURRENT
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sifre L., 2014, CORR
   Silfa F, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243184
   Sim J, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240831
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sutskever I, 2014, ADV NEUR IN, V27
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Zhang Minjia, 2018, P 2018 USENIX C US A
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang X., 2018, 2018 51 ANN IEEE ACM
   Zhu H., 2018, CORR
NR 50
TC 6
Z9 7
U1 0
U2 0
PY 2019
BP 506
EP 517
DI 10.1145/3357526.3357532
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Majumdar, A
   Cadambi, S
   Becchi, M
   Chakradhar, ST
   Graf, HP
AF Majumdar, Abhinandan
   Cadambi, Srihari
   Becchi, Michela
   Chakradhar, Srimat T.
   Graf, Hans Peter
TI A Massively Parallel, Energy Efficient Programmable Accelerator for
   Learning and Classification
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE Design; Performance; Accelerator-based computing; parallel computing;
   heterogeneous computing; machine learning; architecture
ID COPROCESSOR
AB Applications that use learning and classification algorithms operate on large amounts of unstructured data, and have stringent performance constraints. For such applications, the performance of general purpose processors scales poorly with data size because of their limited support for fine-grained parallelism and absence of software-managed caches. The large intermediate data in these applications also limits achievable performance on many-core processors such as GPUs. To accelerate such learning applications, we present a programmable accelerator that can execute multiple learning and classification algorithms. To architect such an accelerator, we profile five representative workloads, and find that their computationally intensive portions can be formulated as matrix or vector operations generating large amounts of intermediate data, which are then reduced by a secondary operation such as array ranking, finding max/min and aggregation. Our proposed accelerator, called MAPLE, has hundreds of simple processing elements (PEs) laid out in a two-dimensional grid, with two key features. First, it uses dynamic in-memory processing where on-chip memory blocks perform the secondary reduction operations. Second, MAPLE uses banked off-chip memory, and organizes its PEs into independent groups each with its own off-chip memory bank. These two features allow MAPLE to scale its performance with data size. We also present an Atom based energy-efficient heterogeneous system with MAPLE as the accelerator that satisfies the application's performance requirements at a lower system power. This article describes the MAPLE architecture, explores its design space with a simulator, illustrates how to automatically map application kernels to the hardware, and presents its performance improvement and energy benefits over classic server-based implementations. We implement a 512-PE FPGA prototype of MAPLE and find that it is 1.5-10x faster than a 2.5 GHz quad-core Xeon processor despite running at a modest 125 MHz clock rate. With MAPLE connected to a 1.6GHz dual-core Atom, we show an energy improvement of 38-84% over the Xeon server coupled to a 1.3 GHz 240 core Tesla GPU.
C1 [Majumdar, Abhinandan; Cadambi, Srihari; Becchi, Michela; Chakradhar, Srimat T.; Graf, Hans Peter] NEC Labs Amer Inc, Princeton, NJ 08540 USA.
RP Majumdar, A (corresponding author), NEC Labs Amer Inc, 4 Independence Way,Suite 200, Princeton, NJ 08540 USA.
EM abhi@nec-labs.com; cadambi@nec-labs.com; mbecchi@nec-labs.com;
   chak@nec-labs.com; hpg@nec-labs.com
CR [Anonymous], ADV KERNEL METHODS S
   [Anonymous], P NEUR INF PROC SYST
   [Anonymous], IEEE T INFO THEORY
   [Anonymous], 2008, P 25 INT C MACHINE L, DOI [10.1145/1390156.1390170, DOI 10.1145/1390156.1390170]
   [Anonymous], P ACM IEEE C SUP
   [Anonymous], P ACM WORKSH GEN PUR
   [Anonymous], 2006, HAL
   [Anonymous], P 12 WORKSH HOT TOP
   [Anonymous], P ANN REC SYST SUMM
   [Anonymous], 2009, LARGE SCALE DEEP UNS
   Bai B, 2010, INFORM RETRIEVAL, V13, P291, DOI 10.1007/s10791-009-9117-9
   Burger D, 2004, COMPUTER, V37, P44, DOI 10.1109/MC.2004.65
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Cosatto E, 2008, INT C PATT RECOG, P672
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Diamond J, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P63, DOI 10.1145/1345206.1345218
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lim K, 2008, CONF PROC INT SYMP C, P315, DOI 10.1109/ISCA.2008.37
   MacQueen J., 1967, P 5 BERK S MATH STAT, P1
   Mei Tao, 2007, P 15 ACM INT C MULTI, P1075
   Nasse F, 2009, LECT NOTES COMPUT SC, V5702, P83, DOI 10.1007/978-3-642-03767-2_10
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Reddi VJ, 2010, CONF PROC INT SYMP C, P314, DOI 10.1145/1816038.1816002
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sato A, 1996, ADV NEUR IN, V8, P423
   Seiler L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360617
   Taylor MB, 2002, IEEE MICRO, V22, P25, DOI 10.1109/MM.2002.997877
NR 28
TC 30
Z9 31
U1 0
U2 6
PD MAR
PY 2012
VL 9
IS 1
AR 6
DI 10.1145/2133382.2133388
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Ni, LB
   Liu, ZC
   Song, WH
   Yang, JJS
   Yu, H
   Wang, KW
   Wang, YG
AF Ni, Leibin
   Liu, Zichuan
   Song, Wenhao
   Yang, J. Joshua
   Yu, Hao
   Wang, Kanwen
   Wang, Yuangang
GP IEEE
TI An Energy-efficient and High-throughput Bitwise CNN on Sneak-path-free
   Digital ReRAM Crossbar
SO 2017 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN (ISLPED)
SE International Symposium on Low Power Electronics and Design
DT Proceedings Paper
CT 22nd IEEE/ACM International Symposium on Low Power Electronics and
   Design (ISLPED)
CY JUL 24-26, 2017
CL Natl Taiwan Univ, Taipei, TAIWAN
HO Natl Taiwan Univ
AB Convolutional neural network (CNN) based machine learning requires a highly parallel as weIl as low power consumption (including leakage power) hardware accelerator. In this paper, we will present a digital ReRAM cross bar based CNN accelerator that can achieve significantly higher throughput and lower power consumption than state-of-arts. The CNN is trained with binary constraints on both weights and activations such that all operations become bitwise. With further use of I-bit comparator, the bitwise CNN model can be naturally realized on a digital ReRAM-crossbar device. A novel sneak-path-free ReRAM-crossbar is further utilized for large-scale realization. Simulation experiments show that the bitwise CNN accelerator on the digital ReRAM crossbar achieves 98.3% and 91. 4% accuracy on MNIST and CIFAR-IO benchmarks, respectively. Moreover, it has a peak throughput of 792GOPS at the power consumption of 6.3mW, which is 18.86 times higher throughput and 44.1 times lower power than CMOS CNN (non-binary) accelerators.
C1 [Ni, Leibin; Liu, Zichuan; Yu, Hao] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Song, Wenhao; Yang, J. Joshua] Univ Massachusetts, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
   [Wang, Kanwen; Wang, Yuangang] Huawei Technol Co Ltd, Data Ctr Technol Lab, Shenzhen, Guangdong, Peoples R China.
RP Yu, H (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM haoyu@ntu.edu.sg
CR [Anonymous], ARXIV161203630
   [Anonymous], 2017, IEEE T COMPUTER AIDE
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   GOLL B, 2009, IEEE INT SOL STAT CI, V329, P328, DOI DOI 10.1109/ISSCC.2009.4977441
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Han S., 2015, ARXIV151000149
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Krizhevsky A, 2014, THE CIFAR 10 DATASET
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Midya R, 2017, ADV MATER, V29, DOI 10.1002/adma.201604457
   Ni LB, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/2996192
   Ni LB, 2016, IEEE INT SYMP CIRC S, P113, DOI 10.1109/ISCAS.2016.7527183
   Ni LB, 2016, ASIA S PACIF DES AUT, P280, DOI 10.1109/ASPDAC.2016.7428024
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Salakhutdinov Ruslan, 2009, ADV NEURAL INFORM PR, P1607
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Yan BN, 2016, IEEE INT SYMP CIRC S, P1390, DOI 10.1109/ISCAS.2016.7527509
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yu SM, 2016, INT EL DEVICES MEET
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 29
TC 0
Z9 0
U1 0
U2 0
PY 2017
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zhao, LT
   Xu, R
   Wang, TQ
   Tian, T
   Wang, XT
   Wu, W
   Ieong, CI
   Jin, X
AF Zhao, Letian
   Xu, Rui
   Wang, Tianqi
   Tian, Teng
   Wang, Xiaotian
   Wu, Wei
   Ieong, Chio-In
   Jin, Xi
TI BaPipe: Balanced Pipeline Parallelism for DNN Training
SO PARALLEL PROCESSING LETTERS
DT Article
DE DNN training; pipeline parallelism; load balancing; parallel and
   distributed systems
AB The size of deep neural networks (DNNs) grows rapidly as the complexity of the machine learning algorithm increases. Distributed deep learning based on model parallelism has been widely used to satisfy the requirements of DNN training related to computation and memory. In this paper, we propose a training framework for pipeline parallelism called BaPipe (Balanced Pipeline) that can automatically explore methods to schedule pipeline parallelism and balanced partition strategies for DNN training on heterogeneous accelerator clusters. In BaPipe, each accelerator calculates the forward and backward propagation for the assigned partition of networks to implement an intra-batch pipeline parallelism strategy. By considering the parameters of DNN models as well as the computation, memory, and communication resources of each accelerator, BaPipe automatically selects the most suitable method of pipeline scheduling from among multiple proposed scheduling modes. It also uses a novel strategy to automatically investigate load balancing in the context of inter-layer partition, intra-layer partition, and coarse-grained partition. We trained such DNNs as VGG-16, ResNet-50, and Google's Neural Machine Translation (GNMT) on GPU clusters, and simulated the training-related performance of FPGA clusters. Compared with the state-of-the-art frameworks for data parallelism (DP) and pipeline parallelism, BaPipe provides a speedup of 3.2x and 4x of memory reduction on various homogeneous and heterogeneous platforms.
C1 [Zhao, Letian; Xu, Rui; Wang, Tianqi; Tian, Teng; Wang, Xiaotian; Wu, Wei; Jin, Xi] Univ Sci & Technol China, State Key Lab Particle Detect & Elect, Hefei 230026, Peoples R China.
   [Zhao, Letian; Xu, Rui; Wang, Tianqi; Tian, Teng; Wang, Xiaotian; Wu, Wei; Jin, Xi] Univ Sci & Technol China, Dept Phys, Inst Microelect, Hefei 230026, Peoples R China.
   [Ieong, Chio-In] Huawei Technol, Shenzhen 518129, Peoples R China.
RP Jin, X (corresponding author), Univ Sci & Technol China, State Key Lab Particle Detect & Elect, Hefei 230026, Peoples R China.; Jin, X (corresponding author), Univ Sci & Technol China, Dept Phys, Inst Microelect, Hefei 230026, Peoples R China.
EM fzhaolt@mail.ustc.edu.cn; xray@mail.ustc.edu.cn;
   tqwang@mail.ustc.edu.cn; tianteng@mail.ustc.edu.cn;
   wxtdsg@mail.ustc.edu.cn; wuw1993@mail.ustc.edu.cn;
   ieong.chio.in@huawei.com; jinxi@ustc.edu.cn
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ben-Nun T, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3320060
   Capes T., 2019, DYNAMIC SCHEDULING M
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fedus William, 2021, SWITCH TRANSFORMERS
   Geng J., 2019, PROC 10 WORKSHOP SCI, P1, DOI DOI 10.1109/ICSIDP47821.2019.9173453
   Geng T, 2018, I C FIELD PROG LOGIC, P394, DOI 10.1109/FPL.2018.00074
   Geng T, 2018, ANN IEEE SYM FIELD P, P81, DOI 10.1109/FCCM.2018.00021
   Gloo, 2020, GLOO
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   He K., 2016, P IEEE C COMPUTER VI
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang YP, 2019, ADV NEUR IN, V32
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jia Zhihao, 2019, P MACH LEARN SYST 20
   Jia Zhihao, 2019, SYSML, V1, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li S., 2020, CHARACTERIZING MODEL
   Li SJ, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING (ICAC 2019), P125, DOI 10.1109/ICAC.2019.00024
   Mayer R, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3363554
   Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646
   Pal S, 2019, IEEE MICRO, V39, P91, DOI 10.1109/MM.2019.2935967
   Park JH, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P307
   Paszke A, 2019, ADV NEUR IN, V32
   Shazeer N, 2018, ADV NEUR IN, V31
   Shoeybi M., 2019, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Wu Y, 2016, ARXIV
   Zhang CL, 2018, INT CON DISTR COMP S, P99, DOI 10.1109/ICDCS.2018.00020
   Zhou QH, 2019, INT CON DISTR COMP S, P196, DOI 10.1109/ICDCS.2019.00028
NR 33
TC 1
Z9 1
U1 1
U2 3
PD SEP
PY 2022
VL 32
IS 03N04
AR 2250005
DI 10.1142/S0129626422500050
EA AUG 2022
WC Computer Science, Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Michel, M
   Burnett, N
AF Michel, Martial
   Burnett, Nicholas
BE Weiland, M
   Juckeland, G
   Alam, S
   Jagode, H
TI Enabling GPU-Enhanced Computer Vision and Machine Learning Research
   Using Containers
SO HIGH PERFORMANCE COMPUTING: ISC HIGH PERFORMANCE 2019 INTERNATIONAL
   WORKSHOPS
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 34th International Conference on High Performance Computing (ISC High
   Performance)
CY JUN 16-20, 2019
CL Frankfurt, GERMANY
DE Computer Vision; Machine Learning; GPU; Docker container
AB Video analytics frameworks often rely on Neural Networks to perform their tasks. For example, a "You Only Look Once" object detection algorithm applies a single neural network to each image, divides the image into regions, and predicts bounding boxes (weighted by the predicted probabilities) with probabilities for each region. Those algorithms often run more efficiently on hardware accelerators. Libraries which use CUDA enabled GPUs can achieve tremendous advances in speed for those functionalities. Frequently, video analytic researchers develop large solutions to allow them to solve problems with complex setup procedures for other researchers to be able to duplicate their efforts. Here we present a software solution that can be run on multiple computer environments without having to customize systems and software, and support the measurement of the performance of machine learning algorithms on disparate datasets. In this publication, we introduce a common base container that provides GPU-optimized access to common Computer Vision (CV) and Machine Learning (ML) libraries, and can be used as the building container (think Docker FROM) for complex analytics to be interactively designed and tested, and as the base for Docker container images that can be shared between analytics researchers.
C1 [Michel, Martial; Burnett, Nicholas] Data Machines Corp, Ashburn, VA 20147 USA.
RP Michel, M (corresponding author), Data Machines Corp, Ashburn, VA 20147 USA.
EM martialmichel@datamachines.io; nicholasburnett@datamachines.io
CR George A, 2016, P TRECVID 2016
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Mariotti K, 2019, SARUS OCI COMPLIANT
NR 3
TC 0
Z9 0
U1 0
U2 0
PY 2020
VL 11887
BP 80
EP 87
DI 10.1007/978-3-030-34356-9_8
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Milan, P
   Rong, HQ
   Michaud, C
   Layad, N
   Liu, ZC
   Coffee, R
AF Milan, Petro
   Rong, Hongqian
   Michaud, Craig
   Layad, Naoufal
   Liu, Zhengchun
   Coffee, Ryan
TI Enabling real-time adaptation of machine learning models at x-ray Free
   Electron Laser facilities with high-speed training optimized
   computational hardware
SO FRONTIERS IN PHYSICS
DT Article
DE AI acceleration; x-ray free electron laser; machine learning; training;
   AI hardware; gpu; sambanova
AB The emergence of novel computational hardware is enabling a new paradigm for rapid machine learning model training. For the Department of Energy's major research facilities, this developing technology will enable a highly adaptive approach to experimental sciences. In this manuscript we present the per-epoch and end-to-end training times for an example of a streaming diagnostic that is planned for the upcoming high-repetition rate x-ray Free Electron Laser, the Linac Coherent Light Source-II. We explore the parameter space of batch size and data parallel training across multiple Graphics Processing Units and Reconfigurable Dataflow Units. We show the landscape of training times with a goal of full model retraining in under 15 min. Although a full from scratch retraining of a model may not be required in all cases, we nevertheless present an example of the application of emerging computational hardware for adapting machine learning models to changing environments in real-time, during streaming data acquisition, at the rates expected for the data fire hoses of accelerator-based user facilities.
C1 [Milan, Petro; Rong, Hongqian; Michaud, Craig] SambaNova Syst Inc, Palo Alto, CA USA.
   [Layad, Naoufal; Coffee, Ryan] LCLS, SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Liu, Zhengchun] DSL, Argonne Natl Lab, Lemont, IL USA.
   [Coffee, Ryan] PULSE Inst, SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
RP Coffee, R (corresponding author), LCLS, SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.; Coffee, R (corresponding author), PULSE Inst, SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM coffee@slac.stanford.edu
CR Coffee RN, 2022, COOK SLIM SIM LCLS S
   Degrave J, 2022, NATURE, V602, P414, DOI 10.1038/s41586-021-04301-9
   Duarte Javier, 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0027-2
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Emani M, 2021, COMPUT SCI ENG, V23, P114, DOI 10.1109/MCSE.2021.3057203
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hansard B., 2020, ADV PHOTON SOURCE UP
   Hartmann N, 2018, NAT PHOTONICS, V12, P215, DOI 10.1038/s41566-018-0107-6
   Layad N., 2022, OPEN SOURCE IMPLEMEN
   Li SQ, 2018, OPT EXPRESS, V26, P4531, DOI 10.1364/OE.26.004531
   Liu ZC, 2021, PROCEEDINGS OF XLOOP 2021: THE 3RD ANNUAL WORKSHOP ON EXTREME-SCALE EXPERIMENT-IN-THE-LOOP COMPUTING, P15, DOI 10.1109/XLOOP54565.2021.00008
   Masters D, 2018, Arxiv, DOI [arXiv:1804.07612, DOI 10.48550/ARXIV.1804.07612]
   McDannald A, 2022, APPL PHYS REV, V9, DOI 10.1063/5.0082956
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Paszke A, 2019, ADV NEUR IN, V32
   PAYNE C, 2019, MUSENET
   SambaNova Systems, 2021, ACC COMP REC DAT ARC
   Sanchez-Gonzalez A, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15461
   Schoenlein R., 2015, SUSTAIN SCI, P1
   Thayer JB., 2018, BUILDING DATA SYSTEM, DOI [10.1109/NSSMIC.2017.8533033, DOI 10.1109/NSSMIC.2017.8533033]
   Therrien AC, 2019, IEEE NUCL SCI CONF R, DOI 10.1109/nss/mic42101.2019.9059671
   Uber I, 2022, HOR
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Walter P, 2021, J SYNCHROTRON RADIAT, V28, P1364, DOI 10.1107/S1600577521007700
   Zhang Chenyu, 2021, Microscopy and Microanalysis, V27, P810, DOI 10.1017/S1431927621003214
NR 25
TC 0
Z9 0
U1 1
U2 1
PD OCT 17
PY 2022
VL 10
AR 958120
DI 10.3389/fphy.2022.958120
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Chan, TCY
   Letourneau, D
   Potter, BG
AF Chan, Timothy C. Y.
   Letourneau, Daniel
   Potter, Benjamin G.
TI Sparse flexible design: a machine learning approach
SO FLEXIBLE SERVICES AND MANUFACTURING JOURNAL
DT Article
DE Process flexibility; Machine learning; Healthcare operations; Radiation
   therapy; Optimization; Network flow
ID PROCESS FLEXIBILITY DESIGN; MANUFACTURING SYSTEMS; LONG-CHAIN;
   NEURAL-NETWORKS; RADIOTHERAPY; OPTIMIZATION; PERFORMANCE; BENEFITS;
   CAPACITY; ACCESS
AB For a general production network, state-of-the-art methods for constructing sparse flexible designs are heuristic in nature, typically computing a proxy for the quality of unseen networks and using that estimate in a greedy manner to modify a current design. This paper develops two machine learning-based approaches to constructing sparse flexible designs that leverage a neural network to accurately and quickly predict the performance of large numbers of candidate designs. We demonstrate that our heuristics are competitive with existing approaches and produce high-quality solutions for both balanced and unbalanced networks. Finally, we introduce a novel application of process flexibility in healthcare operations to demonstrate the effectiveness of our approach in a large numerical case study. We study the flexibility of linear accelerators that deliver radiation to treat various types of cancer. We demonstrate how clinical constraints can be easily absorbed into the machine learning subroutine and how our sparse flexible treatment networks meet or beat the performance of those designed by state-of-the-art methods.
C1 [Chan, Timothy C. Y.; Potter, Benjamin G.] Univ Toronto, Dept Mech & Ind Engn, Toronto, ON M5S 3G8, Canada.
   [Letourneau, Daniel] Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON M5S 2M9, Canada.
RP Potter, BG (corresponding author), Univ Toronto, Dept Mech & Ind Engn, Toronto, ON M5S 3G8, Canada.
EM ben.potter@mail.utoronto.ca
CR Aksin OZ, 2007, OPER RES LETT, V35, P477, DOI 10.1016/j.orl.2006.10.002
   [Anonymous], 2012, STOCH SYST
   Applegate DL, 2009, OPER RES LETT, V37, P11, DOI 10.1016/j.orl.2008.09.006
   Atun R, 2015, LANCET ONCOL, V16, P1153, DOI 10.1016/S1470-2045(15)00222-3
   Bassamboo A, 2012, OPER RES, V60, P1423, DOI 10.1287/opre.1120.1107
   Bello I., 2017, ARXIV161109940, P1
   Bengio Y., 2018, MACHINE LEARNING COM
   Bikker IA, 2015, OPER RES HEALTH CARE, V7, P111, DOI 10.1016/j.orhc.2015.06.005
   Cavalcante IM, 2019, INT J INFORM MANAGE, V49, P86, DOI 10.1016/j.ijinfomgt.2019.03.004
   Chan CW, 2021, OPER RES, V69, P1936, DOI 10.1287/opre.2020.2050
   Chan CW, UTILIZING PARTIAL FL
   Chan TCY, 2019, MANAGE SCI, V65, P1642, DOI 10.1287/mnsc.2017.3004
   Chen S., 2021, SSRN, DOI [10.2139/ssrn.3590865, DOI 10.2139/SSRN.3590865]
   Chen X, 2019, OPER RES, V67, P516, DOI 10.1287/opre.2018.1780
   Chou MC, 2011, OPER RES, V59, P1090, DOI 10.1287/opre.1110.0987
   Chou MC, 2010, EUR J OPER RES, V207, P711, DOI 10.1016/j.ejor.2010.05.038
   Chou MC, 2008, FLEX SERV MANUF J, V20, P59, DOI 10.1007/s10696-008-9053-9
   Chou MC, 2010, OPER RES, V58, P43, DOI 10.1287/opre.1080.0664
   Dai HJ, 2017, ADV NEUR IN, V30
   Delaney G, 2005, CANCER-AM CANCER SOC, V104, P1129, DOI 10.1002/cncr.21324
   Deng TH, 2013, M&SOM-MANUF SERV OP, V15, P24, DOI 10.1287/msom.1120.0390
   Desir A, 2016, OPER RES, V64, P416, DOI 10.1287/opre.2016.1482
   Dong J, 2019, OFF SERVICE PLACEMEN
   Feng WC, 2017, IISE TRANS, V49, P781, DOI 10.1080/24725854.2017.1299953
   Fischetti M, 2017, OPTIMIZATION DECISIO, P203
   Graves SC, 2003, MANAGE SCI, V49, P907, DOI 10.1287/mnsc.49.7.907.16381
   Gupta P., 2020, ARXIV PREPRINT ARXIV
   Gurumurthi S, 2004, NAV RES LOG, V51, P755, DOI 10.1002/nav.20020
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141
   Hopp WJ, 2004, MANAGE SCI, V50, P83, DOI 10.1287/mnsc.1030.0166
   Iravani SM, 2005, MANAGE SCI, V51, P151, DOI 10.1287/mnsc.1040.0333
   JORDAN WC, 1995, MANAGE SCI, V41, P577, DOI 10.1287/mnsc.41.4.577
   Joustra PE, 2012, FLEX SERV MANUF J, V24, P448, DOI 10.1007/s10696-011-9119-y
   Joustra P, 2010, ANN OPER RES, V178, P77, DOI 10.1007/s10479-009-0559-7
   Kaempfer Y., 2018, ABS180309621 CORR
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Larsen E, 2018, ARXIV PREPRINT ARXIV
   Legrain A, 2015, HEALTH CARE MANAG SC, V18, P110, DOI 10.1007/s10729-014-9270-6
   Li SQ, 2015, IEEE ROBOT AUTOM MAG, V22, P51, DOI 10.1109/MRA.2015.2401232
   Mak HY, 2009, FLEX SERV MANUF J, V21, P75, DOI 10.1007/s10696-010-9062-3
   Moore S, 2020, RADIOGRAPHY, V26, pE297, DOI 10.1016/j.radi.2020.04.005
   Price S, 2013, WINT SIMUL C PROC, P2422, DOI 10.1109/WSC.2013.6721616
   Priore P, 2018, COMPUT IND ENG, V126, P282, DOI 10.1016/j.cie.2018.09.034
   Priore P, 2014, AI EDAM, V28, P83, DOI 10.1017/S0890060413000516
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sauré A, 2012, EUR J OPER RES, V223, P573, DOI 10.1016/j.ejor.2012.06.046
   Seward C, 2017, DEEP LEARNING WAREHO
   Sheikhzadeh M, 1998, INT J FLEX MANUF SYS, V10, P351, DOI 10.1023/A:1008057504351
   Simchi-Levi D, 2010, OPERATIONS RULES DEL
   Simchi-Levi D, 2015, OPER RES, V63, P166, DOI 10.1287/opre.2014.1334
   Simchi-Levi D, 2012, OPER RES, V60, P1125, DOI 10.1287/opre.1120.1081
   Smith KA, 1999, INFORMS J COMPUT, V11, P15, DOI 10.1287/ijoc.11.1.15
   Song H, 2020, MANAGE SCI, V66, P3825, DOI 10.1287/mnsc.2019.3395
   Sutskever I, 2014, ADV NEUR IN, V27
   Vieira B, 2016, BMC MED INFORM DECIS, V16, DOI 10.1186/s12911-016-0390-4
   Vinyals O., 2015, ADV NEURAL INFORM PR, P2692, DOI DOI 10.48550/ARXIV.1506.03134
   Wallace R. B., 2005, Manufacturing & Service Operations Management, V7, P276, DOI 10.1287/msom.1050.0086
   Wang X, 2015, OPER RES, V63, P555, DOI 10.1287/opre.2015.1370
   Werker G, 2009, RADIOTHER ONCOL, V92, P76, DOI 10.1016/j.radonc.2009.03.012
   Yan ZZ, 2018, MANAGE SCI, V64, P3421, DOI 10.1287/mnsc.2017.2761
NR 62
TC 1
Z9 1
U1 1
U2 9
PD DEC
PY 2022
VL 34
IS 4
SI SI
BP 1066
EP 1116
DI 10.1007/s10696-021-09439-2
EA FEB 2022
WC Engineering, Industrial; Engineering, Manufacturing; Operations Research
   & Management Science
DA 2023-11-11
ER

PT J
AU Lai, BC
   Pan, JW
   Lin, CY
AF Lai, Bo-Cheng
   Pan, Jyun-Wei
   Lin, Chien-Yu
TI Enhancing Utilization of SIMD-Like Accelerator for Sparse Convolutional
   Neural Networks
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Load balance; machine learning; single-instruction-multiple-data (SIMD)
   architecture; sparse convolutional neural networks (CNNs)
AB Although the existing single-instruction-multiple-data-like (SIMD) accelerators can handle the compressed format of sparse convolutional neural networks, the sparse and irregular distributions of nonzero elements cause low utilization of multipliers in a processing engine (PE) and imbalanced computation between PEs. This brief addresses the above issues by proposing a data screening and task mapping (DSTM) accelerator which integrates a series of techniques, including software refinement and hardware modules. An efficient indexing module is introduced to identify the effectual computation pairs and skip unnecessary computation in a fine-grained manner. The intra-PE load imbalance is alleviated with weight data rearrangement. An effective task sharing mechanism further balances the computation between PEs. When compared with the state-of-the-art SIMD-like accelerator, the proposed DSTM enhances the average PE utilization by 3.5x. The overall processing throughput is 59.7% higher than the previous design.
C1 [Lai, Bo-Cheng; Pan, Jyun-Wei] Natl Chiao Tung Univ, Inst Elect, Hsinchu 30010, Taiwan.
   [Lin, Chien-Yu] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.
RP Lai, BC (corresponding author), Natl Chiao Tung Univ, Inst Elect, Hsinchu 30010, Taiwan.
EM bclai@mail.nctu.edu.tw; s0550233.ee05g@g2.nctu.edu.tw;
   cyulin@cs.washington.edu
CR Accellera Systems Initiative, 2018, SYSTEMC
   Advanced Micro Devices, 2018, HIGH BANDW MEM AMD
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Judd P., 2017, CNVLUTIN2 INEFFECTUA
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   L. P. Hewlett-Packard Development Company, 2008, CACTI INT CACH MEM A
   LIANG ZP, 2017, PROC 22ND INT CONF A, P751
   Lin CY, 2018, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2018.8297290
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Micron Technology, 2018, DRAM MEM STOR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Stanford Vision Lab, 2012, LARG SCAL VIS REC CH
   Transcend, 2018, WHAT AR DAT TRANSF R
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
   Zisserman A., 2014, 14091556 ARXIV
NR 19
TC 8
Z9 8
U1 0
U2 1
PD MAY
PY 2019
VL 27
IS 5
BP 1218
EP 1222
DI 10.1109/TVLSI.2019.2897052
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Mahmoud, M
   Edo, I
   Zadeh, AH
   Awad, OM
   Pekhimenko, G
   Albericio, J
   Moshovos, A
AF Mahmoud, Mostafa
   Edo, Isak
   Zadeh, Ali Hadi
   Awad, Omar Mohamed
   Pekhimenko, Gennady
   Albericio, Jorge
   Moshovos, Andreas
GP IEEE COMP SOC
TI TensorDash: Exploiting Sparsity to Accelerate Deep Neural Network
   Training
SO 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO 2020)
DT Proceedings Paper
CT 53rd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 17-21, 2020
CL ELECTR NETWORK
AB TensorDash is a hardware-based technique that enables data-parallel MAC units to take advantage of sparsity in their input operand streams. When used to compose a hardware accelerator for deep learning, TensorDash can speedup the training process while also increasing energy efficiency. TensorDash combines a low-cost sparse input operand interconnect with an area-ellicient hardware scheduler. The scheduler can effectively extract sparsity in the activations, the weights, and the gradients. Over a wide set of state-of-the-art models covering various applications, TensorDash accelerates the training process by 1.95x while being 1.5.. more energy efficient when incorporated on top of a Tensorcore-based accelerator at less than 5% area overhead. TensorDash is datatype agnostic and we demonstrate it with IEEE standard mixed precision floating point units and a popular optimized for machine learning floating-point format (BFloat16).
C1 [Mahmoud, Mostafa; Edo, Isak; Zadeh, Ali Hadi; Awad, Omar Mohamed] Univ Toronto, Toronto, ON, Canada.
   [Pekhimenko, Gennady; Moshovos, Andreas] Univ Toronto, Vector Inst, Toronto, ON, Canada.
   [Albericio, Jorge] Cerebras Syst, Sunnyvale, CA USA.
RP Mahmoud, M (corresponding author), Univ Toronto, Toronto, ON, Canada.
EM mostafa.mahmoud@mail.utoronto.ca; edoisak@ece.utoronto.ca;
   hadizade@ece.utoronto.ca; awadomar@ece.utoronto.ca;
   pekhimenko@cs.toronto.edu; jorge@cerebras.net; moshovos@ece.utoronto.ca
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Amodei D., OPEN AI BLOG
   [Anonymous], 2019, GAUDI TRAINING PLATF
   [Anonymous], 2012, NEURIPS, DOI DOI 10.5555/2999325.2999464
   [Anonymous], 2017, NVIDIA TESLA V100 GP
   [Anonymous], 2019, CEREBRAS CS1
   Bowman Samuel R., 2015, P 2015 C EMP METH NA, P632, DOI DOI 10.18653/V1/D15-1075
   Burgues J., 2019, 2019 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875651
   Cerebras Systems, 2019, CER WAF SCAL ENG INT
   Chen X, 2019, 2019 IFIP/IEEE SYMPOSIUM ON INTEGRATED NETWORK AND SERVICE MANAGEMENT (IM), P1
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi J., 2018, ARXIV180506085, P1, DOI DOI 10.23919/PANPACIFIC.2018.8319019
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   De Sa Christopher, 2018, ARXIV PREPRINT ARXIV
   Dean J., 2012, P 25 INT C NEURAL IN, VNIPS'12, P1223
   Dettmers T., ARXIV PREPRINT ARXIV
   Drumond Mario, 2018, P 32 INT C NEURAL IN, P451
   Elsken T, 2019, J MACH LEARN RES, V20
   Evans R. D., 2020, ISCA 20
   Golub M., 2018, ARXIV PREPRINT ARXIV
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Google, US BFLOAT16 TENS MOD
   Gupta U, 2019, INT CONFER PARA, P1, DOI 10.1109/PACT.2019.00009
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Hassibi B., 1992, P ADV NEUR INF PROC, V5, DOI DOI 10.5555/645753.668069
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   HewlettPackard, CACTI
   I. Micron Technology, DDR4 POW CALC 4 0
   Iandola F. N., 2016, ARXIV
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P., 2017, CNVLUTIN2 INEFFECTUA
   Kalamkar D., 2019, ARXIV190512322
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   Lee K., 2019, P C N AM CHAPT ASS C, P4171, DOI DOI 10.18653/V1/N19-1423
   Li YF, 2017, IEEE INT CONF ASAP, P1, DOI 10.1109/ASAP.2017.7995252
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Mahmoud M., 2020, ARXIV PREPRINT CSAR
   Mayer R., 2019, SCALABLE DEEP LEARNI
   Merity S., 2017, 5 INT C LEARN REPR I, P1
   Mostafa H, 2019, PR MACH LEARN RES, V97
   NVIDIA, TRAIN MIX PREC
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Rahman R., 2013, INTEL XEON PHI COPRO
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuiki F, 2019, IEEE T COMPUT, V68, P484, DOI 10.1109/TC.2018.2876312
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Sun X, 2017, PR MACH LEARN RES, V70
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang A., 2019, ICLR 19
   Wang N., 2018, ADV NEURAL INFORM PR, P7675, DOI DOI 10.1109/THERMINIC.2018.8593303
   Wang S, 2019, BFLOAT16 SECRET HIGH
   Wen W., 2017, ARXIV170507878, DOI DOI 10.1109/ICC.2017.7997306
   Wu Y., 2019, DETECTRON2, DOI DOI 10.1109/CVPR.2018.00418
   Yang A, 2019, IEEE IMTC P, DOI 10.1109/i2mtc.2019.8826888
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang JQ, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P292, DOI 10.1145/3307650.3322263
   Zhang S., 2016, INTLSYMP MICROARCHIT
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zheng BJ, 2020, ANN I S COM, P1089, DOI 10.1109/ISCA45697.2020.00092
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 79
TC 29
Z9 29
U1 0
U2 0
PY 2020
BP 781
EP 795
DI 10.1109/MICRO50266.2020.00069
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Bauer, W
   Holzinger, P
   Reichenbach, M
   Vaas, S
   Hartke, P
   Fey, D
AF Bauer, Wolfgang
   Holzinger, Philipp
   Reichenbach, Marc
   Vaas, Steffen
   Hartke, Paul
   Fey, Dietmar
BE Mencagli, G
   Heras, DB
TI Programmable HSA Accelerators for Zynq UltraScale plus MPSoC Systems
SO EURO-PAR 2018: PARALLEL PROCESSING WORKSHOPS
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT International European Conference on Parallel and Distributed Computing
   (Euro-Par)
CY AUG 27-28, 2018
CL Turin, ITALY
DE Heterogeneous system architecture; FPGA; Programmable accelerator; HSA
   foundation; Zynq ultrascale; Nyuzi processor
AB Modern algorithms for virtual reality, machine learning or big data find its way into more and more application fields and result in stricter power per watt requirements. This challenges traditional homogeneous computing concepts and drives the development of new, heterogeneous architectures. One idea to attain a balance of high data throughput and flexibility are GPU-like soft-core processors combined with general purpose CPUs as hosts. However, the approaches proposed in recent years are still not sufficient regarding their integration in a shared hardware environment and unified software stack. The approach of the HSA Foundation provides a complete communication definition for heterogeneous systems but lacks FPGA accelerator support. Our work presents a methodology making soft-core processors HSA compliant within MPSoC systems. This enables high level software programming and therefore eases the accessibility of soft-core FPGA accelerators. Furthermore, the integration effort is kept low by fully utilizing the HSA Foundation standards and toolchains.
C1 [Bauer, Wolfgang; Holzinger, Philipp; Reichenbach, Marc; Vaas, Steffen; Fey, Dietmar] Friedrich Alexander Univ Erlangen Nurnberg FAU, Chair Comp Architecture, Dept Comp Sci, Martensstr 3, D-91058 Erlangen, Germany.
   [Hartke, Paul] Xilinx Inc, 2100 Logic Dr, San Jose, CA 95124 USA.
RP Bauer, W (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg FAU, Chair Comp Architecture, Dept Comp Sci, Martensstr 3, D-91058 Erlangen, Germany.
EM WolfgangM.Bauer@fau.de; Philipp.Holzinger@fau.de;
   Marc.Reichenbach@fau.de; Steffen.Vaas@fau.de; phartke@xilinx.com;
   Dietmar.Fey@fau.de
CR Al Kadi M, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P28, DOI 10.1109/FPT.2016.7929185
   Al-Dujaili A, 2012, 2012 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT'12), P57, DOI 10.1109/FPT.2012.6412112
   Altera, 2013, IMPL FPGA DES OPENCL
   AMD, 2016, ROCM OP PLATF DEV DI
   Andryc K, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P230, DOI 10.1109/FPT.2013.6718358
   [Anonymous], 2016, MOB PROC GOES MOB IN
   [Anonymous], HSA FDN SPEC VERS 1
   Bush J, 2016, INT SYM PERFORM ANAL, P204, DOI 10.1109/ISPASS.2016.7482095
   Bush J, 2015, INT SYM PERFORM ANAL, P173, DOI 10.1109/ISPASS.2015.7095803
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Choi J, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P270, DOI 10.1109/FPT.2013.6718365
   Mukherjee S, 2016, INT SYM PERFORM ANAL, P183, DOI 10.1109/ISPASS.2016.7482093
   Rawoof R, 2015, 2015 CONFERENCE ON POWER, CONTROL, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES FOR SUSTAINABLE GROWTH (PCCCTSG), P15, DOI 10.1109/PCCCTSG.2015.7503913
   Reichenbach M., 2017, DES ARCH SIGN IM PRO, P1
   Vaas S, 2016, IEEE SYM PARA DISTR, P181, DOI 10.1109/IPDPSW.2016.143
   Xilinx, 2017, XIL ZYNQ ULTRASCALE
   Xilinx, 2014, XIL SDACCEL DEV ENV
   Xilinx,, 2014, VIVADO DESIGN SUITE
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2019
VL 11339
BP 733
EP 744
DI 10.1007/978-3-030-10549-5_57
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ozga, W
   Quoc, DL
   Fetzer, C
AF Ozga, Wojciech
   Do Le Quoc
   Fetzer, Christof
BE Barker, K
   Ghazinour, K
TI PERUN: Confidential Multi-stakeholder Machine Learning Framework with
   Hardware Acceleration Support
SO DATA AND APPLICATIONS SECURITY AND PRIVACY XXXV
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 35th Annual IFIP WG-11.3 Conference on Data and Applications Security
   and Privacy (DBSec)
CY JUL 19-20, 2021
CL ELECTR NETWORK
DE Multi-stakeholder computation; Machine learning; Confidential computing;
   Trusted computing; Trust management
AB Confidential multi-stakeholder machine learning (ML) allows multiple parties to perform collaborative data analytics while not revealing their intellectual property, such as ML source code, model, or datasets. State-of-the-art solutions based on homomorphic encryption incur a large performance overhead. Hardware-based solutions, such as trusted execution environments (TEEs), significantly improve the performance in inference computations but still suffer from low performance in training computations, e.g., deep neural networks model training, because of limited availability of protected memory and lack of GPU support.
   To address this problem, we designed and implemented Perun, a framework for confidential multi-stakeholder machine learning that allows users to make a trade-off between security and performance. Perun executes ML training on hardware accelerators (e.g., GPU) while providing security guarantees using trusted computing technologies, such as trusted platform module and integrity measurement architecture. Less compute-intensive workloads, such as inference, execute only inside TEE, thus at a lower trusted computing base. The evaluation shows that during the ML training on CIFAR-10 and real-world medical datasets, Perun achieved a 161x to 1560x speedup compared to a pure TEE-based approach.
C1 [Ozga, Wojciech; Fetzer, Christof] Tech Univ Dresden, Dresden, Germany.
   [Ozga, Wojciech] IBM Res Europe Zurich, Ruschlikon, Switzerland.
   [Do Le Quoc] Huawei Munich Res Ctr, Munich, Germany.
   [Fetzer, Christof] Scontain UG, Dresden, Germany.
RP Ozga, W (corresponding author), Tech Univ Dresden, Dresden, Germany.; Ozga, W (corresponding author), IBM Res Europe Zurich, Ruschlikon, Switzerland.
EM woz@zurich.ibm.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   [Anonymous], REUTERS
   Arnautov S, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P689
   Asvadishirehjini A., 2020, ARXIV PREPRINT ARXIV
   Broz Milan, 2018, LUKS DOCUMENTATION
   Chakrabarti S., 2017, ARXIV PREPRINT ARXIV
   Chen GX, 2019, 2019 4TH IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P), P142, DOI 10.1109/EuroSP.2019.00020
   Costan V., 2016, INTEL SGX EXPLAINED, DOI DOI 10.1145/3061639.3062276
   Emont J., AMAZON INVESTIGATES
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Gallery E, 2009, CRYPTOLOGIA, V33, P217, DOI 10.1080/01611190802231140
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Goetzfried J., 2017, P 10 EUR WORKSH SYST
   Gopinath Rahul, 2019, FUZZING BOOK
   Greene James, 2010, INTEL TRUSTED EXECUT
   Gregor F, 2020, I C DEPEND SYS NETWO, P502, DOI 10.1109/DSN48063.2020.00063
   Grover K., 2018, ARXIV PREPRINT ARXIV
   Hunt T., 2018, ARXIV PREPRINT ARXIV
   Hunt T., 2020, 17 USENIX S NETW SYS
   Intel AI, DEEP LEARN MED DEC D
   Intel Corporation, TRUST BOOT TBOOT
   Jang I, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P455, DOI 10.1145/3297858.3304021
   Johnson S., 2016, INTEL SOFTWARE GUARD
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Khandaker MR, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P195
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Knauth T., 2018, ARXIV PREPRINT ARXIV
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kumar Ambuj, 2018, CISC VIS NETW IND GL
   Kumar N, 2020, P IEEE S SECUR PRIV, P336, DOI 10.1109/SP40000.2020.00092
   Quoc DL, 2020, PROCEEDINGS OF THE 2020 21ST INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE '20), P44, DOI 10.1145/3423211.3425687
   Matsakis Nicholas D, 2014, P 2014 ACM SIGADA AN, P103, DOI [DOI 10.1145/2663171.2663188, 10.1145/2692956.2663188]
   MCKEEN F., 2013, P WORKSH HARDW ARCH
   Mishra P, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2505
   Mohassel P, 2017, P IEEE S SECUR PRIV, P19, DOI [10.1109/SP.2017.12, 10.1145/3132747.3132768]
   muslc, MUSL LIBC
   Ng L.K., 2019, 35 AAAI C ART INT
   Noor TH, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522980
   Ohrimenko O, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P619
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sailer R, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P223
   Scontain UG., SCONE CONF ATT SERV
   Shin Jacob, 2013, TCG D RTM ARCHITECTU
   Simpson Amber L, 2019, ARXIV190209063
   Tramer Florian, 2019, 7 INT C LEARN REPR I
   Trusted Computing Group, 2016, TCG RES TPM 2 0 LIB
   Trusted Computing Group TCG, 2019, TCG TRUST ATT PROT T
   Tsai CC, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P645
   Van Bulck J, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P991
   Volgushev N, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303982
   Volos S, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P681
   Weisse Ofir, 2018, TECHNICAL REPORT
   Xu TY, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P244, DOI 10.1145/2517349.2522727
   Yao A. C., 1982, 23rd Annual Symposium on Foundations of Computer Science, P160, DOI 10.1109/SFCS.1982.38
   Zinzindohoué JK, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1789, DOI 10.1145/3133956.3134043
NR 57
TC 1
Z9 1
U1 2
U2 5
PY 2021
VL 12840
BP 189
EP 208
DI 10.1007/978-3-030-81242-3_11
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Sidiropoulos, H
   Chatzikonstantis, G
   Soudris, D
   Strydis, C
AF Sidiropoulos, Harry
   Chatzikonstantis, George
   Soudris, Dimitrios
   Strydis, Christos
GP IEEE
TI The VINEYARD framework for heterogeneous cloud applications: The
   BrainFrame case
SO 2018 CONFERENCE ON DESIGN AND ARCHITECTURES FOR SIGNAL AND IMAGE
   PROCESSING (DASIP)
SE Conference on Design and Architectures for Signal and Image Processing
DT Proceedings Paper
CT 12th Conference on Design and Architectures for Signal and Image
   Processing (DASIP)
CY OCT 10-12, 2018
CL Porto, PORTUGAL
DE reconfigurable computing; hardware accelerators; FPGAs; neurocomputing;
   cloud computing
AB Emerging cloud applications like machine learning, AI, big data analytics and scientific computing require high-performance computing systems that can sustain the increased amount of data processing without consuming excessive power. To this end, many cloud operators have started deploying hardware accelerators, like GPUs and FPGAs, to increase the performance of computationally intensive tasks. However, increased performance, comes at a higher cost of increased programming complexity for utilizing these accelerators. VINEYARD has developed a versatile framework that allows the seamless deployment and utilization of heterogeneous accelerators in the cloud without increasing the programming complexity while offering the flexibility of software packages. This paper presents the main components that have been developed in the VINEYARD framework and focuses on BrainFrame, the neurocomputing case that demonstrates the new framework's value. BrainFrame not only accelerates neuronal simulations but also has an architecture that allows easy access to neuroscientists, hiding the system complexity, and enabling a modular integration of new accelerated simulators.
C1 [Sidiropoulos, Harry; Chatzikonstantis, George; Soudris, Dimitrios] ICCS, Sch ECE, Athens, Greece.
   [Strydis, Christos] Erasmus MC, Univ Med Ctr Rotterdam, Dept Neurosci, Rotterdam, Netherlands.
RP Sidiropoulos, H (corresponding author), ICCS, Sch ECE, Athens, Greece.
EM harry@microlab.ntua.gr; georgec@microlab.ntua.gr;
   dsoudris@microlab.ntua.gr; c.strydis@erasmusmc.nl
CR Apache Spark, UN AN ENG LARG SCAL
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chatzikonstantis George, 2017, High Performance Computing. ISC High Performance 2017 International Workshops DRBSD, ExaComm, HCPM, HPC-IODC, IWOPH, IXPUG, P^3MA, VHPC, Visualization at Scale, WOPSSS. Revised Selected Papers: LNCS 10524, P363, DOI 10.1007/978-3-319-67630-2_27
   Intel, INT OP PROGR ACC ENG
   Jeffers J, 2016, INTEL XEON PHI PROCE
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Mavridis S, 2017, I C FIELD PROG LOGIC
   PyNN, SIM IND LANG BUILD N
   Smaragdos G, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7fc5
   van Albada Sacha J., 2018, FRONTIERS NEUROSCIEN, V12
   WULFRAM G, 2002, SPIKING NEURON MODEL
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2018
BP 70
EP 75
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Yuan, BH
   Jankov, D
   Zou, J
   Tang, YX
   Bourgeois, D
   Jermaine, C
AF Yuan, Binhang
   Jankov, Dimitrije
   Zou, Jia
   Tang, Yuxin
   Bourgeois, Daniel
   Jermaine, Chris
TI Tensor Relational Algebra for Distributed Machine Learning System Design
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article
AB We consider the question: what is the abstraction that should be implemented by the computational engine of a machine learning system? Current machine learning systems typically push whole tensors through a series of compute kernels such as matrix multiplications or activation functions, where each kernel runs on an AI accelerator (ASIC) such as a GPU. This implementation abstraction provides little built-in support for ML systems to scale past a single machine, or for handling large models with matrices or tensors that do not easily fit into the RAM of an ASIC. In this paper, we present an alternative implementation abstraction called the tensor relational algebra (TRA). The TRA is a set-based algebra based on the relational algebra. Expressions in the TRA operate over binary tensor relations, where keys are multi-dimensional arrays and values are tensors. The TRA is easily executed with high efficiency in a parallel or distributed environment, and amenable to automatic optimization. Our empirical study shows that the optimized TRA-based back-end can significantly outperform alternatives for running ML workflows in distributed clusters.
C1 [Yuan, Binhang; Jankov, Dimitrije; Tang, Yuxin; Bourgeois, Daniel; Jermaine, Chris] Rice Univ, Houston, TX 77251 USA.
   [Zou, Jia] Arizona State Univ, Tempe, AZ 85287 USA.
RP Yuan, BH (corresponding author), Rice Univ, Houston, TX 77251 USA.
EM by8@rice.edu; dj16@rice.edu; jia.zou@asu.edu; yuxin.tang@rice.edu;
   dcb10@rice.edu; cmj4@rice.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aberger CR, 2018, PROC INT CONF DATA, P449, DOI 10.1109/ICDE.2018.00048
   Agarwal RC, 1995, IBM J RES DEV, V39, P575, DOI 10.1147/rd.395.0575
   [Anonymous], 2015, DASK PARALLEL COMPUT, DOI [10.25080/Majora-7b98-3ed-013, DOI 10.25080/MAJORA-7B98-3ED-013]
   Balay S., 2019, PETSC USERS MANUAL
   Barcelo Pablo, 2019, P 3 INT WORKSH DAT M, P9
   Barker B., 2015, WORKSH HIGH PERF COM, V262
   Baumann P., 1998, SIGMOD Record, V27, P575, DOI 10.1145/276305.276386
   Brown P G, 2010, SIGMOD 10, P963, DOI DOI 10.1145/1807167.1807271
   Cai Zhuhua, 2013, SIGMOD, DOI [DOI 10.1145/2463676.2465283, 10.1145/2463676]
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   CHOI JY, 1992, FRONTIERS 92 : THE FOURTH SYMPOSIUM ON THE FRONTIERS OF MASSIVELY PARALLEL COMPUTATION, P120, DOI 10.1109/FMPC.1992.234898
   D Team, 2016, DEEPLEARNING4J OPEN, V2, P2
   Dai J, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P50, DOI 10.1145/3357223.3362707
   de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24
   Dolmatova O, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2573, DOI 10.1145/3318464.3389747
   Ghoting A, 2011, PROC INT CONF DATA, P231, DOI 10.1109/ICDE.2011.5767930
   Gu R, 2017, IEEE T PARALL DISTR, V28, P2539, DOI 10.1109/TPDS.2017.2686384
   Han D, 2019, INT CONF MANAGE DATA, P759, DOI 10.1145/3299869.3319865
   Hunter T, 2016, AREA SPARK MEETUP
   Hutchison Dylan, 2017, P 4 ACM SIGMOD WORKS, V2, P1, DOI 10.1145
   Jankov D, 2019, PROC VLDB ENDOW, V12, P822, DOI 10.14778/3317315.3317323
   Jasny M, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P159, DOI 10.1145/3318464.3380575
   Khamis M., 2018, P 2018 INT C ADV VIS, P1
   Khamis MA, 2018, PODS'18: PROCEEDINGS OF THE 37TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P325, DOI 10.1145/3196959.3196960
   Khamis MA, 2016, PODS'16: PROCEEDINGS OF THE 35TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P13, DOI 10.1145/2902251.2902280
   Kim M., 2014, P 2014 ACM CIKM INT, P969
   Kim M, 2014, P 23 ACM INT C CONFE, P2039, DOI 10.1145/2661829.2661842
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Laue S, 2020, AAAI CONF ARTIF INTE, V34, P4527
   Li Shen, PROC VLDB ENDOW, V13, P12
   Li XP, 2017, PROC VLDB ENDOW, V10, P1933, DOI 10.14778/3137765.3137812
   Luo SY, 2019, IEEE T KNOWL DATA EN, V31, P1224, DOI 10.1109/TKDE.2018.2827988
   McAuley J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2783258.2783381
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Moritz P., 2015, ARXIV PREPRINT ARXIV
   Solomonik E, 2011, LECT NOTES COMPUT SC, V6853, P90, DOI 10.1007/978-3-642-23397-5_10
   VanDeGeijn RA, 1997, CONCURRENCY-PRACT EX, V9, P255, DOI 10.1002/(SICI)1096-9128(199704)9:4<255::AID-CPE250>3.0.CO;2-2
   Vasilache N., 2018, ARXIV PREPRINT ARXIV
   Warden Pete., 2018, ARXIV PREPRINT ARXIV
   Zaharia M., 2010, P 2 USENIX C HOT TOP
NR 41
TC 8
Z9 8
U1 0
U2 1
PD APR
PY 2021
VL 14
IS 8
BP 1338
EP 1350
DI 10.14778/3457390.3457399
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Wang, M
   Yang, TJ
   Flechas, MA
   Harris, P
   Hawks, B
   Holzman, B
   Knoepfel, K
   Krupa, J
   Pedro, K
   Tran, N
AF Wang, Michael
   Yang, Tingjun
   Flechas, Maria Acosta
   Harris, Philip
   Hawks, Benjamin
   Holzman, Burt
   Knoepfel, Kyle
   Krupa, Jeffrey
   Pedro, Kevin
   Tran, Nhan
TI GPU-Accelerated Machine Learning Inference as a Service for Computing in
   Neutrino Experiments
SO FRONTIERS IN BIG DATA
DT Article
DE machine learning; heterogeneous (CPU plus GPU) computing; GPU (graphics
   processing unit); particle physics; cloud computing (SaaS)
AB Machine learning algorithms are becoming increasingly prevalent and performant in the reconstruction of events in accelerator-based neutrino experiments. These sophisticated algorithms can be computationally expensive. At the same time, the data volumes of such experiments are rapidly increasing. The demand to process billions of neutrino events with many machine learning algorithm inferences creates a computing challenge. We explore a computing model in which heterogeneous computing with GPU coprocessors is made available as a web service. The coprocessors can be efficiently and elastically deployed to provide the right amount of computing for a given processing task. With our approach, Services for Optimized Network Inference on Coprocessors (SONIC), we integrate GPU acceleration specifically for the ProtoDUNE-SP reconstruction chain without disrupting the native computing workflow. With our integrated framework, we accelerate the most time-consuming task, track and particle shower hit identification, by a factor of 17. This results in a factor of 2.7 reduction in the total processing time when compared with CPU-only production. For this particular task, only 1 GPU is required for every 68 CPU threads, providing a cost-effective solution.
C1 [Wang, Michael; Yang, Tingjun; Flechas, Maria Acosta; Hawks, Benjamin; Holzman, Burt; Knoepfel, Kyle; Pedro, Kevin; Tran, Nhan] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Harris, Philip; Krupa, Jeffrey] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Tran, Nhan] Northwestern Univ, Evanston, IL USA.
RP Wang, M (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM mwang@fnal.gov
CR Aaij R, 2020, Comput Softw Big Sci, V4, P7, DOI 10.1007/s41781-020-00039-7
   Abi B, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/12/P12004
   Abi B, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/t08008
   Abi B., 2020, ARXIV200615052
   Acciarri R, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/03/P03011
   Acciarri R, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/02/P02017
   Adams C, 2019, PHYS REV D, V99, DOI 10.1103/PhysRevD.99.092001
   [Anonymous], ABS151203385 CORR
   [Anonymous], 1998, TECH REP
   Aurisano A, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/09/P09001
   Ayres D.S., 2007, NOVA TECHNICAL DESIG, DOI DOI 10.2172/935497
   Bocci A, 2020, EPJ WEB CONF, V245, DOI 10.1051/epjconf/202024505009
   Capozzi F, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.131803
   Caulfield AM, 2016, INT SYMP MICROARCH
   Dominé L, 2020, PHYS REV D, V102, DOI 10.1103/PhysRevD.102.012005
   Duarte Javier, 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0027-2
   DUNE Collaboration, 2016, J PHYS C SER, V718, DOI 10.1088/1742-6596/718/6/062032
   Garren L., 2020, LARRECODNN VERSION V
   Graham B., 2017, SUBMANIFOLD SPARSE C
   Halzen F, 2010, REV SCI INSTRUM, V81, DOI 10.1063/1.3480478
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Krupa J., 2020, ARXIV200710359
   Kubernetes, 2020, LINUX FDN CONCEPTS W
   Marshall J., 2013, INT C CAL HIGH EN FR, P305
   MICHEL L, 1950, P PHYS SOC LOND A, V63, P514, DOI 10.1088/0370-1298/63/5/311
   Nunokawa H, 2008, PROG PART NUCL PHYS, V60, P338, DOI 10.1016/j.ppnp.2007.10.001
   Nvidia, 2019, TRITON
   Pappalardo A., 2020, XILINXBREVITAS PRETR, DOI [10.5281/zenodo.3979501, DOI 10.5281/ZENODO.3979501]
   Pedro K., 2019, SONICCMS VERSION V5
   Pietropaolo F, 2017, J PHYS CONF SER, V888, DOI 10.1088/1742-6596/888/1/012038
   Qian X, 2015, PROG PART NUCL PHYS, V83, P1, DOI 10.1016/j.ppnp.2015.05.002
   Rohr D, 2020, EPJ WEB CONF, V245, DOI 10.1051/epjconf/202024510005
   Scholberg K, 2012, ANNU REV NUCL PART S, V62, P81, DOI 10.1146/annurev-nucl-102711-095006
   Sfiligoi Igor, 2020, High Performance Computing. 35th International Conference, ISC High Performance 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12151), P23, DOI 10.1007/978-3-030-50743-5_2
   Snider E. L., 2017, Journal of Physics: Conference Series, V898, DOI 10.1088/1742-6596/898/4/042057
   Summers, 2020, ARXIV200610159
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
NR 37
TC 7
Z9 7
U1 0
U2 5
PD JAN 14
PY 2021
VL 3
AR 604083
DI 10.3389/fdata.2020.604083
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Zhang, F
   Petersen, M
   Johnson, L
   Hall, J
   O'Bryant, SE
AF Zhang, Fan
   Petersen, Melissa
   Johnson, Leigh
   Hall, James
   O'Bryant, Sid E.
TI Accelerating Hyperparameter Tuning in Machine Learning for Alzheimer's
   Disease With High Performance Computing
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
DT Article
DE machine learning; hyperparameter tuning; alzheimer's disease; high
   performance computing; support vector machine
ID BIOMARKERS; DISCOVERY; ALGORITHM
AB Driven by massive datasets that comprise biomarkers from both blood and magnetic resonance imaging (MRI), the need for advanced learning algorithms and accelerator architectures, such as GPUs and FPGAs has increased. Machine learning (ML) methods have delivered remarkable prediction for the early diagnosis of Alzheimer's disease (AD). Although ML has improved accuracy of AD prediction, the requirement for the complexity of algorithms in ML increases, for example, hyperparameters tuning, which in turn, increases its computational complexity. Thus, accelerating high performance ML for AD is an important research challenge facing these fields. This work reports a multicore high performance support vector machine (SVM) hyperparameter tuning workflow with 100 times repeated 5-fold cross-validation for speeding up ML for AD. For demonstration and evaluation purposes, the high performance hyperparameter tuning model was applied to public MRI data for AD and included demographic factors such as age, sex and education. Results showed that computational efficiency increased by 96%, which helped to shed light on future diagnostic AD biomarker applications. The high performance hyperparameter tuning model can also be applied to other ML algorithms such as random forest, logistic regression, xgboost, etc.
C1 [Zhang, Fan; Petersen, Melissa; Johnson, Leigh; Hall, James; O'Bryant, Sid E.] Univ North Texas, Hlth Sci Ctr, Inst Translat Res, Ft Worth, TX 76107 USA.
   [Zhang, Fan; Petersen, Melissa] Univ North Texas, Dept Family Med, Hlth Sci Ctr, Ft Worth, TX 76107 USA.
   [Johnson, Leigh; Hall, James; O'Bryant, Sid E.] Univ North Texas, Dept Pharmacol & Neurosci, Hlth Sci Ctr, Ft Worth, TX 76107 USA.
RP Zhang, F; O'Bryant, SE (corresponding author), Univ North Texas, Hlth Sci Ctr, Inst Translat Res, Ft Worth, TX 76107 USA.; Zhang, F (corresponding author), Univ North Texas, Dept Family Med, Hlth Sci Ctr, Ft Worth, TX 76107 USA.; O'Bryant, SE (corresponding author), Univ North Texas, Dept Pharmacol & Neurosci, Hlth Sci Ctr, Ft Worth, TX 76107 USA.
EM fan.zhang@unthsc.edu; sid.obryant@unthsc.edu
CR Arevalo-Rodriguez I, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010783.pub2
   Corporation M, 2020, DOPARALLEL FOREACH P
   Eddelbuettel D, 2021, WIRES COMPUT STAT, V13, DOI 10.1002/wics.1515
   Franzmeier N, 2020, ALZHEIMERS DEMENT, V16, P501, DOI 10.1002/alz.12032
   Grassi M, 2018, J ALZHEIMERS DIS, V61, P1555, DOI 10.3233/JAD-170547
   Hampel H, 2018, NAT REV NEUROL, V14, P639, DOI 10.1038/s41582-018-0079-7
   Hsu C.W., 2003, PRACTICAL GUIDE SUPP
   Khan A., 2020, JMIR BIOMED ENG, V5, DOI [10.2196/14389, DOI 10.2196/14389]
   Kublanov VS, 2017, APPL BIONICS BIOMECH, V2017, DOI 10.1155/2017/5985479
   Lee Kuok Leong, 2019, Journal of Physics: Conference Series, V1372, DOI 10.1088/1742-6596/1372/1/012065
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Marcus DS, 2010, J COGNITIVE NEUROSCI, V22, P2677, DOI 10.1162/jocn.2009.21407
   Merelli I, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/825649
   O'Bryant SE, 2020, ALZH DEMENT-DADM, V12, DOI 10.1002/dad2.12033
   O'Bryant SE, 2019, ALZH DEMENT-DADM, V11, P374, DOI 10.1016/j.dadm.2019.03.001
   O'Bryant SE, 2018, J ALZHEIMERS DIS, V66, P97, DOI 10.3233/JAD-180619
   O'Bryant SE, 2017, ALZHEIMERS DEMENT, V13, P45, DOI 10.1016/j.jalz.2016.09.014
   O'Bryant Sid E, 2016, Alzheimers Dement (Amst), V3, P83, DOI 10.1016/j.dadm.2016.06.004
   O'Bryant SE, 2014, J ALZHEIMERS DIS, V42, P1325, DOI 10.3233/JAD-141041
   O'Bryant SE, 2013, J ALZHEIMERS DIS, V34, P841, DOI 10.3233/JAD-122074
   O'Bryant SE, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028092
   O'Bryant SE, 2011, DEMENT GERIATR COGN, V32, P55, DOI 10.1159/000330750
   Podcasy JL, 2016, DIALOGUES CLIN NEURO, V18, P437
   Prevention C. F. D. C. A., 2021, ALZHEIMERS DIS HLTH
   Rodriguez S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21330-0
   Roe CM, 2011, ARCH NEUROL-CHICAGO, V68, P1145, DOI 10.1001/archneurol.2011.192
   Schmidt B, 2017, DRUG DISCOV TODAY, V22, P712, DOI 10.1016/j.drudis.2017.01.014
   Stamate D, 2019, ALZH DEMENT-TRCI, V5, P933, DOI 10.1016/j.trci.2019.11.001
   Waring S, 2008, TEXAS PUBLIC HLTH J, V60, P9
   Weiner Michael W, 2015, Alzheimers Dement, V11, pe1, DOI 10.1016/j.jalz.2014.11.001
   Weston S., 2020, FOREACH FOREACH LOOP
   Zetterberg H, 2019, MOL BRAIN, V12, DOI 10.1186/s13041-019-0448-1
   Zhang F, 2021, J ALZHEIMERS DIS, V79, P1691, DOI 10.3233/JAD-201254
   Zhang ZW, 2019, COMPUT BIOL MED, V108, P354, DOI 10.1016/j.compbiomed.2019.02.017
NR 34
TC 3
Z9 3
U1 2
U2 12
PY 2021
VL 4
AR 798962
DI 10.3389/frai.2021.798962
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Tennant, C
   Carpenter, A
   Powers, T
   Solopova, AS
   Vidyaratne, L
   Iftekharuddin, K
AF Tennant, Chris
   Carpenter, Adam
   Powers, Tom
   Solopova, Anna Shabalina
   Vidyaratne, Lasitha
   Iftekharuddin, Khan
TI Superconducting radio-frequency cavity fault classification using
   machine learning at Jefferson Laboratory
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB We report on the development of machine learning models for classifying C100 superconducting radio-frequency (SRF) cavity faults in the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. CEBAF is a continuous-wave recirculating linac utilizing 418 SRF cavities to accelerate electrons up to 12 GeV through five passes. Of these, 96 cavities (12 cryomodules) are designed with a digital low-level rf system configured such that a cavity fault triggers waveform recordings of 17 rf signals for each of the eight cavities in the cryomodule. Subject matter experts are able to analyze the collected time-series data and identify which of the eight cavities faulted first and classify the type of fault. This information is used to find trends and strategically deploy mitigations to problematic cryomodules. However, manually labeling the data is laborious and time consuming. By leveraging machine learning, near real-time-rather than postmortem-identification of the offending cavity and classification of the fault type has been implemented. We discuss performance of the machine learning models during a recent physics run. Results show the cavity identification and fault classification models have accuracies of 84.9% and 78.2%, respectively.
C1 [Tennant, Chris; Carpenter, Adam; Powers, Tom; Solopova, Anna Shabalina; Vidyaratne, Lasitha] Jefferson Lab, Newport News, VA 23606 USA.
   [Iftekharuddin, Khan] Old Dominion Univ, Norfolk, VA 23529 USA.
RP Tennant, C (corresponding author), Jefferson Lab, Newport News, VA 23606 USA.
CR Adderly P., PHYS REV ACCEL BEAMS
   Bishop C.M., 2006, INFORM SCI STAT, P627, DOI DOI 10.1117/1.2819119
   Box GE, 2015, TIME SERIES ANAL FOR
   Daly E, 2005, REN FPC END GROUP TR
   Davis K., 2012, P 26 LIN C LINAC 12, P240
   Davis K, 2005, P 12 INT WORKSH RF S, P619
   Edelen A., ARXIV181103172
   Gebru T., ARXIV180309010V7
   Hovater C., 2010, P 25 LIN ACC C LINAC, P280
   Mitchell M., ARXIV181003993V2
   Nanopoulos A, 2001, INFORMATION PROCESSING AND TECHNOLOGY, P49
   Nawaz AS, 2016, CONF CONTR FAULT-TOL, P196, DOI 10.1109/SYSTOL.2016.7739750
   Powers T, 1993, P 6 WORKSHOP RF SUPE, P1
   Powers T., 2019, P 19 INT C RF SUP SR, P763, DOI 10.18429/JACoWSRF2019-WETEB3
   Reece CE, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.124801
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   statsmodels.tsa.ar_model, AUTOREG
   Tennant C., 2020, 20011 JEFF LAB
   Van Sciver S, 1986, HELIUM CRYOGENICS, P141
   Wang L, 2008, LECT NOTES ARTIF INT, V5012, P369, DOI 10.1007/978-3-540-68125-0_33
   Wang XZ, 2007, IEEE DATA MINING, P351, DOI 10.1109/ICDM.2007.103
   White G, 2019, P 10 INT PART ACC C, P1216
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
   Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18
   Xu D., 2015, ANN DATA SCI, V2, P165, DOI 10.1007/s40745-015-0040-1
NR 26
TC 23
Z9 25
U1 0
U2 4
PD NOV 30
PY 2020
VL 23
IS 11
AR 114601
DI 10.1103/PhysRevAccelBeams.23.114601
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Kundu, S
   Soyyigit, A
   Hoque, KA
   Basu, K
AF Kundu, Shamik
   Soyyigit, Ahmet
   Hoque, Khaza Anuarul
   Basu, Kanad
GP IEEE
TI High-level Modeling of Manufacturing Faults in Deep Neural Network
   Accelerators
SO 2020 26TH IEEE INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN (IOLTS 2020)
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 26th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 13-16, 2020
CL ELECTR NETWORK
DE Neural Network Accelerator; Tensor Processing Unit (TPU); Probabilistic
   Model Checking; Stuck-at Faults
AB The advent of data-driven real-time applications requires the implementation of Deep Neural Networks (DNNs) on Machine Learning accelerators. Google's Tensor Processing Unit (TPU) is one such neural network accelerator that uses systolic array-based matrix multiplication hardware for computation in its crux. Manufacturing faults at any state element of the matrix multiplication unit can cause unexpected errors in these inference networks. In this paper, we propose a formal model of permanent faults and their propagation in a TPU using the Discrete-Time Markov Chain (DTMC) formalism. The proposed model is analyzed using the probabilistic model checking technique to reason about the likelihood of faulty outputs. The obtained quantitative results show that the classification accuracy is sensitive to the type of permanent faults as well as their location, bit position and the number of layers in the neural network. The conclusions from our theoretical model have been validated using experiments on a digit recognition-based DNN.
C1 [Kundu, Shamik; Basu, Kanad] Univ Texas Dallas, Dallas, TX 75080 USA.
   [Soyyigit, Ahmet; Hoque, Khaza Anuarul] Univ Missouri, Columbia, MO USA.
RP Kundu, S (corresponding author), Univ Texas Dallas, Dallas, TX 75080 USA.
EM shamik.kundu@utdallas.edu; as3ff@mail.missouri.edu; hoquek@missouri.edu;
   kanad.basu@utdallas.edu
CR [Anonymous], 2013, P INT WORKSH FORM TE
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Hansson H., 1994, Formal Aspects of Computing, V6, P512, DOI 10.1007/BF01211866
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KIM JH, 1989, IEEE T COMPUT, V38, P515, DOI 10.1109/12.21144
   Kung, 1983, TECH REP
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kwiatkowska M, 2002, LECT NOTES COMPUT SC, V2324, P200
   Kwiatkowska M, 2007, LECT NOTES COMPUT SC, V4486, P220
   Zhang J, 2018, IEEE VLSI TEST SYMP
NR 10
TC 11
Z9 11
U1 0
U2 0
PY 2020
DI 10.1109/iolts50870.2020.9159704
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Caliari, C
   Oeftiger, A
   Boine-Frankenheim, O
AF Caliari, Conrad
   Oeftiger, Adrian
   Boine-Frankenheim, Oliver
TI Identification of magnetic field errors in synchrotrons based on deep
   Lie map networks
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB Magnetic field errors pose a limitation in the performance of synchrotrons, as they excite nonsystematic resonances, reduce dynamic aperture, and may result in beam loss. Their effect can be compensated by assuming knowledge of their location and strength. Established identification procedures are based on orbit response matrices or resonance driving terms. While they sequentially build a field error model for subsequent accelerator sections, a method detecting field errors in parallel could save valuable beam time. We introduce deep Lie map networks, which enable the construction of an accelerator model including multipole components for the magnetic field errors by linking charged particle dynamics with machine learning methodology in a data-driven approach. Based on simulated beam position monitor readings for the example case of SIS18 at GSI, we demonstrate inference of location and strengths of gradient and sextupole errors for all accelerator sections in parallel. The obtained refined accelerator model may support setup of corrector magnets in operation to allow more precise control over tunes, chromaticities, and resonance compensation.
C1 [Caliari, Conrad; Boine-Frankenheim, Oliver] Tech Univ Darmstadt, Inst Accelerator Sci & Electromagnet Fields, Schlossgarten Str 8, D-64289 Darmstadt, Germany.
   [Oeftiger, Adrian; Boine-Frankenheim, Oliver] GSI Helmholtzzentrum Schwerionenforsch GmbH, Planck Str 1, D-64291 Darmstadt, Germany.
RP Caliari, C (corresponding author), Tech Univ Darmstadt, Inst Accelerator Sci & Electromagnet Fields, Schlossgarten Str 8, D-64289 Darmstadt, Germany.
CR Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Appel S, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.054201
   Barth W, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.050102
   Bartholomew-Biggs M, 2000, J COMPUT APPL MATH, V124, P171, DOI 10.1016/S0377-0427(00)00422-2
   Bergstra J., 2011, ADV NEURAL INFORM PR, V24, DOI 10.5555/2986459.2986743
   Berz M., 2015, INTRO BEAM PHYS
   Bezanson J, 2017, SIAM REV, V59, P65, DOI 10.1137/141000671
   Cai SZ, 2021, J HEAT TRANS-T ASME, V143, DOI 10.1115/1.4050542
   Caliari C., 2021, THESIS TU DARMSTADT
   Zeiler MD, 2012, Arxiv, DOI [arXiv:1212.5701, DOI 10.48550/ARXIV.1212.5701]
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Franczak B., 1987, GSISISTN8713
   Grote H, 2003, PROCEEDINGS OF THE 2003 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P3497
   Herr W., 2020, NONLINEAR DYNAMICS A
   Innes M., 2018, J OPEN SOURCE SOFTW, DOI [DOI 10.21105/JOSS.00602, 10.21105/joss.00602]
   Ivanov A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.074601
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Krishnapriyan A., 2021, ADV NEURAL INF PROCE, V34, P26548, DOI DOI 10.48550/ARXIV.2109.01050
   Ondreka D., 2019, P 10 INT PART ACC C, P932
   Parfenova A, 2011, NUCL INSTRUM METH A, V646, P7, DOI 10.1016/j.nima.2011.03.051
   Qiang J, 2023, PHYS REV ACCEL BEAMS, V26, DOI 10.1103/PhysRevAccelBeams.26.024601
   Rackauckas C., 2020, AAAI SPRING S MLPS
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Safranek J, 1997, NUCL INSTRUM METH A, V388, P27, DOI 10.1016/S0168-9002(97)00309-4
   Schwinzerl M., 2021, OPTIMISING EXTENDING
   Tomás R, 2005, PHYS REV SPEC TOP-AC, V8, DOI 10.1103/PhysRevSTAB.8.024001
   YOSHIDA H, 1990, PHYS LETT A, V150, P262, DOI 10.1016/0375-9601(90)90092-3
NR 27
TC 0
Z9 0
U1 0
U2 0
PD JUN 2
PY 2023
VL 26
IS 6
AR 064601
DI 10.1103/PhysRevAccelBeams.26.064601
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Shoji, T
   Waidyasooriya, HM
   Ono, T
   Hariyama, M
   Aoki, Y
   Kondoh, Y
   Nakagawa, Y
AF Shoji, Tomoki
   Waidyasooriya, Hasitha Muthumala
   Ono, Taisuke
   Hariyama, Masanori
   Aoki, Yuichiro
   Kondoh, Yuki
   Nakagawa, Yaoko
GP IEEE
TI A Memory-Bandwidth-Efficient Word2vec Accelerator Using OpenCL for FPGA
SO 2019 SEVENTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING
   WORKSHOPS (CANDARW 2019)
DT Proceedings Paper
CT 7th International Symposium on Computing and Networking (CANDAR)
CY NOV 26-29, 2019
CL Nagasaki, JAPAN
DE Word embedding; FPGA; machine learning; natural language processing;
   data compression
AB Word2vec is a word embedding method that converts words into vectors in such a way that the semantically and syntactically relevant words are closed to each other in the vector space. FPGAs can be used to design low-power accelerators for Word2vec. FPGAs use highly parallel computations which require parallel data access. Since FPGAs generally have a small external memory access bandwidth compared to CPUs and GPUs, the processing speed is often restricted. We evaluate the trade-off between bandwidth and accuracy using different fixed-point formats, and propose a memory-bandwidth-efficient FPGA accelerator by utilizing 19-bit fixed-point data. We have implemented the proposed accelerator on an Intel Arria 10 FPGA using OpenCL, and achieved upto 28% bandwidth reduction without any degradation to the computation accuracy. Since the reduced bandwidth allows us to access more data without any data access bottleneck, it is possible to increase the processing speed by increasing the degree of parallelism.
C1 [Shoji, Tomoki; Waidyasooriya, Hasitha Muthumala; Ono, Taisuke; Hariyama, Masanori] Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-3-09 Aramaki Aza Aoba, Sendai, Miyagi 9808579, Japan.
   [Aoki, Yuichiro; Kondoh, Yuki; Nakagawa, Yaoko] Hitachi Ltd, Res & Dev Grp, Kokubunji, Tokyo 1858601, Japan.
RP Shoji, T (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-3-09 Aramaki Aza Aoba, Sendai, Miyagi 9808579, Japan.
EM tomoki.shoji.ql@dc.tohoku.ac.jp; hasitha@tohoku.ac.jp;
   ono52@dc.tohoku.ac.jp; hariyama@tohoku.ac.jp;
   yuichiro.aoki.jk@hitachi.co; yuki.kondo.fe@hitachi.co;
   yaoko.nakagawa.gn@hitachi.co
CR Agrawal RK, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P6, DOI 10.1109/ICCMC.2017.8282627
   [Anonymous], 2012, P INT C ENG RECONFIG
   [Anonymous], 2016, ARXIV160404661
   [Anonymous], 2015, 32 ICML
   Bai X, 2014, IEEE INT CONGR BIG, P358, DOI 10.1109/BigData.Congress.2014.59
   Canny J, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P233, DOI 10.1109/BigData.2015.7363760
   Chelba C., 2014, ARXIV PREPRINT ARXIV
   Goldberg Y., 2014, CORR
   Ji S., 2016, P NIPS WORKSH EFF ME
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, P3294, DOI DOI 10.5555/2969442.2969607
   Liu YF, 2014, INT C DIGITAL HOME, P8, DOI 10.1109/ICDH.2014.9
   Ma L, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2895, DOI 10.1109/BigData.2015.7364114
   Mikolov T., 2013, NIPS, P3111
   Mikolov T., 2013, P WORKSHOP ICLR
   Ono T, 2019, IEEE INT SYMP CIRC S
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Rengasamy V., 2017, P 7 WORKSH IRR APPL, P3
   Seong H, 2016, 2016 URSI ASIA-PACIFIC RADIO SCIENCE CONFERENCE (URSI AP-RASC), P269, DOI 10.1109/URSIAP-RASC.2016.7601160
   Simonton T. M., 2017, HIGH PERF EXTR COMP, P1
   Waidyasooriya H., 2017, DESIGN FPGA BASED CO
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 103
EP 108
DI 10.1109/CANDARW.2019.00026
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Parashar, A
   Rhu, M
   Mukkara, A
   Puglielli, A
   Venkatesan, R
   Khailany, B
   Emer, J
   Keckler, SW
   Dally, WJ
AF Parashar, Angshuman
   Rhu, Minsoo
   Mukkara, Anurag
   Puglielli, Antonio
   Venkatesan, Rangharajan
   Khailany, Brucek
   Emer, Joel
   Keckler, Stephen W.
   Dally, William J.
GP Assoc Comp Machinery
TI SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks
SO 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017)
DT Proceedings Paper
CT 44th Annual International Symposium on Computer Architecture (ISCA)
CY JUN 24-28, 2017
CL Toronto, CANADA
DE Convolutional neural networks; accelerator architecture
AB Convolutional Neural Networks (CNNs) have emerged as a fundamental technology for machine learning. High performance and extreme energy efficiency are critical for deployments of CNNs, especially in mobile platforms such as autonomous vehicles, cameras, and electronic personal assistants. This paper introduces the Sparse CNN (SCNN) accelerator architecture, which improves performance and energy efficiency by exploiting the zero-valued weights that stem from network pruning during training and zero-valued activations that arise from the common ReLU operator. Specifically, SCNN employs a novel dataflow that enables maintaining the sparse weights and activations in a compressed encoding, which eliminates unnecessary data transfers and reduces storage requirements. Furthermore, the SCNN dataflow facilitates efficient delivery of those weights and activations to a multiplier array, where they are extensively reused; product accumulation is performed in a novel accumulator array. On contemporary neural networks, SCNN can improve both performance and energy by a factor of 2.7x and 2.3x, respectively, over a comparably provisioned dense CNN accelerator.
C1 [Parashar, Angshuman; Rhu, Minsoo; Venkatesan, Rangharajan; Khailany, Brucek; Emer, Joel; Keckler, Stephen W.; Dally, William J.] NVIDIA, Santa Clara, CA 95051 USA.
   [Mukkara, Anurag; Emer, Joel] MIT, Cambridge, MA 02139 USA.
   [Puglielli, Antonio] Univ Calif Berkeley, Berkeley, CA USA.
   [Dally, William J.] Stanford Univ, Stanford, CA 94305 USA.
RP Parashar, A (corresponding author), NVIDIA, Santa Clara, CA 95051 USA.
EM aparashar@nvidia.com
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M, 2016, INT SYMP MICROARCH
   Amodei D, 2015, COMPUTER SCI
   [Anonymous], 2012, IMAGENET CLASSIFICAT
   [Anonymous], 2003, THESIS UC BERKELEY
   Caffe, 2017, CAFF MOD ZOO
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Diamos G, 2016, PR MACH LEARN RES, V48
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gao Huang, 2016, DEEP NETWORKS STOCHA
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hannun A., 2014, DEEP SPEECH SCALING
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Martin G, 2009, IEEE DES TEST COMPUT, V26, P18, DOI 10.1109/MDT.2009.83
   Mentor, 2017, CAT HIGH LEV SYNTH
   NVIDIA, 2016, NVIDIA CUDNN
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Rhu M, 2016, INT SYMP MICROARCH
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Venkatesh G., 2016, ACCELERATING DEEP CO
   Zhang SJ, 2016, INT SYMP MICROARCH
NR 32
TC 589
Z9 601
U1 2
U2 27
PY 2017
BP 27
EP 40
DI 10.1145/3079856.3080254
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Perina, AB
   Bonato, V
AF Perina, Andre Bannwart
   Bonato, Vanderlei
GP IEEE
TI Mapping Estimator for OpenCL Heterogeneous Accelerators
SO 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT
   2018)
DT Proceedings Paper
CT 17th International Conference on Field-Programmable Technology (FPT)
CY DEC 10-14, 2018
CL Naha, JAPAN
AB To increase computing performance while keeping energy consumption to an acceptable budget, heterogeneous systems are currently investigated. By using dedicated compute units as accelerators to speedup specific parts of an application, hardware resources are better utilised resulting in a more energy efficient computing system. However, the task of performing such application mapping to accelerators is still a challenge, requiring knowledge beyond software domain in order to understand which part of the code fits better to the capability of the hardware available. Currently, there are tools supporting unified frontends and languages to simplify the programming of such heterogeneous systems, however there is still a high dependency of the user to manually perform the final mapping process. This work exposes a machine learning framework used to automatically infer the most suitable accelerator (between FPGA and GPU) for a given code by statically estimating energy efficiency. This framework can be used to assist the developer in deciding the best mapping for its application with an average hit-rate of 85 percent.
C1 [Perina, Andre Bannwart; Bonato, Vanderlei] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
RP Perina, AB (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
EM abperina@usp.br; vbonato@usp.br
CR Agarwal A, 2010, IEEE EMBED SYST LETT, V2, P72, DOI 10.1109/LES.2010.2055231
   Aji AM, 2015, IEEE INT C CL COMP, P42, DOI 10.1109/CLUSTER.2015.15
   [Anonymous], 2015, P 3 INT WORKSH OOENC
   [Anonymous], OPENCL OP STAND PAR
   [Anonymous], 2016, P ACM DES AUT C
   [Anonymous], 2013, IFAC P, DOI DOI 10.3182/20130619-3-RU-3018.00196
   [Anonymous], LLVM COMPILER INFRAS
   [Anonymous], 2016, INT C HIGH PERF COMP
   Brodtkorb AR, 2010, SCI PROGRAMMING-NETH, V18, P1, DOI 10.3233/SPR-2009-0296
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Choi YK, 2017, ICCAD-IEEE ACM INT, P691
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   Grewe D, 2011, LECT NOTES COMPUT SC, V6601, P286, DOI 10.1007/978-3-642-19861-8_16
   Paone E, 2015, DES AUT TEST EUROPE, P736
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Wang S., 2017, DESIGN AUTOMATION C, P1
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
NR 17
TC 0
Z9 0
U1 0
U2 1
PY 2018
BP 297
EP 300
DI 10.1109/FPT.2018.00057
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Neshatpour, K
   Malik, M
   Homayoun, H
AF Neshatpour, Katayoun
   Malik, Maria
   Homayoun, Houman
GP IEEE
TI Accelerating Machine-Learning Kernels in Hadoop Using FPGAs
SO 2015 15TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID
   COMPUTING
SE IEEE-ACM International Symposium on Cluster Cloud and Grid Computing
DT Proceedings Paper
CT 2015 15th IEEE ACM International Symposium on Cluster Cloud and Grid
   Computing (CCGrid 2015)
CY MAY 04-07, 2015
CL Shenzhen, PEOPLES R CHINA
DE Big data; acceleration; FPGA
AB Big data applications share inherent characteristics that are fundamentally different from traditional desktop CPU, parallel and web service applications. They rely on deep machine learning and data mining applications. A recent trend for big data analytics is to provide heterogeneous architectures to allow support for hardware specialization to construct the right processing engine for analytics applications. However, these specialized heterogeneous architectures require extensive exploration of design aspects to find the optimal architecture in terms of performance and cost. This paper analyzes how offloading computational intensive kernels of machine learning algorithms to a heterogeneous CPU+FPGA platform enhances the performance. We use the latest Xilinx Zynq boards for implementation and result analysis. Furthermore, we perform a comprehensive analysis of communication and computation overheads such as data I/O movements, and calling several standard libraries that can not be offloaded to the accelerator to understand how the speedup of each application will contribute to its overall execution in an end-to-end Hadoop MapReduce environment.
C1 [Neshatpour, Katayoun; Malik, Maria; Homayoun, Houman] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
RP Neshatpour, K (corresponding author), George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
CR Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Dean Jeffrey, 2004, P C S OP SYST DES IM
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Honjo T, 2013, IEEE INT CONF BIG DA
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Shan Y, 2010, FPGA 10, P93
   Van Craeynest K, 2012, CONF PROC INT SYMP C, P213, DOI 10.1109/ISCA.2012.6237019
   White T., 2009, HADOOP DEFINITIVE GU
NR 8
TC 16
Z9 17
U1 0
U2 7
PY 2015
BP 1151
EP 1154
DI 10.1109/CCGrid.2015.165
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Kao, SC
   Jeong, G
   Krishna, T
AF Kao, Sheng-Chun
   Jeong, Geonhwa
   Krishna, Tushar
GP IEEE COMP SOC
TI ConfuciuX: Autonomous Hardware Resource Assignment for DNN Accelerators
   using Reinforcement Learning
SO 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO 2020)
DT Proceedings Paper
CT 53rd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 17-21, 2020
CL ELECTR NETWORK
DE DNN Accelerator; Machine Learning; Reinforcement Learning; Genetic
   Algorithm
ID LOW-POWER; OPTIMIZATION; EXPLORATION; DESIGN
AB DNN accelerators provide efficiency by leveraging reuse of activations/weights/outputs during the DNN computations to reduce data movement from DRAM to the chip. The reuse is captured by the accelerator's dataflow. While there has been significant prior work in exploring and comparing various datallows, the strategy for assigning on-chip hardware resources (i.e., compute and memory) given a dataflow that can optimize for performance/energy while meeting platform constraints of area/power for DNN(s) of interest is still relatively unexplored. The design-space of choices for balancing compute and memory explodes combinatorially, as we show in this work (e.g., as large as O(10(72)) choices for running MobileNet-V2), making it infeasible to do manual-tuning via exhaustive searches. It is also difficult to come up with a specific heuristic given that different DNNs and layer types exhibit different amounts of reuse.
   In this paper, we propose an autonomous strategy called Con-fuciuX to find optimized HW resource assignments for a given model and dataflow style. ConfuciuX leverages a reinforcement learning method, REINFORCE, to guide the search process, leveraging a detailed HW performance cost model within the training loop to estimate rewards. We also augment the RL approach with a genetic algorithm for further fine-tuning. Con-fuciuX demonstrates the highest sample-efficiency for training compared to other techniques such as Bayesian optimization, genetic algorithm, simulated annealing, and other RL methods. It converges to the optimized hardware configuration 4.7 to 24 times faster than alternate techniques.
C1 [Kao, Sheng-Chun; Krishna, Tushar] Georgia Inst Technol, Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Jeong, Geonhwa] Georgia Inst Technol, Comp Sci, Atlanta, GA 30332 USA.
RP Kao, SC (corresponding author), Georgia Inst Technol, Elect & Comp Engn, Atlanta, GA 30332 USA.
EM felix@gatech.edu; geonhwa.jeong@gatech.edu; tushar@ece.gatech.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdelfattah Mohamed S, 2020, ARXIV PREPRINT ARXIV
   Ahn B. H., 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, OPENAI GYM
   [Anonymous], 2017, NVDLA DEEP LEARNING
   [Anonymous], STARS BARS COMBINATO
   [Anonymous], 2020, MAESTRO TOOL
   [Anonymous], 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, 2017 IEEEACM INT S L
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Bengio, 2007, ICML, P473
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   CHANG PP, 1991, SOFTWARE PRACT EXPER, V21, P1301, DOI 10.1002/spe.4380211204
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TQ, 2018, ADV NEUR IN, V31
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cong Jason, 2018, IEEE ACM INT C COMPU, P1
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Fujimoto S, 2018, PR MACH LEARN RES, V80
   Gao YX, 2018, PR MACH LEARN RES, V80
   Haarnoja T, 2018, PR MACH LEARN RES, V80
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Jiang W., 2019, P 2019 ACM SIGDA INT, P305, DOI DOI 10.1145/3289602
   Jiang WW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358192
   Jiang WW, 2018, IEEE T COMPUT AID D, V37, P2542, DOI 10.1109/TCAD.2018.2857098
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Klockner A., 2014, P ACM SIGPLAN INT WO, DOI [DOI 10.1145/2627373.2627387, 10.1145/2627373.2627387]
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lane Nicholas D, 2016, P 15 INT C INFORM PR, P1
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Lillicrap TP., 2015, ARXIV, DOI DOI 10.1016/S1098-3015(10)67722-4
   Lu Q., 2019, ABS191100105 CORR, Vabs/1911.00105
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Mnih V, 2016, PR MACH LEARN RES, V48
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Novillo D, 2014, PROCEEDINGS OF LLVM-HPC 14 2014 LLVM COMPILER INFRASTRUCTURE IN HPC, P22, DOI 10.1109/LLVM-HPC.2014.8
   Paliwal A., 2020, REINFORCED GENETIC A
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parsa M., 2019, ARXIV PREPRINT ARXIV
   Pelikan M, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P525
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Popov I., 2017, DATA EFFICIENT DEEP
   Radford A., 2019, OPENAI BLOG
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Salimans T., 2017, ARXIV170105517
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Santoro G, 2018, DES AUT TEST EUROPE, P1151, DOI 10.23919/DATE.2018.8342185
   Schkufza E, 2013, ACM SIGPLAN NOTICES, V48, P305, DOI 10.1145/2499368.2451150
   Schulman J., 2017, ARXIV, DOI DOI 10.1016/J.JDEVECO.2016.04.001
   Shao YS, 2016, INT SYMP MICROARCH
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Stamoulis D, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240796
   Stamoulis D, 2018, DES AUT TEST EUROPE, P19
   Steuwer M, 2017, INT SYM CODE GENER, P74, DOI 10.1109/CGO.2017.7863730
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2020, Arxiv, DOI [arXiv:1905.11946, DOI 10.48550/ARXIV.1905.11946]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   TORRADO R, 2018, P 2018 IEEE C COMP I
   Vasilache N., 2018, CORR
   Vaswani A., 2017, P 31 INT C NEURAL IN
   Volodymyr Mnih, 2013, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1312.5602
   Wei RC, 2018, Arxiv, DOI arXiv:1711.03016
   Wei XC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240856
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Whaley R Clinton, 1998, P 1998 ACMIEEE C SUP, P38, DOI [10.5555/509058.509096, DOI 10.1109/SC.1998.10004]
   Wu Y., 2016, TRAINING AGENT 1 PER
   Wu Y., 2016, ARXIV PREPRINT ARXIV
   Wu YH, 2017, ADV NEUR IN, V30
   Yang L, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218676
   Yang X, 2020, Arxiv, DOI arXiv:1809.04070
   Yin SY, 2018, SYMP VLSI CIRCUITS, P139, DOI 10.1109/VLSIC.2018.8502309
   Yonghui Wu, 2016, ARXIV PREPRINT ARXIV
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhao ZY, 2019, INT SYM PERFORM ANAL, P282, DOI 10.1109/ISPASS.2019.00040
   Zheng SX, 2019, IEEE T CIRCUITS-I, V66, P4648, DOI 10.1109/TCSI.2019.2942092
   Zhong GW, 2017, DES AUT TEST EUROPE, P1141, DOI 10.23919/DATE.2017.7927161
   Zhong ST, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, FITME 2009, P305, DOI 10.1109/FITME.2009.81
NR 96
TC 32
Z9 32
U1 2
U2 3
PY 2020
BP 622
EP 636
DI 10.1109/MICRO50266.2020.00058
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Isakov, M
   Bu, L
   Cheng, H
   Kinsy, MA
AF Isakov, Mihailo
   Bu, Lake
   Cheng, Hai
   Kinsy, Michel A.
GP IEEE
TI Preventing Neural Network Model Exfiltration in Machine Learning
   Hardware Accelerators
SO PROCEEDINGS OF THE 2018 ASIAN HARDWARE ORIENTED SECURITY AND TRUST
   SYMPOSIUM (ASIANHOST)
DT Proceedings Paper
CT 3rd Asian Hardware Oriented Security and Trust Symposium (AsianHOST)
CY DEC 17-18, 2018
CL Hong Kong Univ Sci & Technol, Hong Kong Univ Sci & Technol Jockey Club
   Ins, Hong Kong, HONG KONG
HO Hong Kong Univ Sci & Technol, Hong Kong Univ Sci & Technol Jockey Club Ins
DE Neural network; model exfiltration; hardware security; model theft;
   memory probing; side-channels; inference
AB Machine learning (ML) models are often trained using private datasets that are very expensive to collect, or highly sensitive, using large amounts of computing power. The models are commonly exposed either through online APIs, or used in hardware devices deployed in the field or given to the end users. This provides an incentive for adversaries to steal these ML models as a proxy for gathering datasets. While API based model exfiltration has been studied before, the theft and protection of machine learning models on hardware devices have not been explored as of now. In this work, we examine this important aspect of the design and deployment of ML models. We illustrate how an attacker may acquire either the model or the model architecture through memory probing, side-channels, or crafted input attacks, and propose (1) power-efficient obfuscation as an alternative to encryption, and (2) timing side-channel countermeasures.
C1 [Isakov, Mihailo; Bu, Lake; Cheng, Hai; Kinsy, Michel A.] Boston Univ, Adapt & Secure Comp Syst Lab, Dept Elect & Comp Engn, Boston, MA 02215 USA.
RP Isakov, M (corresponding author), Boston Univ, Adapt & Secure Comp Syst Lab, Dept Elect & Comp Engn, Boston, MA 02215 USA.
EM mihailo@bu.edu; bulake@bu.edu; chenghai@bu.edu; mkinsy@bu.edu
CR Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1615
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Amodei Dario, 2018, AI AND COMPUTE
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2015, COMPUT SCI, DOI DOI 10.4140/TCP.N.2015.249
   [Anonymous], 2016, CORR
   Bu L., 2018, 61 IEEE INT MIDW S C
   Carlini N., 2018, CORR
   Isakov M., 2018, CLOSNETS BATCHLESS D
   Juuti M., 2018, CORR
   Kinsy M. A., 2018, CORR
   Kolosnjaji B., 2018, CORR
   Mcdanel B., DISTRIBUTED DEEP NEU
   Oh Seong Joon, 2018, INT C LEARN REPR
   Riazi M. Sadegh, 2018, CORR
   Robon N, 2007, IEEE CUST INTEGR CIR, P799, DOI 10.1109/CICC.2007.4405850
   Rouhani Bita Darvish, 2017, CORR
   Stefanov E., 2013, ACM SIGSAC C COMP CO, DOI DOI 10.1145/2508859.2516660
   Tramer F., 2016, CORR
   XIE P., 2014, CORR
NR 20
TC 8
Z9 8
U1 0
U2 1
PY 2018
BP 62
EP 67
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Yoon, JY
   Kim, H
   Ham, EG
   Yang, HN
   Kim, JH
AF Yoon, Jee-Ye
   Kim, Hayeon
   Ham, Eun-Gyeong
   Yang, Hannah
   Kim, Ji-Hoon
GP IEEE
TI Machine Learning-based Wearable Bio-processor for Real-Time Blood
   Pressure Estimation
SO 2022 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND
   COMMUNICATION (ICEIC)
DT Proceedings Paper
CT International Conference on Electronics, Information, and Communication
   (ICEIC)
CY FEB 06-09, 2022
CL Jeju, SOUTH KOREA
DE Blood Pressure; BP Estimation; Bio-processor; Machine Learning; SoC
   (System-on-Chip)
AB Recently, as continuous monitoring of blood pressure (BP) becomes important for the treatment and management of hypertension, which is a representative chronic disease, many studies on non-invasive cuff-less BP have been conducted. Due to accuracy degradation of the simple linear algorithms, complex nonlinear algorithms are preferred, but its latency and energy efficiency are suffered from the limited CPU computational capability on wearable devices. In this paper, we present a wearable bio-processor that is capable of real-time BP estimation based on Electrocardiogram (ECG) and Photoplethysmography (PPG), which can provide high BP estimation accuracy with a nonlinear regression machine learning model. The proposed bio-processor including Arm Cortex-M0 and dedicated hardware accelerators runs at 50MHz and is prototyped with a Xilinx Artix-7 FPGA. It shows the root mean square error (RMSE) of 6.04 mmHg and 5.88 mmHg for Systolic BP and Diastolic BP, respectively.
C1 [Yoon, Jee-Ye; Kim, Hayeon; Ham, Eun-Gyeong; Yang, Hannah; Kim, Ji-Hoon] Ewha Womans Univ, Dept Elect & Elect Engn, Seoul, South Korea.
RP Yoon, JY (corresponding author), Ewha Womans Univ, Dept Elect & Elect Engn, Seoul, South Korea.
EM iamyjypy@ewhain.net; hayeonsarang11@ewhain.net; dmsrud25669@ewhain.net;
   hannah714@ewhain.net; jihoonkim@ewha.ac.kr
CR 김종화, 2008, [Science of Emotion & Sensibility, 감성과학], V11, P235
   Cho Jinwoo, 2020, [Journal of the Korea Society Industrial Information System, 한국산업정보학회논문지], V25, P1, DOI 10.9723/jksiis.2020.25.3.001
   Johnson Alistair, 2023, PN
   Kher R., 2019, J BIOMEDICAL ENG RES, V3, P101
   OBrien Eoin, 1993, J HYPERTENS, V11, pS43, DOI DOI 10.1097/00004872-199306000-00013
   Pandey V, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P191, DOI 10.1109/ICETEESES.2016.7581383
   Park Young-Im, 2007, [The Journal of Korean Academic Society of Nursing Education, 한국간호교육학회지], V13, P95
   Sadhukhan D, 2012, PROC TECH, V4, P873, DOI 10.1016/j.protcy.2012.05.143
NR 8
TC 1
Z9 1
U1 2
U2 2
PY 2022
DI 10.1109/ICEIC54506.2022.9748830
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Valentino, G
   Salvachua, B
AF Valentino, Gianluca
   Salvachua, Belen
GP IOP
TI Machine Learning Applied at the LHC for Beam Loss Pattern Classification
SO 9TH INTERNATIONAL PARTICLE ACCELERATOR CONFERENCE (IPAC18)
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 9th International Particle Accelerator Conference (IPAC)
CY APR 29-MAY 04, 2018
CL Triumf Lab, Vancouver, CANADA
HO Triumf Lab
AB Beam losses at the LHC are constantly monitored because they can heavily impact the performance of the machine. One of the highest risks is to quench the LHC superconducting magnets in the presence of losses leading to a long machine downtime in order to recover cryogenic conditions. Smaller losses are more likely to occur and have an impact on the machine performance, reducing the luminosity production or reducing the lifetime of accelerator systems due to radiation effects, such as magnets. Understanding the characteristics of the beam loss, such as the beam and the plane, is crucial in order to correct them. Regularly during the year, dedicated loss map measurements are performed in order to validate the beam halo cleaning of the collimation system. These loss maps have the particular advantage that they are performed in well controlled conditions and can therefore be used by a machine learning algorithm to classify the type of losses during the LHC machine cycle. This study shows the result of the beam loss classification and its retrospective application to beam loss data from the 2017 run.
C1 [Valentino, Gianluca] Univ Malta, MSD-2080 Msida, Malta.
   [Valentino, Gianluca; Salvachua, Belen] CERN, CH-1211 Geneva 23, Switzerland.
RP Valentino, G (corresponding author), Univ Malta, MSD-2080 Msida, Malta.; Valentino, G (corresponding author), CERN, CH-1211 Geneva 23, Switzerland.
EM gianluca.valentino@um.edu.mt
CR [Anonymous], P 4 INT PART ACC C I
   [Anonymous], 2012, P IPAC12 NEW ORL LOU
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Holzer EB, 2005, IEEE NUCL SCI CONF R, P1052
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Redaelli S., 2016, HB 2016 MALM SWED
   Salvachua B., 2017, P 8 INT PART ACC C C, P88
   Theodoropoulos P., 2015, THESIS
   Valentino G, 2017, J PHYS CONF SER, V874, DOI 10.1088/1742-6596/874/1/012002
   Valentino G, 2012, PHYS REV SPEC TOP-AC, V15, DOI 10.1103/PhysRevSTAB.15.051002
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2018
VL 1067
AR 072036
DI 10.1088/1742-6596/1067/7/072036
WC Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Lee, D
   Gerstlauer, A
AF Lee, Dongwook
   Gerstlauer, Andreas
TI Learning-Based, Fine-Grain Power Modeling of System-Level Hardware IPs
SO ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS
DT Article
DE Power modeling; power estimation; machine learning; virtual platform;
   system-level design; high-level synthesis; hardware accelerator
AB Accurate power and performance models are needed to enable rapid, early system-level analysis and optimization. There is, however, a lack of fast yet fine-grain power models of hardware components at such high levels of abstraction. In this article, we present novel learning-based approaches for extending fast functional simulation models of accelerators and other hardware intellectual property components (IPs) with accurate cycle-, block-, and invocation-level power estimates. Our proposed power modeling approach is based on annotating functional hardware descriptions with capabilities that, depending on observability, allow capturing data-dependent resource, block, or input and output (I/O) activity without a significant loss in simulation speed. We further leverage advanced machine learning techniques to synthesize abstract power models using novel decomposition techniques that reduce model complexities and increase estimation accuracy. Results of applying our approach to various industrial-strength design examples show that our power models can predict cycle-, basic block-, and invocation-level power consumption to within 10%, 9%, and 3% of a commercial gate-level power estimation tool, respectively, all while running at several order of magnitude faster speeds of 1-10Mcycles/sec. Model training and synthesis takes less than 34 minutes in all cases, including up to 30 minutes for training data and trace generation using gate-level simulations.
C1 [Lee, Dongwook; Gerstlauer, Andreas] Univ Texas Austin, 2501 Speedway, Austin, TX 78712 USA.
RP Lee, D (corresponding author), Univ Texas Austin, 2501 Speedway, Austin, TX 78712 USA.
EM dongwook.lee@utexas.edu; gerstl@ece.utexas.edu
CR Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Bogliolo A, 2000, ACM T DES AUTOMAT EL, V5, P337, DOI 10.1145/348019.348081
   Chen D., 2007, ASIA S PACIFIC DESIG
   Copty E, 2011, DES AUT CON, P351
   Gashler M., 2008, MACHINE LEARNING APP, P900, DOI DOI 10.1109/ICMLA.2008.154
   Gruttner K., 2014, INT C EMB COMP SYST
   Gupta S, 2000, IEEE T VLSI SYST, V8, P18, DOI 10.1109/92.820758
   Hsieh C.-T., 1996, INT C COMP AID DES I
   Hsu CW, 2011, DES AUT CON, P47
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lee D., 2015, INT C COMP AID DES I
   Lee D., 2015, DESIGN AUTOMATION TE
   Lee D., 2017, LEARNING BASED IP PO
   Lee I., 2006, AS S PAC C DES AUT A
   Li S, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2445572.2445577
   Lorenz D., 2014, EUR C DIG SYST DES D
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Nangate, 2017, OP CELL LIB
   Neal R. M., 2007, TECHNOMETRICS, V49, P366, DOI [10.1117/1.2819119, DOI 10.1198/TECH.2007.S518, 10.1198/tech.2007.s518]
   Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020
   Park Y. H., 2007, INT C COMP DES ICCD
   Park YH, 2011, IEEE T VLSI SYST, V19, P668, DOI 10.1109/TVLSI.2009.2039153
   Pedram M., 1997, LOW POWER DESIGN DEE
   Potlapally N. R., 2001, INT C VLSI DES ICVD
   Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327
   Ravi S., 2003, INT C VLSI DES ICVD
   Schürmans S, 2013, DES AUT CON
   Schurmans S., 2015, INT C EMB COMP SYST
   Shao Y. S., 2014, INT S COMP ARCH ISCA
   Spiliopoulos V., 2013, INT S MOD AN SIM COM
   Sunwoo D., 2010, INT C FIELD PROGR LO
   Trabelsi C., 2011, EURASIP J EMBEDDED S, V1, P1
   Wu G., 2015, DISSERTATION
   Zhao ZR, 2017, IEEE T COMPUT AID D, V36, P299, DOI 10.1109/TCAD.2016.2578882
   Zhong L., 2004, INT C COMP AID DES I
NR 36
TC 6
Z9 6
U1 0
U2 0
PD APR
PY 2018
VL 23
IS 3
AR 30
DI 10.1145/3177865
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Murmann, B
AF Murmann, Boris
TI Mixed-Signal Computing for Deep Neural Network Inference
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Deep learning; hardware accelerators; in-memory computing; machine
   learning (ML); mixed analog digital integrated circuits; neural
   networks; switched capacitor (SC) circuits
ID SRAM MACRO; MEMORY; CHIP; ACCELERATOR; TOLERANCE; ANALOG; FAULT; CMOS
AB Modern deep neural networks (DNNs) require billions of multiply-accumulate operations per inference. Given that these computations demand relatively low precision, it is feasible to consider analog computing, which can be more efficient than digital in the low-SNR regime. This overview article investigates the potential of mixed analog/digital computing approaches in the context of modern DNN processor architectures, which are typically limited by memory access. We discuss how memory-like and in-memory compute fabrics may help alleviate this bottleneck and derive asymptotic efficiency limits at the processing array level. It is shown that single-digit fJ/op energy efficiencies are feasible for 4-bit mixed-signal arithmetic. In this analysis, special consideration is given to the SNR and amortization requirements of the analog-digital interfaces. In addition, we consider the pros and cons for a variety of implementation styles and highlight the challenge of retaining high compute efficiency for a complete DNN accelerator design.
C1 [Murmann, Boris] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
RP Murmann, B (corresponding author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
EM murmann@stanford.edu
CR [Anonymous], 2015, P 42 ANN INT S COMP
   [Anonymous], 2019, ARXIV190907514
   [Anonymous], 2019, ARXIV190603474
   Bankman D, 2019, CONF REC ASILOMAR C, P1511, DOI [10.1109/IEEECONF44664.2019.9048704, 10.1109/ieeeconf44664.2019.9048704]
   Bankman D., 2019, MIXED SIGNAL PROCESS
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Benini L., 2020, NANOCHIPS 2020, P323
   Bose SK, 2019, CONF REC ASILOMAR C, P1522, DOI [10.1109/IEEECONF44664.2019.9048891, 10.1109/ieeeconf44664.2019.9048891]
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Camusy V, 2019, IEEE J EM SEL TOP C, V9, P697, DOI 10.1109/JETCAS.2019.2950386
   Chou CC, 2018, ISSCC DIG TECH PAP I, P478
   Cosemans S, 2019, INT EL DEVICES MEET
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Dally WJ, 2018, SYMP VLSI CIRCUITS, P3, DOI 10.1109/VLSIC.2018.8502368
   Dean J, 2020, ISSCC DIG TECH PAP I, P8, DOI 10.1109/ISSCC19947.2020.9063049
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Duan Y., 2017, NAT COMMUN, DOI DOI 10.1038/NCOMMS14542
   Emer J. S., 2020, SYNTHESIS LECT COMPU
   Esser Steven K, 2019, ARXIV190208153
   Gonugondla S. K., 2020, ICCAD, P1
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo K., NEURAL NETWORK ACCEL
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hubara I, 2018, J MACH LEARN RES, V18
   Jia HY, 2020, IEEE J SOLID-ST CIRC, V55, P2609, DOI 10.1109/JSSC.2020.2987714
   Jiang ZW, 2020, IEEE J SOLID-ST CIRC, V55, P1888, DOI 10.1109/JSSC.2020.2992886
   Klachko M, 2019, IEEE IJCNN
   Knag P. C., 2020, 2020 IEEE S VLSI CIR, P1
   Le BQ, 2019, IEEE T ELECTRON DEV, V66, P641, DOI 10.1109/TED.2018.2879788
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin YH, 2019, IEEE T ELECTRON DEV, V66, P1289, DOI 10.1109/TED.2019.2894273
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Ma S., 2019, ARXIV191200106
   Mei L., 2020, ARXIV200711360
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Moons B, 2018, IEEE CUST INTEGR CIR
   Murmann B, 2015, 2015 49TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, P1341, DOI 10.1109/ACSSC.2015.7421361
   Murmann B, ADC PERFORMANCE SURV
   MURRAY AF, 1994, IEEE T NEURAL NETWOR, V5, P792, DOI 10.1109/72.317730
   Omran H, 2016, IEEE T CIRCUITS-I, V63, P763, DOI 10.1109/TCSI.2016.2537824
   Rekhi AS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317770
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarpeshkar R, 1998, NEURAL COMPUT, V10, P1601, DOI 10.1162/089976698300017052
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Torres-Huitzil C, 2017, IEEE ACCESS, V5, P17322, DOI 10.1109/ACCESS.2017.2742698
   Tripathi V, 2014, IEEE T CIRCUITS-I, V61, P2236, DOI 10.1109/TCSI.2014.2332264
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Verhelst M., 2020, NANOCHIPS 2030, P293, DOI DOI 10.1007/978-3-030-18338-7_18
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   VITTOZ EA, 1990, 1990 IEEE INTERNATIONAL SYMP ON CIRCUITS AND SYSTEMS, VOLS 1-4, P1372, DOI 10.1109/ISCAS.1990.112386
   Wan W., 2020, PROC IEEE S VLSI TEC, P1, DOI DOI 10.1109/VLSITECHNOLOGY18217.2020.9265066
   Wu Y., 2020, 2020 INT S PERF AN S, P1
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang Lei, 2020, DES AUT CON
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yu CS, 2020, IEEE CUST INTEGR CIR
   Yu SM, 2020, IEEE CUST INTEGR CIR, DOI 10.1109/cicc48029.2020.9075887
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang BA, 2019, INT CONF ACOUST SPEE, P1388, DOI 10.1109/ICASSP.2019.8683521
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/ICASSP40776.2020.9053977, 10.1109/icassp40776.2020.9053977]
   Zimmer B, 2020, IEEE J SOLID-ST CIRC, V55, P920, DOI 10.1109/JSSC.2019.2960488
   Zisserman, 2014, CORR
NR 69
TC 33
Z9 35
U1 3
U2 8
PD JAN
PY 2021
VL 29
IS 1
BP 3
EP 13
DI 10.1109/TVLSI.2020.3020286
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Zhao, R
   Song, WN
   Zhang, WT
   Xing, TW
   Lin, JH
   Srivastava, M
   Gupta, R
   Zhang, ZR
AF Zhao, Ritchie
   Song, Weinan
   Zhang, Wentao
   Xing, Tianwei
   Lin, Jeng-Hau
   Srivastava, Mani
   Gupta, Rajesh
   Zhang, Zhiru
GP ACM
TI Accelerating Binarized Convolutional Neural Networks with
   Software-Programmable FPGAs
SO FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
CY FEB 22-24, 2017
CL Monterey, CA
AB Convolutional neural networks (CNN) are the current state-of-the-art for many computer vision tasks. CNNs outperform older methods in accuracy, but require vast amounts of computation and memory. As a result, existing CNN applications are typically run on clusters of CPUs or GPUs. Research on FPGA acceleration of CNN workloads has achieved reductions in power and energy consumption. However, large GPUs outperform modern FPGAs in throughput, and the existence of compatible deep learning frameworks give GPUs a significant advantage in programmability.
   Recent work in machine learning demonstrates the potential of very low precision CNNs - i.e., CNNs with binarized weights and activations. Such binarized neural networks (BNNs) appear well suited for FPGA implementation, as their dominant computations are bitwise logic operations and their memory requirements are greatly reduced. A combination of low-precision networks and high-level design methodology may help address the performance and productivity gap between FPGAs and GPUs. In this paper, we present the design of a BNN accelerator that is synthesized from C++ to FPGA-targeted Verilog. The accelerator outperforms existing FPGA-based CNN accelerators in GOPS as well as energy and resource efficiency.
C1 [Zhao, Ritchie; Zhang, Zhiru] Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14853 USA.
   [Song, Weinan; Zhang, Wentao] Peking Univ, Sch Elect Engn & Comp Sci, Beijing, Peoples R China.
   [Xing, Tianwei; Srivastava, Mani] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90024 USA.
   [Lin, Jeng-Hau; Gupta, Rajesh] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Zhao, R (corresponding author), Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14853 USA.
EM rz252@cornell.edu; zhiruz@cornell.edu
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   [Anonymous], 2013, PROC 30 INT C MACH L
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Czajkowski Tomasz S., 2012, FPL, P531, DOI DOI 10.1109/FPL.2012.6339272
   He K., 2015, ARXIV
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Kathail V, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P4, DOI 10.1145/2847263.2847284
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   OVTCHAROV K, 2015, MICROSOFT RES
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Simonyan K., 2015, ARXIV140915568
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Theano Development Team, 2016, ABS160502688 ARXIV
   Venieris S. I., 2016, IEEE S FIELD PROGR C
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou S., 2016, ARXIV160606160
NR 28
TC 248
Z9 254
U1 4
U2 41
PY 2017
BP 15
EP 24
DI 10.1145/3020078.3021741
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chung, CC
   Liang, YP
   Chang, YC
   Chang, CM
AF Chung, Ching-Che
   Liang, Yu-Pei
   Chang, Ya-Ching
   Chang, Chen-Ming
GP IEEE
TI A Binary Weight Convolutional Neural Network Hardware Accelerator for
   Analysis Faults of the CNC Machinery on FPGA
SO 2023 INTERNATIONAL VLSI SYMPOSIUM ON TECHNOLOGY, SYSTEMS AND
   APPLICATIONS, VLSI-TSA/VLSI-DAT
DT Proceedings Paper
CT International VLSI Symposium on Technology, Systems and Applications
   (VLSI-TSA/VLSI-DAT)
CY APR 17-20, 2023
CL Hsinchu, TAIWAN
DE binary neural network (BNN); convolutional neural network (CNN); CNC
   vibration signal identification
AB With the development of machine learning technologies and the internet of things, many traditional industrial problems can be solved by combining these two technologies. For example, the CNC machinery fault can be detected by collecting the data from vibration sensors and analysis with machine learning algorithms. However, previous studies only focused on the accuracy of the machine learning model but did not consider the overhead of hardware implementation. This paper proposes a real-time CNC machinery fault detection solution using a binary weight convolutional neural network to identify vibration signals. In addition, the operations in the designed neural network have been converted to fixed-point operations to speed up the calculations and reduce memory usage. Finally, the proposed method has been implemented on FPGA to evaluate the capabilities. According to the experimental result, the proposed method can achieve 95.07% accuracy while implemented on the FPGA with 130MHz clock frequency.
C1 [Chung, Ching-Che; Liang, Yu-Pei; Chang, Ya-Ching; Chang, Chen-Ming] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Chiayi, Taiwan.
RP Chung, CC (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Chiayi, Taiwan.
EM wildwolf@cs.ccu.edu.tw; ypliang@cs.ccu.edu.tw
CR Case Western Reserve University Bearing Data Center, CAS W RES U BEAR DAT
   Che CC, 2019, ADV MECH ENG, V11, DOI 10.1177/1687814019897212
   Chen ZY, 2020, MECH SYST SIGNAL PR, V140, DOI 10.1016/j.ymssp.2020.106683
   Ge JH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030290
   Guo P, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S0218126619400048
   Kaplan K, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.106019
   Li HM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092034
   Li SB, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081729
   Li X, 2020, ISA T, V97, P365, DOI 10.1016/j.isatra.2019.07.027
   Lin JH, 2019, DES AUT TEST EUROPE, P1112, DOI [10.23919/date.2019.8714951, 10.23919/DATE.2019.8714951]
   Smith WA, 2015, MECH SYST SIGNAL PR, V64-65, P100, DOI 10.1016/j.ymssp.2015.04.021
   Wang SH, 2018, KNOWL-BASED SYST, V144, P65, DOI 10.1016/j.knosys.2017.12.027
   Yuan YH, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1437, DOI [10.1109/ITAIC.2019.8785497, 10.1109/itaic.2019.8785497]
NR 13
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/VLSI-TSA/VLSI-DAT57221.2023.10134316
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Noronha, DH
   Zhao, RZ
   Que, ZQ
   Goeders, J
   Luk, W
   Wilton, S
AF Noronha, Daniel Holanda
   Zhao, Ruizhe
   Que, Zhiqiang
   Goeders, Jeffrey
   Luk, Wayne
   Wilton, Steve
GP IEEE
TI An Overlay for Rapid FPGA Debug of Machine Learning Applications
SO 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2019)
DT Proceedings Paper
CT International Conference on Field-Programmable Technology (ICFPT)
CY DEC 09-13, 2019
CL Tianjin, PEOPLES R CHINA
AB FPGAs show promise as machine learning accelerators for both training and inference. Designing these circuits on reconfigurable technology is challenging, especially due to bugs that only manifest on-chip when the circuit is running at speed. In this paper, we propose a flexible debug overlay family that provides software-like debug times for machine learning applications. At compile time, the overlay is added to the design and compiled. At debug time, the overlay can be configured to record statistical information about identified weight and activation matrices; this configuration can be changed between debug iterations allowing the user to record a different set of matrices, or record different information about the observed matrices. Importantly, no recompilation is required between debug iterations. Although the flexibility of our overlay suffers some overhead compared to fixed instrumentation, we argue that the ability to change the debugging scenario without requiring a recompilation may be compelling and outweigh the disadvantage of higher overhead for many applications.
C1 [Noronha, Daniel Holanda; Wilton, Steve] Univ British Columbia, Vancouver, BC, Canada.
   [Zhao, Ruizhe; Que, Zhiqiang; Luk, Wayne] Imperial Coll London, London, England.
   [Goeders, Jeffrey] Brigham Young Univ, Provo, UT 84602 USA.
RP Noronha, DH (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM danielhn@ece.ubc.ca; ruizhe.zhao15@imperial.ac.uk; z.que@imperial.ac.uk;
   jgoeders@byu.edu; w.luk@imperial.ac.uk; stevew@ece.ubc.ca
CR Abdelfattah M. S., 2018, FPL
   Altera, 2015, QUART PRIM PROED HDB, V3
   Calagar Nazanin, 2014, INT C FIELD PROGRAMM
   Chen Tianqi, 2018, OSDI
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Daoud EA, 2011, IEEE T COMPUT, V60, P937, DOI 10.1109/TC.2010.122
   Daoud EA, 2009, IEEE T COMPUT AID D, V28, P1387, DOI 10.1109/TCAD.2009.2023198
   Eslami F., 2016, ABS160606457 CORR
   Eslami F., 2015, INT C FIELD PROGR TE
   Fu Y., 2018, XILINX ML SUITE OVER
   Goeders J., 2014, FIELD PROGR LOG APPL
   Goeders J, 2017, IEEE T COMPUT AID D, V36, P83, DOI 10.1109/TCAD.2016.2565204
   Hale R, 2018, I C FIELD PROG LOGIC, P81, DOI 10.1109/FPL.2018.00022
   Hemmert KS, 2003, ANN IEEE SYM FIELD P, P228
   Holanda Noronha D., 2018, INT WORKSH FPGAS SOF
   Hung Eddie, 2014, Reconfigurable Computing: Architectures, Tools, and Applications. 10th International Symposium, ARC 2014. Proceedings: LNCS 8405, P73, DOI 10.1007/978-3-319-05960-0_7
   Intel, 2017, QUART PRIM PROED HDB, V3
   Jamal AS, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P209, DOI 10.1145/3174243.3174254
   Khan Habib ul Hasan, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P433, DOI 10.1007/978-3-319-78890-6_35
   Ko H. F., 2010, IEEE T VERY LARGE SC, V19, P1380
   Kourfali A., 2018, LAT AM TEST S MARCH
   Kourfali A, 2016, IEEE SYM PARA DISTR, P277, DOI 10.1109/IPDPSW.2016.95
   Kumar P.B., 2017, INT C FIELD PROGR LO
   Monson Joshua S, 2015, P 2015 ACMSIGDA INT, P5
   Noronha DH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P110, DOI 10.1145/3289602.3293922
   Poulos Z, 2012, DES AUT TEST EUROPE, P292
   Quinton B., 2010, IEEE INT WORKSH SIL
   Wheeler T., 2001, Field Programmable Logic and Applications. 11th International Conference, FPL 2001. Proceedings (Lecture Notes in Computer Science Vol.2147), P483
   Xilinx, 2016, INT LOG AN V6 1 LOGI
   Xilinx, 2012, CHIPSCOPE PROS COR U
NR 30
TC 4
Z9 4
U1 0
U2 0
PY 2019
BP 135
EP 143
DI 10.1109/ICFPT47387.2019.00024
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Siemieniuk, A
   Chelini, L
   Khan, AA
   Castrillon, J
   Drebes, A
   Corporaal, H
   Grosser, T
   Kong, M
AF Siemieniuk, Adam
   Chelini, Lorenzo
   Khan, Asif Ali
   Castrillon, Jeronimo
   Drebes, Andi
   Corporaal, Henk
   Grosser, Tobias
   Kong, Martin
TI OCC: An Automated End-to-End Machine Learning Optimizing Compiler for
   Computing-In-Memory
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Tensors; Hardware; Common Information Model (computing); Computer
   architecture; Runtime library; Phase change materials; Memristors;
   Computing-in-memory (CIM); machine learning (ML); memristor; MLIR
AB Memristive devices promise an alternative approach toward non-Von Neumann architectures, where specific computational tasks are performed within the memory devices. In the machine learning (ML) domain, crossbar arrays of resistive devices have shown great promise for ML inference, as they allow for hardware acceleration of matrix multiplications. But, to enable widespread adoption of these novel architectures, it is critical to have an automatic compilation flow as opposed to relying on a manual mapping of specific kernels on the crossbar arrays. We demonstrate the programmability of memristor-based accelerators using the new compiler design principle of multilevel rewriting, where a hierarchy of abstractions lowers programs level-by-level and perform code transformations at the most suitable abstraction. In particular, we develop a prototype compiler, which progressively lowers a mathematical notation for tensor operations arising in ML workloads, to fixed-function memristor-based hardware blocks.
C1 [Siemieniuk, Adam; Chelini, Lorenzo; Corporaal, Henk] Tech Univ Eindhoven, Dept Elect Engn, NL-5612 AZ Eindhoven, Netherlands.
   [Khan, Asif Ali; Castrillon, Jeronimo] Tech Univ Dresden, Dept Comp Sci, D-01069 Dresden, Germany.
   [Drebes, Andi] Ecole Normale Super, INRIA, F-75012 Paris, France.
   [Grosser, Tobias] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Kong, Martin] Univ Oklahoma, Sch Comp Sci, Norman, OK 73019 USA.
RP Siemieniuk, A (corresponding author), Tech Univ Eindhoven, Dept Elect Engn, NL-5612 AZ Eindhoven, Netherlands.
EM a.i.siemieniuk@student.tue.nl
CR Ambrosi J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P141
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2018, PLAIDML
   Baumgartner G, 2005, P IEEE, V93, P276, DOI 10.1109/JPROC.2004.840311
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Borkar S, 2013, INT PARALL DISTRIB P, P3, DOI 10.1109/IPDPS.2013.121
   Burr GW, 2010, J VAC SCI TECHNOL B, V28, P223, DOI 10.1116/1.3301579
   Castrillon J, 2018, IEEE T MULTI-SCALE C, V4, P243, DOI 10.1109/TMSCS.2017.2771750
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Drebes A., 2020, PROC 10 INT WORKSHOP
   Drebes A, 2020, TECKYL MLIR FRONTEND
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   Gysi T, 2020, DOMAIN SPECIFIC MULT
   Jiang HW, 2022, IEEE DES TEST, V39, P48, DOI 10.1109/MDAT.2021.3050715
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Le Gallo M, 2018, IEEE T ELECTRON DEV, V65, P4304, DOI 10.1109/TED.2018.2865352
   Li SY, 2016, 2016 IEEE POWER & ENERGY SOCIETY INNOVATIVE SMART GRID TECHNOLOGIES CONFERENCE (ISGT)
   Mehonic A., 2020, MEMRISTORS IN MEMORY
   Oord A. V. D., 2016, ARXIV
   Qureshi Moinuddin K., 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P14, DOI 10.1145/1669112.1669117
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Sebastian A, 2019, J PHYS D APPL PHYS, V52, DOI 10.1088/1361-6463/ab37b6
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Springer P, 2018, ACM T MATH SOFTWARE, V44, DOI 10.1145/3157733
   Stock K., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P1058, DOI 10.1109/IPDPS.2011.101
   Tang YQ, 2020, IEEE T CIRCUITS-I, V67, P1576, DOI 10.1109/TCSI.2019.2961643
   Truong L, 2016, ACM SIGPLAN NOTICES, V51, P209, DOI [10.1145/2908080.2908105, 10.1145/2980983.2908105]
   Vadivel K, 2020, DES AUT TEST EUROPE, P1602, DOI 10.23919/DATE48585.2020.9116464
   Vasilache N, 2019, ACM T ARCHIT CODE OP, V16, DOI 10.1145/3355606
   Vasudevan A, 2017, IEEE INT CONF ASAP, P19, DOI 10.1109/ASAP.2017.7995254
   Yang A, 2019, IEEE IMTC P, DOI 10.1109/i2mtc.2019.8826888
   Zhang MJ, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P951
NR 39
TC 3
Z9 3
U1 1
U2 4
PD JUN
PY 2022
VL 41
IS 6
BP 1674
EP 1686
DI 10.1109/TCAD.2021.3101464
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nasser, A
   Fadel, KA
   Abbas, KO
   Ahmed, KH
   AbdelSalam, M
   Gaber, M
AF Nasser, Ahmed
   Fadel, Karim Ahmed
   Abbas, Karim Ossama
   Ahmed, Karim Hussein
   AbdelSalam, Mohamed
   Gaber, Mahmoud
GP IEEE
TI An Automated Flow for Configuration and Generation of CNN based AI
   accelerators for HW Emulation & FPGA Prototyping
SO 2021 28TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS, AND
   SYSTEMS (IEEE ICECS 2021)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 28th IEEE International Conference on Electronics, Circuits, and Systems
   (IEEE ICECS)
CY NOV 28-DEC 01, 2021
CL Dubai, U ARAB EMIRATES
DE Machine Learning (ML); Convolutional Neural Networks (CNNs); Register
   Transfer Logic (RTL)
AB Machine learning (ML) algorithms have proven to be a concrete component in various fields that aim to be fully automated. Therefore, many researchers have shed the light on the modifications of ML algorithms to be fully automated for more complicated tasks. However, the acceleration of such algorithms is extremely hard due to the high computations and memory required. This paper implements automated flow using Perl scripts and generated LeNet-5 (A Convolutional Neural Network Model). Our target is high throughput, configurable and scalable RTL design that is generated by Perl scripts. Our flow is designing and verifying using Veloce emulator.
C1 [Nasser, Ahmed; Fadel, Karim Ahmed; Abbas, Karim Ossama; Ahmed, Karim Hussein; Gaber, Mahmoud] Cairo Univ, Elect & Commun Engn Dept, Cairo, Egypt.
   [AbdelSalam, Mohamed] Mentor A Siemens Business, Cairo, Egypt.
RP Nasser, A (corresponding author), Cairo Univ, Elect & Commun Engn Dept, Cairo, Egypt.
EM ahmedelgendy1998@gmail.com; karim2lfadel@gmail.com; karim@eng.cu.edu.eg;
   karimhussein118@gmail.com; mohamed_abdelsalam@mentor.com;
   eng.mahmoud9371@gmail.com
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Nair V., 2010, ICML, P807
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
NR 4
TC 0
Z9 0
U1 0
U2 0
PY 2021
DI 10.1109/ICECS53924.2021.9665606
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Skoda, P
   Rogina, BM
AF Skoda, P.
   Rogina, B. Medved
BE Biljanovic, P
   Butkovic, Z
   Skala, K
   Grbac, TG
   CicinSain, M
   Sruk, V
   Ribaric, S
   Gros, S
   Vrdoljak, B
   Mauher, M
   Tijan, E
   Lukman, D
TI FPGA Kernels for Classification Rule Induction
SO 2016 39TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION
   TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO)
DT Proceedings Paper
CT 39th International Convention on Information and Communication
   Technology, Electronics and Microelectronics (MIPRO)
CY MAY 30-JUN 03, 2016
CL Opatija, CROATIA
DE FPGA; dataflow; machine learning; classification rules
AB Classification is one of the core tasks in machine learning data mining. One of several models of classification are classification rules, which use a set of if-then rules to describe a classification model. In this paper we present a set of FPGA-based compute kernels for accelerating classification rule induction. The kernels can be combined to perform specific procedures in rule induction process, such as evaluating rule coverage, or estimating out-of-bag-error. Since classification problems are getting increasingly larger, there is a need for faster implementations of classification rule induction. One of the platforms that offer great potential for accelerating data mining tasks is FPGA (field programmable gate array), which provides the means for implementing application specific accelerators.
C1 [Skoda, P.; Rogina, B. Medved] Rudjer Boskovic Inst, Zagreb, Croatia.
RP Skoda, P (corresponding author), Rudjer Boskovic Inst, Zagreb, Croatia.
EM pskoda@irb.hr
CR [Anonymous], OPENMP APPL PROGR IN
   [Anonymous], MIPRO 2014 P 38 INT
   [Anonymous], MIPRO 2014 P 37 INT
   [Anonymous], FDN TRENDS ELECT DES
   [Anonymous], RECONFIGURABLE COMPU
   Choudhary AN, 2011, WIRES DATA MIN KNOWL, V1, P41, DOI 10.1002/widm.9
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   DENNIS JB, 1980, COMPUTER, V13, P48, DOI 10.1109/MC.1980.1653418
   Han J, 2011, DATA MINING CONCEPTS
   Narayanan R, 2007, DES AUT TEST EUROPE, P189
   Pell O, 2012, COMPUT SCI ENG, V14, P98, DOI 10.1109/MCSE.2012.78
   Skoda P., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P362
NR 12
TC 0
Z9 0
U1 0
U2 3
PY 2016
BP 337
EP 342
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Telecommunications
DA 2023-11-11
ER

PT C
AU Chan, JW
   Yeo, CK
AF Chan, Jun Wei
   Yeo, Chai Kiat
GP IEEE
TI Electrical Power Consumption Forecasting with Transformers
SO 2022 IEEE ELECTRICAL POWER AND ENERGY CONFERENCE (EPEC)
SE IEEE Electrical Power and Energy Conference
DT Proceedings Paper
CT IEEE Electrical Power and Energy Conference (EPEC)
CY DEC 05-07, 2022
CL ELECTR NETWORK
AB Until recently, state of the art (SOTA) deep learning methods for time series prediction problems, such as electricity load forecasting, have been based on recurrent neural networks (RNN), convolutional neural networks (CNN), or combinations thereof. However, RNNs involve sequential computations that cannot be parallelized on machine learning accelerators, while CNNs require very deep networks to capture long distance relationships. This paper proposes a sparse transformer based method for time series prediction. The proposed model achieves comparable accuracy to the SOTA method, TSRNN, on the London Smart Meter dataset while achieving up to 10 times faster inference speed.
C1 [Chan, Jun Wei; Yeo, Chai Kiat] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
RP Chan, JW (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM s200132@e.ntu.edu.sg; asckyeo@ntu.edu.sg
CR [Anonymous], 2017, SMART METERS LONDON
   [Anonymous], 2021, INT J WILDLAND FIRE, DOI DOI 10.1071/WF20190
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Durbin J., 2012, TIME SERIES ANAL STA, V5
   Hyndman RJ, 2008, SPRINGER SER STAT, P3
   Jin X., 2019, ENHANCING LOCALITY B, V32
   Lee-Thorp J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4296
   Nassif A., 2021, INT REV MODELLING SI, V14, P408
   Nassif A. B., 2021, INT REV MODELLING SI, V14, P12
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y., 2019, P INT C LEARN REPR
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Zaheer M., 2020, BIG BIRD TRANSFORMER, V33, P17283
   Zerveas G, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2114, DOI 10.1145/3447548.3467401
NR 14
TC 0
Z9 0
U1 1
U2 2
PY 2022
BP 255
EP 260
DI 10.1109/EPEC56903.2022.10000228
WC Energy & Fuels; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Baehr, S
   Sander, O
   Heck, M
   Feindt, M
   Becker, J
AF Baehr, S.
   Sander, O.
   Heck, M.
   Feindt, M.
   Becker, J.
TI A framework for porting the NeuroBayes machine learning algorithm to
   FPGAs
SO JOURNAL OF INSTRUMENTATION
DT Article; Proceedings Paper
CT Topical Workshop on Electronics for Particle Physics (TWEPP)
CY SEP 28-OCT 02, 2015
CL Lisbon, PORTUGAL
DE Online farms and online filtering; Hardware and accelerator control
   systems; Data acquisition concepts; Pattern recognition, cluster
   finding, calibration and fitting methods
ID II PIXEL DETECTOR; REDUCTION SYSTEM
AB The NeuroBayes machine learning algorithm is deployed for online data reduction at the pixel detector of Belle II. In order to test, characterize and easily adapt its implementation on FPGAs, a framework was developed. Within the framework an HDL model, written in python using MyHDL, is used for fast exploration of possible configurations. Under usage of input data from physics simulations figures of merit like throughput, accuracy and resource demand of the implementation are evaluated in a fast and flexible way. Functional validation is supported by usage of unit tests and HDL simulation for chosen configurations.
C1 [Baehr, S.; Sander, O.; Becker, J.] Karlsruhe Inst Technol ITIV, Engesserstr 5, D-76021 Karlsruhe, Germany.
   [Heck, M.; Feindt, M.] Karlsruhe Inst Technol IEKP, Karlsruhe, Germany.
RP Baehr, S (corresponding author), Karlsruhe Inst Technol ITIV, Engesserstr 5, D-76021 Karlsruhe, Germany.
EM Steffen.baehr@kit.edu
CR [Anonymous], 2012, AMBA AXI ACE PROT SP
   [Anonymous], ARXIV10110352
   Feindt M, 2011, NUCL INSTRUM METH A, V654, P432, DOI 10.1016/j.nima.2011.06.008
   Furletov S, 2012, J INSTRUM, V7, DOI 10.1088/1748-0221/7/01/C01014
   Gessler T, 2015, IEEE T NUCL SCI, V62, P1149, DOI 10.1109/TNS.2015.2414713
   KEMMER J, 1987, NUCL INSTRUM METH A, V253, P365, DOI 10.1016/0168-9002(87)90518-3
   Knopf J, 2011, J INSTRUM, V6, DOI 10.1088/1748-0221/6/01/C01085
   Lemarenko M, 2012, J INSTRUM, V7, DOI 10.1088/1748-0221/7/01/C01069
   Levit D., 2014, IEEE REAL TIM C, P1
   Levit D., 2013, IEEE NUCL SCI S, P1
   Mentor Graphics, MOD US MAN 10 2A
   Moll A, 2011, J PHYS CONF SER, V331, DOI 10.1088/1742-6596/331/3/032024
   Spruck B, 2013, IEEE T NUCL SCI, V60, P3709, DOI 10.1109/TNS.2013.2281571
NR 13
TC 1
Z9 1
U1 0
U2 3
PD JAN
PY 2016
VL 11
AR C01058
DI 10.1088/1748-0221/11/01/C01058
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Lu, H
   Wei, X
   Lin, N
   Yan, GH
   Li, XW
AF Lu, Hang
   Wei, Xin
   Lin, Ning
   Yan, Guihai
   Li, Xiao-Wei
GP Assoc Comp Machinery
TI Tetris: Re-architecting Convolutional Neural Network Computation for
   Machine Learning Accelerators
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
   DIGEST OF TECHNICAL PAPERS
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 37th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 05-08, 2018
CL San Diego, CA
AB Inference efficiency is the predominant consideration in designing deep learning accelerators. Previous work mainly focuses on skipping zero values to deal with remarkable ineffectual computation, while zero bits in non-zero values, as another major source of ineffectual computation, is often ignored. The reason lies on the difficulty of extracting essential bits during operating multiply-and-accumulate (MAC) in the processing element. Based on the fact that zero bits occupy as high as 68.9% fraction in the overall weights of modern deep convolutional neural network models, this paper firstly proposes a weight kneading technique that could eliminate ineffectual computation caused by either zero value weights or zero bits in non-zero weights, simultaneously. Besides, a split-and-accumulate (SAC) computing pattern in replacement of conventional MAC, as well as the corresponding hardware accelerator design called Tetris are proposed to support weight kneading at the hardware level. Experimental results prove that Tetris could speed up inference up to 1.50x, and improve power efficiency up to 5.33x compared with the state-of-the-art baselines.
C1 [Lu, Hang; Yan, Guihai; Li, Xiao-Wei] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Lu, Hang; Wei, Xin; Lin, Ning; Yan, Guihai; Li, Xiao-Wei] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Lu, H (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.; Lu, H (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM luhang@ict.ac.cn; weixin@ict.ac.cn; linning@ict.ac.cn; yan@ict.ac.cn;
   lxw@ict.ac.cn
CR [Anonymous], 2017, INCREMENTAL NETWORK
   [Anonymous], DES COMP
   [Anonymous], CAFFE MODEL ZOO
   [Anonymous], 2017, P 44 ANN INT S COMP
   [Anonymous], 49 ANN IEEE ACM INT
   [Anonymous], ARXIV13124400V3
   [Anonymous], CAFFE DEEP LEARNING
   [Anonymous], P 43 INT S COMP ARCH
   [Anonymous], 2014, P 47 ANN IEEE ACM IN
   [Anonymous], 2017, P 50 ANN IEEE ACM IN
   [Anonymous], TENSORRT PROGR INF A
   [Anonymous], 2014, ARXIV14091556V6
   [Anonymous], ARXIV160504711V2
   [Anonymous], PRIMETIME STAT TIM A
   Chen YH, 2017, IEEE MICRO, V37, P12, DOI 10.1109/MM.2017.54
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Zhang X, 2014, 2013 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CLOUD COMPUTING (ISCC), P19, DOI 10.1109/ISCC.2013.16
NR 20
TC 24
Z9 25
U1 0
U2 4
PY 2018
DI 10.1145/3240765.3240855
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zyarah, AM
   Kudithipudi, D
AF Zyarah, Abdullah M.
   Kudithipudi, Dhireesha
TI Semi-Trained Memristive Crossbar Computing Engine with <i>In Situ</i>
   Learning Accelerator
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE On-device learning; semi-trained neural network; memristive crossbar;
   extreme learning machine
ID MACHINE
AB On-device intelligence is gaining significant attention recently as it offers local data processing and low power consumption. In this research, an on-device training circuitry for threshold-current memristors integrated in a crossbar structure is proposed. Furthermore, alternate approaches of mapping the synaptic weights into fully trained and semi-trained crossbars are investigated. In a semi-trained crossbar, a confined subset of memristors are tuned and the remaining subset of memristors are not programmed. This translates to optimal resource utilization and power consumption, compared to a fully programmed crossbar. The semi-trained crossbar architecture is applicable to a broad class of neural networks. System level verification is performed with an extreme learning machine for binomial and multinomial classification. The total power for a single 4 x 4 layer network, when implemented in IBM 65nm node, is estimated to be approximate to 42.16 mu W and the area is estimated to be 26.48 mu m x 22.35 mu m.
C1 [Zyarah, Abdullah M.; Kudithipudi, Dhireesha] Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
RP Zyarah, AM (corresponding author), Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
EM amz6011@rit.edu; dxkeec@rit.edu
CR Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   [Anonymous], ARXIV170705316
   [Anonymous], 2015, ARXIV150606899
   [Anonymous], 2016, THESIS
   Auerbach JE, 2014, ALIFE 2014: THE FOURTEENTH INTERNATIONAL CONFERENCE ON THE SYNTHESIS AND SIMULATION OF LIVING SYSTEMS, P465, DOI 10.7551/978-0-262-32621-6-ch076
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chakma G, 2018, IEEE J EM SEL TOP C, V8, P125, DOI 10.1109/JETCAS.2017.2777181
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Fan DL, 2014, IEEE T NANOTECHNOL, V13, P574, DOI 10.1109/TNANO.2014.2312177
   Hasan R, 2017, MICROELECTRON J, V66, P31, DOI 10.1016/j.mejo.2017.05.005
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Kawahara T, 2008, IEEE J SOLID-ST CIRC, V43, P109, DOI 10.1109/JSSC.2007.909751
   Kim H, 2012, IEEE T CIRCUITS-I, V59, P148, DOI 10.1109/TCSI.2011.2161360
   Kvatinsky S, 2013, IEEE T CIRCUITS-I, V60, P211, DOI 10.1109/TCSI.2012.2215714
   Lichman M., 2013, UCI MACHINE LEARNING
   Merkel C, 2014, IEEE COMP SOC ANN, P77, DOI 10.1109/ISVLSI.2014.67
   PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1
   Perina AB, 2017, 2017 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P516, DOI 10.1109/DSD.2017.32
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Sah MP, 2012, IEEE INT SYMP CIRC S, P1604
   Snider GS, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURES, P85, DOI 10.1109/NANOARCH.2008.4585796
   Soudry D, 2015, IEEE T NEUR NET LEAR, V26, P2408, DOI 10.1109/TNNLS.2014.2383395
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Suri M., 2015, NEURAL NETW IJCNN, V2015, P1, DOI DOI 10.1109/IJCNN.2015.7280603
   Taha TM, 2014, IEEE INT SOC CONF, P383, DOI 10.1109/SOCC.2014.6948959
   Yao E, 2017, IEEE T VLSI SYST, V25, P60, DOI 10.1109/TVLSI.2016.2558842
   Zyarah AM, 2017, IEEE INT SYMP CIRC S
   Zyarah AM, 2017, IEEE IJCNN, P3371, DOI 10.1109/IJCNN.2017.7966279
NR 37
TC 3
Z9 3
U1 0
U2 4
PD DEC
PY 2018
VL 14
IS 4
SI SI
AR 43
DI 10.1145/3233987
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Khandelwal, S
   Wadhwa, E
   Shreejith, S
AF Khandelwal, Shashwat
   Wadhwa, Eashan
   Shreejith, Shanker
BE Pericas, M
   Pnevmatikatos, D
   Trancoso, PPM
   Sourdis, I
TI Deep Learning-based Embedded Intrusion Detection System for Automotive
   CAN
SO 2022 IEEE 33RD INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 33rd International Conference on Application-specific Systems,
   Architectures and Processors (ASAP)
CY JUL 12-14, 2022
CL Gothenburg, SWEDEN
DE Field Programmable Gate Arrays; Controller Area Network; Intrusion
   Detection Systems; Machine Learning
AB Rising complexity of in-vehicle electronics is enabling new capabilities like autonomous driving and active safety. However, rising automation also increases risk of security threats which is compounded by lack of in-built security measures in legacy networks like CAN, allowing attackers to observe, tamper and modify information shared over such broadcast networks. Various intrusion detection approaches have been proposed to detect and tackle such threats, with machine learning models proving highly effective. However, deploying machine learning models will require high processing power through high-end processors or GPUs to perform them close to line rate. In this paper, we propose a hybrid FPGA-based ECU approach that can transparently integrate IDS functionality through a dedicated off-the-shelf hardware accelerator that implements a deep-CNN intrusion detection model. Our results show that the proposed approach provides an average accuracy of over 99% across multiple attack datasets with 0.64% false detection rates while consuming 94% less energy and achieving 51.8% reduction in per-message processing latency when compared to IDS implementations on GPUs.
C1 [Khandelwal, Shashwat; Wadhwa, Eashan; Shreejith, Shanker] Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
RP Khandelwal, S (corresponding author), Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
EM khandels@tcd.ie; wadhwae@tcd.ie; shankers@tcd.ie
CR Alshammari A., 2018, WIRELESS ENG TECHNOL, V9, P79, DOI [10.4236/wet.2018.94007, DOI 10.4236/WET.2018.94007]
   Cai Zhiqiang, 2019, BLACK HAT US, V2019, P39
   Cho KN, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12111309
   De Araujo PF, 2021, IEEE ACCESS, V9, P166855, DOI 10.1109/ACCESS.2021.3136147
   Desta Araya Kibrom, 2020, PROC INT TELECOMMUNI, P1
   Hanselmann M, 2020, IEEE ACCESS, V8, P58194, DOI 10.1109/ACCESS.2020.2982544
   Iehira K, 2018, CONSUM COMM NETWORK
   Ling C, 2012, PROC C INFORM TECHNO, V10
   Narayanan SN, 2015, Arxiv, DOI arXiv:1512.08048
   Nie S., 2017, BLACK HAT US
   R. B. GmbH, 2015, ENG CONTR UN MS 6
   Seo E, 2018, ANN CONF PRIV SECUR, P286
   Shreejith S, 2018, IEEE MICRO, V38, P72, DOI 10.1109/MM.2018.022071137
   Shreejith S, 2013, IEEE EMBED SYST LETT, V5, P12, DOI 10.1109/LES.2013.2243698
   Song HM, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100198
   Tariq S, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P1048, DOI 10.1145/3341105.3373868
   Weber M., 2018, 9 EUR C EMB REAL TIM
   Wu S, 2018, Arxiv, DOI arXiv:1802.04680
   Xilinx, 2021, CAN FD 3 0 US GUID
   Xilinx, 2020, ZYNQ DPU V3 2
   Yang L, 2022, IEEE INTERNET THINGS, V9, P616, DOI 10.1109/JIOT.2021.3084796
   Yang L, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013892
NR 22
TC 3
Z9 3
U1 2
U2 2
PY 2022
BP 88
EP 92
DI 10.1109/ASAP54787.2022.00023
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Rapp, M
   Amrouch, H
   Wolf, M
   Henkel, J
AF Rapp, Martin
   Amrouch, Hussam
   Wolf, Marilyn
   Henkel, Joerg
GP IEEE
TI Machine Learning Techniques to Support Many-Core Resource Management:
   Challenges and Opportunities
SO 2019 ACM/IEEE 1ST WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD)
DT Proceedings Paper
CT ACM/IEEE 1st Workshop on Machine Learning for CAD (MLCAD)
CY SEP 03-04, 2019
CL Canmore, CANADA
DE Resource Management; Machine Learning; Gray Box Modeling; Neural Network
   Design; Accelerator
ID SYSTEMS
AB Resource management in many-core processors, housing tens to hundreds of cores on a single die, becomes more and more challenging due to the ever-increasing number of possible management decisions (e.g., task mapping). Machine learning (ML) techniques emerge as promising solutions to support resource management algorithms in taking the best decisions due to their adaptability. However, there are several challenges with ML-based solutions. We discuss two key challenges in detail. Firstly, ML-based techniques often suffer from high computational complexity for the inference at run-time - which is especially critical when it comes to the embedded system domain. Secondly, employing ML techniques as a "black box" may result in deriving models that fail in reflecting the reality.
   We take a task migration technique that maximizes the performance of a thermally-constrained many-core as a case study. This technique selects the migration to execute next with the support of a neural network (NN) that predicts the performance impact of a migration. We demonstrate the above-mentioned challenges in this case study and discuss potential remedies. To lower the run-time overhead, we discuss overhead-aware design of the NN and using already existing accelerators in smartphone SoCs. Finally we also demonstrate how existing domain knowledge can be introduced into the models to ensure that models are consistent with the reality and experimentally show the potential.
C1 [Rapp, Martin; Amrouch, Hussam; Henkel, Joerg] Karlsruhe Inst Technol, Karlsruhe, Germany.
   [Wolf, Marilyn] Univ Nebraska, Lincoln, NE 68583 USA.
RP Rapp, M (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM martin.rapp@kit.edu; amrouch@kit.edu; mwolf@unl.edu; henkel@kit.edu
CR Amodei D., 2016, ARXIV160606565
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Chen Z, 2015, DES AUT TEST EUROPE, P1521
   Carvalho ELD, 2010, IEEE DES TEST COMPUT, V27, P26, DOI 10.1109/MDT.2010.106
   Doppa JR, 2019, IEEE DES TEST, V36, P35, DOI 10.1109/MDAT.2019.2932894
   Garey M. R., 1975, SIAM Journal on Computing, V4, P397, DOI 10.1137/0204035
   Hakhamaneshi K, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942062
   Hong Zhang, 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P1820, DOI 10.1109/IJCNN.1999.832655
   Huang W, 2006, IEEE T VLSI SYST, V14, P501, DOI 10.1109/TVLSI.2006.876103
   Ignatov A., 2018, ARXIV181001109
   Kim C, 2002, ACM SIGPLAN NOTICES, V37, P211, DOI 10.1145/605432.605420
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Mandal SK, 2019, IEEE T VLSI SYST, V27, P2842, DOI 10.1109/TVLSI.2019.2926106
   Pagani S., 2018, IEEE T COMPUTER AIDE, P1
   Pagani S, 2017, IEEE T COMPUT, V66, P147, DOI 10.1109/TC.2016.2564969
   Ramey Carl, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477491
   Rapp Martin, 2020, IEEE Transactions on Computers, V69, P1, DOI 10.1109/TC.2019.2935446
   Rapp M, 2019, DES AUT TEST EUROPE, P1579, DOI [10.23919/date.2019.8714974, 10.23919/DATE.2019.8714974]
   SINGH AK, 2013, DES AUT CON
   Wang S., 2019, ARXIV PREPRINT ARXIV
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1109/mlcad48534.2019.9142064
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Shen, HY
   Lee, YC
   Tong, TW
   Yang, CH
AF Shen, Hsueh-Yen
   Lee, Yu-Chi
   Tong, Tzu-Wei
   Yang, Chia-Hsiang
TI A 40-nm 91-mW, 90-fps Learning-Based Full HD Super-Resolution
   Accelerator
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Superresolution; Image reconstruction; Feature extraction; Kernel;
   Training; Throughput; Image restoration; CMOS integrated circuits;
   energy-efficient architecture; hardware accelerator; machine learning;
   super-resolution
ID INTERPOLATION; SVD
AB Super-resolution has been utilized in a plenty of applications to provide better visual experience. To meet the high-throughput and low-power needs, some dedicated accelerators for super-resolution have been proposed. Neural-network (NN)-based super-resolution accelerators achieve impressive restoration performance, but the high-computational complexity does not allow a high throughput for video streaming. This work presents a super-resolution accelerator that implements the rapid and accurate image super-resolution (RAISR) algorithm for reconstructing super-resolution images. The utilization of the low-resolution (LR) upscaler is increased by 50% by the proposed memory scheduling scheme. Kernel compression is utilized to reduce the overall on-chip memory by 72%. A patch reuse scheme achieves a 91% reduction in external memory access times compared to the direct-mapped design. The architecture is flexible to reconstruct full HD images with a variety of upscaling factors (2x, 3 x , 4 x). Fabricated in a 40-nm CMOS technology, the proposed super-resolution accelerator integrates 3.11-M gates in a core area of 3.33 mm (2) . The chip is able to deliver a throughput of 90 frame/s (fps) for all supported upscaling factors and dissipates 91 mW at 200 MHz. Compared with the state-of-the-art designs, this work achieves a 5.4-to-28.4 x higher normalized throughput with 5.1-to-36 x lower normalized energy dissipation.
C1 [Shen, Hsueh-Yen; Lee, Yu-Chi; Tong, Tzu-Wei; Yang, Chia-Hsiang] Natl Taiwan Univ, Grad Inst Elect Engn, Taipei 10617, Taiwan.
   [Shen, Hsueh-Yen; Tong, Tzu-Wei] MediaTek, Hsinchu 300, Taiwan.
   [Yang, Chia-Hsiang] Natl Taiwan Univ, Dept Elect Engn, Taipei 10617, Taiwan.
RP Yang, CH (corresponding author), Natl Taiwan Univ, Grad Inst Elect Engn, Taipei 10617, Taiwan.; Yang, CH (corresponding author), Natl Taiwan Univ, Dept Elect Engn, Taipei 10617, Taiwan.
EM chyee@ntu.edu.tw
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Barrett R., 1994, TEMPLATES SOLUTION L
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Forsythe G. E., 1960, T AM MATH SOC, V94, P1, DOI DOI 10.1090/S0002-9947-1960-0109825-2
   Guenther D, 2016, IEEE T CIRCUITS-I, V63, P1283, DOI 10.1109/TCSI.2016.2561904
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Jeong SC, 2010, EUR SIGNAL PR CONF, P1791
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2019, SYMP VLSI CIRCUITS, pC302, DOI [10.23919/VLSIC.2019.8778104, 10.23919/vlsic.2019.8778104]
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Shen HY, 2021, ISSCC DIG TECH PAP I, V64, P66, DOI 10.1109/ISSCC42613.2021.9366026
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zeyde R., 2010, P 7 INT C CURVES SUR, P711
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 23
TC 0
Z9 0
U1 2
U2 3
PD FEB
PY 2023
VL 58
IS 2
BP 520
EP 529
DI 10.1109/JSSC.2022.3207951
EA OCT 2022
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Khoshavi, N
   Sargolzaei, S
   Bi, Y
   Roohi, A
AF Khoshavi, Navid
   Sargolzaei, Saman
   Bi, Yu
   Roohi, Arman
GP IEEE
TI Entropy-Based Modeling for Estimating Adversarial Bit-flip Attack Impact
   on Binarized Neural Network
SO 2021 26TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 26th Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 18-21, 2021
CL ELECTR NETWORK
DE black-box attack; white-box attack; deep neural network accelerator;
   machine learning; bit-flip attack; Statistical Model
AB Over past years, the high demand to efficiently process deep learning (DL) models has driven the market of the chip design companies. However, the new Deep Chip architectures, a common term to refer to DL hardware accelerator, have slightly paid attention to the security requirements in quantized neural networks (QNNs), while the black/white -box adversarial attacks can jeopardize the integrity of the inference accelerator. Therefore in this paper, a comprehensive study of the resiliency of QNN topologies to black-box attacks is examined. Herein, different attack scenarios are performed on an FPGA-processor co-design, and the collected results are extensively analyzed to give an estimation of the impact's degree of different types of attacks on the QNN topology. To be specific, we evaluated the sensitivity of the QNN accelerator to a range number of bit-flip attacks (BFAs) that might occur in the operational lifetime of the device. The BFAs are injected at uniformly distributed times either across the entire QNN or per individual layer during the image classification. The acquired results are utilized to build the entropy-based model that can be leveraged to construct resilient QNN architectures to bit-flip attacks.
C1 [Khoshavi, Navid] Florida Polytech Univ, Lakeland, FL 33805 USA.
   [Sargolzaei, Saman] Univ Tennessee, Martin, TN 38238 USA.
   [Bi, Yu] Univ Rhode Isl, Kingston, RI 02881 USA.
   [Roohi, Arman] Univ Nebraska, Lincoln, NE USA.
RP Khoshavi, N (corresponding author), Florida Polytech Univ, Lakeland, FL 33805 USA.
EM nkhoshavinajafabadi@floridapoly.edu; ssargolz@utm.edu; yu_bi@uri.edu;
   aroohi@unl.edu
CR [Anonymous], 2015, 32 ICML
   Azizimazreah A., 2018, 2018 IEEE INT C, P1
   Courbariaux M., 2016, C NEUR INF PROC SYST
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Guo C, 2017, ARXIV PREPRINT ARXIV
   Khoshavi N, 2020, 21 INT S QUAL EL DES
   Khoshavi N., 2020, P 57 ACM IEEE DES AU, P1
   Rakin A. S., 2020, P IEEE CVF C COMP VI
   Rakin A.S., 2019, ARXIV PREPRINT ARXIV
   Roohi A, 2020, IEEE T COMPUT, V69, P349, DOI 10.1109/TC.2019.2949042
   Salamat S., 2020, IEEE T COMPUT
   Salamat S, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P53, DOI 10.1145/3289602.3293913
   Schirmeier H. B, 2016, THESIS TECHNICAL U D
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wu S, 2018, ARXIV PREPRINT ARXIV
NR 16
TC 2
Z9 2
U1 0
U2 0
PY 2021
BP 493
EP 498
DI 10.1145/3394885.3431594
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Saidi, A
   Ben Othman, S
   Dhouibi, M
   Ben Saoud, S
AF Saidi, Afef
   Ben Othman, Slim
   Dhouibi, Meriam
   Ben Saoud, Slim
TI FPGA-based implementation of classification techniques: A survey
SO INTEGRATION-THE VLSI JOURNAL
DT Article
DE Machine learning; Deep learning; Classification; Implementation;
   Optimizations; Challenges
ID SUPPORT VECTOR MACHINE; DEEP NEURAL-NETWORKS; AUTOMATED DETECTION; CNN;
   CANCER; ACCELERATION; EXPLORATION; ALGORITHMS; PREDICTION; SELECTION
AB Recently, a number of classification techniques have been introduced. However, processing large dataset in a reasonable time has become a major challenge. This made classification task more complex and expensive in calculation. Thus, the need for solutions to overcome these constraints such as field programmable gate arrays (FPGAs). In this paper, we give an overview of the various classification techniques. Then, we present the existing FPGA based implementation of these classification methods. After that, we investigate the confronted challenges and the optimizations strategies. Finally, we highlight the hardware accelerator architectures and tools for hardware design suggested to improve the FPGA implementation of classification methods.
C1 [Saidi, Afef; Ben Othman, Slim; Dhouibi, Meriam; Ben Saoud, Slim] Univ Carthage, Adv Syst Lab, Tunisia Polytech Sch, BP 743, La Marsa 2078, Tunisia.
RP Saidi, A (corresponding author), Univ Carthage, Adv Syst Lab, Tunisia Polytech Sch, BP 743, La Marsa 2078, Tunisia.
EM afef.saidi@ept.run.tn; Slim.benothman@ept.rnu.tn;
   meriam.dhouibi@ept.rnu.tn; slim.bensaoud@gmail.com
CR Abdelouahab K, 2017, IEEE EMBED SYST LETT, V9, P113, DOI 10.1109/LES.2017.2743247
   Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Afifi S, 2019, MICROPROCESS MICROSY, V65, P57, DOI 10.1016/j.micpro.2018.12.005
   Ahmed I. O., 2018, J CLIN ENG, V43, P22
   Ahmmed R, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P229, DOI 10.1109/ECACE.2017.7912909
   Alexander H., 2018, J NONLINEAR SCI
   Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2018, SSRG INT J ELECT COM, P14
   [Anonymous], 2019, DNNDK USER GUIDE
   [Anonymous], 2017, P 2017 22 INT C DIGI
   [Anonymous], 2018, INT J SCI RES SCI EN
   [Anonymous], 2014, PROC 8 INT WORKSHOP
   [Anonymous], 2018, 2018 17 INT S INFOTE, DOI DOI 10.1109/INFOTEH.2018.8345545
   [Anonymous], 2018, ZYNQ 7000 SOC TECHN
   [Anonymous], 2017, INT ARCH PHOTOGRAMM
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Arulmurugan R, 2018, L N COMPUT VIS BIOME, V28, P103, DOI 10.1007/978-3-319-71767-8_9
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Atallah DM, 2019, MULTIMED TOOLS APPL, V78, P20383, DOI 10.1007/s11042-019-7370-5
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Baptista D, 2018, ENERGIES, V11, DOI 10.3390/en11092460
   Batool M, 2019, 2019 INT C APPL ENG, P145, DOI [10.1109/ICAEM.2019.8853770, DOI 10.1109/ICAEM.2019.8853770]
   Behadada O, 2017, INT J DISTRIB SYST T, V8, P17, DOI 10.4018/IJDST.2017100102
   Ben Jabeur S, 2017, J RETAIL CONSUM SERV, V36, P197, DOI 10.1016/j.jretconser.2017.02.005
   Bi XA, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00018
   Bo CJ, 2018, MULTIMED TOOLS APPL, V77, P10419, DOI 10.1007/s11042-017-4403-9
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Cai H., 2019, ONCE FOR ALL TRAIN N
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Cao J, 2017, INT J NETW MANAG, V27, DOI 10.1002/nem.1962
   Carreira-Perpiñán MA, 2018, PROC CVPR IEEE, P8532, DOI 10.1109/CVPR.2018.00890
   Chaudhary P, 2017, P ICMSSP INT C MULT, P61, DOI DOI 10.1145/314511.3145521
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen WS, 2018, JPEN-PARENTER ENTER, V42, P132, DOI 10.1177/0148607116667282
   Chen XF, 2018, INT GEOSCI REMOTE SE, P2451, DOI 10.1109/IGARSS.2018.8517973
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Cho K., 2014, P C EMP METH NAT LAN, P1724
   Colangelo P, 2018, ANN IEEE SYM FIELD P, P73, DOI 10.1109/FCCM.2018.00020
   Delaye E, 2017, ICCAD-IEEE ACM INT, P908, DOI 10.1109/ICCAD.2017.8203877
   Ding HS, 2017, PROC INT CONF DOC, P507, DOI 10.1109/ICDAR.2017.89
   Disse E, 2018, CLIN NUTR, V37, P1661, DOI 10.1016/j.clnu.2017.07.017
   Du B.L, 2017, MACH LEARN ADV TECH, P1
   Errattahia R, 2019, COMPUT SPEECH LANG, V55, P187, DOI 10.1016/j.csl.2018.12.007
   Esmeray F., 2018, TRENDS COMPUT SCI IN, V3, P1
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fang SX, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P392, DOI 10.1109/FPT.2018.00081
   Faraone J, 2018, I C FIELD PROG LOGIC, P97, DOI 10.1109/FPL.2018.00025
   Feng X, 2019, INTEGRATION, V69, P309, DOI 10.1016/j.vlsi.2019.07.005
   Fujii T., 2017, FPGA REALIZATION DEE, P268
   Fujiwara Y, 2018, IEEE INT CONF BIG DA, P683, DOI 10.1109/BigData.2018.8622287
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Gao HB, 2018, IEEE T IND INFORM, V14, P4224, DOI 10.1109/TII.2018.2822828
   Garcia M.V. A, 2013, GARCA2013TASSA
   Geng T, 2018, I C FIELD PROG LOGIC, P394, DOI 10.1109/FPL.2018.00074
   Gianey HK, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P37, DOI 10.1109/MLDS.2017.11
   Giardino D, 2019, INT J ADV SCI ENG IN, V9, P167
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Mendes TSG, 2019, INT J IMAGE DATA FUS, V10, P58, DOI 10.1080/19479832.2018.1469547
   Goyani M., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI DOI 10.17485/ijst/2017/v10i9/108944
   Guan Y., 2017, USING DATA COMPRESSI, P14
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Gulten A.T, 2018, BALK J ELECT COMPUT, V6, P83
   Guo JM, 2017, INFORM SYST FRONT, V19, P1233, DOI 10.1007/s10796-017-9764-0
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Gupta S, 2017, PROC CVPR IEEE, P7272, DOI 10.1109/CVPR.2017.769
   Gurleen K, 2016, INT J ADV RES COMP S, V6, P258
   Hai M, 2017, PROCEDIA COMPUT SCI, V122, P1100, DOI 10.1016/j.procs.2017.11.479
   Haider SI, 2019, ELEKTRON ELEKTROTECH, V25, P47, DOI 10.5755/j01.eie.25.4.23970
   Han S, DESIGN AUTOMATION EF
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Hasan A, 2018, MATH COMPUT APPL, V23, DOI 10.3390/mca23010011
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hemanth DJ, 2014, NEUROCOMPUTING, V130, P98, DOI 10.1016/j.neucom.2011.12.066
   Higa A., 2018, INT J COMPUT APPL TE, V1, P23, DOI [10.7753/ijcatr0701.1004, DOI 10.7753/IJCATR0701.1004]
   Hong K, 2018, PATTERN RECOGN, V77, P140, DOI 10.1016/j.patcog.2017.12.013
   Hu HC, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P524, DOI 10.1109/CompComm.2017.8322601
   Hu Q., 2018, TRAINING BINARY WEIG, P657
   Hu QH, 2018, AAAI CONF ARTIF INTE, P3247
   Hu YM, 2019, IEEE COMP SOC ANN, P7, DOI 10.1109/ISVLSI.2019.00011
   Huang QG, 2018, IEEE WINT CONF APPL, P709, DOI 10.1109/WACV.2018.00083
   Hulaj A, 2017, 2017 INTERNATIONAL CONFERENCE ON CONTROL, ARTIFICIAL INTELLIGENCE, ROBOTICS & OPTIMIZATION (ICCAIRO), P283, DOI 10.1109/ICCAIRO.2017.59
   Hussain HM, 2013, IEEE ENG MED BIO, P3058, DOI 10.1109/EMBC.2013.6610186
   Hwang WJ, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P582, DOI 10.1109/TSP.2017.8076054
   Jabbar MA, 2017, BIOMED RES-INDIA, V28, P4154
   Jamma D, 2017, INT C MICROELECTRON, P330
   Javed A, 2017, BIOMED RES-INDIA, V28, P7361
   Jensen C, 2019, J APPL CLIN MED PHYS, V20, P146, DOI 10.1002/acm2.12542
   Jermyn M, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.094002
   Jiang JH, 2019, SOFT COMPUT, V23, P13321, DOI 10.1007/s00500-019-03874-y
   Jiang W., 2019, HARDWARE SOFTWARE CO
   Jiang WW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358192
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Jiang YY, 2017, MIDWEST SYMP CIRCUIT, P180, DOI 10.1109/MWSCAS.2017.8052890
   Jiao L, 2017, I C FIELD PROG LOGIC
   Jing Shen, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1200, DOI 10.1109/ICCT46805.2019.8947127
   Joshi A., 2018, ANAL K NEAREST NEIGH, V9, P26126, DOI DOI 10.24327/IJRSR.2018.0904
   Joshi P., 2019, INT RES J ENG TECHNO
   Kachris C, 2017, INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION (SAMOS 2017), P70, DOI 10.1109/SAMOS.2017.8344613
   Kamel A., 2018, ACCELERATING CNN INF
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Kaymak S, 2017, PROCEDIA COMPUT SCI, V120, P126, DOI 10.1016/j.procs.2017.11.219
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Kharrat A., 2019, CLASSIFICATION BRAIN, DOI [10.1117/12.2522848, DOI 10.1117/12.2522848]
   Kiilu K.K., 2018, INT J SCI RES PUBL, V8, DOI [10.29322/IJSRP.8.3.2018.p7517, DOI 10.29322/IJSRP.8.3.2018.P7517]
   Krishnan H., 2017, INT J ENG TECHNOL SC, V4, P457
   Kueh SM, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2867864
   Kumar Kotikalapudi Shiva, 2018, Int J Yoga, V11, P152, DOI 10.4103/ijoy.IJOY_76_16
   Kuttranont P., 2017, J TELECOMMUN ELECT C, V9
   Lamba A., 2016, INT J ADV RES COMPUT, V5, P430, DOI [10.17148/IJARCCE.2016.55101, DOI 10.17148/IJARCCE.2016.55101, DOI 10.17706/IJCCE.2016.5.6.430-440]
   Langhout GC, 2018, LASER MED SCI, V33, P619, DOI 10.1007/s10103-017-2433-1
   Levine S, 2016, J MACH LEARN RES, V17
   Li H., 2017, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1608.08710
   Li LF, 2019, IEEE ACCESS, V7, P11854, DOI 10.1109/ACCESS.2019.2892063
   Li M, 2018, TECHNOL HEALTH CARE, V26, pS509, DOI 10.3233/THC-174836
   Li YM, 2017, J MED IMAG HEALTH IN, V7, P444, DOI 10.1166/jmihi.2017.2033
   Li YC, 2018, EXPERT SYST APPL, V96, P261, DOI 10.1016/j.eswa.2017.12.016
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu C, 2018, APPL PSYCH MEAS, V42, P58, DOI 10.1177/0146621617712246
   Liu CC, 2019, SIGNAL PROCESS, V156, P84, DOI 10.1016/j.sigpro.2018.10.019
   Liu F., 2019, ARRHYTHMIAS CLASSIFI, P136
   Liu HY, 2019, KNOWL-BASED SYST, V163, P332, DOI 10.1016/j.knosys.2018.08.036
   Liu X, 2018, PROCEDIA COMPUT SCI, V141, P104, DOI 10.1016/j.procs.2018.10.155
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Liu ZQ, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P207, DOI 10.1109/FPT.2017.8280142
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Lu Qing, 2019, ICCAD
   Ludwig SA, 2018, INT SER OPER RES MAN, V262, P327, DOI 10.1007/978-3-319-65455-3_13
   Luo AW, 2019, IEEE ACCESS, V7, P14472, DOI 10.1109/ACCESS.2019.2894169
   Luo JH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041174
   Ma YF, 2017, I C FIELD PROG LOGIC
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mai JG, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P150, DOI 10.1109/RCAR.2018.8621732
   Malhotra S, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P42, DOI 10.1109/CONFLUENCE.2017.7943121
   Masino J, 2017, J ACOUST SOC AM, V141, P4220, DOI 10.1121/1.4983757
   Masood S., 2018, PREDICTION HUMAN ETH, P217
   McGinnis Ryan S., 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P410, DOI 10.1109/BHI.2018.8333455
   Ming L.C., 2018, GLOB J ENG TECHNOL R, P30
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Mohamed A.E, 2017, INT J APPL SCI TECHN, V7
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Motamedi M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3131289
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Munther A, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN (ICED), P210, DOI 10.1109/ICED.2014.7015800
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Oord A. V. D., 2016, ARXIV
   Osisanwo F. Y., 2017, INT J COMPUT TRENDS, V48, P128, DOI [10.14445/22312803/IJCTT-V48P126, DOI 10.14445/22312803/IJCTT-V48P126]
   Owaida M, 2017, I C FIELD PROG LOGIC
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Parmar Y, 2020, IEEE T CIRCUITS-II, V67, P370, DOI 10.1109/TCSII.2019.2907974
   Pathan S, 2020, BIOCYBERN BIOMED ENG, V40, P52, DOI 10.1016/j.bbe.2019.11.003
   Patil R. A., 2012, Proceedings of the 25th International Conference on VLSI Design. VLSI Design 2012. Held jointly with 11th International Conference on Embedded Systems, P62, DOI 10.1109/VLSID.2012.47
   PATIL RR, 2014, INT J ADV RES COMPUT, V3, P6787
   Pfeiffer Mark, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1527, DOI 10.1109/ICRA.2017.7989182
   Pi YL, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2019.101009
   Pitsis G, 2019, INT CONF ACOUST SPEE, P3917, DOI 10.1109/ICASSP.2019.8682732
   Poecze F, 2018, PROCEDIA COMPUT SCI, V130, P660, DOI 10.1016/j.procs.2018.04.117
   Porcello J.C., 2019, AEROSP CONF PROC, DOI 10.1109/AERO.2019.8741916
   Posewsky T, 2018, LECT NOTES COMPUT SC, V10793, P311, DOI 10.1007/978-3-319-77610-1_23
   Prabhat A., 2017, P INT C COMP COMM IN, P1
   Pradhan D, 2017, COMPUT BIOL CHEM, V70, P211, DOI 10.1016/j.compbiolchem.2017.08.009
   Priyanka S, 2015, INT J ADV RES COMPUT, V4, P2792
   Prost-Boucle A, 2017, I C FIELD PROG LOGIC
   Qiao YR, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3850
   Qin Q, 2018, IEEE INT SYMP PARAL, P729, DOI 10.1109/BDCloud.2018.00110
   Raj N, 2018, BIOMED PHARMACOL J, V11, P113
   Rajalakshmi R, 2018, COMPUT INTELL-US, V34, P363, DOI 10.1111/coin.12158
   Raju K. S., 2018, IMPROVED MAMMOGRAM C, P369
   Raman MRG, 2017, NEURAL NETWORKS, V92, P89, DOI 10.1016/j.neunet.2017.01.012
   Ramli S., 2018, INDONES J ELECT ENG, V9, P667, DOI [10.11591/ijeecs.v9.i3.pp667-672, DOI 10.11591/IJEECS.V9.I3.PP667-672]
   Rau CS, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15020277
   Renteria-Cedano J, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8070761
   Rui T, 2018, MULTIMED TOOLS APPL, V77, P10635, DOI 10.1007/s11042-017-4684-z
   Rui T, 2017, MULTIMED TOOLS APPL, V76, P25079, DOI 10.1007/s11042-017-4837-0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sagala NTM, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P1, DOI 10.1145/3195106.3195129
   Saini R, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P2129, DOI 10.1109/RTEICT.2017.8256976
   Sarker I.H., 2018, IMPROVED NAIVE BAYES, P72
   Saurav S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P766, DOI 10.1109/ICACCI.2018.8554645
   Sayehi I, 2017, INT J ADV COMPUT SC, V8, P148
   Sejdinovic D, 2017, IFMBE PROC, V62, P685, DOI 10.1007/978-981-10-4166-2_103
   Seto K, 2019, INT SYM QUAL ELECT, P253, DOI 10.1109/ISQED.2019.8697641
   Sharifzadeh F, 2019, J INDIAN SOC REMOTE, V47, P551, DOI 10.1007/s12524-018-0891-y
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shi JS, 2018, AAAI CONF ARTIF INTE, P8157
   Shinji K., 2018, SASIMI 2018 P, P326
   Singh P, 2019, IEEE WINT CONF APPL, P1318, DOI 10.1109/WACV.2019.00145
   Sirkunan J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTER SCIENCE AND INFORMATICS (EECSI), P39
   Sohail A, 2018, BIOMED OPT EXPRESS, V9, P2041, DOI 10.1364/BOE.9.002041
   Soni S, 2014, INT J COMPUT APPL, V92, P0975, DOI DOI 10.5120/16045-5206
   Soofi A.A., 2017, J BASIC APPL SCI, V13, P459, DOI [DOI 10.6000/1927-5129.2017.13.76, 10.6000/1927-5129.2017.13.76]
   Sorensen L, 2018, J NEUROSCI METH, V302, P66, DOI 10.1016/j.jneumeth.2018.01.003
   Spagnolo F, 2020, J LOW POWER ELECT AP, V10, DOI 10.3390/jlpea10010001
   Sree BRL, 2019, INT J SPEECH TECHNOL, V22, P143, DOI 10.1007/s10772-018-09586-2
   Suleiman A, 2017, IEEE J SOLID-ST CIRC, V52, P844, DOI 10.1109/JSSC.2017.2648820
   Sun G., 2018, INT J PERFORM ENG, V14, P1088
   Sutskever I., 2014, ADV NEUR IN, P3104
   Syarif AR, 2017, INT CONF INFORM COMM, P181, DOI 10.1109/ICTS.2017.8265667
   Syed F.H., 2017, PACIS 2017 P
   Sze V, 2017, IEEE CUST INTEGR CIR
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tahmassebi A., 2018, COMPLEXITY, V2018, P2740817, DOI [DOI 10.1155/2018/2740817, 10.1155/2018/2740817]
   Talbot R., 2015, P 9 INT WORKSH SEM E, P626
   Tangthaikwan K, 2017, INT CONF KNOWL SMART, P111, DOI 10.1109/KST.2017.7886107
   Tayeb S, 2017, IEEE INT CONF BIG DA, P3897, DOI 10.1109/BigData.2017.8258395
   Tharwat A, 2018, EXPERT SYST APPL, V107, P32, DOI 10.1016/j.eswa.2018.04.017
   Trisal SK, 2019, J INTELL FUZZY SYST, V36, P5475, DOI 10.3233/JIFS-181336
   Tsoutsouras V, 2017, J SIGNAL PROCESS SYS, V88, P127, DOI 10.1007/s11265-017-1230-1
   Tuhin RA, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P360, DOI [10.1109/ccoms.2019.8821658, 10.1109/CCOMS.2019.8821658]
   Tung F, 2018, PROC CVPR IEEE, P7873, DOI 10.1109/CVPR.2018.00821
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vaishnnave MP, 2019, 2019 IEEE INT C SYST, P15, DOI DOI 10.1109/ICSCAN.2019.8878733
   Veena V, 2018, INT J COMPUT ENG APP, P1
   VENIERIS SI, 2017, I C FIELD PROG LOGIC, DOI DOI 10.23919/FPL.2017.8056828
   Verma A, 2019, ADV INFORM COMPUTING, P149
   Vinh N., 2018, 3 JORN COMP EMP REC
   Vojt J., 2016, DEEP NEURAL NETWORKS
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang HD, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P956, DOI 10.1109/IEMCON.2018.8614917
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Wang M, 2019, INT J MACH LEARN CYB, V10, P3031, DOI 10.1007/s13042-018-00920-3
   Wang WR, 2014, AAAI CONF ARTIF INTE, P2128
   Wang YR, 2019, INT J REMOTE SENS, V40, P7356, DOI 10.1080/01431161.2018.1513669
   Wang Y, 2018, J MED IMAG HEALTH IN, V8, P62, DOI 10.1166/jmihi.2018.2233
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wu RD, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020143
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xu Y, 2018, IEICE ELECTRON EXPR, V15, DOI 10.1587/elex.15.20180099
   Xu Z., 2018, BMVC BRIT MACHINE VI
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yu JC, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P227, DOI 10.1109/FPT.2017.8280147
   Zairi H, 2020, NEURAL COMPUT APPL, V32, P4105, DOI 10.1007/s00521-019-04081-4
   Zeng HY, 2016, BIOINFORMATICS, V32, P121, DOI 10.1093/bioinformatics/btw255
   Zhai XL, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00379
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2018, ISPRS J PHOTOGRAMM, V140, P133, DOI 10.1016/j.isprsjprs.2017.07.014
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030295
   Zhang TY, 2018, LECT NOTES COMPUT SC, V11212, P191, DOI 10.1007/978-3-030-01237-3_12
   Zhang Xiaofan, 2019, ARXIV190508369
   Zhang Xiaofan, 2017, 2017 27 INT C FIELD, P1
   Zhang XY, 2019, IEEE COMP SOC ANN, P25, DOI 10.1109/ISVLSI.2019.00014
   Zhao MH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020350
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhao RZ, 2018, I C FIELD PROG LOGIC, P147, DOI 10.1109/FPL.2018.00033
   Zhiqiang L, 2019, ELECTRONICS, P1
   Zhong GW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3301278
   Zhou T, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101630
   Zhuang BH, 2018, PROC CVPR IEEE, P7920, DOI 10.1109/CVPR.2018.00826
   Zhuang Z., 2018, ADV NEURAL INFORM PR, P875
NR 261
TC 11
Z9 11
U1 3
U2 36
PD NOV
PY 2021
VL 81
BP 280
EP 299
DI 10.1016/j.vlsi.2021.08.004
EA AUG 2021
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Chaudhuri, A
   Talukdar, J
   Chakrabarty, K
AF Chaudhuri, Arjun
   Talukdar, Jonti
   Chakrabarty, Krishnendu
GP IEEE
TI Special Session: Fault Criticality Assessment in AI Accelerators
SO 2022 IEEE 40TH VLSI TEST SYMPOSIUM (VTS)
SE IEEE VLSI Test Symposium
DT Proceedings Paper
CT 40th IEEE VLSI Test Symposium (VTS)
CY APR 25-27, 2022
CL ELECTR NETWORK
AB The ubiquitous application of deep neural networks (DNN) has led to a rise in demand for AI accelerators. DNN-specific functional criticality analysis identifies faults that cause measurable and significant deviations from acceptable requirements such as the inferencing accuracy. This paper examines the problem of classifying structural faults in the processing elements (PEs) of systolic-array accelerators. We first present a two-tier machine-learning (ML) based method to assess the functional criticality of faults. The problem of minimizing misclassification is addressed by utilizing generative adversarial networks (GANs). The two- tier ML/GAN-based criticality assessment method leads to less than 1 % test escapes during functional criticality evaluation of structural faults. While supervised learning techniques can be used to accurately estimate fault criticality, it requires a considerable amount of ground truth for model training. We therefore describe a neural-twin framework for analyzing fault criticality with a negligible amount of ground-truth data. A recently proposed misclassification-driven training algorithm is used to sensitize and identify biases that are critical to the functioning of the accelerator for a given application workload. The proposed framework achieves up to 100% accuracy in fault-criticality classification in 16-bit and 32-bit PEs by using the criticality knowledge of only 2% of the total faults in a PE.
C1 [Chaudhuri, Arjun; Talukdar, Jonti; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
RP Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
CR ai, GOOGLE EDGE TPU CORA
   bit, SYSTEM ARCHITECTURE
   Chaudhuri A., 2021, DATE
   Chaudhuri A, 2021, IEEE ITC
   Chaudhuri A, 2020, INT TEST CONF P, DOI 10.1109/ITC44778.2020.9325272
   Chaudhuri A, 2020, ASIAN TEST SYMPOSIUM, P18, DOI [10.1109/ATS49688.2020.9301581, 10.1109/ats49688.2020.9301581]
   Chauhan A, 2023, INORG NANO-MET CHEM, V53, P460, DOI 10.1080/24701556.2021.2025078
   Chen CY, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1074, DOI 10.23919/DATE51398.2021.9473989
   Gebregiorgis A, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000110
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kundu S, 2021, IEEE T VLSI SYST, V29, P485, DOI 10.1109/TVLSI.2020.3048829
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Sadi M, 2022, IEEE T COMPUT AID D, V41, P104, DOI 10.1109/TCAD.2021.3051841
   Zhang J, 2018, IEEE VLSI TEST SYMP
NR 15
TC 1
Z9 1
U1 2
U2 2
PY 2022
DI 10.1109/VTS52500.2021.9794215
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Constantinides, GA
AF Constantinides, G. A.
TI Rethinking arithmetic for deep neural networks
SO PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL
   AND ENGINEERING SCIENCES
DT Editorial Material
DE neural network; computing; accelerator; field-programmable gate array
AB We consider efficiency in the implementation of deep neural networks. Hardware accelerators are gaining interest as machine learning becomes one of the drivers of high-performance computing. In these accelerators, the directed graph describing a neural network can be implemented as a directed graph describing a Boolean circuit. We make this observation precise, leading naturally to an understanding of practical neural networks as discrete functions, and show that the so-called binarized neural networks are functionally complete. In general, our results suggest that it is valuable to consider Boolean circuits as neural networks, leading to the question of which circuit topologies are promising. We argue that continuity is central to generalization in learning, explore the interaction between data coding, network topology, and node functionality for continuity and pose some open questions for future research. As a first step to bridging the gap between continuous and Boolean views of neural network accelerators, we present some recent results from our work on LUTNet, a novel Field-Programmable Gate Array inference approach. Finally, we conclude with additional possible fruitful avenues for research bridging the continuous and discrete views of neural networks. This article is part of a discussion meeting issue 'Numerical algorithms for high-performance computational science'.
C1 [Constantinides, G. A.] Imperial Coll London, EEE Dept, London, England.
RP Constantinides, GA (corresponding author), Imperial Coll London, EEE Dept, London, England.
EM g.constantinides@imperial.ac.uk
CR [Anonymous], 2003, DIGITAL ARITHMETIC
   BLUM L, 1989, B AM MATH SOC, V21, P1, DOI 10.1090/S0273-0979-1989-15750-9
   Bondy J., 2008, GRAPH THEORY
   BRAYTON RK, 1990, P IEEE, V78, P264, DOI 10.1109/5.52213
   Clote Peter, 2002, BOOLEAN FUNCTIONS CO
   Couroucli M, 2016, BRIT SCH ATHENS MOD, V1, P1
   Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263
   Du Simon S, 2019, ICLR
   Gephi, 2017, OP GRAPH VIZ PLATF
   Ghasemzadeh M, 2018, P IEEE INT S FIELD P
   Gillis N, 2014, J GLOBAL OPTIM, V58, P439, DOI 10.1007/s10898-013-0053-2
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gouk H., 2018, REGULARISATION NEURA
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Haaswijk W, 2018, P DES AUT C SAN FRAN
   Han Song, 2015, C NEUR INF PROC SYST
   Har-Even B, 2018, POWERVR SERIES2NX RA
   Hauck Scott, 2007, RECONFIGURABLE COMPU
   Higham Nicholas J, 2002, ACCURACY STABILITY N, Vsecond, DOI [10.1137/1.9780898718027, DOI 10.1137/1.9780898718027]
   Hopkins M, 2019, STOCHASTIC ROUNDING
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Kahn G, 1974, P IFIP C INF PROC ST
   Koren I., 2001, COMPUTER ARITHMETIC
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Le Q. V., 2016, ARXIV161101578
   LeCun Y., 1989, CONNECTIONISM PERSPE, V19, P143
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Neal R.M., 1994, CRGTR941 U TOR
   Nielson F., 2010, PRINCIPLES PROGRAM A
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   O Searcoid M., 2007, METRIC SPACES
   Quine Willard V., 1952, AM MATH MON, V59, P521, DOI [10.1080/00029890.1952.11988183, DOI 10.1080/00029890.1952.11988183]
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   RUDELL RL, 1987, IEEE T COMPUT AID D, V6, P727, DOI 10.1109/TCAD.1987.1270318
   Savage C, 1997, SIAM REV, V39, P605, DOI 10.1137/S0036144595295272
   Scaman K, 2018, ADV NEUR IN, V31
   Schey KL., 2016, SIAG OPT VIEWS NEWS, V24, P1, DOI DOI 10.1016/J.STR.2016.05.011.DYNAMICAL
   Strang G, 2018, SIAM NEWS
   Su J, 2018, TECHNICAL REPORT
   Triggs R, 2018, CLOSER LOOK ARMS MAC
   TRIVEDI KS, 1977, IEEE T COMPUT, V26, P681, DOI 10.1109/TC.1977.1674901
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang E, 2019, P IEEE INT S FIELD P
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Warren Henry S., 2012, HACKERS DELIGHT, V2nd
   Weste N, 2002, CMOS VLSI DESIGN CIR
   Wolf Clifford, 2013, YOSYS OPEN SYNTHESIS
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
NR 49
TC 1
Z9 1
U1 0
U2 6
PD MAR 6
PY 2020
VL 378
IS 2166
SI SI
AR 20190051
DI 10.1098/rsta.2019.0051
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Zhang, P
   Fang, JB
   Tang, T
   Yang, CQ
   Wang, Z
AF Zhang, Peng
   Fang, Jianbin
   Tang, Tao
   Yang, Canqun
   Wang, Zheng
GP IEEE
TI Auto-tuning Streamed Applications on Intel Xeon Phi
SO 2018 32ND IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS)
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 27th International Heterogeneity in Computing Workshop in conjunction
   with 32nd IEEE International Parallel and Distributed Processing
   Symposium (IPDPS)
CY MAY 21-25, 2018
CL Vancouver, CANADA
DE Heterogeneous computing; Parallelism; Performance Tuning; Machine
   learning
AB Many-core accelerators, as represented by the XeonPhi coprocessors and GPGPUs, allow software to exploit spatial and temporal sharing of computing resources to improve the overall system performance. To unlock this performance potential requires software to effectively partition the hardware resource to maximize the overlap between host-device communication and accelerator computation, and to match the granularity of task parallelism to the resource partition. However, determining the right resource partition and task parallelism on a per program, per dataset basis is challenging. This is because the number of possible solutions is huge, and the benefit of choosing the right solution may be large, but mistakes can seriously hurt the performance. In this paper, we present an automatic approach to determine the hardware resource partition and the task granularity for any given streamed application, targeting the Intel XeonPhi architecture. Instead of hand-crafting the heuristic for which the process will have to repeat for each hardware generation, we employ machine learning techniques to automatically learn it. We achieve this by first learning a predictive model offline using training programs; we then use the learned model to predict the resource partition and task granularity for any unseen programs at runtime. We apply our approach to 23 representative parallel applications and evaluate it on a CPU-XeonPhi mixed heterogenous many-core platform. Our approach achieves, on average, a 1.6x (upto 5.6x) speedup, which translates to 94.5% of the performance delivered by a theoretically perfect predictor.
C1 [Zhang, Peng; Fang, Jianbin; Tang, Tao; Yang, Canqun] Natl Univ Def Technol, Coll Comp, Compiler Lab, Changsha, Hunan, Peoples R China.
   [Wang, Zheng] Univ Lancaster, Sch Comp & Commun, MetaLab, Lancaster, England.
RP Zhang, P (corresponding author), Natl Univ Def Technol, Coll Comp, Compiler Lab, Changsha, Hunan, Peoples R China.
EM zhangpeng13a@nudt.edu.cn; j.fang@nudt.edu.cn; taotang84@nudt.edu.cn;
   canqun@nudt.edu.cn; z.wang@lancaster.ac.uk
CR [Anonymous], 2016, NPC
   [Anonymous], 2015, HSTREAMS ARCH MPSS 3
   [Anonymous], 2015, CUDA C BEST PRACTICE
   [Anonymous], 2014, HIPC
   [Anonymous], 2016, IPDPSW
   [Anonymous], 2013, CGO
   [Anonymous], ICPE
   [Anonymous], 2014, INT WORKSHOP LANGUAG
   Boyer M., 2013, IPDPSW
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen C, 2017, COMPUTING, V99, P791, DOI 10.1007/s00607-016-0537-2
   Cummins C, 2017, INT CONFER PARA, P219, DOI 10.1109/PACT.2017.24
   Cummins Chris, 2017, CGO
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Emani MK, 2013, INT SYM CODE GENER, P347
   Fang J., 2016, PARALLEL PROCESSING
   Fursin Grigori, 2008, GCC SUMMIT
   Gomez-Luna, 2012, J PARALLEL DISTRIBUT
   Gregg C., 2011, ISPASS
   Grewe D., 2011, HIPEAC
   Grewe D., 2013, LCPC
   Jianbin Fang, 2011, 2011 International Conference on Parallel Processing, P216, DOI 10.1109/ICPP.2011.45
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Li A., 2017, SC
   Liu B., 2015, IJHPCA
   Luk C.-K., 2009, MICRO
   Manly BFJ., 2004, MULTIVARIATE STAT ME, V3rd ed
   Marco V. S., 2017, P 18 ACM IFIP USENIX
   Meswani M. R., 2013, IJHPCA
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Newburn C. J., 2016, IPDPSW
   Ogilvie W. F., 2017, CGO
   Owens J. D., 2008, P IEEE
   Ren J, 2017, IEEE INFOCOM SER
   Taylor B., LCTES
   The Khronos OpenCL Working Group, 2016, OPENCL OP STAND PAR
   Tournavitis G., 2009, PLDI
   Wang Z., 2010, PACT
   WANG Z, 2009, PPOPP
   Wang Z., 2014, CC
   Wang Z, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2579561
   Wang Z, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2512436
   Werkhoven V., 2014, CCGRID
NR 45
TC 12
Z9 13
U1 0
U2 4
PY 2018
BP 515
EP 525
DI 10.1109/IPDPS.2018.00061
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Wang, Z
   Zhou, LB
   Xie, WT
   Chen, WG
   Su, JY
   Chen, WX
   Du, AH
   Li, SL
   Liang, ML
   Lin, YJ
   Zhao, W
   Wu, YZ
   Sun, TF
   Fang, WQ
   Yu, ZB
AF Wang, Zheng
   Zhou, Libing
   Xie, Wenting
   Chen, Weiguang
   Su, Jinyuan
   Chen, Wenxuan
   Du, Anhua
   Li, Shanliao
   Liang, Minglan
   Lin, Yuejin
   Zhao, Wei
   Wu, Yanze
   Sun, Tianfu
   Fang, Wenqi
   Yu, Zhibin
TI Accelerating hybrid and compact neural networks targeting perception and
   control domains with coarse-grained dataflow reconfiguration
SO JOURNAL OF SEMICONDUCTORS
DT Article
DE CMOS technology; digital integrated circuits; neural networks; dataflow
   architecture
ID GAME; GO
AB Driven by continuous scaling of nanoscale semiconductor technologies, the past years have witnessed the progressive advancement of machine learning techniques and applications. Recently, dedicated machine learning accelerators, especially for neural networks, have attracted the research interests of computer architects and VLSI designers. State-of-the-art accelerators increase performance by deploying a huge amount of processing elements, however still face the issue of degraded resource utilization across hybrid and non-standard algorithmic kernels. In this work, we exploit the properties of important neural network kernels for both perception and control to propose a reconfigurable dataflow processor, which adjusts the patterns of data flowing, functionalities of processing elements and on-chip storages according to network kernels. In contrast to state-of-the-art fine-grained data flowing techniques, the proposed coarse-grained dataflow reconfiguration approach enables extensive sharing of computing and storage resources. Three hybrid networks for MobileNet, deep reinforcement learning and sequence classification are constructed and analyzed with customized instruction sets and toolchain. A test chip has been designed and fabricated under UMC 65 nm CMOS technology, with the measured power consumption of 7.51 mW under 100 MHz frequency on a die size of 1.8 x 1.8 mm(2).
C1 [Wang, Zheng; Chen, Weiguang; Sun, Tianfu; Fang, Wenqi; Yu, Zhibin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Zhou, Libing; Xie, Wenting; Su, Jinyuan; Chen, Wenxuan; Du, Anhua; Lin, Yuejin; Zhao, Wei] Xidian Univ, Sch Microelect, Xian 710071, Peoples R China.
   [Li, Shanliao; Liang, Minglan] Guilin Univ Elect Technol, Sch Informat & Commun, Guilin 541004, Peoples R China.
   [Wu, Yanze] Changzhou Campus Hohai Univ, Changzhou 213022, Jiangsu, Peoples R China.
RP Wang, Z (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM zheng.wang@siat.ac.cn
CR [Anonymous], IEEE ACM INT S MICR
   [Anonymous], 2017, ABS170404861 CORR
   [Anonymous], 2018, IEEE AS PAC C CIRC S, P519
   Basterretxea K, 2004, IEE P-CIRC DEV SYST, V151, P18, DOI 10.1049/ip-cds:20030607
   Chen WG, 2019, IEEE COMP SOC ANN, P521, DOI 10.1109/ISVLSI.2019.00099
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1162/089976600300015015, 10.1049/cp:19991218]
   Gulli A., 2017, DEEP LEARNING KERAS
   Guo K, 2017, ARXIV171208934
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Li SL, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P544, DOI 10.1109/APCCAS.2018.8605662
   Lin DD, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Redmon J., 2016, ARXIV160207360, P779
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Vasilache Nicolas, 2014, ARXIV14127580
   Volodymyr Mnih, 2013, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1312.5602
   Yang CG, 2019, IEEE T NEUR NET LEAR, V30, P777, DOI 10.1109/TNNLS.2018.2852711
   Yin S, 2017, S VLSI CIRC
   YIN S, 2017, IEEE J SOLID-ST CIRC, V53, P968, DOI DOI 10.1109/JSSC.2017.2778281
NR 27
TC 3
Z9 3
U1 1
U2 3
PD FEB
PY 2020
VL 41
IS 2
AR 022401
DI 10.1088/1674-4926/41/2/022401
WC Physics, Condensed Matter
DA 2023-11-11
ER

PT J
AU Mathur, R
   Kumar, AKA
   John, L
   Kulkarni, JP
AF Mathur, Rahul
   Kumar, Ajay Krishna Ananda
   John, Lizy
   Kulkarni, Jaydeep P.
TI Thermal-Aware Design Space Exploration of 3-D Systolic ML Accelerators
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE 3-D integration; energy efficient; systolic accelerators; thermal
ID INTERCONNECT
AB Machine learning (ML) accelerators have a broad spectrum of use cases that pose different requirements on accelerator design for latency, energy, and area. In the case of systolic array-based ML accelerators, this puts different constraints on processing element (PE) array dimensions and SRAM buffer sizes. The 3-D integration packs more compute or memory in the same 2-D footprint, which can be utilized to build more powerful or energy-efficient accelerators. However, 3-D also expands the design space of ML accelerators by additionally including different possible ways of partitioning the PE array and SRAM buffers among the vertical tiers. Moreover, the partitioning approach may also have different thermal implications. This work provides a systematic framework for performing system-level design space exploration of 3-D systolic accelerators. Using this framework, different 3-D-partitioned accelerator configurations are proposed and evaluated. The 3-D-stacked accelerator designs are modeled using the hybrid wafer bonding technique with a 1.44-mu m pitch of 3-D connection. Results show that different partitioning of the systolic array and SRAM buffers in a four-tier 3-D configuration can lead to either 1.1-3.9x latency reduction or 1-3x energy reduction compared to the baseline design of the same 2-D area footprint. It is also shown that by carefully organizing the systolic array and SRAM tiers using logic over memory, the temperature rise with 3-D across benchmarks can be limited to 6 ffiC.
C1 [Mathur, Rahul; Kumar, Ajay Krishna Ananda; John, Lizy; Kulkarni, Jaydeep P.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Mathur, R (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM rahul.mathur@utexas.edu
CR Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2020, INT ROADMAP DEVICES
   [Anonymous], 2015, PROC IEEE SOI 3D SUB, DOI DOI 10.1109/S3S.2015.7333538
   Brunet L, 2018, INT EL DEVICES MEET
   Chen FC, 2019, ELEC COMP C, P594, DOI 10.1109/ECTC.2019.00095
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YY, 2015, IEEE INT ULTRA SYM, DOI 10.1109/ULTSYM.2015.0453
   Fisher DW, 2020, ELEC COMP C, P595, DOI 10.1109/ECTC32862.2020.00099
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gopireddy B, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P643, DOI 10.1145/3307650.3322233
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hu CC, 2019, S VLSI TECH, pT20, DOI 10.23919/VLSIT.2019.8776486
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jouve A, 2017, IEEE SOI3DSUB MICRO
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kung H. T., 1979, SPARSE MATRIX P, V1, P256
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kung S. Y., 1985, IEEE ASSP Magazine, V2, P4, DOI 10.1109/MASSP.1985.1163741
   Lau J. H., 2011, 2011 International Symposium on Advanced Packaging Materials (APM 2011), P462, DOI 10.1109/ISAPM.2011.6105753
   Lau J.H., 2021, SEMICONDUCTOR ADV PA, P343, DOI DOI 10.1007/978-981-16-1376-0_7
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Lin MS, 2020, IEEE J SOLID-ST CIRC, V55, P956, DOI 10.1109/JSSC.2019.2960207
   Mahajan R, 2019, IEEE T COMP PACK MAN, V9, P1952, DOI 10.1109/TCPMT.2019.2942708
   Mathur R, 2020, ELEC COMP C, P541, DOI 10.1109/ECTC32862.2020.00091
   Mocuta A, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P147, DOI 10.1109/VLSIT.2018.8510683
   Podpod A, 2018, ELEC COMP C, P370, DOI 10.1109/ECTC.2018.00063
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samajdar Ananda, 2018, SCALE SIM SYSTOLIC C
   Samal SK, 2014, DES AUT CON, DOI 10.1145/2593069.2593140
   Sayal A, 2019, ISSCC DIG TECH PAP I, V62, P228, DOI 10.1109/ISSCC.2019.8662510
   Sekiguchi M, 2006, ELEC COMP C, P1367, DOI 10.1109/ECTC.2006.1645835
   Shigetou A, 2006, IEEE T ADV PACKAGING, V29, P218, DOI 10.1109/TADVP.2006.873138
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Sinha S, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372120
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Vaswani A, 2017, ADV NEUR IN, V30
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Xilinx, 2018, ACC DNNS XIL ALV ACC
   Xu XL, 2020, IEEE T IND INFORM, V16, P4187, DOI 10.1109/TII.2019.2936869
   Yeric G, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Yeric G, 2019, IEEE CUST INTEGR CIR, DOI 10.1109/CICC.2019.8780343
   Zhang T, 2014, ARXIV14121058
NR 45
TC 9
Z9 9
U1 0
U2 0
PD JUN
PY 2021
VL 7
IS 1
BP 70
EP 78
DI 10.1109/JXCDC.2021.3092436
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Muscianisi, G
   Fiameni, G
   Azab, A
AF Muscianisi, Giuseppa
   Fiameni, Giuseppe
   Azab, Abdulrahman
BE Weiland, M
   Juckeland, G
   Alam, S
   Jagode, H
TI Singularity GPU Containers Execution on HPC Cluster
SO HIGH PERFORMANCE COMPUTING: ISC HIGH PERFORMANCE 2019 INTERNATIONAL
   WORKSHOPS
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 34th International Conference on High Performance Computing (ISC High
   Performance)
CY JUN 16-20, 2019
CL Frankfurt, GERMANY
DE Singularity; GPU; Tensorflow
AB This paper describes how to use the Singularity containerization tool in a HPC cluster equipped with GPU accelerators. The application chosen for benchmarking is Tensorflow, the open-source software library for machine learning. The singularity containers built have run into GALILEO HPC cluster at CINECA. A performance comparison between bare metal and container executions is also provided, showing a negligible difference in the number of images computed per second.
C1 [Muscianisi, Giuseppa; Fiameni, Giuseppe] CINECA Interuniv Consortium, Bologna, Italy.
   [Azab, Abdulrahman] Univ Oslo, Oslo, Norway.
RP Muscianisi, G (corresponding author), CINECA Interuniv Consortium, Bologna, Italy.
EM g.muscianisi@cineca.it; g.fiameni@cineca.it;
   abdulrahman.azab@usit.uio.no
CR Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurtzer GM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177459
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
NR 6
TC 2
Z9 2
U1 0
U2 2
PY 2020
VL 11887
BP 61
EP 68
DI 10.1007/978-3-030-34356-9_6
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Kundu, S
   Banerjee, S
   Raha, A
   Natarajan, S
   Basu, K
AF Kundu, Shamik
   Banerjee, Suvadeep
   Raha, Arnab
   Natarajan, Suriyaprakash
   Basu, Kanad
TI Toward Functional Safety of Systolic Array-Based Deep Learning Hardware
   Accelerators
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Circuit faults; Hardware; Fault tolerant systems; Fault tolerance;
   Testing; Safety; Arrays; Functional safety (FuSa); neural network
   accelerator; stuck-at faults; systolic array; tensor processing unit
   (TPU)
AB High accuracy and ever-increasing computing power have made deep neural networks (DNNs) the algorithm of choice for various machine learning, computer vision, and image processing applications across the computing spectrum. To this end, Google developed the tensor processing unit (TPU) to accelerate the computationally intensive matrix multiplication operation of a DNN on its systolic array architecture. Faults manifested in the datapath of such a systolic array due to latent manufacturing defects or single-event effects may lead to functional safety (FuSa) violation. Although DNNs are known to resist minor perturbations with their inherent fault-tolerant characteristics, we show that the classification accuracy of the model plummets from 97.4% to 7.75% with a minimal fault rate of 0.0003% in the accelerator, implying catastrophic circumstances when deployed across mission-critical systems. Hence, to ensure FuSa of such accelerators, this article provides an extensive FuSa assessment of the accelerator exposed to faults in the datapath, by varying the network parameters, position, and characteristics of the induced error across multiple exhaustive data sets. Furthermore, we propose two novel strategies to obtain a diminutive set of functional test patterns to detect FuSa violation in a DNN accelerator. Our experimental results demonstrate that the obtained test sets can achieve an average of 92.63% (in some cases, up to 100%) fault coverage with cardinality as low as 0.1% of the entire test data set.
C1 [Kundu, Shamik; Basu, Kanad] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75080 USA.
   [Banerjee, Suvadeep; Raha, Arnab; Natarajan, Suriyaprakash] Intel Corp, Santa Clara, CA 95054 USA.
RP Kundu, S (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75080 USA.
EM shamik.kundu@utdallas.edu; suvadeep.banerjee@intel.com;
   arnab.raha@intel.com; suriyaprakash.natarajan@intel.com;
   kanad.basu@utdallas.edu
CR ALIPPI C, 1995, IEEE T CIRCUITS-I, V42, P358, DOI 10.1109/81.390269
   Bernardi P, 2013, DES AUT TEST EUROPE, P1462
   Bettola S, 1998, IEEE T COMPUT, V47, P357, DOI 10.1109/12.660173
   Chen W, 2019, IEEE DES TEST, V36, P31, DOI 10.1109/MDAT.2019.2908643
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   De Carvalho M, 2013, IEEE INT ON LINE, P43, DOI 10.1109/IOLTS.2013.6604049
   Gebregiorgis A., 2019, PROC INT TEST C ITC, P1
   Jha S, 2019, I C DEPEND SYS NETWO, P112, DOI 10.1109/DSN.2019.00025
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   KERLIRZIN P, 1993, NEURAL COMPUT, V5, P473, DOI 10.1162/neco.1993.5.3.473
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lam M. S., 1983, CMUCS83166
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Park SK, 2015, IEEE INT MEM WORKSH, P1
   Piuri V, 2001, J PARALLEL DISTR COM, V61, P18, DOI 10.1006/jpdc.2000.1663
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Schorn C, 2019, DES AUT TEST EUROPE, P1507, DOI [10.23919/date.2019.8714885, 10.23919/DATE.2019.8714885]
   Xu XW, 2020, BMJ-BRIT MED J, V368, DOI [10.1136/bmj.m606, 10.1136/bmj.m792]
   Zhang J, 2018, IEEE VLSI TEST SYMP
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
NR 23
TC 26
Z9 26
U1 0
U2 9
PD MAR
PY 2021
VL 29
IS 3
BP 485
EP 498
DI 10.1109/TVLSI.2020.3048829
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ma, LX
   Shao, E
   Zhou, YY
   Tan, GM
AF Ma, Lixian
   Shao, En
   Zhou, Yueyuan
   Tan, Guangming
GP IEEE COMP SOC
TI WidePipe: High-Throughput Deep Learning Inference System on a Cluster of
   Neural Processing Units
SO 2021 IEEE 39TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2021)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 39th IEEE International Conference on Computer Design ICCD)
CY OCT 24-27, 2021
CL ELECTR NETWORK
DE deep neural network; high-performance computing; cloud intelligent
   services; cloud computing
AB The wide application of machine learning technology promotes the generation of ML-as-a-Service(MLaaS), which is a serverless computing paradigm for rapidly deploying a trained model as a serving. However, it is a challenge to design an inference system that is capable of coping with large traffic for low latency and heterogeneous neural networks. It is difficult to adaptively configure multilevel parallelism in existing cloud inference systems for machine learning servings, particularly if the cluster has accelerators, such as GPUs, NPUs, FPGAs, etc. These issues lead to poor resource utilization and limit the system throughput. In this paper, we propose and implement a high-throughput inference system called WidePipe, which WidePipe leverages reinforcement learning to co-adapt resource allocation and batch size of request according to device status. We evaluated the performance of WidePipe for a large cluster with 1000 neural processing units in 250 nodes. Our experimental results show that WidePipe has a 2.11 x higher throughput than current inference systems when deploying heterogeneous machine learning servings, meeting the service-level objectives for the response time.
C1 [Ma, Lixian; Shao, En; Zhou, Yueyuan; Tan, Guangming] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Shao, En; Tan, Guangming] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Shao, E (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.; Shao, E (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM shaoen@ict.ac.cn
CR Ali A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00073
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Olston C., 2017, ARXIV171206139
   Qin HY, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356164
NR 6
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 563
EP 566
DI 10.1109/ICCD53106.2021.00091
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Vukobratovic, BZ
   Struharik, RJR
AF Vukobratovic, Bogdan Z.
   Struharik, Rastislav J. R.
TI Co-Processor for evolutionary full decision tree induction
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Data mining; Machine learning; Hardware-software co-design; Decision
   trees; Evolutionary algorithms; Hardware acceleration; FPGA;
   Co-processor
ID SUPPORT VECTOR MACHINES; ARCHITECTURE; IMPLEMENTATION; ACCELERATOR
AB In this paper a co-processor for the hardware aided decision tree induction using evolutionary approach (EFTIP) is proposed. EFTIP is used for hardware acceleration of the fitness evaluation task since this task is proven in the paper to be the execution time bottleneck. The EFTIP co-processor can significantly improve the execution time of a novel algorithm for the full decision tree induction using evolutionary approach (EFTI) when used to accelerate the fitness evaluation task. The comparison of the HW/SW EFTI implementation with the pure software implementation suggests that the proposed HW/SW architecture offers substantial DT induction time speedups for the selected benchmark datasets from the standard UCI machine learning repository database. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Vukobratovic, Bogdan Z.; Struharik, Rastislav J. R.] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradov 6, Novi Sad 21000, Serbia.
RP Vukobratovic, BZ (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradov 6, Novi Sad 21000, Serbia.
EM bogdan.vukobratovic@gmail.com; rasti@uns.ac.rs
CR Abe S., 2005, SUPPORT VECTOR MACHI, V53
   Aggarwal C. C., 2012, MINING TEXT DATA, P163, DOI 10.1007/978-1-4614-3223-4
   Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   Anguita D, 2011, J CIRCUIT SYST COMP, V20, P263, DOI 10.1142/S0218126611007244
   Angulta D, 2008, NEUROCOMPUTING, V72, P480, DOI 10.1016/j.neucom.2007.12.006
   [Anonymous], 2013, INTRO BIOINFORMATICS
   [Anonymous], 2006, FPGA IMPLEMENTATIONS
   [Anonymous], 2011, J SOFTWARE ENG APPL, DOI DOI 10.4236/JSEA.2011.45036
   [Anonymous], 2006, DATA MINING COMPUTAT
   BALDI P, 2001, BIOINFORMATICS MACHI
   Barros RC, 2012, IEEE T SYST MAN CY C, V42, P291, DOI 10.1109/TSMCC.2011.2157494
   Bekkerman R., 2011, SCALING MACHINE LEAR
   Blake CL, 1998, UCI REPOSITORY MACHI
   Bot MCJ, 2000, LECT NOTES COMPUT SC, V1802, P247
   Challa S., 2011, FUNDAMENTALS OBJECT
   Choudhary AN, 2011, WIRES DATA MIN KNOWL, V1, P41, DOI 10.1002/widm.9
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   Echanobe J, 2014, MICROPROCESS MICROSY, V38, P730, DOI 10.1016/j.micpro.2014.07.005
   Flach P., 2012, MACHINE LEARNING ART
   Haykin S, 2009, NEURAL NETWORKS LEAR
   HEATH D, 1993, IJCAI-93, VOLS 1 AND 2, P1002
   Kretowski M, 2005, ADV SOFT COMP, P309, DOI 10.1007/3-540-32392-9_32
   Liu Bing, 2007, WEB DATA MINING EXPL
   Llorà X, 2004, LECT NOTES COMPUT SC, V3103, P797
   Madokoro H, 2013, J COMPUT, V8, P559, DOI 10.4304/jcp.8.3.559-566
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Papagelis A., 2012, 2012 IEEE 24 INT C T
   Prince S. J., 2012, COMPUTER VISION MODE
   Qingzheng Li, 2011, Journal of Low Power Electronics and Applications, V1, P45, DOI 10.3390/jlpea1010045
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Rokach L., 2007, DATA MINING DECISION
   Russell MA., 2013, MINING SOCIAL WEB DA
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Savich A, 2012, MICROPROCESS MICROSY, V36, P138, DOI 10.1016/j.micpro.2010.12.001
   Struharik R, 2014, I S INTELL SYST INFO, P257, DOI 10.1109/SISY.2014.6923596
   Struharik RJR, 2009, IET COMPUT DIGIT TEC, V3, P259, DOI 10.1049/iet-cdt.2008.0055
   Struharik RJR, 2009, J CIRCUIT SYST COMP, V18, P1033, DOI 10.1142/S0218126609005526
   Vainbrand D, 2011, MICROPROCESS MICROSY, V35, P152, DOI 10.1016/j.micpro.2010.08.005
   Vranjkovic V., 2011, 2011 19th Telecommunications Forum Telfor (TELFOR), P1543, DOI 10.1109/TELFOR.2011.6143852
   Vranjkovic VS, 2015, J CIRCUIT SYST COMP, V24, DOI 10.1142/S0218126615500644
   Vukobratovic B, 2015, INT SYMP COMP INTELL, P95, DOI 10.1109/CINTI.2015.7382901
   Weiss SM, 2010, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84996-226-1
   Witten Ian., 2005, DATA MINING PRACTICA
   Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653
NR 46
TC 2
Z9 2
U1 0
U2 7
PD SEP
PY 2016
VL 45
BP 253
EP 269
DI 10.1016/j.micpro.2016.05.013
PN B
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Geng, T
   Li, A
   Shi, RB
   Wu, CS
   Wang, TQ
   Li, YF
   Haghi, P
   Tumeo, A
   Che, S
   Reinhardt, S
   Herbordt, MC
AF Geng, Tong
   Li, Ang
   Shi, Runbin
   Wu, Chunshu
   Wang, Tianqi
   Li, Yanfei
   Haghi, Pouya
   Tumeo, Antonino
   Che, Shuai
   Reinhardt, Steve
   Herbordt, Martin C.
GP IEEE COMP SOC
TI AWB-GCN: A Graph Convolutional Network Accelerator with Runtime Workload
   Rebalancing
SO 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO 2020)
DT Proceedings Paper
CT 53rd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 17-21, 2020
CL ELECTR NETWORK
DE Graph Neural Network; Graph Convolutional Network; Sparse Matrix
   Multiplication; Computer Architecture; Machine Learning Accelerator;
   Dynamic Scheduling
ID NEURAL-NETWORK; SPARSE; PERFORMANCE; MODEL
AB Deep learning systems have been successfully applied to Euclidean data such as images, video, and audio. In many applications, however, information and their relationships are better expressed with graphs. Graph Convolutional Networks (GCNs) appear to be a promising approach to efficiently learn from graph data structures, having shown advantages in many critical applications. As with other deep learning modalities, hardware acceleration is critical. The challenge is that real-world graphs are often extremely large and unbalanced; this poses significant performance demands and design challenges.
   In this paper, we propose Autotuning-Workload-Balancing GCN (AWB-GCN) to accelerate GCN inference. To address the issue of workload imbalance in processing real-world graphs, three hardware-based autotuning techniques are proposed: dynamic distribution smoothing, remote switching, and row remapping. In particular, AWB-GCN continuously monitors the sparse graph pattern, dynamically adjusts the workload distribution among a large number of processing elements (up to 4K PEs), and, after converging, reuses the ideal configuration. Evaluation is performed using an Intel D5005 FPGA with five commonly-used datasets. Results show that 4K-PE AWB-GCN can significantly elevate PE utilization by 7.7x on average and demonstrate considerable performance speedups over CPUs (3255x), GPUs (80.3x), and a prior GCN accelerator (5.1x).
C1 [Geng, Tong; Wu, Chunshu; Wang, Tianqi; Haghi, Pouya; Herbordt, Martin C.] Boston Univ, Boston, MA 02215 USA.
   [Geng, Tong; Li, Ang; Tumeo, Antonino] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
   [Che, Shuai; Reinhardt, Steve] Microsoft, Redmond, WA USA.
   [Shi, Runbin] Univ Hong Kong, Hong Kong, Peoples R China.
   [Li, Yanfei] Zhejiang Univ, Hangzhou, Peoples R China.
RP Geng, T (corresponding author), Boston Univ, Boston, MA 02215 USA.; Geng, T (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99352 USA.
CR Abou-Rjeili A., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Abu-El-Haija S., 2018, ADV NEURAL INFORM PR, P9197
   Adamic LA, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.046135
   Aiello W, 2001, EXP MATH, V10, P53, DOI 10.1080/10586458.2001.10504428
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2008, NVR2008004
   Asgari B, 2020, INT S HIGH PERF COMP, P249, DOI 10.1109/HPCA47549.2020.00029
   Ashari A, 2014, INT CONF HIGH PERFOR, P781, DOI 10.1109/SC.2014.69
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Bruna J., 2014, INT C LEARN REPR ICL
   Chen Jianfei, 2017, ARXIV171010568
   Chen Y.-H., 2016, IEEE Journal of Solid-State Circuits, V52, P127
   Chen YD, 2019, IEEE T PARALL DISTR, V30, P923, DOI 10.1109/TPDS.2018.2871189
   Chung F., 2004, INTERNET MATH, V1, P257, DOI DOI 10.1080/15427951.2004.10129089
   Coley CW, 2019, CHEM SCI, V10, P370, DOI 10.1039/c8sc04228d
   Dai HJ, 2018, PR MACH LEARN RES, V80
   Defferrard M., 2016, P3844
   Deveci M, 2017, IEEE SYM PARA DISTR, P693, DOI 10.1109/IPDPSW.2017.8
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Fey M., ARXIV190302428, V2019
   Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947
   Gao J., 2020, ARXIV200211273
   Geng T., P81
   Geng T, 2021, IEEE T PARALL DISTR, V32, P199, DOI 10.1109/TPDS.2020.3013637
   Geng T, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P461, DOI 10.1145/3330345.3330386
   Gonzalez Joseph E, 2012, 10 USENIX S OP SYST, P17, DOI DOI 10.1145/74850.74870
   Gori M., 2005, V2, P729
   Greathouse JL, 2014, INT CONF HIGH PERFOR, P769, DOI 10.1109/SC.2014.68
   Ham TJ, 2016, INT SYMP MICROARCH
   Hamilton W., 2017, P1024
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Henaff M., 2015, ARXIV150605163
   Huy-Trung Nguyen, 2018, 2018 IEEE International Conference on Information Communication and Signal Processing (ICICSP). Proceedings, P118, DOI 10.1109/ICICSP.2018.8549713
   Kim D, 2017, DES AUT TEST EUROPE, P1462, DOI 10.23919/DATE.2017.7927222
   Kipf T.N., 2016, ARXIV
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Kwon H., P754
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Latapy M, 2008, THEOR COMPUT SCI, V407, P458, DOI 10.1016/j.tcs.2008.07.017
   Li A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356169
   Li Y., 2015, P 4 INT C LEARNING R
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Liu Y, 2020, ARXIV200111553CSEESS
   Micheli A, 2009, IEEE T NEURAL NETWOR, V20, P498, DOI 10.1109/TNN.2008.2010350
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Ozdal MM, 2016, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2016.24
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Song L., P531
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie C, 2014, ADV NEUR IN, V27
   Xie T, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.145301
   Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yang HX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3165, DOI 10.1145/3292500.3340404
   You JX, 2018, PR MACH LEARN RES, V80
   Yun S, 2019, ADV NEUR IN, V32
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhuang CY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P499, DOI 10.1145/3178876.3186116
   Zhuo Ling, 2005, P 2005 ACMSIGDA 13 I, P63
   Zitnik M, 2018, BIOINFORMATICS, V34, P457, DOI 10.1093/bioinformatics/bty294
NR 67
TC 82
Z9 84
U1 1
U2 4
PY 2020
BP 922
EP 936
DI 10.1109/MICRO50266.2020.00079
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Chang, IF
   Chen, HR
   Chao, PCP
AF Chang, I. -Feng
   Chen, Hao-Ren
   Chao, Paul C. -P.
TI Design and implementation for a high-efficiency hardware accelerator to
   realize the learning machine for predicting OLED degradation
SO MICROSYSTEM TECHNOLOGIES-MICRO-AND NANOSYSTEMS-INFORMATION STORAGE AND
   PROCESSING SYSTEMS
DT Article
ID NEURAL-NETWORK
AB A new learning machine based on neural network (NN) and its hardware accelerator are successfully built in this study for predicting the luminance decay of Organic Light Emitting Diode (OLED) displays. It is known that although OLED displays has become the mainstream in the current high-end display market, OLEDs tend to degrade in emission as used extensively for a long time. The operable voltage also rises with the usage time increasing, which causes the operating point to drift. To compensate the OLED degradation, a NN model is successfully built with favorable accuracy. Furthermore, the built NN model is implemented in FPGA hardware platform with a high-performance computing architecture, which uses registers to access inputs, integrates the multiplication, addition operations for weights and activation function into the same combinational logic circuit, and a pipeline architecture to improve maximum operation per unit time. The hardware architecture is designed via Verilog, and further verified by Xilinx Artix-7. Its operating frequency can be as high as 55.6 MHz, while resource consumption is only 1.0k LUTs, favorable as opposed to all the other past, related studies. Experiment shows that the computation of the built NN by the proposed accelerator can be completed 55.6 million times per second. In addition, the degradation prediction errors by the accelerator are as small as 2.08%, 5.51% and 4.36% for red, green and blue OLEDs, respectively, while the figure of merit, the product of computation time and area is as low as 109.86 (Time*Area), the lowest compared to all the past reported works.
C1 [Chang, I. -Feng; Chen, Hao-Ren; Chao, Paul C. -P.] Natl Yang Ming Chiao Tung Univ, Dept Elect & Elect Engn, Hsinchu 300, Taiwan.
RP Chao, PCP (corresponding author), Natl Yang Ming Chiao Tung Univ, Dept Elect & Elect Engn, Hsinchu 300, Taiwan.
EM pchao@nycu.edu.tw
CR Aoyama T, 2002, IEEE IJCNN, P1007, DOI 10.1109/IJCNN.2002.1005613
   Hao, 2017, ARXIV
   Liu HW, 2019, RESULTS PHYS, V12, P361, DOI 10.1016/j.rinp.2018.11.001
   Liu HW, 2017, IEEE T ELECTRON DEV, V64, P2867, DOI 10.1109/TED.2017.2701346
   Lu KY, 2017, IEEE ACCESS, V5, P21660, DOI 10.1109/ACCESS.2017.2761802
   Medus LD, 2019, IEEE ACCESS, V7, P76084, DOI 10.1109/ACCESS.2019.2920885
   Nedjah N, 2012, EXPERT SYST APPL, V39, P9191, DOI 10.1016/j.eswa.2012.02.085
   Oliveira JGM, 2017, INT CARIBB CONF DEVI, P41, DOI 10.1109/ICCDCS.2017.7959699
   Pearson MJ, 2007, IEEE T NEURAL NETWOR, V18, P1472, DOI 10.1109/TNN.2007.891203
   Zhai XJ, 2016, IEEE ACCESS, V4, P8138, DOI 10.1109/ACCESS.2016.2619181
NR 10
TC 0
Z9 0
U1 3
U2 4
PD AUG
PY 2023
VL 29
IS 8
SI SI
BP 1069
EP 1081
DI 10.1007/s00542-023-05442-9
EA APR 2023
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Materials Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT J
AU Armeniakos, G
   Zervakis, G
   Soudris, D
   Henkel, J
AF Armeniakos, Giorgos
   Zervakis, Georgios
   Soudris, Dimitrios
   Henkel, Joerg
TI Hardware Approximate Techniques for Deep Neural Network Accelerators: A
   Survey
SO ACM COMPUTING SURVEYS
DT Article
DE Approximate computing; arithmetic circuits; deep neural networks; error
   metrics; hardware approximation
ID DESIGN; CIRCUITS; MULTIPLIERS; CHALLENGES; FRAMEWORK; TRENDS; NOISE
AB Deep Neural Networks (DNNs) are very popular because of their high performance in various cognitive tasks in Machine Learning (ML). Recent advancements in DNNs have brought levels beyond human accuracy in many tasks, but at the cost of high computational complexity. To enable efficient execution of DNN inference, more and more research works, therefore, are exploiting the inherent error resilience of DNNs and employing Approximate Computing (AC) principles to address the elevated energy demands of DNN accelerators. This article provides a comprehensive survey and analysis of hardware approximation techniques for DNN accelerators. First, we analyze the state of the art, and by identifying approximation families, we cluster the respective works with respect to the approximation type. Next, we analyze the complexity of the performed evaluations (with respect to the dataset and DNN size) to assess the efficiency, potential, and limitations of approximate DNN accelerators. Moreover, a broad discussion is provided regarding error metrics that are more suitable for designing approximate units for DNN accelerators as well as accuracy recovery approaches that are tailored to DNN inference. Finally, we present how Approximate Computing for DNN accelerators can go beyond energy efficiency and address reliability and security issues as well.
C1 [Armeniakos, Giorgos; Soudris, Dimitrios] Natl Tech Univ Athens, Athens, Greece.
   [Zervakis, Georgios; Henkel, Joerg] Karlsruhe Inst Technol, Karlsruhe, Germany.
RP Armeniakos, G (corresponding author), Natl Tech Univ Athens, Athens, Greece.
EM armeniakos@microlab.ntua.gr; georgios.zervakis@kit.edu;
   dsoudris@microlab.ntua.gr; henkel@kit.edu
CR Agrawal A, 2021, ISSCC DIG TECH PAP I, V64, P144, DOI 10.1109/ISSCC42613.2021.9365791
   Agrawal A, 2019, P S COMP ARITHM, P92, DOI 10.1109/ARITH.2019.00023
   Al Bahou A, 2018, PROC IEEE COOL CHIPS
   Amrouch H, 2020, IEEE T COMPUT AID D, V39, P3842, DOI 10.1109/TCAD.2020.3012753
   Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2012, PREDICTION CANDIDATE
   Ansari MS, 2020, IEEE T VLSI SYST, V28, P317, DOI 10.1109/TVLSI.2019.2940943
   Arm, 2020, ARM ETH N PROC
   Banner R, 2019, ADV NEUR IN, V32
   Barata C, 2019, I S BIOMED IMAGING, P841, DOI [10.1109/isbi.2019.8759561, 10.1109/ISBI.2019.8759561]
   Bhardwaj K, 2015, INT SYM QUAL ELECT, P263
   BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108
   Capra M, 2020, IEEE ACCESS, V8, P225134, DOI 10.1109/ACCESS.2020.3039858
   Cerebras, 2021, CER WAF SCAL ENG
   Chen CY, 2018, DES AUT TEST EUROPE, P821, DOI 10.23919/DATE.2018.8342119
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi J., 2018, ARXIV
   Choi J., 2019, P MACHINE LEARNING S, V1, P348
   Chuliang Guo, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P235, DOI 10.1109/ASP-DAC47756.2020.9045176
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Courbariaux M, 2015, ADV NEUR IN, V28
   De la Parra C, 2021, ASIA S PACIF DES AUT, P365, DOI 10.1145/3394885.3431533
   De la Parra C, 2020, DES AUT TEST EUROPE, P1193, DOI 10.23919/DATE48585.2020.9116476
   De la Parra Cecilia, 2020, KNOWLEDGE DISTILLATI
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Deng Zhaoxia, 2015, ARXIV
   Faraone J, 2020, IEEE T VLSI SYST, V28, P115, DOI 10.1109/TVLSI.2019.2939429
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Galloway A., 2018, P INT C LEARN REPR
   Gholami A., 2021, ARXIV
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goyal P., 2018, ARXIV
   Graphcore, 2020, INT PROC UN
   Groq, 2021, TENS STREAM PROC
   Guesmi Amira, 2020, ARXIV
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   Hammad I, 2021, IEEE ACCESS, V9, P7220, DOI 10.1109/ACCESS.2021.3049299
   Han J, 2013, PROC EUR TEST SYMP
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hanif MA, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317787
   Hao C, 2021, IEEE DES TEST, V38, P7, DOI 10.1109/MDAT.2021.3069952
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2018, I SYMPOS LOW POWER E, P110, DOI 10.1145/3218603.3218643
   Hemmat M, 2021, IEEE T COMPUT AID D, V40, P2090, DOI 10.1109/TCAD.2020.3033750
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hochreiter S., 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/NECO.1997.9.8.1735
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Huan YX, 2016, 2016 29TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P102, DOI 10.1109/SOCC.2016.7905445
   Hubara I, 2016, ADV NEUR IN, V29
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jiang HL, 2020, P IEEE, V108, P2108, DOI 10.1109/JPROC.2020.3006451
   Jiao X, 2018, DES AUT TEST EUROPE, P1223, DOI 10.23919/DATE.2018.8342202
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Khalid F, 2019, IEEE INT ON LINE, P182, DOI [10.1109/iolts.2019.8854377, 10.1109/IOLTS.2019.8854377]
   Kim MS, 2019, IEEE T COMPUT, V68, P660, DOI 10.1109/TC.2018.2880742
   Kim M, 2021, IEEE J SOLID-ST CIRC, V56, P803, DOI 10.1109/JSSC.2020.3029235
   Koppula S, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P166, DOI 10.1145/3352460.3358280
   Krishnamoorthi R., 2018, ARXIV
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leung CS, 2010, IEEE T NEURAL NETWOR, V21, P1232, DOI 10.1109/TNN.2010.2049580
   Liang Tailin, 2021, ARXIV
   Liao H., 2019, 2019 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875654
   Ma Y, 2013, AUGMENTED LAGRANGE M
   MATUS A, 1981, P NATL ACAD SCI-BIOL, V78, P3010, DOI 10.1073/pnas.78.5.3010
   Mitchell J. N., 1962, IRE T ELECT COMPUT, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Mocerino L, 2019, DES AUT TEST EUROPE, P848, DOI [10.23919/DATE.2019.8714880, 10.23919/date.2019.8714880]
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2020, IEEE J EM SEL TOP C, V10, P406, DOI 10.1109/JETCAS.2020.3032495
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Muñoz-González L, 2019, INTEL SYST REF LIBR, V151, P47, DOI 10.1007/978-3-319-98842-9_3
   Nagabushan N, 2016, IEEE I C COMP INT CO, P134
   Narodytska N, 2017, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW.2017.172
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, DOI DOI 10.2118/18761-MS
   NVIDIA, 2020, A100 TENS COR GPU AR
   Pagani S, 2020, IEEE T COMPUT AID D, V39, P101, DOI 10.1109/TCAD.2018.2878168
   Panda P, 2019, IEEE ACCESS, V7, P70157, DOI 10.1109/ACCESS.2019.2919463
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Park JS, 2021, ISSCC DIG TECH PAP I, V64, P152, DOI 10.1109/ISSCC42613.2021.9365928
   Parmar Y, 2020, IEEE T CIRCUITS-II, V67, P370, DOI 10.1109/TCSII.2019.2907974
   Pilipovic R, 2021, IEEE T CIRCUITS-I, V68, P2535, DOI 10.1109/TCSI.2021.3069168
   Piyasena D, 2019, I C FIELD PROG LOGIC, P354, DOI 10.1109/FPL.2019.00063
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rapp M, 2022, IEEE T COMPUT AID D, V41, P3162, DOI 10.1109/TCAD.2021.3124762
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reda Sherief, 2018, APPROXIMATE CIRCUITS
   Ren Pengzhen, 2021, ARXIV
   Riaz M, 2020, IEEE ACCESS, V8, P127014, DOI 10.1109/ACCESS.2020.3008256
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Ryu S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317784
   Saadat H, 2018, IEEE T COMPUT AID D, V37, P2623, DOI 10.1109/TCAD.2018.2857262
   Salamin Sami, 2021, DESIGN AUTOMATION TE
   Sarwar SS, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3097264
   Semery Oleg, 2021, PYTORCHCV PYPI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shafique M, 2020, IEEE DES TEST, V37, P30, DOI 10.1109/MDAT.2020.2971217
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Shao Y, 2011, IEEE GEOSCI REMOTE S, V8, P113, DOI 10.1109/LGRS.2010.2052782
   Sharify S, 2018, DES AUT CON, DOI 10.1145/3195970.3196072
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   So DR, 2019, PR MACH LEARN RES, V97
   Soliman Taha, 2021, PROC IEEE INT C ARTI, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tambon Florian, 2021, ARXIV
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Ujiie T, 2016, IEEE COMPUT SOC CONF, P870, DOI 10.1109/CVPRW.2016.113
   Umuroglu Y, 2018, I C FIELD PROG LOGIC, P307, DOI 10.1109/FPL.2018.00059
   Vasicek Z, 2019, DES AUT TEST EUROPE, P96, DOI [10.23919/date.2019.8714977, 10.23919/DATE.2019.8714977]
   Vasicek Z, 2015, IEEE T EVOLUT COMPUT, V19, P432, DOI 10.1109/TEVC.2014.2336175
   Vaverka F, 2020, DES AUT TEST EUROPE, P294, DOI 10.23919/DATE48585.2020.9116299
   Venkataramani S, 2020, P IEEE, V108, P2232, DOI 10.1109/JPROC.2020.3029453
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Vogel S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240803
   Vogel S, 2019, DES AUT TEST EUROPE, P1094, DOI [10.23919/date.2019.8714901, 10.23919/DATE.2019.8714901]
   Wang N., 2018, TRAINING DEEP NEURAL
   Wechsler Ofri, 2019, 2019 IEEE Hot Chips 31 Symposium (HCS), DOI 10.1109/HOTCHIPS.2019.8875671
   Yang TJ, 2017, CONF REC ASILOMAR C, P1916, DOI 10.1109/ACSSC.2017.8335698
   Zervakis Georgios, 2021, 2021 58th ACM/IEEE Design Automation Conference (DAC), P481, DOI 10.1109/DAC18074.2021.9586092
   Zervakis G, 2021, ASIA S PACIF DES AUT, P189, DOI 10.1145/3394885.3431632
   Zervakis G, 2020, IEEE ACCESS, V8, P53522, DOI 10.1109/ACCESS.2020.2981395
   Zervakis G, 2016, IEEE T VLSI SYST, V24, P3105, DOI 10.1109/TVLSI.2016.2535398
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
   Zhou A, 2017, ARXIV
   Zhou SY, 2018, LECT NOTES COMPUT SC, V11305, P210, DOI 10.1007/978-3-030-04221-9_19
   Zhu C., 2017, P INT C LEARN REPR I
NR 137
TC 10
Z9 10
U1 5
U2 14
PD MAY
PY 2023
VL 55
IS 4
AR 83
DI 10.1145/3527156
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Peserico, N
   Shastri, BJ
   Sorger, VJ
AF Peserico, Nicola
   Shastri, Bhavin J.
   Sorger, Volker J.
TI Integrated Photonic Tensor Processing Unit for a Matrix Multiply: A
   Review
SO JOURNAL OF LIGHTWAVE TECHNOLOGY
DT Review
DE Matrix-vector multiplication; photonics; PICs; silicon photonics; tensor
   core
ID CONVOLUTIONAL NEURAL-NETWORKS; SILICON; COMPRESSION; MODULATOR;
   CIRCUITS; DESIGN; OPTICS
AB The explosion of artificial intelligence and machine-learning algorithms, connected to the exponential growth of the exchanged data, is driving a search for novel application-specific hardware accelerators. Among the many, the photonics field appears to be in the perfect spotlight for this global data explosion, thanks to its almost infinite bandwidth capacity associated with limited energy consumption. In this review, we will overview the major advantages that photonics has over electronics for hardware accelerators, followed by a comparison between the major architectures implemented on Photonics Integrated Circuits (PIC) for both the linear and nonlinear parts of Neural Networks. By the end, we will highlight the main driving forces for the next generation of photonic accelerators, as well as the main limits that must be overcome.
C1 [Peserico, Nicola] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [Shastri, Bhavin J.] Queens Univ, Dept Phys Engn Phys & Astron, Kingston, ON K7L 3N6, Canada.
   [Sorger, Volker J.] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [Sorger, Volker J.] Optelligence LLC, Wilmington, DE 19801 USA.
RP Sorger, VJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
EM npeserico@gwu.edu; bhavin.shastri@queensu.ca; sorger@gwu.edu
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   Al-Qadasi MA, 2022, APL PHOTONICS, V7, DOI 10.1063/5.0070992
   Alexoudi T, 2020, LIGHT-SCI APPL, V9, DOI 10.1038/s41377-020-0325-9
   Amin R, 2019, APL MATER, V7, DOI 10.1063/1.5109039
   Amin R, 2021, APL PHOTONICS, V6, DOI 10.1063/5.0062830
   Amin R, 2020, OPTICA, V7, P333, DOI 10.1364/OPTICA.389437
   Amin R, 2018, OPT EXPRESS, V26, P15445, DOI 10.1364/OE.26.015445
   Annoni A, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2017.110
   Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Astrid M, 2018, ETRI J, V40, P421, DOI 10.4218/etrij.2018-0065
   Baghdadi R, 2021, OPT EXPRESS, V29, P19113, DOI 10.1364/OE.423949
   Bai YP, 2023, NANOPHOTONICS-BERLIN, V12, P795, DOI 10.1515/nanoph-2022-0485
   Bandyopadhyay S, 2022, Arxiv, DOI arXiv:2208.01623
   Bannon Pete, 2019, 2019 IEEE HOT CHIPS, P1, DOI [10.1109/HOTCHIPS.2019.8875645, DOI 10.1109/HOTCHIPS.2019.8875645]
   Billah MR, 2018, OPTICA, V5, P876, DOI 10.1364/OPTICA.5.000876
   Blalock D, 2020, ARXIV200303033, DOI DOI 10.1109/CVPR.2019.01152
   Bogaerts W, 2018, LASER PHOTONICS REV, V12, DOI 10.1002/lpor.201700237
   Brückerhoff-Plückelmann F, 2022, NANOPHOTONICS-BERLIN, V11, P4063, DOI 10.1515/nanoph-2021-0752
   Burgues J., 2019, 2019 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875651
   Carolan J, 2015, SCIENCE, V349, P711, DOI 10.1126/science.aab3642
   Cem A, 2023, J LIGHTWAVE TECHNOL, V41, P5425, DOI 10.1109/JLT.2023.3263235
   Chan WTJ, 2016, PR IEEE COMP DESIGN, P41, DOI 10.1109/ICCD.2016.7753259
   Chang L, 2022, NAT PHOTONICS, V16, P95, DOI 10.1038/s41566-021-00945-1
   Cheng QX, 2020, P IEEE, V108, P1261, DOI 10.1109/JPROC.2020.2968184
   Cheng Y, 2020, Arxiv, DOI arXiv:1710.09282
   Cheng ZG, 2018, ADV MATER, V30, DOI 10.1002/adma.201802435
   Chrostowski L, 2015, SILICON PHOTONICS DESIGN, P1
   Chrostowski L, 2019, IEEE J SEL TOP QUANT, V25, DOI 10.1109/JSTQE.2019.2917501
   Clements WR, 2016, OPTICA, V3, P1460, DOI 10.1364/OPTICA.3.001460
   Costanzo R, 2020, IEEE MICROW WIREL CO, V30, P673, DOI 10.1109/LMWC.2020.2993726
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Demirkiran C, 2022, Arxiv, DOI arXiv:2109.01126
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Drenski T., 2019, 2019 24 OPT COMM C, P1, DOI DOI 10.23919/ps.2019.8818001
   Erickson BJ, 2017, J DIGIT IMAGING, V30, P400, DOI 10.1007/s10278-017-9965-6
   Etiemble D., 2018, 45 YEAR CPU EVOLUTIO
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Feng CH, 2022, ACS PHOTONICS, V9, P3906, DOI 10.1021/acsphotonics.2c01188
   Frad MMP, 2020, OPT EXPRESS, V28, P12138, DOI 10.1364/OE.391473
   Fradkov AL, 2020, IFAC PAPERSONLINE, V53, P1385, DOI 10.1016/j.ifacol.2020.12.1888
   Fratalocchi A, 2015, NAT NANOTECHNOL, V10, P11, DOI 10.1038/nnano.2014.314
   Ganguly A, 2019, INT SYM QUAL ELECT, P335, DOI 10.1109/ISQED.2019.8697354
   Gui YL, 2022, NANOPHOTONICS-BERLIN, V11, P4001, DOI 10.1515/nanoph-2021-0796
   Gupta P., 2022, P SPIE, V12019, P77
   Haensch W, 2017, IEEE DEVICE RES CONF
   Hamerly R., 2021, P IEEE OPT FIB COMM, P1
   Han S., 2015, ARXIV151000149
   Hochberg M, 2010, NAT PHOTONICS, V4, P492, DOI 10.1038/nphoton.2010.172
   Huang CR, 2021, NAT ELECTRON, V4, P837, DOI 10.1038/s41928-021-00661-2
   Hwang T, 2018, Arxiv, DOI [arXiv:1803.08971, DOI 10.2139/SSRN.3147971, 10.48550/arXiv.1803.08971]
   Ibrahim TA, 2004, OPT LETT, V29, P2779, DOI 10.1364/OL.29.002779
   Jalali B, 2006, IEEE J SEL TOP QUANT, V12, P412, DOI 10.1109/JSTQE.2006.872708
   Kari SR, 2023, IEEE J SEL TOP QUANT, V29, DOI 10.1109/JSTQE.2023.3239918
   LEONARD J, 1990, COMPUT CHEM ENG, V14, P337, DOI 10.1016/0098-1354(90)87070-6
   Leuthold J, 2010, NAT PHOTONICS, V4, P535, DOI [10.1038/NPHOTON.2010.185, 10.1038/nphoton.2010.185]
   Lima T. F. d., 2020, IEEE J SEL TOPICS QU, V26
   Lischke S, 2021, NAT PHOTONICS, V15, P925, DOI 10.1038/s41566-021-00893-w
   Liu G., 2021, J PHYS PHOTON, V3, DOI [10.1088/2515-7647/abe3d9https://iopscience.iop.org/article/10.1088/2515-7647/abe3d9, DOI 10.1088/2515-7647/ABE3D9HTTPS://IOPSCIENCE.IOP.ORG/ARTICLE/10.1088/2515-7647/ABE3D9]
   Ma W, 2021, NAT PHOTONICS, V15, P77, DOI 10.1038/s41566-020-0685-y
   Ma X., 2022, HIGH DENSITY INTEGRA, DOI 10.21203/rs.3.rs-1833027/v1
   Machupalli R, 2022, MICROPROCESS MICROSY, V89, DOI 10.1016/j.micpro.2022.104441
   Mahesh B., 2020, MACHINE LEARNING ALG, V9, P381, DOI [10.21275/ART20203995, DOI 10.21275/ART20203995]
   Margalit N, 2021, APPL PHYS LETT, V118, DOI 10.1063/5.0050117
   Meng JW, 2022, Arxiv, DOI arXiv:2203.13337
   Meng JW, 2021, ADV PHOTON RES, V2, DOI 10.1002/adpr.202000033
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Miller DAB, 2015, OPTICA, V2, P747, DOI 10.1364/OPTICA.2.000747
   Miller DAB, 2013, PHOTONICS RES, V1, P1, DOI 10.1364/PRJ.1.000001
   Miscuglio M, 2020, OPTICA, V7, P1812, DOI 10.1364/OPTICA.408659
   Miscuglio M, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0001942
   Morichetti F, 2014, IEEE PHOTONICS J, V6, DOI 10.1109/JPHOT.2014.2310203
   Morichetti F, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1294
   Narayana VK, 2017, MICROPROCESS MICROSY, V50, P113, DOI 10.1016/j.micpro.2017.03.006
   Patil C, 2022, APPL PHYS REV, V9, DOI 10.1063/5.0071799
   Peserico N., 2022, P INT C IM SYST APPL
   Peserico N, 2022, OPT MATER EXPRESS, V12, P1347, DOI 10.1364/OME.451802
   Pethick M., 2003, P INT C PAR DISTR CO, V392, P165
   Petrenko S, 2018, BIG DATA TECHNOLOGIE, P115
   Pickus S. K., 2013, IEEE PHOTONIC SOC, V27
   Rahim A, 2021, ADV PHOTONICS, V3, DOI 10.1117/1.AP.3.2.024003
   Rakowski Michal, 2020, 2020 Optical Fiber Communications Conference and Exhibition (OFC). Proceedings
   Ramesh A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.06125
   Rani R, 2021, WIRELESS PERS COMMUN, V118, P679, DOI 10.1007/s11277-020-08039-x
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Redaelli A, 2022, MAT SCI SEMICON PROC, V137, DOI 10.1016/j.mssp.2021.106184
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Ribeiro A, 2016, OPTICA, V3, P1348, DOI 10.1364/OPTICA.3.001348
   Ríos C, 2015, NAT PHOTONICS, V9, P725, DOI [10.1038/NPHOTON.2015.182, 10.1038/nphoton.2015.182]
   Sahoo D, 2022, MATER RES BULL, V148, DOI 10.1016/j.materresbull.2021.111679
   Saiyeda A., 2017, INT J ADV RES COMPUT, V8, P68
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P160, DOI 10.1007/s42979-021-00592-x
   Sarwat SG, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn3243
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shastri B. J., 2022, P EUR C OPT COMM, V12019, P135
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shen C., 2022, ARXIV
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Shi Y, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33877-7
   Shokraneh F., 2020, P IEEE PHOT C, P1
   Siew SY, 2021, J LIGHTWAVE TECHNOL, V39, P4374, DOI 10.1109/JLT.2021.3066203
   SOREF RA, 1987, IEEE J QUANTUM ELECT, V23, P123, DOI 10.1109/JQE.1987.1073206
   Sorger VJ, 2020, OPT MATER EXPRESS, V10, P2192, DOI 10.1364/OME.400423
   Standaert T, 2016, IEEE INT INTERC TECH, P2, DOI 10.1109/IITC-AMC.2016.7507636
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sung WY, 2016, Arxiv, DOI arXiv:1511.06488
   Sunny FP, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3459009
   Tahersima MH, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/34/344005
   Tait AN, 2022, PHYS REV APPL, V17, DOI 10.1103/PhysRevApplied.17.054029
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Vega-Gonzalez V, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993538
   Wang H, 2022, NANOPHOTONICS-BERLIN, V11, P5113, DOI 10.1515/nanoph-2022-0413
   Wang H, 2022, PROC SPIE, V12200, DOI 10.1117/12.2639327
   Wang ZC, 2017, LASER PHOTONICS REV, V11, DOI 10.1002/lpor.201700063
   Xu QF, 2011, OPT EXPRESS, V19, P5244, DOI 10.1364/OE.19.005244
   Xu ZF, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00976-5
   Yadav N., 2015, INTRO NEURAL NETWORK, P13
   Yang AA, 2019, PER GLOB PAST, P1
   Yang L, 2012, OPT EXPRESS, V20, P13560, DOI 10.1364/OE.20.013560
   Yang TJ, 2017, CONF REC ASILOMAR C, P1916, DOI 10.1109/ACSSC.2017.8335698
   Zhang H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20719-7
   Zhang J, 2018, IEEE VLSI TEST SYMP
   Zhang WP, 2022, OPTICA, V9, P579, DOI 10.1364/OPTICA.446100
   Zhao C, 2022, J APPL SPECTROSC+, V88, P1247, DOI 10.1007/s10812-022-01306-8
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou JH, 2017, IEEE ACM INT SYMP, P731, DOI 10.1109/CCGRID.2017.114
   Zhuang BH, 2018, PROC CVPR IEEE, P7920, DOI 10.1109/CVPR.2018.00826
NR 133
TC 0
Z9 0
U1 10
U2 10
PD JUN 15
PY 2023
VL 41
IS 12
BP 3704
EP 3716
DI 10.1109/JLT.2023.3269957
WC Engineering, Electrical & Electronic; Optics; Telecommunications
DA 2023-11-11
ER

PT J
AU de Portugal, JC
   Snuverink, J
AF de Portugal, Jaime Coello
   Snuverink, Jochem
TI Experience with anomaly detection using ensemble models on streaming
   data at HIPA
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Particle accelerators; Machine learning; Anomaly detection
AB Anomaly detection techniques are applied in many industry settings with great success. This paper presents experimental evidence of usefulness of these techniques in the High Intensity Proton Accelerator at the Paul Scherrer Institute. We present an anomaly detection model built as a combination of the Numenta NuPIC model and an LSTM autoregressor that works on streaming data from several beam diagnostic devices, automatically learning complex patterns from these signals after a relatively small adaptation time and small number of false positives. We show how this system could have alerted human experts of the failure of critical beam instrumentation tens of minutes in advance by finding anomalies preceding it, which stood unnoticed for several hours. We also present a full framework to exploit these models, which allows to monitor live data from the diagnostic devices, model results and diagnostic data and show historical data for easier model tuning.
C1 [de Portugal, Jaime Coello; Snuverink, Jochem] Paul Scherrer Inst PSI, Forschungsstr 111, CH-5232 Villigen, Switzerland.
RP de Portugal, JC (corresponding author), Paul Scherrer Inst PSI, Forschungsstr 111, CH-5232 Villigen, Switzerland.
EM jaime.coello@psi.ch; jochem.snuverink@psi.ch
CR Ahmad S, 2017, NEUROCOMPUTING, V262, P134, DOI 10.1016/j.neucom.2017.04.070
   [Anonymous], 1997, NEURAL COMPUT
   Box GE., 2016, TIME SERIES ANAL FOR, V5
   Dalesio L. R., 1991, P ICALEPCS, P288
   Daum M., 2009, P 23 PARTICLE ACCELE, P1748
   DOttavio T., 2019, P 17 INT C ACC LARG, P1619
   Fol E, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.102805
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guha S, 2016, PR MACH LEARN RES, V48
   Hawkins J, 2016, FRONT NEURAL CIRCUIT, V10, DOI 10.3389/fncir.2016.00023
   Khalkhali I., 2011, INT J COMPUT SCI
   Piekarski M., 2019, PROC 17 INT C ACCELE, P1379, DOI [10.18429/JACoW-ICALEPCS2019-WEPHA121, DOI 10.18429/JACOW-ICALEPCS2019-WEPHA121]
   Reggiani D, 2020, J NEUTRON RES, V22, P325, DOI 10.3233/JNR-200162
   Rezapour M, 2019, INT J ADV COMPUT SC, V10, P1
   Said Elsayed Mahmoud, 2020, Q2SWinet '20: Proceedings of the 16th Symposium on QoS and Security for Wireless and Mobile Networks, P37, DOI 10.1145/3416013.3426457
   Sharmila VC, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741421
   Taylor M., 2018, ZENODO, DOI [10.5281/zenodo.1257382, DOI 10.5281/ZENODO.1257382]
   Wang K, 2004, LECT NOTES COMPUT SC, V3224, P203
   Wielgosz M, 2018, ENG APPL ARTIF INTEL, V74, P166, DOI 10.1016/j.engappai.2018.06.012
   Wu, 2016, ARXIV160908144
NR 20
TC 0
Z9 0
U1 3
U2 7
PD DEC 21
PY 2021
VL 1020
AR 165900
DI 10.1016/j.nima.2021.165900
EA OCT 2021
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Schmidt, C
   Amid, A
   Wright, J
   Keller, B
   Mao, H
   Settaluri, K
   Salomaa, J
   Zhao, J
   Ou, A
   Asanovic, K
   Nikolic, B
AF Schmidt, Colin
   Amid, Alon
   Wright, John
   Keller, Ben
   Mao, Howard
   Settaluri, Keertana
   Salomaa, Jarno
   Zhao, Jerry
   Ou, Albert
   Asanovic, Krste
   Nikolic, Borivoje
TI Programmable Fine-Grained Power Management and System Analysis of RISC-V
   Vector Processors in 28-nm FD-SOI
SO IEEE SOLID-STATE CIRCUITS LETTERS
DT Article
DE Dynamic voltage scaling; energy efficiency; microprocessors; system
   analysis and design; system-on-chip; vector processors
AB This letter presents a RISC-V System-on-Chip (SoC) with fully integrated switched-capacitor DC-DC converters, adaptive clock generators, mixed-precision floating-point vector accelerators, a 5-Gb/s serial memory interface, and an integrated power management unit (PMU) manufactured in 28-nm FD-SOI. The vector accelerator improves performance and energy per task on a matrix multiplication kernel by 15x and 13x, respectively, and end-to-end performance on machine learning and graph analytical workloads by 8x-12x. Inclusion of microarchitectural counters and fine spatial power-domain granularity facilitate the predictive power-management algorithms that reduce energy per task by 13%-22% compared to the baseline scalar processor. System-level simulations of a range of SoC architectural variations with multiple cores and vector accelerators complement the silicon measurements.
C1 [Schmidt, Colin; Amid, Alon; Wright, John; Mao, Howard; Settaluri, Keertana; Zhao, Jerry; Ou, Albert; Asanovic, Krste; Nikolic, Borivoje] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
   [Keller, Ben] NVIDIA Corp, NVIDIA Res Dept, Santa Clara, CA 95050 USA.
   [Salomaa, Jarno] Aalto Univ, Sch Elect Engn, Dept Micro & Nanosci, Aalto 00076, Finland.
RP Amid, A (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
CR Asanovic K., 2016, ROCKET CHIP GENERATO
   Biancolin D, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P330, DOI 10.1145/3289602.3293894
   Burton EA, 2014, APPL POWER ELECT CO, P432, DOI 10.1109/APEC.2014.6803344
   Gholami A, 2018, IEEE COMPUT SOC CONF, P1719, DOI 10.1109/CVPRW.2018.00215
   Karandikar S, 2018, CONF PROC INT SYMP C, P29, DOI 10.1109/ISCA.2018.00014
   Keller B, 2016, PROC EUR SOLID-STATE, P269, DOI 10.1109/ESSCIRC.2016.7598294
   Lee Y., 2020, 2020 IEEE S VLSI
   Lee Y., 2015, UCBEECS2015264
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Wright J., IEEE T VERY LARGE SC
   Zimmer B, 2015, SYMP VLSI CIRCUITS, DOI 10.1109/VLSIC.2015.7231305
NR 12
TC 0
Z9 0
U1 0
U2 1
PY 2020
VL 3
BP 210
EP 213
DI 10.1109/LSSC.2020.3010295
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Chaudhuri, A
   Talukdar, J
   Su, F
   Chakrabarty, K
AF Chaudhuri, Arjun
   Talukdar, Jonti
   Su, Fei
   Chakrabarty, Krishnendu
TI Functional Criticality Analysis of Structural Faults in AI Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Artificial intelligence (AI) accelerator; binary classification;
   catastrophic faults; deep learning; defect screening; functional
   criticality; generative adversarial network (GAN); greedy
   fault-dropping; stuck-at faults; systolic array; test escape; two-tier
   framework
ID NEURAL-NETWORKS
AB The ubiquitous application of deep neural networks (DNNs) has led to a rise in demand for artificial intelligence (AI) accelerators. For example, the tensor processing unit from Google-based on a systolic array-and its variants are of considerable interest for DNN inferencing using AI accelerators. This article studies the problem of classifying structural faults in such an accelerator based on their functional criticality. We first analyze pin-level faults in the processing elements (PEs) of a systolic array. Simulation results for the LeNet network with 8-bit fixed-point, 16-bit floating-point (FP), and 32-bit FP data paths applied to the MNIST dataset show that over 93% of the pin-level structural faults in a PE are functionally benign. We present a greedy iterative framework for determining the criticality of stuck-at faults in a PE netlist and analyze the limitations of criticality analysis methods based on repeated fault simulations. We next present a scalable two-tier machine-learning (ML)-based method to assess the functional criticality of stuck-at faults in a computationally efficient manner. We address the problem of minimizing misclassification by utilizing generative adversarial networks (GANs). Two-tier ML/GAN-based criticality assessment leads to less than 1% test escapes during functional criticality evaluation of structural faults.
C1 [Chaudhuri, Arjun; Talukdar, Jonti; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
   [Su, Fei] Intel Corp, Design Engn Grp, Folsom, CA 95630 USA.
RP Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
EM ac499@duke.edu
CR [Anonymous], 2020, SUPPLEMENTARY MAT FU
   [Anonymous], GOOGLE EDGE TPU CORA
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], SYSTEM ARCHITECTURE
   Belkina AC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13055-y
   Chaudhuri A, 2020, REP
   Chaudhuri A, 2022, IEEE T COMPUT AID D, V41, P2348, DOI 10.1109/TCAD.2021.3107401
   CHEN TP, 1995, IEEE T NEURAL NETWOR, V6, P911, DOI 10.1109/72.392253
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Day Oscar, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0089-0
   Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Ernst R, 2016, IEEE DES TEST, V33, P65, DOI 10.1109/MDAT.2016.2594790
   FREEDMAN LS, 1992, STATISTICIAN, V41, P405, DOI 10.2307/2349005
   Gebregiorgis A., 2019, PROC INT TEST C ITC, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo X, 2012, ISRN BIOINFORMAT
   Hopkins M, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0052
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Liu YD, 2020, IEEE T COMPUT AID D, V39, P1699, DOI 10.1109/TCAD.2019.2925353
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sadowski P.J., 2013, ADV NEURAL INFORM PR, P2814, DOI DOI 10.17744/MEHC.25.2.XHYREGGXDCD0Q4NY
   Samajdar Ananda, 2018, ARXIV
   Schutze H., 2006, P 15 ACM INT C INFOR, P662
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Xu Z, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000149
   Zaremba W, 2014, Arxiv, DOI arXiv:1307.1954
   Zhang J, 2018, IEEE VLSI TEST SYMP
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
NR 36
TC 1
Z9 1
U1 1
U2 2
PD DEC
PY 2022
VL 41
IS 12
BP 5657
EP 5670
DI 10.1109/TCAD.2022.3166108
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Mondal, S
   Ramprasath, S
   Zeng, ZQ
   Kunal, K
   Sapatnekar, SS
AF Mondal, Sudipta
   Ramprasath, S.
   Zeng, Ziqing
   Kunal, Kishor
   Sapatnekar, Sachin S.
GP IEEE
TI A Multicore GNN Training Accelerator
SO 2023 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN, ISLPED
DT Proceedings Paper
CT IEEE/ACM International Symposium on Low Power Electronics and Design
   (ISLPED)
CY AUG 07-08, 2023
CL Vienna, AUSTRIA
AB Graph neural networks (GNN) are vital for analytics on real-world problems with graph models. This work develops a multicore GNN training accelerator and develops multicore-specific optimizations for superior performance. It uses enhanced multicore-specific dynamic caching to circumvent the costs of irregular DRAM access patterns of graph-structured data. A novel feature vector segmentation approach is used to maximize on-chip data reuse with high on-chip computation per memory access, reducing data access latency, using a machine learning model for optimal performance. The work presents a major advance over prior FPGA/ASIC GNN accelerators by handling significantly larger datasets (with up to 8.6M vertices) on a variety of GNN models. On average, training speedup of 17x and energy efficiency improvement of 322x is achieved over DGL on a GPU; a speedup of 14x with 268x lower energy is shown over GPU-based GNNAdvisor; and 11x and 24x speedups are
C1 [Mondal, Sudipta; Ramprasath, S.; Zeng, Ziqing; Kunal, Kishor; Sapatnekar, Sachin S.] Univ Minnesota, Minneapolis, MN 55455 USA.
RP Mondal, S (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
CR Chen C., 2021, DAC
   Chen X., 2021, IEEE T COMPUT AID D
   Gandhi S, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P551
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   github, CACTI 6 5
   Hu Weihua, 2020, ADV NEURAL INFORM PR
   Jia Zhihao, 2020, P MACH LEARN SYST ML, V2, P187
   Jiang N., 2013, INT S PERFORMANCE AN, P86, DOI 10.1109/ISPASS.2013.6557149
   Kahng A. B., 2015, IEEE EMBEDDED SYS LE
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kim Y., 2015, IEEE COMP ARCH LETT, V15
   Ma L., 2019, USENIX ATC
   Mondal S., 2022, DAC
   Mondal S., 2022, IEEE T COMPUT AID D
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Stevens J., 2021, DAC
   Sun G., 2022, IEEE T COMPUT
   Tailor S., 2021, ICLR
   Wang MX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P803
   Wang Y., 2021, OSDI
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   You HR, 2022, INT S HIGH PERF COMP, P460, DOI 10.1109/HPCA53966.2022.00041
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhang BY, 2021, ANN IEEE SYM FIELD P, P29, DOI 10.1109/FCCM51124.2021.00012
   Zhiqi Lin, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P401, DOI 10.1145/3419111.3421281
   Zhou Z., 2021, PACT
   Zhou Z, 2021, DES AUT CON, P1009, DOI 10.1109/DAC18074.2021.9586181
NR 27
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/ISLPED58423.2023.10244283
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Mandal, SK
   Krishnan, G
   Goksoy, AA
   Nair, GR
   Cao, Y
   Ogras, UY
AF Mandal, Sumit K.
   Krishnan, Gokul
   Goksoy, A. Alper
   Nair, Gopikrishnan Ravindran
   Cao, Yu
   Ogras, Umit Y.
TI COIN: Communication-Aware In-Memory Acceleration for Graph Convolutional
   Networks
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Machine learning; resistive RAM; graph neural networks;
   processing-in-memory
ID PERFORMANCE; NM
AB Graph convolutional networks (GCNs) have shown remarkable learning capabilities when processing graph-structured data found inherently in many application areas. GCNs distribute the outputs of neural networks embedded in each vertex over multiple iterations to take advantage of the relations captured by the underlying graphs. Consequently, they incur a significant amount of computation and irregular communication overheads, which call for GCN-specific hardware accelerators. To this end, this paper presents a communication-aware in-memory computing architecture (COIN) for GCN hardware acceleration. Besides accelerating the computation using custom compute elements (CE) and in-memory computing, COIN aims at minimizing the intra- and inter-CE communication in GCN operations to optimize the performance and energy efficiency. Experimental evaluations with widely used datasets show up to 105x improvement in energy consumption compared to state-of-the-art GCN accelerator.
C1 [Mandal, Sumit K.; Goksoy, A. Alper; Ogras, Umit Y.] Univ Wisconsin, Dept Elect & Comp Engn, 1415 Johnson Dr, Madison, WI 53706 USA.
   [Krishnan, Gokul; Nair, Gopikrishnan Ravindran; Cao, Yu] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
RP Mandal, SK (corresponding author), Univ Wisconsin, Dept Elect & Comp Engn, 1415 Johnson Dr, Madison, WI 53706 USA.
EM skmandal@wisc.edu; gkrish19@asu.edu; agoksoy@wisc.edu; graveen1@asu.edu;
   yu.cao@asu.edu; uogras@wisc.edu
CR Abadal S., 2020, ARXIV PREPRINT ARXIV
   Angizi S, 2019, DES AUT TEST EUROPE, P378, DOI [10.23919/DATE.2019.8715270, 10.23919/date.2019.8715270]
   [Anonymous], NVIDIA QUADRO RTX 80
   [Anonymous], GRAPH NETS LIB
   Arka AI, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1667, DOI 10.23919/DATE51398.2021.9473949
   Arka AI, 2021, IEEE T VLSI SYST, V29, P1743, DOI 10.1109/TVLSI.2021.3110721
   Bojchevski Aleksandar, 2017, ARXIV170703815
   Boyd S., 2014, CONVEX OPTIMIZATION
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Challapalle Nagadastagiri, 2021, ICCAD, P1
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen X., 2020, ARXIV200912495
   Chung I.-H., 2012, PROC INT C HIGH PERF, P1
   Dai HJ, 2018, PR MACH LEARN RES, V80
   Duvenaud David K., 2015, P 28 INT C NEUR INF, P2224, DOI [DOI 10.48550/ARXIV.1509.09292, DOI 10.5555/2969442.2969488]
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Giles C. L., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P89, DOI 10.1145/276675.276685
   Hamilton WL., 2017, ADV NEURAL INFORM PR, V2017, P1025, DOI DOI 10.48550/ARXIV.1706.02216
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Joardar B. K., 2021, PROC IEEEACM INT C C, P1
   KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150
   Kiningham Kevin, 2022, IEEE T COMPUT
   Kipf T.N., 2016, ARXIV
   Krishnan Gakul, 2021, 2021 China Semiconductor Technology International Conference (CSTIC), DOI 10.1109/CSTIC52283.2021.9461480
   Krishnan G., ACM J EMERG TECH COM, V18, P2021
   Krishnan G, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3476999
   Krishnan G, 2020, IEEE DES TEST, V37, P79, DOI 10.1109/MDAT.2020.3001559
   Lerer A., ARXIV190312287
   Li F, 2013, IEEE IPCCC
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Liu WF, 2015, J PARALLEL DISTR COM, V85, P47, DOI 10.1016/j.jpdc.2015.06.010
   Mandal S. K., 2021, COMMUNICATION AWARE
   Mandal SK, 2020, IEEE J EM SEL TOP C, V10, P362, DOI 10.1109/JETCAS.2020.3015509
   Mandal Sumit K., 2021, NETWORK CHIP SECURIT, P55
   Mao HZ, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P270, DOI 10.1145/3341302.3342080
   McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988
   Qiao XM, 2018, DES AUT CON, DOI 10.1145/3195970.3195998
   Sarangi S., 2021, PROC IEEE INT S CIRC, P1
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Tian C, 2020, INT PARALL DISTRIB P, P936, DOI 10.1109/IPDPS47924.2020.00100
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang M., 2019, GRAPH LIBR EFFICIENT
   Wang Zhao, 2020, C ADV COMP ARCH, P73
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Ying R, 2018, ADV NEUR IN, V31
   Zhao W, 2006, IEEE T ELECTRON DEV, V53, P2816, DOI 10.1109/TED.2006.884077
NR 51
TC 4
Z9 4
U1 1
U2 5
PD JUN
PY 2022
VL 12
IS 2
BP 472
EP 485
DI 10.1109/JETCAS.2022.3169899
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Liu, L
   Qu, Z
   Deng, L
   Tu, FB
   Li, SC
   Hu, X
   Gu, ZY
   Ding, YF
   Xie, Y
AF Liu, Liu
   Qu, Zheng
   Deng, Lei
   Tu, Fengbin
   Li, Shuangchen
   Hu, Xing
   Gu, Zhenyu
   Ding, Yufei
   Xie, Yuan
GP IEEE COMP SOC
TI DUET: Boosting Deep Neural Network Efficiency on Dual-Module
   Architecture
SO 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO 2020)
DT Proceedings Paper
CT 53rd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 17-21, 2020
CL ELECTR NETWORK
DE Neural networks; accelerator architecture
AB Deep Neural Networks (DNNs) have been driving the mainstream of Machine Learning applications. However, deploying DNNs on modern hardware with stringent latency requirements and energy constraints is challenging because of the compute-intensive and memory-intensive execution patterns of various DNN models. We propose an algorithm-architecture co-design to boost DNN execution efficiency. Leveraging the noise resilience of nonlinear activation functions in DNNs, we propose dual-module processing that uses approximate modules learned from original DNN layers to compute insensitive activations. Therefore, we can save expensive computations and data accesses of unnecessary sensitive activations. We then design an Executor-Speculator dual-module architecture with support for balance execution and memory access reduction. With acceptable model inference quality degradation, our accelerator design can achieve 2.24x speedup and 1.97x energy efficiency improvement for compute-bound Convolutional Neural Networks (CNNs) and memory-bound Recurrent Neural Networks (RNNs).
C1 [Liu, Liu; Qu, Zheng; Deng, Lei; Tu, Fengbin; Li, Shuangchen; Hu, Xing; Ding, Yufei; Xie, Yuan] UC Santa Barbara, Santa Barbara, CA 93106 USA.
   [Gu, Zhenyu] Alibaba DAMO Acad, Beijing, Peoples R China.
RP Liu, L (corresponding author), UC Santa Barbara, Santa Barbara, CA 93106 USA.
EM liu_liu@ucsb.edu; zhengqu@ucsb.edu; leideng@ucsb.edu;
   fengbintu@ucsb.edu; shuangchenli@ece.ucsb.edu; xinghu@ucsb.edu;
   zhenyu.gu@alibaba-inc.com; yufeiding@cs.ucsb.edu; yuanxie@ece.ucsb.edu
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Achlioptas Dimitris, 2001, P 20 ACM SIGMOD SIGA, P274, DOI DOI 10.1145/375551.375608
   Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Campos V., 2018, P INT C LEARN REPR
   Cao SJ, 2019, PROC CVPR IEEE, P11208, DOI 10.1109/CVPR.2019.01147
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Devlin J., 2018, PREPRINT
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao XY, 2019, CONF REC ASILOMAR C, P930, DOI [10.1109/IEEECONF44664.2019.9048939, 10.1109/ieeeconf44664.2019.9048939]
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hua WZ, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P139, DOI 10.1145/3352460.3358283
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2016, INT SYMP MICROARCH
   Kim D, 2017, DES AUT TEST EUROPE, P1462, DOI 10.23919/DATE.2017.7927222
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kung H., 2018, ARXIV PREPRINT ARXIV
   Lin J., 2017, ADV NEURAL INFORM PR
   Lin Y, 2017, IEEE INT CONF COMMUN, P782
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu L., 2019, 7 INT C LEARN REPR I
   Liu Liyuan, 2020, INT C MACH LEARN ICM
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mahmoud M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P134, DOI 10.1109/MICRO.2018.00020
   Neil D., 2017, PR MACH LEARN RES, P2584
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Song MC, 2018, CONF PROC INT SYMP C, P752, DOI 10.1109/ISCA.2018.00068
   Wang Y., 2016, P 2016 C EMP METH NA, P606, DOI 10.18653/v1/D16-1058
   Xu Y., 2018, 32 AAAI C ARTIFICIAL
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang JF, 2019, SYMP VLSI CIRCUITS, pC306, DOI 10.23919/VLSIC.2019.8778193
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhao R, 2019, PR MACH LEARN RES, V97
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhu JY, 2018, DES AUT TEST EUROPE, P241, DOI 10.23919/DATE.2018.8342010
NR 55
TC 14
Z9 15
U1 1
U2 1
PY 2020
BP 738
EP 750
DI 10.1109/MICRO50266.2020.00066
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Chang, J
   Choi, Y
   Lee, T
   Cho, J
AF Chang, Jiho
   Choi, Yoonsung
   Lee, Taegyoung
   Cho, Junhee
GP IEEE
TI Reducing MAC operation in convolutional neural network with sign
   prediction
SO 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION
   TECHNOLOGY CONVERGENCE (ICTC)
SE International Conference on Information and Communication Technology
   Convergence
DT Proceedings Paper
CT 9th International Conference on Information and Communication Technology
   Convergence (ICTC)
CY OCT 17-19, 2018
CL SOUTH KOREA
DE CNN; Hardware accelerator; Sign prediction; activation function
AB Due to recent researches on artificial neural network algorithms and machine learning, the accuracy of image recognition and natural language processing has increased to the level of human beings in specific fields. Especially, researches to improve the accuracy of algorithms are being actively conducted, and researches on hardware accelerators that implement such algorithms quickly and efficiently are actively under way. In order to utilize artificial intelligence reasoning ability as well as computing speed in mobile or embedded environment, it is necessary to reduce the power consumption and memory usage of artificial intelligence hardware. In this paper, we propose a algorithm to reduce the computational complexity in designing the CNN accelerator. We tried to reduce the MAC computation by encoding the inputs and predicting the sign of the MAC operation. We confirmed the performance improvement by evaluating the sign predictor through the simulation results.
C1 [Chang, Jiho] Elect & Telecommun Res Inst, Intelligent Robot Syst Res Grp, Daejeon, South Korea.
   [Choi, Yoonsung; Lee, Taegyoung; Cho, Junhee] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
RP Chang, J (corresponding author), Elect & Telecommun Res Inst, Intelligent Robot Syst Res Grp, Daejeon, South Korea.
EM changjh@etri.re.kr; giantsol2@kaist.ac.kr; taegyoung@kaist.ac.kr;
   junheecho@kaist.ac.kr
CR Akhlaghi Vahideh, 2018, ISCA 2018
   [Anonymous], 2016, MICRO
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Gao M., 2017, SIGARCH COMPUT ARCHI, V45, P751, DOI [DOI 10.1145/3093337.3037702, 10.1145/3093337.3037702]
   Han S., 2015, ARXIV151000149
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
NR 9
TC 8
Z9 8
U1 0
U2 0
PY 2018
BP 177
EP 182
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Koromilas, E
   Kachris, C
   Soudris, D
   Ballesteros, FJ
   Martinez, P
   Jimenez-Peris, R
AF Koromilas, Elias
   Kachris, Christoforos
   Soudris, Dimitrios
   Ballesteros, Francisco J.
   Martinez, Patricio
   Jimenez-Peris, Ricardo
GP IEEE
TI Modular FPGA Acceleration of Data Analytics in Heterogenous Computing
SO 2019 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 22nd Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 25-29, 2019
CL Florence, ITALY
DE data analytics; databases; cloud computing; FPGAs; heterogeneous
   computing
AB Emerging cloud applications like machine learning, AI and big data analytics require high performance computing systems that can sustain the increased amount of data processing without consuming excessive power. Towards this end, many cloud operators have started deploying hardware accelerators, like FPGAs, to increase the performance of computationally intensive tasks but increasing the programming complexity to utilize these accelerators. VINEYARD has developed an efficient framework that allows the seamless deployment and utilization of hardware accelerators in the cloud without increasing the programming complexity and offering the flexibility of software packages. This paper presents a modular approach for the acceleration of data analytics using FPGAs. The modular approach allows the automatic development of integrated hardware designs for the acceleration of data analytics. The proposed framework shows the data analytics modules can be used to achieve up to 3.5x speedup compared to high performance general-purpose processors.
C1 [Koromilas, Elias] NTUA, Athens, Greece.
   [Koromilas, Elias; Ballesteros, Francisco J.; Martinez, Patricio; Jimenez-Peris, Ricardo] LenXcale, Madrid, Spain.
   [Kachris, Christoforos; Soudris, Dimitrios] NTUA, ICCS, Athens, Greece.
   [Ballesteros, Francisco J.] Univ Rey Juan Carlos, Madrid, Spain.
   [Koromilas, Elias] InAccel Inc, Athens, Greece.
RP Koromilas, E (corresponding author), NTUA, Athens, Greece.; Koromilas, E (corresponding author), LenXcale, Madrid, Spain.; Koromilas, E (corresponding author), InAccel Inc, Athens, Greece.
EM elias.koromilas@gmail.com; kachris@microlab.ntua.gr;
   dsoudris@microlab.ntua.gr
CR Bacon DF, 2013, COMMUN ACM, V56, P56, DOI 10.1145/2436256.2436271
   Kachris C., 2016, INT S APPL REC COMP
   Mavridis S, 2017, I C FIELD PROG LOGIC
   Segal Oren, 2014, FIELD PROGR LOG APPL, P1, DOI [10.1109/FPL.2014.6927442, DOI 10.1109/FPL.2014.6927442]
   Windh S, 2015, P IEEE, V103, P390, DOI 10.1109/JPROC.2015.2399275
NR 5
TC 2
Z9 2
U1 0
U2 2
PY 2019
BP 626
EP 629
DI 10.23919/date.2019.8715018
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Srivastava, N
   Jin, HC
   Smith, S
   Rong, HB
   Albonesi, D
   Zhang, ZR
AF Srivastava, Nitish
   Jin, Hanchen
   Smith, Shaden
   Rong, Hongbo
   Albonesi, David
   Zhang, Zhiru
GP IEEE
TI Tensaurus: A Versatile Accelerator for Mixed Sparse-Dense Tensor
   Computations
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2020)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 26th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 22-26, 2020
CL San Diego, CA
ID MODEL
AB Tensor factorizations are powerful tools in many machine learning and data analytics applications. Tensors are often sparse, which makes sparse tensor factorizations memory bound. In this work, we propose a hardware accelerator that can accelerate both dense and sparse tensor factorizations. We co-design the hardware and a sparse storage format, which allows accessing the sparse data in vectorized and streaming fashion and maximizes the utilization of the memory bandwidth. We extract a common computation pattern that is found in numerous matrix and tensor operations and implement it in the hardware. By designing the hardware based on this common compute pattern, we can not only accelerate tensor factorizations but also mixed sparse-dense matrix operations. We show significant speedup and energy benefit over the state-of-the-art CPU and GPU implementations of tensor factorizations and over CPU, GPU and accelerators for matrix operations.
C1 [Srivastava, Nitish; Jin, Hanchen; Albonesi, David; Zhang, Zhiru] Cornell Univ, Ithaca, NY 14853 USA.
   [Smith, Shaden] Microsoft AI & Res, Redmond, WA USA.
   [Rong, Hongbo] Intel Parallel Comp Lab, Bangalore, Karnataka, India.
RP Srivastava, N (corresponding author), Cornell Univ, Ithaca, NY 14853 USA.
EM nks45@cornell.edu; dha7@cornell.edu; zhiruz@cornell.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], INT PAR DISTR PROC S
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2017, P INT C LEARN REP IC
   [Anonymous], J PARALLEL DISTRIBUT
   [Anonymous], INT S CIRC SYST
   [Anonymous], 2017, FORMIDABLE REPOSITOR
   [Anonymous], INT S MICR MICRO
   [Anonymous], INT C KNOWL DISC DAT
   [Anonymous], 2013, INT C MACH LEARN
   [Anonymous], 2019, ARXIV190106043
   [Anonymous], 2018, P INT C HIGH PERFORM
   [Anonymous], INT S PAR ALG ARCH
   [Anonymous], INT C CLUST COMP CLU
   [Anonymous], 2002, ACM T MATH SOFTWARE
   [Anonymous], JOINT EUR C MACH LEA
   [Anonymous], 2019, ARXIV190701522
   [Anonymous], INT C OBJ OR PROGR S
   [Anonymous], 2016, JEDEC PUBLISHES HBM2
   [Anonymous], 2016, INT S COMP ARCH ISCA
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], WORKSH DEEP LEARN UN
   [Anonymous], P KDD CUP
   [Anonymous], INT C WORLD WID WEB
   [Anonymous], INT PAR DISTR PROC S
   [Anonymous], 49 ANN IEEE ACM INT
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], INT S FIELD PROGR GA
   [Anonymous], INT C HIGH PERF COMP
   [Anonymous], 2011, ACM SIGARCH COMPUTER
   [Anonymous], ARXIV180210574
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], IEEE S FIELD PROGR C
   [Anonymous], INT C COMP ARCH SYNT
   [Anonymous], IEEE S FIELD PROGR C
   [Anonymous], 2009, INT S MICR MICRO
   [Anonymous], INT S MICR MICRO
   [Anonymous], INT S HIGH PERF COMP
   [Anonymous], AS S PAC DES AUT C A
   [Anonymous], 2010, GPU TECHNOLOGY C
   [Anonymous], IEEE HIGH PERF EXTR
   [Anonymous], INT PAR DISTR PROC S
   [Anonymous], 2019, IEEE S FIELD PROGR C
   Ballard G, 2018, INT C HIGH PERFORM, P22, DOI 10.1109/HiPC.2018.00012
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Davis T. A., 2011, U FLORIDA SPARSE MAT
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   Hamilton Will, 2017, ADV NEURAL INFORM PR
   Han S, 2015, ADV NEUR IN, V28
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kolda T. G., 2006, WORKSH LINK AN COUNT
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lebedev V., 2014, ARXIV14126553
   Li JH, 2018, J SENSORS, V2018, DOI 10.1155/2018/5902318
   Lockhart D., 2014, INT S MICR MICRO
   Muralimanohar Naveen, 2009, S Q J MODERN FOREIGN
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Smith S., 2017, EUR C PAR PROC
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 63
TC 46
Z9 46
U1 1
U2 7
PY 2020
BP 689
EP 702
DI 10.1109/HPCA47549.2020.00062
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Tabor, Z
   Kabat, D
   Waligórski, MPR
AF Tabor, Zbislaw
   Kabat, Damian
   Waligorski, Michael P. R.
TI DeepBeam: a machine learning framework for tuning the primary electron
   beam of the PRIMO Monte Carlo software
SO RADIATION ONCOLOGY
DT Article
DE Machine learning; Deep learning; Monte Carlo; Beam simulation; Quality
   assurance (QA); Quality control (QC); Principal component analysis
   (PCA); Support vector regression
ID ABSORBED DOSE DISTRIBUTIONS; PHOTON-BEAM; PARAMETERS; SIMULATION; LINAC;
   VARIAN
AB Background: Any Monte Carlo simulation of dose delivery using medical accelerator-generated megavolt photon beams begins by simulating electrons of the primary electron beam interacting with a target. Because the electron beam characteristics of any single accelerator are unique and generally unknown, an appropriate model of an electron beam must be assumed before MC simulations can be run. The purpose of the present study is to develop a flexible framework with suitable regression models for estimating parameters of the model of primary electron beam in simulators of medical linear accelerators using real reference dose profiles measured in a water phantom.
   Methods: All simulations were run using PRIMO MC simulator. Two regression models for estimating the parameters of the simulated primary electron beam, both based on machine learning, were developed. The first model applies Principal Component Analysis to measured dose profiles in order to extract principal features of the shapes of the these profiles. The PCA-obtained features are then used by Support Vector Regressors to estimate the parameters of the model of the electron beam. The second model, based on deep learning, consists of a set of encoders processing measured dose profiles, followed by a sequence of fully connected layers acting together, which solve the regression problem of estimating values of the electron beam parameters directly from the measured dose profiles. Results of the regression are then used to reconstruct the dose profiles based on the PCA model. Agreement between the measured and reconstructed profiles can be further improved by an optimization procedure resulting in the final estimates of the parameters of the model of the primary electron beam. These final estimates are then used to determine dose profiles in MC simulations.
   Results: Analysed were a set of actually measured (real) dose profiles of 6 MV beams from a real Varian 2300 C/D accelerator, a set of simulated training profiles, and a separate set of simulated testing profiles, both generated for a range of parameters of the primary electron beam of the Varian 2300 C/D PRIMO simulator. Application of the two-stage procedure based on regression followed by reconstruction-based minimization of the difference between measured (real) and reconstructed profiles resulted in achieving consistent estimates of electron beam parameters and in a very good agreement between the measured and simulated photon beam profiles.
   Conclusions: The proposed framework is a readily applicable and customizable tool which may be applied in tuning virtual primary electron beams of Monte Carlo simulators of linear accelerators. The codes, training and test data, together with readout procedures, are freely available at the site: https://github.com/taborzbislaw/DeepBeam.
C1 [Tabor, Zbislaw] AGH Univ Sci & Technol, Al Adama Mickiewicza 30, PL-30059 Krakow, Poland.
   [Kabat, Damian] Maria Sklodowska Curie Natl Res Inst Oncol, Krakow Branch, Garncarska 11, PL-31115 Krakow, Poland.
   [Waligorski, Michael P. R.] Cracow Univ Technol, Podchorazych 1, PL-30084 Krakow, Poland.
RP Tabor, Z (corresponding author), AGH Univ Sci & Technol, Al Adama Mickiewicza 30, PL-30059 Krakow, Poland.
EM tabor.zbislaw@gmail.com
CR Almberg SS, 2012, MED PHYS, V39, P40, DOI 10.1118/1.3668315
   [Anonymous], 2007, HDB RADIOTHERAPY PHY, DOI DOI 10.1201/9781420012026
   [Anonymous], 1998, NEW YORK
   [Anonymous], 2013, MONTE CARLO TECHNIQU
   Bacala AM, 2020, RADIAT ONCOL, V15, DOI 10.1186/s13014-019-1455-1
   Björk P, 2002, PHYS MED BIOL, V47, P4019, DOI 10.1088/0031-9155/47/22/308
   Brualla L, 2010, RADIAT PHYS CHEM, V79, P929, DOI 10.1016/j.radphyschem.2010.03.020
   Chetty IJ, 2007, MED PHYS, V34, P4818, DOI 10.1118/1.2795842
   Failla G., 2010, ACUROS XB ADV DOSE C
   Jiang SB, 2000, MED PHYS, V27, P180, DOI 10.1118/1.598883
   Jolliffe I.T., 2002, SPRINGER SERIES STAT, DOI [DOI 10.1002/9781118445112.STAT02052, DOI 10.1186/1471-2202-15-106]
   Kraft D, 1988, 8828 DFVLR FB
   Maskani Reza, 2015, Asian Pac J Cancer Prev, V16, P7795
   Mohammed M, 2018, RADIAT PHYS CHEM, V144, P69, DOI 10.1016/j.radphyschem.2017.11.017
   Najafzadeh M, 2019, J X-RAY SCI TECHNOL, V27, P1047, DOI 10.3233/XST-190568
   Park Hyojun, 2018, [Journal of Radiation Protection and Research, 방사선방어학회지], V43, P10, DOI 10.14407/jrpr.2018.43.1.10
   Pena J, 2007, MED PHYS, V34, P1076, DOI 10.1118/1.2514155
   Rodriguez M, 2013, STRAHLENTHER ONKOL, V189, P881, DOI 10.1007/s00066-013-0415-1
   Salvat F., 2011, PENELOPE 2011 A CODE
   Storchi P, 1996, PHYS MED BIOL, V41, P637, DOI 10.1088/0031-9155/41/4/005
   Tugrul T, 2019, REP PRACT ONCOL RADI, V24, P331, DOI 10.1016/j.rpor.2019.05.002
   Tzedakis A, 2004, MED PHYS, V31, P907, DOI 10.1118/1.1668551
   Ulmer W, 2005, PHYS MED BIOL, V50, P1767, DOI 10.1088/0031-9155/50/8/010
NR 23
TC 4
Z9 4
U1 1
U2 11
PD JUN 29
PY 2021
VL 16
IS 1
AR 124
DI 10.1186/s13014-021-01847-w
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Bruchon, N
   Fenu, G
   Gaio, G
   Lonza, M
   Pellegrino, FA
   Salvato, E
AF Bruchon, Niky
   Fenu, Gianfranco
   Gaio, Giulio
   Lonza, Marco
   Pellegrino, Felice Andrea
   Salvato, Erica
GP IEEE
TI Toward the Application of Reinforcement Learning to the Intensity
   Control of a Seeded Free-Electron Laser
SO 2019 23RD INTERNATIONAL CONFERENCE ON MECHATRONICS TECHNOLOGY (ICMT
   2019)
DT Proceedings Paper
CT 23rd International Conference on Mechatronics Technology (ICMT)
CY OCT 23-26, 2019
CL Salerno, ITALY
AB The optimization of particle accelerators is a challenging task, and many different approaches have been proposed in years, to obtain an optimal tuning of the plant and to keep it optimally tuned despite drifts or disturbances. Indeed, the classical model-free approaches (such as Gradient Ascent or Extremum Seeking algorithms) have intrinsic limitations. To overcome those limitations, Machine Learning techniques, in particular, the Reinforcement Learning, are attracting more and more attention in the particle accelerator community. The purpose of this paper is to apply a Reinforcement Learning model-free approach to the alignment of a seed laser, based on a rather general target function depending on the laser trajectory. The study focuses on the alignment of the lasers at FERMI, the free-electron laser facility at Elettra Sincrotrone Trieste. In particular, we employ Q-learning with linear function approximation and report experimental results obtained in two setups, which are the actual setups where the final application has to be deployed. Despite the simplicity of the approach, we report satisfactory preliminary results, that represent the first step toward a fully automatic procedure for seed laser to the electron beam. Such a superimposition is, at present, performed manually.
C1 [Bruchon, Niky; Fenu, Gianfranco; Pellegrino, Felice Andrea; Salvato, Erica] Univ Trieste, Dept Engn & Architecture, Trieste, Italy.
   [Gaio, Giulio; Lonza, Marco] Elettra Sincrotrone, Trieste, Italy.
RP Bruchon, N (corresponding author), Univ Trieste, Dept Engn & Architecture, Trieste, Italy.
EM niky.bruchon@phd.units.it; fenu@units.it; giulio.gaio@elettra.eu;
   marco.lonza@elettra.eu; fapellegrino@units.it;
   erica.salvato@phd.units.it
CR Agapov I, 2014, NUCL INSTRUM METH A, V768, P151, DOI 10.1016/j.nima.2014.09.057
   Agapov I., 2015, IPAC
   Allaria E, 2015, J SYNCHROTRON RADIAT, V22, P485, DOI 10.1107/S1600577515005366
   Allaria E, 2013, NAT PHOTONICS, V7, P913, DOI [10.1038/nphoton.2013.277, 10.1038/NPHOTON.2013.277]
   Allaria E, 2012, NAT PHOTONICS, V6, P699, DOI [10.1038/NPHOTON.2012.233, 10.1038/nphoton.2012.233]
   Ariyur K. B., 2003, REAL TIME OPTIMIZATI
   Bruchon N, 2017, NUCL INSTRUM METH A, V871, P20, DOI 10.1016/j.nima.2017.07.048
   Cleva S., 2013, P ICALEPCS2013
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Edelen A. L., 2017, TECH REP
   Edelen A. L., 2017, NIPS
   Gaio G., 2015, ICALEPCS
   Gaio G., 2018, ICALEPCS
   Gaio G., 2013, P ICALEPCS SAN FRANC, P1362
   Geramifard Alborz, 2013, Foundations and Trends in Machine Learning, V6, P375, DOI 10.1561/2200000042
   Hirlaender S., 2019, NEW PARADIGMS TUNING
   Konda VR, 2000, ADV NEUR IN, V12, P1008
   Mataric M. J., 1994, INT C MACHINE LEARNI, P181, DOI DOI 10.1016/B978-1-55860-335-6.50030-1
   McIntire M., 2016, IPAC
   McIntire M, 2016, UAI
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278
   Recht Benjamin, 2018, ARXIV180609460
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Szepesvari C., 2010, SYNTHESIS LECT ARTIF, V4, P1, DOI [10.1007/978-3-031-01551-9, DOI 10.1007/978-3-031-01551-9]
   Tomin S., 2016, IPAC
   Vermorel J, 2005, LECT NOTES ARTIF INT, V3720, P437, DOI 10.1007/11564096_42
   Veronese M., 2014, IBIC2014
   Veronese M., 2008, TUPTPF026 P BIW08 TA
   Veronese M., 2012, IBIC, V12, P449
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   YU LH, 1991, PHYS REV A, V44, P5178, DOI 10.1103/PhysRevA.44.5178
NR 33
TC 7
Z9 7
U1 0
U2 1
PY 2019
DI 10.1109/icmect.2019.8932150
WC Automation & Control Systems; Engineering, Electrical & Electronic;
   Engineering, Mechanical
DA 2023-11-11
ER

PT C
AU Kwon, Y
   Lee, Y
   Rhu, M
AF Kwon, Youngeun
   Lee, Yunjae
   Rhu, Minsoo
GP IEEE Comp Soc
TI Tensor Casting: Co-Designing Algorithm-Architecture for Personalized
   Recommendation Training
SO 2021 27TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2021)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 27th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 27-MAR 03, 2021
CL ELECTR NETWORK
DE computer architecture; memory-centric; machine learning; deep learning;
   recommendation system
AB Personalized recommendations are one of the most widely deployed machine learning (ML) workload serviced from cloud datacenters. As such, architectural solutions for high-performance recommendation inference have recently been the target of several prior literatures. Unfortunately, little have been explored and understood regarding the training side of this emerging ML workload. In this paper, we first perform a detailed workload characterization study on training recommendations, root-causing sparse embedding layer training as one of the most significant performance bottlenecks. We then propose our algorithm-architecture co-design called Tensor Casting, which enables the development of a generic accelerator architecture for tensor gather-scatter that encompasses all the key primitives of training embedding layers. When prototyped on a real CPU-GPU system, Tensor Casting provides 1.9-21 x improvements in training throughput compared to state-of-the-art approaches.
C1 [Kwon, Youngeun; Lee, Yunjae; Rhu, Minsoo] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
RP Kwon, Y (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
EM yekwon@kaist.ac.kr; yunjae408@kaist.ac.kr; mrhu@kaist.ac.kr
CR Alian M., 2019, P INT S MICR MICRO
   Alian M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P802, DOI [10.1109/MICR0.2018.00070, 10.1109/MICRO.2018.00070]
   Alibaba, 2018, US BEH DAT TAOB REC
   Amazon, 2018, AMAZON PRODUCT DATA
   [Anonymous], 2015, THRUST LIB
   [Anonymous], 2019, DEEP LEARNING RECOMM
   [Anonymous], P INT S HIGH PERF CO
   [Anonymous], P INT S COMP ARCH IS
   Asghari-Moghaddam H., 2016, P INT S MICR MICRO
   C. System, 2019, CEREBRAS CS 1 WORLD
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi Y, 2021, INT S HIGH PERF COMP, P493, DOI 10.1109/HPCA51647.2021.00049
   Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027
   Choukse E., 2020, P INT S COMP ARCH IS
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Facebook, 2019, ACC FAC INFR APPL SP
   Google, 2017, CLOUD TPUS ML ACC TE
   Graphcore, 2019, INT PROC UN
   Grouplens, 2016, MOV 20 3 DAT
   Gunny A., 2020, ACCELERATING WIDE DE
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   Habana, 2019, HAB GAUD
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hwang R., 2020, P INT S COMP ARCH IS
   Hynix, 2017, 128 GB 3DS LRDIMM WO
   Hyun B, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1109, DOI 10.1145/3373376.3378494
   Intel, 2019, INT NERV NEUR NETW P
   Intel, 2019, INT MATH KERN LIBR
   JEDEC, 2018, HIGH BANDW MEM HBM2
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaggle, 2014, CRIT DISPL ADV CHALL
   Khan I, 2016, 2016 13TH IEEE ANNUAL CONSUMER COMMUNICATIONS & NETWORKING CONFERENCE (CCNC)
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kwon Y., 2019, IEEE MICRO
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Kwon Y, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P148, DOI 10.1109/MICRO.2018.00021
   Kwon Y, 2018, IEEE COMPUT ARCHIT L, V17, P134, DOI 10.1109/LCA.2018.2823302
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Micron, 2017, MICR SYST POW CALC D
   NVIDIA, 2017, NVIDIA TESL V100
   NVIDIA, 2019, CUDNN GPU ACC DEEP L
   NVIDIA, 2018, NVLINK HIGH SPEED IN
   NVIDIA, 2017, NVIDIA DGX 1V DEEP L
   NVIDIA, 2019, CUBLAS LIB
   NVLabs, 2018, CUB LIB
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rhu M, 2016, INT SYMP MICROARCH
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Santoro A., 2016, ARXIV160506065CS
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Zhao W., 2019, P ACM INT C INF KNOW
NR 53
TC 5
Z9 5
U1 2
U2 8
PY 2021
BP 235
EP 248
DI 10.1109/HPCA51647.2021.00029
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Roorda, E
   Wilton, SJE
AF Roorda, Esther
   Wilton, Steven J. E.
GP IEEE
TI Online Training from Streaming Data with Concept Drift on FPGAs
SO 2023 24TH INTERNATIONAL SYMPOSIUM ON QUALITY ELECTRONIC DESIGN, ISQED
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 24th International Symposium on Quality Electronic Design (ISQED)
CY APR 05-07, 2023
CL ELECTR NETWORK
AB In dynamic environments, the inputs to machine learning models may exhibit statistical changes over time, through what is called concept drift. Incremental training can allow machine learning models to adapt to changing conditions and maintain high accuracy by continuously updating network parameters. In the context of FPGA-based accelerators however, online incremental learning is challenging due to resource and communication constraints, as well as the absence of labelled training data. These challenges have not been fully evaluated or addressed in existing research. In this paper, we present and evaluate strategies for performing incremental training on streaming data with concept drift on FPGA-based platforms. We first present FPGA-based implementations of existing training algorithms to demonstrate the viability of online training with concept shift and to evaluate design tradeoffs. We then propose a technique for online training without labelled data and demonstrate its potential in the context of FPGA-based hardware acceleration.
C1 [Roorda, Esther; Wilton, Steven J. E.] Univ British Columbia, Vancouver, BC, Canada.
RP Roorda, E (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
CR Ditzler G, 2013, IEEE T KNOWL DATA EN, V25, P2283, DOI 10.1109/TKDE.2012.136
   Gomes Heitor Murilo, 2019, ACM SIGKDD Explorations Newsletter, V21, P6, DOI 10.1145/3373464.3373470
   Hacene G. B., 2019, 2019 17 IEEE INT NEW, P1
   Hacene GB, 2019, J SIGNAL PROCESS SYS, V91, P1063, DOI 10.1007/s11265-019-01450-z
   Hacene GB, 2017, IEEE GLOB CONF SIG, P789, DOI 10.1109/GlobalSIP.2017.8309068
   Hoens TR, 2012, PROG ARTIF INTELL, V1, P89, DOI 10.1007/s13748-011-0008-0
   Li Z, 2017, 43RD EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC 2017), DOI [10.1109/TPAMI.2017.2773081, 10.1109/TCC.2017.2764082]
   Losing V, 2018, NEUROCOMPUTING, V275, P1261, DOI 10.1016/j.neucom.2017.06.084
   van de Ven GM, 2019, Arxiv, DOI arXiv:1904.07734
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Piyasena D, 2021, I C FIELD PROG LOGIC, P294, DOI 10.1109/FPL53798.2021.00059
   Piyasena D, 2020, I C FIELD PROG LOGIC, P262, DOI 10.1109/FPL50879.2020.00051
   Settles B, 2009, TECHNICAL REPORT
   Siddhartha, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P309, DOI 10.1109/FPT.2018.00060
   Venkatesan R, 2017, Arxiv, DOI arXiv:1705.00744
   Wozniak M, 2016, PROCEDIA COMPUT SCI, V80, P1724, DOI 10.1016/j.procs.2016.05.514
   Yoon J, 2018, Arxiv, DOI arXiv:1708.01547
   Zliobaite I, 2014, IEEE T NEUR NET LEAR, V25, P27, DOI 10.1109/TNNLS.2012.2236570
   Zliobaite I, 2011, LECT NOTES ARTIF INT, V6913, P597, DOI 10.1007/978-3-642-23808-6_39
NR 20
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 724
EP 731
DI 10.1109/ISQED57927.2023.10129312
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Roelke, A
   Stan, MR
AF Roelke, Alec
   Stan, Mircea R.
BE Stan, M
   Bhatia, K
   Li, H
   Alioto, M
   Sridhar, R
TI Co-optimizing CPUs and Accelerators in Constrained Systems
SO 2018 31ST IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC)
SE International SoC Design Conference
DT Proceedings Paper
CT 31st IEEE International System-on-Chip Conference (SOCC)
CY SEP 04-07, 2018
CL Arlington, VA
AB The rapid rise in popularity of machine learning techniques to mimic functionalities of human cognition and solve problems such as natural language processing has driven a push toward the creation of application-specific accelerators included alongside general-purpose CPUs to improve the performance of inference applications. While significant work has been done to model these accelerators and create ways to explore their design spaces and have even incorporated external effects like data transfer latency, they do not account for the portion of the workload running on the CPU. When designing an electronic system under constraints, prioritizing the accelerator can harm the power or performance of the CPU and reduce the overall quality of the design when running workloads with significant components on it. In this work, we present several workloads running on a RISC-V system with an accelerator tailored to each one and show how the overall power, performance, and area can benefit in the presence of constraints by co-designing the two parts. By using this methodology, we show that power, performance, and area can be improved by up to 66%, 40%, and 25%, respectively, given constraints on each metric.
C1 [Roelke, Alec; Stan, Mircea R.] Univ Virginia, Dept Elect Engn, Charlottesville, VA 22903 USA.
RP Roelke, A (corresponding author), Univ Virginia, Dept Elect Engn, Charlottesville, VA 22903 USA.
EM ar4jc@virginia.edu; mircea@virginia.edu
CR [Anonymous], 1998, MULTIVARIATE DATA AN
   [Anonymous], 2013, P 40 ANN INT S COMPU
   [Anonymous], 2014, ARXIV14125567V2CSCL
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Cong JS, 2015, ICCAD-IEEE ACM INT, P380, DOI 10.1109/ICCAD.2015.7372595
   Eldridge S, 2015, INT CONFER PARA, P99, DOI 10.1109/PACT.2015.21
   Huang S, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P613, DOI 10.1109/ICSICT.2016.7998993
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H., 2008, P 25 INT C MACH LEAR, P536, DOI DOI 10.1145/1390156.1390224
   Lee Y, 2014, PROC EUR SOLID-STATE, P199, DOI 10.1109/ESSCIRC.2014.6942056
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Roelke A., 2017, 1 WORSKH COMP ARCH R
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Shao YS, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1, DOI [10.1109/ETS.2016.7519291, 10.1109/CompComm.2016.7924653]
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Thomas S, 2014, I S WORKL CHAR PROC, P76, DOI 10.1109/IISWC.2014.6983043
   Xi S, 2015, INT S HIGH PERF COMP, P577, DOI 10.1109/HPCA.2015.7056064
NR 21
TC 0
Z9 0
U1 0
U2 1
PY 2018
BP 254
EP 259
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chen, ZY
   Gu, J
AF Chen, Zhengyu
   Gu, Jie
TI High-Throughput Dynamic Time Warping Accelerator for Time-Series
   Classification With Pipelined Mixed-Signal Time-Domain Computing
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Dynamic programming; dynamic time warping (DTW); energy efficient
   computing; machine learning; mixed-signal time-domain (TD) computing
   (MSTC); time flip-flop (TFF); time-series classification (TSC)
AB Time-series classification (TSC) is a challenging problem in machine learning and significant efforts have been made to improve its speed and computation efficiency. Among various approaches, dynamic time warping (DTW) algorithm is one of the most prevalent methods for TSC due to its succinctness and generality. To improve the throughput of the operation, this work presents a mixed-signal DTW accelerator utilizing mixed-signal time-domain (TD) computing where signals are encoded and processed using time pulses. A pipelined operation is enabled by a specially designed time flip-flop (TFF) circuit leading to dramatic improvements in performance and scalability of the operation. A 65-nm CMOS test chip was implemented and measured. The results show more than 9x improvements in throughput compared with prior work on TSC. As most existing TD designs suffer from the lack of TD storage elements, this work utilizes sequential circuit elements in TD computing extending the capability of time-based circuits.
C1 [Chen, Zhengyu; Gu, Jie] Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.
RP Chen, ZY (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.
EM zhengyuchen2015@u.northwestern.edu
CR Bankman D, 2016, IEEE ASIAN SOLID STA, P21, DOI 10.1109/ASSCC.2016.7844125
   Beck Eugen, 2019, ARXIV190701030
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Cao NY, 2019, ISSCC DIG TECH PAP I, V62, P222, DOI 10.1109/ISSCC.2019.8662311
   Chen ZY, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317800
   Chen ZY, 2019, ISSCC DIG TECH PAP I, V62, P324, DOI 10.1109/ISSCC.2019.8662340
   Chen ZY, 2018, IEEE ASIAN SOLID STA, P257
   Chen ZY, 2016, I SYMPOS LOW POWER E, P100, DOI 10.1145/2934583.2934585
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Ding H, 2008, PROC VLDB ENDOW, V1, P1542
   Everson LR, 2019, ISSCC DIG TECH PAP I, V62, P50, DOI 10.1109/ISSCC.2019.8662455
   Farrar M, 2007, BIOINFORMATICS, V23, P156, DOI 10.1093/bioinformatics/btl582
   Fawaz Hassan Ismail, 2018, ARXIV180904356
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Jeong YS, 2011, PATTERN RECOGN, V44, P2231, DOI 10.1016/j.patcog.2010.09.022
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim K, 2014, IEEE J SOLID-ST CIRC, V49, P1007, DOI 10.1109/JSSC.2013.2297412
   Li K. F, 2012, P 14 INT C INF INT W, P132
   Liu Y, 2013, BMC BIOINF, V14
   Madhavan A., 2020, ARXIV200309355
   Madhavan A, 2014, CONF PROC INT SYMP C, P517, DOI 10.1109/ISCA.2014.6853226
   Madhavan A, 2017, IEEE CUST INTEGR CIR
   Miyashita D, 2014, IEEE J SOLID-ST CIRC, V49, P73, DOI 10.1109/JSSC.2013.2284363
   Neves N, 2015, IEEE T VLSI SYST, V23, P1287, DOI 10.1109/TVLSI.2014.2333757
   Sayal A, 2019, ISSCC DIG TECH PAP I, V62, P228, DOI 10.1109/ISSCC.2019.8662510
   Stewart Duncan., EDGE CHIPS COME THEI
   Sundaresan V. K., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol. IV. Conference D: Architectures for Vision and Pattern Recognition, P27, DOI 10.1109/ICPR.1992.202121
   Vincent James., TESLAS NEW CHIP ISNT
   Xu XW, 2018, IEEE T COMPUT AID D, V37, P729, DOI 10.1109/TCAD.2017.2729344
   Yan T, 2006, IEEE ELECTR DEVICE L, V27, P856, DOI 10.1109/LED.2006.882568
   Yu SM, 2016, INT EL DEVICES MEET
NR 32
TC 11
Z9 12
U1 2
U2 5
PD FEB
PY 2021
VL 56
IS 2
BP 624
EP 635
DI 10.1109/JSSC.2020.3021066
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Alcolea, A
   Resano, J
AF Alcolea, Adrian
   Resano, Javier
TI FPGA Accelerator for Gradient Boosting Decision Trees
SO ELECTRONICS
DT Article
DE decision trees; GBDT; FPGA; energy efficiency
ID IMPLEMENTATION
AB A decision tree is a well-known machine learning technique. Recently their popularity has increased due to the powerful Gradient Boosting ensemble method that allows to gradually increasing accuracy at the cost of executing a large number of decision trees. In this paper we present an accelerator designed to optimize the execution of these trees while reducing the energy consumption. We have implemented it in an FPGA for embedded systems, and we have tested it with a relevant case-study: pixel classification of hyperspectral images. In our experiments with different images our accelerator can process the hyperspectral images at the same speed at which they are generated by the hyperspectral sensors. Compared to a high-performance processor running optimized software, on average our design is twice as fast and consumes 72 times less energy. Compared to an embedded processor, it is 30 times faster and consumes 23 times less energy.
C1 [Alcolea, Adrian] Univ Zaragoza, Dept Comp Sci & Syst Engn DIIS, C Maria de Luna 1, Zaragoza 50018, Spain.
   [Resano, Javier] Univ Zaragoza, Engn Res Inst Aragon I3A, C Mariano Esquillor SN, Zaragoza 50018, Spain.
RP Alcolea, A (corresponding author), Univ Zaragoza, Dept Comp Sci & Syst Engn DIIS, C Maria de Luna 1, Zaragoza 50018, Spain.
EM alcolea@unizar.es; jresano@unizar.es
CR Alcolea A., 2021, FPGA ACCELERATOR GBD
   Alcolea A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030534
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Deotte C., IEEE CIS FRAUD DETEC
   Dorogush A.V., ARXIV17060951
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Geron A., HANDS ON MACHINE LEA
   Ikeda Taiga, 2020, Applied Reconfigurable Computing Architectures, Tools, and Applications. 16th International Symposium, ARC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 120830), P345, DOI 10.1007/978-3-030-44534-8_26
   Ke GL, 2017, ADV NEUR IN, V30
   Kulaga R., 2014, IMAGE PROCESS COMMUN, V19, DOI [10.1515/ipc-2015-0012, DOI 10.1515/IPC-2015-0012]
   Li SM, 2023, NEURAL COMPUT APPL, V35, P13037, DOI 10.1007/s00521-020-05592-1
   Lopez S, 2013, P IEEE, V101, P698, DOI 10.1109/JPROC.2012.2231391
   Narayanan R, 2007, DES AUT TEST EUROPE, P189
   Oberg J., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P330, DOI 10.1109/FPL.2012.6339226
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Shepovalov M, 2020, INTEGRATION, V70, P1, DOI 10.1016/j.vlsi.2019.09.007
   Sun R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105942
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Yokogawa, WT210 WT230 DIGITAL
   Zhang TN, 2021, CHEMOSPHERE, V268, DOI 10.1016/j.chemosphere.2020.128801
NR 20
TC 12
Z9 12
U1 5
U2 18
PD FEB
PY 2021
VL 10
IS 3
AR 314
DI 10.3390/electronics10030314
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Ho, K
   Zhao, H
   Jog, A
   Mohanty, S
AF Ho, Khoa
   Zhao, Hui
   Jog, Adwait
   Mohanty, Saraju
GP IEEE
TI Improving GPU Throughput through Parallel Execution Using Tensor Cores
   and CUDA Cores
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
DE Accelerator; GPU; Machine Learning; Tensor core; GEMM; throughput;
   parallel scheduling
AB To accelerate the execution of Machine Learning applications, recent GPUs use Tensor cores to speed up the general matrix multiplication (GEMM), which is the heart of deep learning. The Streaming Processors in such GPUs also contain CUDA cores to implement general computations. While the Tensor cores can significantly improve the performance of GEMM, the CUDA cores remain idle when Tensor cores are running. This leads to inefficient resource utilization. In this work, we propose to offload part of the GEMM operations from Tensor cores to CUDA cores to fully utilize GPU resources. We investigated the performance bottleneck in such offloading schemes and proposed architectural optimization to maximize the GPU throughput. Our technique is purely hardware-based and does not require a new compiler or other software support. Our evaluation results show that the proposed scheme can improve performance by 19% at the maximum.
C1 [Ho, Khoa; Zhao, Hui; Mohanty, Saraju] Univ North Texas, Dept Comp Sci & Engn, Denton, TX USA.
   [Jog, Adwait] William & Mary, Dept Comp Sci, Williamsburg, VA USA.
RP Jog, A (corresponding author), William & Mary, Dept Comp Sci, Williamsburg, VA USA.
EM khoaho@my.unt.edu; hui.zhao@unt.edu; ajog@wm.edu; saraju.mohanty@unt.edu
CR Adriaens JT, 2012, INT S HIGH PERF COMP, P79
   Appleyard J., 2017, NVIDIA DEV TECHN BLO
   Cheng X., 2020, P 21 INT S QUALITY E
   Cheng X., 2019, 2019 ACM S ARCH
   Cheng X., 2020, P 34 ACM INT C SUPER
   Cheng XW, 2018, DES AUT CON
   Choquette J, 2018, IEEE MICRO, V38, P42, DOI 10.1109/MM.2018.022071134
   Harris M., 2016, NVIDIA DEV TECHNICAL
   Jia Z., 2018, DISSECTING NVIDIA VO
   Jia Z, 2019, DISSECTING NVIDIA TU
   Kandiah V., 2021, IEEEACM INT S MICROA
   Kerr A., 2019, NVIDIA GPU TECH C GT
   NVIDIA, 2018, CUDA TOOLK DOC V9 1
   NVIDIA, 2019, CUTLASS CUDA TEMPL L
   NVIDIA, 2020, NVID A100 TENS COR G
   NVIDIA, 2022, CUTLASS CUDA TEMPL L
   NVIDIA, 2020, NVIDIA AMP GA102 GPU
   NVIDIA, 2018, NVIDIA TUR GPU ARCH
   NVIDIA Corporation, 2014, CUDNN DEV GUID
   NVIDIA Corporation, 2017, NVIDIA TESL V100 GPU, P53
   NVIDIA Corporation, 2008, CUBLAS DEV GUID
   Pool J., 2021, NVIDIA DEV TECHNICAL
   Raihan MA, 2019, INT SYM PERFORM ANAL, P79, DOI 10.1109/ISPASS.2019.00016
   Tardy M., 2020, NVIDIA DEV TECHNICAL
   Yamaguchi T., 2021, NVIDIA DEV TECHNICAL
   Zhao H., 2021, IEEE INT C COMP DES
   Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269
NR 27
TC 0
Z9 0
U1 1
U2 2
PY 2022
BP 223
EP 228
DI 10.1109/ISVLSI54635.2022.00051
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Guo, KY
   Zeng, SL
   Yu, JC
   Wang, Y
   Yang, HZ
AF Guo, Kaiyuan
   Zeng, Shulin
   Yu, Jincheng
   Wang, Yu
   Yang, Huazhong
TI [DL] A Survey of FPGA-based Neural Network Inference Accelerators
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA architecture; neural network; parallel processing
AB Recent research on neural networks has shown a significant advantage in machine learning over traditional algorithms based on handcrafted features and models. Neural networks are now widely adopted in regions like image, speech, and video recognition. But the high computation and storage complexity of neural network inference poses great difficulty on its application. It is difficult for CPU platforms to offer enough computation capacity. GPU platforms are the first choice for neural network processes because of its high computation capacity and easy-to-use development frameworks.
   However, FPGA-based neural network inference accelerator is becoming a research topic. With specifically designed hardware, FPGA is the next possible solution to surpass GPU in speed and energy efficiency. Various FPGA-based accelerator designs have been proposed with software and hardware optimization techniques to achieve high speed and energy efficiency. In this article, we give an overview of previous work on neural network inference accelerators based on FPGA and summarize the main techniques used. An investigation from software to hardware, from circuit level to system level is carried out to complete analysis of FPGA-based neural network inference accelerator design and serves as a guide to future work.
C1 [Guo, Kaiyuan; Zeng, Shulin; Yu, Jincheng; Wang, Yu; Yang, Huazhong] Tsinghua Univ, 30 Shuangqing Rd, Beijing 100084, Peoples R China.
RP Guo, KY (corresponding author), Tsinghua Univ, 30 Shuangqing Rd, Beijing 100084, Peoples R China.
EM gky15@mails.tsinghua.edu.cn; zengsl18@mails.tsinghua.edu.cn;
   yjc16@mails.tsinghua.edu.cn; yu-wang@mail.tsinghua.edu.cn;
   yanghz@tsinghua.edu.cn
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Alwani M., 2016, MICROPAGE, P1
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2016, MICRO
   [Anonymous], 2017, FPL
   [Anonymous], 2017, EUR C COMP VIS
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Dally, 2016, ARXIV161201064
   DeePhi Tech, 2017, DNNDK
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Nguyen D, 2017, DES AUT TEST EUROPE, P890, DOI 10.23919/DATE.2017.7927113
   Ghasemzadeh M, 2018, ANN IEEE SYM FIELD P, P57, DOI 10.1109/FCCM.2018.00018
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Guo JX, 2017, ANN IEEE SYM FIELD P, P31, DOI 10.1109/FCCM.2017.13
   Gupta P. K, 2016, 26 INT C FIELD PROGR
   Han S., 2015, ARXIV151000149
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hannun A., 2014, DEEP SPEECH SCALING
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horowitz M., ENERGY TABLE 45NM PR
   Howard A. G., 2017, ARXIV
   Iandola F. N., 2016, ARXIV
   Jia Y., 2017, P 22 ACM INT C MULT, P675
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Li JH, 2017, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2017.8296231
   Li Y, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.00002
   Li Yang, 2018, P INT S LOW POW EL D, V50
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Lin Xinhan, 2018, P 55 ANN DES AUT C, V16
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZQ, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P61, DOI 10.1109/FPT.2016.7929190
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Morcel R, 2017, ANN IEEE SYM FIELD P, P196, DOI 10.1109/FCCM.2017.62
   Moss DJM, 2017, I C FIELD PROG LOGIC, DOI 10.23919/FPL.2017.8056823
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Nakahara H, 2017, 27 INT C FIELD PROGR, P1
   Nakahara H, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P290, DOI 10.1145/3020078.3021782
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samragh M, 2017, ANN IEEE SYM FIELD P, P85, DOI 10.1109/FCCM.2017.43
   Shen JZ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P97, DOI 10.1145/3174243.3174257
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris S. I., 2017, P 27 INT C FIELD PRO, P1, DOI [10.23919/FPL.2017.8056828, DOI 10.1109/ICMTS.2017.7954259]
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Wang J., 2018, ARXIV180804311
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Winograd Shmuel, 1980, ARITHMETIC COMPLEXIT, DOI [10.1137/1.9781611970364, DOI 10.1137/1.9781611970364]
   Wu E., 2017, I C FIELD PROG LOGIC, P1, DOI 10.23919/FPL.2017.8056794
   Xiao Qingcheng, 2017, P 54 ANN DES AUT C 2, V62
   Xilinx Inc, 2018, CHAIDNN
   Xilinx Inc, 2018, XFDNN
   Yu JC, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P227, DOI 10.1109/FPT.2017.8280147
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang CR, 2016, BMC CANCER, V16, DOI 10.1186/s12885-016-2067-x
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhang Xiaofan, 2018, P INT C COMP AID DES, V56
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhou S., 2016, ARXIV160606160
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
   Zhuge CH, 2018, PR GR LAK SYMP VLSI, P123, DOI 10.1145/3194554.3194597
   2018, IEEE T COMPUT AID D, V37, P35, DOI DOI 10.1109/TCAD.2017.2705069
NR 84
TC 131
Z9 139
U1 7
U2 105
PD APR
PY 2019
VL 12
IS 1
AR 2
DI 10.1145/3289185
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Li, JJ
   Jiang, SH
   Gong, SJ
   Wu, JY
   Yan, JC
   Yan, GH
   Li, XW
AF Li, Jiajun
   Jiang, Shuhao
   Gong, Shijun
   Wu, Jingya
   Yan, Junchao
   Yan, Guihai
   Li, Xiaowei
TI SqueezeFlow: A Sparse CNN Accelerator Exploiting Concise Convolution
   Rules
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Convolutional neural networks; accelerator architecture; hardware
   acceleration
ID NEURAL-NETWORKS
AB Convolutional Neural Networks (CNNs) have been widely used in machine learning tasks. While delivering state-of-the-art accuracy, CNNs are known as both compute- and memory-intensive. This paper presents the SqueezeFlow accelerator architecture that exploits sparsity of CNN models for increased efficiency. Unlike prior accelerators that trade complexity for flexibility, SqueezeFlow exploits concise convolution rules to benefit from the reduction of computation and memory accesses as well as the acceleration of existing dense architectures without intrusive PE modifications. Specifically, SqueezeFlow employs a PT-OS-sparse dataflow that removes the ineffective computations while maintaining the regularity of CNN computations. We present a full design down to the layout at 65 nm, with an area of 4.80mm2 and power of 536.09mW. The experiments show that SqueezeFlow achieves a speedup of 2:9 on VGG16 compared to the dense architectures, with an area and power overhead of only 8.8 and 15.3 percent, respectively. On three representative sparse CNNs, SqueezeFlow improves the performance and energy efficiency by 1:8 and 1:5 over the state-of-the-art sparse accelerators.
C1 [Li, Jiajun; Jiang, Shuhao; Gong, Shijun; Wu, Jingya; Yan, Junchao; Yan, Guihai; Li, Xiaowei] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Li, Jiajun; Jiang, Shuhao; Gong, Shijun; Wu, Jingya; Yan, Junchao; Yan, Guihai; Li, Xiaowei] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
RP Yan, GH; Li, XW (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
EM lijiajun@ict.ac.cn; jiangshuhao@ict.ac.cn; gongshijun@ict.ac.cn;
   wujingya@ict.ac.cn; yanjunchao@ict.ac.cn; yan@ict.ac.cn; lxw@ict.ac.cn
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M., 2016, MICROPAGE, P1
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2014, P 2014 5 ASIA PACIFI, DOI DOI 10.1145/2637166.2637229
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Deng Y, 2011, IEEE T IMAGE PROCESS, V20, P2329, DOI 10.1109/TIP.2011.2109729
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Han S., 2016, INT C LEARN REPR ICL
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Ienne P, 1996, J VLSI SIG PROCESS S, V13, P5, DOI 10.1007/BF00930664
   Jiang N., 2018, Fungal Systematics and Evolution, V2, P1, DOI 10.3114/fuse.2018.02.01
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2017, 11 IEEE ACM INT S NE, V2017, P1, DOI [10.1145/3130218.3130230, DOI 10.1145/3130218.3130230]
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   LeCun Y., 2007, ADV NEURAL INFORM PR, V20, P1185
   Lee CHL, 2006, IEEE T KNOWL DATA EN, V18, P613, DOI 10.1109/TKDE.2006.80
   Lee H., 2007, ADV NEURAL INF PROCE, V20, P873
   Li JJ, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P450, DOI 10.1145/3287624.3287641
   Li JJ, 2018, DES AUT TEST EUROPE, P343, DOI 10.23919/DATE.2018.8342033
   Li JJ, 2018, DES AUT TEST EUROPE, P189, DOI [10.1007/978-981-13-0641-9_11, 10.23919/DATE.2018.8342001]
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI DOI 10.1145/2485922.2485925
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Ranzato MA., 2006, ADV NEURAL INFORM PR, V19, P1137
   SamuelWilliams Leonid Oliker, 2007, SC 07, P1, DOI DOI 10.1145/1362622.1362674
   Schmidhuber J., 2011, P 22 INT JOINT C ART
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simard PY, 1999, ADV NEUR IN, V11, P571
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STRANG G, 1986, STUD APPL MATH, V74, P171
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Williams S., 2008, THESIS
   Yuster R, 2005, ACM T ALGORITHMS, V1, P2, DOI 10.1145/1077464.1077465
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang X, 2016, IFAC PAPERSONLINE, V49, P1, DOI 10.1016/j.ifacol.2016.10.130
NR 55
TC 28
Z9 28
U1 2
U2 11
PD NOV
PY 2019
VL 68
IS 11
BP 1663
EP 1677
DI 10.1109/TC.2019.2924215
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Thuerck, D
   Weber, N
   Bifulco, R
AF Thuerck, Daniel
   Weber, Nicolas
   Bifulco, Roberto
TI Flynn's Reconciliation: Automating the Register Cache Idiom for
   Cross-accelerator Programming
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE Accelerated computing; GPGPU; warp-register cache; batched kernels;
   SIMT; SIMD; cross-architecture compilation; source-to-source compiler
ID SIMD; OPENCL; MULTI
AB A large portion of the recent performance increase in the High Performance Computing (HPC) and Machine Learning (ML) domains is fueled by accelerator cards. Many popular ML frameworks support accelerators by organizing computations as a computational graph over a set of highly optimized, batched general-purpose kernels. While this approach simplifies the kernels' implementation for each individual accelerator, the increasing heterogeneity among accelerator architectures for HPC complicates the creation of portable and extensible libraries of such kernels. Therefore, using a generalization of the CUDA community's warp register cache programming idiom, we propose a new programming idiom (CoRe) and a virtual architecture model (PIRCH), abstracting over SIMD and SIMT paradigms. We define and automate the mapping process from a single source to PIRCH's intermediate representation and develop backends that issue code for three different architectures: Intel AVX512, NVIDIA GPUs, and NEC SX-Aurora. Code generated by our source-to-source compiler for batched kernels, borG, competes favorably with vendor-tuned libraries and is up to 2x faster than hand-tuned kernels across architectures.
C1 [Thuerck, Daniel; Weber, Nicolas; Bifulco, Roberto] NEC Labs Europe, Kurftirsten Anlage 36, Heidelberg, Germany.
   [Thuerck, Daniel] Tech Univ Darmstadt, Darmstadt, Germany.
RP Thuerck, D (corresponding author), NEC Labs Europe, Kurftirsten Anlage 36, Heidelberg, Germany.
EM daniel.thuerck@neclab.eu; nicolas.weber@neclab.eu;
   roberto.bifulco@neclab.eu
CR Aleen F, 2018, INT J PARALLEL PROG, V46, P471, DOI 10.1007/s10766-016-0485-7
   Ali Y, 2019, PROCEEDINGS OF SCALA 2019: 2019 IEEE/ACM 10TH WORKSHOP ON LATEST ADVANCES IN SCALABLE ALGORITHMS FOR LARGE-SCALE SYSTEMS (SCALA), P1, DOI 10.1109/ScalA49573.2019.00006
   Anderson Andrew, 2015, ACM T ARCHIT CODE OP, V12, P1
   [Anonymous], 2003, CASES 2003 INT C COM
   [Anonymous], 2010, PYCPARSER
   Anzt H, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4460
   Anzt H, 2017, PROC INT CONF PARAL, P91, DOI 10.1109/ICPP.2017.18
   Applegate D., 2001, COMPUTATIONAL COMBIN, P261
   Barham P, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P177, DOI 10.1145/3317550.3321441
   Bauer M, 2014, ACM SIGPLAN NOTICES, V49, P119, DOI [10.1145/2555243.2555258, 10.1145/2692916.2555258]
   Beckingsale DA, 2019, PROCEEDINGS OF P3HPC 2019: 2019 IEEE/ACM INTERNATIONAL WORKSHOP ON PERFORMANCE, PORTABILITY AND PRODUCTIVITY IN HPC (P3HPC), P71, DOI 10.1109/P3HPC49587.2019.00012
   Bertolacci IJ, 2016, PROCEEDINGS OF WACCPD 2016: THIRD WORKSHOP ON ACCELERATOR PROGRAMMING USING DIRECTIVES, P57, DOI [10.1109/WACCPD.2016.5, 10.1109/WACCPD.2016.010]
   Buchheim C, 2008, OPER RES LETT, V36, P430, DOI 10.1016/j.orl.2008.01.004
   Cassignol A, 2019, PREHOSP EMERG CARE, V23, P543, DOI 10.1080/10903127.2018.1549627
   Chen PY, 2019, IEEE CUST INTEGR CIR, DOI 10.1109/CICC.2019.8780148
   Clark N, 2007, INT S HIGH PERF COMP, P216
   de Fine Licht J., 2019, P INT C HIGH PERF CO
   Diaz J, 2012, IEEE T PARALL DISTR, V23, P1369, DOI 10.1109/TPDS.2011.308
   Du P, 2012, PARALLEL COMPUT, V38, P391, DOI 10.1016/j.parco.2011.10.002
   FLETCHER R, 1964, COMPUT J, V7, P149, DOI 10.1093/comjnl/7.2.149
   Fung WWL, 2009, ACM T ARCHIT CODE OP, V6, DOI 10.1145/1543753.1543756
   Griebl M, 1998, 1998 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, PROCEEDINGS, P106, DOI 10.1109/PACT.1998.727179
   Hahnle Nicolai, 2019, D68994 RFC REDEFINE
   Haider M.A.R., 2017, IEEE 8 INT S POW EL, P1, DOI DOI 10.1109/PEDG.2017.7972500
   Haj-Ali A, 2020, INT SYM CODE GENER, P242, DOI 10.1145/3368826.3377928
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Joyner David, 2012, ACM COMMUN COMPUT AL, V45, P225, DOI DOI 10.1145/2110170.2110185
   Karrenberg R, 2015, AUTOMATIC SIMD VECTO, P85
   Kessenich John, 2018, SPIR V SPECIFICATION, P3
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lattner Chris, 2020, 200211054 ARXIV
   Leissa R., 2014, P 2014 WORKSH PROGR, P17, DOI DOI 10.1145/2568058.2568062
   Leissa R, 2012, ACM SIGPLAN NOTICES, V47, P65, DOI 10.1145/2370036.2145825
   Lemaitre Florian, 2018, P 4 WORKSH PROGR MOD, P1
   Li A, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P53, DOI 10.1145/3205289.3205294
   Lopez MG, 2016, PROCEEDINGS OF WACCPD 2016: THIRD WORKSHOP ON ACCELERATOR PROGRAMMING USING DIRECTIVES, P13, DOI [10.1109/WACCPD.2016.006, 10.1109/WACCPD.2016.9]
   Molina A., 2019, ARXIV PREPRINT ARXIV
   Moll Simon, 2019, D57504 RFC PROTOTYPE
   Moll Simon, 2019, P 5 WORKSH PROGR MOD, P1
   Nuzman D, 2011, INT SYM CODE GENER, P151, DOI 10.1109/CGO.2011.5764683
   NVIDIA, 2020, CUDA C PROGRAMMING G
   Pharr M., 2012, 2012 INNOVATIVE PARA, P1, DOI 10.1109/InPar.2012.6339601
   Rodríguez-Gallegos CD, 2019, PROG PHOTOVOLTAICS, V27, P113, DOI 10.1002/pip.3036
   Shin J, 2002, 2002 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, PROCEEDINGS, P45, DOI 10.1109/PACT.2002.1106003
   Steuwer M, 2017, INT SYM CODE GENER, P74, DOI 10.1109/CGO.2017.7863730
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Thuerck D, 2019, 2019 IEEE/ACM 9TH WORKSHOP ON IRREGULAR APPLICATIONS - ARCHITECTURES AND ALGORITHMS (IA3), P51, DOI 10.1109/IA349570.2019.00014
   Thuerck D, 2018, PROCEEDINGS OF IA3 2018: 2018 IEEE/ACM 8TH WORKSHOP ON IRREGULAR APPLICATIONS: ARCHITECTURES AND ALGORITHMS, P1, DOI 10.1109/IA3.2018.00008
   Thuerck Daniel, 2020, P IEEEACM 10 WORKSH
   Tino A, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3392032
   Vandermersch P., 2014, ARXIV PREPRINT ARXIV
   Vasilache N, 2019, ACM T ARCHIT CODE OP, V16, DOI 10.1145/3355606
   Wang Endong, 2014, HIGH PERFORMANCE COM, P167, DOI [10.1007/978-3-319-06486-4_7, DOI 10.1007/978-3-319-06486-47]
   Weber N, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3106341
   Wu JY, 2016, INT SYM CODE GENER, P105, DOI 10.1145/2854038.2854041
   Zhao Tuowen, 2019, P INT C HIGH PERFORM, P1
NR 56
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2021
VL 18
IS 3
AR 37
DI 10.1145/3458357
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Pham-Quoc, C
AF Cuong Pham-Quoc
BE Bao, VNQ
   Quang, PM
   Hoa, HV
TI Design Framework for FPGA-based Hardware Accelerators with Heterogeneous
   Interconnect
SO PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY
   DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE
   (NICS)
DT Proceedings Paper
CT 6th National-Foundation-for Science-and-Technology-Development
   (NAFOSTED) Conference on Information and Computer Science (NICS)
CY DEC 12-13, 2019
CL Posts & Telecommunicat Inst Technol Hanoi, Hanoi, VIETNAM
HO Posts & Telecommunicat Inst Technol Hanoi
AB In recent years, several hardware accelerators have been proposed for both embedded and high-performance computing systems. Hardware accelerators nowadays become more popular for improving the performance of modern computing systems such as Machine Learning or Big Data analytics. However, the interconnects in general-purpose hardware accelerators are not well optimized to satisfy the communication demands of an application. In this work, we present an automated approach to design hardware accelerator systems with an efficient hybrid interconnect for hardware kernels driven by the detailed data communication patterns of an application. The heterogeneous interconnect includes an NoC, shared local memory, or both. Based on the quantitative data communication profile, each application is developed with a custom hybrid interconnect to achieve an optimized performance while keeping the hardware resource usage for the interconnect as low as possible. Our experimental results in an embedded system and a high-performance computing system achieve overall application speed-ups by up to 2.87 x and 1.54 x compared to the baseline systems, respectively. The experimental results also show that the designed systems can reduce hardware resources usage up to 33% for the embedded system and 45% for the high-performance computing system.
C1 [Cuong Pham-Quoc] Ho Chi Minh City Univ Technol, VNU HCM, Ho Chi Minh City, Vietnam.
RP Pham-Quoc, C (corresponding author), Ho Chi Minh City Univ Technol, VNU HCM, Ho Chi Minh City, Vietnam.
EM cuongpham@hcmut.edu.vn
CR [Anonymous], GAM DEV C
   [Anonymous], 1994, COMPUTER VISION PATT
   Ashraf I., 2015, EXACOMM 2015
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CONG J, 2017, DAC 17
   Cong Jason, 2016, SOURCE SOURCE OPTIMI, P137, DOI [10.1007/978-3-319-26408-0, DOI 10.1007/978-3-319-26408-0]
   Cuong PQ, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND APPLICATIONS (ACOMP), P1, DOI 10.1109/ACOMP.2018.00009
   Cuong PQ, 2017, PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND APPLICATIONS (ACOMP), P111, DOI 10.1109/ACOMP.2017.27
   Cuong PQ, 2013, DES AUT TEST EUROPE, P843
   Cuong Pham-Quoc, 2016, ACM SIGARCH Computer Architecture News, V44, P14, DOI 10.1145/3039902.3039906
   Pham-Quoc C, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P151, DOI 10.1109/IPDPSW.2014.21
   Cuong PQ, 2013, 2013 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS (AHS), P189, DOI 10.1109/AHS.2013.6604245
   Cutress I., 2019, XILINX ANNOUNCES PRO
   Esmaeilzadeh H, 2012, IEEE MICRO, V32, P122, DOI 10.1109/MM.2012.17
   Glick D., 2019, FPGA 19, P306
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   Hara Yuko, 2009, J INFORM PROCESSING, V17, P242
   Kumar R, 2005, COMPUTER, V38, P32, DOI 10.1109/MC.2005.379
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Micron, 2012, HYBR COR COMP
   Nane R, 2014, 2014 12TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (EUC 2014), P138, DOI 10.1109/EUC.2014.28
   Nethercote N, 2007, ACM SIGPLAN NOTICES, V42, P89, DOI 10.1145/1273442.1250746
   Pnevmatikatos D, 2015, MICROPROCESS MICROSY, V39, P321, DOI 10.1016/j.micpro.2014.09.006
   Putnam A, 2017, ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2017, P328, DOI 10.1145/3075564.3095083
   Sanchez D, 2010, ACM T ARCHIT CODE OP, V7, DOI 10.1145/1756065.1736069
   Scott J., 1998, IEEE POW DRIV MICR W
   Smith S. M., 1992, SUSAN LOW LEVEL IMAG
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Torabzadehkashi M, 2019, EUROMICRO WORKSHOP P, P430, DOI 10.1109/EMPDP.2019.8671589
   Vassiliadis S, 2004, IEEE T COMPUT, V53, P1363, DOI 10.1109/TC.2004.104
   Voros NS, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2442116.2442120
   Wei XC, 2017, ASIA S PACIF DES AUT, P488, DOI 10.1109/ASPDAC.2017.7858370
   Xilinx, 2009, ML150 REF DES
   Xilinx, 2014, VIV HIGH LEV SYNTH
   Yang HJ, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P128, DOI 10.1145/2847263.2847283
NR 36
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 148
EP 153
DI 10.1109/nics48868.2019.9023825
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Chaudhuri, A
   Liu, CS
   Fan, XX
   Chakrabarty, K
AF Chaudhuri, Arjun
   Liu, Chunsheng
   Fan, Xiaoxin
   Chakrabarty, Krishnendu
TI C-Testing and Efficient Fault Localization for AI Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE C-testing; AI accelerators; fault localization; reconfigurable scan
AB Accelerators for machine learning [artificial intelligence (AI)] inferencing applications are homogeneous designs composed of identical cores. Each core or processing element (PE) contains multiply-and-accumulate units, control logic, and registers for storing and forwarding weights and activations. Testing homogeneous array-based AI accelerator chips by running automatic test pattern generation (ATPG) at the array level results in a high CPU time and pattern count. We propose a constant-testable (C-testable) method for test generation at the PE level such that the ATPG effort does not increase with the number of PEs. Our results show that compared to the traditional array-level testing, the proposed method achieves up to 4.2x (3.5x), 1530x (2388x), and 170x (142x) reduction in the test pattern count, ATPG runtime, and test cycle count, respectively, for stuck-at (transition) faults in a 256x256 array, while preserving the test coverage. A reconfigurable scan architecture is introduced to enable the proposed C-testable solution for the entire accelerator array. The design-space exploration of a hierarchical test-compaction framework is presented. We also describe four debug solutions for fault localization and diagnosis.
C1 [Chaudhuri, Arjun; Liu, Chunsheng; Fan, Xiaoxin] Alibaba Grp Inc, DAMO Acad, Sunnyvale, CA 94085 USA.
   [Chaudhuri, Arjun; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
RP Chaudhuri, A (corresponding author), Alibaba Grp Inc, DAMO Acad, Sunnyvale, CA 94085 USA.; Chaudhuri, A (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
EM ac499@duke.edu
CR Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   ELHUNI H, 1986, IEEE T COMPUT AID D, V5, P573, DOI 10.1109/TCAD.1986.1270228
   Genc H., 2019, ARXIV191109925
   Giles G., 2008, PROC IEEE INT TEST C, P1
   Han T, 2015, IEEE T VLSI SYST, V23, P1439, DOI 10.1109/TVLSI.2014.2341674
   Jiang LJ, 2017, PROC INT CONF PARAL, P422, DOI 10.1109/ICPP.2017.51
   Jiao Y, 2020, ISSCC DIG TECH PAP I, P136, DOI 10.1109/ISSCC19947.2020.9062984
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim KS, 2008, IEEE DES TEST COMPUT, V25, P142, DOI 10.1109/MDT.2008.39
   Knowles M., 2018, CISC VIS NETW IND GL
   Liu X, 2016, 2016 IEEE 25TH NORTH ATLANTIC TEST WORKSHOP (NATW), P12, DOI 10.1109/NATW.2016.10
   LOMBARDI F, 1989, INTEGRATION, V8, P269, DOI 10.1016/0167-9260(89)90020-5
   Marinissen E. J., 1999, International Test Conference 1999. Proceedings (IEEE Cat. No.99CH37034), P616, DOI 10.1109/TEST.1999.805786
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Rabaey J. M., 2003, DIGITAL INTEGRATED C, V7
   Rajski J, 2002, INT TEST CONF P, P301, DOI 10.1109/TEST.2002.1041773
   Ramdas A, 2013, IEEE T COMPUT AID D, V32, P1124, DOI 10.1109/TCAD.2013.2245376
   Sadi M, 2022, IEEE T COMPUT AID D, V41, P104, DOI 10.1109/TCAD.2021.3051841
   Samajdar Ananda, 2018, SCALE SIM SYSTOLIC C
   Sharma M., 2011, Proceedings of the 2011 IEEE International Test Conference (ITC), P1, DOI 10.1109/TEST.2011.6139171
   Singhal R., 2019, CISC VIS NETW IND GL
   Srinivasan P, 2010, IEEE COMP SOC ANN, P52, DOI 10.1109/ISVLSI.2010.59
   Sun BH, 2018, IEEE COMPUT SOC CONF, P1758, DOI 10.1109/CVPRW.2018.00219
   Whetsel L., 2005, U.S. Patent, Patent No. [A11051696, 11051696]
   Wohl P, 2005, IEEE VLSI TEST SYMP, P359, DOI 10.1109/VTS.2005.48
   Wu YJ, 2003, IEEE T COMPUT AID D, V22, P327, DOI 10.1109/TCAD.2002.807889
NR 28
TC 9
Z9 9
U1 0
U2 2
PD JUL
PY 2022
VL 41
IS 7
BP 2348
EP 2361
DI 10.1109/TCAD.2021.3107401
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Shivanandamurthy, SM
   Thakkar, IG
   Salehi, SA
AF Shivanandamurthy, Supreeth Mysore
   Thakkar, Ishan G.
   Salehi, Sayed Ahmad
GP IEEE Comp Soc
TI <i>ATRIA</i>: A Bit-Parallel Stochastic Arithmetic Based Accelerator for
   In-DRAM CNN Processing
SO 2021 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2021)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 20th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 07-09, 2017-2021
CL ELECTR NETWORK
DE Stochastic Arithmetic; In-Memory Processing; Convolutional Neural
   Networks
AB With the rapidly growing use of Convolutional Neural Networks (CNNs) in real-world applications related to machine learning and Artificial Intelligence (AI), several hardware accelerator designs for CNN inference and training have been proposed recently. In this paper, we present ATRIA, a novel bit-pArallel sTochastic aRithmetic based In-DRAM Accelerator for energy-efficient and high-speed inference of CNNs. ATRIA employs light-weight modifications in DRAM cell arrays to implement bit-parallel stochastic arithmetic based acceleration of multiply-accumulate (MAC) operations inside DRAM. ATRIA significantly improves the latency, throughput, and efficiency of processing CNN inferences by performing 16 MAC operations in only five consecutive memory operation cycles. We mapped the inference tasks of four benchmark CNNs on ATRIA to compare its performance with five state-of-the-art in-DRAM CNN accelerators from prior work. The results of our analysis show that ATRIA exhibits only 3.5% drop in CNN inference accuracy and still achieves improvements of up to 3.2x in frames-per-second (FPS) and up to 10x in efficiency (FPS/W/mm(2)), compared to the best-performing in-DRAM accelerator from prior work.
C1 [Shivanandamurthy, Supreeth Mysore; Thakkar, Ishan G.; Salehi, Sayed Ahmad] Univ Kentucky, Dept Elect & Comp Engn, Lexington, KY 40506 USA.
RP Shivanandamurthy, SM (corresponding author), Univ Kentucky, Dept Elect & Comp Engn, Lexington, KY 40506 USA.
EM supreethms@uky.edu; igthakkar@uky.edu; sayedsalehi@uky.edu
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   [Anonymous], 2010, MEMORY SYSTEMS CACHE
   [Anonymous], 2018, DISCIPLINED APPROA 1
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Chang KK, 2016, INT S HIGH PERF COMP, P568, DOI 10.1109/HPCA.2016.7446095
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Deng Q, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317845
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li SC, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P696, DOI [10.1109/MICRO.2018.00062, 10.1109/MICR0.2018.00062]
   Li Z, 2016, PR IEEE COMP DESIGN, P678, DOI 10.1109/ICCD.2016.7753357
   Lou QW, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3304110
   Ren A, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P405, DOI 10.1145/3037697.3037746
   Seshadri Vivek, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P185, DOI 10.1145/2540708.2540725
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thakkar IG, 2015, IEEE T MULTI-SCALE C, V1, P168, DOI 10.1109/TMSCS.2015.2481425
   Zamanlooy B., 2013, IEEE T VLSI SYST, V22, P39, DOI DOI 10.1109/TVLSI.2012.2232321
   Zunino RF, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P117
NR 28
TC 3
Z9 3
U1 0
U2 3
PY 2021
BP 200
EP 205
DI 10.1109/ISVLSI51109.2021.00045
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Rawal, A
   Fang, YW
   Chien, AA
AF Rawal, Arjun
   Fang, Yuanwei
   Chien, Andrew A.
GP IEEE
TI Programmable Acceleration for Sparse Matrices in a Data-movement Limited
   World
SO 2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
DE heterogeneous architecture; accelerator; memory bandwidth wall; sparse
   matrix multiplication
ID SIMULATION
AB Data movement cost is a critical performance concern in today's computing systems. We propose a heterogeneous architecture that combines a CPU core with an efficient data recoding accelerator and evaluate it on sparse matrix computation. Such computations underly a wide range of important computations such as partial differential equation solvers, sequence alignment, and machine learning and are often data movement limited. The data recoding accelerator is orders of magnitude more energy efficient than a conventional CPU for recoding, allowing sparse matrix representation to be optimized for data movement.
   We evaluate the heterogeneous system with a recoding accelerator using the TAMU sparse matrix library, studying >369 diverse sparse matrix examples finding geometric mean performance benefits of 2.4x. In contrast, CPU's exhibit poor recoding performance (up to 30x worse), making data representation optimization infeasible. Holding SpMV performance constant, adding the recoding optimization and accelerator can produce power reductions of 63% and 51% on DDR and HBM-based memory systems, respectively, when evaluated on a set of 7 representative matrices. These results show the promise of this new heterogeneous architecture approach.
C1 [Rawal, Arjun; Fang, Yuanwei; Chien, Andrew A.] Univ Chicago, Comp Sci Dept, Chicago, IL 60637 USA.
RP Rawal, A (corresponding author), Univ Chicago, Comp Sci Dept, Chicago, IL 60637 USA.
EM arjunrawal4@cs.uchicago.edu; fywkevin@cs.uchicago.edu;
   achien@cs.uchicago.edu
CR [Anonymous], 2013, INTEL COMMUNICATIONS
   [Anonymous], 2012, P 26 ACM INT C SUP I
   [Anonymous], 2016, THE 49TH ANNUAL IEEE
   [Anonymous], 2014, OPERATING SYSTEMS DE
   [Anonymous], 2010, IBM POWER EDGE NETWO
   Ashari A., P INT C HIGH PERF CO, P781
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Birdsall C. K., 2004, PLASMA PHYS VIA COMP
   Blelloch G. E., 1993, TECHNICAL REPORT
   Boehm M, 2016, PROC VLDB ENDOW, V9, P1425, DOI 10.14778/3007263.3007279
   Buluc A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P721, DOI 10.1109/IPDPS.2011.73
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Elafrou A, 2017, PROC INT CONF PARAL, P292, DOI 10.1109/ICPP.2017.38
   Fang Y., 2014, 4 WORKSH ARCH SYST B
   Fang Y., 2017, TECHNICAL REPORT
   Fang YW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P55, DOI 10.1145/3123939.3123983
   Fang Yuanwei, 2015, P 48 INT S MICR MICR
   Fowers J., 2015, P FCCM 15 MAY
   Fowers J, 2014, ANN IEEE SYM FIELD P, P36, DOI 10.1109/FCCM.2014.23
   GERMANO M, 1991, PHYS FLUIDS A-FLUID, V3, P1760, DOI 10.1063/1.857955
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Heroux M. A., 2007, HPCCG SOLVER PACKAGE
   Kreutzer M, 2014, SIAM J SCI COMPUT, V36, pC401, DOI 10.1137/130930352
   Lawlor O. S., 2013, P 3 WORKSH IRR APPL, P6
   Lehane A, 2015, TR201505 U CHIC
   Li JJ, 2013, ACM SIGPLAN NOTICES, V48, P117, DOI 10.1145/2499370.2462181
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Liu Xing, 2013, P 27 INT ACM C INT C, P273, DOI DOI 10.1145/2464996.2465013
   Merrill D, 2016, ACM SIGPLAN NOTICES, V51, P389, DOI 10.1145/2851141.2851190
   Mount David W, 2007, CSH Protoc, V2007, DOI 10.1101/pdb.top17
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   NVIDIA, 2017, TIT V HAS 21 BILL TR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Robert C., 2014, MACHINE LEARNING PRO
   Rogers B. M., ACM SIGARCH COMPUTER, V37, P371
   SamuelWilliams Leonid Oliker, 2007, SC 07, P1, DOI DOI 10.1145/1362622.1362674
   Sedaghati N, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P99, DOI 10.1145/2751205.2751244
   Sonnhammer ELL, 1995, GENE, V167, pGC1, DOI 10.1016/0378-1119(95)00714-8
   Springel V, 2005, MON NOT R ASTRON SOC, V364, P1105, DOI 10.1111/j.1365-2966.2005.09655.x
   Thanh-Hoang T., 2016, P DATE 16 MAR
   Williams S., 2010, SCI COMPUTING MULTIC, P83
   Xilinx, 2016, ULTR PLUS HAS 21 2 T
   Xu BH, 1997, CHEM ENG SCI, V52, P2785, DOI 10.1016/S0009-2509(97)00081-X
NR 43
TC 4
Z9 4
U1 0
U2 0
PY 2019
BP 47
EP 56
DI 10.1109/IPDPSW.2019.00016
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Zhu, MY
   Luo, JP
   Mao, WD
   Wang, ZF
AF Zhu, Mingyu
   Luo, Jiapeng
   Mao, Wendong
   Wang, Zhongfeng
GP IEEE
TI An Efficient FPGA-based Accelerator for Deep Forest
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS 22)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-JUN 01, 2022
CL Austin, TX
DE Deep Forest; Random Forest; Decision Tree; Machine Learning; Hardware
   Acceleration; FPGA
AB Deep Forest is a prominent machine learning algorithm known for its high accuracy in forecasting. Compared with deep neural networks, Deep Forest has almost no multiplication operations and has better performance on small datasets. However, due to the deep structure and large forest quantity, it suffers from large amounts of calculation and memory consumption. In this paper, an efficient hardware accelerator is proposed for deep forest models, which is also the first work to implement Deep Forest on FPGA. Firstly, a delicate node computing unit (NCU) is designed to improve inference speed. Secondly, based on NCU, an efficient architecture and an adaptive dataflow are proposed, in order to alleviate the problem of node computing imbalance in the classification process. Moreover, an optimized storage scheme in this design also improves hardware utilization and power efficiency. The proposed design is implemented on an FPGA board, Intel Stratix V, and it is evaluated by two typical datasets, ADULT and Face Mask Detection. The experimental results show that the proposed design can achieve around 40 x speedup compared to that on a 40 cores high performance x86 CPU.
C1 [Zhu, Mingyu; Luo, Jiapeng; Mao, Wendong; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
RP Wang, ZF (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
EM mingyu.zhu@smail.nju.edu.cn; luojiapeng1993@gmail.com;
   wdmao@smail.nju.edu.cn; zfwang@nju.edu.cn
CR Alharam A. K., 2020, 2020 IEEE INT S CIRC
   Baranyi Peter, TP TOOLBOX
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   LICHMAN M., 2013, UCI MACHINE LEARNING
   Liu FT, 2008, J ARTIF INTELL RES, V32, P355, DOI 10.1613/jair.2470
   Nakahara H., 2017, 2017 IEEE 47 INT S M
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Van Essen Brian, 2012, IEEE INT S FIELD PRO
   Zhou Z.-H., 2017, DEEP FOREST ALTERNAT
NR 10
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 3334
EP 3338
DI 10.1109/ISCAS48785.2022.9937620
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ji, HX
   Song, LH
   Jiang, L
   Li, H
   Chen, YR
AF Ji, Houxiang
   Song, Linghao
   Jiang, Li
   Li, Ha (Haken)
   Chen, Yiran
GP IEEE
TI RECOM: An Efficient Resistive Accelerator for Compressed Deep Neural
   Networks
SO PROCEEDINGS OF THE 2018 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 19-23, 2018
CL Dresden, GERMANY
AB Deep Neural Networks (DNNs) play a key role in prevailing machine learning applications. Resistive random-access memory (ReRAM) is capable of both computation and storage, contributing to the acceleration on DNNs by processing in memory. Besides, a significant amount of zero weights is observed in DNNs, providing a space to reduce computation cost further by skipping ineffectual calculations associated with them. However, the irregular distribution of zero weights in DNNs makes it difficult for resistive accelerators to take advantage of the sparsity as expected efficiently, because of its high reliance on regular matrix-vector multiplication in ReRAM. In this work, we propose ReCom, the first resistive accelerator to support sparse DNN processing. ReCom is an efficient resistive accelerator for compressed deep neural networks, where DNN weights are structurally compressed to eliminate zero parameters and become hardware-friendly. Zero DNN activation is also considered at the same time. Two technologies, Structurally-compressed Weight. Oriented Fetching (SWOP) and hi-layer Pipeline for Memory and Computation (IPMC), are particularly proposed. In our evaluation, ReCom can achieve 3.37x speedup and 2.41x energy efficiency compared to a state-of-the-art resistive accelerator.
C1 [Ji, Houxiang] Shanghai Jiao Tong Univ, Zhiyuan Coll, Shanghai, Peoples R China.
   [Ji, Houxiang; Jiang, Li] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Song, Linghao; Li, Ha (Haken); Chen, Yiran] Duke Univ, Dept Elect & Comp Engn, Durham, NC USA.
RP Jiang, L (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Chen, YR (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC USA.
EM jihouxiang@sjtu.edu.cn; linghao.song@duke.edu; ljiang_cs@sjtu.edu.cn;
   hai.li@duke.edu; yiran.chern@duke.edu
CR [Anonymous], 2018, HPCA
   [Anonymous], 1998, P IEEE
   [Anonymous], 2012, IEEE SIGNAL PROCESSI
   [Anonymous], 2017, HPCA
   [Anonymous], 2016, ISCA
   [Anonymous], 2009, PROC IEEE C COMPUT V
   [Anonymous], 2016, NIPS
   [Anonymous], 2016, ISCA
   [Anonymous], 2017, ADC PERFORMANCE SURV
   [Anonymous], 2016, ISCA
   [Anonymous], 2016, ISCA
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim D., 2017, DATE
   Krizhevsky A, 2012, NIPS, P1097
   Niu D., 2013, ICCAD
   Xu C., 2015, HPCA
NR 16
TC 44
Z9 47
U1 0
U2 5
PY 2018
BP 237
EP 240
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Huang, H
   Yang, J
   Rong, HJ
   Du, SY
AF Huang, Hui
   Yang, Jing
   Rong, Hai-Jun
   Du, Shaoyi
TI A generic FPGA-based hardware architecture for recursive least mean
   p-power extreme learning machine
SO NEUROCOMPUTING
DT Article
DE Field-programmable gate array (FPGA); On-chip machine learning; Generic
   architecture; Recursive least mean p-power extreme learning machine
   (RLMP-ELM)
ID EFFICIENT IMPLEMENTATION; ERROR CRITERION; NEURAL-NETWORK; ALGORITHM;
   ACCELERATOR
AB Recursive least mean p-power extreme learning machine (RLMP-ELM) is a newly proposed online machine learning algorithm and is able to provide a robust online prediction of the datasets with noises of different statistics. To further explore the proposed RLMP-ELM to be used in real-world embedded systems, a generic serial FPGA-based hardware architecture of RLMP-ELM is presented in this paper. The entire hardware architecture of RLMP-ELM includes three serial processing modules, which are implemented parameterizably and can be adapted for different application requirements. The hardware framework is in a serial fashion, but parallelization efforts are focused on the processes with high computing complexity by analysis of potential inter-task dependency. To overcome the limitation of memory bandwidth, the block RAM and ping-pong on-chip buffer are applied to improve the computational throughput. The validation experiments are performed through five datasets with different p values. Accuracy results show that our implementation on FPGA could achieve similar accuracy compared to 64-bit floating-point software implementation. We also report and compare hardware performance of our proposed architecture with other existing implementations. The results show that our hardware architecture offers the excellent balance among accuracy, logic occupation and hardware performance. (c) 2021 Published by Elsevier B.V.
C1 [Huang, Hui; Rong, Hai-Jun] Xi An Jiao Tong Univ, State Key Lab Strength & Vibrat Mech Struct, Shaanxi Key Lab Environm & Control Flight Vehicle, Sch Aerosp, Xian 710049, Shaanxi, Peoples R China.
   [Yang, Jing] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Inst Control Engn, Xian 710049, Shaanxi, Peoples R China.
   [Du, Shaoyi] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
RP Rong, HJ (corresponding author), Xi An Jiao Tong Univ, State Key Lab Strength & Vibrat Mech Struct, Shaanxi Key Lab Environm & Control Flight Vehicle, Sch Aerosp, Xian 710049, Shaanxi, Peoples R China.
EM hjrong@xjtu.edu.cn
CR [Anonymous], 2009, P ACMSIGDA INT S FIE
   Bjorck A., 1967, BIT, V7, P1, DOI [10.1007/BF01934122, DOI 10.1007/BF01934122]
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Deryabin M.A., NEUROCOMPUTING, V407
   Frances-Villora JV, 2016, COMPUT ELECTR ENG, V51, P139, DOI 10.1016/j.compeleceng.2016.02.007
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Golub G. H., 1996, MATRIX COMPUTATIONS
   Han JH, 2020, TSINGHUA SCI TECHNOL, V25, P479, DOI 10.26599/TST.2019.9010019
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jin JH, 2014, MIDWEST SYMP CIRCUIT, P133, DOI 10.1109/MWSCAS.2014.6908370
   Li SJ, 2017, NEUROCOMPUTING, V261, P153, DOI 10.1016/j.neucom.2016.05.112
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   MA Y, 2017, P ACM SIGDA INT S FP
   Mohammadi M, 2018, IEEE T PARALL DISTR, V29, P481, DOI 10.1109/TPDS.2017.2768366
   Ortega-Zamorano F, 2016, IEEE T NEUR NET LEAR, V27, P1840, DOI 10.1109/TNNLS.2015.2460991
   Patil A, 2017, NEUROCOMPUTING, V261, P193, DOI 10.1016/j.neucom.2016.09.118
   PEI SC, 1994, IEEE J SEL AREA COMM, V12, P1540, DOI 10.1109/49.339922
   Ragusa E, 2020, NEURAL PROCESS LETT, V51, P1611, DOI 10.1007/s11063-019-10165-y
   Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506
   Rosado A, 2012, IEEE I C ELECT CIRC, P41, DOI 10.1109/ICECS.2012.6463562
   Shah NH, 2020, INT J SYST SCI-OPER, V7, P34, DOI [10.1080/23302674.2018.1487606, 10.1109/TNNLS.2018.2815085]
   van Heeswijk M, 2011, NEUROCOMPUTING, V74, P2430, DOI 10.1016/j.neucom.2010.11.034
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xiao YG, 1999, IEEE T SIGNAL PROCES, V47, P1172, DOI 10.1109/78.752620
   Xie ZZ, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P221, DOI 10.1109/ICACI.2012.6463155
   Xu J., FIXED POINT EVALUATI
   Yang A, IEEE T COMPUT AID D
   Yang J, 2017, NEURAL NETWORKS, V91, P22, DOI 10.1016/j.neunet.2017.04.001
   Yang J, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016656591
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang GH, 2020, NEUROCOMPUTING, V382, P106, DOI 10.1016/j.neucom.2019.11.045
   ZHOU J, 2009, P INT WORKSH ADV PAR, P110
NR 35
TC 1
Z9 1
U1 3
U2 13
PD OCT 7
PY 2021
VL 456
BP 421
EP 435
DI 10.1016/j.neucom.2021.05.069
EA JUN 2021
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Lin, CJ
   Luo, Y
   Wang, LM
   Chen, LD
AF Lin, Chun-Jen
   Luo, Yan
   Wang, Liang-min
   Chen, Li-De
GP IEEE
TI Flow Scheduling in a Heterogeneous NFV Environment using Reinforcement
   Learning
SO 2021 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND
   STORAGE (NAS)
DT Proceedings Paper
CT 15th IEEE International Conference on Networking, Architecture and
   Storage (NAS)
CY OCT 24-26, 2021
CL Riverside, CA
DE Network Function Virtualization; Virtual Network Function; Scheduling;
   Reinforcement Learning
AB Network function virtualization (NFV) allows network functions executed on general-purpose servers or virtual machines (VMs) instead of proprietary hardware, greatly improving the flexibility and scalability of network services. Recent trends in using programmable accelerators to speed up NFV performance introduce challenges in flow scheduling in a dynamic NFV environment. Reinforcement learning (RL) trains machine learning models for decision making to maximize returns in uncertain environments such as NFV. In this paper, we study the allocation of heterogeneous processors (CPUs and FPGAs) to minimize the delays of flows in the system. We conduct extensive simulations to evaluate the performance of reinforcement learning based scheduling algorithms such as Advantage Actor Critic (A2C), Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO), and compare with greedy policies. The results show that RL based schedulers can effectively learn from past experiences and converge to the optimal greedy policy. We also analyze in-depth how the policies lead to different processor utilization and flow processing time, and provide insights into these policies.
C1 [Lin, Chun-Jen; Luo, Yan] Univ Massachusetts, Dept Elect & Comp Engn, Lowell, MA 01854 USA.
   [Wang, Liang-min; Chen, Li-De] Intel Corp, Santa Clara, CA 95051 USA.
RP Lin, CJ (corresponding author), Univ Massachusetts, Dept Elect & Comp Engn, Lowell, MA 01854 USA.
CR DALEY DJ, 1987, STOCH PROC APPL, V25, P301, DOI 10.1016/0304-4149(87)90208-0
   Dhakal A, 2019, PROCEEDINGS OF THE 2019 IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2019), P396, DOI [10.1109/NETSOFT.2019.8806698, 10.1109/netsoft.2019.8806698]
   Fei XC, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3397022
   Harchol-Balter M, 2010, PROBAB ENG INFORM SC, V24, P219, DOI 10.1017/S0269964809990246
   Hill A., 2018, GITHUB REPOSITORY
   Li XY, 2018, INT CON DISTR COMP S, P1, DOI 10.1109/ICDCS.2018.00011
   Mao HZ, 2019, ADV NEUR IN, V32
   Mao HZ, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P270, DOI 10.1145/3341302.3342080
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '16), P50, DOI 10.1145/3005745.3005750
   Mao Hongzi, 2018, ARXIV181001963
   Mijumbi R, 2016, IEEE COMMUN SURV TUT, V18, P236, DOI 10.1109/COMST.2015.2477041
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Schulman J., 2017, ARXIV, DOI DOI 10.1016/J.JDEVECO.2016.04.001
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Shao SJ, 2018, IEEE INT CONF ASAP, P135
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Suo J, 2016, 2016 21ST OPTOELECTRONICS AND COMMUNICATIONS CONFERENCE (OECC) HELD JOINTLY WITH 2016 INTERNATIONAL CONFERENCE ON PHOTONICS IN SWITCHING (PS)
   Volodymyr Mnih, 2013, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1312.5602
   Watanabe Y, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P136, DOI 10.1109/FPT.2017.8280131
   Xiao YK, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329056
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 259
EP 266
DI 10.1109/NAS51552.2021.9605395
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Telecommunications
DA 2023-11-11
ER

PT C
AU Metz, CA
   Goli, M
   Drechsler, R
AF Metz, Christopher A.
   Goli, Mehran
   Drechsler, Rolf
GP Assoc Comp Machinery
TI Towards Neural Hardware Search: Power Estimation of CNNs for GPGPUs with
   Dynamic Frequency Scaling
SO MLCAD '22: PROCEEDINGS OF THE 2022 ACM/IEEE 4TH WORKSHOP ON MACHINE
   LEARNING FOR CAD (MLCAD)
DT Proceedings Paper
CT 4th ACM/IEEE Workshop on Machine Learning for CAD (MLCAD)
CY SEP 12-13, 2022
CL Snowbird, UT
DE Machine Learning; Power Estimation; Neural Hardware Search; CNN; GPGPU
AB Machine Learning (ML) algorithms are essential for emerging technologies such as autonomous driving and application-specific Internet of Things (IoT) devices. Convolutional Neural Network (CNN) is one of the major techniques used in such systems. This leads to leveraging ML accelerators like GPGPUs to meet the design constraints. However, GPGPUs have high power consumption, and selecting the most appropriate accelerator requires Design Space Exploration (DSE), which is usually time-consuming and needs high manual effort. Neural Hardware Search (NHS) is an upcoming approach to automate the DSE for Neural Networks. Therefore, automatic approaches for power, performance, and memory estimations are needed.
   In this paper, we present a novel approach, enabling designers to fast and accurately estimate the power consumption of CNNs inferencing on GPGPUs with Dynamic Frequency Scaling (DFS) in the early stages of the design process. The proposed approach uses static analysis for feature extraction and Random Forest Tree regression analysis for predictive model generation. Experimental results demonstrate that our approach can predict the CNNs power consumption with a Mean Absolute Percentage Error (MAPE) of 5.03% compared to the actual hardware.
C1 [Metz, Christopher A.] Univ Bremen, Inst Comp Sci, Bremen, Germany.
   [Goli, Mehran; Drechsler, Rolf] Univ Bremen, DFKI GmbH, Inst Comp Sci, Bremen, Germany.
RP Metz, CA (corresponding author), Univ Bremen, Inst Comp Sci, Bremen, Germany.
EM cmetz@uni-bremen.de; mehran@uni-bremen.de; drechsler@uni-bremen.de
CR Abe Yuki, 2012, USENIX 2012 WORKSHOP, V12
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Busia P, 2021, IEEE ACCESS, V9, P133289, DOI 10.1109/ACCESS.2021.3115243
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Dutta B, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P240, DOI 10.1145/3203217.3203273
   Fingeroff M., 2021, MENTOR A SIEMENS BUS
   Foertter Fernanda, 2018, SUMMIT GPU SUPERCOMP
   gatech, 2013, GPU OC
   Goli M, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3388140
   Goli M, 2018, P IEEE RAP SYST PROT, P97, DOI 10.1109/RSP.2018.8631997
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Imandoust S.B., 2013, INT J ENG RES APPL, V3, P605, DOI DOI 10.1016/J.JTBI.2009.08.004
   Kim SW, 2021, IEEE NETWORK, V35, P177, DOI 10.1109/MNET.011.2000248
   Kohavi R., 2002, DATA MINING TASKS ME, P267, DOI 10.5555/778212.778254
   Mei XX, 2017, DIGIT COMMUN NETW, V3, P89, DOI 10.1016/j.dcan.2016.10.001
   Metz C. A., 2021, ARXIV
   Metz CA, 2022, IEEE INT SYMP DESIGN, P166, DOI 10.1109/DDECS54261.2022.9770153
   Metz CA, 2021, 2021 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS 2021), P29, DOI 10.1145/3478684.3479255
   Nvidia, 2016, NVID SMI
   Nvidia, 2022, PROF US GUID
   ONNX Community, 2019, ONNX
   Wang Q, 2020, IEEE T PARALL DISTR, V31, P2865, DOI 10.1109/TPDS.2020.3004623
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
NR 24
TC 1
Z9 1
U1 1
U2 1
PY 2022
BP 103
EP 109
DI 10.1145/3551901.3556481
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Boroumand, S
   Afshar, HP
   Brisk, P
   Mohammadi, S
AF Boroumand, Sina
   Afshar, Hadi P.
   Brisk, Philip
   Mohammadi, Siamak
GP IEEE
TI Exploration of Approximate Multipliers Design Space using Carry
   Propagation Free Compressors
SO 2018 23RD ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 22-25, 2018
CL Jeju, SOUTH KOREA
DE Approximate computation; Multiplier; Adder; Machine Learning
AB Many emerging application domains, such as machine learning, can tolerate limited amounts of arithmetic inaccuracy. When designing custom compute accelerators for these domains, hardware designers can explore tradeoffs that sacrifice accuracy in order to reduce area, delay, and/or power consumption. This paper explores the design space of approximate multipliers using a family of approximate compressors as building blocks for the partial product reduction tree. We present a tool that allows the user to specify an allowable level of error tolerance, and returns the minimum area, delay, or power approximate multiplier that provides that level of accuracy. Our experimental results indicate that our proposed compressors generate more accurate and more efficient approximate multipliers than existing state-of-the-art techniques.
C1 [Boroumand, Sina; Mohammadi, Siamak] Univ Tehran, Tehran, Iran.
   [Afshar, Hadi P.] Qualcomm Res, San Diego, CA USA.
   [Brisk, Philip] Univ Calif Riverside, Riverside, CA 92521 USA.
RP Boroumand, S (corresponding author), Univ Tehran, Tehran, Iran.
EM s_boroumand@ut.ac.ir; hpafshar@qti.qualcomm.com; philip@cs.ucr.edu;
   smohamadi@ut.ac.ir
CR [Anonymous], P 53 ANN DES AUT C N
   [Anonymous], 2011, P DATE
   [Anonymous], 2014, P C DES AUT TEST EUR
   Hrbacek Radek, 2016, 2016 International Conference on Design and Technology of Integrated Systems in Nanoscale Era (DTIS), P1, DOI 10.1109/DTIS.2016.7483885
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Lin CH, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P33, DOI 10.1109/ICCD.2013.6657022
   Liu Y, 2010, IEEE T VLSI SYST, V18, P517, DOI 10.1109/TVLSI.2009.2012863
   Momeni A, 2015, IEEE T COMPUT, V64, P984, DOI 10.1109/TC.2014.2308214
   Petra N, 2010, IEEE T CIRCUITS-I, V57, P1312, DOI 10.1109/TCSI.2009.2033536
   Qiqieh I, 2017, DES AUT TEST EUROPE, P7, DOI 10.23919/DATE.2017.7926950
   Stine JE, 2003, EUROMICRO SYMPOSIUM ON DIGITAL SYSTEM DESIGN, PROCEEDINGS, P112, DOI 10.1109/DSD.2003.1231908
   Venkatachalam S., 2017, IEEE T VERY LARGE SC
   Venkataramani S, 2012, DES AUT CON, P796
   Yang ZX, 2015, INT SYM DEFEC FAU TO, P183, DOI 10.1109/DFT.2015.7315159
NR 16
TC 3
Z9 3
U1 0
U2 1
PY 2018
BP 611
EP 616
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ricci, S
   Mannocci, P
   Farronato, M
   Hashemkhani, S
   Ielmini, D
AF Ricci, Saverio
   Mannocci, Piergiulio
   Farronato, Matteo
   Hashemkhani, Shahin
   Ielmini, Daniele
TI Forming-Free Resistive Switching Memory Crosspoint Arrays for In-Memory
   Machine Learning
SO ADVANCED INTELLIGENT SYSTEMS
DT Article
DE forming; in-memory computing; matrix-vector multiplication; principal
   component analysis; resistive switching memory
AB In-memory computing (IMC) with crosspoint arrays of resistive switching memory (RRAM) has gained wide attention for accelerating machine learning, data analysis, and deep neural networks. By IMC, matrix-vector multiplication (MVM) can be executed in the crosspoint array in just one step, thus accelerating a broad range of tasks in machine learning and data analytics. However, a key issue for RRAM crosspoint arrays is the forming operation of the memories which limits the stability and accuracy of the conductance state in the memory device. In this work, a hardware implementation of crosspoint array of forming-free devices for fast, energy-efficient accelerators of MVM is reported. RRAM devices with a 1.5 nm-thick HfO2 layer show an initial low resistance without forming and an analogue-mode programming behavior for high-accuracy IMC. Accurate hardware MVM is demonstrated by experimental eigenvalue/eigenvector calculation according to the power-iteration algorithm, with a fast convergence within about ten iterations to the correct solution. Deflation technique and principal component analysis (PCA) enable the classification of the Iris dataset with 98% accuracy compared with floating-point implementation. These results support forming-free crosspoint arrays for accelerating advanced machine learning with IMC.
C1 [Ricci, Saverio; Mannocci, Piergiulio; Farronato, Matteo; Hashemkhani, Shahin; Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn DEIB, Piazza L da Vinci 32, I-20133 Milan, Italy.
   [Ricci, Saverio; Mannocci, Piergiulio; Farronato, Matteo; Hashemkhani, Shahin; Ielmini, Daniele] IUNET, Piazza L da Vinci 32, I-20133 Milan, Italy.
RP Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn DEIB, Piazza L da Vinci 32, I-20133 Milan, Italy.; Ielmini, D (corresponding author), IUNET, Piazza L da Vinci 32, I-20133 Milan, Italy.
EM daniele.ielmini@polimi.it
CR [Anonymous], 2016, 2016 IEEE INT EL DEV
   Bishop C.M., 2016, PATTERN RECOGN, P205
   Chen SC, 2022, ADV MATER, V34, DOI 10.1002/adma.202105022
   Farronato M, 2022, ADV ELECTRON MATER, V8, DOI 10.1002/aelm.202101161
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hubbard WA, 2015, NANO LETT, V15, P3983, DOI 10.1021/acs.nanolett.5b00901
   Hui F, 2017, ADV ELECTRON MATER, V3, DOI 10.1002/aelm.201600195
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Jolliffe I. T., 2002, PRINCIPAL COMPONENTS
   Kang H., 2021, NEUROMORPH COMPUT EN, V1, P021001, DOI [10.1088/2634-4386/ac29ca, DOI 10.1088/2634-4386/AC29CA]
   Kim H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25455-0
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li YS, 2021, ADV INTELL SYST-GER, V3, DOI 10.1002/aisy.202000137
   Lv HB, 2015, SCI REP-UK, V5, DOI 10.1038/srep07764
   Mannocci P, 2022, IEEE NANOTECHNOL MAG, V16, P4, DOI 10.1109/MNANO.2022.3141515
   Martens H, 2001, MULTIVARIATE ANAL QU
   Milano G, 2022, NAT MATER, V21, P195, DOI 10.1038/s41563-021-01099-9
   Milo V, 2021, IEEE T ELECTRON DEV, V68, P3832, DOI 10.1109/TED.2021.3089995
   Pedretti G, 2021, IEEE T ELECTRON DEV, V68, P4373, DOI 10.1109/TED.2021.3095433
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Qi MQ, 2019, J NANOMATER, V2019, DOI 10.1155/2019/6724018
   Raghavan N., 2013, APPL PHYS LETT
   Sharath SU, 2014, APPL PHYS LETT, V104, DOI 10.1063/1.4864653
   Skaja K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28992-9
   Sun W, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11411-6
   Tominov RV, 2022, NANOMATERIALS-BASEL, V12, DOI 10.3390/nano12030455
   Valov I, 2014, CHEMELECTROCHEM, V1, P26, DOI 10.1002/celc.201300165
   Wang C, 2018, MICROELECTRON ENG, V187, P121, DOI 10.1016/j.mee.2017.11.003
   Wang C, 2021, NAT NANOTECHNOL, V16, P1079, DOI 10.1038/s41565-021-00943-y
   Wang JR, 2019, ADV MATER TECHNOL-US, V4, DOI 10.1002/admt.201800544
   Wang T., 2021, NANOSCALE HORIZ, V4, P1293
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xu C, 2011, DES AUT TEST EUROPE, P734
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang K, 2022, SMALL SCI, V2, DOI 10.1002/smsc.202100049
   Yao CY, 2019, RSC ADV, V9, P12615, DOI 10.1039/c9ra01121h
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
NR 38
TC 7
Z9 7
U1 3
U2 28
PD AUG
PY 2022
VL 4
IS 8
SI SI
AR 2200053
DI 10.1002/aisy.202200053
EA MAY 2022
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
DA 2023-11-11
ER

PT C
AU Noronha, DH
   Que, ZQ
   Luk, W
   Wilton, SJE
AF Noronha, Daniel Holanda
   Que, Zhiqiang
   Luk, Wayne
   Wilton, Steven J. E.
GP IEEE Comp Soc
TI Flexible Instrumentation for Live On-Chip Debug of Machine Learning
   Training on FPGAs
SO 2021 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2021)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 29th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 09-12, 2021
CL ELECTR NETWORK
AB FPGAs have recently shown promise for accelerating machine learning training. This has led to research into the co-design of narrow-precision accelerator architectures and the investigation of novel machine learning models. Such research can be extremely expensive, as the steep cost of training a model can increase several-fold due to the need of performing hyperparameter tuning and adjustments to the model to ensure acceptable convergence speed and accuracy. In this scenario, monitoring key data on-chip is essential to more quickly understand and diagnose problems, significantly reducing training costs.
   Previous work has proposed on-chip debug instrumentation to monitor key signals for both general-purpose circuits and inference algorithms. This instrumentation either performs limited on-chip compression, or is extremely restricted in the amount of run-time customization that may occur. We argue that for training applications, the extremely long and expensive training runs warrant significantly more flexibility in the on-chip instrumentation, even at the expense of some chip area.
   In this paper, we propose flexible debug instrumentation that allows for the live debugging of machine learning systems during training. Different from previous debug instrumentation, our instrumentation offers firmware programmability, allowing the researcher to gather data in a large variety of ways that would likely not be anticipated at compile time.
C1 [Noronha, Daniel Holanda; Wilton, Steven J. E.] Univ British Columbia, Vancouver, BC, Canada.
   [Que, Zhiqiang; Luk, Wayne] Imperial Coll London, London, England.
RP Noronha, DH (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM danielhn@ece.ubc.ca; z.que@imperial.ac.uk; w.luk@imperial.ac.uk;
   stevew@ece.ubc.ca
CR Amazon, AM EC2 F1 INST EN FA AM EC2 F1 INST EN FA
   [Anonymous], 1984, SOFTWARE SYSTEM TEST
   [Anonymous], 2015, 32 INT C MACHINE LEA
   Baidu, FPGA CLOUD SERV FPGA CLOUD SERV
   Brown T.B., 2020, P 34 INT C NEUR INF
   Burger D. C., 2020, U.S. Patent, Patent No. [20200265301A1, 20200265301]
   Cai Shanqing, 2016, P REL MACH LEARN WIL
   Denolf K., 2019, U.S. Patent US, Patent No. [20190057305A1, 20190057305]
   Denolf K., 2020, WIPO Patent WO, Patent No. [2020068437A1, 2020068437]
   Drumond M., 2018, ABS180401526
   Drumond Mario, 2018, P 32 INT C NEURAL IN, P451
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Fox S, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P85, DOI 10.1109/FPT.2016.7929193
   Geng T, 2018, I C FIELD PROG LOGIC, P394, DOI 10.1109/FPL.2018.00074
   Hale R, 2018, I C FIELD PROG LOGIC, P81, DOI 10.1109/FPL.2018.00022
   Intel, 2015, QUART PRIM PROED HDB QUART PRIM PROED HDB, V3
   Islam MJ, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P510, DOI 10.1145/3338906.3338955
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Li C, 2020, LAMBDA
   Lo D., 2020, U.S. Patent, Patent No. [20200264876A1, 20200264876]
   Noronha DH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P110, DOI 10.1145/3289602.3293922
   Noronha DH, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P135, DOI 10.1109/ICFPT47387.2019.00024
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Putnam A, 2015, IEEE MICRO, V35, P10, DOI 10.1109/MM.2015.42
   Rouhani B. D., 2020, P NEURIPS, P1
   Santurkar S., 2019, DOES BATCH NORMALIZA
   Shah S, 2019, PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS (EICS'19), DOI 10.1145/3319499.3328231
   Venkataramanaiah SK, 2019, I C FIELD PROG LOGIC, P166, DOI 10.1109/FPL.2019.00034
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Wiggers K., 2020, OPENAI LAUNCHES API
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xilinx, 2012, CHIPSCOPE PROS COR U CHIPSCOPE PROS COR U
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhang J., 2018, MANIFOLD MODEL AGNOS
   Zhao WL, 2016, IEEE INT CONF ASAP, P107, DOI 10.1109/ASAP.2016.7760779
NR 35
TC 2
Z9 2
U1 0
U2 1
PY 2021
BP 20
EP 28
DI 10.1109/FCCM51124.2021.00011
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Tracy, T
   Fu, Y
   Roy, I
   Jonas, E
   Glendenning, P
AF Tracy, Tommy, II
   Fu, Yao
   Roy, Indranil
   Jonas, Eric
   Glendenning, Paul
BE Kunkel, JM
   Balaji, P
   Dongarra, J
TI Towards Machine Learning on the Automata Processor
SO HIGH PERFORMANCE COMPUTING
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 31st International Conference on ISC High Performance
CY JUN 19-23, 2016
CL Frankfurt, GERMANY
DE Automata processor; Machine learning; Random forest
AB A variety of applications employ ensemble learning models, using a collection of decision trees, to quickly and accurately classify an input based on its vector of features. In this paper, we discuss the implementation of such a method, namely Random Forests, as the first machine learning algorithm to be executed on the Automata Processor (AP). The AP is an upcoming reconfigurable co-processor accelerator which supports the execution of numerous automata in parallel against a single input data-flow. Owing to this execution model, our approach is fundamentally different, translating Random Forest models from existing memory-bound tree-traversal algorithms to pipelined designs that use multiple automata to check all of the required thresholds independently and in parallel. We also describe techniques to handle floating-point feature values which are not supported in the native hardware, pipelining of the execution stages, and compression of automata for the fastest execution times. The net result is a solution which when evaluated using two applications, namely handwritten digit recognition and sentiment analysis, produce up to 63 and 93 times speed-up respectively over single-core state-of-the-art CPU-based solutions. We foresee these algorithmic techniques to be useful not only in the acceleration of other applications employing Random Forests, but also in the implementation of other machine learning methods on this novel architecture.
C1 [Tracy, Tommy, II] Univ Virginia, Charlottesville, VA 22903 USA.
   [Fu, Yao; Glendenning, Paul] Micron Technol Inc, Milpitas, CA USA.
   [Roy, Indranil] Micron Technol Inc, Boise, ID USA.
   [Jonas, Eric] Univ Calif Berkeley, Berkeley, CA 94720 USA.
RP Tracy, T (corresponding author), Univ Virginia, Charlottesville, VA 22903 USA.
EM tjt7a@virginia.edu; alfu@micron.com; iroy@micron.com;
   jonas@ericjonas.com; pglendenning@micron.com
CR Asadi N, 2014, IEEE T KNOWL DATA EN, V26, P2281, DOI 10.1109/TKDE.2013.73
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1501/0000000035, 10.1561/0600000035]
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lucchese C, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P73, DOI 10.1145/2766462.2767733
   Ozuysal M, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383123
   Prenger R., 2013, TECHNICAL REPORT
   Qi YJ, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P307, DOI 10.1007/978-1-4419-9326-7_11
   Roy I., 2015, THESIS
   Roy I, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.51
   Stan J., 2015, CS201506 U VIRG
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Wang K., 2015, IPDPS 2015
   Windeatt T, 2002, LECT NOTES COMPUT SC, V2364, P42
   Zhang K, 2011, INT C PAR DISTRIB SY, P188, DOI 10.1109/ICPADS.2011.37
   Zhou K, 2015, IEEE INT C SEMANT CO, P236, DOI 10.1109/ICOSC.2015.7050812
NR 18
TC 30
Z9 30
U1 0
U2 0
PY 2016
VL 9697
BP 200
EP 218
DI 10.1007/978-3-319-41321-1_11
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Özeloglu, A
   Gürbüz, IG
   San, IS
AF Ozeloglu, Alican
   Gurbuz, Ismihan Gul
   San, Ismail
TI Deep reinforcement learning-based autonomous parking design with neural
   network compute accelerators
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE autonomous parking; dataflow; Deep Q-Learning; FPGA; high-level
   synthesis; neural network accelerator; System-on-Chip
ID ARCHITECTURE
AB We describe the design and implementation of an autonomous prototype vehicle which finds an empty parking slot in a parking area, and parks itself in the empty parking slot, using neural networks based on deep reinforcement learning (RL). To perform an autonomous parking procedure for our prototype vehicle, two different artificial neural networks (ANNs) are trained using a deep RL Algorithm in a simulation environment and embedded into the computing platform of the prototype car. One of the ANNs enables the vehicle to drive autonomously in the parking environment. At the same time, an image processing algorithm is used to determine whether a parking slot is empty. When the image processing algorithm finds a suitable parking slot, a different ANN is activated and performs a safe parking procedure. However, ANN-based machine learning techniques require high processing power and impose a high computational burden on embedded CPU and GPU platforms. To alleviate the computational burden, one can achieve higher performance and less power consumption using an application-specific hardware design, where logic resources are fully exploited according to the algorithm of interest, in an energy-efficient manner. In this article, hardware accelerators for our ANN models are designed and generated via the Vivado high-level synthesis (HLS) tool, targeting an ARM based programmable SoC platform, ZedBoard. Our ANN accelerators have achieved a speedup of 17x as compared to an ARM software implementation. For deeper fully-connected layers used in deep RL-based solutions, function-level parallelism (Vivado's dataflow) is employed to improve the computational efficiency. Our proposed stage-level description for fully connected layers outperforms recent studies in terms of computation time.
C1 [Ozeloglu, Alican; Gurbuz, Ismihan Gul; San, Ismail] Eskisehir Tech Univ, Dept Elect & Elect Engn, Eskisehir, Turkey.
RP San, IS (corresponding author), Eskisehir Tech Univ, Dept Elect & Elect Engn, Eskisehir, Turkey.
EM isan@eskisehir.edu.tr
CR Ardakani A., 2016, ARXIV PREPRINT ARXIV
   Baktir AB., 2020, P 2020 INT C EL COMM, P1, DOI DOI 10.1109/ICECCE49384.2020.9179399
   Cho WS., 2017, ARXIV PREPRINT ARXIV
   Fayjie AR, 2018, INT CONF UBIQ ROBOT, P896
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Ioannou L, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P355, DOI 10.1109/ICFPT47387.2019.00066
   Kahn G., 1974, IFIP 74 N HOLLAND, P471
   Kaur, 2013, ARXIV PREPRINT ARXIV
   Min K, 2018, IEEE INT VEH SYM, P226, DOI 10.1109/IVS.2018.8500645
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mohanty PK, 2017, INT CONF COMPUT INT, P88, DOI 10.1109/CINE.2017.11
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Ortega-Zamorano F, 2016, IEEE T NEUR NET LEAR, V27, P1840, DOI 10.1109/TNNLS.2015.2460991
   Paidi V, 2020, IET INTELL TRANSP SY, V14, P1295, DOI 10.1049/iet-its.2019.0468
   Qasaimeh M, 2019, IEEE I C EMBED SOFTW, DOI 10.1109/icess.2019.8782524
   Qiao YR, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3850
   Scicluna N, 2012, IEEE I C ELECT CIRC, P229, DOI 10.1109/ICECS.2012.6463759
   Shang L., 2002, FPGA 2002. Tenth ACM International Symposium on Field-Programmable Gate Arrays, P157, DOI 10.1145/503048.503072
   Stitt G., 2004, ACM T EMBED COMPUT S, V3, P218
   Teich J, 2012, P IEEE, V100, P1411, DOI 10.1109/JPROC.2011.2182009
   Huynh TV, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P254, DOI 10.1109/NAFOSTED.2017.8108073
   Thies W, 2002, LECT NOTES COMPUT SC, V2304, P179
   ┬u├╗zeloglu A., 2020, P 2020 UL YUKS BAS H, P1
   Varadharajan SK, 2017, 2017 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P245, DOI 10.1109/ICEDSS.2017.8073688
   VERMA G, 2015, INDIAN J SCI TECHNOL, V8, pNI411
   Vosandi L., 2014, PIPING OV7670 VIDEO
   Wang C, 2017, IEEE T PARALL DISTR, V28, P2993, DOI 10.1109/TPDS.2017.2701828
   Wang Y, 2018, IEEE T PARALL DISTR, V29, P1428, DOI 10.1109/TPDS.2018.2791440
   Wang Y, 2017, ACM SIGPLAN NOTICES, V52, P81, DOI [10.1145/3078633.3081032, 10.1145/3140582.3081032]
   Wei ZP, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON AGENTS (ICA), P20, DOI 10.1109/AGENTS.2018.8460004
   Zaman KS, 2022, IEEE T NEUR NET LEAR, V33, P6068, DOI 10.1109/TNNLS.2021.3082304
   Zhai XJ, 2016, IEEE ACCESS, V4, P8138, DOI 10.1109/ACCESS.2016.2619181
NR 34
TC 1
Z9 1
U1 5
U2 30
PD APR 25
PY 2022
VL 34
IS 9
SI SI
AR e6670
DI 10.1002/cpe.6670
EA NOV 2021
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Lin, JP
   Qian, Q
   Murphy, J
   Hsu, A
   Hero, A
   Ma, Y
   Thomas, AGR
   Krushelnick, K
AF Lin, Jinpu
   Qian, Qian
   Murphy, Jon
   Hsu, Abigail
   Hero, Alfred
   Ma, Yong
   Thomas, Alexander G. R.
   Krushelnick, Karl
TI Beyond optimization-supervised learning applications in relativistic
   laser-plasma experiments
SO PHYSICS OF PLASMAS
DT Article
ID ELECTRON ACCELERATION; DRIVEN; FILAMENTATION; ENHANCEMENT; PHYSICS;
   BEAMS
AB We explore the applications of a variety of machine learning techniques in relativistic laser-plasma experiments beyond optimization purposes. With the trained supervised learning models, the beam charge of electrons produced in a laser wakefield accelerator is predicted given the laser wavefront change caused by a deformable mirror. Feature importance analysis using the trained models shows that specific aberrations in the laser wavefront are favored in generating higher beam charges, which reveals more information than the genetic algorithms and the statistical correlation do. The predictive models enable operations beyond merely searching for an optimal beam charge. The quality of the measured data is characterized, and anomaly detection is demonstrated. The model robustness against measurement errors is examined by applying a range of virtual measurement error bars to the experimental data. This work demonstrates a route to machine learning applications in a highly nonlinear problem of relativistic laser-plasma interaction for in-depth data analysis to assist physics interpretation. Published under an exclusive license by AIP Publishing.
C1 [Lin, Jinpu; Qian, Qian; Murphy, Jon; Ma, Yong; Thomas, Alexander G. R.; Krushelnick, Karl] Univ Michigan, Gerard Mourou Ctr Ultrafast Opt Sci, Ann Arbor, MI 48109 USA.
   [Hsu, Abigail] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
   [Hero, Alfred] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
RP Lin, JP (corresponding author), Univ Michigan, Gerard Mourou Ctr Ultrafast Opt Sci, Ann Arbor, MI 48109 USA.
EM linjinp@umich.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Albert F, 2016, PLASMA PHYS CONTR F, V58, DOI 10.1088/0741-3335/58/10/103001
   Born M., 1980, PRINCIPLES OPTICS EL, V6th
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bussolino GC, 2013, J PHYS D APPL PHYS, V46, DOI 10.1088/0022-3727/46/24/245501
   Camporeale E, 2017, J GEOPHYS RES-SPACE, V122, P10910, DOI 10.1002/2017JA024383
   Chen Y, 2019, SPACE WEATHER, V17, P1404, DOI 10.1029/2019SW002214
   Chollet F., 2015, KERAS
   Dann SJD, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.041303
   Dergachev AA, 2014, QUANTUM ELECTRON+, V44, P1085, DOI 10.1070/QE2014v044n12ABEH015472
   Döpp A, 2016, NUCL INSTRUM METH A, V830, P515, DOI 10.1016/j.nima.2016.01.086
   Englesbe AC, 2016, OPT EXPRESS, V24, P6071, DOI 10.1364/OE.24.006071
   Esarey E, 2009, REV MOD PHYS, V81, P1229, DOI 10.1103/RevModPhys.81.1229
   Faure J, 2004, NATURE, V431, P541, DOI 10.1038/nature02963
   Feister S., 2019, ARXIV190611777
   Fibich G, 2004, OPT LETT, V29, P1772, DOI 10.1364/OL.29.001772
   Finney LA, 2021, OPT COMMUN, V490, DOI 10.1016/j.optcom.2021.126902
   Gaffney JA, 2019, PHYS PLASMAS, V26, DOI 10.1063/1.5108667
   Geddes CGR, 2004, NATURE, V431, P538, DOI 10.1038/nature02900
   Gonoskov A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43465-3
   Gonsalves AJ, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.084801
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guénot D, 2017, NAT PHOTONICS, V11, P293, DOI [10.1038/NPHOTON.2017.46, 10.1038/nphoton.2017.46]
   Hah J, 2017, OPT EXPRESS, V25, P17271, DOI 10.1364/OE.25.017271
   Hatfield P, 2020, IEEE T PLASMA SCI, V48, P14, DOI 10.1109/TPS.2019.2944416
   Hatfield PW, 2021, NATURE, V593, P351, DOI 10.1038/s41586-021-03382-w
   He ZH, 2016, SCI REP-UK, V6, DOI 10.1038/srep36224
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   He ZH, 2013, NEW J PHYS, V15, DOI 10.1088/1367-2630/15/5/053016
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Hsu A, 2020, PHYS PLASMAS, V27, DOI 10.1063/1.5130585
   Humbird KD, 2020, IEEE T PLASMA SCI, V48, P61, DOI 10.1109/TPS.2019.2955098
   Humbird KD, 2019, STAT ANAL DATA MIN, V12, P496, DOI 10.1002/sam.11435
   Humbird KD, 2019, IEEE T NEUR NET LEAR, V30, P1286, DOI 10.1109/TNNLS.2018.2869694
   Jiao ZB, 2020, SPACE WEATHER, V18, DOI 10.1029/2020SW002440
   Kain V, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.124801
   Kim HT, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09267-1
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Lefebvre S, 2018, APPL PHYS B-LASERS O, V124, DOI 10.1007/s00340-018-7083-x
   Li LN, 2020, SPECTROCHIM ACTA B, V169, DOI 10.1016/j.sab.2020.105850
   Lin J, 2019, OPT EXPRESS, V27, P10912, DOI 10.1364/OE.27.010912
   Lin JP, 2018, OPT COMMUN, V421, P79, DOI 10.1016/j.optcom.2018.03.075
   Liu C, 2014, OPT LETT, V39, P80, DOI 10.1364/OL.39.000080
   lopusz, 2019, AWESOME INTERPRETABL, DOI DOI 10.1007/978-3-030-65965-3_28
   Lu W, 2007, PHYS REV SPEC TOP-AC, V10, DOI 10.1103/PhysRevSTAB.10.061301
   Maier AR, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.031039
   Malka V., 2002, Science, V298, P1596, DOI 10.1126/science.1076782
   Mangles SPD, 2004, NATURE, V431, P535, DOI 10.1038/nature02939
   Milchberg H., 2019, WORKSH OPP CHALL BES
   Nayuki T, 2005, REV SCI INSTRUM, V76, DOI 10.1063/1.1942527
   Noaman-ul-Haq M, 2018, NUCL INSTRUM METH A, V883, P191, DOI 10.1016/j.nima.2017.11.075
   Piccione A, 2020, NUCL FUSION, V60, DOI 10.1088/1741-4326/ab7597
   Prencipe I, 2017, HIGH POWER LASER SCI, V5, DOI 10.1017/hpl.2017.18
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Rea C, 2018, PLASMA PHYS CONTR F, V60, DOI 10.1088/1361-6587/aac7fe
   Roso Luis, 2018, EPJ Web of Conferences, V167, DOI 10.1051/epjconf/201816701001
   Rovige L, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0040926
   Salehi F, 2017, OPT LETT, V42, P215, DOI 10.1364/OL.42.000215
   Salehi F., 2019, THESIS U MARYLAND
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Smith JR, 2020, NEW J PHYS, V22, DOI 10.1088/1367-2630/abbfce
   Streeter MJV, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5027297
   TAJIMA T, 1979, PHYS REV LETT, V43, P267, DOI 10.1103/PhysRevLett.43.267
   Tsai HE, 2018, PHYS PLASMAS, V25, DOI 10.1063/1.5023694
   Weinberger K., 2018, MACHINE LEARNING INT
   Wen M, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.214801
   Witman M, 2019, PLASMA SOURCES SCI T, V28, DOI 10.1088/1361-6595/ab3c15
NR 67
TC 7
Z9 9
U1 3
U2 15
PD AUG
PY 2021
VL 28
IS 8
AR 083102
DI 10.1063/5.0047940
WC Physics, Fluids & Plasmas
DA 2023-11-11
ER

PT C
AU Kawecka, A
   Brylinski, W
   Kuttan, MO
   Linnyk, O
   Pawlowski, J
   Schmidt, K
   Slodkowski, M
   Wyszynski, O
   Zielinski, J
AF Kawecka, Anna
   Brylinski, Wojciech
   Kuttan, Manjunath Omana
   Linnyk, Olena
   Pawlowski, Janik
   Schmidt, Katarzyna
   Slodkowski, Marcin
   Wyszynski, Oskar
   Zielinski, Jakub
GP IOP
TI NA61/SHINE online noise filtering using machine learning methods
SO 20TH INTERNATIONAL WORKSHOP ON ADVANCED COMPUTING AND ANALYSIS
   TECHNIQUES IN PHYSICS RESEARCH
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 20th International Workshop on Advanced Computing and Analysis
   Techniques in Physics Research (ACAT)
CY NOV 29-DEC 03, 2021
CL ELECTR NETWORK
AB The NA61/SHINE is a high-energy physics experiment operating at the SPS accelerator at CERN. The physics program of the experiment was recently extended, requiring a significant upgrade of the detector setup. The main goal of the upgrade is to increase the event flow rate from 80Hz to 1kHz by exchanging the read-out electronics of the NA61/SHINE main tracking detectors (Time-Projection-Chambers - TPCs). As the amount of collected data will increase significantly, a tool for online noise filtering is needed. The standard method is based on the reconstruction of tracks and removal of clusters which do not belong to any particle trajectory. However, this method takes a substantial amount of time and resources. A novel approach based on machine learning methods is presented in this proceedings.
C1 [Kawecka, Anna; Brylinski, Wojciech; Slodkowski, Marcin; Zielinski, Jakub] Warsaw Univ Technol, Warsaw, Poland.
   [Kawecka, Anna] Chalmers Univ Technol, Gothenburg, Sweden.
   [Kuttan, Manjunath Omana; Linnyk, Olena; Pawlowski, Janik] Frankfurt Inst Adv Studies, Frankfurt, Germany.
   [Kuttan, Manjunath Omana] Goethe Univ Frankfurt, Frankfurt, Germany.
   [Linnyk, Olena] Justus Liebig Univ Giessen, Giessen, Germany.
   [Linnyk, Olena] Milch & Zucker AG, Giessen, Germany.
   [Pawlowski, Janik] Philipps Univ Marburg, Marburg, Germany.
   [Schmidt, Katarzyna] Univ Silesia, Katowice, Poland.
   [Wyszynski, Oskar] Jan Kochanowski Univ Humanities & Sci, Kielce, Poland.
RP Kawecka, A (corresponding author), Warsaw Univ Technol, Warsaw, Poland.; Kawecka, A (corresponding author), Chalmers Univ Technol, Gothenburg, Sweden.
EM anna.kawecka@cern.ch
CR Abgrall N, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/06/P06005
   Chollet F., 2021, DEEP LEARNING PYTHON
   Jin T, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P835, DOI 10.1145/3297858.3304038
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Meier U, 2011, PROC INT CONF DOC, P1250, DOI 10.1109/ICDAR.2011.252
   Pawlowski J., CAUSALITY MOTI UNPUB
   Pawlowski J, CERNTHESIS2021041
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
NR 9
TC 0
Z9 0
U1 1
U2 1
PY 2023
VL 2438
AR 012104
DI 10.1088/1742-6596/2438/1/012104
WC Computer Science, Interdisciplinary Applications; Physics, Applied;
   Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Cagnotta, A
   Carnevali, F
   De Iorio, A
AF Cagnotta, Antimo
   Carnevali, Francesco
   De Iorio, Agostino
TI Machine Learning Applications for Jet Tagging in the CMS Experiment
SO APPLIED SCIENCES-BASEL
DT Review
DE experimental physics; machine learning; jet tagging; particle physics;
   LHC machine; CMS Experiment
AB The fundamental physics research at the frontier accessible by today's particle accelerators such as the CERN Large Hadron Collider pose unique challenges in terms of complexity and abundance of data to analyse. In this context, it is of paramount importance to develop algorithms capable of dealing with multivariate problems to enhance humans' ability to interpret data and ultimately increase the discovery potential of the experiments. Machine learning techniques therefore assume an increasingly important role in the experiments at the LHC. In this work, we give an overview of the latest developments in this field, with a particular focus on the algorithms developed and used within the CMS Collaboration. The review follows this structure: (1) Introduction presents the CMS Experiment at LHC and the most common methods used in particle physics; (2) Jet Flavour Tagging briefly describes the main algorithms used to reconstruct heavy-flavour jets; (3) Jet Substructure and Deep Tagging focuses on the identification of heavy-particle decay in boosted jets; (4) Analysis Applications gives examples of applying the algorithm in physics analyses; and (5) Conclusions summarises the state-of-the-art and gives indications for future studies.
C1 [Cagnotta, Antimo; Carnevali, Francesco; De Iorio, Agostino] Univ Napoli Federico II, Dipartimento Fis Ettore Pancini, Complesso Univ Monte S Angelo, I-80126 Naples, Italy.
   [Cagnotta, Antimo; Carnevali, Francesco; De Iorio, Agostino] Ist Nazl Fis Nucl, Sez Napoli, Complesso Univ Monte S Angelo, I-80126 Naples, Italy.
RP De Iorio, A (corresponding author), Univ Napoli Federico II, Dipartimento Fis Ettore Pancini, Complesso Univ Monte S Angelo, I-80126 Naples, Italy.; De Iorio, A (corresponding author), Ist Nazl Fis Nucl, Sez Napoli, Complesso Univ Monte S Angelo, I-80126 Naples, Italy.
EM agostino.deiorio@unina.it
CR Aad G, 2019, EUR PHYS J C, V79, DOI 10.1140/epjc/s10052-019-7450-8
   Aad G, 2012, PHYS LETT B, V716, P1, DOI 10.1016/j.physletb.2012.08.020
   ATLAS collaboration, 2017, ATLPHYSPUB2017003
   Bols E, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/12/P12012
   Cacciari M, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/04/063
   Chatrchyan S, 2012, PHYS LETT B, V716, P30, DOI 10.1016/j.physletb.2012.08.021
   Chatrchyan S, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/10/P10009
   Chatrchyan S, 2013, J INSTRUM, V8, DOI 10.1088/1748-0221/8/04/P04013
   Chatrchyan S, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/S08004
   Chen T., 2015, ARXIV
   Chollet F., 2015, KERAS
   CMS Collaboration, 2021, SEARCH W DEC VECT LI
   CMS Collaboration, 2021, SEARCH HIGGS BOS PAI
   CMS Collaboration, 2017, J INSTRUM, V12
   Dasgupta M, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP09(2013)029
   Evans L, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/S08001
   Feickert M., 2021, ARXIV
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guest D, 2018, ANNU REV NUCL PART S, V68, P161, DOI 10.1146/annurev-nucl-101917-021019
   He K., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.90
   Khachatryan V, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/02/P02014
   Khachatryan V, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/01/P01020
   Khachatryan V, 2015, J INSTRUM, V10, DOI 10.1088/1748-0221/10/08/P08010
   Khachatryan V, 2015, J INSTRUM, V10, DOI 10.1088/1748-0221/10/06/P06005
   Larkoski Andrew J., 2014, Journal of High Energy Physics, DOI 10.1007/JHEP05(2014)146
   Nair V, 2010, INT C MACH LEARN HAI, V27, P807
   Qu HL, 2020, PHYS REV D, V101, DOI 10.1103/PhysRevD.101.056019
   Sirunyan AM, 2021, PHYS LETT B, V820, DOI 10.1016/j.physletb.2021.136535
   Sirunyan AM, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/10/P10017
   Sirunyan AM, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/P06005
   Sirunyan AM, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/07/P07004
   Sirunyan AM, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/10/P10005
   Sirunyan AM, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/06/P06015
   Sirunyan AM, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/05/P05011
   Sirunyan AM, 2017, J HIGH ENERGY PHYS, P1, DOI [10.1007/JHEP08(2017)029, 10.1007/JHEP05(2017)029]
   Thaler J, 2011, J HIGH ENERGY PHYS, DOI 10.1007/JHEP03(2011)015
   The ATLAS Collaboration, 2016, BOOST HIGGS BB BOS I
   Tumasyan A, 2021, EUR PHYS J C, V81, DOI 10.1140/epjc/s10052-021-09721-5
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
NR 39
TC 0
Z9 0
U1 0
U2 1
PD OCT
PY 2022
VL 12
IS 20
AR 10574
DI 10.3390/app122010574
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT C
AU Li, XC
   Zhu, Y
   Sung, E
AF Li, XC
   Zhu, Y
   Sung, E
GP IEEE
TI Sequential bootstrapped support vector machines - A SVM accelerator
SO PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS
   (IJCNN), VOLS 1-5
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT IEEE International Joint Conference on Neural Networks (IJCNN 2005)
CY JUL 31-AUG 04, 2005
CL Montreal, CANADA
AB Support Vector Machine has obtained much success in machine learning. But it requires to solve a quadratic optimization(QP) problem so that its training time increases dramatically with the increase of training set. Hence, standard SVM with batch learning has difficulty in handling large scale problems. In this paper, we introduce a SVM accelerator, called Sequential Bootstrapped SVM (SeqSVM), to speed up the training of SVM. At the beginning, the SeqSVM trains a SVM classifier on a small part of all training samples and then keeps on selecting the so-called convex hull samples from the given large training set to retrain this SVM until all convex hull samples are selected. The key principle in our method is to help the SVM pick the convex hull sample that is wrongly classified by the current SVM and furthest from the current SVM solution. The convex hull sample, which disagrees most with the SVM solution, will fie on the convex hull of each class distribution and all support vectors lie on the convex hull in the case of linearly separable classes. Two difficulties have to be overcome. The first is that the SeqSVM's iterations will take too many if there are too many support vectors. The second is that when the class distributions are not separable, it is not easy to pick convex hull samples. In this paper, we show how these two difficulties are overcome. Experimental results on both artificial database and benchmark databases demonstrated the effectiveness of proposed algorithm to reduce the learning time of SVM on the whole training set.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Li, XC (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM xuchunli@pmail.ntu.edu.sg; eericsung@ntu.edu.sg
CR [Anonymous], P ADV NEUR INF PROC
   [Anonymous], P KDD 2001 KNOWL DIS
   [Anonymous], 1998, NEW YORK
   [Anonymous], 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   BALCZAR JL, 2001, P 12 INT C ALG LEARN, P119
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Herbich R, 2001, J MACH LEARN RES, V1, P245, DOI 10.1162/153244301753683717
   Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Mitchell T.M., 1997, MACH LEARN, V1
   Scholkopf B., 1999, ADV KERNAL METHODS S
   Shin H, 2003, LECT NOTES ARTIF INT, V2637, P376
   Tong S., 2001, THESIS
   WANG L, 2003, P IEEE INT C COMP VI
   Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477
NR 17
TC 4
Z9 4
U1 0
U2 0
PY 2005
BP 1437
EP 1442
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Liu, WC
   Liu, WY
   Ye, YC
   Lou, Q
   Xie, YY
   Jiang, L
AF Liu, Weichen
   Liu, Wenyang
   Ye, Yichen
   Lou, Qian
   Xie, Yiyuan
   Jiang, Lei
GP IEEE
TI HolyLight: A Nanophotonic Accelerator for Deep Learning in Data Centers
SO 2019 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 22nd Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 25-29, 2019
CL Florence, ITALY
DE Nanophotonic Computing; Convolutional Neural Network; Accelerator
AB Convolutional Neural Networks (CNNs) are widely adopted in object recognition, speech processing and machine translation, due to their extremely high inference accuracy. However, it is challenging to compute massive computationally expensive convolutions of deep CNNs on traditional CPUs and GPUs. Emerging Nanophotonic technology has been employed for on-chip data communication, because of its CMOS compatibility, high bandwidth and low power consumption. In this paper, we propose a nanophotonic accelerator, HolyLight, to boost the CNN inference throughput in datacenters. Instead of an all-photonic design, HolyLight performs convolutions by photonic integrated circuits, and process the other operations in CNNs by CMOS circuits for high inference accuracy. We first build HolyLight-M by microdisk-based matrix-vector multipliers. We find analog-todigital converters (ADCs) seriously limit its inference throughput per Watt. We further use microdisk-based adders and shifters to architect HolyLight-A without ADCs. Compared to the state-of-the-art ReRAM-based accelerator, HolyLight-A improves the CNN inference throughput per Watt by 13 x with trivial accuracy degradation.
C1 [Liu, Weichen] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Liu, Wenyang] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
   [Ye, Yichen; Xie, Yiyuan] Southwest Univ, Sch Elect & Informat Engn, Chongqing, Peoples R China.
   [Lou, Qian; Jiang, Lei] Indiana Univ Bloomington, Sch Informat Comp & Engn, Bloomington, IN USA.
RP Liu, WC (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM liu@ntu.edu.sg
CR [Anonymous], FPL
   Assefa S., 2010, OPTICS EXPRESS
   Chen S., 2015, J LIGHTWAVE TECHNOLO
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Ciregan D., 2012, CVPR
   Jiang LD, 2017, INT CONF MEAS, P102, DOI [10.1109/ICMTMA.2017.31, 10.1109/ICMTMA.2017.0032]
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin X., 2018, SCIENCE
   Lin Z., 2016, ICLR
   Murmann B., ADC PERFORMANCE POWE
   Raghavendra R, 2008, ACM SIGPLAN NOTICES, V43, P48, DOI 10.1145/1353536.1346289
   Sampson A., FODLAM 1 ORDER DEEP
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Simard PY, 2003, PROC INT CONF DOC, P958
   Tait A. N., 2017, SCI REPORTS
   Wang J, 2011, PROGRESS ON POST-GENOME TECHNOLOGIES AND MODERN NATURAL PRODUCTS, 2011, P27
   Yang L., 2013, SPIE
   Yang R, 2012, OPT EXPRESS, V20, DOI 10.1364/OE.20.009341
   Ye Y., 2009, 3DIC
   Ying Z., 2018, IEEE J SELECTED TOPI
   Ying Z., 2018, OPTICS LETT, V43
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao Z., 2017, ASICON
   Zhou  A., 2017, ARXIV170203044
NR 29
TC 46
Z9 49
U1 1
U2 12
PY 2019
BP 1483
EP 1488
DI 10.23919/date.2019.8715195
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Hori, S
   Tamukoh, H
AF Hori, Sansei
   Tamukoh, Hakaru
BE Sugisaka, M
   Jia, Y
   Ito, T
   Lee, JJ
TI A Hardware-Oriented Random Number Generation Method and A Verification
   System for FPGA
SO PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON ARTIFICIAL LIFE AND
   ROBOTICS (ICAROB 2021)
DT Proceedings Paper
CT 26th International Conference on Artificial Life and Robotics (ICAROB)
CY JAN 21-24, 2021
CL ELECTR NETWORK
DE FPGA; Hardware Accelerator; Xillybus; Deep Learning; Random Number
   Generator; RBM
AB Deep learning technology has made remarkable progress in recent years and has been applied to a variety of applications such as smartphones and cloud servers. These systems employ dedicated processors to save power consumptions and process massive data. In this paper, we introduce a hardware-oriented restricted Boltzmann machine and propose a field-programmable gate array (FPGA) infrastructure for easy verification of user circuits. The infrastructure makes it easy to communicate and control between the host PC and the user circuit.
C1 [Hori, Sansei; Tamukoh, Hakaru] Kyushu Inst Technol, Grad Sch Life Sci & Syst Engn, 2-4 Hibikino, Kitakyushu, Fukuoka 8080196, Japan.
RP Hori, S (corresponding author), Kyushu Inst Technol, Grad Sch Life Sci & Syst Engn, 2-4 Hibikino, Kitakyushu, Fukuoka 8080196, Japan.
EM hori-sansei@edu.brain.kyutech.ac.jp; tamukoh@brain.kyutech.ac.jp
CR Fischer Asja, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P14, DOI 10.1007/978-3-642-33275-3_2
   Hinton G., 2010, 2010003 UTML TR
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hori S., 2019, IEICE TECH REP, V119, P1
   Hori S, 2016, LECT NOTES COMPUT SC, V9886, P391, DOI 10.1007/978-3-319-44778-0_46
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   NVIDIA, NVIDIA TESL V100 GPU
   TRIMBERGER S, 1993, P IEEE, V81, P1030, DOI 10.1109/5.231341
   Wang S, 2019, BFLOAT16 SECRET HIGH
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2021
BP 12
EP 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Theory & Methods; Robotics
DA 2023-11-11
ER

PT J
AU Lee, E
   Han, T
   Seo, D
   Shin, G
   Kim, J
   Kim, S
   Jeong, S
   Rhe, J
   Park, J
   Ko, JH
   Lee, Y
AF Lee, Eunyoung
   Han, Taeyoung
   Seo, Donguk
   Shin, Gicheol
   Kim, Jaerok
   Kim, Seonho
   Jeong, Soyoun
   Rhe, Johnny
   Park, Jaehyun
   Ko, Jong Hwan
   Lee, Yoonmyung
TI A Charge-Domain Scalable-Weight In-Memory Computing Macro With Dual-SRAM
   Architecture for Precision-Scalable DNN Accelerators
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Computer architecture; Microprocessors; Merging; Capacitors; SRAM cells;
   Couplings; Transistors; In-memory computing; deep neural networks;
   charge-domain compute; machine learning; bit-scalable
ID NEURAL-NETWORK ACCELERATOR; CNN ACCELERATOR; PROCESSOR; COMPUTATION
AB This paper presents a charge-domain in-memory computing (IMC) macro for precision-scalable deep neural network accelerators. The proposed Dual-SRAM cell structure with coupling capacitors enables charge-domain multiply and accumulate (MAC) operation with variable-precision signed weights. Unlike prior charge-domain IMC macros that only support binary neural networks or digitally compute weighted sums for MAC operation with multi-bit weights, the proposed macro implements analog weighted sums for energy-efficient bit-scalable MAC operations with a novel series-coupled merging scheme. A test chip with a 16-kb SRAM macro is fabricated in 28-nm FDSOI process, and the measured macro throughput is 125.2-876.5 GOPS for weight bit-precision varying from 2 to 8. The macro also achieves energy efficiency ranging from 18.4 TOPS/W for 8-b weight to 119.2 TOPS/W for 2-b weight.
C1 [Lee, Eunyoung; Han, Taeyoung] Samsung Elect, Memory Div, Suwon 16677, South Korea.
   [Seo, Donguk; Shin, Gicheol; Kim, Jaerok; Rhe, Johnny; Ko, Jong Hwan; Lee, Yoonmyung] Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon 16419, South Korea.
   [Kim, Seonho; Jeong, Soyoun] Sungkyunkwan Univ, Dept Semicond & Display Engn, Suwon 16419, South Korea.
   [Park, Jaehyun] Sungkyunkwan Univ, Dept Artificial Intelligence, Suwon 16419, South Korea.
RP Lee, Y (corresponding author), Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon 16419, South Korea.
EM eleeal0809@gmail.com; yoonmyung@skku.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Baker R. J., 2007, CMOS CIRCUIT DESIGN, P736
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dong Q, 2017, SYMP VLSI CIRCUITS, pC160, DOI 10.23919/VLSIC.2017.8008465
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jia HY, 2020, IEEE J SOLID-ST CIRC, V55, P2609, DOI 10.1109/JSSC.2020.2987714
   Jia Y, 2014, THESIS U CALIFORNIA
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim J, 2020, IEEE COMPUT SOC CONF, P975, DOI 10.1109/CVPRW50498.2020.00129
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Okumura S, 2019, S VLSI TECH, pC248
   Si X, 2020, IEEE J SOLID-ST CIRC, V55, P189, DOI 10.1109/JSSC.2019.2952773
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Su F, 2017, S VLSI TECH, pC260
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tripathi V, 2014, IEEE T CIRCUITS-I, V61, P2236, DOI 10.1109/TCSI.2014.2332264
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yin SY, 2018, SYMP VLSI CIRCUITS, P37, DOI 10.1109/VLSIC.2018.8502388
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 30
TC 25
Z9 26
U1 0
U2 10
PD AUG
PY 2021
VL 68
IS 8
BP 3305
EP 3316
DI 10.1109/TCSI.2021.3080042
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Wang, XD
   Li, G
   Sun, JC
   Fan, HJ
   Chen, Y
   Jiao, HL
AF Wang, Xudong
   Li, Geng
   Sun, Jiacong
   Fan, Huanjie
   Chen, Yong
   Jiao, Hailong
GP IEEE
TI Ternary In-Memory MAC Accelerator With Dual-6T SRAM Cell for Deep Neural
   Networks
SO 2022 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, APCCAS
DT Proceedings Paper
CT IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)
CY NOV 11-13, 2022
CL So Univ Sci & Technol, Shenzhen, PEOPLES R CHINA
HO So Univ Sci & Technol
DE In-memory computing; ternary neural networks; multiply-accumulate;
   encoding
AB In-memory computing (IMC) based on static random access memory (SRAM) is a promising solution to enable highly energy-efficient multiply-accumulate (MAC) operations for machine learning accelerators. In this paper, an in-SRAM computing technique is proposed by using a dual-six-transistor (dual-6T) SRAM cell. The dual-6T SRAM cell is composed of two conventional-6T-SRAM-cell-like 6T cells with split wordlines, achieving a compact array layout. With specialized coding, the dual-6T SRAM circuit is one of the few in-memory accelerators which support parallel MAC operations with both ternary activation and ternary weight. A 128x64 memory array is implemented in a 55-nm low-power CMOS technology. Due to the compact bitcell topology and smart coding, the proposed dual-6T memory array achieves up to 635 TOPS/W energy efficiency @ 100 MHz and 38.84 TOPS/mm(2) peak area efficiency @ 350 MHz, which is competitive among the state-of-the-art in-memory computing MAC accelerators.
C1 [Wang, Xudong; Li, Geng; Sun, Jiacong; Fan, Huanjie; Jiao, Hailong] Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen, Peoples R China.
   [Chen, Yong] Univ Macau, State Key Lab Analog & Mixed Signal VLSI, Macau, Peoples R China.
RP Jiao, HL (corresponding author), Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen, Peoples R China.
EM jiaohailong@pku.edu.cn
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], MNIST HANDWRITTEN DI
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I, 2016, ADV NEUR IN, V29
   Jain S, 2020, IEEE T VLSI SYST, V28, P1567, DOI 10.1109/TVLSI.2020.2993045
   Jhang CJ, 2021, IEEE T CIRCUITS-I, V68, P1773, DOI 10.1109/TCSI.2021.3064189
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2016, Arxiv, DOI arXiv:1605.04711
   Okumura S, 2019, S VLSI TECH, pC248
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 246
EP 250
DI 10.1109/APCCAS55924.2022.10090389
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Shen, YM
   Ferdman, M
   Milder, P
AF Shen, Yongming
   Ferdman, Michael
   Milder, Peter
GP Assoc Comp Machinery
TI Maximizing CNN Accelerator Efficiency Through Resource Partitioning
SO 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017)
DT Proceedings Paper
CT 44th Annual International Symposium on Computer Architecture (ISCA)
CY JUN 24-28, 2017
CL Toronto, CANADA
DE Convolutional Neural Network; FPGA; Accelerator
ID COPROCESSOR
AB Convolutional neural networks (CNNs) are revolutionizing machine learning, but they present significant computational challenges. Recently, many FPGA-based accelerators have been proposed to improve the performance and efficiency of CNNs. Current approaches construct a single processor that computes the CNN layers one at a time; the processor is optimized to maximize the throughput at which the collection of layers is computed. However, this approach leads to inefficient designs because the same processor structure is used to compute CNN layers of radically varying dimensions.
   We present a new CNN accelerator paradigm and an accompanying automated design methodology that partitions the available FPGA resources into multiple processors, each of which is tailored for a different subset of the CNN convolutional layers. Using the same FPGA resources as a single large processor, multiple smaller specialized processors increase computational efficiency and lead to a higher overall throughput. Our design methodology achieves 3.8x higher throughput than the state-of-the-art approach on evaluating the popular AlexNet CNN on a Xilinx Virtex-7 FPGA. For the more recent SqueezeNet and GoogLeNet, the speedups are 2.2x and 2.0x.
C1 [Shen, Yongming; Ferdman, Michael; Milder, Peter] SUNY Stony Brook, Stony Brook, NY 11794 USA.
RP Shen, YM (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
EM yoshen@cs.stonybrook.edu; mferdman@cs.stonybrook.edu;
   peter.milder@stonybrook.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M., 2016, MICROPAGE, P1
   [Anonymous], 2016, MICRO
   [Anonymous], J DAIRY SCI, DOI DOI 10.1109/MICR0.2014.58
   [Anonymous], 2016, 7 SER FPGAS MEM RES
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Judd Patrick, 2016, P 2016 INT C SUPERCO, DOI 10.1145/2925426.2926294
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Peemen M, 2015, DES AUT TEST EUROPE, P169
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Redmon J., 2016, ARXIV160207360, P779
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen Y., 2017, P 25 IEEE INT S FIEL
   Song L., 2016, P DAC
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Van den Oord A., 2013, ADV NEURAL INF PROCE, V26
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zisserman A., 2014, 14091556 ARXIV
NR 32
TC 206
Z9 219
U1 3
U2 18
PY 2017
BP 535
EP 547
DI 10.1145/3079856.3080221
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT C
AU Zhao, L
   Deng, Q
   Zhang, YT
   Yang, J
AF Zhao, Lei
   Deng, Quan
   Zhang, Youtao
   Yang, Jun
GP ACM
TI RFAcc: A 3D ReRAM Associative Array based Random Forest Accelerator
SO INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019)
DT Proceedings Paper
CT 33rd ACM International Conference on Supercomputing (ICS)
CY JUN 26-28, 2019
CL Phoenix, AZ
DE ReRAM; Random Forest; Accelerator
AB Random forest (RF) is a widely adopted machine learning method for solving classification and regression problems. Training a random forest demands a large number of relational comparison and data movement operations, which take long time when using modern CPUs. Accelerating random forest training using either GPUs or FPGAs achieves only modest speedups.
   In this paper, we propose RFAcc, a ReRAM based accelerator, to speed up random forest training process. We first devise a 3D ReRAM based relational comparison engine, referred to as 3D-VRComp, to enable parallel in-memory value comparison. We then exploit 3D-VRComp to construct RFAcc to speedup random forest training. Finally, we propose three optimizations, i.e., unary encoding, pipeline design, and parallel tree node training, to fully utilize the accelerator resources for maximized throughput improvement. Our experimental results show that, on average, RFAcc achieves 8564 and 16850 times speedup and 6.6 x 10(4) and 2.6 x 10(5) times energy saving over the training on a 4.2GHz Intel Core i7 CPU and a NVIDIA GTX1080 GPU, respectively.
C1 [Zhao, Lei; Zhang, Youtao; Yang, Jun] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
   [Deng, Quan] Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
RP Zhao, L (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.
EM lez21@pitt.edu; dengquan12@nudt.edu.cn; zhangyt@cs.pitt.edu;
   juy9@pitt.edu
CR [Anonymous], 2013, LEARNING RANDOM FORE
   [Anonymous], IEEE T ELECT DEVICES
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Breiman L., 2001, MACHINE LEARNING
   Cheng C., 2013, I C FIELD PROG LOGIC
   Chevallier Christophe J, 2010, INT SOL STAT CIRC C
   Chi Ping, 2016, INT S COMP ARCH
   Corinna Cortes., 1995, MACH LEARN, V20, P273, DOI DOI 10.1023/A:1022627411411
   David H., 2010 ACMIEEE INT S L
   Deng Yexin, 2013, INT EL DEV M
   Dong X., 2012, IEEE T COMPUTER AIDE
   Feng Ji, 2017, INT JOINT C ART INT
   Fernandez-Delgado Manuel, 2014, J MACHINE LEARNING R
   Grahn Hakan, 2011, IEEE ACS INT C COMP
   Huang Li-Yue, 2014, S VLSI CIRC
   Huangfu WQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196098
   Kaggle, 2019, KAGGL COMP
   Kak Subhash, 2016, CIRCUITS SYSTEMS SIG
   Kang W, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2703863
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   LeCun Yann, 1998, P IEEE
   Li Shuangchen, 2016, INT C COMP AID DES
   LICHMAN M., 2013, UCI MACHINE LEARNING
   Nvidia, 2019, NVID SYST MAN INT
   Schapire Robert E, 1990, MACHINE LEARNING
   Schulz H., 2015, INT C COMP VIS THEOR
   Shaiee Ali, 2016, INT S COMP ARCH
   Sharad M., 2012, IEEE T NANOTECHNOLOG
   Xu Cong, 2014, AS S PAC DES AUT C
   Zhao He, 2017, J STAT SOFTWARE
NR 30
TC 9
Z9 10
U1 3
U2 6
PY 2019
BP 473
EP 483
DI 10.1145/3330345.3330387
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Rucker, A
   Shahbaz, M
   Olukotun, K
AF Rucker, Alexander
   Shahbaz, Muhammad
   Olukotun, Kunle
TI Chopping off the Tail: Bounded Non-Determinism for Real-Time
   Accelerators
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Servers; Load modeling; Data centers; Hardware acceleration; Software;
   Processor scheduling; Runtime; Data centers; hardware accelerators; tail
   latency; non-determinism; disaggregation; SLO
AB Modern data centers run web-scale applications on tens of thousands of servers, generating tens of thousands of Remote Procedure Calls (RPCs) to backend services for each incoming user request. Tail latency, due to a small fraction of randomly slow RPCs, decreases the performance of these incoming requests, degrades users' quality of experience, and limits disaggregation (applications' ability to scale across a data center). We argue that current approaches to improve tail latency (especially, those bounding computation time) are insufficient, even with (reconfigurable-) hardware accelerators. Instead, to chop off the tail, datacenter services should dynamically trade correctness (or result quality) for timeliness, providing bounded latency with near-ideal accuracy. In this paper, we discuss how the increasing prevalence of machine learning (including search techniques like approximate nearest neighbor and PageRank), perceptual algorithms (like computational photography and image/video caching), and natural language processing lets modern hardware accelerators make these dynamic correctness tradeoffs while improving users' quality of experience.
C1 [Rucker, Alexander; Olukotun, Kunle] Stanford Univ, Stanford, CA 94305 USA.
   [Shahbaz, Muhammad] Purdue Univ, W Lafayette, IN 47907 USA.
RP Rucker, A (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM acrucker@stanford.edu; mshahbaz@purdue.edu; kunle@stanford.edu
CR Ananthanarayanan G., 2014, P USENIX C NETW SYST, P289
   [Anonymous], 2019, SPRING SER CHALLENGE, DOI DOI 10.1007/978-3-030-05318-5_1
   [Anonymous], 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), DOI DOI 10.1145/3132747.3132780
   [Anonymous], 2016, PROC INT CONF PARAL, DOI DOI 10.1109/ICPP.2016.39
   [Anonymous], 2020, ANN I S COM, DOI DOI 10.1109/ISCA45697.2020.00027
   [Anonymous], 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION
   [Anonymous], 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), DOI DOI 10.1145/3230543.3230564
   [Anonymous], 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION
   [Anonymous], 2017, SIGC 17 P 2017 C, DOI DOI 10.1145/3098822.3098825
   Belay A., 2014, P USENIX S OP SYST D, P49
   Dean J, 2013, COMMUN ACM, V56, P74, DOI 10.1145/2408776.2408794
   Ibanez S., 2019, P 18 ACM WORKSH HOT, P52, DOI DOI 10.1145/3365609.3365851
   Jouppi N.P., 2021, P ACM IEEE ANN INT S, P1
   Kulkarni N., 2019, INT S HIGH PERF COMP, P159, DOI DOI 10.1109/HPCA.2019.00035
   Li J., 2014, P ACM S CLOUD COMP, P1
   Olukotun K., 2018, ISCA 2018
   Shah Hemal, 2014, 7306 RFC
NR 17
TC 0
Z9 0
U1 0
U2 0
PD JUL-DEC
PY 2021
VL 20
IS 2
BP 110
EP 113
DI 10.1109/LCA.2021.3102224
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Olyaiy, M
   Ng, C
   Fedorova, A
   Lis, M
AF Olyaiy, MohammadHossein
   Ng, Christopher
   Fedorova, Alexandra (Sasha)
   Lis, Mieszko
GP IEEE
TI Sunstone: A Scalable and Versatile Scheduler for Mapping Tensor Algebra
   on Spatial Accelerators
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE, ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY APR 23-25, 2023
CL Raleigh, NC
DE dataflow computing; accelerator architectures; scheduling algorithms;
   neural network hardware; parallel processing
AB Tensor algebra, the main component of several popular machine learning techniques, benefits from modern accelerators due to the massive parallelism and data reuse available. To achieve the benefits, however, optimizing the dataflow is crucial: prior works showed that 19x energy savings are possible by tuning the dataflow. This optimization is challenging because: (1) the optimization space for modern chip architectures with several levels of memory and multiple levels of spatial processing is vast, and (2) distinct tensor computations follow different memory access and reuse patterns.
   In this manuscript, we algebraically analyze the possible reuse when executing tensor workloads on an accelerator. Based on our analysis, we develop several principles that significantly reduce the dataflow optimization space even for modem, complex chip architectures. Moreover, these principles are transferable to various tensor workloads with different memory access patterns.
   Compared to prior work, our techniques can find dataflow for typical tensor workloads up to 800x faster and with up to 1.9x better energy-delay products.
C1 [Olyaiy, MohammadHossein; Ng, Christopher; Fedorova, Alexandra (Sasha); Lis, Mieszko] Univ British Columbia, Vancouver, BC, Canada.
RP Olyaiy, M (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM mohamadol@ece.ubc.ca; chris.ng@ece.ubc.ca; sasha@ece.ubc.ca;
   mieszko@ece.ubc.ca
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   [Anonymous], 2009, HP LAB
   [Anonymous], 2017, FROSTT FORMIDABLE RE
   Austin W, 2016, INT PARALL DISTRIB P, P912, DOI 10.1109/IPDPS.2016.67
   Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081
   Baghdadi R, 2019, INT SYM CODE GENER, P193, DOI [10.5281/zenodo.2375075, 10.1109/CGO.2019.8661197]
   Baghdadi R, 2015, INT CONFER PARA, P138, DOI 10.1109/PACT.2015.17
   Bi X, 2018, ANN STAT, V46, P3308, DOI 10.1214/17-AOS1659
   Chatarasi P, 2020, Arxiv, DOI arXiv:2002.07752
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Denton E, 2014, ADV NEUR IN, V27
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Elango V, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P42, DOI 10.1145/3211346.3211354
   Frolov Evgeny, 2016, ABS160306038 CORR
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Ghimire D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060945
   Grosser T, 2012, PARALLEL PROCESS LET, V22, DOI 10.1142/S0129626412500107
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P943, DOI 10.1145/3445814.3446762
   Huang QJ, 2021, CONF PROC INT SYMP C, P554, DOI 10.1109/ISCA52012.2021.00050
   Jaderberg M., 2014, ARXIV14053866, DOI DOI 10.5244/C.28.88
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Kossaifi J, 2017, IEEE COMPUT SOC CONF, P1940, DOI 10.1109/CVPRW.2017.243
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   L. Gurobi Optimization, 2021, GUROBI OPTIMIZER REF
   Lebedev V., 2015, SPEEDING UP CONVOLUT
   Li R, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P928, DOI 10.1145/3445814.3446759
   Liu Y, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108171
   McKinley KS, 1996, ACM T PROGR LANG SYS, V18, P424, DOI 10.1145/233561.233564
   Mei LY, 2021, IEEE T COMPUT, V70, P1160, DOI 10.1109/TC.2021.3059962
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Parashar Angshuman, TIMELOOP SYSTEMATIC
   Qijing Huang, UCB BAR COSA SCHEDUL
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smilde A. K., 2005, MULTIWAY ANAL APPL C
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Sun J.-T., 2005, P 14 INT C WORLD WID, P382, DOI DOI 10.1145/1060745.1060803
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan ZH, 2021, CONF PROC INT SYMP C, P1013, DOI 10.1109/ISCA52012.2021.00083
   Vasilache N., 2018, TENSOR COMPREHENSION
   Vasilescu MAO, 2002, LECT NOTES COMPUT SC, V2350, P447
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wijeratne Sasindu, 2021, ABS210908874 CORR
   Wolf M. E., 1991, SIGPLAN Notices, V26, P30, DOI 10.1145/113446.113449
   WOLFE M, 1989, PROCEEDINGS : SUPERCOMPUTING 89, P655, DOI 10.1145/76263.76337
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Wu Yannan (Nellie), ACCELERGY PROJECT TI
   Xiao QC, 2021, CONF PROC INT SYMP C, P1055, DOI 10.1109/ISCA52012.2021.00086
   Yang DQ, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P711, DOI 10.1109/MICRO50266.2020.00064
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yunxiang Hu, 2022, 2022 14th International Conference on Computer Research and Development (ICCRD), P100, DOI 10.1109/ICCRD54409.2022.9730377
   Zhang KQ, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942103
   Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863
NR 69
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 259
EP 271
DI 10.1109/ISPASS57527.2023.00033
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Senoo, T
   Jinguji, A
   Kuramochi, R
   Nakahara, H
AF Senoo, Takeshi
   Jinguji, Akira
   Kuramochi, Ryosuke
   Nakahara, Hiroki
GP IEEE
TI A Multilayer Perceptron Training Accelerator using Systolic Array
SO 2021 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2021)
   & 2021 IEEE CONFERENCE ON POSTGRADUATE RESEARCH IN MICROELECTRONICS AND
   ELECTRONICS (PRIMEASIA 2021)
DT Proceedings Paper
CT IEEE Asia Pacific Conference on Circuits and Systems (APCCAS) / IEEE
   Conference on Postgraduate Research in Microelectronics and Electronics
   (PRIMEASIA)
CY NOV 22-26, 2021
CL ELECTR NETWORK
DE neural network; training accelerator; multilayer perceptron; machine
   learning; intrusion detection system
AB Neural networks are now used in various applications, and the demand for fast training with large amounts of data is emerging For example, a network intrusion detection (NID) system needs to be trained in a short period to detect attacks based on large amount of traffic logs. We propose a training accelerator as a systolic array on a Xilinx U50 Alveo FPGA card to solve this problem. We found that the accuracy is almost the same as conventional training even when the forward and backward paths are run simultaneously by delaying the weight update. Compared to the Intel Core i9 CPU and NVIDIA RTX 3090 GPU, it was three times faster than the CPU and 2.5 times faster than the GPU. The processing speed per power consumption was 11.5 times better than the CPU and 21.4 times better than the GPU. From these results, we can conclude that implementing a training accelerator on FPGAs as a systolic array can achieve high speed and high energy efficiency.
C1 [Senoo, Takeshi; Jinguji, Akira; Kuramochi, Ryosuke; Nakahara, Hiroki] Tokyo Inst Technol, Tokyo, Japan.
RP Senoo, T (corresponding author), Tokyo Inst Technol, Tokyo, Japan.
EM senoo@reconf.ict.e.titech.ac.jp; jinguji@reconf.ict.e.titech.ac.jp;
   kuramochi@reconf.ict.e.titech.ac.jp; nakahara@ict.e.titech.ac.jp
CR [Anonymous], 2006, FPGA IMPLEMENTATIONS
   Cadambi S., 2012, P 19 INT C PAR ARCH, P273
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Gironés RG, 2005, J VLSI SIG PROC SYST, V40, P189, DOI 10.1007/s11265-005-4961-3
   Jaderberg M., 2016, ARXIV160805343
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   NAKAHARA H, 2017, ICFPT, P168
   Yadan O., 2015, ARXIV PREPRINT ARXIV
   Yang Q., 2018, P MACHINE LEARNING R, P2103
   Zhao W., 2016, IEEE 27 INT C APPL S
NR 10
TC 1
Z9 1
U1 0
U2 4
PY 2021
BP 77
EP 80
DI 10.1109/APCCAS51387.2021.9687773
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
DA 2023-11-11
ER

PT C
AU Khoshavi, N
   Broyles, C
   Bi, Y
AF Khoshavi, Navid
   Broyles, Connor
   Bi, Yu
GP IEEE
TI Compression or Corruption? A Study on the Effects of Transient Faults on
   BNN Inference Accelerators
SO PROCEEDINGS OF THE TWENTYFIRST INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2020)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 21st International Symposium on Quality Electronic Design (ISQED)
CY MAR 25-26, 2020
CL Santa Clara, CA
DE Fault Injection; Deep Neural Network Accelerator; Machine Learning; Soft
   Error
ID AGING MITIGATION; NEURAL-NETWORKS
AB Over past years, the philosophy for designing the artificial intelligence algorithms has significantly shifted towards automatically extracting the composable systems from massive data volumes. This paradigm shift has been expedited by the big data booming which enables us to easily access and analyze the highly large data sets. The most well-known class of big data analysis techniques is called deep learning. These models require significant computation power and extremely high memory accesses which necessitate the design of novel approaches to reduce the memory access and improve power efficiency while taking into account the development of domain-specific hardware accelerators to support the current and future data sizes and model structures. The current trends for designing application-specific integrated circuits barely consider the essential requirement for maintaining the complex neural network computation to be resilient in the presence of soft errors. The soft errors might strike either memory storage or combinational logic in the hardware accelerator that can affect the architectural behavior such that the precision of the results fall behind the minimum allowable correctness. In this study, we demonstrate that the impact of soft errors on a customized deep learning algorithm called Binarized Neural Network might cause drastic image misclassification. Our experimental results show that the accuracy of image classifier can drastically drop by 76.70% and 19.25% in lfcW1A1 and cnvW1A1 networks, respectively across CIFAR-10 and MNIST datasets during the fault injection for the worst-case scenarios.
C1 [Khoshavi, Navid] Florida Polytech Univ, Dept Comp Sci, Lakeland, FL 33805 USA.
   [Khoshavi, Navid; Broyles, Connor] Florida Polytech Univ, Dept Elect & Comp Engn, Lakeland, FL 33805 USA.
   [Bi, Yu] Univ Rhode Isl, Dept Elect & Comp Engn, 825 Chalkstone Ave, Providence, RI 02908 USA.
RP Khoshavi, N (corresponding author), Florida Polytech Univ, Dept Comp Sci, Lakeland, FL 33805 USA.; Khoshavi, N (corresponding author), Florida Polytech Univ, Dept Elect & Comp Engn, Lakeland, FL 33805 USA.
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Azizi A, 2019, INT J INTERACT DES M, V13, P373, DOI 10.1007/s12008-018-0501-9
   Barenghi A, 2012, P IEEE, V100, P3056, DOI 10.1109/JPROC.2012.2188769
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Dixit A, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Hubara I, 2018, J MACH LEARN RES, V18
   Karpathy, STANFORD CS CLASS CS
   Khoshavi N, 2017, INTEGRATION, V59, P10, DOI 10.1016/j.vlsi.2017.03.013
   Khoshavi N, 2016, INT SYM QUAL ELECT, P6, DOI 10.1109/ISQED.2016.7479148
   Khoshavi N, 2014, MIDWEST SYMP CIRCUIT, P929, DOI 10.1109/MWSCAS.2014.6908568
   Kim Y, 2014, CONF PROC INT SYMP C, P361, DOI 10.1109/ISCA.2014.6853210
   Lacey G, 2016, DEEP LEARNING FPGAS
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Lin CY, 2018, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2018.8297290
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Schirmeier H. B, 2016, THESIS TU DORTMUND G
   Seifert N, 2012, IEEE T NUCL SCI, V59, P2666, DOI 10.1109/TNS.2012.2218128
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
NR 21
TC 5
Z9 5
U1 0
U2 0
PY 2020
BP 99
EP 104
DI 10.1109/isqed48828.2020.9137006
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zhao, M
   Qin, DY
   Guo, RL
   Wang, XX
AF Zhao, Min
   Qin, Danyang
   Guo, Ruolin
   Wang, Xinxin
TI Indoor Floor Localization Based on Multi-Intelligent Sensors
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
DT Article
DE indoor floor localization; sensors; geomagnetic field; machine learning
ID LOCATION
AB With the continuous expansion of the market of indoor localization, the requirements of indoor localization technology are becoming higher and higher. Existing indoor floor localization (IFL) systems based on Wi-Fi signal and barometer data are susceptible to external environment changes, resulting in large errors. A method for indoor floor localization using multiple intelligent sensors (MIS-IFL) is proposed to decrease the localization errors, which consists of a fingerprint database construction phase and a floor localization phase. In the fingerprint database construction phase, data acquisition is performed using magnetometer sensor, accelerator sensor and gyro sensor in the smartphone. In the floor localization phase, an active pattern recognition is performed through the collaborative work of multiple intelligent sensors and machine learning classifiers. Then floor localization is performed using magnetic data mapping, Euclidean closest approximation and majority principle. Finally, the inter-floor detection link based on machine learning is added to improve the overall localization accuracy of MIS-IFL. The experimental results show that the performance of the proposed method is superior to the existing IFL.
C1 [Zhao, Min; Qin, Danyang; Guo, Ruolin; Wang, Xinxin] Heilongjiang Univ, Key Lab Elect & Commun Engn, Harbin 150080, Peoples R China.
RP Qin, DY (corresponding author), Heilongjiang Univ, Key Lab Elect & Commun Engn, Harbin 150080, Peoples R China.
EM 2181223@s.hlju.edu.cn; qindanyang@hlju.edu.cn; 2181226@s.hlju.edu.cn;
   2181246@s.hlju.edu.cn
CR Agarwal, 2014, P 15 WORKSHOP MOBILE
   [Anonymous], 2017, RES MULTIINFORMATION
   Ayanoglu A., 2018, P INT C IND POS IND, P1
   Chen Z.Z., 2018, INF COMMUN TECHNOL L, V185, P93
   Gao RP, 2014, IEEE ICC, P2599, DOI 10.1109/ICC.2014.6883715
   Holzinger A, 2015, ONLINE INFORM REV, V39, P437, DOI 10.1108/OIR-04-2015-0121
   Hou E.Z, 2017, BUILD ENERGY SAV, V2017, P53
   Kumar V., 2013, INTRO DATA MINING PE, V14, P279
   Liu B, 2016, IEEE T VEH TECHNOL, V65, P9942, DOI 10.1109/TVT.2016.2531185
   Liu HH, 2011, 2011 IEEE REGION 10 CONFERENCE TENCON 2011, P597, DOI 10.1109/TENCON.2011.6129175
   Liu KX, 2016, PROCEEDINGS 2016 IEEE SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING SOSE 2016, P314, DOI 10.1109/SOSE.2016.18
   Luo HY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112678
   Ma W., P INT C MOIL AD HOC, P172
   Salamah AH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071678
   Shen XF, 2015, IEEE INT CONF MOB, P416, DOI 10.1109/MASS.2015.103
   Shi Q.F., 2018, J NAVIG POSITION, V6, P72
   Shu YC, 2015, IEEE J SEL AREA COMM, V33, P1443, DOI 10.1109/JSAC.2015.2430274
   Speybroeck N, 2012, INT J PUBLIC HEALTH, V57, P243, DOI 10.1007/s00038-011-0315-z
   Sun L, 2015, INT J DISTRIB SENS, V2015, P1, DOI [10.1155/2015/946457, DOI 10.1155/2015/946457]
   Wu JX, 2015, IEEE T NEUR NET LEAR, V26, P2357, DOI 10.1109/TNNLS.2014.2382123
   Wu T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061974
   Xia H, 2015, SENSORS-BASEL, V15, P7857, DOI 10.3390/s150407857
   Ye HB, 2016, WIREL COMMUN MOB COM, V16, P2557, DOI 10.1002/wcm.2706
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhao F, 2017, IEEE T IND INFORM, V13, P330, DOI 10.1109/TII.2015.2491264
   Zhao Hong, 2016, Journal of Computer Applications, V36, P301, DOI 10.11772/j.issn.1001-9081.2016.02.0301
NR 26
TC 2
Z9 2
U1 1
U2 27
PD JAN
PY 2021
VL 10
IS 1
AR 6
DI 10.3390/ijgi10010006
WC Computer Science, Information Systems; Geography, Physical; Remote
   Sensing
DA 2023-11-11
ER

PT C
AU Tian, D
   Deng, JM
   Zio, E
   Di Maio, F
   Liao, F
AF Tian, David
   Deng, Jiamei
   Zio, Enrico
   Di Maio, Francesco
   Liao, Fucheng
GP IEEE
TI Failure Modes Detection of Nuclear Systems using Machine Learning
SO 2018 5TH INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND THEIR
   APPLICATIONS (DSA)
DT Proceedings Paper
CT 5th International Conference on Dependable Systems and Their
   Applications (DSA)
CY SEP 22-23, 2018
CL Dalian, PEOPLES R CHINA
DE failure modes detection; nuclear systems; machine learning; pattern
   classification; Gaussian mixture models; neural networks
ID REMAINING USEFUL LIFE; FUZZY SYSTEM; IDENTIFICATION; CLASSIFICATION;
   SCENARIOS; ROD
AB Early detection of the failure of a nuclear system is an important topic in nuclear energy. This paper proposes three machine learning methodologies to detect the failure modes (FM) of the Lead-Bismuth Eutectic eXperimental Accelerator Driven System (LBE-XADS) nuclear system after the first 10%, 50% and 90% time periods of the 3000 seconds mission time of the LBE-XADS. The first methodology detects the FM of the LBE-XADS after the first 10% time period and consists of two Gaussian mixture-based (GM-based) classifiers. The second methodology detects the FM of the LBE-XADS after the first 50% time period and consists of a GM-based classifier and a neural network MLP1. The third methodology detects the failure mode of the LBE-XADS after the first 90% time period and consists of a GM-based classifier and a neural network MLP2. The three proposed methodologies outperformed the fuzzy similarity approach of the previous work.
C1 [Tian, David; Deng, Jiamei] Leeds Beckett Univ, Leeds, W Yorkshire, England.
   [Zio, Enrico; Di Maio, Francesco] Politecn Milan, Milan, Italy.
   [Liao, Fucheng] Univ Sci & Technol Beijing, Beijing, Peoples R China.
RP Tian, D (corresponding author), Leeds Beckett Univ, Leeds, W Yorkshire, England.
EM dtian09@gmail.com; J.Deng@leedsbeckett.ac.uk; enrico.zio@polimi.it
CR Alamaniotis M, 2014, MECH SYST SIGNAL PR, V48, P188, DOI 10.1016/j.ymssp.2014.02.014
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P1
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], FLINS 8 INT FLINS C
   [Anonymous], 2002, ALGORITHMS PATTERN R
   [Anonymous], 2005, MORGAN KAUFMANN SERI
   [Anonymous], 2006, PATTERN RECOGN
   [Anonymous], 2003, IAEATECDOC1352
   [Anonymous], J SCI INNOVATIVE RES
   [Anonymous], 2008 INT C PROGN HLT
   Back JH, 2017, ANN NUCL ENERGY, V110, P989, DOI 10.1016/j.anucene.2017.08.006
   Baraldi P, 2011, ANN NUCL ENERGY, V38, P1161, DOI 10.1016/j.anucene.2010.12.009
   Bishop C.M., 1995, NEURAL NETWORKS PATT
   Cammi A, 2006, PROG NUCL ENERG, V48, P578, DOI 10.1016/j.pnucene.2006.03.006
   Guimaraes ACF, 2007, ANN NUCL ENERGY, V34, P233, DOI 10.1016/j.anucene.2006.11.012
   Haibo He, 2009, IEEE Transactions on Knowledge and Data Engineering, V21, P1263, DOI 10.1109/TKDE.2008.239
   Han J, 2012, MOR KAUF D, P1
   Hand D.J., 2001, ADAP COMP MACH LEARN
   Marseguerra M, 2006, NUCL SCI ENG, V153, P157, DOI 10.13182/NSE06-A2602
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Na MG, 2004, NUCL ENG DES, V232, P289, DOI 10.1016/j.nucengdes.2004.06.007
   Owre F, 2001, NUCL ENG DES, V209, P201, DOI 10.1016/S0029-5493(01)00403-4
   Ramasso E, 2014, IEEE T RELIAB, V63, P555, DOI 10.1109/TR.2014.2315912
   Santosh TV, 2009, RELIAB ENG SYST SAFE, V94, P759, DOI 10.1016/j.ress.2008.08.005
   Secchi P, 2008, ANN NUCL ENERGY, V35, P2338, DOI 10.1016/j.anucene.2008.07.010
   Souza TJ, 2017, ANN NUCL ENERGY, V103, P204, DOI 10.1016/j.anucene.2017.01.004
   Tian ZG, 2010, MECH SYST SIGNAL PR, V24, P1542, DOI 10.1016/j.ymssp.2009.11.005
   Wang WQ, 2004, MECH SYST SIGNAL PR, V18, P813, DOI 10.1016/S0888-3270(03)00079-7
   Wei XY, 2016, SCI TECHNOL NUCL INS, V2016, DOI 10.1155/2016/4720685
   WILLSKY AS, 1976, AUTOMATICA, V12, P601, DOI 10.1016/0005-1098(76)90041-8
   Yin D, 2008, INT CONF BIOMED, P128, DOI 10.1109/BMEI.2008.210
   Zio E, 2010, ANN NUCL ENERGY, V37, P482, DOI 10.1016/j.anucene.2010.01.017
   Zio E, 2010, RELIAB ENG SYST SAFE, V95, P49, DOI 10.1016/j.ress.2009.08.001
   Zio E, 2009, ANN NUCL ENERGY, V36, P1386, DOI 10.1016/j.anucene.2009.06.012
NR 34
TC 2
Z9 2
U1 0
U2 2
PY 2018
BP 35
EP 43
DI 10.1109/DSA.2018.00017
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chen, Y
   Cao, YJ
   Wu, S
   Cao, X
   Cai, T
   Hu, H
AF Chen, Yang
   Cao, Yajie
   Wu, Song
   Cao, Xu
   Cai, Ting
   Hu, Hai
TI Antigen processing and presentation-related signature-derived BNIP3 is a
   novel oncogene and immunotherapy determinant in osteosarcoma based on
   machine learning and <i>in vitro</i> validation
SO JOURNAL OF GENE MEDICINE
DT Article; Early Access
DE BNIP3; immunotherapy; machine learning; osteosarcoma; tumor
   microenvironment
ID CELL-PROLIFERATION; CANCER; APOPTOSIS
AB Background: In recent decades, osteosarcoma has remained the most prevalent kind of malignant tumor. An important and crucial factor in immunotherapy is antigen processing and presentation (APP). The specific functions and pathogenic processes of APP in osteosarcoma have not, however, been studied.Methods: Patients with osteosarcoma were divided into groups using APP-related genes. Machine learning was used to further build the APP-related score. Investigated in-depth were the prognostic relevance of the score, mutation features, immunological aspects, and pharmacological prediction performance. Investigations of the prognostic utility, immunological traits, drug prediction effectiveness and immunotherapy prediction of BNIP3 were performed in-depth.Results: Investigations by cell counting kit-8, Transwell and 5-ethynyl-2-deoxyuridine (EdU) demonstrated that BNIP3 is an osteosarcoma tumor accelerator. The osteosarcoma gene BNIP3 may promote macrophage migration. The APP-related score shows potential for clinical use.Conclusions: It was anticipated that more in vitro and in vivo studies would confirm BNIP3's tumorigenic and immunogenic processes in osteosarcoma.
C1 [Chen, Yang; Wu, Song; Cao, Xu; Hu, Hai] Cent South Univ, Xiangya Hosp 3, Dept Orthoped, Changsha, Peoples R China.
   [Cao, Yajie] Cent South Univ, Xiangya Hosp 3, Ctr Clin Pharmacol, Changsha, Peoples R China.
   [Cai, Ting] Cent South Univ, Xiangya Hosp 3, Dept Gastroenterol, Changsha, Peoples R China.
RP Hu, H (corresponding author), Cent South Univ, Xiangya Hosp 3, Dept Orthoped, Changsha, Peoples R China.
EM huhai166@csu.edu.cn
CR Becht E, 2016, GENOME BIOL, V17, DOI 10.1186/s13059-016-1070-5
   Beltran PJ, 2011, J PHARMACOL EXP THER, V337, P644, DOI 10.1124/jpet.110.178400
   Brown HK, 2017, CANCER LETT, V386, P189, DOI 10.1016/j.canlet.2016.11.019
   Charoentong P, 2017, CELL REP, V18, P248, DOI 10.1016/j.celrep.2016.12.019
   Chen CL, 2021, CANCER LETT, V500, P1, DOI 10.1016/j.canlet.2020.12.024
   Corre I, 2020, CELLS-BASEL, V9, DOI 10.3390/cells9040976
   ElKordy MA, 2018, J EGYPT NATL CANCER, V30, P7, DOI 10.1016/j.jnci.2018.02.001
   Endo-Munoz L, 2010, BRIT J CANCER, V103, P73, DOI 10.1038/sj.bjc.6605723
   Geeleher P, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107468
   Gill J, 2021, NAT REV CLIN ONCOL, V18, P609, DOI 10.1038/s41571-021-00519-8
   He GP, 2023, BIOACT MATER, V19, P690, DOI 10.1016/j.bioactmat.2022.05.006
   He M, 2019, AGING-US, V11, P5744, DOI 10.18632/aging.102157
   Jiang P, 2018, NAT MED, V24, P1550, DOI 10.1038/s41591-018-0136-1
   Kansara M, 2014, NAT REV CANCER, V14, P722, DOI 10.1038/nrc3838
   Li TW, 2017, CANCER RES, V77, pE108, DOI 10.1158/0008-5472.CAN-17-0307
   Liu Q, 2019, CELL BIOL INT, V43, P1245, DOI 10.1002/cbin.11121
   Liu SC, 2023, J HEMATOL ONCOL, V16, DOI 10.1186/s13045-023-01430-8
   Man G, 2021, CANCER MANAG RES, V13, P7527, DOI 10.2147/CMAR.S328559
   McGranahan N, 2015, CANCER CELL, V27, P15, DOI 10.1016/j.ccell.2014.12.001
   Meltzer PS, 2021, NEW ENGL J MED, V385, P2066, DOI 10.1056/NEJMra2103423
   Qu CR, 2022, MOL CANCER, V21, DOI 10.1186/s12943-022-01669-8
   Romano Erminia, 2018, Oncotarget, V9, P17631, DOI 10.18632/oncotarget.24815
   Sadykova LR, 2020, CANCER INVEST, V38, P259, DOI 10.1080/07357907.2020.1768401
   Schumacher TN, 2015, SCIENCE, V348, P69, DOI 10.1126/science.aaa4971
   Vianello C, 2022, CELL DEATH DIS, V13, DOI 10.1038/s41419-022-04741-9
   Wan DD, 2022, CLIN EXP PHARMACOL P, V49, P1179, DOI 10.1111/1440-1681.13701
   Wang XJ, 2019, HEPATOLOGY, V69, P545, DOI 10.1002/hep.30215
   Wang YC, 2022, J HEMATOL ONCOL, V15, DOI 10.1186/s13045-022-01325-0
   Wedekind MF, 2018, PEDIATR BLOOD CANCER, V65, DOI 10.1002/pbc.27227
   Yahiro K, 2021, HUM VACC IMMUNOTHER, V17, P1294, DOI 10.1080/21645515.2020.1824499
   Yang CF, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21196985
   Ye FF, 2015, TUMOR BIOL, V36, P4731, DOI 10.1007/s13277-015-3122-y
   Yoshihara K, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3612
   Yu WX, 2020, EUR REV MED PHARMACO, V24, P915, DOI 10.26355/eurrev_202001_20076
   Yu XB, 2021, CELL BIOSCI, V11, DOI 10.1186/s13578-021-00600-w
NR 35
TC 0
Z9 0
U1 2
U2 2
PD 2023 SEP 1
PY 2023
AR e3586
DI 10.1002/jgm.3586
EA SEP 2023
WC Biotechnology & Applied Microbiology; Genetics & Heredity; Medicine,
   Research & Experimental
DA 2023-11-11
ER

PT C
AU Pfingstner, J
   Schulte, D
   Schmickler, H
   Hofbaur, M
AF Pfingstner, Juergen
   Schulte, Daniel
   Schmickler, Hermann
   Hofbaur, Michael
GP IEEE
TI An interleaved, model-supported system identification scheme for the
   particle accelerator CLIC
SO 49TH IEEE CONFERENCE ON DECISION AND CONTROL (CDC)
SE IEEE Conference on Decision and Control
DT Proceedings Paper
CT 49th IEEE Conference on Decision and Control (CDC)
CY DEC 15-17, 2010
CL Atlanta, GA
AB The particle accelerator CLIC is a future linear collider, which is developed at CERN. The quality of the particle-beams produced by CLIC is very sensitive to ground motion. The efficiency of the feedback used to counteract ground motion, relies crucially on the quality of the system knowledge. Therefore, we present a system identification scheme to follow changes of accelerator parameters. The algorithm is based on the well-known RLS (recursive least squares) algorithm with exponential forgetting, but adds modifications to improve the learning speed and to address excitation on-strains given by the system. Parallel-running, interleaved RLS algorithms identify parts of the overall system. The different results are combined by using a priori knowledge. Parts that could not be identified directly, are extrapolated with the help of physical models. The modified algorithm can follow system changes with a factor of approx. 30 improved learning speed, compared to the conventional RLS algorithm. It works robustly, in spite of sensor noise and disturbances acting on the excitation signals. The prize that has to be paid is a minimum permanent error of 13% due to model errors. The scheme can easily be adapted to other linear accelerators. Moreover it should be possible to reduce the steady-state error of the identification for other machines, since the main linac of CLIC is an especially difficult system to model and excite.
C1 [Pfingstner, Juergen] Graz Univ Technol, A-8010 Graz, Austria.
   [Schulte, Daniel; Schmickler, Hermann] CERN, Geneva, Switzerland.
   [Hofbaur, Michael] Private Univ UMIT Hall Tyrol, Hall Tyrol, Austria.
RP Pfingstner, J (corresponding author), Graz Univ Technol, A-8010 Graz, Austria.
EM juergen.pfingstner@cern.ch
CR [Anonymous], 2000, PHYS PARTICLE ACCELE
   Astrom K., 2008, ADAPTIVE CONTROL
   Barr D.S., 1992, 1992 ACC INSTR WORKS
   Chao A.W., 1993, PHYS COLLECTIVE BEAM
   Guignard G., 2000, 3 TEV LINEAR COLLIDE
   Himel T., 1993, P 1993 PART ACC C
   LJUNG L, 1990, AUTOMATICA, V26, P7, DOI 10.1016/0005-1098(90)90154-A
   Pfingstner J., AMPLITUDE MODEL BEAM
   Pfingstner J., 2009, 2009 CLIC BEAM INSTR
   Schulte D., 2009, LATTICE DESIGN CONSI
   Sery A, 1996, PHYS REV E, V53, P5323, DOI 10.1103/PhysRevE.53.5323
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2010
BP 4455
EP 4460
DI 10.1109/CDC.2010.5718078
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, JJ
   Agostini, NB
   Song, SA
   Tan, C
   Limaye, A
   Amatya, V
   Manzano, J
   Minutoli, M
   Castellana, VG
   Tumeo, A
   Wei, GY
   Brooks, D
AF Zhang, Jeff Jun
   Agostini, Nicolas Bohm
   Song, Shihao
   Tan, Cheng
   Limaye, Ankur
   Amatya, Vinay
   Manzano, Joseph
   Minutoli, Marco
   Castellana, Vito Giovanni
   Tumeo, Antonino
   Wei, Gu-Yeon
   Brooks, David
GP IEEE Comp Soc
TI Towards Automatic and Agile AI/ML Accelerator Design with End-to-End
   Synthesis
SO 2021 IEEE 32ND INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2021)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 32nd IEEE International Conference on Application-specific Systems,
   Architectures and Processors (ASAP)
CY JUL 07-08, 2021
CL ELECTR NETWORK
ID ARCHITECTURE; NETWORKS
AB Domain-specific designs offer greater energy efficiency and performance gain than general-purpose processors. For this reason, modern system-on-chips have a significant portion of their silicon area with custom accelerators. However, designing hardware by hand is laborious and time-consuming, given the large design space and the performance, power, and area constraints that are not realized in the software. Moreover, domain-specific algorithms (e.g., machine learning models) are evolving quickly, challenging the accelerator design further. To address these issues, this paper presents SODA Synthesizer, an automated open-source high-level ML framework to Verilog modular compiler targeting AI/ML Application-Specific Integrated Circuits (ASICs) accelerators. SODA tightly couples the Multi-Level Intermediate Representation (MLIR) compiler infrastructure [24] and open-source HLS approaches. Thus, SODA can support various ML frameworks and algorithms and can perform optimizations that combine specialized architecture templates and conventional HLS to generate the hardware modules. In addition, SODA's closed-loop design space exploration (DSE) engine allows developers to perform end-to-end design space explorations on different metrics and technology nodes.
C1 [Zhang, Jeff Jun; Wei, Gu-Yeon; Brooks, David] Harvard Univ, Cambridge, MA 02138 USA.
   [Agostini, Nicolas Bohm; Song, Shihao; Tan, Cheng; Limaye, Ankur; Amatya, Vinay; Manzano, Joseph; Minutoli, Marco; Castellana, Vito Giovanni; Tumeo, Antonino] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
RP Zhang, JJ (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM jeffzhang@g.harvard.edu; antonino.tumeo@pnnl.gov
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agostini NB, 2020, INT SYM COMP ARCHIT, P10, DOI 10.1109/SBAC-PAD49847.2020.00013
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Castellana Vito Giovanni, P 35 IEEE INT PAR DI
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Dean J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1, DOI 10.1145/3308558.3313785
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Farahnakian F, 2014, EUROMICRO WORKSHOP P, P500, DOI 10.1109/PDP.2014.109
   Ferrandi F, 2010, IEEE T COMPUT AID D, V29, P911, DOI 10.1109/TCAD.2010.2048354
   Google Inc, 2019, XLA IS COMP OPT TENS
   Gupta Sumit, 2007, SPARK PARALLELIZING
   Harvard Architecture Circuits and Compilers Group., PHOT ANAL APPL SOCS
   Jiang WW, 2020, IEEE T COMPUT AID D, V39, P4805, DOI 10.1109/TCAD.2020.2986127
   Kotsifakou M, 2018, ACM SIGPLAN NOTICES, V53, P68, DOI 10.1145/3200691.3178493
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Lin TR, 2020, INT S HIGH PERF COMP, P99, DOI 10.1109/HPCA47549.2020.00018
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Mantovani P., 2020, P 2020 IEEEACM INT C, P1
   Menghani G., 2021, EFFICIENT DEEP LEARN, P2021
   Mirhoseini A., 2020, ABS200410746 CORR
   MLIR Developers, GPU DIAL
   Moradi S, 2018, IEEE T BIOMED CIRC S, V12, P106, DOI 10.1109/TBCAS.2017.2759700
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Paszke Adam, ARXIV PREPRINT ARXIV
   Pilato C, 2008, J SYST ARCHITECT, V54, P1046, DOI 10.1016/j.sysarc.2008.04.010
   Ragan-Kelley J, 2018, COMMUN ACM, V61, P106, DOI 10.1145/3150211
   Rotem N., 2018, GLOW GRAPH LOWERING
   Shao YS, 2015, IEEE MICRO, V35, P58, DOI 10.1109/MM.2015.50
   Sharifian A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P940, DOI 10.1145/3352460.3358292
   Snyder W, 2003, VERILATOR
   Soldavini Stephanie, ARXIV PREPRINT ARXIV, P2021
   Song Shihao, 2020, 2020 16TH EUROPEAN DEPENDABLE COMPUTING CONFERENCE (EDCC 2020), P17, DOI DOI 10.1109/EDCC51268.2020.00013
   Titirsha Twisha, IEEE T PARALL DISTR, P2021
   Tumeo Antonino, 2020, P IEEE ACM 57 DES AU, P1
   Whatmough P., 2020, IEEE MICRO, P1
   Wu Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P1429, DOI 10.1109/ICCCAS.2002.1179048
   Zhang Jeff, ACM T EMBEDDED COMPU, V18, P1
NR 41
TC 3
Z9 3
U1 0
U2 3
PY 2021
BP 218
EP 225
DI 10.1109/ASAP52443.2021.00040
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Nassar, R
   Brini, E
   Parui, S
   Liu, C
   Dignon, GL
   Dill, KA
AF Nassar, Roy
   Brini, Emiliano
   Parui, Sridip
   Liu, Cong
   Dignon, Gregory L.
   Dill, Ken A.
TI Accelerating Protein Folding Molecular Dynamics Using Inter-Residue
   Distances from Machine Learning Servers
SO JOURNAL OF CHEMICAL THEORY AND COMPUTATION
DT Article
ID PHYSICAL MODELS; SIMULATIONS; PREDICTION; PARAMETERS; ACCURACY; ORDER
AB Recently, predicting the native structures of proteins has become possible using computational molecular physics (CMP)-physics-based force fields sampled with proper statistics-but only for small proteins. Algorithms with better scaling are needed. We describe ML x MELD x MD, a molecular dynamics (MD) method that inputs residue contacts derived from machine learning (ML) servers into MELD, a Bayesian accelerator that preserves detailed-balance statistics. Contacts are derived from trRosetta-predicted distance histograms (distograms) and are integrated into MELD's atomistic MD as spatial restraints through parametrized potential functions. In the CASP14 blind prediction event, ML x MELD x MD predicted 13 native structures to better than 4.5 A error, including for 10 proteins in the range of 115-250 amino acids long. Also, the scaling of simulation time vs protein length is much better than unguided MD: tsim similar to e0.023N for ML x MELD x MD vs tsim similar to e0.168N for MD alone. This shows how machine learning information can be leveraged to advance physics-based modeling of proteins.
C1 [Nassar, Roy; Brini, Emiliano; Parui, Sridip; Liu, Cong; Dignon, Gregory L.] SUNY Stony Brook, Laufer Ctr Phys & Quantitat Biol, Stony Brook, NY 11794 USA.
   [Nassar, Roy; Liu, Cong; Dill, Ken A.] SUNY Stony Brook, Dept Chem, Stony Brook, NY 11794 USA.
   [Dill, Ken A.] SUNY Stony Brook, Dept Phys & Astron, Laufer Ctr Phys & Quantitat Biol, Stony Brook, NY 11794 USA.
RP Dill, KA (corresponding author), SUNY Stony Brook, Dept Chem, Stony Brook, NY 11794 USA.; Dill, KA (corresponding author), SUNY Stony Brook, Dept Phys & Astron, Laufer Ctr Phys & Quantitat Biol, Stony Brook, NY 11794 USA.
EM dill@laufercenter.org
CR Adhikari U, 2019, J AM CHEM SOC, V141, P6519, DOI 10.1021/jacs.8b10735
   [Anonymous], CASP14
   Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754
   BERMAN AL, 1994, P NATL ACAD SCI USA, V91, P4044, DOI 10.1073/pnas.91.9.4044
   Brini E, 2020, SCIENCE, V370, P1056, DOI 10.1126/science.aaz3041
   Freddolino PL, 2010, NAT PHYS, V6, P751, DOI 10.1038/NPHYS1713
   Nguyen H, 2014, J AM CHEM SOC, V136, P13959, DOI 10.1021/ja5032776
   Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Lindorff-Larsen K, 2011, SCIENCE, V334, P517, DOI 10.1126/science.1208351
   MacCallum JL, 2015, P NATL ACAD SCI USA, V112, P6985, DOI 10.1073/pnas.1506788112
   Maier JA, 2015, J CHEM THEORY COMPUT, V11, P3696, DOI 10.1021/acs.jctc.5b00255
   Nguyen H, 2013, J CHEM THEORY COMPUT, V9, P2020, DOI 10.1021/ct3010485
   Pan AC, 2016, J CHEM THEORY COMPUT, V12, P1360, DOI 10.1021/acs.jctc.5b00913
   Perez A, 2017, WIRES COMPUT MOL SCI, V7, DOI 10.1002/wcms.1309
   Perez A, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1601274
   Perez A, 2016, CURR OPIN STRUC BIOL, V36, P25, DOI 10.1016/j.sbi.2015.12.002
   Perez A, 2015, P NATL ACAD SCI USA, V112, P11846, DOI 10.1073/pnas.1515561112
   Piana S, 2014, CURR OPIN STRUC BIOL, V24, P98, DOI 10.1016/j.sbi.2013.12.006
   Robertson JC, 2018, J CHEM THEORY COMPUT, V14, P6734, DOI 10.1021/acs.jctc.8b00886
   Sanyal T, 2019, J CHEM PHYS, V151, DOI 10.1063/1.5108761
   Schlick T, 2021, ANNU REV BIOPHYS, V50, P267, DOI 10.1146/annurev-biophys-091720-102019
   Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7
   Shaw DE, 2010, SCIENCE, V330, P341, DOI 10.1126/science.1187409
   Sugita Y, 1999, CHEM PHYS LETT, V314, P141, DOI 10.1016/S0009-2614(99)01123-9
   Wang L, 2015, J AM CHEM SOC, V137, P2695, DOI 10.1021/ja512751q
   Xu D, 1998, FOLD DES, V3, P11, DOI 10.1016/S1359-0278(98)00004-2
   Xu JB, 2019, P NATL ACAD SCI USA, V116, P16856, DOI 10.1073/pnas.1821309116
   Xu JR, 2010, BIOINFORMATICS, V26, P889, DOI 10.1093/bioinformatics/btq066
   Yang JY, 2020, P NATL ACAD SCI USA, V117, P1496, DOI 10.1073/pnas.1914677117
   Zhang Y, 2004, PROTEINS, V57, P702, DOI 10.1002/prot.20264
   Zuckerman DM, 2011, ANNU REV BIOPHYS, V40, P41, DOI 10.1146/annurev-biophys-042910-155255
NR 32
TC 5
Z9 5
U1 2
U2 11
PD MAR 8
PY 2022
VL 18
IS 3
BP 1929
EP 1935
DI 10.1021/acs.jctc.1c00916
WC Chemistry, Physical; Physics, Atomic, Molecular & Chemical
DA 2023-11-11
ER

PT C
AU Sharma, P
   Jadhao, V
AF Sharma, Prateek
   Jadhao, Vikram
BE Ardagna, CA
   Chang, C
   Daminai, E
   Ranjan, R
   Wang, Z
   Ward, R
   Zhang, J
   Zhang, W
TI Molecular Dynamics Simulations on Cloud Computing and Machine Learning
   Platforms
SO 2021 IEEE 14TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD 2021)
SE IEEE International Conference on Cloud Computing
DT Proceedings Paper
CT IEEE 14th International Conference on Cloud Computing (CLOUD)
CY SEP 05-10, 2021
CL ELECTR NETWORK
AB Scientific computing applications have benefited greatly from high performance computing infrastructure such as supercomputers. However, we are seeing a paradigm shift in the computational structure, design, and requirements of these applications. Increasingly, data-driven and machine learning approaches are being used to support, speed-up, and enhance scientific computing applications, especially molecular dynamics simulations. Concurrently, cloud computing platforms are increasingly appealing for scientific computing, providing 'infinite" computing powers, easier programming and deployment models, and access to computing accelerators such as TPUs (Tensor Processing Units). This confluence of machine learning (ML) and cloud computing represents exciting opportunities for cloud and systems researchers. NIL-assisted molecular dynamics simulations are a new class of workload, and exhibit unique computational patterns. These simulations present new challenges for low-cost and high-performance execution. We argue that transient cloud resources, such as low-cost preemptible cloud VMs, can be a viable platform for this new workload. Finally, we present some low-hanging fruits and long-term challenges in cloud resource management, and the integration of molecular dynamics simulations into ML platforms (such as TensorFlow).
C1 [Sharma, Prateek; Jadhao, Vikram] Indiana Univ, Bloomington, IN 47405 USA.
RP Sharma, P (corresponding author), Indiana Univ, Bloomington, IN 47405 USA.
EM prateeks@iu.edu; vjadhao@iu.edu
CR Anderson JA, 2020, COMP MATER SCI, V173, DOI 10.1016/j.commatsci.2019.109363
   Anousheh N, 2020, AIP ADV, V10, DOI 10.1063/5.0028003
   Barrett R., 2020, J OPEN SOURCE SOFTW, V5, P2367, DOI [10.21105/joss.02367, DOI 10.21105/JOSS.02367]
   Casalino Lorenzo, 2020, bioRxiv, DOI 10.1101/2020.06.11.146522
   Doerr S, 2021, J CHEM THEORY COMPUT, V17, P2355, DOI 10.1021/acs.jctc.0c01343
   Ewen JP, 2018, FRICTION, V6, P349, DOI 10.1007/s40544-018-0207-9
   Ferguson AL, 2018, J PHYS-CONDENS MAT, V30, DOI 10.1088/1361-648X/aa98bd
   Gao X, 2020, J CHEM INF MODEL, V60, P3408, DOI 10.1021/acs.jcim.0c00451
   Hagan MF, 2016, CURR OPIN VIROL, V18, P36, DOI 10.1016/j.coviro.2016.02.012
   Häse F, 2019, CHEM SCI, V10, P2298, DOI 10.1039/c8sc04516j
   Kadupitige J. C. S., 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P41, DOI 10.1145/3369583.3392671
   Kadupitiya J., 2021, PHYS REV RES
   Kadupitiya JCS, 2021, TRIBOL LETT, V69, DOI 10.1007/s11249-021-01457-3
   Kadupitiya JCS, 2020, J COMPUT SCI-NETH, V42, DOI 10.1016/j.jocs.2020.101107
   Kadupitiya JCS, 2020, INT J HIGH PERFORM C, V34, P357, DOI 10.1177/1094342019899457
   Kadupitiya JCS, 2019, LECT NOTES COMPUT SC, V11537, P116, DOI 10.1007/978-3-030-22741-8_9
   Marson RL, 2015, MRS COMMUN, V5, P397, DOI 10.1557/mrc.2015.54
   Moradzadeh A, 2019, J PHYS CHEM LETT, V10, P7568, DOI 10.1021/acs.jpclett.9b02820
   Netto MAS, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150224
   PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039
   Schoenholz S. S., 2020, ADV NEURAL INFORM PR, V33, P11428
   Sun YZS, 2019, CHEM SCI, V10, P4377, DOI 10.1039/c8sc05340e
   Wang J, 2019, ACS CENTRAL SCI, V5, P755, DOI 10.1021/acscentsci.8b00913
   Yao K, 2018, CHEM SCI, V9, P2261, DOI 10.1039/c7sc04934j
NR 24
TC 4
Z9 5
U1 1
U2 2
PY 2021
BP 751
EP 753
DI 10.1109/CLOUD53861.2021.00101
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Scheinker, A
   Huang, EC
   Taylor, C
AF Scheinker, Alexander
   Huang, En-Chuan
   Taylor, Charles
TI Extremum Seeking-Based Control System for Particle Accelerator Beam Loss
   Minimization
SO IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY
DT Article
DE Particle beams; Loss measurement; Tuning; Radio frequency; Particle beam
   measurements; Magnetic hysteresis; Neutrons; Adaptive control; extremum
   seeking (ES); model-independent control; optimization; particle
   accelerator control; time-varying systems
ID ITERATIVE LEARNING CONTROL; STABILITY; FEEDBACK
AB Particle accelerators throughout the world vary widely in terms of age and availability of advanced noninvasive diagnostics that provide varying levels of detail about the accelerated beams. Beam loss measurements and current monitors are ubiquitous in the accelerator community, they are noninvasive, and they are some of the most important metrics in terms of preventing damage or irradiation of beam pipes and equipment for high-energy machines. However, beam loss and current measurements are difficult to use for feedback tuning because of a lack of a known analytic relationship between scalar loss measurements throughout an accelerator and the hundreds of thousands of parameters that influence the beam and time variation of the beam source itself. In this work, we present a model-independent extremum seeking (ES) controller, which has been implemented for automated tuning and optimization of the Los Alamos Neutron Science Center (LANSCE) linear ion accelerator based only on scalar quantities, such as beam loss or flux measurements. We demonstrate the approach on various accelerator subsystems, including groups of radio frequency (RF) accelerating cavities, quadrupole magnets, bending magnets, and steering magnets. This tool is now available as a use graphical user interface (GUI) in the LANSCE control room, allowing beam physicists to choose arbitrary groups of parameters and beam loss or current monitors for adaptive tuning.
C1 [Scheinker, Alexander; Huang, En-Chuan; Taylor, Charles] Los Alamos Natl Lab, Appl Electrodynam Grp, Los Alamos, NM 87545 USA.
RP Scheinker, A (corresponding author), Los Alamos Natl Lab, Appl Electrodynam Grp, Los Alamos, NM 87545 USA.
EM ascheink@lanl.gov; en-chuan@lanl.gov; cetaylor@lanl.gov
CR Abdelgalil M., 2020, ARXIV
   [Anonymous], EXTREMUM SEEKING OPT
   Benosman M, 2019, INT J ADAPT CONTROL, V33, P335, DOI 10.1002/acs.2892
   Bolder J, 2015, IEEE T CONTR SYST T, V23, P722, DOI 10.1109/TCST.2014.2327578
   DALESIO LR, 1994, NUCL INSTRUM METH A, V352, P179, DOI 10.1016/0168-9002(94)91493-1
   Grushkovskaya V, 2021, INT J ADAPT CONTROL, V35, P1233, DOI 10.1002/acs.3152
   Grushkovskaya V, 2018, AUTOMATICA, V94, P151, DOI 10.1016/j.automatica.2018.04.024
   Guay M, 2021, INT J ADAPT CONTROL, V35, P1188, DOI 10.1002/acs.3123
   Guay M, 2018, AUTOMATICA, V93, P498, DOI 10.1016/j.automatica.2018.03.081
   Guay M, 2017, AUTOMATICA, V77, P61, DOI 10.1016/j.automatica.2016.11.018
   Han WH, 2020, IEEE T SYST MAN CY-S, V50, P707, DOI 10.1109/TSMC.2017.2714198
   Jackson J.D., 1975, ELECTRODYNAMICS, VSecond Edition
   Krstic M, 2000, AUTOMATICA, V36, P595, DOI 10.1016/S0005-1098(99)00183-1
   Lu XL, 2021, IEEE T CONTR SYST T, V29, P961, DOI 10.1109/TCST.2020.2982353
   Michalowsky Simon, 2017, 2017 IEEE 56th Annual Conference on Decision and Control (CDC), P2095, DOI 10.1109/CDC.2017.8263956
   Mills G, 2018, IEEE T AUTOMAT CONTR, V63, P3232, DOI 10.1109/TAC.2018.2809503
   Neumann-Brosig M, 2020, IEEE T CONTR SYST T, V28, P730, DOI 10.1109/TCST.2018.2886159
   Poveda JI, 2017, IFAC PAPERSONLINE, V50, P735, DOI 10.1016/j.ifacol.2017.08.240
   Rezaeizadeh A, 2018, IEEE T CONTR SYST T, V26, P1567, DOI 10.1109/TCST.2017.2727439
   Rybarcyk L. J., 2012, P 52 ICFA ADV BEAM D
   Scheinker A., 2017, P 2017 N AM PART ACC
   Scheinker A, 2018, IEEE T CONTR SYST T, V26, P336, DOI 10.1109/TCST.2017.2664728
   Scheinker A, 2017, IEEE T CONTR SYST T, V25, P1521, DOI 10.1109/TCST.2016.2604742
   Scheinker A, 2016, AUTOMATICA, V69, P250, DOI 10.1016/j.automatica.2016.02.023
   Scheinker A, 2014, SYST CONTROL LETT, V63, P25, DOI 10.1016/j.sysconle.2013.10.004
   Scheinker A, 2014, IEEE T CONTR SYST T, V22, P34, DOI 10.1109/TCST.2013.2240387
   Scheinker A, 2014, J DYN SYST-T ASME, V136, DOI 10.1115/1.4025457
   Scheinker A, 2013, P AMER CONTR CONF, P2637
   Scheinker A, 2013, IEEE T AUTOMAT CONTR, V58, P1107, DOI 10.1109/TAC.2012.2225514
   Schexnider AJ, 2013, PHILANTH EDUC, P1, DOI 10.1057/9781137323460
   SLATER JC, 1946, REV MOD PHYS, V18, P441, DOI 10.1103/RevModPhys.18.441
   Suttner R, 2019, AUTOMATICA, V101, P214, DOI 10.1016/j.automatica.2018.11.055
   Tan Y, 2006, AUTOMATICA, V42, P889, DOI 10.1016/j.automatica.2006.01.014
   Vandermeulen I, 2018, IEEE T CONTR SYST T, V26, P857, DOI 10.1109/TCST.2017.2692742
   Wangler TP., 2008, LINEAR ACCELERATORS, V2nd
   Yu H, 2021, J DYN SYST-T ASME, V143, DOI 10.1115/1.4048781
   Zhang XJ, 2021, IEEE T CONTR SYST T, V29, P972, DOI 10.1109/TCST.2019.2949540
   Zheng Y, 2018, IEEE T CONTR SYST T, V26, P1028, DOI 10.1109/TCST.2017.2692739
NR 38
TC 3
Z9 3
U1 0
U2 3
PD SEP
PY 2022
VL 30
IS 5
BP 2261
EP 2268
DI 10.1109/TCST.2021.3136133
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nguyen, MH
   Lai, YK
AF Manh-Hung Nguyen
   Lai, Yu-Kuen
GP IEEE
TI Implement a Continuous Learning Model to Detect Different Types of DDoS
   Attacks with Hierarchical Temporal Memory
SO PROCEEDINGS OF 2022 ASIA-PACIFIC SIGNAL AND INFORMATION PROCESSING
   ASSOCIATION ANNUAL SUMMIT AND CONFERENCE (APSIPA ASC)
SE Asia-Pacific Signal and Information Processing Association Annual Summit
   and Conference
DT Proceedings Paper
CT 14th Annual Summit and Conference of the
   Asia-Pacific-Signal-and-Information-Processing-Association (APSIPA ASC)
CY NOV 07-10, 2022
CL Chiang Mai, THAILAND
AB This paper presents a machine learning model developed based on Hierarchical Temporal Memory to detect DDoS attacks. The model can support continuous learning, which can allow the model to update new attack patterns in real time. We also design a mechanism to evaluate the confidence score for each classification to detect uncertain patterns for deeper analysis by traffic engineers. Furthermore, the model uses features of packet length distribution and inter-arrival time, which can be extracted with FPGA accelerators for a high-speed network, to classify different types of attacks. Finally, we use the CICDDoS 2019 dataset in our experiments to evaluate the performance and achieve a good result.
C1 [Manh-Hung Nguyen; Lai, Yu-Kuen] Chung Yuan Christian Univ, Dept Elect Engn, Chungli, Taiwan.
RP Nguyen, MH (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, Chungli, Taiwan.
EM hungnguyen@cnsrl.cycu.edu.tw; ylai@cnsrl.cycu.edu.tw
CR Ahmad Subutai, PROPERTIES SPARSE DI, P18
   Ahmed ME, 2019, IEEE T INF FOREN SEC, V14, P1471, DOI 10.1109/TIFS.2018.2879616
   Barua A, 2022, IEEE T DEPEND SECURE, V19, P1770, DOI 10.1109/TDSC.2020.3037054
   Constantinides C, 2019, INT CONF NEW TECHNOL, DOI 10.1109/ntms.2019.8763842
   Cui YW, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00111
   Cui YW, 2016, NEURAL COMPUT, V28, P2474, DOI 10.1162/NECO_a_00893
   Fontugne R., 2010, ACM CONEXT 10
   Hawkins, 2021, THOUSAND BRAINS NEW
   Hawkins J, 2017, FRONT NEURAL CIRCUIT, V11, DOI 10.3389/fncir.2017.00081
   Lai YK, 2020, ASIAPAC SIGN INFO PR, P1566
   Nguyen Manh Hung, 1948, 2021 ASIAPACIFIC SIG, P1942
   Shieh CS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11115213
   Viegas E, 2019, FUTURE GENER COMP SY, V93, P473, DOI 10.1016/j.future.2018.09.051
   Xu BH, 2017, INT CONF SOFTW ENG, P712, DOI 10.1109/ICSESS.2017.8343013
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1780
EP 1785
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Telecommunications
DA 2023-11-11
ER

PT J
AU Kala, S
   Nalesh, S
AF Kala, S.
   Nalesh, S.
TI Efficient CNN Accelerator on FPGA
SO IETE JOURNAL OF RESEARCH
DT Article
DE Convolutional neural networks; deep learning; FPGA; hardware
   accelerator; Winograd algorithm
AB Convolutional neural networks (CNNs) are classical models for computer vision and machine learning applications such as video surveillance, pattern recognition, weather forecasting, traffic, and safety. CNNs involve computationally intensive operations and require huge off-chip memory bandwidth, which makes it a challenging task to deploy on real-time embedded systems. Compared to central processing units and graphic processing units, field programmable gate arrays (FPGA)-based CNNs are gaining popularity owing to their flexibility and efficiency. In this work, we present an efficient CNN accelerator based on blocked Winograd-GEMM architecture with high performance. We implement ResNet-18 CNN model on XC7VX690T FPGA using proposed architecture. This implementation operates at a clock frequency of 200 MHz and gives average throughput of 383 GOPS which is comparable to other state-of-art implementations. This manuscript is an extended version of [S. Kala, J. Mathew, B. R. Jose, and S. Nalesh, "UniWiG: Unified Winograd-GEMM Architecture for Accelerating CNN on FPGAs," in2019 32nd International Conference on VLSI Design and 2019 18th International Conference on Embedded Systems (VLSID), Delhi, NCR, India, 2019, pp. 209-214. DOI: 10.1109/VLSID.2019.00055.].
C1 [Kala, S.] Indian Inst Informat Technol Kottayam, Dept Elect & Commun Engn, Kottayam, Kerala, India.
   [Nalesh, S.] Cochin Univ Sci & Technol, Dept Elect, Cochin, Kerala, India.
RP Kala, S (corresponding author), Indian Inst Informat Technol Kottayam, Dept Elect & Commun Engn, Kottayam, Kerala, India.
EM kala@iiitkottayam.ac.in; nalesh@cusat.ac.in
CR Abtahi T., 2017, 2017 IEEE INT S CIRC, P1
   Baskin C, 2018, IEEE SYM PARA DISTR, P162, DOI 10.1109/IPDPSW.2018.00032
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kala S, 2019, IEEE T VLSI SYST, V27, P2816, DOI 10.1109/TVLSI.2019.2941250
   Kala S, 2019, I CONF VLSI DESIGN, P209, DOI 10.1109/VLSID.2019.00055
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LI HM, 2016, I C FIELD PROG LOGIC
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Lu H, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240855
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2017, IEEE INT SYMP CIRC S, P456
   Mathieu Michael, 2014, 2 INT C LEARN REPR
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Shen JW, 2020, INT J DIGIT EARTH, V13, P429, DOI 10.1080/17538947.2018.1523958
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Yu JC, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P227, DOI 10.1109/FPT.2017.8280147
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
NR 23
TC 8
Z9 12
U1 4
U2 59
PD NOV 1
PY 2020
VL 66
IS 6
SI SI
BP 733
EP 740
DI 10.1080/03772063.2020.1821797
EA SEP 2020
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Gao, WL
   Yu, CX
   Chen, RY
AF Gao, Weilu
   Yu, Cunxi
   Chen, Ruiyang
TI Artificial Intelligence Accelerators Based on Graphene Optoelectronic
   Devices
SO ADVANCED PHOTONICS RESEARCH
DT Article
DE artificial intelligence hardware accelerators; graphene; photodetectors;
   spatial light modulators
AB Optical and optoelectronic approaches of performing matrix-vector multiplication (MVM) operations have shown the great promise of accelerating machine learning (ML) algorithms with unprecedented performance. The incorporation of nanomaterials into the system can further improve the device and system performance thanks to their extraordinary properties, but the nonuniformity and variation of nanostructures in the macroscopic scale pose severe limitations for large-scale hardware deployment. Here, a new optoelectronic architecture is presented, consisting of spatial light modulators and tunable responsivity photodetector arrays made from graphene to perform MVM. The ultrahigh carrier mobility of graphene, high-power-efficiency electro-optic control, and extreme parallelism suggest ultrahigh data throughput and ultralow energy consumption. Moreover, a methodology of performing accurate calculations with imperfect components is developed, laying the foundation for scalable systems. Finally, a few representative ML algorithms are demonstrated, including singular value decomposition, support vector machine, and deep neural networks, to show the versatility and generality of the platform.
C1 [Gao, Weilu; Yu, Cunxi; Chen, Ruiyang] Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
RP Gao, WL (corresponding author), Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
EM weilu.gao@utah.edu
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Anzi L, 2018, 2D MATER, V5, DOI 10.1088/2053-1583/aaab96
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Banszerus L, 2015, SCI ADV, V1, DOI 10.1126/sciadv.1500222
   BARTANA I, 1995, OPT LETT, V20, P303, DOI 10.1364/OL.20.000303
   Beletic J. W., 2008, HIGH ENERGY OPTICAL, V7021
   Cakmakyapan S, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0020-2
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   DUNNING GJ, 1991, OPT LETT, V16, P928, DOI 10.1364/OL.16.000928
   Ebbesen TW, 1998, NATURE, V391, P667, DOI 10.1038/35570
   Fan KB, 2017, OPT EXPRESS, V25, P25318, DOI 10.1364/OE.25.025318
   Gao WL, 2014, NANO LETT, V14, P1242, DOI 10.1021/nl4041274
   Gao WL, 2012, ACS NANO, V6, P7806, DOI 10.1021/nn301888e
   Garcia-Vidal FJ, 2010, REV MOD PHYS, V82, P729, DOI 10.1103/RevModPhys.82.729
   Ghosh DS, 2009, OPT LETT, V34, P325, DOI 10.1364/OL.34.000325
   Gong Y., 2021, NANOPHOTONICS-BERLIN, V1
   GOODMAN JW, 1978, OPT LETT, V2, P1, DOI 10.1364/OL.2.000001
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Inoue T, 2016, OPT EXPRESS, V24, P15101, DOI 10.1364/OE.24.015101
   Jafari B, 2019, APPL OPTICS, V58, P6280, DOI 10.1364/AO.58.006280
   Kim S, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10146
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li SQ, 2019, SCIENCE, V364, P1087, DOI 10.1126/science.aaw6747
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Lin YM, 2009, NANO LETT, V9, P422, DOI 10.1021/nl803316h
   Liu HT, 2008, NATURE, V452, P728, DOI 10.1038/nature06762
   LU TW, 1989, APPL OPTICS, V28, P4908, DOI 10.1364/AO.28.004908
   Mizaikoff B, 2013, CHEM SOC REV, V42, P8683, DOI 10.1039/c3cs60173k
   Nandakumar SR, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351656
   Peng C, 2019, OPT EXPRESS, V27, P30669, DOI 10.1364/OE.27.030669
   Pierangeli D, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.213902
   PSALTIS D, 1985, OPT LETT, V10, P98, DOI 10.1364/OL.10.000098
   Qiu CY, 2015, OPT LETT, V40, P4480, DOI 10.1364/OL.40.004480
   Qiu CY, 2012, SCI REP-UK, V2, DOI 10.1038/srep00855
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Saade A, 2016, INT CONF ACOUST SPEE, P6215, DOI 10.1109/ICASSP.2016.7472872
   Schlottmann CR, 2011, IEEE J EM SEL TOP C, V1, P403, DOI 10.1109/JETCAS.2011.2165755
   Sharma T, 2016, 2016 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON BRINGING ARCHITECTURAL DESIGN THINKING INTO DEVELOPERS DAILY ACTIVITIES (BRIDGE), P1, DOI [10.1145/2896935.2896938, 10.1109/Bridge.2016.009]
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Shu J, 2014, OPT EXPRESS, V22, P3747, DOI 10.1364/OE.22.003747
   Sitzmann V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201333
   Spall J, 2020, OPT LETT, V45, P5752, DOI 10.1364/OL.401675
   Vollmer M., 2017, INFRARED THERMAL IMA
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Wu ZC, 2004, SCIENCE, V305, P1273, DOI 10.1126/science.1101243
   Xie LJ, 2015, SCI REP-UK, V5, DOI 10.1038/srep08671
   Yao Y, 2014, NANO LETT, V14, P6526, DOI 10.1021/nl503104n
   Zhang C, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P161, DOI 10.1109/SPAWDA.2015.7364463
NR 54
TC 7
Z9 7
U1 1
U2 3
PD JUN
PY 2021
VL 2
IS 6
AR 2100048
DI 10.1002/adpr.202100048
WC Materials Science, Multidisciplinary; Optics
DA 2023-11-11
ER

PT J
AU Li, JJ
   Zheng, H
   Wang, K
   Louri, A
AF Li, Jiajun
   Zheng, Hao
   Wang, Ke
   Louri, Ahmed
TI SGCNAX: A Scalable Graph Convolutional Neural Network Accelerator With
   Workload Balancing
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Random access memory; Optimization; Engines; Registers; Neural networks;
   Computational modeling; Accelerator architectures; Graph convolutional
   neural networks; dataflow accelerators; domain-specific accelerators;
   memory access optimization
AB Convolutional Neural Networks (GCNs) have emerged as promising tools for graph-based machine learning applications. Given that GCNs are both compute- and memory-intensive, this constitutes a major challenge for the underlying hardware to efficiently process large-scale GCNs. In this article, we introduce SGCNAX, a scalable GCN accelerator architecture for the high-performance and energy-efficient acceleration of GCNs. Unlike prior GCN accelerators that either employ limited loop optimization techniques, or determine the design variables based on random sampling, we systematically explore the loop optimization techniques for GCN acceleration and propose a flexible GCN dataflow that adapts to different GCN configurations to achieve optimal efficiency. We further propose two hardware-based techniques to address the workload imbalance problem caused by the unbalanced distribution of zeros in GCNs. Specifically, SGCNAX exploits an outer-product-based computation architecture that mitigates the intra-PE (Processing Elements) workload imbalance, and employs a group-and-shuffle approach to mitigate the inter-PE workload imbalance. Simulation results show that SGCNAX performs 9.2x, 1.6x and 1.2x better, and reduces DRAM accesses by a factor of 9.7x, 2.9x and 1.2x compared to HyGCN, AWB-GCN, and GCNAX, respectively.
C1 [Li, Jiajun; Zheng, Hao; Wang, Ke; Louri, Ahmed] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
RP Li, JJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
EM lijiajun@gwu.edu; haozheng@gwu.edu; cory@gwu.edu; louri@gwu.edu
CR Abdolrashidi A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P600, DOI 10.1145/3123939.3123976
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   ALLEN JR, 1984, SIGPLAN NOTICES, V19, P233, DOI 10.1145/502949.502897
   [Anonymous], 2009, CACTI 60 TOOL UNDERS
   Ao Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P346, DOI 10.1007/978-3-030-58610-2_21
   Auten A, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218751
   Balaji V, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P133, DOI 10.1145/3307681.3326609
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dai GH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P105, DOI 10.1145/2847263.2847339
   Defferrard M, 2016, ADV NEUR IN, V29
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Ham TJ, 2016, INT SYMP MICROARCH
   Hamilton WL, 2017, ADV NEUR IN, V30
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Henaff M., 2015, ARXIV150605163
   Hong SP, 2011, ACM SIGPLAN NOTICES, V46, P267, DOI 10.1145/2038037.1941590
   Horowitz M, 2012, STANFORD VLSI WIKI
   Jiang W., 2021, ARXIV
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kiningham K., 2020, ARXIV200713828
   Lerer A., ARXIV190312287
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Ma XY, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P227, DOI 10.1145/3020078.3021743
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Nie Q., 2020, THESIS PRINCETON U
   Oguntebi T, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P111, DOI 10.1145/2847263.2847337
   Ozdal MM, 2016, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2016.24
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pugh W., 1991, Conference Proceedings. 1991 International Conference on Supercomputing, P341, DOI 10.1145/109025.109108
   SADI F, 2018, IEEE HIGH PERF EXTR, pNI323
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Shi F., 2021, ARXIV210501280
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song TA, 2019, I S BIOMED IMAGING, P414, DOI 10.1109/ISBI.2019.8759531
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1082, DOI 10.1145/3366423.3380186
   Wee CY, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101929
   Welling M., 2016, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yan MY, 2020, IEEE COMPUT ARCHIT L, V19, P22, DOI 10.1109/LCA.2020.2970395
   Yan MY, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P615, DOI 10.1145/3352460.3358318
   Yang DQ, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P711, DOI 10.1109/MICRO50266.2020.00064
   Yang HX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3165, DOI 10.1145/3292500.3340404
   Yang YF, 2020, ANN I S COM, P419, DOI 10.1109/ISCA45697.2020.00043
   Yu Wang, 2019, 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), P136, DOI 10.1109/FCCM.2019.00028
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
   Zhang ZH, 2020, IEEE COMPUT ARCHIT L, V19, P59, DOI 10.1109/LCA.2020.2988991
   Zhang ZW, 2022, IEEE T KNOWL DATA EN, V34, P249, DOI 10.1109/TKDE.2020.2981333
   Zhong JL, 2014, SIGMOD REC, V43, P35
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
NR 61
TC 2
Z9 2
U1 4
U2 20
PD NOV 1
PY 2022
VL 33
IS 11
BP 2834
EP 2845
DI 10.1109/TPDS.2021.3133691
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kumar, AKA
   Gerstlauer, A
AF Kumar, Ajay Krishna Ananda
   Gerstlauer, Andreas
GP IEEE
TI Learning-Based CPU Power Modeling
SO 2019 ACM/IEEE 1ST WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD)
DT Proceedings Paper
CT ACM/IEEE 1st Workshop on Machine Learning for CAD (MLCAD)
CY SEP 03-04, 2019
CL Canmore, CANADA
DE Machine learning; power modeling; micro-architecture simulation
AB With the end of Dennard scaling, energy efficiency has become an important metric driving future processor architectures, particularly in the fields of mobile and embedded devices. To support rapid, power-aware micro-architectural design space exploration, it is important to accurately quantify the power consumption of the processors early in the design flow and at a high level of abstraction. Existing CPU power models rely on either generic analytical power models or simple regression-based techniques that suffer from large inaccuracies. More recently, machine learning techniques have been proposed to build accurate power models. However, existing approaches still require slow RTL simulations or have only been demonstrated for fixed-function accelerators at higher levels.
   In this work, we present a machine learning-based approach for power modeling of programmable CPUs at the microarchitecture level. Our models provide cycle-accurate and hierarchical power estimates down to sub-block granularity. Using only high-level information that can be obtained from microarchitecture simulations, we extract representative features and develop low-complexity learning formulations that require a small number of gate-level simulations for training. Results show that our hierarchically composed model predicts cycle-by-cycle power consumption of RISC-V processor core within 2.2% of a gate-level power estimation on average.
C1 [Kumar, Ajay Krishna Ananda; Gerstlauer, Andreas] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Kumar, AKA (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM ajaykrishna1111@utexas.edu; gerstl@utexas.edu
CR [Anonymous], 2010, FPL
   Bogliolo A, 2000, ACM T DES AUTOMAT EL, V5, P337, DOI 10.1145/348019.348081
   Brooks D, 2003, IBM J RES DEV, V47, P653, DOI 10.1147/rd.475.0653
   Lee D, 2018, ACM T DES AUTOMAT EL, V23, DOI 10.1145/3177865
   Lee W, 2015, I SYMPOS LOW POWER E, P189, DOI 10.1109/ISLPED.2015.7273512
   Park YH, 2011, IEEE T VLSI SYST, V19, P668, DOI 10.1109/TVLSI.2009.2039153
   Rossi D., 2015, 2015 IEEE HOT CHIPS, P1
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Snyder W., 2004, VERILATOR SYSTEMPERL
   Xi S, 2015, INT S HIGH PERF COMP, P577, DOI 10.1109/HPCA.2015.7056064
   Yang JL, 2015, ASIA S PACIF DES AUT, P779, DOI 10.1109/ASPDAC.2015.7059105
   Zhou Y, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI [10.1145/3316781.3317884, 10.23919/eos/esd.2019.8869988]
NR 12
TC 1
Z9 1
U1 0
U2 0
PY 2019
DI 10.1109/mlcad48534.2019.9142100
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Hong, S
   Lee, I
   Park, Y
AF Hong, Seongmin
   Lee, Inho
   Park, Yongjun
GP IEEE
TI NN Compactor: Minimizing Memory and Logic Resources for Small Neural
   Networks
SO PROCEEDINGS OF THE 2018 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 19-23, 2018
CL Dresden, GERMANY
DE Neural networks; Accelerator; Automation; Quantization
AB Special neural accelerators are an appealing hardware platform for machine learning systems because they provide both high performance and energy efficiency. Although various neural accelerators have recently been introduced, they are difficult to adapt to embedded platforms because current neural accelerators require high memory capacity and bandwidth for the fast preparation of synaptic weights. Embedded platforms are often unable to meet these memory requirements because of their limited resources. In FPGA-based IoT (internet of things) systems, the problem becomes even worse since computation units generated from logic blocks cannot be fully utilized due to the small size of block memory. In order to overcome this problem, we propose a novel dual-track quantization technique to reduce synaptic weight width based on the magnitude of the value while minimizing accuracy loss. In this value-adaptive technique, large and small value weights are quantized differently. In this paper, we present a fully automatic framework called NN Compactor that generates a compact neural accelerator by minimizing the memory requirements of synaptic weights through dual-track quantization and minimizing the logic requirements of PUs with minimum recognition accuracy loss. For the three widely used datasets of MNIST, CNAE-9, and Forest, experimental results demonstrate that our compact neural accelerator achieves an average performance improvement of G.4 x over a baseline embedded system using minimal resources with minimal accuracy loss.
C1 [Hong, Seongmin; Lee, Inho] Hongik Univ, Dept Elect & Elect Engn, Seoul, South Korea.
   [Park, Yongjun] Hanyang Univ, Dept Comp Sci, Seoul, South Korea.
RP Hong, S (corresponding author), Hongik Univ, Dept Elect & Elect Engn, Seoul, South Korea.
EM seongminhong@mail.hongik.ac.kr; inholee@mail.hongik.ac.kr;
   yongjunpark@hanyang.ac.kr
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2016, MICRO
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Hannun A., 2014, DEEP SPEECH SCALING
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kung J, 2015, I SYMPOS LOW POWER E, P85, DOI 10.1109/ISLPED.2015.7273495
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
NR 8
TC 4
Z9 4
U1 0
U2 1
PY 2018
BP 581
EP 584
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Smagulova, K
   Fouda, ME
   Kurdahi, F
   Salama, KN
   Eltawil, A
AF Smagulova, Kamilya
   Fouda, Mohammed E.
   Kurdahi, Fadi
   Salama, Khaled N.
   Eltawil, Ahmed
TI Resistive Neural Hardware Accelerators
SO PROCEEDINGS OF THE IEEE
DT Article
DE Compute-in-memory (CIM); deep neural networks (DNNs); hardware
   acceleration; in-memory computing; processing-in-memory; resistive
   random access memory (ReRAM)
ID RRAM DEVICES; MEMORY; DESIGN; NETWORK; ENERGY; RERAM; ARCHITECTURE;
   PERFORMANCE; INFERENCE; ALGORITHM
AB Deep neural networks (DNNs), as a subset of machine learning (ML) techniques, entail that real-world data can be learned, and decisions can be made in real time. However, their wide adoption is hindered by a number of software and hardware limitations. The existing general-purpose hardware platforms used to accelerate DNNs are facing new challenges associated with the growing amount of data and are exponentially increasing the complexity of computations. Emerging nonvolatile memory (NVM) devices and the compute-in-memory (CIM) paradigm are creating a new hardware architecture generation with increased computing and storage capabilities. In particular, the shift toward resistive random access memory (ReRAM)-based in-memory computing has great potential in the implementation of area- and power-efficient inference and in training large-scale neural network architectures. These can accelerate the process of IoT-enabled AI technologies entering our daily lives. In this survey, we review the state-of-the-art ReRAM-based DNN many-core accelerators, and their superiority compared to CMOS counterparts was shown. The review covers different aspects of hardware and software realization of DNN accelerators, their present limitations, and prospects. In particular, a comparison of the accelerators shows the need for the introduction of new performance metrics and benchmarking standards. In addition, the major concerns regarding the efficient design of accelerators include a lack of accuracy in simulation tools for software and hardware codesign.
C1 [Smagulova, Kamilya; Salama, Khaled N.; Eltawil, Ahmed] King Abdullah Univ Sci & Technol, Div Comp Elect & Math Sci & Engn CEMSE, Thuwal 23955, Saudi Arabia.
   [Fouda, Mohammed E.; Kurdahi, Fadi] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
RP Fouda, ME (corresponding author), Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
EM foudam@uci.edu
CR Abbas Z, 2021, GENES-BASEL, V12, DOI 10.3390/genes12020296
   Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   Agyeman, 2017, PROC 2 INT WORKSHOP, P22
   Ahmad Irfan, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P107, DOI 10.1109/ICSSIT48917.2020.9214125
   Al-Mamun M. S., 2020, PRIME ARCH ELECT
   Amer K, 2021, PROC SPIE, V11605, DOI 10.1117/12.2587105
   Ankit A, 2020, IEEE T COMPUT, V69, P1128, DOI 10.1109/TC.2020.2998456
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2011, P IEEE INT EL DEV M, DOI [10.1109/IEDM.2011.6131650, DOI 10.1109/IEDM.2011.6131650]
   [Anonymous], 2009, HP LAB
   [Anonymous], 2016, 2016 12 C PHD RES MI
   [Anonymous], 2013, PROC NVMW
   Azzaz M., 2016, 2016 IEEE 8th International Memory Workshop (IMW), DOI 10.1109/IMW.2016.7495268
   Banerjee W, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9061029
   Banerjee W, 2020, J APPL PHYS, V127, DOI 10.1063/1.5136264
   Bannerjee G., 2018, INT J SCI RES COMP A, V7, P1, DOI DOI 10.15838/ALT.2018.1.4.5
   Barci M, 2015, IEEE INT MEM WORKSH, P189
   Barlow SE, 2020, CURR OPIN INSECT SCI, V38, P15, DOI 10.1016/j.cois.2020.01.008
   Beckmann K, 2020, ACM J EMERG TECH COM, V16, DOI 10.1145/3381859
   Beigi M. V., 2019, THESIS NW U DEP EL E
   Beigi MV, 2020, INT CONFER PARA, P353, DOI 10.1145/3410463.3414672
   Beigi MV, 2018, INT PARALL DISTRIB P, P670, DOI 10.1109/IPDPS.2018.00076
   Bjerregaard T, 2006, ACM COMPUT SURV, V38, P1, DOI 10.1145/1132952.1132953
   Briganti G, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00027
   Butcher B, 2011, INT INTEG REL WRKSP, P146, DOI 10.1109/IIRW.2011.6142611
   Cai Y, 2018, DES AUT CON, DOI 10.1145/3195970.3196071
   Campa C., 2021, DEFINING INNOVATION
   Carta D, 2016, NANOTECHNOLOGY, V27, DOI 10.1088/0957-4484/27/34/345705
   Cha E, 2016, APPL PHYS LETT, V108, DOI 10.1063/1.4945367
   Charan G, 2020, IEEE J EXPLOR SOLID-, V6, P27, DOI 10.1109/JXCDC.2020.2987605
   Chen C., 2014, IEDM, P2
   Chen CY, 2015, IEEE T COMPUT, V64, P180, DOI 10.1109/TC.2014.12
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen PY, 2023, ASIA S PACIF DES AUT, P228, DOI 10.1145/3566097.3567860
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chi P., 2015, 2015001 SEAL LAB
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chiu YC, 2015, S VLSI TECH, DOI 10.1109/VLSIT.2015.7223671
   Chmaj G, 2015, 2015 4TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO), P37, DOI 10.1109/MECO.2015.7181929
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   Dandekar R, 2020, Arxiv, DOI arXiv:2003.09403
   DeOrio A, 2012, IEEE T COMPUT AID D, V31, P726, DOI 10.1109/TCAD.2011.2181509
   Ding YK, 2020, NAT ELECTRON, V3, P514, DOI 10.1038/s41928-020-00476-7
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Fouda ME, 2019, Arxiv, DOI arXiv:1903.01512
   Efnusheva Danijela, 2017, International Journal of Computer Science & Information Technology, V9, P151, DOI 10.5121/ijcsit.2017.9214
   Elsken T, 2019, J MACH LEARN RES, V20
   Eshraghian JK, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P267, DOI [10.1109/aicas.2019.8771550, 10.1109/AICAS.2019.8771550]
   Fan Zhang, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P187, DOI 10.1109/ASP-DAC47756.2020.9045730
   Fantini A., 2014, S VLSI TECHN, P1
   Fari A. I., 2020, J APPL SCI ENV SUSTA, V6, P32
   Fei X, 2021, TSINGHUA SCI TECHNOL, V26, P322, DOI 10.26599/TST.2019.9010070
   Fouda M. E., 2020, MEMRISTIVE DEVICES B, P499
   Fouda M, 2018, NANOARCH'18: PROCEEDINGS OF THE 14TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURES, P31, DOI 10.1145/3232195.3232226
   Fouda ME, 2020, IEEE ACCESS, V8, P228392, DOI 10.1109/ACCESS.2020.3044652
   Fouda ME, 2019, CONF REC ASILOMAR C, P495, DOI [10.1109/IEEECONF44664.2019.9049043, 10.1109/ieeeconf44664.2019.9049043]
   Fouda ME, 2019, IEEE T NANOTECHNOL, V18, P704, DOI 10.1109/TNANO.2019.2927493
   Fouda ME, 2019, IEEE T NANOTECHNOL, V18, P611, DOI 10.1109/TNANO.2018.2880734
   Fouda ME, 2018, IEEE T CIRCUITS-I, V65, P270, DOI 10.1109/TCSI.2017.2714101
   Gao Y, 2019, Arxiv, DOI arXiv:1904.09981
   Giordano Massimo, 2021, 2021 Symposium on VLSI Circuits, DOI 10.23919/VLSICircuits52068.2021.9492347
   google, GOOGL DEM LEAD PERF
   Grossi A, 2019, IEEE T ELECTRON DEV, V66, P1281, DOI 10.1109/TED.2019.2894387
   Guan XM, 2012, IEEE T ELECTRON DEV, V59, P1172, DOI 10.1109/TED.2012.2184545
   Gül F, 2019, RESULTS PHYS, V12, P1091, DOI 10.1016/j.rinp.2018.12.092
   Gupta S, 2019, I SYMPOS LOW POWER E, DOI 10.1109/irps.2019.8720595
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gwennap L., TENSTORRENT SCALES P
   Gwennap L., 2020, MICROPROCESSOR REP
   He ZZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317870
   Hemmati Mohammad Reza, 2018, 2018 International Young Engineers Forum (YEF-ECE). Proceedings, P31, DOI 10.1109/YEF-ECE.2018.8368935
   Houshmand P, 2020, IEDM, P1
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu Yu-Hen, 2012, J ELECTR COMPUT ENG, P1
   Huangfu WQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196098
   Hyung Dong Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P151, DOI 10.1109/VLSIT.2012.6242506
   Jacob I.J., 2019, J ARTIF INTELL, V1, P83, DOI DOI 10.36548/JAICN.2019.2.004
   Jiang Hongwu, 2022, 2022 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits), P266, DOI 10.1109/VLSITechnologyandCir46769.2022.9830211
   Jung G, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1733
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kalimuthu A., 2012, 2012 IEEE INT C COMP, P1
   Károly AI, 2021, IEEE T SYST MAN CY-S, V51, P266, DOI 10.1109/TSMC.2020.3018325
   Khan SH, 2021, PHOTODIAGN PHOTODYN, V35, DOI 10.1016/j.pdpdt.2021.102473
   Kim H, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3145478
   Ko S, 2020, Arxiv, DOI arXiv:2004.04865
   Korenda AR, 2018, INT WIREL COMMUN, P1261, DOI 10.1109/IWCMC.2018.8450341
   Krishnan G, 2022, ACM J EMERG TECH COM, V18, DOI 10.1145/3460233
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumar P, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P276, DOI 10.1109/NOCS.2009.5071477
   Labati RD, 2019, PATTERN RECOGN LETT, V126, P78, DOI 10.1016/j.patrec.2018.03.028
   Lacey D., UPDATED GRAPHCORE IP
   Le BQ, 2019, IEEE T ELECTRON DEV, V66, P641, DOI 10.1109/TED.2018.2879788
   Lee S, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218735
   Li F, 2019, IEEE INT SOC CONF, P359, DOI 10.1109/SOCC46988.2019.1570548234
   Li Y, 2020, J ENG-JOE, V2020, P344, DOI 10.1049/joe.2019.1203
   Liashchynskyi P, 2019, Arxiv, DOI [arXiv:1912.06059, 10.48550/arXiv.1912.06059]
   Lin TR, 2019, Arxiv, DOI arXiv:1905.04423
   Liu CC, 2017, DES AUT CON, DOI 10.1145/3061639.3062310
   Liu MY, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P216, DOI 10.1145/3287624.3288743
   Liu Q., 2020, 2020 57 ACMIEEE DESI, P1
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Lohn AJ, 2014, J APPL PHYS, V115, DOI 10.1063/1.4885045
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Medina E, 2020, IEEE MICRO, V40, P17, DOI 10.1109/MM.2020.2975185
   Meena JS, 2014, NANOSCALE RES LETT, V9, DOI 10.1186/1556-276X-9-526
   Mei LY, 2021, IEEE T COMPUT, V70, P1160, DOI 10.1109/TC.2021.3059962
   Nabavinejad SM, 2020, IEEE J EM SEL TOP C, V10, P268, DOI 10.1109/JETCAS.2020.3022920
   Nag A, 2018, IEEE MICRO, V38, P41, DOI 10.1109/MM.2018.053631140
   Nail C, 2016, INT EL DEVICES MEET
   Onimaru K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235748
   Pan H, 2020, ELECTRON COMMER RES, V20, P297, DOI 10.1007/s10660-020-09409-0
   Payvand M, 2020, IEEE J EM SEL TOP C, V10, P522, DOI 10.1109/JETCAS.2020.3040248
   Payvand M, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P218, DOI [10.1109/aicas48895.2020.9073998, 10.1109/AICAS48895.2020.9073998]
   Marugán AP, 2018, APPL ENERG, V228, P1822, DOI 10.1016/j.apenergy.2018.07.084
   Prakash A, 2015, APPL PHYS LETT, V106, DOI 10.1063/1.4922446
   Prakash A, 2016, PHYS SCI REV, V1, DOI 10.1515/psr-2016-0010
   Prakash A, 2015, IEEE ELECTR DEVICE L, V36, P32, DOI 10.1109/LED.2014.2375200
   Qiao XM, 2018, DES AUT CON, DOI 10.1145/3195970.3195998
   Ramadan M, 2019, MICROELECTRON J, V90, P169, DOI 10.1016/j.mejo.2019.06.004
   Ren C, 2020, J INF PROCESS SYST, V16, P1015, DOI 10.3745/JIPS.04.0187
   Rohan A, 2019, IEEE ACCESS, V7, P69575, DOI 10.1109/ACCESS.2019.2919332
   Roldán JB, 2021, NANOMATERIALS-BASEL, V11, DOI 10.3390/nano11051261
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shamshirband S, 2019, IEEE ACCESS, V7, P164650, DOI 10.1109/ACCESS.2019.2951750
   Sheng X, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800876
   Shin H, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415665
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Spetalnick S. D., 2022, IEEE INT SOL STAT CI, V65, P1
   Staudigl F, 2022, IEEE DES TEST, V39, P90, DOI 10.1109/MDAT.2021.3102013
   Sun PX, 2015, SCI REP-UK, V5, DOI [10.1038/srep13504, 10.1038/srep10001]
   Sze Vivienne, 2020, IEEE Solid-State Circuits Magazine, V12, P28, DOI 10.1109/MSSC.2020.3002140
   Tang S., 2017, NONVOLATILE MEMORY S, P1
   Walczyk C, 2011, IEEE T ELECTRON DEV, V58, P3124, DOI 10.1109/TED.2011.2160265
   Wang HS, 2002, INT SYMP MICROARCH, P294, DOI 10.1109/MICRO.2002.1176258
   Wang YH, 2021, ASIA S PACIF DES AUT, P499, DOI 10.1145/3394885.3431599
   Wei E, 2012, IEEE DECIS CONTR P, P5445, DOI 10.1109/CDC.2012.6425904
   Wei Z, 2008, INT EL DEVICES MEET, P293, DOI 10.1109/IEDM.2008.4796676
   Wilson L., 2013, INT TECHNOLOGY ROADM
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Woo J, 2018, IEEE NANOTECHNOL MAG, V12, P36, DOI 10.1109/MNANO.2018.2844902
   Wu YH, 2016, Arxiv, DOI arXiv:1609.08144
   Xia LX, 2018, IEEE J EM SEL TOP C, V8, P102, DOI 10.1109/JETCAS.2017.2776980
   Xia LX, 2017, DES AUT CON, DOI 10.1145/3061639.3062248
   Xie XF, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3417709
   Xu C, 2015, INT S HIGH PERF COMP, P476, DOI 10.1109/HPCA.2015.7056056
   Xu C, 2014, ASIA S PACIF DES AUT, P825, DOI 10.1109/ASPDAC.2014.6742992
   Xu C, 2013, DES AUT CON
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Xue CX, 2020, IEEE J SOLID-ST CIRC, V55, P203, DOI 10.1109/JSSC.2019.2951363
   Yasuda S, 2017, S VLSI TECH, pT30, DOI 10.23919/VLSIT.2017.7998189
   Yazdinejad A, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106630
   Yoon J.-H., IEEE INT SOLID STATE
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Yuan G, 2021, CONF PROC INT SYMP C, P265, DOI 10.1109/ISCA52012.2021.00029
   Yuzong Chen, 2021, IEEE Open Journal of Circuits and Systems, V2, P210, DOI 10.1109/OJCAS.2020.3042550
   Zahoor F, 2020, NANOSCALE RES LETT, V15, DOI 10.1186/s11671-020-03299-9
   Zangeneh M, 2014, IEEE T VLSI SYST, V22, P1815, DOI 10.1109/TVLSI.2013.2277715
   Zhang BG, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P438, DOI 10.1145/3287624.3287707
   Zhang L., 2014, IEDM, P6
   Zhang WQ, 2020, NAT ELECTRON, V3, P371, DOI 10.1038/s41928-020-0435-7
   Zhu LG, 2015, J MATERIOMICS, V1, P285, DOI 10.1016/j.jmat.2015.07.009
NR 163
TC 0
Z9 0
U1 9
U2 9
PD MAY
PY 2023
VL 111
IS 5
BP 500
EP 527
DI 10.1109/JPROC.2023.3268092
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, GW
   Attaluri, N
   Emer, JS
   Sanchez, D
AF Zhang, Guowei
   Attaluri, Nithya
   Emer, Joel S.
   Sanchez, Daniel
GP Assoc Comp Machinery
TI GAMMA: Leveraging Gustayson's Algorithm to Accelerate Sparse Matrix
   Multiplication
SO ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL
   SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 26th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY APR 12-23, 2021
CL ELECTR NETWORK
DE sparse matrix multiplication; sparse linear algebra; accelerator;
   Gustavson's algorithm; high-radix merge; explicit data orchestration;
   data movement reduction
AB Sparse matrix-sparse matrix multiplication (sPMsPM) is at the heart of a wide range of scientific and machine learning applications. sPMsPM is inefficient on general-purpose architectures, making accelerators attractive. However, prior sPMsPM accelerators use inner- or outer-product dataflows that suffer poor input or output reuse, leading to high traffic and poor performance. These prior accelerators have not explored Gustayson's algorithm, an alternative sPMsPM dataflow that does not suffer from these problems but features irregular memory access patterns that prior accelerators do not support.
   We present GAMMA, an sPMsPM accelerator that uses Gustayson's algorithm to address the challenges of prior work. GAMMA performs spMspM's computation using specialized processing elements with simple high-radix mergers, and performs many merges in parallel to achieve high throughput. GAMMA uses a novel on-chip storage structure that combines features of both caches and explicitly managed buffers. This structure captures Gustayson's irregular reuse patterns and streams thousands of concurrent sparse fibers (i.e., lists of coordinates and values for rows or columns) with explicitly decoupled data movement. GAMMA features a new dynamic scheduling algorithm to achieve high utilization despite irregularity. We also present new preprocessing algorithms that boost GAMMA'S efficiency and versatility. As a result, GAMMA outperforms prior accelerators by gmean 2.1x, and reduces memory traffic by gmean 2.2x and by up to 13x.
C1 [Zhang, Guowei; Attaluri, Nithya; Emer, Joel S.; Sanchez, Daniel] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Zhang, GW (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM zhanggw@csail.mit.edu; nsattaluri@csail.mit.edu; emer@csail.mit.edu;
   sanchez@csail.mit.edu
CR [Anonymous], 2004, P 15 ANN ACM SIAM S
   [Anonymous], 1999, P ACM IEEE C SUP SC9
   [Anonymous], 2016, NIPS
   [Anonymous], 2010, GPU TECHNOLOGY C
   Azad A, 2016, SIAM J SCI COMPUT, V38, pC624, DOI 10.1137/15M104253X
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Ballard Grey, 2016, ACM T PARALLEL COMPU, V3
   Bell N, 2012, SIAM J SCI COMPUT, V34, pC123, DOI 10.1137/110838844
   Canning A, 1996, COMPUT PHYS COMMUN, V94, P89, DOI 10.1016/0010-4655(96)00009-4
   Chan TM, 2010, SIAM J COMPUT, V39, P2075, DOI 10.1137/08071990X
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chierichetti F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P219
   Chou S, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P823, DOI 10.1145/3385412.3385963
   CliffordWolf Johann Glaser, 2012, P 21 AUSTRIANWORKSHO
   Cuthill E., 1969, P 1969 24 NATL C, P157, DOI 10.1145/800195.805928
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Dhulipala L, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1535, DOI 10.1145/2939672.2939862
   Dongen S, 2000, NATL RES I MATH COMP
   Emer J. S., 2020, SYNTHESIS LECT COMPU
   Gilbert JR, 2007, LECT NOTES COMPUT SC, V4699, P260
   GILBERT JR, 1992, SIAM J MATRIX ANAL A, V13, P333, DOI 10.1137/0613024
   Gustavson F. G., 1978, ACM Transactions on Mathematical Software, V4, P250, DOI 10.1145/355791.355796
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hong CW, 2019, PROCEEDINGS OF THE 24TH SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '19), P300, DOI 10.1145/3293883.3295712
   Jaleel Aamer, 2010, P 37 ANN INT S COMPU
   Jiang P, 2020, PROCEEDINGS OF THE 25TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '20), P376, DOI 10.1145/3332466.3374546
   Kanellopoulos K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P600, DOI 10.1145/3352460.3358286
   Kaplan H., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P52, DOI 10.1145/1137856.1137866
   Karypis G., 1994, Proceedings Supercomputing '94 (Cat. No.94CH34819), P204, DOI 10.1109/SUPERC.1994.344280
   Kepner J, 2015, PROCEDIA COMPUT SCI, V51, P2453, DOI 10.1016/j.procs.2015.05.353
   Kjolstad F, 2019, INT SYM CODE GENER, P180, DOI [10.1109/CGO.2019.8661185, 10.1109/cgo.2019.8661185]
   Kjolstad Fredrik, 2018, P ACM SIGPLAN C OBJE
   Kolodziej SP., 2019, J OPEN SOURCE SOFTW, V4, P1244, DOI [10.21105/joss.01244, DOI 10.21105/JOSS.01244]
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Mukkara Anurag, 2019, P 52 ANN IEEEACM INT
   Nagasaka Y, 2018, INT CONF PARA PROC, DOI 10.1145/3229710.3229720
   Nangate S., 2008, CALIFORNIA 2008 45NM
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pellauer M, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P137, DOI 10.1145/3297858.3304025
   Penn G, 2006, THEOR COMPUT SCI, V354, P72, DOI 10.1016/j.tcs.2005.11.008
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   RABIN MO, 1989, J ALGORITHM, V10, P557, DOI 10.1016/0196-6774(89)90005-9
   Sadi F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P347, DOI 10.1145/3352460.3358330
   Sewell K, 2012, IEEE J EM SEL TOP C, V2, P278, DOI 10.1109/JETCAS.2012.2193936
   Song H., 2016, DEEP COMPRESSION COM
   Srikanth S, 2019, ACM T ARCHIT CODE OP, V16, DOI 10.1145/3355396
   Srivastava N, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P766, DOI 10.1109/MICRO50266.2020.00068
   Vuduc R, 2005, J PHYS CONF SER, V16, P521, DOI 10.1088/1742-6596/16/1/071
   Wang Endong, 2014, HIGH PERFORMANCE COM, P167, DOI [10.1007/978-3-319-06486-4_7, DOI 10.1007/978-3-319-06486-47]
   Wei H, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1813, DOI 10.1145/2882903.2915220
   Xie Z, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P94, DOI 10.1145/3330345.3330354
   Yamazaki I, 2011, LECT NOTES COMPUT SC, V6449, P421, DOI 10.1007/978-3-642-19328-6_38
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
NR 59
TC 0
Z9 0
U1 1
U2 1
PY 2021
BP 687
EP 701
DI 10.1145/3445814.3446702
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Xiao, SL
   Liu, WK
   Lin, JS
   Yu, ZY
AF Xiao, Shanlin
   Liu, Weikun
   Lin, Junshu
   Yu, Zhiyi
TI A Data-Driven Asynchronous Neural Network Accelerator
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Accelerator; asynchronous circuit; data-driven; energy-efficiency;
   neural network
ID PROCESSOR
AB Deep neural networks (DNNs) are revolutionizing machine learning, with unprecedented accuracy on many AI tasks. Energy-efficient neural acceleration is crucial in broadening DNN applications in cloud and mobile end devices. However, power-hungry clock networks limit the energy-efficiency of DNN accelerators. In this work, we propose a novel DNN hardware accelerator, called the asynchronous neural network processor (AsNNP). At the heart of AsNNP is a scalable hierarchy matrix multiply unit, with bit-serial processing elements working in parallel. It replaces the global clock networks with asynchronous handshake protocols to realize the synchronization and communication between each part, minimizing the dynamic power. Meanwhile, a fine-grain asynchronous pipeline based on weak-conditioned half-buffer (WCHB) is introduced to pipe successive computations in a data-driven manner, i.e., once data arrives computation begins, maximizing the throughput. These techniques enable AsNNP to work in a fully data-driven asynchronous communication fashion with optimized energy-efficiency. The proposed accelerator is implemented with quasi-delay-insensitive (QDI) clockless logic family and evaluated in a 65 nm process. Compared with the synchronous baseline, simulation results show that AsNNP offers 2.2 x higher equivalent frequency and 1.59 x lower power. Compared with state-of-the-art DNN accelerators, AsNNP shows 1.17 x -4.97x energy-efficiency improvement.
C1 [Xiao, Shanlin; Liu, Weikun; Lin, Junshu; Yu, Zhiyi] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Peoples R China.
RP Xiao, SL; Yu, ZY (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Peoples R China.
EM xiaoshlin@mail.sysu.edu.cn; liuwk3@mail2.sysu.edu.cn;
   linjsh23@mail2.sysu.edu.cn; yuzhiyi@mail.sysu.edu.cn
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2016, RISTRETTO HARDWARE O
   Bhadra D, 2017, DES AUT TEST EUROPE, P794, DOI 10.23919/DATE.2017.7927097
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WJ, 2018, IEEE ASIAN SOLID STA, P51
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   HOARE CAR, 1978, COMMUN ACM, V21, P666, DOI 10.1145/359576.359585
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2017, IEEE COMPUT ARCHIT L, V16, P80, DOI 10.1109/LCA.2016.2597140
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kim H, 2019, INT S HIGH PERF COMP, P661, DOI 10.1109/HPCA.2019.00017
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Li X., 2019, P 56 ANN DES AUT C 2, P1
   Liu R, 2019, PLATELETS, V30, P844, DOI 10.1080/09537104.2018.1529298
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   MARTIN AJ, 1986, DISTRIB COMPUT, V1, P226, DOI 10.1007/BF01660034
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moreira MT, 2018, IEEE T CIRCUITS-I, V65, P1981, DOI 10.1109/TCSI.2017.2772206
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Paszke A, 2019, ADV NEUR IN, V32
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang BZ, 2012, INT SYMP ASYNCHRON C, P33, DOI 10.1109/ASYNC.2012.20
   Wang XW, 2019, INT S HIGH PERF COMP, P81, DOI 10.1109/HPCA.2019.00029
   Wong CG, 2003, DES AUT CON, P508
   Yin SY, 2019, IEEE J SOLID-ST CIRC, V54, P1120, DOI 10.1109/JSSC.2018.2881913
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 42
TC 3
Z9 3
U1 4
U2 20
PD SEP
PY 2021
VL 40
IS 9
BP 1874
EP 1886
DI 10.1109/TCAD.2020.3025508
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kumar, A
   Talawar, B
AF Kumar, Anil
   Talawar, Basavaraj
TI ELBA-NoC: ensemble learning-based accelerator for 2D and 3D
   network-on-chip architectures
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL SCIENCE AND ENGINEERING
DT Article
DE network-on-chip; NoC; 2D NoC; 3D NoC; simulation; performance modelling;
   machine learning; prediction; regression; ensemble learning; random
   forest; Booksim; performance; power; area; router; traffic pattern
ID PERFORMANCE EVALUATION; RANDOM FORESTS; DESIGN
AB Network-on-chips (NoCs) have emerged as a scalable alternative to traditional bus and point-to-point architectures, it has become highly sensitive as the number of cores increases. Simulation is one of the main tools used in NoC for analysing and testing new architectures. To achieve the best performance vs. cost trade-off, simulators have become an essential tool. Software simulators are too slow for evaluating large scale NoCs. This paper presents a framework which can be used to analyse overall performance of 2D and 3D NoC architectures which is fast and accurate. This framework is named as ensemble learning-based accelerator (ELBA-NoC) which is built using random forest regression algorithm to predict parameters of NoCs. On 2D, 3D NoC architectures, ELBA-NoC was tested and the results obtained were compared with extensively used Booksim NoC simulator. The framework showed an error rate of less than 5% and an overall speedup of up to 16 Kx.
C1 [Kumar, Anil; Talawar, Basavaraj] Natl Inst Technol Karnataka Surathkal, Dept Comp Sci & Engn, Syst Parallelizat & Architecture Res Lab SPARK La, Mangalore 575025, Karnataka, India.
RP Kumar, A (corresponding author), Natl Inst Technol Karnataka Surathkal, Dept Comp Sci & Engn, Syst Parallelizat & Architecture Res Lab SPARK La, Mangalore 575025, Karnataka, India.
EM anilkumar.cs14f05@nitk.edu.in; basavaraj@nitk.edu.in
CR Abdel-Rahman E. M., 2009, IEEE INT GEOSC REM S
   Agarwal N, 2009, INT SYM PERFORM ANAL, P33, DOI 10.1109/ISPASS.2009.4919636
   Alazemi F, 2018, INT S HIGH PERF COMP, P492, DOI 10.1109/HPCA.2018.00049
   Angepat H., 2014, SYNTHESIS LECT COMPU, V9, P1, DOI 10.2200/S00586ED1V01Y201407CAC029
   [Anonymous], 2007, NIRGAM AUTH
   [Anonymous], 2006, ACM J EMERG TECH COM, DOI [10.1145/1148015.1148016, DOI 10.1145/1148015.1148016]
   [Anonymous], MACH LEARN
   [Anonymous], 2010, P 3 INT WORKSH NETW, DOI DOI 10.1145/1921249.1921254
   [Anonymous], 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   [Anonymous], 2015, OPEN SOURCE NETWORK
   [Anonymous], 2018, INT TECHNICAL ROADMA
   [Anonymous], 2014, ACM INT C SUP 25 ANN, DOI DOI 10.1145/2591635.2667187
   Arden W, 2006, MAT SCI ENG B-SOLID, V134, P104, DOI 10.1016/j.mseb.2006.07.004
   Benini L, 2002, COMPUTER, V35, P70, DOI 10.1109/2.976921
   Boyan JA, 2001, J MACH LEARN RES, V1, P77, DOI 10.1162/15324430152733124
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Carloni LP, 2010, IEEE T VLSI SYST, V18, P679, DOI 10.1109/TVLSI.2009.2014772
   Catania V, 2015, IEEE INT CONF ASAP, P162, DOI 10.1109/ASAP.2015.7245728
   Chen Sun, 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P201, DOI 10.1109/NOCS.2012.31
   Dally W. J., 2004, PRINCIPLES PRACTICES
   Ebrahimi M., 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P19, DOI 10.1109/NOCS.2012.10
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Farahnakian F, 2014, MICROPROCESS MICROSY, V38, P64, DOI 10.1016/j.micpro.2013.11.008
   Farahnakian F, 2012, 2012 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS (SAMOS): ARCHITECTURES, MODELING AND SIMULATION, P236, DOI 10.1109/SAMOS.2012.6404180
   Feero B, 2007, IEEE COMP SOC ANN, P305, DOI 10.1109/ISVLSI.2007.79
   Feero BS, 2009, IEEE T COMPUT, V58, P32, DOI 10.1109/TC.2008.142
   Fitzgibbon A., LECT NOTES COMPUTER, V7578
   Grimm R, 2008, GEODERMA, V146, P102, DOI 10.1016/j.geoderma.2008.05.008
   Guo Q., 2015, IEEE T COMPUTER AIDE
   Hastie T., 2009, ELEMENTS STAT LEARNI, Vsecond
   Ismail R, 2010, T GIS, V14, P709, DOI 10.1111/j.1467-9671.2010.01229.x
   Jeong K, 2009, 2009 INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC 2009), P53, DOI 10.1109/SOCDC.2009.5423853
   Jeong K, 2010, IEEE EMBED SYST LETT, V2, P62, DOI 10.1109/LES.2010.2051413
   Jiang N, 2013, IEEE IPCCC, pD
   Jiang N, 2012, BOOKSIM 2 0
   Jin YH, 2012, IEEE T PARALL DISTR, V23, P242, DOI 10.1109/TPDS.2011.164
   Kahng Andrew B., 2010, 2010 15th Asia and South Pacific Design Automation Conference (ASP-DAC 2010), P241, DOI 10.1109/ASPDAC.2010.5419887
   Kahng A.B, 2011, ORION 2 0 POWER AREA
   Kahng AB, 2009, DES AUT TEST EUROPE, P423
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kumar A, 2018, WIRELESS PERS COMMUN, V102, P2211, DOI 10.1007/s11277-018-5376-3
   Li YL, 2010, IEEE IMAGE PROC, P1521, DOI 10.1109/ICIP.2010.5652915
   Mak T, 2011, IEEE T IND ELECTRON, V58, P3701, DOI 10.1109/TIE.2010.2081953
   Pande PP, 2005, IEEE T COMPUT, V54, P1025, DOI 10.1109/TC.2005.134
   Pinto A., 2007, METHODOLOGY OPEN SOF
   Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1
   Puente V, 2002, 10TH EUROMICRO WORKSHOP ON PARALLEL, DISTRIBUTED AND NETWORK-BASED PROCESSING, PROCEEDINGS, P15, DOI 10.1109/EMPDP.2002.994207
   Qian ZL, 2016, IEEE T COMPUT AID D, V35, P471, DOI 10.1109/TCAD.2015.2474393
   Qian ZL, 2013, DES AUT TEST EUROPE, P354
   Sanju V, 2014, INT J COMPUT SCI ENG, V9, P95, DOI 10.1504/IJCSE.2014.058702
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Somasundaram K, 2014, MICROELECTRON J, V45, P989, DOI 10.1016/j.mejo.2014.05.003
   Talawar B., 2019, J CIRCUITS SYSTEMS C
   Topol AW, 2006, IBM J RES DEV, V50, P491, DOI 10.1147/rd.504.0491
   Touati HC, 2020, INT J EMBED SYST, V12, P39, DOI 10.1504/IJES.2020.105278
   Van Chu T., 2015, THESIS TOKYO I TECHN
   Van Chu T, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3151758
   Wang D., IEEE T COMPUT
   Whelihan D, 2003, NOCSIM SIMULATOR
   Wu J, 2017, INT J COMPUT SCI ENG, V14, P164, DOI 10.1504/IJCSE.2017.10003830
NR 60
TC 1
Z9 1
U1 0
U2 0
PY 2020
VL 23
IS 4
BP 319
EP 335
DI 10.1504/IJCSE.2020.113176
WC Computer Science, Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Malita, M
   Popescu, GV
   Stefan, GM
AF Malita, Mihaela
   Popescu, George Vladut
   Stefan, Gheorghe M.
BE Wu, XT
   Jermaine, C
   Xiong, L
   Hu, XH
   Kotevska, O
   Lu, SY
   Xu, WJ
   Aluru, S
   Zhai, CX
   Al-Masri, E
   Chen, ZY
   Saltz, J
TI Pseudo-Reconfigurable Heterogeneous Solution for Accelerating Spectral
   Clustering
SO 2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
DT Proceedings Paper
CT 8th IEEE International Conference on Big Data (Big Data)
CY DEC 10-13, 2020
CL ELECTR NETWORK
DE Spectral clustering; parallel algorithm; parallel computing;
   accelerator; heterogeneous computing; pseudo-reconfigurable computing
AB Spectral clustering is a Machine Learning technique intensively used in Big Data applications. It makes extensive use of linear algebra. This article introduces the concept of MapReduce Accelerator (MRA) as the reconfigurable part of a heterogeneous computing system. Although the accelerator we propose is a general purpose one, it has some specific features related to the targeted application. This is possible due to the pseudo-reconfigurable environment which deploys in FPGA a parameterizable programmable accelerator. The main specific characteristics of the accelerator are proposed as a result of the analysis performed on the spectral clustering algorithms. The architecture is described and the spectral clustering algorithms are evaluated. The proposed solution is compared, in terms of computing performance and energy consumption, with other solutions published in the literature. The increase in computing performance is accompanied by a 3-5 times reduction in energy consumed. The accelerator is a linear array of cells controlled by a sequencer loop closed through a reduction network. Each cell is a simple, accumulator-based execution unit with a big two-port register file. The reduction network is a log-depth pipelined circuit performing few reduction functions such as add, min, max. The experimental system is a PYNQ-Z2 board equipped with Zinq 7020 SoC; it is used to implement and evaluate the acceleration provided by an 128-cell MRA.
C1 [Malita, Mihaela] Smith Coll, Comp Sci Dept, Northampton, MA 01063 USA.
   [Popescu, George Vladut] Univ Politehn Bucuresti, Elect Devices Circ & Arch Dept, Bucharest, Romania.
   [Stefan, Gheorghe M.] Univ Politehn Bucuresti, Elect Devices Circuits & Arch Dept, Bucharest, Romania.
RP Malita, M (corresponding author), Smith Coll, Comp Sci Dept, Northampton, MA 01063 USA.
EM mmalita@smith.edu; georgevlad.popescu@yahoo.com; gheorghe.stefan@upb.ro
CR [Anonymous], STRUCTURED PARALLEL
   [Anonymous], 1989, COMBINATORICS GRAPH, DOI DOI 10.4064/-25-1-57-70
   FIEDLER M, 1973, CZECH MATH J, V23, P298
   FISCHER I, 2004, IDSIA1204
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Hamad Denis, 2008, INTRO SPECTRAL CLUST
   Jin Y., 2016 IEEE INT PAR DI
   Lupu S., 2020, THESIS
   Malita Mihaela, 2007, Computer Architecture News, V35, P32, DOI 10.1145/1360464.1360474
   Martin L., 2018, P 35 INT C MACH LEAR
   Mavroeidis D, 2010, DATA MIN KNOWL DISC, V21, P241, DOI 10.1007/s10618-010-0191-9
   Mujtaba H., 2016, NVIDIA PASCAL GP100
   Shinnou H, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P201
   Stefan G., 2014, 113 INT C CIRC SYST, P582
   STEFAN G. M., 2006, HOT CHIPS S HIGH PER
   Tremblay N, 2016, INT CONF ACOUST SPEE, P4094, DOI 10.1109/ICASSP.2016.7472447
   Volkov V, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P499
   Wu JP, 2014, J COMPUT APPL MATH, V269, P101, DOI 10.1016/j.cam.2014.03.018
NR 18
TC 1
Z9 1
U1 0
U2 1
PY 2020
BP 5138
EP 5145
DI 10.1109/BigData50022.2020.9378150
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Wang, ZJ
   Huang, S
   Huang, YJ
   Cui, HL
AF Wang, Zijian
   Huang, Shuo
   Huang, Yujin
   Cui, Helei
GP ACM
TI Energy-Latency Attacks to On-Device Neural Networks via Sponge Poisoning
SO PROCEEDINGS OF THE INAUGURAL ASIACCS 2023 WORKSHOP ON SECURE AND
   TRUSTWORTHY DEEP LEARNING SYSTEMS, SECTL
DT Proceedings Paper
CT Inaugural AsiaCCS Workshop on Secure and Trustworthy Deep Learning
   Systems (SecTL)
CY JUL 10, 2023
CL Melbourne, AUSTRALIA
DE on-device machine learning; energy-latency attacks; availability
   attacks; sponge attacks; poisoning
AB In recent years, on-device deep learning has gained attention as a means of developing affordable deep learning applications for mobile devices. However, on-device models are constrained by limited energy and computation resources. In the mean time, a poisoning attack known as sponge poisoning has been developed. This attack involves feeding the model with poisoned examples to increase the energy consumption during inference. As previous work is focusing on server hardware accelerators, in this work, we extend the sponge poisoning attack to an on-device scenario to evaluate the vulnerability of mobile device processors. We present an on-device sponge poisoning attack pipeline to simulate the streaming and consistent inference scenario to bridge the knowledge gap in the on-device setting. Our exclusive experimental analysis with processors and on-device networks shows that sponge poisoning attacks can effectively pollute the modern processor with its built-in accelerator. We analyze the impact of different factors in the sponge poisoning algorithm and highlight the need for improved defense mechanisms to prevent such attacks on on-device deep learning applications.
C1 [Wang, Zijian; Huang, Shuo; Huang, Yujin] Monash Univ, Melbourne, Vic, Australia.
   [Huang, Shuo; Cui, Helei] Northwestern Polytech Univ, Xian, Peoples R China.
RP Wang, ZJ (corresponding author), Monash Univ, Melbourne, Vic, Australia.
EM zwan0324@student.monash.edu; Shuo.huang1@monash.edu;
   Yujin.Huang@monash.edu; chl@nwpu.edu.cn
CR Agarap A.F., 2018, ARXIV
   Anderson D, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE 2ND USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST'03), P245
   [Anonymous], 2011, 2011 IEEE 73 VEH TEC
   [Anonymous], 2000, 2827 RFC, DOI 10.17487/rfc2827
   Bellardo J, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE 12TH USENIX SECURITY SYMPOSIUM, P15
   Brazdil David, 2018, IMPROVING STABILITY
   Chai J., 2021, MACHINE LEARNING APP, V6
   Chen YJ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3398209
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cina Antonio Emanuele, 2022, MACHINE LEARNING SEC
   CVML Team, 2017, APPLE MACHINE LEARNI
   de Rooi J, 2011, ANAL CHIM ACTA, V705, P218, DOI 10.1016/j.aca.2011.05.030
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Efraim R, 2014, IEEE COMPUT ARCHIT L, V13, P25, DOI 10.1109/L-CA.2012.32
   Cinà AE, 2022, Arxiv, DOI arXiv:2203.08147
   Fushuai Wang, 2021, 2021 International Symposium on Artificial Intelligence and its Application on Media (ISAIAM), P116, DOI 10.1109/ISAIAM53259.2021.00031
   Gao Huang ZL, 2017, PROC CVPR IEEE, P4700, DOI DOI 10.1109/CVPR.2017.243
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu TY, 2019, Arxiv, DOI arXiv:1708.06733
   Guo C, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00020
   Han JL, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P900, DOI 10.1145/3442381.3449942
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Hinton G, 2009, LEARNING MULTIPLE LA
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Ignatov A, 2019, IEEE INT CONF COMP V, P3617, DOI 10.1109/ICCVW.2019.00447
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jagielski M, 2018, P IEEE S SECUR PRIV, P19, DOI 10.1109/SP.2018.00057
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Juuti M, 2019, 2019 4TH IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P), P512, DOI 10.1109/EuroSP.2019.00044
   Doan K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11946, DOI 10.1109/ICCV48922.2021.01175
   Kurakin A., 2018, INT C LEARNING REPRE, P99
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li C, 2016, CONF PROC INT SYMP C, P493, DOI 10.1109/ISCA.2016.50
   Liao C, 2018, Arxiv, DOI arXiv:1808.10307
   Liu XY, 2018, Arxiv, DOI arXiv:1802.06367
   Liu YQ, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23291
   Mengwei Xu, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287075
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Palmieri F, 2015, J SUPERCOMPUT, V71, P1620, DOI 10.1007/s11227-014-1242-6
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shafahi A, 2018, ADV NEUR IN, V31
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Shumailov I, 2021, 2021 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2021), P212, DOI 10.1109/EuroSP51992.2021.00024
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Solans D, 2021, LECT NOTES ARTIF INT, V12457, P162, DOI 10.1007/978-3-030-67658-2_10
   Somani G, 2016, COMPUT NETW, V109, P157, DOI 10.1016/j.comnet.2016.03.022
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tarkoma S, 2014, SMARTPHONE ENERGY CONSUMPTION: MODELING AND OPTIMIZATION, P1, DOI 10.1017/CBO9781107326279
   TEAM COUNTERPOINT, 2022, INF GLOB SMARTPH AP
   Tolpegin V., 2020, EUROPEAN S RES COMPU, P480, DOI DOI 10.1007/978-3-030-58951-6_24
   Torfi A, 2021, Arxiv, DOI [arXiv:2003.01200, DOI 10.48550/ARXIV.2003.01200]
   Wang Y., 2018, DATA POISONING ATTAC
   Wen W, 2016, ADV NEUR IN, V29
   Xu Z, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23235
   Xu Z, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P929
   Yao YS, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P2041, DOI 10.1145/3319535.3354209
   Zhao YR, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P45, DOI 10.1109/ICFPT47387.2019.00014
   Zhu MC, 2017, Arxiv, DOI [arXiv:1710.01878, DOI 10.48550/ARXIV.1710.01878]
NR 63
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3591197.3591307
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Stang, M
   Grimm, D
   Gaiser, M
   Sax, E
AF Stang, Marco
   Grimm, Daniel
   Gaiser, Moritz
   Sax, Eric
GP IEEE
TI Evaluation of Deep Reinforcement Learning Algorithms for Autonomous
   Driving
SO 2020 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV)
SE IEEE Intelligent Vehicles Symposium
DT Proceedings Paper
CT 31st IEEE Intelligent Vehicles Symposium (IV)
CY JUN 23-26, 2020
CL ELECTR NETWORK
AB Once considered futuristic, machine learning is already integrated into our everyday life and will shape many areas of our daily life in the future: This success is mainly due to the progress in machine learning and the increase in computing power. While machine learning is used to solve partial problems in autonomous driving, the support of high-resolution maps severely limits the use of autonomous vehicles in unknown areas. At the same time, the structuring of the overall problem into modular subsystems for perception, self-localization, planning, and control limits the performance of the systems. A particularly promising alternative is end-to-end learning, which optimizes the system as a whole. In this work, we investigate the application of an end-to-end learning method for autonomous driving, employing reinforcement learning. For this purpose, a system is developed which allows the examination of different reinforcement learning approaches in a simulated environment. The system receives simulated images of the front camera as input and provides the control values for steering angle, accelerator, and brake pedal position as direct output. The desired behavior is learned automatically through interaction with the environment. The reward function is currently optimized for following a lane at the highest possible speed. Using specially modeled environments with different levels of detail, multiple deep reinforcement learning approaches are compared. Among other aspects, the extent to which a transferability of trained models to unknown environments is possible is examined. Our investigations show that Soft Actor-Critic is the best choice of the tested algorithms concerning learning speed and the ability to generalize to unseen environments.
C1 [Stang, Marco; Grimm, Daniel; Gaiser, Moritz; Sax, Eric] Karlsruhe Inst Technol, Inst Informat Proc Technol, Engesserstr 5, D-76131 Karlsruhe, Germany.
RP Stang, M (corresponding author), Karlsruhe Inst Technol, Inst Informat Proc Technol, Engesserstr 5, D-76131 Karlsruhe, Germany.
EM marco.stang@kit.edu; daniel.grimm@kit.edu; moritz.gaiser@kit.edu;
   eric.sax@kit.edu
CR Bojarski Mariusz, 2016, arXiv
   Cobbe K., 2018, ARXIV181202341
   Ellis C, 2019, MAPPING WORLD SOLVIN
   Finn C, 2015, ABS150906113 CORR
   Haarnoja, 2018, ARXIV181205905
   Haarnoja T, 2018, PR MACH LEARN RES, V80
   Henderson P, 2018, AAAI CONF ARTIF INTE, P3207
   Kendall A, 2019, IEEE INT CONF ROBOT, P8248, DOI [10.1109/icra.2019.8793742, 10.1109/ICRA.2019.8793742]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562
   Lillicrap TP., 2015, ARXIV, DOI DOI 10.1016/S1098-3015(10)67722-4
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208
   McAllister R, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4745
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278
   Shah S., 2018, P FIELD SERV ROB RES, P621, DOI 10.1007/978-3-319-67361-5_40
   Stang M., 2019, PROC HUMAN INTERACTI, P713
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Szepesvari Csaba, 2010, ALGORITHMS REINFORCE, DOI [http://dx.doi.org/10.2200/S00268ED1V01Y201005AIM009, DOI 10.2200/S00268ED1V01Y201005AIM009]
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Vishnukumar HJ, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P714, DOI 10.1109/IntelliSys.2017.8324372
   Vitelli M., 2016, CARMA DEEP REINFORCE
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
NR 24
TC 4
Z9 4
U1 0
U2 1
PY 2020
BP 1576
EP 1582
WC Computer Science, Artificial Intelligence; Robotics; Transportation
   Science & Technology
DA 2023-11-11
ER

PT C
AU Angstadt, K
   Jeannin, JB
   Weimer, W
AF Angstadt, Kevin
   Jeannin, Jean-Baptiste
   Weimer, Westley
GP ACM
TI Accelerating Legacy String Kernels via Bounded Automata Learning
SO TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR
   PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV)
DT Proceedings Paper
CT 25th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY MAR 16-20, 2020
CL Lausanne, SWITZERLAND
DE automata learning; automata processing; legacy programs
ID ABSTRACTION REFINEMENT; MODEL; STATE; CHECKING; QUERIES
AB The adoption of hardware accelerators, such as FPGAs, into general-purpose computation pipelines continues to rise, but programming models for these devices lag far behind their CPU counterparts. Legacy programs must often be rewritten at very low levels of abstraction, requiring intimate knowledge of the target accelerator architecture. While techniques such as high-level synthesis can help port some legacy software, many programs perform poorly without manual, architecture-specific optimization.
   We propose an approach that combines dynamic and static analyses to learn a model of functional behavior for off-the-shelf legacy code and synthesize a hardware description from this model. We develop a framework that transforms Boolean string kernels into hardware descriptions using techniques from both learning theory and software verification. These include Angluin-style state machine learning algorithms, bounded software model checking with incremental loop unrolling, and string decision procedures. Our prototype implementation can correctly learn functionality for kernels that recognize regular languages and provides a near approximation otherwise. We evaluate our prototype tool on a benchmark suite of real-world, legacy string functions mined from GitHub repositories and demonstrate that we are able to learn fully-equivalent hardware designs in 72% of cases and close approximations in another 11%. Finally, we identify and discuss challenges and opportunities for more general adoption of our proposed framework to a wider class of function types.
C1 [Angstadt, Kevin; Weimer, Westley] Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA.
   [Jeannin, Jean-Baptiste] Univ Michigan, Aerosp Engn, Ann Arbor, MI 48109 USA.
RP Angstadt, K (corresponding author), Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA.
EM angstadt@umich.edu; jeannin@umich.edu; weimerw@umich.edu
CR Aarts F, 2013, IEEE ICST WORKSHOP, P461, DOI 10.1109/ICSTW.2013.60
   Alonso Gustavo, 2018, QUEUE, V16
   Alur R, 2015, NATO SCI PEAC SECUR, V40, P1, DOI 10.3233/978-1-61499-495-4-1
   Ammons G, 2003, ACM SIGPLAN NOTICES, V38, P182, DOI 10.1145/780822.781152
   Angluin D., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P351, DOI 10.1145/129712.129746
   ANGLUIN D, 1981, INFORM CONTROL, V51, P76, DOI 10.1016/S0019-9958(81)90090-5
   ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6
   Angstadt K, 2019, IEEE T PARALL DISTR, V30, P939, DOI 10.1109/TPDS.2018.2869736
   Angstadt K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P921, DOI [10.1109/MICRO.2018.00079, 10.1109/MICR0.2018.00079]
   Angstadt K, 2018, IEEE COMPUT ARCHIT L, V17, P84, DOI 10.1109/LCA.2017.2780105
   [Anonymous], 2006, INTRO THEORY COMPUTA
   [Anonymous], 2017, PROC INT C SUPERCOMP
   [Anonymous], 1994, INTRO COMPUTATIONAL
   [Anonymous], 2012, BIG DAT UN BEG EXPL
   [Anonymous], 2015, ARCHITECTURES SYSTEM
   [Anonymous], 2014, TECHNICAL REPORT
   Asanovic K., 2006, LANDSCAPE PARALLEL C
   Ball T., 2001, Model Checking Software. 8th International SPIN Workshop. Proceedings (Lecture Notes in Computer Science Vol.2057), P103
   Ball T, 2002, LECT NOTES COMPUT SC, V2280, P158
   Berzish M, 2017, PROCEEDINGS OF THE 17TH CONFERENCE ON FORMAL METHODS IN COMPUTER AIDED DESIGN (FMCAD 2017), P55, DOI 10.23919/FMCAD.2017.8102241
   Beyer Dirk, 2011, Computer Aided Verification. Proceedings 23rd International Conference, CAV 2011, P184, DOI 10.1007/978-3-642-22110-1_16
   Beyer Dirk, 2007, International Journal on Software Tools for Technology Transfer, V9, P505, DOI 10.1007/s10009-007-0044-z
   Beyer D., 2010, 2010 Formal Methods in Computer-Aided Design (FMCAD 2010), P189
   Biere A, 2009, FRONT ARTIF INTEL AP, V185, P457, DOI 10.3233/978-1-58603-929-5-457
   Bollig Benedikt, 2009, INT JOINT C ART INT
   Bradley AR, 2011, LECT NOTES COMPUT SC, V6538, P70, DOI 10.1007/978-3-642-18275-4_7
   BRZOZOWSKI JA, 1964, J ACM, V11, P481, DOI 10.1145/321239.321249
   Cadar C., 2008, P 8 USENIX C OPERATI, V8, P209
   Caron P, 2000, THEOR COMPUT SCI, V233, P75, DOI 10.1016/S0304-3975(97)00296-X
   Cassel S, 2016, FORM ASP COMPUT, V28, P233, DOI 10.1007/s00165-016-0355-5
   Caulfield AM, 2016, INT SYMP MICROARCH
   Cheung A, 2013, ACM SIGPLAN NOTICES, V48, P3, DOI 10.1145/2499370.2462180
   Clarke E, 2003, J ACM, V50, P752, DOI 10.1145/876638.876643
   Craig William, 1957, J SYMBOLIC LOGIC, V22, P269, DOI [DOI 10.2307/2963594, 10.2307/2963594]
   Daelemans W, 2010, MACH TRANSL, V24, P291, DOI 10.1007/s10590-011-9086-9
   de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24
   de Ruiter J, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P193
   Di Tucci L, 2017, PR IEEE COMP DESIGN, P423, DOI 10.1109/ICCD.2017.74
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   DNV GL, 2016, AR YOU ABL LEV BIG D
   Fang YW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P55, DOI 10.1145/3123939.3123983
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Fiterau-Brostean P, 2016, LECT NOTES COMPUT SC, V9780, P454, DOI 10.1007/978-3-319-41540-6_25
   Ginsbach P, 2018, ACM SIGPLAN NOTICES, V53, P139, DOI [10.1145/3296957.3173182, 10.1145/3173162.3173182]
   Gogte Vaibhav, 2016, 49 ANN IEEE ACM INT, P44
   Gulwani S, 2016, LECT NOTES ARTIF INT, V9706, P9, DOI 10.1007/978-3-319-40229-1_2
   Nguyen HDT, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P772, DOI 10.1109/ICSE.2013.6606623
   Hooimeijer P, 2009, PLDI'09 PROCEEDINGS OF THE 2009 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P188, DOI 10.1145/1542476.1542498
   Huang YW, 2004, 2004 INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS, PROCEEDINGS, P199
   Isberner M, 2014, LECT NOTES COMPUT SC, V8734, P307, DOI 10.1007/978-3-319-11164-3_26
   Isberner Malte, 2015, THESIS
   Jhala R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1592434.1592438
   Kamil S, 2016, ACM SIGPLAN NOTICES, V51, P711, DOI [10.1145/2908080.2908117, 10.1145/2980983.2908117]
   Karpenkov EG, 2016, LECT NOTES COMPUT SC, V9971, P139, DOI 10.1007/978-3-319-48869-1_11
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Kiezun A, 2009, ISSTA 2009: INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P105
   Lahti S, 2019, IEEE T COMPUT AID D, V38, P898, DOI 10.1109/TCAD.2018.2834439
   Lee D, 1996, P IEEE, V84, P1090, DOI 10.1109/5.533956
   Lin AW, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI 10.1145/2914770.2837641
   Margaria T., 2004, P HIGH LEV DES VAL T
   McMillan KL, 2006, LECT NOTES COMPUT SC, V4144, P123
   Mechtaev S, 2016, PROC INT CONF SOFTW, P691, DOI 10.1145/2884781.2884807
   Mendis C, 2015, ACM SIGPLAN NOTICES, V50, P391, DOI [10.1145/2813885.2737974, 10.1145/2737924.2737974]
   Trinh MT, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1232, DOI 10.1145/2660267.2660372
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Moerman J, 2017, ACM SIGPLAN NOTICES, V52, P613, DOI 10.1145/3093333.3009879
   Moreau T, 2018, IEEE EMBED SYST LETT, V10, P2, DOI 10.1109/LES.2017.2758679
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Necula GC, 2002, LECT NOTES COMPUT SC, V2304, P213
   Park J, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P745, DOI 10.1145/2786805.2786807
   Rinard M, 2003, ACM SIGPLAN NOTICES, V38, P57, DOI 10.1145/966051.966060
   RIVEST RL, 1993, INFORM COMPUT, V103, P299, DOI 10.1006/inco.1993.1021
   Roy I., 2015, THESIS
   Roy I, 2016, INT PARALL DISTRIB P, P283, DOI 10.1109/IPDPS.2016.116
   Roy I, 2016, INT PARALL DISTRIB P, P1123, DOI 10.1109/IPDPS.2016.94
   Roy I, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.51
   Schuts M, 2016, LECT NOTES COMPUT SC, V9681, P311, DOI 10.1007/978-3-319-33693-0_20
   Shalf JM, 2015, COMPUTER, V48, P14, DOI 10.1109/MC.2015.374
   Solar-Lezama A, 2006, ACM SIGPLAN NOTICES, V41, P404, DOI 10.1145/1168917.1168907
   Solar-Lezama A, 2008, PLDI'08: PROCEEDINGS OF THE 2008 SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN & IMPLEMENTATION, P136, DOI 10.1145/1375581.1375599
   Spishak E., 2012, P 14 WORKSH FORM TEC, P20, DOI [10.1145/2318202.2318207, DOI 10.1145/2318202.2318207]
   Steffen B, 2011, LECT NOTES COMPUT SC, V6659, P256, DOI 10.1007/978-3-642-21455-4_8
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Tinelli Cesare, 2019, TECHNICAL REPORT
   Tracy T, 2016, LECT NOTES COMPUT SC, V9697, P200, DOI 10.1007/978-3-319-41321-1_11
   Vaandrager F, 2017, COMMUN ACM, V60, P85, DOI 10.1145/2967606
   Valiant L. G., 1984, Communications of the ACM, V27, P1134, DOI 10.1145/1968.1972
   van Lunteren J, 2012, INT SYMP MICROARCH, P461, DOI 10.1109/MICRO.2012.49
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wadden J, 2016, PR IEEE COMP DESIGN, P622, DOI 10.1109/ICCD.2016.7753349
   Wadden J, 2016, I S WORKL CHAR PROC, P105, DOI 10.1109/IISWC.2016.7581271
   Wang K, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P135, DOI 10.1145/2903150.2903172
   Wang M. H., 2016, NUCL INSTRUMENTS MET
   Weiss Gail, 2018, P MACH LEARN RES P 3, P5247, DOI DOI 10.48550/ARXIV.1711.09576
   Xie T, 2017, I C FIELD PROG LOGIC
   Yu X., 2013, P ACM INT C COMPUTIN, DOI [10.1145/2482767.2482791, DOI 10.1145/2482767.2482791]
   Zhou K, 2015, IEEE INT C SEMANT CO, P236, DOI 10.1109/ICOSC.2015.7050812
   Zohouri Hamid Reza, 2016, HIGH PERFORMANCE COM
NR 99
TC 4
Z9 4
U1 0
U2 0
PY 2020
BP 235
EP 249
DI 10.1145/3373376.3378503
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Araki, T
   Nakamura, Y
AF Araki, Takuya
   Nakamura, Yuichi
GP IEEE
TI Future Trend of Deep Learning Frameworks - From the perspective of Big
   Data analytics and HPC
SO 2017 ASIA-PACIFIC SIGNAL AND INFORMATION PROCESSING ASSOCIATION ANNUAL
   SUMMIT AND CONFERENCE (APSIPA ASC 2017)
SE Asia-Pacific Signal and Information Processing Association Annual Summit
   and Conference
DT Proceedings Paper
CT 9th Annual Summit and Conference of the
   Asia-Pacific-Signal-and-Information-Processing-Association (APSIPA ASC)
CY DEC 12-15, 2017
CL Kuala Lumpur, MALAYSIA
AB Deep learning is becoming more and more important in many areas including signal processing, because of its high recognition accuracy and interesting applications built on top of the models. There is no doubt that deep learning frameworks played an important role for its popularization; they made it easy to utilize deep learning by hiding the detailed implementation of the algorithms including utilization of accelerators like GPU. On the other hand, there have been Big Data analytics frameworks for classical machine learning like Hadoop and Spark. In addition, there also have been many researches in the field of HPC middleware, whose workload is similar to that of deep learning. In this paper, we discuss such frameworks and middleware including their targeted workloads and tradeoffs, and also discuss the future trend of deep learning frameworks including our preliminary proposal.
C1 [Araki, Takuya; Nakamura, Yuichi] NEC Corp Ltd, Syst Platform Res Labs, Kawasaki, Kanagawa, Japan.
RP Araki, T (corresponding author), NEC Corp Ltd, Syst Platform Res Labs, Kawasaki, Kanagawa, Japan.
EM t-araki@dc.jp.nec.com; yuichi@az.jp.nec.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agarwal Amit, 2014, MSRTR2014112
   Angerson E., 1990, Proceedings of Supercomputing '90 (Cat. No.90CH2916-5), P2, DOI 10.1109/SUPERC.1990.129995
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2015, P WORKSH MACH LEARN
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], 2007, NIPS
   [Anonymous], 2012, P 9 USENIX S NETW SY
   [Anonymous], PYTH SCI COMP C SCIP
   Araki T., 2017, P 16 INT S PAR DISTR
   Blackford L Susan, 1997, SCALAPACK USERS GUID
   Canny J, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P95
   Chen T., 2015, WORKSH MACH LEARN SY
   Collobert R., 2002, 0246 IDIAP RR
   D'Azevedo E, 2000, CONCURRENCY-PRACT EX, V12, P1481, DOI 10.1002/1096-9128(20001225)12:15<1481::AID-CPE540>3.0.CO;2-V
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Future Technologies Group, BERK LAB CHECKP REST
   Gabriel E, 2004, LECT NOTES COMPUT SC, V3241, P97
   Gatys L., 2016, ARXIV, V16, P326, DOI [DOI 10.1167/16.12.326, 10.1167/16.12.326]
   Hoffer E., 2017, ARXIV170508741
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, P324, DOI [10.1145/355841.355847, 10.1145/355841.355848]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., MNIST DATABASE HANDW
   Lehoucq RB, 1997, ARPACK USERS GUIDE S
   Maschhoff K. J., 1996, P 3 INT WORKSH APPL
   Message Passing Interface Forum, 2015, MPI MESS PASS INT ST
   Momose Shintaro, 2014, Supercomputing. 29th International Conference, ISC 2014. Proceedings: LNCS 8488, P199, DOI 10.1007/978-3-319-07518-1_13
   Preferred Networks, CHAINERMN DISTR DEEP
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Thakur R, 2005, INT J HIGH PERFORM C, V19, P49, DOI 10.1177/1094342005051521
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
NR 32
TC 2
Z9 2
U1 0
U2 2
PY 2017
BP 696
EP 703
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Liang, JY
   Mi, JR
   Wei, W
   Wang, F
AF Liang, Jiye
   Mi, Junrong
   Wei, Wei
   Wang, Feng
TI An accelerator for attribute reduction based on perspective of objects
   and attributes
SO KNOWLEDGE-BASED SYSTEMS
DT Article
DE Feature selection; Accelerating algorithm; Attribute reduction; Rough
   set; Large scale data
ID FEATURE-SELECTION; KNOWLEDGE GRANULATION; DECISION PERFORMANCE; ROUGH
   SETS; INFORMATION; ENTROPY; SYSTEMS; DIMENSIONALITY; UNCERTAINTY
AB Feature selection is an active area of research in pattern recognition, machine learning and artificial intelligence, which greatly improves the performance of forecasting or classification. In rough set theory, attribute reduction, as a special form of feature selection, aims to retain the discernability of the original attribute set. To solve this problem, many heuristic attribute reduction algorithms have been proposed in the literature. However, these methods are computationally time-consuming for large scale datasets. Recently, an accelerator was introduced by computing reducts on gradually reducing the size of the universe. Although the accelerator can considerably shorten the computational time, it remains a challenging issue. To further enhance the efficiency of these algorithms, we develop a new accelerator for attribute reduction, which simultaneously reduces the size of the universe and the number of attributes at each iteration of the process of reduction. Based on the new accelerator, several representative heuristic attribute reduction algorithms are accelerated. Experiments show that these accelerated algorithms can significantly reduce computational time while maintaining their results the same as before. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Mi, Junrong] Shanxi Univ, Sch Management, Taiyuan 030006, Shanxi, Peoples R China.
   [Liang, Jiye; Wei, Wei; Wang, Feng] Shanxi Univ, Sch Comp & Informat Technol, Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China.
RP Wei, W (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China.
EM ljy@sxu.edu.cn; jrmi@sxu.edu.cn; weiwei@sxu.edu.cn; sxuwangfeng@126.com
CR Babu VS, 2009, PATTERN RECOGN, V42, P1719, DOI 10.1016/j.patcog.2008.11.021
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   Feng L, 2011, KNOWL-BASED SYST, V24, P837, DOI 10.1016/j.knosys.2011.03.005
   Guyon I., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/j.patrec.2005.09.004
   Hu QH, 2008, KNOWL-BASED SYST, V21, P294, DOI 10.1016/j.knosys.2007.07.001
   Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017
   HU XH, 1995, COMPUT INTELL-US, V11, P323, DOI 10.1111/j.1467-8640.1995.tb00035.x
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kryszkiewicz M, 2008, LECT NOTES COMPUT SC, V5390, P76, DOI 10.1007/978-3-540-89876-4_5
   Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006
   Liang J, 2006, INT J GEN SYST, V35, P641, DOI 10.1080/03081070600687668
   Liang JY, 2009, INFORM SCIENCES, V179, P458, DOI 10.1016/j.ins.2008.10.010
   Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635
   Liang JY, 2002, INT J UNCERTAIN FUZZ, V10, P95, DOI 10.1142/S021848850200134X
   Mac Parthaláin N, 2009, PATTERN RECOGN, V42, P655, DOI 10.1016/j.patcog.2008.08.029
   Meng ZQ, 2009, INFORM SCIENCES, V179, P2774, DOI 10.1016/j.ins.2009.04.002
   MODRZEJEWSKI M, 1993, P EUR C MACH LEARN, P213
   Pavlenko T, 2003, J STAT PLAN INFER, V115, P565, DOI 10.1016/S0378-3758(02)00166-0
   Pawlak Z., 1991, SPRINGER SCI BUSINES, VVolume 9, DOI DOI 10.1007/978-94-011-3534-4
   Pawlak Z, 2007, INFORM SCIENCES, V177, P41, DOI 10.1016/j.ins.2006.06.007
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2008, INFORM SCIENCES, V178, P181, DOI 10.1016/j.ins.2007.08.010
   Qian YH, 2011, PATTERN RECOGN, V44, P1658, DOI 10.1016/j.patcog.2011.02.020
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016
   Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1
   Skowron A., 1992, INTELLIGENT DECISION, P331, DOI DOI 10.1007/978-94-015-7975-9_21
   Slezak D, 2002, FUND INFORM, V53, P365
   Slezak D., 1995, RES REPORT
   Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4
   Tsang ECC, 2008, IEEE T FUZZY SYST, V16, P1130, DOI 10.1109/TFUZZ.2006.889960
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GY, 2005, FUND INFORM, V68, P289
   Wei W., 2011, INFORM SCI
   Wei W, 2010, INT J GEN SYST, V39, P813, DOI 10.1080/03081079.2010.499102
   Wei W, 2009, PROCEEDINGS OF THE 8TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P167, DOI 10.1109/COGINF.2009.5250768
   Wong SKM., 1985, J B POLISH ACAD SCI, V33, P693
   Yang XB, 2011, KNOWL-BASED SYST, V24, P858, DOI 10.1016/j.knosys.2011.03.007
   Yao YY, 2008, INFORM SCIENCES, V178, P3356, DOI 10.1016/j.ins.2008.05.010
   Yao YY, 2009, INFORM SCIENCES, V179, P867, DOI 10.1016/j.ins.2008.11.020
   ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2
NR 47
TC 37
Z9 46
U1 0
U2 16
PD MAY
PY 2013
VL 44
BP 90
EP 100
DI 10.1016/j.knosys.2013.01.027
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT J
AU Kim, S
   Lee, Y
   Kim, HD
   Choi, SJ
AF Kim, Sungho
   Lee, Yongwoo
   Kim, Hee-Dong
   Choi, Sung-Jin
TI 16-Bit Fixed-Point Number Multiplication With CNT Transistor Dot-Product
   Engine
SO IEEE ACCESS
DT Article
DE Crossbar array; dot product; matrix multiplication; precision extension
AB Resistive crossbar arrays can carry out energy-efficient vector-matrix multiplication, which is a crucial operation in most machine learning applications. However, practical computing tasks that require high precision remain challenging to implement in such arrays because of intrinsic device variability. Herein, we experimentally demonstrate a precision-extension technique whereby high precision can be attained through the combined operation of multiple devices, each of which stores a portion of the required bit width. Additionally, designed analog-to-digital converters are used to remove the unpredictable effects from noise sources. An 8 x 15 carbon nanotube transistor array can perform multiplication operation, where operands have up to 16 valid bits, without any error, making in-memory computing approaches attractive for high-throughput energy-efficient machine learning accelerators.
C1 [Kim, Sungho; Kim, Hee-Dong] Sejong Univ, Dept Elect Engn, Seoul 05006, South Korea.
   [Lee, Yongwoo; Choi, Sung-Jin] Kookmin Univ, Sch Elect Engn, Seoul 02707, South Korea.
RP Choi, SJ (corresponding author), Kookmin Univ, Sch Elect Engn, Seoul 02707, South Korea.
EM sjchoiee@kookmin.ac.kr
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Gao LG, 2015, IEEE ELECTR DEVICE L, V36, P1157, DOI 10.1109/LED.2015.2481819
   Gao LG, 2012, IEEE INT CONF VLSI, P87, DOI 10.1109/VLSI-SoC.2012.6379011
   Golub G. H., 2012, MATRIX COMPUTATIONS, V3
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hsu SK, 2006, IEEE J SOLID-ST CIRC, V41, P256, DOI 10.1109/JSSC.2005.859893
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu M, 2012, DES AUT CON, P498
   Kim S, 2019, NANOSCALE, V11, P21449, DOI 10.1039/c9nr06715a
   Kim S, 2014, ACS NANO, V8, P2369, DOI 10.1021/nn405827t
   Kuzum D, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/382001
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Strukov DB, 2009, APPL PHYS A-MATER, V94, P515, DOI 10.1007/s00339-008-4975-3
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Wang N., 2018, ADV NEURAL INFORM PR, P7675, DOI DOI 10.1109/THERMINIC.2018.8593303
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 22
TC 3
Z9 3
U1 1
U2 9
PY 2020
VL 8
BP 133597
EP 133604
DI 10.1109/ACCESS.2020.3009637
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Ahrens, J
AF Ahrens, James
TI Technology Trends and Challenges for Large-Scale Scientific
   Visualization
SO IEEE COMPUTER GRAPHICS AND APPLICATIONS
DT Article
AB Scientific visualization is a key approach to understanding the growing massive streams of data from scientific simulations and experiments. In this article, I review technology trends including the positive effects of Moore's law on science, the significant gap between processing and data storage speeds, the emergence of hardware accelerators for ray-tracing, and the availability of robust machine learning techniques. These trends represent changes to the status quo and present the scientific visualization community with a new set of challenges. A major challenge involves extending our approaches to visualize the modern scientific process, which includes scientific verification and validation. Another key challenge to the community is the growing number, size, and complexity of scientific datasets. A final challenge is to take advantage of emerging technology trends in custom hardware and machine learning to significantly improve the large-scale data visualization process.
C1 [Ahrens, James] Los Alamos Natl Lab, Informat Sci Technol Inst, Los Alamos, NM 87545 USA.
RP Ahrens, J (corresponding author), Los Alamos Natl Lab, Informat Sci Technol Inst, Los Alamos, NM 87545 USA.
EM ahrens@lanl.gov
CR Ahrens J, 2014, INT CONF HIGH PERFOR, P424, DOI 10.1109/SC.2014.40
   [Anonymous], 2009, MICROSOFT RES
   Ayachit U., 2015, P 1 WORKSHOP IN SITU, P25, DOI [DOI 10.1145/2828612.2828624, 10.1145/2828612.2828624]
   Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229
   Caswell Hal, 2001, pi
   Chen J., 2013, DEP ENERGY ADV SCI C
   Childs H, 2020, INT J HIGH PERFORM C, V34, P676, DOI 10.1177/1094342020935991
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Marsaglia N, 2021, SYMP LARG DATA ANAL, P73, DOI 10.1109/LDAV53230.2021.00015
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   Raghu M, 2020, ARXIV200311755
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 16
TC 1
Z9 1
U1 3
U2 12
PD JUL 15
PY 2022
VL 42
IS 4
BP 114
EP 119
DI 10.1109/MCG.2022.3176325
WC Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Mukherjee, A
   Saurav, K
   Nair, P
   Shekhar, S
   Lis, M
AF Mukherjee, Avilash
   Saurav, Kumar
   Nair, Prashant
   Shekhar, Sudip
   Lis, Mieszko
GP IEEE
TI A Case for Emerging Memories in DNN Accelerators
SO PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2021)
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY FEB 01-05, 2021
CL ELECTR NETWORK
DE Machine-Learning; Convolutional Neural Networks; Non-Volatile Memories;
   PCM; RRAM; MRAM
ID STT-MRAM
AB The popularity of Deep Neural Networks (DNNs) has led to many DNN accelerator architectures, which typically focus on the on-chip storage and computation costs. However, much of the energy is spent on accesses to off-chip DRAM memory. While emerging resistive memory technologies such as MRAM, PCM, and RRAM can potentially reduce this energy component, they suffer from drawbacks such as low endurance that prevent them from being a DRAM replacement in DNN applications.
   In this paper, we examine how DNN accelerators can be designed to overcome these limitations and how emerging memories can be used for off-chip storage. We demonstrate that through (a) careful mapping of DNN computation to the accelerator and (b) a hybrid setup (both DRAM and an emerging memory), we can reduce inference energy over a DRAM-only design by a factor ranging from 1.12x on EfficientNetB7 to 6.3x on ResNet-50, while also increasing the endurance from 2 weeks to over a decade. As the energy benefits vary dramatically across DNN models, we also develop a simple analytical heuristic solely based on DNN model parameters that predicts the suitability of a given DNN for emerging-memory-based accelerators.
C1 [Mukherjee, Avilash; Nair, Prashant; Shekhar, Sudip; Lis, Mieszko] Univ British Columbia, Vancouver, BC, Canada.
   [Saurav, Kumar] QUALCOMM India, Bengaluru, Karnataka, India.
RP Mukherjee, A (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM avilash@ece.ubc.ca; saurav@qti.qualcomm.com; prashantnair@ece.ubc.ca;
   sudip@ece.ubc.ca; mieszko@ece.ubc.ca
CR [Anonymous], 2020, P 2020 IEEE CVF C CO
   [Anonymous], DDR4 SDRAM SYSTEM PO
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chih YD, 2020, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC19947.2020.9062955
   Choi Y., ISSCC 2012
   De Sandre Guido, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P268, DOI 10.1109/ISSCC.2010.5433911
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong Q, 2018, ISSCC DIG TECH PAP I, P480, DOI 10.1109/ISSCC.2018.8310393
   Fackenthal R, 2014, ISSCC DIG TECH PAP I, V57, P338, DOI 10.1109/ISSCC.2014.6757460
   Gudaparthi S, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P1, DOI 10.1145/3352460.3358316
   Guo KY, 2018, IEEE COMP SOC ANN, P435, DOI 10.1109/ISVLSI.2018.00085
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Jeloka S, 2017, SYMP VLSI CIRCUITS, pC196, DOI 10.23919/VLSIC.2017.8008480
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kanda A, 2019, IEEE SOLID-ST CIRC L, V2, P273, DOI 10.1109/LSSC.2019.2948813
   Lee BC, 2010, IEEE MICRO, V30, P131, DOI 10.1109/MM.2010.24
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Patrigeon G, 2019, IEEE ACCESS, V7, P58085, DOI 10.1109/ACCESS.2019.2906942
   Rho K, 2017, ISSCC DIG TECH PAP I, P396, DOI 10.1109/ISSCC.2017.7870428
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sassine G, 2018, INT RELIAB PHY SYM
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Taito Y, 2015, ISSCC DIG TECH PAP I, V58, P132, DOI 10.1109/ISSCC.2015.7062961
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 29
TC 3
Z9 3
U1 1
U2 2
PY 2021
BP 938
EP 941
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Software Engineering
DA 2023-11-11
ER

PT J
AU Struharik, R
   Vukobratovic, B
AF Struharik, R.
   Vukobratovic, B.
TI A system for hardware aided decision tree ensemble evolution
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article
DE Data mining; Machine learning; Hardware-software co-design; Decision
   trees; Evolutionary algorithms; Ensemble classifiers; Hardware
   acceleration; FPGA; Co-processor
ID SUPPORT VECTOR MACHINES; ARCHITECTURE; IMPLEMENTATION; ACCELERATOR
AB In this paper a system for hardware-aided induction of decision tree ensembles using the evolutionary approach (Decision Tree Ensemble Evolution co-Processor DTEEP) is proposed. DTEEP is used for hardware acceleration of the fitness evaluation, since it is shown that most of the ensemble inference time is spent on this task. The DTEEP co-processor can significantly improve execution time of an algorithm for a full tree evolutionary induction of the decision tree ensembles (An Evolutionary Ensemble of Full Trees Induction-EEFTI) by accelerating the fitness evaluation task. Comparing the HW/SW EEFTI implementation with the pure software implementation suggests that the proposed HW/SW architecture offers substantial speedups for all the tests performed on the selected UCI (University of California, Irvine) machine learning repository datasets. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Struharik, R.; Vukobratovic, B.] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
RP Vukobratovic, B (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
EM rasti@uns.ac.rs; vukobratovic@uns.ac.rs
CR Abe S., 2005, SUPPORT VECTOR MACHI, V53
   Aggarwal C. C., 2012, MINING TEXT DATA, P163, DOI 10.1007/978-1-4614-3223-4
   Ali U, 2010, J SYST ARCHITECT, V56, P317, DOI 10.1016/j.sysarc.2010.04.008
   Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   Anguita D, 2011, J CIRCUIT SYST COMP, V20, P263, DOI 10.1142/S0218126611007244
   [Anonymous], 2013, INTRO BIOINFORMATICS
   [Anonymous], 2011, J SOFTWARE ENG APPL, DOI DOI 10.4236/JSEA.2011.45036
   [Anonymous], 2006, DATA MINING COMPUTAT
   B├a┬╝hlmann P., 2012, HDB COMPUTATIONAL ST, P985, DOI DOI 10.1007/978-3-642-21551-3_33
   BALDI P, 2001, BIOINFORMATICS MACHI
   Barros RC, 2012, IEEE T SYST MAN CY C, V42, P291, DOI 10.1109/TSMCC.2011.2157494
   Bekkerman R., 2011, SCALING MACHINE LEAR
   Bermak A, 2003, IEEE T NEURAL NETWOR, V14, P1097, DOI 10.1109/TNN.2003.816362
   Blake CL, 1998, UCI REPOSITORY MACHI
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bot MCJ, 2000, LECT NOTES COMPUT SC, V1802, P247
   Cantú-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857
   Choudhary AN, 2011, WIRES DATA MIN KNOWL, V1, P41, DOI 10.1002/widm.9
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   Echanobe J, 2014, MICROPROCESS MICROSY, V38, P730, DOI 10.1016/j.micpro.2014.07.005
   Flach P., 2012, MACHINE LEARNING ART
   Haykin S, 2009, NEURAL NETWORKS LEAR
   Huang Y. S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P347, DOI 10.1109/CVPR.1993.1626170
   Hussain H., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P627, DOI 10.1109/FPL.2012.6339251
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Kretowski M, 2005, ADV SOFT COMP, P309, DOI 10.1007/3-540-32392-9_32
   Liu Bing, 2007, WEB DATA MINING EXPL
   Llorà X, 2004, LECT NOTES COMPUT SC, V3103, P797
   Madokoro H, 2013, J COMPUT, V8, P559, DOI 10.4304/jcp.8.3.559-566
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Murthy SK, 1994, J ARTIF INTELL RES, V2, P1, DOI 10.1613/jair.63
   Omondi AR, 2006, FPGA IMPLEMENTATIONS OF NEURAL NETWORKS, P1, DOI 10.1007/0-387-28487-7_1
   Osman HE, 2009, IEEE INTL CONF IND I, P319, DOI 10.1109/INDIN.2009.5195824
   Ozay M., 2008, 2008 IEEE 16 SIGN PR
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Papagelis A, 2000, PROC INT C TOOLS ART, P203, DOI 10.1109/TAI.2000.889871
   Prince S. J., 2012, COMPUTER VISION MODE
   Qingzheng Li, 2011, Journal of Low Power Electronics and Applications, V1, P45, DOI 10.3390/jlpea1010045
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Rokach L., 2007, DATA MINING DECISION
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Savich A, 2012, MICROPROCESS MICROSY, V36, P138, DOI 10.1016/j.micpro.2010.12.001
   Shi MH, 2008, IEEE SENS J, V8, P403, DOI 10.1109/JSEN.2008.917124
   Struharik R, 2014, I S INTELL SYST INFO, P257, DOI 10.1109/SISY.2014.6923596
   Struharik RJR, 2009, IET COMPUT DIGIT TEC, V3, P259, DOI 10.1049/iet-cdt.2008.0055
   Struharik RJR, 2013, J CIRCUIT SYST COMP, V22, DOI 10.1142/S0218126613500321
   Struharik RJR, 2009, J CIRCUIT SYST COMP, V18, P1033, DOI 10.1142/S0218126609005526
   Tomasi M, 2010, J SYST ARCHITECT, V56, P577, DOI 10.1016/j.sysarc.2010.07.012
   Vainbrand D, 2011, MICROPROCESS MICROSY, V35, P152, DOI 10.1016/j.micpro.2010.08.005
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Vranjkovic V., 2011, 2011 19th Telecommunications Forum Telfor (TELFOR), P1543, DOI 10.1109/TELFOR.2011.6143852
   Vranjkovic VS, 2015, J CIRCUIT SYST COMP, V24, DOI 10.1142/S0218126615500644
   Vukobratovic B, 2015, INT SYMP COMP INTELL, P95, DOI 10.1109/CINTI.2015.7382901
   Weiss SM, 2010, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84996-226-1
   Witten Ian., 2005, DATA MINING PRACTICA
   Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653
   Yu J, 2013, J SYST ARCHITECT, V59, P1005, DOI 10.1016/j.sysarc.2013.08.008
NR 59
TC 6
Z9 6
U1 0
U2 7
PD FEB
PY 2018
VL 112
BP 67
EP 83
DI 10.1016/j.jpdc.2017.10.001
PN 1
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Kimm, H
   Paik, I
   Kimm, H
AF Kimm, Haklin
   Paik, Incheon
   Kimm, Hanke
GP IEEE COMP SOC
TI Performance Comparision of TPU, GPU, CPU on Google Colaboratory over
   Distributed Deep Learning
SO 2021 IEEE 14TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE
   SYSTEMS-ON-CHIP (MCSOC 2021)
DT Proceedings Paper
CT 14th IEEE International Symposium on Embedded Multicore/Many-Core
   Systems-on-Chip (MCSoC)
CY DEC 20-23, 2021
CL Singapore, SINGAPORE
DE Distributed Deep Learning; Google Colab; TPU and GPU; Human Activity
   Recognition; Bidirectional LSTM
AB Deep Learning models need massive amounts compute powers and tend to improve performance running on special purpose processors accelerators designed to speed up compute-intensive applications. The accelerators like Tensor Processing Units (TPUs) and Graphics Processing Units (GPUs) are widely used as deep learning hardware platforms which can often achieve better performance than CPUs, with their massive parallel execution resources and high memory bandwidth. Google Colaboratory known as Colab is a cloud service based on Jupyter Notebook that allows the users to write and execute mostly Python in a browser and admits free access to TPUs and GPUs without extra configuration need, which are widely available cloud hardware platforms. In this paper, we present a through comparison of the hardware platforms on Google Colab that is benchmarked with Distributed Bidirectional Long Short-Term Memory (dBLSTM) models upon the number of layers, the number of units each layer, and the numbers of input and output units the datasets. Human Activity Recognition (HAR) data from UCI machine-learning library have been applied to the proposed distributed bidirectional LSTM model to find the performance, strengths, bottlenecks of the hardware platforms of TPU, GPU and CPU upon hyperparameters, execution time, and evaluation metrics: accuracy, precision, recall and F1 score.
C1 [Kimm, Haklin] East Stroudsburg Univ, Dept Comp Sci, East Stroudsburg, PA 18301 USA.
   [Paik, Incheon] Univ Aizu, Sch Comp Sci & Engn, Fukushima, Japan.
   [Kimm, Hanke] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
RP Kimm, H (corresponding author), East Stroudsburg Univ, Dept Comp Sci, East Stroudsburg, PA 18301 USA.
EM hkimm@esu.edu; paikic@u-aizu.ac.jp; hkimm@cs.stonybrook.edu
CR [Anonymous], 2019, DEEP LEARNING PYTHON
   [Anonymous], 2019, DIVE DEEP LEARNING
   [Anonymous], CORR
   Ben-Nun T., 2018, ARXIV180209941
   Carneiro T, 2018, IEEE ACCESS, V6, P61677, DOI 10.1109/ACCESS.2018.2874767
   Cheng X., 2020, ARXIV200603259
   Dean J., 2017, HOT CHIPS
   Debnath B., 2020, ARXIV200914326
   Fazli M., 2020, ARXIV201016052
   Gao W., 2020, ARXIV200614435
   Goodfellow Ian, 2019, DEEP LEARNING
   Mayer R., 2019, ACM COMPUT SURV, V1
   Pérez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53
   Rainbursingh J., 2019, P IEEE 13 INT S EMB
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang Y E, 2019, ARXIV190710701
NR 16
TC 4
Z9 4
U1 0
U2 4
PY 2021
BP 312
EP 319
DI 10.1109/MCSoC51149.2021.00053
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Fingler, H
   Tarte, I
   Yu, HC
   Szekely, A
   Hu, BD
   Akella, A
   Rossbach, CJ
AF Fingler, Henrique
   Tarte, Isha
   Yu, Hangchen
   Szekely, Ariel
   Hu, Bodun
   Akella, Aditya
   Rossbach, Christopher J.
BE Aamodt, TM
   Jerger, NE
   Swift, M
TI Towards a Machine Learning-Assisted Kernel with LAKE
SO PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL
   SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, VOL 2, ASPLOS
   2023
DT Proceedings Paper
CT 28th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY MAR 25-29, 2023
CL Vancouver, CANADA
DE ML for systems; systems for ML; accelerators; GPU; operating systems
AB The complexity of modern operating systems (OSes), rapid diversification of hardware, and steady evolution of machine learning (ML) motivate us to explore the potential of ML to improve decisionmaking in OS kernels. We conjecture that ML can better manage tradeoff spaces for subsystems such as memory management and process and I/Oscheduling that currently rely on hand-tuned heuristics to provide reasonable average-case performance. We explore the replacement of heuristics with ML-driven decision-making in five kernel subsystems, consider the implications for kernel design, shared OS-level components, and access to hardware acceleration. We identify obstacles, address challenges and characterize tradeoffs for the benefits ML can provide that arise in kernel-space.
   We find that use of specialized hardware such as GPUs is critical to absorbing the additional computational load required byML decisioning, but that poor accessibility of accelerators in kernel space is a barrier to adoption. We also find that the benefits of ML and acceleration for OSes is subsystem-, workload- and hardware-dependent, suggesting that using ML in kernels will require frameworks to help kernel developers navigate new tradeoff spaces. We address these challenge by building a system called LAKE for supporting ML and exposing accelerators in kernel space. LAKE includes APIs for feature collection and management across abstraction layers and module boundaries. LAKE provides mechanisms for managing the variable profitability of acceleration, and interfaces for mitigating contention for resources between user and kernel space. We show that an ML-backed I/O latency predictor can have its inference time reduced by up to 96% with acceleration.
C1 [Fingler, Henrique; Tarte, Isha; Hu, Bodun; Akella, Aditya; Rossbach, Christopher J.] Univ Texas Austin, Austin, TX 78712 USA.
   [Yu, Hangchen] Meta, Menlo Pk, CA USA.
   [Szekely, Ariel] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Fingler, H (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.
EM hfingler@cs.utexas.edu; tarteisha@utexas.edu; athy@meta.com;
   arielck@mit.edu; bodunhu@utexas.edu; akella@cs.utexas.edu;
   rossbach@cs.utexas.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Akgun Ibrahim Umit, 2020, KMLIB MACHINE LEARNI
   Akgun Ibrahim Umit, 2021, P 13 ACM WORKSH HOT, P94, DOI [10.1145/3465332.3470875, DOI 10.1145/3465332.3470875]
   Akshintala Amogh, 2019, 2019 International Conference on High Performance Computing & Simulation (HPCS), P880, DOI 10.1109/HPCS48598.2019.9188169
   Al Maruf H, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P843
   amazon, AM EBS VOL TYP
   azure, INTR NEW PROD INN SA
   bitfusion, BITF EL AI INFR MULT
   Brinkmann Andre, 2009, P C HIGH PERFORMANCE, P35
   Chakraborttii C, 2021, LECT NOTES ARTIF INT, V12460, P427, DOI 10.1007/978-3-030-67667-4_26
   cloud, GOOGLE CLOUD BLOG
   Cortez E, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P153, DOI 10.1145/3132747.3132772
   Demme John, 2013, SIGARCH COMPUT ARCHI, P559, DOI [10.1145/2485922.2485970, DOI 10.1145/2508148.2485970]
   doc.dpdk, DPDK DOC
   Doudali TD, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P37, DOI 10.1145/3307681.3325398
   Druschel P., 1994, Computer Communication Review, V24, P2, DOI 10.1145/190809.190315
   Duato Jose, 2011, 2011 18 INT C HIGH P, P1
   ebpf, EBPF INTR TUT COMM R
   Eskin E, 2001, DISCEX'01: DARPA INFORMATION SURVIVABILITY CONFERENCE & EXPOSITION II, VOL I, PROCEEDINGS, P165, DOI 10.1109/DISCEX.2001.932213
   Fingler Henrique, 2022, Zenodo, DOI 10.5281/ZENODO.7277139
   Fingler Henrique, 2022, Zenodo, DOI 10.5281/ZENODO.7277147
   Fingler H, 2022, INT PARALL DISTRIB P, P739, DOI 10.1109/IPDPS53621.2022.00077
   Ganfure GO, 2020, IEEE T COMPUT AID D, V39, P3311, DOI 10.1109/TCAD.2020.3012173
   Gottschlag M, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), P1721, DOI 10.1109/HPCC.and.EUC.2013.245
   graphcore, GRAPHC ACC MACH LEAR
   Gueron S, 2009, LECT NOTES COMPUT SC, V5665, P51, DOI 10.1007/978-3-642-03317-9_4
   Gupta Vishakha, 2009, P 3 ACM WORKSHOP SYS, P17, DOI DOI 10.1145/1519138.1519141
   Halcrow Mike, 2007, LINUX J, V2007
   Han S, 2010, ACM SIGCOMM COMP COM, V40, P195, DOI 10.1145/1851275.1851207
   Hao MZ, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P173
   Hou SF, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WIW 2016), P104, DOI [10.1109/WIW.2016.15, 10.1109/WIW.2016.040]
   Humphries Jack Tigar, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P588, DOI 10.1145/3477132.3483542
   Hunt T, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P817
   Jain Paras, 2018, 32 C NEUR INF PROC S
   Jin Hee Kim, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293955
   Jingde Chen, 2020, APSys 20. Proceedings of the 2020 SIGOPS Asia-Pacific Workshop on Systems, P67, DOI 10.1145/3409963.3410492
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Käsper E, 2009, LECT NOTES COMPUT SC, V5747, P1
   Kaffes Kostis, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P134, DOI 10.1145/3419111.3421274
   Kang Y, 2013, IEEE S MASS STOR SYS
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Kim G, 2016, Arxiv, DOI arXiv:1611.01726
   Kim J, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P715
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kutch Patrick, 2011, 321211002 INT
   Laga A, 2016, IEEE NON-VOLATILE ME
   Landgraf J, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P818, DOI [10.1145/3445814.344675, 10.1145/3445814.3446755]
   Lin WC, 2017, IEEE INT CONF EMBED
   Liu M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3214304
   Lozi JP, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901326
   Maas M, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P541, DOI 10.1145/3373376.3378525
   Meswani MR, 2015, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2015.7056027
   Negi Atul, 2005, TENCON 2005 2005 IEE, P1
   Nishtala R, 2017, INT S HIGH PERF COMP, P409, DOI 10.1109/HPCA.2017.13
   Nobile MS, 2017, BRIEF BIOINFORM, V18, P870, DOI 10.1093/bib/bbw058
   nvidia, NVIDIA REL OP SOURC
   nvidia, OPT REC NEUR NETW CU
   Ousterhout A, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P361
   Pinneterre S, 2018, IEEE INT SYM BROADB
   Pratt I, 2001, IEEE INFOCOM SER, P67, DOI 10.1109/INFCOM.2001.916688
   Raina Rajat, 2009, INT C MACHINE LEARNI, P873, DOI DOI 10.1145/1553374.1553486
   Reaño C, 2012, INT C HIGH PERFORM
   Rossbach CJ, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P233
   Shi L, 2012, IEEE T COMPUT, V61, P804, DOI 10.1109/TC.2011.112
   Shriver E, 1999, PROCEEDINGS OF THE 1999 USENIX ANNUAL TECHNICAL CONFERENCE, P71
   Smith Warren, 2006, PREDICTING APPL RUN, V64, P122, DOI [10.1007/BFb0053984, DOI 10.1007/BFB0053984]
   Sukharev Pavel, 2019, INT J ADV SCI ENG IN, V9, P1528, DOI [10.18517/ijaseit.9.5.5820, DOI 10.18517/IJASEIT.9.5.5820]
   Sun WB, 2013, Arxiv, DOI arXiv:1305.3345
   Sun WB, 2013, 2013 ACM/IEEE SYMPOSIUM ON ARCHITECTURES FOR NETWORKING AND COMMUNICATIONS SYSTEMS (ANCS), P25, DOI 10.1109/ANCS.2013.6665173
   Sun Weibin, 2012, P 5 ANN INT SYST STO, P9
   Suranauwarat S., 2001, Operating Systems Review, V35, P61, DOI 10.1145/506084.506090
   Suzuki Yusuke, 2014, 2014 USENIX ANN TECH, P109
   Tian Kun, 2014, P 2014 USENIX C USEN, P121
   Volos S, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P681
   von Eicken T., 1995, Operating Systems Review, V29, P40, DOI 10.1145/224057.224061
   Vu Lan, 2014, P HIGH PERFORMANCE C
   Wang YW, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P622, DOI 10.1145/3503222.3507704
   Xu ZY, 2019, IEEE J SEL AREA COMM, V37, P1325, DOI 10.1109/JSAC.2019.2904358
   Yeh TT, 2017, ACM SIGPLAN NOTICES, V52, P221, DOI [10.1145/3155284.3018754, 10.1145/3018743.3018754]
   Yiming Qiu, 2021, HotOS '21: Proceedings of the Workshop on Hot Topics in Operating Systems, P175, DOI 10.1145/3458336.3465288
   Yiying Zhang, 2019, ACM SIGOPS Operating Systems Review, V53, P40, DOI 10.1145/3352020.3352027
   Yu HC, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P807, DOI 10.1145/3373376.3378466
   Zhang X, 2013, P 8 ACM EUROPEAN C C, P379
NR 85
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 846
EP 861
DI 10.1145/3575693.3575697
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Chen, YR
   Xie, Y
   Song, LH
   Chen, F
   Tang, TQ
AF Chen, Yiran
   Xie, Yuan
   Song, Linghao
   Chen, Fan
   Tang, Tianqi
TI A Survey of Accelerator Architectures for Deep Neural Networks
SO ENGINEERING
DT Review
DE Deep neural network; Domain-specific architecture; Accelerator
ID DIANNAO
AB Recently, due to the availability of big data and the rapid growth of computing power, artificial intelligence (AI) has regained tremendous attention and investment. Machine learning (ML) approaches have been successfully applied to solve many problems in academia and in industry. Although the explosion of big data applications is driving the development of ML, it also imposes severe challenges of data processing speed and scalability on conventional computer systems. Computing platforms that are dedicatedly designed for AI applications have been considered, ranging from a complement to von Neumann platforms to a "must-have" and stand-alone technical solution. These platforms, which belong to a larger category named "domain-specific computing," focus on specific customization for AI. In this article, we focus on summarizing the recent advances in accelerator designs for deep neural networks (DNNs)-that is, DNN accelerators. We discuss various architectures that support DNN executions in terms of computing units, dataflow optimization, targeted network topologies, architectures on emerging technologies, and accelerators for emerging applications. We also provide our visions on the future trend of AI chip designs. (C) 2020 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.
C1 [Chen, Yiran; Song, Linghao; Chen, Fan] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
   [Xie, Yuan; Tang, Tianqi] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
RP Chen, YR (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
EM yiran.chen@duke.edu
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ambrogio S, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   [Anonymous], P 30 INT C NEUR INF
   [Anonymous], 8 BIT INFERENCE TENS
   [Anonymous], THE MNIST DATABASE
   [Anonymous], 2015, P 2015 52 ACM EDAC I
   [Anonymous], P 2019 IEEE INT SOL
   [Anonymous], 2016, ARXIV160704381
   [Anonymous], 49 ANN IEEE ACM INT
   [Anonymous], 2011, P 2011 IEEE HOT CHIP
   [Anonymous], 2017, LOW POWER ELECT DESI, DOI DOI 10.1109/ISLPED.2017.8009163
   [Anonymous], P 2017 IEEE INT S HI
   Beckmann K, 2016, MRS ADV, V1, P3355, DOI 10.1557/adv.2016.377
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Chen A, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Chen F, 2018, EUR J MED RES, V23, DOI 10.1186/s40001-018-0320-2
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YY, 2013, IEEE T ELECTRON DEV, V60, P1114, DOI 10.1109/TED.2013.2241064
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cho K., 2014, P 19 C EMPIRICAL MET, P1, DOI [10.3115/v1/D14-1179, DOI 10.3115/V1/D14-1179, 10.3115]
   Choi S, 2014, NANOSCALE, V6, P400, DOI 10.1039/c3nr05016e
   Dongale TD, 2015, MAT SCI SEMICON PROC, V35, P174, DOI 10.1016/j.mssp.2015.03.015
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2015, COMMUN ACM, V58, P105, DOI 10.1145/2589750
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Guo XC, 2010, CONF PROC INT SYMP C, P371, DOI 10.1145/1816038.1816012
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Jain S, 2018, DES AUT CON, DOI 10.1145/3195970.3196012
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KEENER JP, 1981, SIAM J APPL MATH, V41, P503, DOI 10.1137/0141042
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Liu CC, 2016, IEEE COMP SOC ANN, P110, DOI 10.1109/ISVLSI.2016.46
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lu H, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240855
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Mao HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P669, DOI [10.1109/MICRO.2018.00060, 10.1109/MICR0.2018.00060]
   McCarthy J, 2006, AI MAG, V27, P12
   MCCULLOCH WS, 1990, B MATH BIOL, V52, P99, DOI 10.1016/S0092-8240(05)80006-0
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Pino RE, 2012, DES AUT CON, P585
   Qiao XM, 2018, DES AUT CON, DOI 10.1145/3195970.3195998
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Song MC, 2018, INT S HIGH PERF COMP, P66, DOI 10.1109/HPCA.2018.00016
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Turing A. M., 1950, MIND, V59, P433, DOI https://doi.org/10.1093/mind/LIX.236.433
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Yazdanbakhsh A, 2018, CONF PROC INT SYMP C, P650, DOI 10.1109/ISCA.2018.00060
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 65
TC 124
Z9 128
U1 14
U2 65
PD MAR
PY 2020
VL 6
IS 3
BP 264
EP 274
DI 10.1016/j.eng.2020.01.007
WC Engineering, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Mouselinos, S
   Leon, V
   Xydis, S
   Soudris, D
   Pekmestzi, K
AF Mouselinos, Spyridon
   Leon, Vasileios
   Xydis, Sotirios
   Soudris, Dimitrios
   Pekmestzi, Kiamal
GP IEEE
TI TF2FPGA: A Framework for Projecting and Accelerating Tensorflow CNNs on
   FPGA Platforms
SO 2019 8TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS
   TECHNOLOGIES (MOCAST)
DT Proceedings Paper
CT 8th International Conference on Modern Circuit and System Technologies
   (MOCAST)
CY MAY 13-15, 2019
CL Thessaloniki, GREECE
DE Machine Learning; Convolutional Neural Networks; FPGA Accelerators;
   Dataflow Hardware Mapping
AB FPGA-based accelerators of Convolutional Neural Networks (CNNs) deliver significant performance, while leaving much room for optimizations. In this paper, we present a CNN accelerator based on the state-of-the-art Dataflow Hardware Mapping (DHM) methodology, optimized with the use of 8-bit unsigned integer quantization, 1-bit input mapping and deep-to-shallow conversion techniques. Interestingly, we introduce a Tensorflow-to-VHDL framework to generate high-performance accelerators for inferencing on FPGAs, adopting a holistic view of CNN problems. The proposed framework uses a VHDL library of our pre-optimized layers and modules, and creates the accelerator by extracting the model definition and weights from the respective Tensorflow files. The 8-bit quantized weights are stored in an on-board ROM memory, and thus, the need for external-to-FPGA "glue logic" modules and increased bandwidth is eliminated. Additionally, we include a Matrix Multiplication-to-FIR conversion method that manages to include the fully connected part of the CNN inside the FPGA. Finally, we achieve 75% less memory footprint and 53% less resource utilization compared to the state-of-the-art based architectures, and up to x10 speedup vs different GPU, CPU combinations.
C1 [Mouselinos, Spyridon; Leon, Vasileios; Xydis, Sotirios; Soudris, Dimitrios; Pekmestzi, Kiamal] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
RP Mouselinos, S (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
EM mouselinos.spur.kw@gmail.com; vleon@microlab.ntua.gr;
   sxydis@microlab.ntua.gr; dsoudris@microlab.ntua.gr;
   pekmes@microlab.ntua.gr
CR Abadi Martin, 2016, arXiv
   Abdelouahab K., 2017, CORR
   Ba LJ, 2014, ADV NEURAL INFORM PR, V3, P2654, DOI DOI 10.5555/2969033.2969123
   Chellappa R, 1998, IEEE T IMAGE PROCESS, V7, P1093, DOI 10.1109/TIP.1998.704303
   Dennis J. B., 1975, 2nd Annual Symposium on Computer Architecture, P126
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Iandola F. N., 2016, ARXIV
   Komodakis N, 2016, BMVC, P1, DOI DOI 10.5244/C.30.87
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lai L., 2017, CORR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Shariatmadari H, 2016, 2016 IEEE 27TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P188
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
NR 14
TC 8
Z9 8
U1 0
U2 2
PY 2019
DI 10.1109/mocast.2019.8741940
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Abts, D
   Ross, J
   Sparling, J
   Wong-VanHaren, M
   Baker, M
   Hawkins, T
   Bell, A
   Thompson, J
   Kahsai, T
   Kimmell, G
   Hwang, J
   Leslie-Hurd, R
   Bye, M
   Creswick, ER
   Boyd, M
   Venigalla, M
   Laforge, E
   Purdy, J
   Kamath, P
   Maheshwari, D
   Beidler, M
   Rosseel, G
   Ahmad, O
   Gagarin, G
   Czekalski, R
   Rane, A
   Parmar, S
   Werner, J
   Sproch, J
   Macias, A
   Kurtz, B
AF Abts, Dennis
   Ross, Jonathan
   Sparling, Jonathan
   Wong-VanHaren, Mark
   Baker, Max
   Hawkins, Tom
   Bell, Andrew
   Thompson, John
   Kahsai, Temesghen
   Kimmell, Garrin
   Hwang, Jennifer
   Leslie-Hurd, Rebekah
   Bye, Michael
   Creswick, E. R.
   Boyd, Matthew
   Venigalla, Mahitha
   Laforge, Evan
   Purdy, Jon
   Kamath, Purushotham
   Maheshwari, Dinesh
   Beidler, Michael
   Rosseel, Geert
   Ahmad, Omar
   Gagarin, Gleb
   Czekalski, Richard
   Rane, Ashay
   Parmar, Sahil
   Werner, Jeff
   Sproch, Jim
   Macias, Adrian
   Kurtz, Brian
GP IEEE
TI Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep
   Learning Workloads
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
ID ARCHITECTURE
AB In this paper, we introduce the Tensor Streaming Processor (TSP) architecture, a functionally-sliced microarchitecture with memory units interleaved with vector and matrix deep learning functional units in order to take advantage of dataflow locality of deep learning operations. The TSP is built based on two key observations: (1) machine learning workloads exhibit abundant data parallelism, which can be readily mapped to tensors in hardware, and (2) a simple and deterministic processor with producer-consumer stream programming model enables precise reasoning and control of hardware components, achieving good performance and power efficiency. The TSP is designed to exploit parallelism inherent in machine-learning workloads including instruction-level, memory concurrency, data and model parallelism, while guaranteeing determinism by eliminating all reactive elements in the hardware (e.g. arbiters, and caches). Early ResNet50 image classification results demonstrate 20.4K processed images per second (IPS) with a batch-size of onea 4x improvement compared to other modern GPUs and accelerators [44]. Our first ASIC implementation of the TSP architecture yields a computational density of more than 1 TeraOp/s per square mm of silicon for its 25x29 mm 14nm chip operating at a nominal clock frequency of 900 MHz. The TSP demonstrates a novel hardware-software approach to achieve fast, yet predictable, performance on machine-learning workloads within a desired power envelope.
C1 [Abts, Dennis; Ross, Jonathan; Sparling, Jonathan; Wong-VanHaren, Mark; Baker, Max; Hawkins, Tom; Bell, Andrew; Thompson, John; Kahsai, Temesghen; Kimmell, Garrin; Hwang, Jennifer; Leslie-Hurd, Rebekah; Bye, Michael; Creswick, E. R.; Boyd, Matthew; Venigalla, Mahitha; Laforge, Evan; Purdy, Jon; Kamath, Purushotham; Maheshwari, Dinesh; Beidler, Michael; Rosseel, Geert; Ahmad, Omar; Gagarin, Gleb; Czekalski, Richard; Rane, Ashay; Parmar, Sahil; Werner, Jeff; Sproch, Jim; Macias, Adrian; Kurtz, Brian] Groq Inc, Mountain View, CA 94041 USA.
RP Abts, D (corresponding author), Groq Inc, Mountain View, CA 94041 USA.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Ahn J.H., 2009, P C HIGH PERFORMANCE, P1, DOI DOI 10.1145/1654059.1654101
   Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Akin B, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P126, DOI 10.1145/3352460.3358305
   Almasi George, 2011, ENCY PARALLEL COMPUT, P1539
   Andreyev A., INTRO DATA CTR FABRI
   [Anonymous], 2016, ARXIV161101491
   [Anonymous], 2003, SUPERCOMPUTING SC
   Azizimazreah A, 2019, INT S HIGH PERF COMP, P94, DOI 10.1109/HPCA.2019.00030
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Barroso L. A., 2009, DATACENTER COMPUTER
   Barroso LA, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P282, DOI [10.1109/ISCA.2000.854398, 10.1145/342001.339696]
   Barroso LA, 2007, COMPUTER, V40, P33, DOI 10.1109/MC.2007.443
   Barroso Luiz Andre, 2010, INT C MAN DAT SIGMOD
   Dally W. J., 2004, PRINCIPLES PRACTICES
   DALLY WJ, 1992, IEEE T PARALL DISTR, V3, P194, DOI 10.1109/71.127260
   Dally WJ, 2001, DES AUT CON, P684, DOI 10.1109/DAC.2001.935594
   Dean J., 2012, NIPS 12, P1223
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Deng CH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P264, DOI 10.1145/3307650.3322258
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Gudaparthi S, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P1, DOI 10.1145/3352460.3358316
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hegde K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P933, DOI [10.1109/MICR0.2018.00080, 10.1109/MICRO.2018.00080]
   Hua WZ, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P139, DOI 10.1145/3352460.3358283
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khailany B, 2001, IEEE MICRO, V21, P35, DOI 10.1109/40.918001
   Kim H, 2019, INT S HIGH PERF COMP, P661, DOI 10.1109/HPCA.2019.00017
   Kim J, 2005, CONF PROC INT SYMP C, P420, DOI 10.1109/ISCA.2005.35
   Lascorz AD, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P28, DOI 10.1145/3352460.3358295
   Li YJ, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P279, DOI [10.1145/3307650.3322259, 10.1109/yac.2019.8787727]
   Li YJ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P175, DOI 10.1109/MICRO.2018.00023
   Mahmoud M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P134, DOI 10.1109/MICRO.2018.00020
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Melvin Stephen W, 1984, INT C SYST SCI
   Nakhjavani RS, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P137, DOI 10.1109/HPCSim.2014.6903679
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Patterson David, 1990, COMPUTER ARCHITECTUR
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Scott S, 2006, CONF PROC INT SYMP C, P16, DOI 10.1145/1150019.1136488
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Smith J. E., 1982, 9th Annual Symposium on Computer Architecture, P112
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Song MC, 2018, CONF PROC INT SYMP C, P752, DOI 10.1109/ISCA.2018.00068
   Vaswani A., 2017, P ADV NEURAL INFORM, P5998
   Wentzlaff D, 2007, IEEE MICRO, V27, P15, DOI 10.1109/MM.2007.4378780
   Williams S, 2009, ROOFLINE INSIGHTFUL
   Wu Y, 2016, ARXIV
   Xu RG, 2018, PROCEEDINGS OF 2018 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2018), P23, DOI [10.1109/PMBS.2018.00006, 10.1109/PMBS.2018.8641600]
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang JQ, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P292, DOI 10.1145/3307650.3322263
   Zhu YH, 2018, CONF PROC INT SYMP C, P547, DOI 10.1109/ISCA.2018.00052
NR 56
TC 29
Z9 29
U1 1
U2 9
PY 2020
BP 145
EP 158
DI 10.1109/ISCA45697.2020.00023
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Mao, G
   Yakovlev, A
   Xia, F
   Lan, T
   Yu, SQ
   Shafik, R
AF Mao, Gang
   Yakovlev, Alex
   Xia, Fei
   Lan, Tian
   Yu, Shengqi
   Shafik, Rishad
GP IEEE
TI Automated Synthesis of Asynchronous Tsetlin Machines on FPGA
SO 2022 29TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND
   SYSTEMS (IEEE ICECS 2022)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 29th IEEE International Conference on Electronics, Circuits and Systems
   (IEEE ICECS)
CY OCT 24-26, 2022
CL Glasgow, SCOTLAND
DE Asynchronous circuit; Machine learning; Tsetlin machine; QDI
AB Implementing custom machine learning (ML) accelerators involves running thousands if not millions of clock cycles of simulations per training epoch and is infeasible in low-level commercial EDA tools. This task becomes even more difficult if the ML hardware is asynchronous rather than clocked. Asynchronous designs provide towards significant energy-efficiency, which is the most important challenge in artificial intelligence (AI) today. Field programmable gate array (FPGA) based prototyping could help make design automation feasible, but existing FPGAs are clocked, and adapting them for implementing asynchronous circuits is challenging. This is primarily because FPGAs violate the usual timing constraints in those circuits, such as isochronic forks. This paper addresses the core aspect of design automation of asynchronous circuits through FPGAs by solving the problem of mapping critical timing constraints while retaining important delay-insensitivity properties in a range of algorithms compatible with the FPGA synthesis tools. Our case study involves circuits implementing a novel ML algorithm, known as the Tsetlin machine, the central part of a TM, and majority voting are synthesized. Different scales of circuits with up to 9513 LUTs implement the clause generator.
C1 [Mao, Gang; Yakovlev, Alex; Xia, Fei; Lan, Tian; Yu, Shengqi; Shafik, Rishad] Newcastle Univ, Microsyst Res Grp, Newcastle Upon Tyne, Tyne & Wear, England.
RP Mao, G (corresponding author), Newcastle Univ, Microsyst Res Grp, Newcastle Upon Tyne, Tyne & Wear, England.
EM g.mao2@newcastle.ac.uk; alex.yakovlev@newcastle.ac.uk;
   fei.xia@newcastle.ac.uk; t.lan3@newcastle.ac.uk; s.yu10@newcastle.ac.uk;
   rishad.shafik@newcastle.ac.uk
CR Dashkin R., 2021, IEEE T COMPUTER AIDE
   Furushima J, 2016, INFORM-J COMPUT INFO, V40, P399
   Granmo OC, 2021, Arxiv, DOI arXiv:1804.01508
   Hauck S., 1992, FPL
   Kushnerov A, 2021, INT SYMP ASYNCHRON C, P17, DOI 10.1109/ASYNC48570.2021.00011
   Lan T., 2022, ISTM 22
   Li Y., 2011, DATE
   Lines A, 2018, INT SYMP ASYNCHRON C, P32, DOI 10.1109/ASYNC.2018.00018
   Low H. S., 2014, FPL
   Manoranjan JV, 2014, 2014 IX SOUTHERN CONFERENCE ON PROGRAMMABLE LOGIC (SPL 2014)
   Mao G., 2022, ISVLSI 2022
   MARTIN AJ, 1986, DISTRIB COMPUT, V1, P226, DOI 10.1007/BF01660034
   Shafik R, 2018, IEEE T COMPUT, V67, P1445, DOI 10.1109/TC.2018.2822697
   Stevens KS, 2003, IEEE T VLSI SYST, V11, P129, DOI 10.1109/TVLSI.2002.801606
   Tsetlin M. L., 1973, AUTOMATON THEORY MOD, V102
   Wheeldon A, 2021, INT SYMP ASYNCHRON C, P40, DOI 10.1109/ASYNC48570.2021.00014
   Workcraft homepage, US
   Xu Y, 2009, PR IEEE COMP DESIGN, P16, DOI 10.1109/ICCD.2009.5413183
   Yakovlev A., 1992, 1992 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.92CH03183-1), P104, DOI 10.1109/ICCAD.1992.279390
NR 19
TC 0
Z9 0
U1 0
U2 1
PY 2022
DI 10.1109/ICECS202256217.2022.9970999
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Huang, YP
   Cheng, YL
   Bapna, A
   Firat, O
   Chen, MX
   Chen, DH
   Lee, H
   Ngiam, J
   Le, QV
   Wu, YH
   Chen, ZF
AF Huang, Yanping
   Cheng, Youlong
   Bapna, Ankur
   Firat, Orhan
   Chen, Mia Xu
   Chen, Dehao
   Lee, HyoukJoong
   Ngiam, Jiquan
   Le, Quoc V.
   Wu, Yonghui
   Chen, Zhifeng
BE Wallach, H
   Larochelle, H
   Beygelzimer, A
   d'Alche-Buc, F
   Fox, E
   Garnett, R
TI GPipe: Efficient Training of Giant Neural Networks using Pipeline
   Parallelism
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 32 (NIPS 2019)
SE Advances in Neural Information Processing Systems
DT Proceedings Paper
CT 33rd Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 08-14, 2019
CL Vancouver, CANADA
AB Scaling up deep neural network capacity has been known as an effective approach to improving model quality for several different machine learning tasks. In many cases, increasing model capacity beyond the memory limit of a single accelerator has required developing special algorithms or infrastructure. These solutions are often architecture-specific and do not transfer to other tasks. To address the need for efficient and task-independent model parallelism, we introduce GPipe, a pipeline parallelism library that allows scaling any network that can be expressed as a sequence of layers. By pipelining different sub-sequences of layers on separate accelerators, GPipe provides the flexibility of scaling a variety of different networks to gigantic sizes efficiently. Moreover, GPipe utilizes a novel batchsplitting pipelining algorithm, resulting in almost linear speedup when a model is partitioned across multiple accelerators. We demonstrate the advantages of GPipe by training large-scale neural networks on two different tasks with distinct network architectures: (i) Image Classification: We train a 557-million-parameter AmoebaNet model and attain a top-1 accuracy of 84.4% on ImageNet-2012, (ii) Multilingual Neural Machine Translation: We train a single 6-billion-parameter, 128-layer Transformer model on a corpus spanning over 100 languages and achieve better quality than all bilingual models.
EM huangyp@google.com; ylc@google.com; ankurbpn@google.com;
   orhanf@google.com; miachen@google.com; dehao@google.com;
   hyouklee@google.com; jngiam@google.com; qvl@google.com;
   yonghui@google.com; zhifengc@google.com
CR Arivazhagan N., 2019, ARXIV190705019
   Auli M., 2019, ABS190110430 CORR
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen Mia Xu, 2018, ABS180409849 CORR
   Chen Tianqi, 2016, ARXIV160406174
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Cubuk E.D., 2018, ARXIV180509501
   Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, PREPRINT
   DeVries T., 2017, ARXIV
   Gehring J., 2017, ARXIV170503122, P1243, DOI DOI 10.18653/V1/P16-1220
   Griewank A, 2000, ACM T MATH SOFTWARE, V26, P19, DOI 10.1145/347837.347846
   Harlap A., 2018, ARXIV180603377
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kornblith S., 2018, CORR
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Lee S, 2014, ADV NEUR IN, V27
   Li M, 2014, 11 USENIX S OP SYST, P583, DOI DOI 10.1145/2640087.2644155
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Ngiam Jiquan, 2018, ARXIV181107056
   Peng Chao, 2017, CVPR, V7
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Peters M., 2018, ACL
   PETROWSKI A, 1993, IEEE T NEURAL NETWOR, V4, P970, DOI 10.1109/72.286892
   Radford A., 2019, OPENAI BLOG
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Real E., 2019, P AAAI C ART INT, DOI DOI 10.1609/AAAI.V33I01.33014780
   Shazeer N, 2018, ADV NEUR IN, V31
   Shen J., 2019, ARXIV190208295
   Socher Richard, 2017, ADV NEURAL INFORM PR, P6297
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vaswani A., 2017, P 31 INT C NEURAL IN
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Wu Yonghui, 2017, T ASS COMPUTATIONAL
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang Hongyi, 2019, ARXIV190109321
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 46
TC 302
Z9 306
U1 7
U2 10
PY 2019
VL 32
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Chen, YJ
   Luo, T
   Liu, SL
   Zhang, SJ
   He, LQ
   Wang, J
   Li, L
   Chen, TS
   Xu, ZW
   Sun, NH
   Temam, O
AF Chen, Yunji
   Luo, Tao
   Liu, Shaoli
   Zhang, Shijin
   He, Liqiang
   Wang, Jia
   Li, Ling
   Chen, Tianshi
   Xu, Zhiwei
   Sun, Ninghui
   Temam, Olivier
GP IEEE
TI DaDianNao: A Machine-Learning Supercomputer
SO 2014 47TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
SE International Symposium on Microarchitecture Proceedings
DT Proceedings Paper
CT 47th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY DEC 13-17, 2014
CL Cambridge, ENGLAND
AB Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses.
   However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on-chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system. We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects.
C1 [Chen, Yunji; Luo, Tao; Liu, Shaoli; Zhang, Shijin; Wang, Jia; Li, Ling; Chen, Tianshi; Xu, Zhiwei; Sun, Ninghui] Chinese Acad Sci, ICT, SKL Comp Architecture, Beijing, Peoples R China.
   [He, Liqiang; Temam, Olivier] Inria, Scalay, France.
   [Luo, Tao] Univ CAS, Beijing, Peoples R China.
   [He, Liqiang] Inner Mongolia Univ, Hohhot, Peoples R China.
RP Chen, YJ (corresponding author), Chinese Acad Sci, ICT, SKL Comp Architecture, Beijing, Peoples R China.
CR [Anonymous], INT S VLSI CIRC VLSI
   [Anonymous], ANN C NEUR INF PROC
   [Anonymous], 2012, P 17 C EL POW DISTR
   [Anonymous], INT C INF KNOWL MAN
   [Anonymous], DDR3 SDRAM RDIMM DAT
   [Anonymous], INT S MICR
   [Anonymous], NEURAL COMPUTATION
   [Anonymous], IEEE T INFORM THEORY
   [Anonymous], 2013, INT C MACH LEARN
   [Anonymous], INT S COMP ARCH NEW
   [Anonymous], 2013, IEEE INT C ACOUSTICS
   [Anonymous], IEEE INT EL DEV M IE
   [Anonymous], INT S COMP ARCH
   [Anonymous], INT S COMP ARCH
   [Anonymous], 2008, INT C PAR ARCH COMP
   [Anonymous], 2011, P DEEP LEARN UNS FEA
   [Anonymous], IEEE INT EL DEV M IE
   [Anonymous], 1998, P IEEE
   [Anonymous], 2012, TECHNICAL REPORT
   [Anonymous], IEEE MICRO
   [Anonymous], IEEE T VERY LARGE SC
   [Anonymous], HOT CHIPS
   [Anonymous], INT C ARCH SUPP PROG
   [Anonymous], EE TIM DES ARM VIRT
   [Anonymous], 2014, INT C ARCH SUPP PROG
   [Anonymous], 2005, TECHNOLOGY INTEL MAG
   [Anonymous], 2012, INT C MACH LEARN
   [Anonymous], P 38 INT S COMP ARCH
   [Anonymous], INT S COMP ARCH PORT
   Bengio, 2007, ICML, P473
   Ciresan D., 2011, P 22 INT JOINT C ART, V2, P1237
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dally W., 2003, PRINCIPLES PRACTICES
   Deng J., 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Fan K, 2009, INT S HIGH PERF COMP, P313, DOI 10.1109/HPCA.2009.4798266
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Huang LB, 2012, IEEE T COMPUT, V61, P745, DOI 10.1109/TC.2011.77
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Matick RE, 2005, IBM J RES DEV, V49, P145, DOI 10.1147/rd.491.0145
   Merolla P, 2011, IEEE CUST INTEGR CIR
   Mnih V., 2012, P 29 INT C MACH LEAR, P567, DOI DOI 10.5555/3042573.3042603
   Schemmel J, 2008, IEEE IJCNN, P431, DOI 10.1109/IJCNN.2008.4633828
NR 48
TC 873
Z9 972
U1 7
U2 131
PY 2014
BP 609
EP 622
DI 10.1109/MICRO.2014.58
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Zhang, YW
   Wang, C
   Gong, L
   Lu, YT
   Sun, F
   Xu, CC
   Li, X
   Zhou, XH
AF Zhang, Yiwei
   Wang, Chao
   Gong, Lei
   Lu, Yuntao
   Sun, Fan
   Xu, Chongchong
   Li, Xi
   Zhou, Xuehai
BE Wang, G
   Fox, G
   Martinez, G
   Hill, R
   Mueller, P
TI Implementation and Optimization of the Accelerator Based on FPGA
   Hardware for LSTM Network
SO 2017 15TH IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED
   PROCESSING WITH APPLICATIONS AND 2017 16TH IEEE INTERNATIONAL CONFERENCE
   ON UBIQUITOUS COMPUTING AND COMMUNICATIONS (ISPA/IUCC 2017)
SE IEEE International Symposium on Parallel and Distributed Processing with
   Applications
DT Proceedings Paper
CT 15th IEEE International Symposium on Parallel and Distributed Processing
   with Applications (ISPA) / 16th IEEE International Conference on
   Ubiquitous Computing and Communications (IUCC)
CY DEC 12-15, 2017
CL Guangzhou, PEOPLES R CHINA
AB Today, artificial neural networks (ANNs) are important machine learning methods which are widely used in a variety of applications. As the emerging field of ANNs, recurrent neural networks (RNNs) are often used for sequence-related applications. And Long Short-Term Memory (LSTM) is an improved RNN which contains complex computational logic. To achieve high accuracy, researchers always build large-scale LSTM networks which are time-consuming and power-consuming. Thus the acceleration of LSTM networks, low power & energy consumption become the hot issues in today's research. In this paper, we present a hardware accelerator for the LSTM neural network layer based on FPGA Zedboard and use pipeline methods to parallelize the forward computing process. To optimize our implementation, we also use multiple methods including tiled matrix-vector multiplication, binary adder tree, and overlap of computation and data access. Through the acceleration and optimization methods, our accelerator is power-efficient and has a better performance than ARM Cortex A9 processor and Intel Core i5 processor.
C1 [Zhang, Yiwei] USTC, Dept Comp Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   USTC, Suzhou Inst Adv Study, Suzhou, Peoples R China.
RP Zhang, YW (corresponding author), USTC, Dept Comp Sci & Technol, Hefei 230027, Anhui, Peoples R China.
EM zhyiwei@mail.ustc.edu.cn; cswang@ustc.edu.cn;
   leigong0203@mail.ustc.edu.cn; luyuntao@mail.ustc.edu.cn;
   sunfan@mail.ustc.edu.cn; xcc2448@mail.ustc.edu.cn; llxx@ustc.edu.cn;
   xhzhou@ustc.edu.cn
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P115
   [Anonymous], 2012, FIELD PROGRAMMABLE G
   [Anonymous], 2011, P IEEE HCS, DOI DOI 10.1109/HOTCHIPS.2011.7477509
   [Anonymous], 2015, ZYNQ BOOK TUTORIALS
   [Anonymous], 2014, INTEL POWER GADGET
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Chao Wang, 2011, 2011 IEEE 9th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P107, DOI 10.1109/ISPA.2011.40
   Feist T., 2012, CISC VIS NETW IND GL, V5, P30
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K., 2016, ARXIV150304069, V28, P2222, DOI DOI 10.1109/TNNLS.2016.2582924
   Han Song, 2015, C NEUR INF PROC SYST
   Himavathi S, 2007, IEEE T NEURAL NETWOR, V18, P880, DOI 10.1109/TNN.2007.891626
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Storace M, 2011, INT J CIRC THEOR APP, V39, P1, DOI 10.1002/cta.610
   Tavcar R, 2013, INFORM MIDEM, V43, P131
   Temurtas H, 2009, EXPERT SYST APPL, V36, P8610, DOI 10.1016/j.eswa.2008.10.032
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Wang C., 2017, IEEE T PARALLEL DIST
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang C, 2012, J SUPERCOMPUT, V62, P1404, DOI 10.1007/s11227-012-0810-x
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 26
TC 10
Z9 13
U1 1
U2 10
PY 2017
BP 614
EP 621
DI 10.1109/ISPA/IUCC.2017.00098
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications;
   Telecommunications
DA 2023-11-11
ER

PT C
AU Makrani, HM
   Sayadi, H
   Mohsenin, T
   Rafatirad, S
   Sasan, A
   Homayoun, H
AF Makrani, Hosein Mohammadi
   Sayadi, Hossein
   Mohsenin, Tinoosh
   Rafatirad, Setareh
   Sasan, Avesta
   Homayoun, Houman
GP ACM
TI XPPE: Cross-Platform Performance Estimation of Hardware Accelerators
   Using Machine Learning
SO 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019)
DT Proceedings Paper
CT 24th Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 21-24, 2019
CL Natl Museum Emerging Sci & Innovat, Tokyo, JAPAN
HO Natl Museum Emerging Sci & Innovat
DE Design space exploration; performance estimation; machine learning;
   accelerator
AB The increasing heterogeneity in the applications to be processed ceased ASICs to exist as the most efficient processing platform. Hybrid processing platforms such as CPU+FPGA are emerging as powerful processing platforms to support an efficient processing for a diverse range of applications. Hardware/Software co-design enabled designers to take advantage of these new hybrid platforms such as Zynq. However, dividing an application into two parts that one part runs on CPU and the other part is converted to a hardware accelerator implemented on FPGA, is making the platform selection difficult for the developers as there is a significant variation in the application's performance achieved on different platforms. Developers are required to fully implement the design on each platform to have an estimation of the performance. This process is tedious when the number of available platforms is large. To address such challenge, in this work we propose XPPE, a neural network based cross-platform performance estimation. XPPE utilizes the resource utilization of an application on a specific FPGA to estimate the performance on other FPGAs. The proposed estimation is performed for a wide range of applications and evaluated against a vast set of platforms. Moreover, XPPE enables developers to explore the design space without requiring to fully implement and map the application. Our evaluation results show that the correlation between the estimated speed up using XPPE and actual speedup of applications on a Hybrid platform over an ARM processor is more than 0.98.
C1 [Makrani, Hosein Mohammadi; Sayadi, Hossein; Mohsenin, Tinoosh; Rafatirad, Setareh; Sasan, Avesta; Homayoun, Houman] George Mason Univ, Fairfax, VA 22030 USA.
RP Makrani, HM (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
EM hmohamm8@gmu.edu; hsayadi@gmu.edu; tmohseni@gmu.edu; srafatir@gmu.edu;
   asasan@gmu.edu; hhomyou@gmu.edu
CR [Anonymous], ACM T RECONFIGURABLE
   [Anonymous], 2014, IISWC
   [Anonymous], SOCC
   [Anonymous], ICCD
   Azar K. Z., 2019, IACR T CRYPTOGRAPHIC, P97
   Choi Y.-k., 2017, FCCM
   Choi Y.-k., 2017, ICCAD
   Farahmand F., 2017, RECONFIG
   Hara Yuko, 2008, ISCAS
   Holland B, 2011, ACM T RECONFIG TECHN, V4, DOI 10.1145/2000832.2000839
   Jimenez-Gonzalez Daniel, 2015, INT WORKSH FPGAS SOF
   Koeplinger D., 2016, ISCA
   Makrani Hosein Mohammadi, 2018, IEEE ASAP
   Makrani Hosein Mohammadi, 2017, IISWC
   Neshatpour Katayoun, 2018, FCCM
   Neshatpour Katayoun, 2018, SAMOS
   Rezaei S., 2016, RECONFIG
   Roshanisefat Shervin, 2018, GLSVLSI
   Sayadi H., 2018, DAC
   Sayadi Hossein, 2018, CUSTOMIZED MACHINE L
   Schafer Benjamin Carrion, 2014, IEEE EMBEDDED SYSTEM
   Shao Yakun Sophia, 2014, ISCA
   Stangl J., 2018, DATE
   Steffen Craig P, 2007, P REC SYST SUMM I
   Steve, 2018, FCCM
   Vakil Ashkan, 2019, ASP DAC
   Zhong G., 2016, DAC
   Zhong Guanwen, 2017, DATE
   Zhou Y., 2018, FPGA
NR 29
TC 21
Z9 22
U1 1
U2 2
PY 2019
BP 727
EP 732
DI 10.1145/3287624.3288756
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sakaki, H
   Yoshikawa, H
   Yokomizo, H
   Sogo, T
   Kinoshita, K
   Adachi, N
AF Sakaki, H
   Yoshikawa, H
   Yokomizo, H
   Sogo, T
   Kinoshita, K
   Adachi, N
BE Zhao, JJ
   Daneels, A
TI Design of automatic beam transport system at SPring-8 LINAC
SO ACCELERATOR AND LARGE EXPERIMENTAL PHYSICS CONTROL SYSTEMS
DT Proceedings Paper
CT 1997 International Conference on Accelerator and Large Experimental
   Physics Control Systems
CY NOV 03-07, 1997
CL BEIJING, PEOPLES R CHINA
AB At a new accelerator, the best operating parameters have to be found by trial and error. The operator must learn from experience, and it expends much time for operation because the accelerator has many alignments and other errors which are hard to measure. The SPring-8 Linac is also a new accelerator opt:rated since 1996. It's a 140m long, 1GeV electron machine. The machine is used as an injector into the 8GeV synchrotron. The synchrotron demands high energy stability, so the operator must search for the parameter by trial and error. Even after the parameter is fixed, it is possible that the energy is fluctuated by the temperature and various other reasons, and the operator must engage in adjustment continually[1].
   Whenever a parameter is adjusted, the beam profile is also checked on a screen which is made with alumina-ceramic (Desmarquest AF995R). Therefore we design an automatic operation system using screen monitors. Firstly, we develop an image processing system for the screen monitor. Next, we try to do a preliminary automatic control using the system. It is attempted for the electron beam transport.
   This paper presents the image processing system of screen monitor, and some results of a preliminary automatic control experiment using it.
C1 Spring 8 Linac, Ako, Hyogo 67812, Japan.
RP Sakaki, H (corresponding author), Spring 8 Linac, Ako, Hyogo 67812, Japan.
CR HASHIMOTO Y, 1991, INSREP900
   *MATHW INC, 1992, MATLAB OPT TOOLB US
   OHNISHI T, 1997, P 22 LIN ACC M JAP, P140
   PRESS WH, 1980, NUMERICAL RECIPES C
   Sakaki H., 1995, Proceedings of the 1995 Particle Accelerator Conference (Cat. No.95CH35843), P2208, DOI 10.1109/PAC.1995.505500
NR 5
TC 0
Z9 0
U1 0
U2 0
PY 1997
BP 509
EP 511
WC Physics, Multidisciplinary; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Bucknor, NK
   Raghavan, M
AF Bucknor, Norman K.
   Raghavan, Madhusudan
BE Larochelle, P
   McCarthy, JM
TI Application of Machine Learning Techniques to Hybrid Engine Restart
   Prediction
SO PROCEEDINGS OF THE 2022 USCTOMM SYMPOSIUM ON MECHANICAL SYSTEMS AND
   ROBOTICS
SE Mechanisms and Machine Science
DT Proceedings Paper
CT 2nd USCToMM Symposium on Mechanical Systems and Robotics (MSR)
CY MAY 19-21, 2022
CL Rapid City, SD
DE P2 hybrid; Hybrid control; Engine restart; Machine learning
AB Neural network-based artificial intelligence techniques to replace or augment traditional control systems are gaining in popularity. The present work reports on our evaluation of machine learning techniques to predict engine restarts for a P2 hybrid system. A typical P2 hybrid system operates by launching the vehicle electrically from a standstill and allows low speed electric driving. When the driver accelerator input exceeds an electric-drive power demand threshold, the internal combustion engine is started and connected to the driveline to provide added power. The non-zero time between the driver's power request and engine power delivery is referred to as the tip-in response delay. To minimize this delay, we explore the use of machine learning models to predict an engine restart, implying a driver request beyond the electric-drive threshold. We create deep and recurrent neural networks and train them with engine-on timing data, vehicle trajectory and power demand history. Once trained, the neural network flavors are remarkably accurate at predicting the required engine-on state, from which we can infer driver tip-in. A neural network can thus serve as a simplified embedded model to predict engine starts given a preview of the vehicle's probable trajectory. As a result, we can restart the engine ahead of time to minimize the torque hole during tip-in.
C1 [Bucknor, Norman K.; Raghavan, Madhusudan] Gen Motors Res & Dev Ctr, Warren, MI 48090 USA.
RP Bucknor, NK (corresponding author), Gen Motors Res & Dev Ctr, Warren, MI 48090 USA.
EM norman.k.bucknor@gm.com
CR Bianchi F.M., 2017, ARXIV170504378V1CSNE
   Finesso R, 2016, SAE INT J ALTERN POW, V5, P308, DOI 10.4271/2016-01-1243
   Flovik V., NOT USE MACHINE LEAR
   Geron A., 2017, HANDS ONMACHINE LEAR
   Kum D, 2011, J DYN SYST-T ASME, V133, DOI 10.1115/1.4002708
   Li D., 2012, APSIPA TRANS SIGNAL
NR 6
TC 0
Z9 0
U1 3
U2 5
PY 2022
VL 118
BP 32
EP 42
DI 10.1007/978-3-030-99826-4_4
WC Computer Science, Artificial Intelligence; Engineering, Mechanical;
   Robotics
DA 2023-11-11
ER

PT J
AU Abdel-Aal, RE
   Raashid, M
AF Abdel-Aal, RE
   Raashid, M
TI Using abductive machine learning for online vibration monitoring of
   turbo molecular pumps
SO SHOCK AND VIBRATION
DT Article
DE vibration monitoring and diagnostics; statistical vibration analysis;
   turbo molecular pumps; machine learning; abductive networks
ID NEURAL NETWORKS; SYSTEM
AB Turbo molecular vacuum pumps constitute a critical component in many accelerator installations, where failures can be costly in terms of both money and lost beam time. Catastrophic failures can be averted if prior warning is given through a continuous online monitoring scheme. This paper describes the use of modem machine learning techniques for online monitoring of the pump condition through the measurement and analysis of pump vibrations. Abductive machine learning is used for modeling the pump status as 'good' or 'bad' using both radial and axial vibration signals measured close to the pump bearing. Compared to other statistical methods and neural network techniques, this approach offers faster and highly automated model synthesis, requiring little or no user intervention. Normalized 50-channel spectra derived from the low frequency region (0-10 kHz) of the pump vibration spectra provided data inputs for model development. Models derived by training on only 10 observations predict the correct value of the logical pump status output with 100% accuracy for an evaluation population as large as 500 cases. Radial vibration signals lead to simpler models and smaller errors in the computed value of the status output. Performance is comparable with literature data on a similar diagnosis scheme for compressor valves using neural networks.
C1 King Fahd Univ Petr & Minerals, Res Inst, Ctr Appl Phys Sci, Dhahran 31261, Saudi Arabia.
RP Abdel-Aal, RE (corresponding author), King Fahd Univ Petr & Minerals, Res Inst, Ctr Appl Phys Sci, POB 1759, Dhahran 31261, Saudi Arabia.
EM radwan@kfupm.edu.sa
CR ABDELAAL RE, 1991, NUCL INSTRUM METH A, V301, P489, DOI 10.1016/0168-9002(91)90016-J
   ABDELAAL RE, 1994, ENERGY, V19, P739, DOI 10.1016/0360-5442(94)90012-4
   AbTech Corporation, 1990, AIM US MAN
   ALJUWAIR H, 1987, NUCL INSTRUM METH B, V24-5, P810, DOI 10.1016/S0168-583X(87)80253-7
   [Anonymous], 1984, SELF ORG METHODS MOD
   [Anonymous], 1973, PATTERN RECOGNITION
   ARAI K, 1991, P INT JOINT C NEUR N, V1, P177
   Barron A., 1984, SELF ORG METHODS MOD, P87
   BARRON RL, 1984, SELF ORG METHODS MOD, P25
   BOYES JD, 1981, NOISE VIBRATION MONI, P90
   Breiman L., 1984, BIOMETRICS, P357
   CHARALAMBOUS C, 1992, IEE PROC-G, V139, P301, DOI 10.1049/ip-g-2.1992.0050
   GOULD CR, 1981, IEEE T NUCL SCI, V28, P3708, DOI 10.1109/TNS.1981.4331833
   IKEDA S, 1984, SELF ORG METHODS MOD, P149
   IVAKHNENKO AG, 1971, IEEE T SYST MAN CYB, VSMC1, P364, DOI 10.1109/TSMC.1971.4308320
   Knerr S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P41
   KOTANI M, 1991, P IEEE INT JOINT C N, V1, P251
   MALONE JM, 1984, SELF ORG METHODS MOD, P67
   MAYES IW, 1994, P I MECH ENG A-J POW, V208, P267, DOI 10.1243/PIME_PROC_1994_208_047_02
   MONTGOMERY GJ, 1990, P SPIE APPL ART NEUR, P56
   PAGE EA, 1991, HYDROCARBON PROC JAN, P69
   PECK JP, 1994, ISA T, V33, P159, DOI 10.1016/0019-0578(94)90048-5
   RICHARDS SJ, 1992, IRON STEEL ENG   JUN, P33
   SCOTT DE, 1984, SELF ORG METHODS MOD, P67
   VAUGHAN RA, 1991, PATTERN RECOGNITION
   Wasserman P D, 1989, NEURAL COMPUTING THE
   Weiss S. M., 1991, COMPUTER SYSTEMS LEA
   ZHUGE Q, 1990, MECH SYST SIGNAL PR, V4, P355, DOI 10.1016/0888-3270(90)90020-L
NR 28
TC 4
Z9 4
U1 0
U2 4
PY 1999
VL 6
IS 5-6
BP 253
EP 265
DI 10.1155/1999/560297
WC Acoustics; Engineering, Mechanical; Mechanics
DA 2023-11-11
ER

PT J
AU Kiefer, M
   Poulakis, I
   Bress, S
   Markl, V
AF Kiefer, Martin
   Poulakis, Ilias
   Bress, Sebastian
   Markl, Volker
TI Scotch: Generating FPGA-Accelerators for Sketching at Line Rate
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article
AB Sketching algorithms are a powerful tool for single-pass data summarization. Their numerous applications include approximate query processing, machine learning, and large-scale network monitoring. In the presence of high-bandwidth interconnects or in-memory data, the throughput of summary maintenance over input data becomes the bottleneck. While FPGAs have shown admirable throughput and energy-efficiency for data processing tasks, developing FPGA accelerators requires a sophisticated hardware design and expensive manual tuning by an expert.
   We propose Scotch, a novel system for accelerating sketch maintenance using FPGAs. Scotch provides a domain-specific language for the user-friendly, high-level definition of a broad class of sketching algorithms. A code generator performs the heavy-lifting of hardware description, while an auto-tuning algorithm optimizes the summary size. Our evaluation shows that FPGA accelerators generated by Scotch outperform CPU- and GPU-based sketching by up to two orders of magnitude in terms of throughput and up to a factor of five in terms of energy efficiency.
C1 [Kiefer, Martin; Poulakis, Ilias; Bress, Sebastian] Tech Univ Berlin, Berlin, Germany.
   [Markl, Volker] Tech Univ Berlin, German Res Ctr Artificial Intelligence DFKI, Berlin, Germany.
RP Kiefer, M (corresponding author), Tech Univ Berlin, Berlin, Germany.
EM martin.kiefer@tu-berlin.de; ilias.poulakis@tu-berlin.de;
   sebastian.bress@tu-berlin.de; volker.markl@tu-berlin.de
CR Alon N., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, P10, DOI 10.1145/303976.303978
   [Anonymous], 2009, PROC VLDB ENDOW
   [Anonymous], 2013, SYNTHESIS LECT DATA, DOI DOI 10.1007/978-3-031-01849-7
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Bruel P, 2017, 2017 INT C RECONFIGU, P1
   Chen D., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P5, DOI 10.1109/FPL.2012.6339171
   Cho JM, 2014, 2014 INTERNATIONAL SYMPOSIUM ON VLSI DESIGN, AUTOMATION AND TEST (VLSI-DAT)
   Chrysos G, 2019, I C FIELD PROG LOGIC, P278, DOI 10.1109/FPL.2019.00052
   Cormode G, 2005, J ALGORITHMS, V55, P58, DOI 10.1016/j.jalgor.2003.12.001
   Cormode G, 2011, FOUND TRENDS DATABAS, V4, P1, DOI 10.1561/1900000004
   Cormode Graham, 2005, VLDB, P13
   Czajkowski Tomasz S., 2012, FPL, P531, DOI DOI 10.1109/FPL.2012.6339272
   Feigenbaum J, 2003, SIAM J COMPUT, V32, P131, DOI 10.1137/S0097539799361701
   Feist T., 2012, CISC VIS NETW IND GL, V5, P30
   FLAJOLET P, 1985, J COMPUT SYST SCI, V31, P182, DOI 10.1016/0022-0000(85)90041-8
   Flajolet P., 2007, P INT C AN ALG, P137
   Gan E, 2018, PROC VLDB ENDOW, V11, P1647, DOI 10.14778/3236187.3236212
   Goyal A., 2012, P 2012 JOINT C EMPIR, P1093
   King Colian Ian, 2020, POW
   Kurek M, 2016, ANN IEEE SYM FIELD P, P84, DOI 10.1109/FCCM.2016.29
   Li Ping, 2011, ADV NEURAL INFORM PR, P2672
   Masson C, 2019, PROC VLDB ENDOW, V12, P2195, DOI 10.14778/3352063.3352135
   Metwally A, 2005, LECT NOTES COMPUT SC, V3363, P398, DOI 10.1007/978-3-540-30570-5_27
   Mueller R, 2009, PROC VLDB ENDOW, V2
   Papapetrou O, 2012, PROC VLDB ENDOW, V5, P992, DOI 10.14778/2336664.2336672
   Ramakrishna MV, 1997, IEEE T COMPUT, V46, P1378, DOI 10.1109/12.641938
   Rusu F, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1242524.1242528
   Saavedra A, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P38, DOI 10.1109/DSD.2018.00022
   Soto JE, 2019, 2019 22ND EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P659, DOI 10.1109/DSD.2019.00105
   Teubner J, 2013, ACM T DATABASE SYST, V38, DOI 10.1145/2536800
   Teubner J, 2010, PROC INT CONF DATA, P669, DOI 10.1109/ICDE.2010.5447856
   Thorup M., 2004, P 15 ANN ACM SIAM S, P615
   Tong D, 2018, IEEE T PARALL DISTR, V29, P929, DOI 10.1109/TPDS.2017.2766633
   Vengerov D, 2015, PROC VLDB ENDOW, V8, P1530
   Wang ZH, 2016, PROCEEDINGS OF THE 4TH INTERNATIONAL WORKSHOP ON ENERGY HARVESTING AND ENERGY-NEUTRAL SENSING SYSTEMS (ENSSYS'16), P1, DOI [10.1145/2996884.2996885, 10.1109/ICAUMS.2016.8479999]
   Wirbel L., 2014, XILINX SDACCEL UNIFI
   Woods L, 2014, PROC VLDB ENDOW, V7, P963, DOI 10.14778/2732967.2732972
   Zeke Wang, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293941
   Zhu EK, 2016, PROC VLDB ENDOW, V9, P1185
NR 40
TC 6
Z9 6
U1 0
U2 1
PD NOV
PY 2020
VL 14
IS 3
BP 281
EP 293
DI 10.14778/3430915.3430919
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Liu, MY
   Chakrabarty, K
AF Liu, Mengyun
   Chakrabarty, Krishnendu
GP IEEE
TI Adaptive Methods for Machine Learning-Based Testing of Integrated
   Circuits and Boards
SO 2021 IEEE INTERNATIONAL TEST CONFERENCE (ITC 2021)
SE International Test Conference Proceedings
DT Proceedings Paper
CT IEEE International Test Conference (ITC)
CY OCT 10-15, 2021
CL ELECTR NETWORK
ID SUPPORT-VECTOR MACHINES
AB The relentless growth in information technology and artificial intelligence (AI) is placing demands on integrated circuits and boards for high performance, added functionality, and low power consumption. However, these new trends lead to high test cost and challenges associated with test planning. Machine learning (ML) provides an opportunity to overcome the challenges associated with the testing of complex systems. Taking the advantages of ML techniques, useful information can be extracted from test data logs, and this information helps facilitate the testing process for both chips and boards. In addition, the ever-growing need to achieve test-cost reduction with no test-quality degradation is driving the adoption of ML-based adaptive methods for testing. Adaptive test methods observe changes in the distribution of test data and dynamically adjust the testing process, thus reducing test cost. In this paper, we describe efficient solutions for adapting machine-learning techniques to testing and diagnosis. To reduce manufacturing cost, we select different test items for chips with different predicted quality levels. To avoid the periodic interruption of computing tasks in accelerators for AI, we describe an efficient online testing method that interrupts the regular computation only when a high defect rate is estimated. To identify board-level functional faults with high accuracy, we utilize online incremental learning and transfer learning to address the practical issues that arise when we deal with real-life test data in a high-volume production environment.
C1 [Liu, Mengyun; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
RP Liu, MY (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27706 USA.
CR [Anonymous], MACH LEARN
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P37, DOI 10.1007/978-3-642-00296-0_5
   Benner S, 2001, INT TEST CONF P, P908, DOI 10.1109/TEST.2001.966714
   Bickel S, 2009, J MACH LEARN RES, V10, P2137
   Chen MJ, 2008, PR IEEE COMP DESIGN, P234, DOI 10.1109/ICCD.2008.4751867
   Chih-Ying Tsai, 2016, 2016 IEEE 34th VLSI Test Symposium (VTS), P1, DOI 10.1109/VTS.2016.7477268
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Devlin J., 2018, PREPRINT
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jin S, 2016, IEEE T COMPUT AID D, V35, P985, DOI 10.1109/TCAD.2015.2481859
   Kotsiantis S., 2006, GESTS INT T COMPUTER, V30, P25, DOI DOI 10.1007/978-0-387-09823-4_45
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2019, DESIGN AUTOMATION TE
   Lin A., 2013, SAS GLOBAL FORUM
   Liu M., 2020, IEEE T COMPUT AID D
   Liu M., 2021, IEEE T COMPUT AID D
   Liu M., 2018, PROC EUR TEST SYMP, P1, DOI 10.1109/ETS.2018.8400693
   Liu MQ, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON PREDICTIVE CONTROL OF ELECTRICAL DRIVES AND POWER ELECTRONICS (PRECEDE 2019), P160, DOI [10.1109/precede.2019.8753357, 10.1109/marss.2019.8860991]
   Liu MY, 2020, INT TEST CONF P, DOI 10.1109/ITC44778.2020.9325259
   Liu MY, 2018, INT TEST CONF P
   Liu Mengyun, 2020, ACM T DES AUTOMAT EL
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Siatkowski S, 2016, IEEE VLSI TEST SYMP
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sumikawa N., 2011, INT TEST C, P1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tourangeau S, 2006, IEEE ITC
   Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549
   Wu SH, 2008, INT TEST CONF P, P1
   Ye FM, 2014, IEEE T COMPUT AID D, V33, P279, DOI 10.1109/TCAD.2013.2287184
   Ye FM, 2013, IEEE T COMPUT AID D, V32, P723, DOI 10.1109/TCAD.2012.2234827
   Zhang WH, 2019, ADV SOC SCI EDUC HUM, V376, P1, DOI [10.2991/sschd-19.2019.1, 10.1109/euronav.2019.8714160, 10.1145/3316781.3317797]
NR 35
TC 1
Z9 1
U1 2
U2 7
PY 2021
BP 153
EP 162
DI 10.1109/ITC50571.2021.00023
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xue, CB
   Cao, S
   Jiang, RK
   Yang, H
AF Xue, Chengbo
   Cao, Shan
   Jiang, Rongkun
   Yang, Hao
GP IEEE
TI A Reconfigurable Pipelined Architecture for Convolutional Neural Network
   Acceleration
SO 2018 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 27-30, 2018
CL Florence, ITALY
DE Convolutional neural network; inter-layer pipeline; hardware
   accelerator; machine learning
AB The convolutional neural network (CNN) has become widely used in a variety of vision recognition applications, and the hardware acceleration of CNN is in urgent need as increasingly more computations are required in the state-of-the-art CNN networks. In this paper, we propose a pipelined architecture for CNN acceleration. The probability of both inner-layer and inter-layer pipeline for typical CNN networks is analyzed. And two types of data re-ordering methods, the filter-first (FF) flow and the image-first (IF) flow, are proposed for different kinds of layers. Then, a pipelined CNN accelerator for AlexNet is implemented, the dataflow of which can be reconfigurably selected for different layer processing. Simulation results show that the proposed pipelined architecture achieves 43% performance improvement compared with the non-pipelined ones. The AlexNet accelerator is implemented in 65 nm CMOS technology working at 200 MHz, with 350 mW power consumption and 24 GFLOPS peak performance.
C1 [Xue, Chengbo; Jiang, Rongkun; Yang, Hao] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
   [Cao, Shan] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Joint Int Res Lab Specialty Fiber Opt & Adv Commu, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai, Peoples R China.
RP Cao, S (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Joint Int Res Lab Specialty Fiber Opt & Adv Commu, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai, Peoples R China.
EM cshan@shu.edu.cn
CR Alwani M., 2016, MICROPAGE, P1
   Bacis M, 2017, IEEE SYM PARA DISTR, P90, DOI 10.1109/IPDPSW.2017.44
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Natale Giuseppe, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P639, DOI 10.1109/ISVLSI.2017.126
   Park S, 2016, IEEE J SOLID-ST CIRC, V51, P2380, DOI 10.1109/JSSC.2016.2582864
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Zhou YM, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P829, DOI 10.1109/ICCSNT.2015.7490869
NR 11
TC 2
Z9 2
U1 0
U2 3
PY 2018
DI 10.1109/ISCAS.2018.8351425
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Peng, XC
   Huang, SS
   Luo, YD
   Sun, XY
   Yu, SM
AF Peng, Xiaochen
   Huang, Shanshi
   Luo, Yandong
   Sun, Xiaoyu
   Yu, Shimeng
GP IEEE
TI DNN plus NeuroSim: An End-to-End Benchmarking Framework for
   Compute-in-Memory Accelerators with Versatile Device Technologies
SO 2019 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
SE IEEE International Electron Devices Meeting
DT Proceedings Paper
CT 65th IEEE Annual International Electron Devices Meeting (IEDM)
CY DEC 09-11, 2019
CL San Francisco, CA
AB DNN+NeuroSim is an integrated framework to benchmark compute-in-memory (CIM) accelerators for deep neural networks, with hierarchical design options from device-level, to circuit-level and up to algorithm-level. A python wrapper is developed to interface NeuroSim with popular machine learning platforms such as Pytorch and Tensorflow. The framework supports automatic algorithm to hardware mapping, and evaluates both chip-level performance and inference accuracy with hardware constraints. In this work, we analyze the impact of reliability in "analog" synaptic devices, and analog-to-digital converter (ADC) quantization effects on the inference accuracy. Then we benchmark CIM accelerators based on SRAM and versatile emerging devices including RRAM, PCM, FeFET and ECRAM, from VGG to ResNet, and from CIFAR to ImageNet dataset, revealing the benefits of high on-state resistance, e.g. by using three-terminal synapses. The open-source code of DNN+NeuroSim is available at haps://github.com/neurosim/DNN_NeuroSim_V1.0.
C1 [Peng, Xiaochen; Huang, Shanshi; Luo, Yandong; Sun, Xiaoyu; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR Chen P.-Y., 2017, IEDM 2017
   Chen P.-Y., 2018, IRPS 2018
   He K., CVPR 2015
   Jain, ISSCC 2019
   Kim W., 2019, VLSI 2019
   Ni K, IEDM 2018
   Peng X., ISCAS 2019
   Simonyan Karen, ICLR 2015
   Tang J., 2018, IEDM 2018
   Wu J.Y., IEDM 2018
   Wu S., ICLR 2018
   Wu W., VLSI 2018
NR 12
TC 146
Z9 146
U1 0
U2 5
PY 2019
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Felsberger, L
   Kranzlmüller, D
   Todd, B
AF Felsberger, Lukas
   Kranzlmueller, Dieter
   Todd, Benjamin
BE Holzinger, A
   Kieseberg, P
   Tjoa, AM
   Weippl, E
TI Field-Reliability Predictions Based on Statistical System Lifecycle
   Models
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION, CD-MAKE 2018
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 2nd IFIP TC 5, TC 8/WG 8.4, 8.9, TC 12/WG 12.9 International
   Cross-Domain Conference on Machine Learning and Knowledge Extraction
   (CD-MAKE)
CY AUG 27-30, 2018
CL Univ Hamburg, Hamburg, GERMANY
HO Univ Hamburg
DE Reliability prediction; System lifecycle; Bayesian learning
ID PROGRAM
AB Reliability measures the ability of a system to provide its intended level of service. It is influenced by many factors throughout a system lifecycle. A detailed understanding of their impact often remains elusive since these factors cannot be studied independently. Formulating reliability studies as a Bayesian regression problem allows to simultaneously assess their impact and to identify a predictive model of reliability metrics.
   The proposed method is applied to currently operational particle accelerator equipment at CERN. Relevant metrics were gathered by combining data from various organizational databases. To obtain predictive models, different supervised machine learning algorithms were applied and compared in terms of their prediction error and reliability. Results show that the identified models accurately predict the meantime- between-failure of devices - an important reliability metric for repairable systems - and reveal factors which lead to increased dependability. These results provide valuable inputs for early development stages of highly dependable equipment for future particle accelerators.
C1 [Felsberger, Lukas; Kranzlmueller, Dieter] Ludwig Maximilians Univ Muenchen, Inst Informat, Oettingenstr 67, D-80538 Munich, Germany.
   [Felsberger, Lukas; Todd, Benjamin] CERN, Route Meyrin, CH-1211 Geneva, Switzerland.
RP Felsberger, L (corresponding author), Ludwig Maximilians Univ Muenchen, Inst Informat, Oettingenstr 67, D-80538 Munich, Germany.; Felsberger, L (corresponding author), CERN, Route Meyrin, CH-1211 Geneva, Switzerland.
EM lukas.felsberger@cern.ch
CR [Anonymous], 2009, ELEMENTS STAT LEARNI, DOI DOI 10.1007/978-0-387-84858-7_2
   [Anonymous], 2007, PATTERN RECOGN, V16
   Barnard R.W.A., 2008, P INCOSE INT S, V18, P357, DOI DOI 10.1002/J.2334-5837.2008.TB00811.X
   Blondel M., 2018, SCIKIT LEARN USER GU
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Denson W, 1998, IEEE T RELIAB, V47, P321
   Elerath JG, 2012, IEEE T RELIAB, V61, P125, DOI 10.1109/TR.2011.2172030
   Foucher B, 2002, MICROELECTRON RELIAB, V42, P1155, DOI 10.1016/S0026-2714(02)00087-2
   Gauch H., 2003, SCI METHOD PRACTICE
   Gullo L, 1999, P A REL MAI, P365, DOI 10.1109/RAMS.1999.744146
   Johnson BG, 2000, P A REL MAI, P181, DOI 10.1109/RAMS.2000.816304
   Jones J, 1999, IEEE T RELIAB, V48, P127, DOI 10.1109/24.784270
   Kapur KC, 2014, WILEY SER SYST ENG, P1, DOI 10.1002/9781118841716
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Leonard C. T., 1990, Quality and Reliability Engineering International, V6, P243, DOI 10.1002/qre.4680060406
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448
   Miller RJ, 2004, P A REL MAI, P641, DOI 10.1109/RAMS.2004.1285519
   OConnor P., 2012, PRACTICAL RELIABILIT
   Pandian GP, 2018, CHINESE J AERONAUT, V31, P10, DOI 10.1016/j.cja.2017.11.004
   Pecht M, 2002, MICROELECTRON RELIAB, V42, P1259, DOI 10.1016/S0026-2714(02)00132-4
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Womack J., 1990, MACHINE CHANGED WORL
   Zio E, 2009, RELIAB ENG SYST SAFE, V94, P125, DOI 10.1016/j.ress.2008.06.002
NR 23
TC 0
Z9 0
U1 0
U2 2
PY 2018
VL 11015
BP 98
EP 117
DI 10.1007/978-3-319-99740-7_7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Gao, Y
   Liu, ZY
   Wang, DS
AF Gao, Yuan
   Liu, Zhenyu
   Wang, Dongsheng
GP IEEE
TI Error Models of Finite Word Length Arithmetic in CNN Accelerator Design
SO 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING
   (VCIP)
DT Proceedings Paper
CT 30th IEEE Conference on Visual Communications and Image Processing
   (VCIP)
CY NOV 27-30, 2016
CL Chengdu, PEOPLES R CHINA
DE Terms CNN; Finite Word Length; Rounding Error Model
ID COPROCESSOR
AB Convolution Neural Network (CNN) is a state of the art machine learning algorithm. For CNN accelerator implementations, fixed-point and floating-point are two typical numeric representations. Because of the effects of rounding, reducing the word length would save the hardware and the power overheads while sacrificing the computation accuracy. The inherent robustness of neural network makes it possible to maintain the classification accuracy with very limited word length. Therefore, for the CNN accelerator designs, the primary issue is to determine the optimal arithmetic and the associated word length. In this paper, we developed the analytical error models to investigate the finite word length impacts of fixed-point and floating-point arithmetic in the test phase of CNN, respectively. It is revealed that the rounding errors are accumulated during the layer-wise convolution. Therefore, with the augment of network scale, the required word lengths for fixed-point and floating-point are both increased.
C1 [Gao, Yuan] Tsinghua Univ, Lab 4 305, Dept Comp Sci, FIT Bldg, Beijing 100084, Peoples R China.
   [Liu, Zhenyu; Wang, Dongsheng] Tsinghua Univ, Lab 4 305, RIIT&TNList, FIT Bldg, Beijing 100084, Peoples R China.
RP Gao, Y (corresponding author), Tsinghua Univ, Lab 4 305, Dept Comp Sci, FIT Bldg, Beijing 100084, Peoples R China.
EM liuzhenyu73@tsinghua.edu.cn; wds@tsinghua.edu.cn
CR [Anonymous], 2015, ARXIV150202551
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Courbariaux Matthieu., 2014, TRAINING DEEP NEURAL
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farabet Clement, 2011, COMP VIS PATT REC WO
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   OPPENHEIM AV, 1972, PR INST ELECTR ELECT, V60, P957, DOI 10.1109/PROC.1972.8820
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Vassiliadis S, 2000, IEEE T NEURAL NETWOR, V11, P1438, DOI 10.1109/72.883475
   Zhang C, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P161, DOI 10.1109/SPAWDA.2015.7364463
NR 14
TC 0
Z9 0
U1 0
U2 1
PY 2016
WC Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT C
AU Shakiah, SM
   Swaminathan, RV
   Nguyen, HD
   Chinta, R
   Afzal, T
   Susanj, N
   Mouchtaris, A
   Strimel, GP
   Rastrow, A
AF Shakiah, Suhaila M.
   Swaminathan, Rupak Vignesh
   Hieu Duy Nguyen
   Chinta, Raviteja
   Afzal, Tariq
   Susanj, Nathan
   Mouchtaris, Athanasios
   Strimel, Grant P.
   Rastrow, Ariya
GP IEEE
TI ACCELERATOR-AWARE TRAINING FOR TRANSDUCER-BASED SPEECH RECOGNITION
SO 2022 IEEE SPOKEN LANGUAGE TECHNOLOGY WORKSHOP, SLT
SE IEEE Workshop on Spoken Language Technology
DT Proceedings Paper
CT IEEE Spoken Language Technology Workshop (SLT)
CY JAN 09-12, 2023
CL Doha, QATAR
DE Accelerator-aware training; model compression; automatic speech
   recognition (ASR); recurrent neural network transducer (RNN-T)
AB Machine learning model weights and activations are represented in full-precision during training. This leads to performance degradation in runtime when deployed on neural network accelerator (NNA) chips, which leverage highly parallelized fixed-point arithmetic to improve runtime memory and latency. In this work, we replicate the NNA operators during the training phase, accounting for the degradation due to low-precision inference on the NNA in back-propagation. Our proposed method efficiently emulates NNA operations, thus foregoing the need to transfer quantization error-prone data to the Central Processing Unit (CPU), ultimately reducing the user perceived latency (UPL). We apply our approach to Recurrent Neural Network-Transducer (RNN-T), an attractive architecture for on-device streaming speech recognition tasks. We train and evaluate models on 270K hours of English data and show a 5-7% improvement in engine latency while saving up to 10% relative degradation in WER.
C1 [Shakiah, Suhaila M.; Swaminathan, Rupak Vignesh; Hieu Duy Nguyen; Susanj, Nathan; Mouchtaris, Athanasios; Strimel, Grant P.; Rastrow, Ariya] Amazon Com, Alexa Machine Learning, Seattle, WA 98109 USA.
   [Chinta, Raviteja; Afzal, Tariq] Amazon Com, Hardware Compute Grp, Seattle, WA USA.
RP Shakiah, SM (corresponding author), Amazon Com, Alexa Machine Learning, Seattle, WA 98109 USA.
CR Alvarez R, 2016, INTERSPEECH, P2746, DOI 10.21437/Interspeech.2016-128
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Dong LH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5884, DOI 10.1109/ICASSP.2018.8462506
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2012, P INT C MACHINE LEAR
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Han S., 2015, ARXIV151000149
   Nguyen HD, 2020, INTERSPEECH, P3366, DOI 10.21437/Interspeech.2020-1991
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kang HJ, 2020, IEEE T CIRC SYST VID, V30, P2093, DOI 10.1109/TCSVT.2019.2911674
   Leboeuf K, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P1070, DOI 10.1109/ICCIT.2008.131
   Lei T, 2018, Arxiv, DOI arXiv:1709.02755
   Li J, 2021, Arxiv, DOI arXiv:2101.05453
   Lin CW, 2008, IEEE INT SYMP CIRC S, P856, DOI 10.1109/ISCAS.2008.4541553
   Lu Liang, 2020, EXPLORING TRANSFORME
   Macoskey J, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5999, DOI 10.1109/ICASSP39728.2021.9414652
   Macoskey J, 2021, Arxiv, DOI arXiv:2108.01553
   Mouchtaris Athanasios, 2021, P ANN C INT SPEECH C
   Nagaraja Varun, 2021, ARXIV
   Namin AH, 2009, IEEE INT SYMP CIRC S, P2117, DOI 10.1109/ISCAS.2009.5118213
   Panchapagesan S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5639, DOI 10.1109/ICASSP39728.2021.9413905
   Radfar Martin, 2022, P ANN C INT SPEECH C
   Shangguan Y, 2020, Arxiv, DOI arXiv:1909.12408
   Wang YQ, 2020, INT CONF ACOUST SPEE, P6874, DOI [10.1109/ICASSP40776.2020.9054345, 10.1109/icassp40776.2020.9054345]
   Yu JH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6004, DOI 10.1109/ICASSP39728.2021.9413803
   Zhen K, 2021, P INT C ACOUSTICS SP
   Zhen K, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6009, DOI 10.1109/ICASSP39728.2021.9413844
   Zhu Michael, 2018, 6 INT C LEARNING REP
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 100
EP 107
DI 10.1109/SLT54892.2023.10022592
WC Computer Science, Artificial Intelligence; Linguistics
DA 2023-11-11
ER

PT C
AU Chen, YH
   Khadem, A
   He, X
   Talati, N
   Khan, TA
   Mudge, T
AF Chen, Yuhan
   Khadem, Alireza
   He, Xin
   Talati, Nishil
   Khan, Tanvir Ahmed
   Mudge, Trevor
BE IEEE
TI PEDAL: A Power Efficient GCN Accelerator with Multiple DAtafLows
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE Accelerator; power-efficient; multiple dataflows
AB Graphs are ubiquitous in many application domains due to their ability to describe structural relations. Graph Convolutional Networks (GCNs) have emerged in recent years and are rapidly being adopted due to their capability to perform Machine Learning (ML) tasks on graph-structured data. GCN exhibits irregular memory accesses due to the lack of locality when accessing graph-structured data. This makes it hard for general-purpose architectures like CPUs and GPUs to fully utilize their computing resources. In this paper, we propose PEDAL, a power-efficient accelerator for GCN inference supporting multiple dataflows. PEDAL chooses the best-fit dataflow and phase ordering based on input graph characteristics and GCN algorithm, achieving both efficiency and flexibility. To achieve both high power efficiency and performance, PEDAL features a light-weight processing element design. PEDAL achieves 144.5x, 9.4x, and 2.6x speedup compared to CPU, GPU, and HyGCN, respectively, and 8856x, 1606x, 8.4x, and 1.8x better power efficiency compared to CPU, GPU, HyGCN, and EnGN, respectively.
C1 [Chen, Yuhan; Khadem, Alireza; He, Xin; Talati, Nishil; Khan, Tanvir Ahmed; Mudge, Trevor] Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA.
RP Chen, YH (corresponding author), Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA.
EM chenyh@umich.edu; arkhadem@umich.edu; xinhe@umich.edu;
   talatin@umich.edu; takh@umich.edu; tnm@umich.edu
CR Abadal S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3477141
   [Anonymous], 2011, J MACH LEARN RES
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Battaglia Peter, 2016, ADV NEURAL INFORM PR, P4502
   Chakraborty R, 2022, IEEE T PATTERN ANAL, V44, P799, DOI 10.1109/TPAMI.2020.3003846
   Chen C, 2022, INT S HIGH PERF COMP, P429, DOI 10.1109/HPCA53966.2022.00039
   Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188467
   Fey M., 2019, ABS190302428 CORR, V1903, P02428
   Geng T., 2021, MICRO
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Graves A., 2007, ARTIFICIAL NEURAL NE
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hu WH, 2021, Arxiv, DOI arXiv:2005.00687
   Kim M., 2011, MODELING SOCIAL NETW
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kipf T., 2017, ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Muralimanohar N., CACTI 6 0 TOOL UNDER
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Talati N, 2021, I S WORKL CHAR PROC, P87, DOI 10.1109/IISWC53511.2021.00019
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   You HR, 2022, INT S HIGH PERF COMP, P460, DOI 10.1109/HPCA53966.2022.00041
   Zhou J., 2018, ARXIV181208434, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]
   Zhuang CY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P499, DOI 10.1145/3178876.3186116
NR 26
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT C
AU Hsiao, SF
   Wu, PH
   Chen, JM
   Chen, KC
AF Hsiao, Shen-Fu
   Wu, Pei-Hsuan
   Chen, Jien-Min
   Chen, Kun-Chih
GP IEEE
TI Dual-Precision Acceleration of Convolutional Neural Network Computation
   with Mixed Input and Output Data Reuse
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
DE Convolutional Neural Network; Deep Neural Network; Machine Learning;
   data reuse; hardware accelerator
AB Memory access dominates power consumption in hardware acceleration of deep neural networks (DNN) computation due to the movement of huge data and weights. This paper design a DNN accelerator using mixed input and output data reuse scheme to achieve balance between internal memory size and memory access amount, two contradictory design goals in resource limited embedded systems. First, analytical forms for memory size and accesses are derived for different data reuse methods in DNN convolution. After comparing the analysis results across different convolutional layers of the VGG-16 model with different levels of hardware parallelism, we implement a low-cost DNN hardware accelerator using mixed input and output data reuse scheme with 32 processing elements (PEs) operating in parallel. Furthermore, the design supports two precision modes (8-bit and 16-bit) allowing variable precision requirements across DNN layers, resulting in more efficient computation compared with single-precision designs through sharing of hardware resource.
C1 [Hsiao, Shen-Fu; Wu, Pei-Hsuan; Chen, Jien-Min; Chen, Kun-Chih] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung, Taiwan.
RP Hsiao, SF (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung, Taiwan.
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Horowitz M., ENERGY TABLE 45NM PR
   Krizhevsky A., 2012, P NIPS 12, V2012, P25, DOI DOI 10.1016/J.PROTCY.2014.09.007
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Simonyan K, 2015, 3 INT C LEARN REPR I
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
NR 8
TC 0
Z9 0
U1 0
U2 0
PY 2019
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yu, W
   Qu, YL
   Lu, YT
AF Yu, Wei
   Qu, Yili
   Lu, Yutong
GP IOP
TI A Hybrid MapReduce Implementation of PCA on Tianhe-2
SO 2018 INTERNATIONAL CONFERENCE ON COMPUTER INFORMATION SCIENCE AND
   APPLICATION TECHNOLOGY
SE Journal of Physics Conference Series
DT Proceedings Paper
CT International Conference on Computer Information Science and Application
   Technology (CISAT)
CY DEC 07-09, 2018
CL NE Petr Univ, Daqing, PEOPLES R CHINA
HO NE Petr Univ
AB "Big Data" has been a popular word anywhere. Researchers want the data processing more efficient. PCA algorithm is an effective data reduction algorithm applied to almost all big data fields. Meanwhile, there are many Machine Learning Algorithm Library applied to provide commonly-used algorithm, but these algorithms do not make good use of the resources of the supercomputer system. This paper uses MapReduce Model to design and implement PCA algorithm using MPI+OpenMP+SIMD hybrid accelerator programming tools on Tianhe-2 and get a significant speedup.
C1 [Yu, Wei; Lu, Yutong] Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   [Qu, Yili; Lu, Yutong] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Yutong] Natl Supercomp Ctr Guangzhou, Guangzhou 510006, Guangdong, Peoples R China.
RP Lu, YT (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.; Lu, YT (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.; Lu, YT (corresponding author), Natl Supercomp Ctr Guangzhou, Guangzhou 510006, Guangdong, Peoples R China.
EM ytlu@nudt.edu.cn
CR Benson AR, 2013, IEEE INT CONF BIG DA
   Boronea SA, 2010, PROCEEDINGS OF THE 2ND EUROPEAN CONFERENCE ON INTELLECTUAL CAPITAL, P100
   Dean J, 2008, ACM
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Junqueira B F, 2001, J COMPUT HIGH EDUC, V12, P94
   Ordonez C, 2014, DISTRIB PARALLEL DAT, V32, P377, DOI 10.1007/s10619-013-7134-6
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
NR 7
TC 0
Z9 0
U1 0
U2 3
PY 2019
VL 1168
AR 052013
DI 10.1088/1742-6596/1168/5/052013
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ko, S
   Rucker, A
   Zhang, YQ
   Mure, P
   Olukotun, K
AF Ko, Sho
   Rucker, Alexander
   Zhang, Yaqi
   Mure, Paul
   Olukotun, Kunle
GP IEEE Comp Soc
TI Accelerating SLIDE: Exploiting Sparsity on Accelerator Architectures
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
AB A significant trend in machine learning is sparsifying the training of neural networks to reduce the amount of computation required. Algorithms like Sub-LInear Deep learning Engine (SLIDE) [2] use locality-sensitive hashing (LSH) to create sparsity. These sparse training algorithms were originally developed on multi-threaded multicore CPUs. However, they are not well-studied and optimized for accelerator platforms such as GPUs and reconfigurable dataflow architectures (RDAs). In this paper, we study the different variants of the SLIDE algorithm and investigate accuracy-performance tradeoffs on CPU, GPU, and RDAs. The implementation targeting RDA outperforms the GPU by 7.5x. The performance on a limited-memory RDA is improved further by proposing a smart caching algorithm, which is 2 x faster than the baseline RDA. Furthermore, we are able to achieve another 2 x performance by putting all of the weights on-chip using an RDA with enough memory. We believe our work will pave the road for the future development of both algorithm and hardware architecture for sparse training.
C1 [Ko, Sho; Rucker, Alexander; Mure, Paul; Olukotun, Kunle] Stanford Univ, Stanford, CA 94305 USA.
   [Zhang, Yaqi] SambaNova Syst, Palo Alto, CA USA.
RP Ko, S (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
CR [Anonymous], 2010, GPU TECHNOLOGY C
   Bradley T., 2012, GPU PERFORMANCE ANAL, DOI DOI 10.1016/J.JPDC.2021.02.008
   Chandra R., 2001, MORGAN KAUFMANN
   Chen BD, 2020, Arxiv, DOI [arXiv:1903.03129, 10.48550/ARXIV.1903.03129, DOI 10.48550/ARXIV.1903.03129]
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   NVIDIA, 2017, NVIDIA TESLA V100 GP
   Prabhakar R., 2021, HOT CHIPS, V33
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Rucker A., MICRO, P2021
   Vilim M, 2020, ANN I S COM, P309, DOI 10.1109/ISCA45697.2020.00035
NR 14
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 663
EP 670
DI 10.1109/IPDPSW55747.2022.00116
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Juracy, LR
   Garibotti, R
   Moraes, FG
AF Juracy, Leonardo Rezende
   Garibotti, Rafael
   Moraes, Fernando Gehm
TI From CNN to DNN Hardware Accelerators: A Survey on Design, Exploration,
   Simulation, and Frameworks
SO FOUNDATIONS AND TRENDS IN ELECTRONIC DESIGN AUTOMATION
DT Article
ID NEURAL-NETWORKS
AB Over the past decade, a massive proliferation of machine learning algorithms has emerged, from applications for surveillance to self-driving cars. The turning point occurred with the arrival of Convolutional Neural Network (CNN) models and the incredible accuracy brought by Deep Neural Networks (DNNs) at the cost of high computational complexity. In this growing environment, graphic processing units (GPUs) have become the de facto reference platform for the training and inference phases of CNNs and DNNs due to their high processing parallelism and memory bandwidth. However, GPUs are power-hungry architectures. To enable the deployment of CNN and DNN applications on energy-constrained devices (e.g., IoT devices), industry and academic research have moved towards hardware accelerators. Following the evolution of neural networks (from CNNs to DNNs), this survey sheds light on the impact of this architectural shift and discusses hardware accelerator trends in terms of design, exploration, simulation, and frameworks developed in both academia and industry.
C1 [Juracy, Leonardo Rezende; Garibotti, Rafael; Moraes, Fernando Gehm] Pontifical Catholic Univ Rio Grande Sul PUCRS, Sch Technol, Porto Alegre, RS, Brazil.
RP Juracy, LR (corresponding author), Pontifical Catholic Univ Rio Grande Sul PUCRS, Sch Technol, Porto Alegre, RS, Brazil.
EM leonardo.juracy@edu.pucrs.br; rafael.garibotti@pucrs.br;
   fernando.moraes@pucrs.br
CR Agostini NB, 2022, IEEE MICRO, V42, P78, DOI 10.1109/MM.2022.3178580
   Ahmad A, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3380548
   Ajayi T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3326334
   Al-Jawfi R, 2009, INT ARAB J INF TECHN, V6, P304
   Alibaba, 2019, ALIBABA HANGUANG 800
   Amazon, 2018, AWS INFERENTIA
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2018, IEEE INT WORKSHOP DO
   Apple, 2022, IPHONE 11
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Asanovic K., 2016, TECH REP
   Bai L, 2023, IEEE T NEUR NET LEAR, V34, P1808, DOI 10.1109/TNNLS.2020.3006738
   Baskin C, 2021, ACM T COMPUT SYST, V37, DOI 10.1145/3444943
   Bosheng Liu, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P524, DOI 10.1109/ASP-DAC47756.2020.9045580
   Caffe, 2022, US
   Cao S, 2020, IEEE J EM SEL TOP C, V10, P217, DOI 10.1109/JETCAS.2020.2993854
   Cerebras, 2022, CEREBRAS CS 1
   Chang J, 2018, I C INF COMM TECH CO, P177, DOI 10.1109/ICTC.2018.8539530
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XM, 2020, INT S HIGH PERF COMP, P529, DOI 10.1109/HPCA47549.2020.00050
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Das S, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180403
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Digital W., 2022, W DIGITAL MACHINE LE
   Domingues A. R. P., 2020, MA THESIS
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Ernst D, 2004, IEEE MICRO, V24, P10, DOI 10.1109/MM.2004.85
   Facebook, 2022, FACEBOOK HORIZON
   Facebook, 2022, FACEBOOK KINGS CANYO
   Ferianc M., 2021, MDPI ELECT, V10, P1
   Foundation L., 2022, LLVM COMPILER INFRAS
   Fujitsu, 2018, FUJITSU DEEP LEARNIN
   Garibotti R, 2019, IET COMPUT DIGIT TEC, V13, P302, DOI 10.1049/iet-cdt.2018.5136
   Garibotti R, 2018, IEEE T CIRCUITS-II, V65, P1440, DOI 10.1109/TCSII.2018.2860122
   Garibotti R, 2017, IEEE INT SYMP CIRC S
   Genc H, 2021, DES AUT CON, P769, DOI 10.1109/DAC18074.2021.9586216
   Gerogiannis G, 2022, IEEE ACCESS, V10, P18526, DOI 10.1109/ACCESS.2022.3147674
   Giri D, 2020, DES AUT TEST EUROPE, P1049
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google, 2022, CLOUD TPU
   Google, 2022, GOOGLE ASSISTANT YOU
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Haykin S, 2009, NEURAL NETWORKS LEAR
   Heidorn C, 2020, PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS FOR EMBEDDED SYSTEMS (SCOPES 2020), P26, DOI 10.1145/3378678.3391878
   Howard, 2017, ARXIV170404861
   Hsiao SF, 2020, IEEE INT SYMP CIRC S
   Hsiao SF, 2020, IEEE J EM SEL TOP C, V10, P376, DOI 10.1109/JETCAS.2020.3015238
   Huang BM, 2021, IEEE T CIRCUITS-I, V68, P4672, DOI 10.1109/TCSI.2021.3108762
   Huawei, 2019, HUAWEI ASCEND 910
   IBM, 2022, IBM WATSON
   Intel, 2022, INTEL NERVANA
   Jiao Y, 2020, ISSCC DIG TECH PAP I, P136, DOI 10.1109/ISSCC19947.2020.9062984
   Jouppi NP, 2015, IEEE T VLSI SYST, V23, P1254, DOI 10.1109/TVLSI.2014.2334635
   Juracy L. R., 2022, IEEE T CIRCUITS SYST, VI, P1
   Juracy LR, 2021, 2021 IEEE 12TH LATIN AMERICA SYMPOSIUM ON CIRCUITS AND SYSTEM (LASCAS), DOI 10.1109/LASCAS51355.2021.9459183
   Juracy LR, 2021, IEEE T CIRCUITS-I, V68, P4783, DOI 10.1109/TCSI.2021.3104644
   Karbachevsky A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020717
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Keras, 2022, LAYER ACTIVATION FUN
   Kim SJ, 2023, CRANIO, V41, P274, DOI 10.1080/08869634.2020.1839722
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H., 2018, COMPUTING RES REPOSI, P1
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lin W., 2021, IEEE INT C ELECT CIR, P1
   Liu BS, 2020, IEEE T COMPUT AID D, V39, P4881, DOI 10.1109/TCAD.2020.2978836
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Manasi SD, 2021, ASIA S PACIF DES AUT, P235, DOI 10.1145/3394885.3431539
   Mediatek, 2022, MEDIATEK APU
   Microsoft, 2022, PROJECT BRAINWAVE
   Minutoli M., 2020, IEEE INT C COMPUTER, P786
   Moolchandani D, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101887
   NVIDIA, 2022, US
   NVIDIA, 2022, TENSORRT
   NXP, 2022, NXP S32V234 MPU
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Park SS, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010134
   PyTorch, 2022, PYTORCH
   Qualcomm, 2019, QUALCOMM SNAPDRAGON
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Renesas, 2022, RENESAS E
   Russo E, 2022, DES AUT TEST EUROPE, P226, DOI 10.23919/DATE54114.2022.9774747
   Ryu S, 2022, IEEE J SOLID-ST CIRC, V57, P1924, DOI 10.1109/JSSC.2022.3141050
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samsung, 2019, SAMSUNG EXYNOS
   ServiceNow, 2022, ENTERPRISE CHATBOT V
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shao YS, 2016, INT SYMP MICROARCH
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Shivangi S, 2020, PROBIOTICS ANTIMICRO, V12, P1502, DOI 10.1007/s12602-020-09650-x
   Sohrabizadeh A., 2021, COMPUT RES REPOSITOR, P1
   Spagnolo F., 2020, IEEE MEDITERRANEAN C, P1
   Strom N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1488
   Tavakoli M, 2020, IEEE INT CONF ADV LE, P1, DOI 10.1109/ICALT49669.2020.00008
   Technologies D, 2022, VIRTUALIZED COMPUTER
   TensorFlow, 2022, US
   Tesla, 2019, AUTOPILOT FULL SELF
   Tesla, 2022, AUTOPILOT
   Texas, 2022, TEXAS INSTRUMENTS SI
   Toshiba, 2019, TOSHIBA VISCONTI 5
   Udupa P., 2020, IEEE INT S CIRCUITS, P1
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wu Y, 2020, PSYCHOL MED, V50, P1368, DOI [10.1017/S0033291719001314, 10.1145/3290605.3300666]
   Xiang TR, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P243, DOI 10.1109/HPCC/SmartCity/DSS.2018.00063
   Xianzhe Zhou, 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P1, DOI 10.1109/CDMA47397.2020.00006
   Xilinx, 2018, XILINX XDNN
   Xilinx, 2021, VITIS
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yu Y, 2021, IEEE T COMPUT, V70, P45, DOI 10.1109/TC.2020.2983694
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/ICASSP40776.2020.9053977, 10.1109/icassp40776.2020.9053977]
NR 117
TC 0
Z9 0
U1 0
U2 0
PY 2023
VL 13
IS 4
BP 270
EP 344
DI 10.1561/1000000060
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Park, J
   Yi, WS
   Ahn, D
   Kung, J
   Kim, JJ
AF Park, Junki
   Yi, Wooseok
   Ahn, Daehyun
   Kung, Jaeha
   Kim, Jae-Joon
TI Balancing Computation Loads and Optimizing Input Vector Loading in LSTM
   Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Sparse matrices; Logic gates; Hardware; Computer architecture; Clocks;
   History; Standards; Accelerators; computer architecture; hardware;
   machine learning; recurrent neural networks (RNNs)
AB The long short-term memory (LSTM) is a widely used neural network model for dealing with time-varying data. To reduce the memory requirement, pruning is often applied to the weight matrix of the LSTM, which makes the matrix sparse. In this paper, we present a new sparse matrix format, named rearranged compressed sparse column (RCSC), to maximize the inference speed of the LSTM hardware accelerator. The RCSC format speeds up the inference by: 1) evenly distributing the computation loads to processing elements (PEs) and 2) reducing the input vector load miss within the local buffer. We also propose a hardware architecture adopting hierarchical input buffer to further reduce the pipeline stalls which cannot be handled by the RCSC format alone. The simulation results for various datasets show that combined use of the RSCS format and the proposed hardware requires 2x smaller inference runtime on average compared to the previous work.
C1 [Park, Junki; Yi, Wooseok; Ahn, Daehyun; Kim, Jae-Joon] Pohang Univ Sci & Technol, Dept Creat IT Engn, Pohang 37673, South Korea.
   [Kung, Jaeha] Daegu Gyeongbuk Inst Sci & Technol, Dept Informat & Commun Engn, Daegu 42988, South Korea.
RP Kim, JJ (corresponding author), Pohang Univ Sci & Technol, Dept Creat IT Engn, Pohang 37673, South Korea.; Kung, J (corresponding author), Daegu Gyeongbuk Inst Sci & Technol, Dept Informat & Commun Engn, Daegu 42988, South Korea.
EM junkipark@postech.ac.kr; wooseok.yi@postech.ac.kr;
   daehyun.ahn@postech.ac.kr; jhkung@dgist.ac.kr; jaejoon@postech.ac.kr
CR Abadi M., 2016, CORR
   [Anonymous], 2016, P IEEE INT C ADV
   [Anonymous], 2016, 2016 IEEE INT, DOI DOI 10.1109/SiPS.2016.48
   [Anonymous], 1997, NEURAL COMPUT
   Chang A. X. M., 2017, P CIRC SYST ISCAS, P1
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cho K., 2014, P 19 C EMPIRICAL MET, P1, DOI [10.3115/v1/D14-1179, DOI 10.3115/V1/D14-1179, 10.3115]
   Devlin J., 2017, P C EMP METH NAT LAN, P2820
   Dorrance R., 2014, P ACM INT S FIELD PR, P161
   Fowers J, 2014, ANN IEEE SYM FIELD P, P36, DOI 10.1109/FCCM.2014.23
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Garofolo J. S., 1993, TIMIT ACOUSTIC PHONE
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hannun A., 2014, ARXIV14125567
   Hochreiter S., 2001, GRADIENT FLOW RECURR
   Köck M, 2011, USER MODEL USER-ADAP, V21, P51, DOI 10.1007/s11257-010-9087-z
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Ouyang P, 2017, DES AUT CON, DOI 10.1145/3061639.3062187
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park J, 2018, DES AUT TEST EUROPE, P7, DOI 10.23919/DATE.2018.8341971
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Rizakis M., 2018, P INT S APPL REC COM, P3
   Royal College of Physicians HQIP, 2016, GOVT RESOLUTION REPU
   See A., 2016, P C COMP NAT LANG LE, P291
   Shin S, 2016, INT CONF ACOUST SPEE, P976, DOI 10.1109/ICASSP.2016.7471821
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Taylor A., 2003, TREEBANKS SERIES TEX, V20, P5
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
NR 36
TC 3
Z9 3
U1 3
U2 10
PD SEPT
PY 2020
VL 39
IS 9
BP 1889
EP 1901
DI 10.1109/TCAD.2019.2926482
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Navaz, PVM
   Chithra, R
   James, A
AF Navaz, Mohammad P., V
   Chithra, R.
   James, Alex
GP IEEE
TI Memristive Crossbar for Hyper Dimensional Consumer Text Analytics
   Accelerator
SO 2023 21ST IEEE INTERREGIONAL NEWCAS CONFERENCE, NEWCAS
SE IEEE International New Circuits and Systems Conference
DT Proceedings Paper
CT 21st IEEE Interregional NEWCAS Conference (NEWCAS)
CY JUN 26-28, 2023
CL Edinburgh, SCOTLAND
DE Hyper Dimensional Computing; Vector Symbolic Architectures; N-Gram
   Encoding; K Nearest Neighbor
AB Hyper Dimensional (HD) Computing when employed for machine learning tasks such as learning and classification involve the computation and comparison of large hypervectors within memory. The dimensionality of hypervectors in the order of thousands makes it difficult to implement HD computing in von Neumann systems. The in-memory computing capability of the memristor crossbar will speed up the vector-matrix multiplication to perform HD computing. The paper presents a memristive accelerator design for hyper-dimensional consumer text analytics. The hyper-dimensional computing offers simple encoding and data transformation techniques with higher accuracy in comparison with conventional techniques. The circuit implementation of the KNN-based HD classification using N-grams is proposed in the paper. The effect of device variations on the performance of the proposed system is evaluated and the performance is compared with conventional classifiers. The trade-off between accuracy and dimensionality in HD computing is presented.
C1 [Navaz, Mohammad P., V; James, Alex] Digital Univ Kerala, Thiruvananthapuram, Kerala, India.
   [Chithra, R.] Indian Inst Technol & Management Kerala, Kazhakkoottam, India.
RP James, A (corresponding author), Digital Univ Kerala, Thiruvananthapuram, Kerala, India.
EM apj@ieee.org
CR Abhijith M., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P293, DOI 10.1109/ICICICT46008.2019.8993227
   Alonso P, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534359
   [Anonymous], 2007, 22NM PTM MODEL METAL
   Braun D, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P174
   Anderson AG, 2017, Arxiv, DOI arXiv:1705.07199
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Hersche M, 2018, Arxiv, DOI arXiv:1812.05705
   Imani M, 2017, IEEE DES TEST, V34, P94, DOI 10.1109/MDAT.2017.2740839
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Joshi A, 2017, LECT NOTES COMPUT SC, V10106, P265, DOI 10.1007/978-3-319-52289-0_21
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Karunaratne G., 2021, 2021 IEEE 3 INT C AR, P1
   Karunaratne G, 2020, Arxiv, DOI arXiv:1906.01548
   Kleyko D, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3538531
   Molter T. W., 2016, P 15 INT WORKSH CELL, P1
   Peterson LE., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Rahimi A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
   Yang C, 2022, IEEE T CIRCUITS-I, V69, P1395, DOI 10.1109/TCSI.2021.3136355
NR 19
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/NEWCAS57931.2023.10198153
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nikolic, GS
   Dimitrijevic, BR
   Nikolic, TR
   Stojcev, MK
AF Nikolic, Goran S.
   Dimitrijevic, Bojan R.
   Nikolic, Tatjana R.
   Stojcev, Mile K.
GP IEEE
TI A Survey of Three Types of Processing Units: CPU, GPU and TPU
SO 2022 57TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATION,
   COMMUNICATION AND ENERGY SYSTEMS AND TECHNOLOGIES (ICEST)
DT Proceedings Paper
CT 57th International Scientific Conference on Information, Communication
   and Energy Systems and Technologies (ICEST)
CY JUN 16-18, 2022
CL Ohrid, NORTH MACEDONIA
DE CPU; GPU; TPU; hardware accelerator
AB The CPU, GPU, and TPU are three different types of processing units. For the overall performance of the computer, the CPU is responsible. For delivering high-end graphics and video quality, the GPU is responsible. Along with the CPU, the GPU is a piece of additional hardware. TPU is used in the field of Artificial Intelligence, Machine Learning, and Deep Learning. Each of the three processing units has its own set of functions. This article may be of help to a reader with aim to understand the distinctions between the CPU, GPU, and TPU processing units.
C1 [Nikolic, Goran S.; Dimitrijevic, Bojan R.; Nikolic, Tatjana R.; Stojcev, Mile K.] Univ Nis, Fac Elect Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.
RP Nikolic, GS (corresponding author), Univ Nis, Fac Elect Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.
EM goran.nikolic@elfak.ni.ac.rs; bojan.dimitrijevic@elfak.ni.ac.rs;
   tatjana.nikolic@elfak.ni.ac.rs; mile.stojcev@elfak.ni.ac.rs
CR Aamodt Tor M., 2018, GEN PURPOSE GRAPHICS, DOI DOI 10.1007/978-3-031-01759-9
   [Anonymous], 2010, PROCESSOR MICROARCHI
   Charniak E., 2019, INTRO DEEP LEARNING
   Kuhn R., 2021, PARALLEL PROCESSING
   Negnevitsky M., 2005, ARTIF INTELL
   Patterson DA., 2018, COMPUTER ORG DESIGN
   Raj P., 2020, INT J COMPUTER SCI I, V5, P31
   Shao Yakun Sophia, 2015, RES INFRASTRUCTURES
   Smola A, 2008, CAMBRIDGE U UK, V32
   Zahran M, 2019, HETEROGENEOUS COMPUT
NR 10
TC 3
Z9 3
U1 3
U2 3
PY 2022
BP 367
EP 372
DI 10.1109/ICEST55168.2022.9828625
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU He, K
   Chakraborty, I
   Wang, C
   Roy, K
AF He, Kang
   Chakraborty, Indranil
   Wang, Cheng
   Roy, Kaushik
GP IEEE
TI Design Space and Memory Technology Co-exploration for In-Memory
   Computing Based Machine Learning Accelerators
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
DE Machine learning accelerator; in-memory computing; memory technology;
   iso-area; design space
ID DEEP NEURAL-NETWORKS
AB In-Memory Computing (IMC) has become a promising paradigm for accelerating machine learning (ML) inference. While IMC architectures built on various memory technologies have demonstrated higher throughput and energy efficiency compared to conventional digital architectures, little research has been done from systemlevel perspective to provide comprehensive and fair comparisons of different memory technologies under the same hardware budget (area). Since large-scale analog IMC hardware relies on the costly analog-digital converters (ADCs) for robust digital communication, optimizing IMC architecture performance requires synergistic co-design of memory arrays and peripheral ADCs, wherein the trade-offs could depend on the underlying memory technologies. To that effect, we co-explore IMC macro design space and memory technology to identify the best design point for each memory type under iso-area budgets, aiming to make fair comparisons among different technologies, including SRAM, phase change memory, resistive RAM, ferroelectrics and spintronics. First, an extended simulation framework employing spatial architecture with off-chip DRAM is developed, capable of integrating both CMOS and nonvolatile memory technologies. Subsequently, we propose different modes of ADC operations with distinctive weight mapping schemes to cope with different on-chip area budgets. Our results show that under an iso-area budget, the various memory technologies being evaluated will need to adopt different IMC macro-level designs to deliver the optimal energy-delay-product (EDP) at system level. We demonstrate that under small area budgets, the choice of best memory technology is determined by its cell area and writing energy. While area budgets are larger, cell area becomes the dominant factor for technology selection.
C1 [He, Kang; Chakraborty, Indranil; Wang, Cheng; Roy, Kaushik] Purdue Univ, Indianapolis, IN 46202 USA.
RP He, K (corresponding author), Purdue Univ, Indianapolis, IN 46202 USA.
EM he603@purdue.edu; ichakra@purdue.edu; wang4700@purdue.edu;
   kaushik@purdue.edu
CR Ali M, 2021, IEEE SOLID-ST CIRC L, V4, P129, DOI 10.1109/LSSC.2021.3093354
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 1999, CROSSROADS, DOI DOI 10.1145/357783.331677
   Arnaud F, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371934
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Garello K, 2019, SYMP VLSI CIRCUITS, pT194
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZZ, 2017, IEEE INT SYMP NANO, P97, DOI 10.1109/NANOARCH.2017.8053725
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Jaiswal A, 2019, IEEE T VLSI SYST, V27, P2556, DOI 10.1109/TVLSI.2019.2929245
   Keshavarzi A, 2020, IEEE MICRO, V40, P33, DOI 10.1109/MM.2020.3026667
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lu AN, 2020, IEEE T VLSI SYST, V28, P1945, DOI 10.1109/TVLSI.2020.3001526
   Murmann B., 2018, ADC PERFORMANCE SURV
   Ni K, 2018, INT EL DEVICES MEET
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saikia J, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P942, DOI 10.23919/DATE51398.2021.9473973
   Sakr C, 2021, IEEE T SIGNAL PROCES, V69, P6462, DOI 10.1109/TSP.2021.3130488
   Sebastian A, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01481-9
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shao QM, 2021, IEEE T MAGN, V57, DOI 10.1109/TMAG.2021.3078583
   Shen WC, 2012, 2012 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skinner Daniel, 2013, JEDEC MOBILE FORUM C
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Trentzsch M, 2016, INT EL DEVICES MEET
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu W, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P103, DOI 10.1109/VLSIT.2018.8510690
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhu ZH, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317739
NR 39
TC 1
Z9 1
U1 2
U2 2
PY 2022
DI 10.1145/3508352.3549453
WC Computer Science, Theory & Methods; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Myers, A
   Almgren, A
   Amorim, LD
   Bell, J
   Fedeli, L
   Ge, L
   Gott, K
   Grote, DP
   Hogan, M
   Huebl, A
   Jambunathan, R
   Lehe, R
   Ng, C
   Rowan, M
   Shapoval, O
   Thévenet, M
   Vay, JL
   Vincenti, H
   Yang, E
   Zaim, N
   Zhang, W
   Zhao, Y
   Zoni, E
AF Myers, A.
   Almgren, A.
   Amorim, L. D.
   Bell, J.
   Fedeli, L.
   Ge, L.
   Gott, K.
   Grote, D. P.
   Hogan, M.
   Huebl, A.
   Jambunathan, R.
   Lehe, R.
   Ng, C.
   Rowan, M.
   Shapoval, O.
   Thevenet, M.
   Vay, J-L
   Vincenti, H.
   Yang, E.
   Zaim, N.
   Zhang, W.
   Zhao, Y.
   Zoni, E.
TI Porting WarpX to GPU-accelerated platforms
SO PARALLEL COMPUTING
DT Article
DE Exascale Computing; Particle-in-cell methods; Accelerator modeling
ID SIMULATION; CODE
AB WarpX is a general purpose electromagnetic particle-in-cell code that was originally designed to run on many core CPU architectures. We describe the strategy, based on the AMReX library, followed to allow WarpX to use the GPU-accelerated nodes on OLCF's Summit supercomputer, a strategy we believe will extend to the upcoming machines Frontier and Aurora. We summarize the challenges encountered, lessons learned, and give current performance results on a series of relevant benchmark problems.
C1 [Myers, A.; Almgren, A.; Amorim, L. D.; Bell, J.; Ge, L.; Gott, K.; Huebl, A.; Jambunathan, R.; Lehe, R.; Rowan, M.; Shapoval, O.; Vay, J-L; Yang, E.; Zhang, W.; Zhao, Y.; Zoni, E.] Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
   [Ge, L.; Hogan, M.; Ng, C.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Grote, D. P.] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
   [Thevenet, M.] Deutsch Elektronen Synchrotron DESY, D-22607 Hamburg, Germany.
   [Fedeli, L.; Vincenti, H.; Zaim, N.] CEA Univ Paris Saclay, CEA Saclay, LIDYL, F-91191 Gif Sur Yvette, France.
RP Myers, A (corresponding author), Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
EM atmyers@lbl.gov
CR Advanced Micro Devices Inc., 2020, ROCPRIM GITHUB PAGE
   Beckingsale DA, 2019, PROCEEDINGS OF P3HPC 2019: 2019 IEEE/ACM INTERNATIONAL WORKSHOP ON PERFORMANCE, PORTABILITY AND PRODUCTIVITY IN HPC (P3HPC), P71, DOI 10.1109/P3HPC49587.2019.00012
   Burau H, 2010, IEEE T PLASMA SCI, V38, P2831, DOI 10.1109/TPS.2010.2064310
   Bussmann M, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2504564
   CAMPA Collaboration, PART IN CELL MOD INT
   Carneiro P, 2017, ARXIV160704224
   Edwards HC, 2014, J PARALLEL DISTR COM, V74, P3202, DOI 10.1016/j.jpdc.2014.07.003
   Esirkepov TZ, 2001, COMPUT PHYS COMMUN, V135, P144, DOI 10.1016/S0010-4655(00)00228-9
   Godfrey BB, 2014, J COMPUT PHYS, V267, P1, DOI 10.1016/j.jcp.2014.02.022
   Gonoskov A, 2015, PHYS REV E, V92, DOI 10.1103/PhysRevE.92.023305
   Karkkainen M., 2006, P INT COMP ACC PHYS, P35
   Lifschitz AF, 2009, J COMPUT PHYS, V228, P1803, DOI 10.1016/j.jcp.2008.11.017
   Merrill D., 2016, NVR2016001 NVIDIA RE
   NIKISHOV AI, 1970, SOV PHYS JETP-USSR, V30, P660
   NVIDIA Research, 2020, CUB DOC
   Pérez F, 2012, PHYS PLASMAS, V19, DOI 10.1063/1.4742167
   Shapoval O, 2019, COMPUT PHYS COMMUN, V235, P102, DOI 10.1016/j.cpc.2018.09.015
   Surmin I, 2016, LECT NOTES COMPUT SC, V10049, P319, DOI 10.1007/978-3-319-49956-7_25
   Vay JL, 2008, PHYS PLASMAS, V15, DOI 10.1063/1.2837054
   Vay JL, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.130405
   Vay J.-L, 2020, Journal of Physics: Conference Series, V1596, DOI 10.1088/1742-6596/1596/1/012059
   Vazhkudai Sudharshan S., 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P661, DOI 10.1109/SC.2018.00055
   Vincenti H, 2017, COMPUT PHYS COMMUN, V210, P145, DOI 10.1016/j.cpc.2016.08.023
   Vincenti H, 2016, COMPUT PHYS COMMUN, V200, P147, DOI 10.1016/j.cpc.2015.11.009
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yang C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5547
   YEE KS, 1966, IEEE T ANTENN PROPAG, VAP14, P302
   Zhang W., 2020, ARXIV200910401
   Zhang W, 2019, J OPEN SOURCE SOFTW, V4, P1370, DOI DOI 10.21105/JOSS.01370
NR 29
TC 15
Z9 15
U1 0
U2 6
PD DEC
PY 2021
VL 108
AR 102833
DI 10.1016/j.parco.2021.102833
EA SEP 2021
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Redaelli, S
   Assmann, R
   Gander, P
   Jonker, M
   Larnont, M
   Losito, R
   Masi, A
   Sobczak, M
AF Redaelli, S.
   Assmann, R.
   Gander, P.
   Jonker, M.
   Larnont, M.
   Losito, R.
   Masi, A.
   Sobczak, M.
GP IEEE
TI The LHC collimator controls architecture design and beam tests
SO 2007 IEEE PARTICLE ACCELERATOR CONFERENCE, VOLS 1-11
SE IEEE Particle Accelerator Conference
DT Proceedings Paper
CT IEEE Particle Accelerator Conference
CY JUN 25-29, 2007
CL Albuquerque, NM
AB The LHC collimation system will require simultaneous management by the LHC control system of more than 500 jaw positioning mechanisms in order to ensure the required beam cleaning and machine protection performance in all machine phases, from injection at 450 GeV to collision at 7 TeV. Each jaw positionis a critical parameter for the machine safety. In this paper, the architecture of the LHC collimator controls is presented. The basic design to face the accurate control of the LHC collimators and the interfaces to the other components of LHC Software Application and control infrastructures are described. The full controls system has been tested in a real accelerator environment in the CERN SPS during beam tests with a full scale collimator prototype. The results and the lessons learned are presented.
C1 [Redaelli, S.; Assmann, R.; Gander, P.; Jonker, M.; Larnont, M.; Losito, R.; Masi, A.; Sobczak, M.] CERN, Geneva, Switzerland.
RP Redaelli, S (corresponding author), CERN, Geneva, Switzerland.
CR ASSMANN R, PAC05
   JONKER M, 2005, ICALEPCS2005
   KAIN V, 2006, LHCCIES0003 CERN EDM
   MASI A, 2007, 15 IEEE NPSS REAL TI
   REDAELLI S, 2007, 826861 CERN EDMS
   ZAMANTZAS C, 2007, CERNAB2007010B2
NR 6
TC 0
Z9 0
U1 0
U2 0
PY 2007
BP 914
EP 916
WC Engineering, Electrical & Electronic; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Jünger, L
   Winther, S
   Leupers, R
AF Juenger, Lukas
   Winther, Simon
   Leupers, Rainer
BE Fabelo, H
   Ortega, S
   Skavhaug, A
TI X-on-X: Distributed Parallel Virtual Platforms for Heterogeneous Systems
SO 2022 25TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD)
SE EUROMICRO Conference Proceedings
DT Proceedings Paper
CT 25th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2022
CL Maspalomas, SPAIN
DE ESL; PDES; SystemC TLM; Distributed Simulation; InfiniBand
AB The complexity of modern heterogeneous systems leads to simulation performance problems. We show how heterogeneous system verification can be accelerated using a heterogeneous simulator architecture, by distributing simulations amongst different hosts with a novel SystemC TLM-compliant method. Hosts are combined via a high-speed network to leverage their specific advantages when executing simulation segments. To avoid timing causality problems, a conservative, asynchronous parallel discrete event simulation approach is used. We analyze a machine learning task on an embedded Linux system using an ARMv8 virtual platform containing a commercial deep learning accelerator. There, our approach enables speedups of up to 3.9x.
C1 [Juenger, Lukas; Winther, Simon; Leupers, Rainer] Rhein Westfal TH Aachen, Aachen, Germany.
RP Jünger, L (corresponding author), Rhein Westfal TH Aachen, Aachen, Germany.
EM juenger@ice.rwth-aachen.de; winther@ice.rwth-aachen.de;
   leupers@ice.rwth-aachen.de
CR Alian M, 2016, IEEE COMPUT ARCHIT L, V15, P41, DOI 10.1109/LCA.2015.2438295
   [Anonymous], 16662011 IEEE, P1
   [Anonymous], 2016, LANGUAGES DESIGN MET, P135
   Barthels C, 2017, PROC VLDB ENDOW, V10, P517, DOI 10.14778/3055540.3055545
   Becker D, 2015, P IEEE RAP SYST PROT, P54, DOI 10.1109/RSP.2015.7416547
   Bellard F, 2005, USENIX Association Proceedings of the FREENIX/Open Source Track, P41
   Bombieri N, 2012, CODES+ISSS'12:PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE-CODESIGN AND SYSTEM SYNTHESIS, P343
   Busnot G, 2021, INTEGRATION, V79, P23, DOI 10.1016/j.vlsi.2020.12.006
   Chen WW, 2012, DES AUT TEST EUROPE, P141
   Cox D. R., 2005, THESIS ROCHESTER I T
   Google/GitHub, FLATBUFFERS
   Grun P., 2010, CISC VIS NETW IND GL, V55
   Huang K, 2008, INT SYM IND EMBED, P271, DOI 10.1109/SIES.2008.4577715
   Jünger L, 2020, DES AUT TEST EUROPE, P1508, DOI 10.23919/DATE48585.2020.9116573
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Meftali S, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P1496
   Meftali S, 2004, 4TH IEEE INTERNATIONAL WORKSHOP ON SYSTEM-ON-CHIP FOR REAL-TIME APPLICATIONS, PROCEEDINGS, P55, DOI 10.1109/IWSOC.2004.1319849
   Mohammad A, 2017, INT SYM PERFORM ANAL, P153, DOI 10.1109/ISPASS.2017.7975287
   nvdla, NVIDIA DEEP LEARNING
   Peeters J., 2011, P 2011 C DESIGN ARCH, P1
   Sandberg A, 2015, I S WORKL CHAR PROC, P183, DOI 10.1109/IISWC.2015.29
   Sauer C., 2014, P 2014 FORUM SPECIFI, V978, P1
   Schmader T, 2018, PERS SOC PSYCHOL REV, V22, P228, DOI 10.1177/1088868317734080
   Schumacher C., 2010, 2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P241
   Sinha R, 2012, ASIA S PACIF DES AUT, P455, DOI 10.1109/ASPDAC.2012.6164991
   Virtanen J., 2016, 2016 IEEE NORDIC CIR, P1
   Weinstock JH, 2016, DES AUT TEST EUROPE, P493
NR 27
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 142
EP 148
DI 10.1109/DSD57027.2022.00028
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Chuang, KC
   Giles, W
   Adamson, J
AF Chuang, Kai-Cheng
   Giles, William
   Adamson, Justus
TI A tool for patient-specific prediction of delivery discrepancies in
   machine parameters using trajectory log files
SO MEDICAL PHYSICS
DT Article
DE MLC error; patient-specific quality assurance; trajectory log file
ID IMRT; QA; PERFORMANCE; VMAT; ERRORS
AB Purpose: Multileaf collimator (MLC) delivery discrepancy between planned and actual (delivered) positions have detrimental effect on the accuracy of dose distributions for both IMRT and VMAT. In this study, we evaluated the consistency of MLC delivery discrepancies over the course of treatment and over time to verify that a predictive machine learning model would be applicable throughout the course of treatment. Next, the MLC and gantry positions recorded in prior trajectory log files were analyzed to build a machine learning algorithm to predict MLC positional discrepancies during delivery for a new treatment plan. An open source tool was developed and released to predict the MLC positional discrepancies at treatment delivery for any given plan.
   Methods: Trajectory log files of 142 IMRT plans and 125 VMAT plans from 9 Varian TrueBeam linear accelerators were collected and analyzed. The consistency of delivery discrepancy over patient-specific quality assurance (QA) and patient treatment deliveries was evaluated. Data were binned by treatment site and machine type to determine their relationship with MLC and gantry angle discrepancies. Motion-related parameters including MLC velocity, MLC acceleration, control point, dose rate, and gravity vector, gantry velocity and gantry acceleration, where applicable, were analyzed to evaluate correlations with MLC and gantry discrepancies. Several regression models, such as simple/multiple linear regression, decision tree, and ensemble method (boosted tree and bagged tree model) were used to develop a machine learning algorithm to predict MLC discrepancy based on MLC motion parameters.
   Results: MLC discrepancies at patient-specific QA differed from those at patient treatment deliveries by a small (mean = 0.0021 +/- 0.0036 mm, P = 0.0089 for IMRT; mean = 0.0010 +/- 0.0016 mm, P = 0.0003 for VMAT) but statistically significant amount, likely due to setting the gantry angle to zero for QA in IMRT. MLC motion parameters, MLC velocity and gravity vector, showed significant correlation (P < 0.001) with MLC discrepancy, especially MLC velocity, which had an approximately linear relationship (slope = -0.0027, P < 0.001, R-2 = 0.79). Incorporating MLC motion parameters, the final generalized model trained by data from all linear accelerators can predict MLC discrepancy to a high degree of accuracy with high correlation (R-2 = 0.86) between predicted and actual MLC discrepancies. The same prediction results were found across different treatment sites and linear accelerators.
   Conclusion: We have developed a machine learning model using trajectory log files to predict the MLC discrepancies during delivery. This model has been a released as a research tool in which a DICOM-RT with predicted MLC positions can be generated using the original DICOM-RT file as input. This tool can be used to simulate radiotherapy treatment delivery and may be useful for studies evaluating plan robustness and dosimetric uncertainties from treatment delivery. (c) 2020 American Association of Physicists in Medicine
C1 [Chuang, Kai-Cheng] Duke Univ, Med Phys Grad Program, Durham, NC USA.
   [Chuang, Kai-Cheng] Duke Kunshan Univ, Med Phys Grad Program, Kunshan, Peoples R China.
   [Giles, William; Adamson, Justus] Duke Univ, Med Ctr, Dept Radiat Oncol, Durham, NC 27708 USA.
RP Adamson, J (corresponding author), Duke Univ, Med Ctr, Dept Radiat Oncol, Durham, NC 27708 USA.
EM justus.adamson@duke.edu
CR Acharya S, 2016, INT J RADIAT ONCOL, V94, P394, DOI 10.1016/j.ijrobp.2015.10.015
   Agnew A, 2014, PHYS MED BIOL, V59, pN49, DOI 10.1088/0031-9155/59/9/N49
   Agnew CE, 2014, J APPL CLIN MED PHYS, V15, P204, DOI 10.1120/jacmp.v15i6.4994
   [Anonymous], 2019, VAR MED SYST TRUEBEA, P1
   Bohoudi O, 2017, RADIOTHER ONCOL, V125, P439, DOI 10.1016/j.radonc.2017.07.028
   Broggi S, 2013, J APPL CLIN MED PHYS, V14, P265, DOI 10.1120/jacmp.v14i5.4329
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Childress N, 2015, J APPL CLIN MED PHYS, V16, P4, DOI 10.1120/jacmp.v16i1.5385
   Granville DA, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab142e
   Huq MS, 2008, INT J RADIAT ONCOL, V71, pS170, DOI 10.1016/j.ijrobp.2007.06.081
   Katsuta Y, 2016, PHYS MEDICA, V32, P701, DOI 10.1016/j.ejmp.2016.04.015
   Kerns JR, 2014, RADIAT ONCOL, V9, DOI 10.1186/1748-717X-9-176
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Litzenberg DW, 2002, MED PHYS, V29, P810, DOI 10.1118/1.1470499
   Losasso T, 2008, INT J RADIAT ONCOL, V71, pS85, DOI 10.1016/j.ijrobp.2007.06.082
   McGarry CK, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20150489
   Men CH, 2010, PHYS MED BIOL, V55, P4309, DOI 10.1088/0031-9155/55/15/008
   Neal B, 2016, MED PHYS, V43, P2933, DOI 10.1118/1.4949002
   Nelms BE, 2013, MED PHYS, V40, DOI 10.1118/1.4826166
   Nelms BE, 2011, MED PHYS, V38, P1037, DOI 10.1118/1.3544657
   Nyflot MJ, 2019, MED PHYS, V46, P456, DOI 10.1002/mp.13338
   Olasolo-Alonso J, 2017, PHYS MEDICA, V33, P87, DOI 10.1016/j.ejmp.2016.12.013
   Osman AFI, 2020, MED PHYS, V47, P1421, DOI 10.1002/mp.14014
   Rangaraj D., 2017, BAYL U MED CTR P
   Sun BZ, 2013, PRACT RADIAT ONCOL, V3, pE199, DOI 10.1016/j.prro.2012.11.013
   Sun BZ, 2012, J APPL CLIN MED PHYS, V13, P140, DOI 10.1120/jacmp.v13i5.3837
   Teke T, 2010, MED PHYS, V37, P116, DOI 10.1118/1.3266821
   Tomori S, 2018, MED PHYS, V45, P4055, DOI 10.1002/mp.13112
   Tyagi N, 2012, MED PHYS, V39, P7194, DOI 10.1118/1.4764482
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Valdes G, 2017, J APPL CLIN MED PHYS, V18, P279, DOI 10.1002/acm2.12161
   Wijesooriya K, 2012, MED PHYS, V39, P1846, DOI 10.1118/1.3690464
   Wu BB, 2019, MED PHYS, V46, P475, DOI 10.1002/mp.13363
   Zaila A., 2016, PHYS MED, V32, P292, DOI [10.1016/j.ejmp.2016.07.122, DOI 10.1016/J.EJMP.2016.07.122]
NR 34
TC 18
Z9 18
U1 0
U2 14
PD MAR
PY 2021
VL 48
IS 3
BP 978
EP 990
DI 10.1002/mp.14670
EA JAN 2021
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Vestias, MP
   Duarte, RP
   de Sousa, JT
   Neto, HC
AF Vestias, Mario P.
   Duarte, Rui Policarpo
   de Sousa, Jose T.
   Neto, Horacio C.
TI Moving Deep Learning to the Edge
SO ALGORITHMS
DT Review
DE artificial intelligence; deep learning; deep neural network; edge
   computing
ID NEURAL-NETWORKS; CLOUD; CLASSIFICATION; RECOGNITION; ACCELERATOR;
   INTERNET; FLOW; CNN; GO
AB Deep learning is now present in a wide range of services and applications, replacing and complementing other machine learning algorithms. Performing training and inference of deep neural networks using the cloud computing model is not viable for applications where low latency is required. Furthermore, the rapid proliferation of the Internet of Things will generate a large volume of data to be processed, which will soon overload the capacity of cloud servers. One solution is to process the data at the edge devices themselves, in order to alleviate cloud server workloads and improve latency. However, edge devices are less powerful than cloud servers, and many are subject to energy constraints. Hence, new resource and energy-oriented deep learning models are required, as well as new computing platforms. This paper reviews the main research directions for edge computing deep learning algorithms.
C1 [Vestias, Mario P.] Inst Politecn Lisboa, Inst Super Engn Lisboa, Inst Engn Sistemas & Comp Invest & Desenvolviment, P-1959007 Lisbon, Portugal.
   [Duarte, Rui Policarpo; de Sousa, Jose T.; Neto, Horacio C.] Univ Lisbon, Inst Super Tecn, Inst Engn Sistemas & Comp Invest & Desenvolviment, P-1049001 Lisbon, Portugal.
RP Vestias, MP (corresponding author), Inst Politecn Lisboa, Inst Super Engn Lisboa, Inst Engn Sistemas & Comp Invest & Desenvolviment, P-1959007 Lisbon, Portugal.
EM mvestias@deetc.isel.ipl.pt; rui.duarte@tecnico.ulisboa.pt;
   jose.desousa@inesc-id.pt; hcn@inesc-id.pt
CR Abad MSH, 2020, INT CONF ACOUST SPEE, P8866, DOI [10.1109/ICASSP40776.2020.9054634, 10.1109/icassp40776.2020.9054634]
   Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Adam H, 2018, ARXIV180403230
   Addo PM, 2018, RISKS, V6, DOI 10.3390/risks6020038
   Aggarwal C. C., 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Alam M, 2017, GLOBAL SCI TECH, V9, P37
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ali I, 2015, REMOTE SENS-BASEL, V7, P16398, DOI 10.3390/rs71215841
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Amazon, 2016, AL VOIC SERV
   Amazon, 2019, AWS DEEPL
   [Anonymous], 2018, P NIPS 2018 DEC
   [Anonymous], 2016, P 4 INT C LEARN REPR
   [Anonymous], 2019 2 IEEE C MULT
   [Anonymous], 2015, P 3 INT C LEARNING R
   [Anonymous], 2018, ARXIV180201548
   [Anonymous], 2018, P 28 INT C FIELD PRO
   [Anonymous], 2015, P INT C NEUR INF PRO
   [Anonymous], 2018, ARXIV180408333
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2019, P IEEE, DOI DOI 10.1109/JPROC.2019.2918951
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, TENS DNA PROC IP AI
   [Anonymous], 2016, ARXIV161207119
   [Anonymous], 2017, ARXIV170707012
   [Anonymous], 2018, INT C LEARN REPR
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2015, 32 ICML
   [Anonymous], P 14 INT C ART INT S
   [Anonymous], 2018, P USENIX WORKSH HOT
   [Anonymous], 2018, CEV NEUPRO ACC NEUR
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   Apple, 2017, DEEP LEARN SIR VOIC
   Apple, 2017, HEY SIRI ON DEV DDN
   Awasthi A, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P362, DOI 10.1145/3297001.3297062
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Barbera MV, 2013, IEEE INFOCOM SER, P1285
   Beling P, 2018, 2018 SYST INF ENG DE, P129, DOI DOI 10.1109/SIEDS.2018.8374722
   Bobby M, 2018, INT J ADV RES, V6, P566, DOI DOI 10.21474/IJAR01/7839
   BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918
   Chang YY, 2019, ASIA-PAC CONF COMMUN, P126, DOI [10.1109/apcc47188.2019.9026483, 10.1109/APCC47188.2019.9026483]
   Chen C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1265, DOI 10.1145/3331184.3331370
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cisco, CISC GLOB CLOUD IND
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Cuervo E, 2010, Proceedings of the 8th international conference on mobile systems, applications, and services, DOI [10.1145/1814433.1814441, DOI 10.1145/1814433.1814441]
   Dally W.J., 2017, ARXIV171201887
   de Souza JT, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11041077
   Dean J., 2015, COMPUTING RES REPOSI
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Deng Y, 2019, DEEP LEARNING MOBILE
   Erol BA, 2018, STUD COMPUT INTELL, V777, P369, DOI 10.1007/978-3-319-89629-8_14
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Faraone J, 2020, IEEE T VLSI SYST, V28, P115, DOI 10.1109/TVLSI.2019.2939429
   Fergus R, 2014, IEEE C COMP VIS PATT, P6
   Fujii Y, 2018, BMC SURG, V18, DOI 10.1186/s12893-018-0375-6
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Gensler A, 2016, IEEE SYS MAN CYBERN, P2858, DOI 10.1109/SMC.2016.7844673
   Goncalves A, 2019, P INT S APPL REC COM, P387
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   Guo K, 2017, ARXIV171208934
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Gupta I., 2019, ARXIV190306996
   Gyrfalcon Technology, 2018, LIGHTSP 2803S NEUR A
   Han S., 2015, ARXIV151000149
   Hartwig Adam, ARXIV170404861
   Hassan N, 2018, IEEE COMMUN MAG, V56, P110, DOI 10.1109/MCOM.2018.1700906
   Hassoun M., 2003, FUNDAMENTALS ARTIFIC
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E, 2012, IMPROVING NEURAL NET, V3, P212
   Hinton G.E., 1986, PARALLEL DISTRIBUTED, V1, P282, DOI DOI 10.1234/12345678
   Hisilicon, 2019, KIRN 950 5G
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Howard Andrew, 2019, ARXIV190502244
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang WH, 2014, IEEE T INTELL TRANSP, V15, P2191, DOI 10.1109/TITS.2014.2311123
   Huang Y, 2017, 2017 IEEE 26TH NORTH ATLANTIC TEST WORKSHOP (NATW), P1
   Huawei, ASC 910 PROC
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Hung C.C, 2018, P ACM IEEE S EDG COM
   Hwang K, 2017, CLOUD COMPUTING FOR MACHINE LEARNING AND COGNITIVE APPLICATIONS, P1
   Iandola FN, 2016, PROC INT C LEARN
   Ienco Dino, 2017, IEEE Geoscience and Remote Sensing Letters, V14, P1685, DOI 10.1109/LGRS.2017.2728698
   Intel, 2017, INT MOV MYR X VPU
   Jeong HJ, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P401, DOI 10.1145/3267809.3267828
   Jermyn M, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.094002
   Jiang X., 2019, DEEP LEARNING OBJECT
   Kala S, 2019, IEEE T VLSI SYST, V27, P2816, DOI 10.1109/TVLSI.2019.2941250
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kang YP, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P615, DOI 10.1145/3037697.3037698
   Kaur G, 2018, ACCENTS T IMAGE PROC, V4, P21, DOI [DOI 10.19101/TIPCV.2018.411003, 10.19101/TIPCV.2018.411003]
   Keutzer K., 2018, ARXIV180310615
   Kim D, 2018, P IEEE RAP SYST PROT, P104, DOI 10.1109/RSP.2018.8632001
   Konecny J., 2016, WORKSH PRIV MULT MAC
   Krizhevsky A., IMAGENET CLASSIFICAT
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Larochelle H, GREEDY LAYER WISE TR
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Le Q.V, 2017, ARXIV170406877
   LECUN Y, 1989, IEEE COMMUN MAG, V27, P41, DOI 10.1109/35.41400
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   LeCun Y., 1990, HANDWRITTEN DIGIT RE, V2, P396, DOI DOI 10.1111/DSU.12130
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Lee S, 2018, INT C CONTR AUTOMAT, P247
   Leo M, 2019, RISKS, V7, DOI 10.3390/risks7010029
   Li D., 2018, DEEP LEARNING NATURA
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Lin DD, 2016, PR MACH LEARN RES, V48
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu J., 2018, ADV NEURAL INFORM PR, P7663
   Liu SC, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P389, DOI 10.1145/3210240.3210337
   Liu Y, 2010, J IRON STEEL RES INT, V17, P1, DOI 10.3969/j.issn.1005-0507.2010.01.001
   Losing V, 2018, NEUROCOMPUTING, V275, P1261, DOI 10.1016/j.neucom.2017.06.084
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Luo JH, 2019, IEEE T PATTERN ANAL, V41, P2525, DOI 10.1109/TPAMI.2018.2858232
   Mannini A, 2010, SENSORS-BASEL, V10, P1154, DOI 10.3390/s100201154
   Mao JC, 2017, DES AUT TEST EUROPE, P1396, DOI 10.23919/DATE.2017.7927211
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Micikevicius P., 2017, ARXIV171003740
   Miklosik A, 2019, IEEE ACCESS, V7, P85705, DOI 10.1109/ACCESS.2019.2924425
   Najafabadi M M, 2015, J BIG DATA-GER, P1
   Nakahara H, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P168, DOI 10.1109/FPT.2017.8280135
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Pan JL, 2018, IEEE INTERNET THINGS, V5, P439, DOI 10.1109/JIOT.2017.2767608
   Parisi G. I., 2018, CORR
   Peres Tiago, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P402, DOI 10.1007/978-3-030-17227-5_28
   Popa D, 2019, NEURAL COMPUT APPL, V31, P1317, DOI 10.1007/s00521-018-3724-6
   Qiao YR, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3850
   Qualcomm, 2019, 865 5G MOB PLATF
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ran XK, 2018, IEEE INFOCOM SER, P1421, DOI 10.1109/INFOCOM.2018.8485905
   Ren J., 2019, ACM COMPUT SURV, V52, P1
   Ruder, 2017, OVERVIEW MULTI TASK
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samarakoon S, 2020, IEEE T COMMUN, V68, P1146, DOI 10.1109/TCOMM.2019.2956472
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Shi WS, 2019, P IEEE, V107, P1474, DOI 10.1109/JPROC.2019.2928287
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Singh SP, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P162, DOI 10.1109/COMPTELIX.2017.8003957
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Statista, 2020, NUMB INT THINGS IOT
   Struharik RJR, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102991
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   SUN Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI DOI 10.1155/2017/7361042
   Synopsys, 2017, DESIGNWARE EV6X VIS
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tao YD, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P286, DOI 10.1109/MIPR.2019.00058
   Teerapittayanon S, 2017, INT CON DISTR COMP S, P328, DOI 10.1109/ICDCS.2017.226
   Trappey AJC, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071478
   Tsochatzidis L, 2019, J IMAGING, V5, DOI 10.3390/jimaging5030037
   Tung F, 2020, IEEE T PATTERN ANAL, V42, P568, DOI 10.1109/TPAMI.2018.2886192
   Tuvblad C, 2016, DEV PSYCHOPATHOL, V28, P27, DOI 10.1017/S0954579415000267
   Tyagi AC, 2016, IRRIG DRAIN, V65, P388, DOI 10.1002/ird.2076
   Ullah Z, 2020, COMPUT COMMUN, V154, P313, DOI 10.1016/j.comcom.2020.02.069
   V?®stias M.P., 2020, SMART SYST DES APPL, P23, DOI [10.4018/978-1-7998-2112-0.ch002, DOI 10.4018/978-1-7998-2112-0.CH002]
   Varghese B, 2018, FUTURE GENER COMP SY, V79, P849, DOI 10.1016/j.future.2017.09.020
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Véstias M, 2019, I C FIELD PROG LOGIC, P350, DOI 10.1109/FPL.2019.00062
   Véstias MP, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111321
   Véstias MP, 2019, ALGORITHMS, V12, DOI 10.3390/a12080154
   Wang D., 2016, DEEP LEARNING IDENTI
   Wang J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2407, DOI 10.1145/3219819.3220106
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003
   Wang SQ, 2019, IEEE J SEL AREA COMM, V37, P1205, DOI 10.1109/JSAC.2019.2904348
   Wang XF, 2019, IEEE NETWORK, V33, P156, DOI 10.1109/MNET.2019.1800286
   Wang X, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120852
   Wang XY, 2017, IEEE T VEH TECHNOL, V66, P763, DOI 10.1109/TVT.2016.2545523
   Winograd Shmuel, 1980, SOC IND APPL MATH, P71, DOI DOI 10.1137/1.9781611970364
   Wojna Z, 2016, P 2016 IEEE C COMP V
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xiong H, 2014, SCIENCE NEW YORK NY, V347
   XIONG Y, 2019, ARXIV190403775
   Yang Y., 2019, P INT C LERN REPR NE
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zantalis F, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040094
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang H, 2020, IEEE T COMPUT, V69, P26, DOI 10.1109/TC.2019.2936192
   Zhang T., 2018, ARXIV180701860
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang ZH, 2018, TRANSPORT RES C-EMER, V86, P580, DOI 10.1016/j.trc.2017.11.027
   Zhao YL, 2019, IEEE ACCESS, V7, P101213, DOI 10.1109/ACCESS.2019.2927538
   Zhao YL, 2019, ALGORITHMS, V12, DOI 10.3390/a12050112
   Zhao YL, 2018, ALGORITHMS, V11, DOI 10.3390/a11100159
   Zhao ZR, 2018, IEEE T COMPUT AID D, V37, P2348, DOI 10.1109/TCAD.2018.2858384
   Zhou CG, 2019, IEEE ACCESS, V7, P148779, DOI 10.1109/ACCESS.2019.2946681
   Zoph B, ARXIV161101578
NR 199
TC 34
Z9 35
U1 2
U2 23
PD MAY
PY 2020
VL 13
IS 5
AR 125
DI 10.3390/a13050125
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT S
AU Krödel, M
   Kuhnert, KD
AF Krödel, M
   Kuhnert, KD
BE Reusch, B
TI Autonomous driving through intelligent image processing and machine
   learning
SO COMPUTATIONAL INTELLIGENCE: THEORY AND APPLICATIONS, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
DT Article; Proceedings Paper
CT 7th Fuzzy International Conference on Computational Intelligence
CY OCT 01-03, 2001
CL Dortmund, GERMANY
AB This abstract describes the current research in the area of autonomously driving of a vehicle along different road courses [1]. The focus of this paper are two main aspects: firstly, parameters of the environment are being extracted from a video image coming from one single camera which is installed in or in front of the vehicle which is to drive along the road course; secondly, the incoming images from the camera need to be processed by a computer system that way, that not only Steering Commands for the vehicle are being generated (for accelerator / brake as well as the steering wheel) but the appropriateness of those Steering Commands is being constantly weighed and continuously improved over time. Consequently, the current work focuses on a system which is able to learn and to develop completely on its own the ability to steer different vehicles in different environments and combines research in the areas of Intelligent Image Processing, Machine Learning and Robotics.
C1 Univ Siegen, Inst Real Time Syst, D-57068 Siegen, Germany.
RP Krödel, M (corresponding author), Univ Siegen, Inst Real Time Syst, Holderlinstr 3, D-57068 Siegen, Germany.
CR Baird LC., 1999, REINFORCEMENT LEARNI
   BALUJA S, 1997, ROBOTICS AUTONOMOUS, V22
   DICKMANNS ED, 1987, 10 WORLD C AUT CONTR, V4
   JOCHEM TM, 1993, IAS 3 INT C INT AUT
   JOCHEM TM, 1995, INT VEH 95 S SEPT 25
   KRODEL M, 2000, IEEE INT C IND EL CO
NR 6
TC 0
Z9 0
U1 0
U2 1
PY 2001
VL 2206
BP 712
EP 718
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Mukherjee, S
   Gong, X
   Yu, LM
   McCardwell, C
   Ukidave, Y
   Dao, T
   Paravecino, FN
   Kaeli, D
AF Mukherjee, Saoni
   Gong, Xiang
   Yu, Leiming
   McCardwell, Carter
   Ukidave, Yash
   Dao, Tuan
   Paravecino, Fanny Nina
   Kaeli, David
BE Deakin, TM
TI Exploring the Features of OpenCL 2.0
SO International Workshop on OpenCL 2015
DT Proceedings Paper
CT 3rd International Workshop on OPEMCL
CY MAY 12-13, 2015
CL Palo Alto, CA
AB The growth in demand for heterogeneous accelerators has stimulated the development of cutting-edge features in newer accelerators. The heterogeneous programing frameworks such as OpenCL have matured over the years and have introduced new software features for developers. We explore one of these programming frameworks, OpenCL 2.0. To drive our study, we consider a number new features in OpenCL 2.0 using four popular applications from a range of computing domains including signal processing, cybersecurity and machine learning. These applications include: 1) the AES-128 encryption standard, 2) Finite Inpulse Response filtering, 3) Infinite Impulse Response filtering, and 4) Hidden Markov model. In this work, we introduce the latest runtime features enabled in OpenCL 2.0, and discuss how well our sample applications can benefit from some of these features.
C1 [Mukherjee, Saoni; Gong, Xiang; Yu, Leiming; McCardwell, Carter; Ukidave, Yash; Dao, Tuan; Paravecino, Fanny Nina; Kaeli, David] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
RP Mukherjee, S (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM saoni@ece.neu.edu; xgong@ece.neu.edu; ylm@ece.neu.edu;
   cmccardw@ece.neu.edu; yukidave@ece.neu.edu; tdao@ece.neu.edu;
   fninaparavecino@ece.neu.edu; kaeli@ece.neu.edu
CR [Anonymous], 1997, COURSE DIGITAL SIGNA
   [Anonymous], 2011, HETEROGENEOUS COMPUT
   [Anonymous], AMD FUSION DEV SUMMI
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Daemen J, 2002, SPECIFICATION RIJNDA, DOI DOI 10.1007/978-3-662-60769-5_3
   Khronos OpenCL Working Group, 2013, OPENCL 2 0 SPEC
   Manavski SA, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P65
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Oppenheim A.V., 1983, SIGNALS SYSTEMS, V2
   RABINER LR, 1983, AT&T TECH J, V62, P1075, DOI 10.1002/j.1538-7305.1983.tb03115.x
   Yu L., 2014, HET UNC CLUST ARCH A
   2001, FEDERAL INFORM PROCE, V197, P441
NR 12
TC 1
Z9 1
U1 0
U2 0
PY 2015
DI 10.1145/2791321.2791326
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Podusenko, A
   Nikulin, V
   Tanev, I
   Shimohara, K
AF Podusenko, Albert
   Nikulin, Vsevolod
   Tanev, Ivan
   Shimohara, Katsunori
GP IEEE
TI Prediction of Emergency Braking based on the Pattern of Lifting Motion
   of Accelerator Pedal
SO 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL
   ENGINEERS OF JAPAN (SICE)
DT Proceedings Paper
CT 56th Annual Conference of the
   Society-of-Instrument-and-Control-Engineers-of-Japan (SICE)
CY SEP 19-22, 2017
CL Kanazawa Univ, Kanazawa, JAPAN
HO Kanazawa Univ
DE emergency braking; prediction; classifying; time lag; proactive braking
AB We explore the feasibility of classifying the emergency braking situations solely from the pattern of lifting motion of the accelerator pedal. The ultimate objective such a classification lies in reducing the time lag between the instant (i) when the driver lifts their foot from the accelerator pedal and (ii) then energetically presses the brake pedal in order to stop the car in hazardous, emergency braking situations. At high speed, this time lag results in several meters of traveled distance. Therefore, minimizing the lag would result in reduced risks of road traffic accidents lead and enhanced road safety. We proposed a machine learning approach of classifying the emergency braking based on gradient boosting. The latter infers the braking situation as either emergency braking or normal braking or deceleration from the training set of time series of braking events recorded from 11 humans (men and women, aged 22-52) while driving a car in a full scale drive simulator. The experimental results show that the trained classifier detects the emergency braking situations with the f-score of about 0.941 on the testing set of the dynamics of the accelerator pedal.
C1 [Podusenko, Albert; Nikulin, Vsevolod; Tanev, Ivan; Shimohara, Katsunori] Doshisha Univ, Grad Sch Sci & Engn, 1-3 Tatara Miyakodani, Kyoto 6100321, Japan.
RP Podusenko, A (corresponding author), Doshisha Univ, Grad Sch Sci & Engn, 1-3 Tatara Miyakodani, Kyoto 6100321, Japan.
EM podusenko2016@sil.doshisha.ac.jp; nikulin2016@sil.doshisha.ac.jp;
   itanev@sil.doshisha.ac.jp; kshimoha@sil.doshisha.ac.jp
CR Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   FLETCHER R, 1963, COMPUT J, V6, P163, DOI 10.1093/comjnl/6.2.163
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kohavi R., 1995, INT JOINT C ARTIFICI, DOI DOI 10.5555/1643031.1643047
   Podusenko A., FAST ZERO 2 IN PRESS
NR 8
TC 1
Z9 1
U1 2
U2 2
PY 2017
BP 1622
EP 1627
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Largent, A
   Nunes, JC
   Lafond, C
   Périchon, N
   Castelli, J
   Rolland, Y
   Acosta, O
   de Crevoisier, R
AF Largent, A.
   Nunes, J. -C.
   Lafond, C.
   Perichon, N.
   Castelli, J.
   Rolland, Y.
   Acosta, O.
   de Crevoisier, R.
TI MRI-based radiotherapy planning
SO CANCER RADIOTHERAPIE
DT Article
DE Radiotherapy; MRI; Dose calculation; Pseudo CT
ID PSEUDO-CT; ATTENUATION CORRECTION; ADAPTIVE RADIOTHERAPY;
   RADIATION-THERAPY; AUTO-CONTEXT; HEAD; REGISTRATION; IMAGE; NECK;
   SEGMENTATION
AB MRI-based radiotherapy planning is a topical subject due to the introduction of a new generation of treatment machines combining a linear accelerator and a MRI. One of the issues for introducing MRI in this task is the lack of information to provide tissue density information required for dose calculation. To cope with this issue, two strategies may be distinguished from the literature. Either a synthetic CT scan is generated from the MRI to plan the dose, or a dose is generated from the MRI based on physical underpinnings. Within the first group, three approaches appear: bulk density mapping assign a homogeneous density to different volumes of interest manually defined on a patient MRI; machine learning-based approaches model local relationship between CT and MRI image intensities from multiple data, then applying the model to a new MRI; atlas-based approaches use a co-registered training data set (CTMRI) which are registered to a new MRI to create a pseudo CT from spatial correspondences in a final fusion step. Within the second group, physics-based approaches aim at computing the dose directly from the hydrogen contained within the tissues, quantified by MRI. Excepting the physics approach, all these methods generate a synthetic CT called "pseudo CT", on which radiotherapy planning will be finally realized. This literature review shows that atlas-and machine learning-based approaches appear more accurate dosimetrically. Bulk density approaches are not appropriate for bone localization. The fastest methods are machine learning and the slowest are atlas-based approaches. The less automatized are bulk density assignation methods. The physical approaches appear very promising methods. Finally, the validation of these methods is crucial for a clinical practice, in particular in the perspective of adaptive radiotherapy delivered by a linear accelerator combined with an MRI scanner. (C) 2017 Published by Elsevier Masson SAS on behalf of Societe francaise de radiotherapie oncologique (SFRO).
C1 [Largent, A.; Nunes, J. -C.; Castelli, J.; Rolland, Y.; Acosta, O.; de Crevoisier, R.] Univ Rennes 1, Lab Traitement Signal & Image, Campus Beaulieu,263 Ave Gen Leclerc, F-35042 Rennes, France.
   [Lafond, C.; Perichon, N.; Castelli, J.; de Crevoisier, R.] Ctr Reg Lutte Canc Eugene Marquis, Dept Radiotherapie, Ave Bataille Flandres Dunkerque, F-35042 Rennes, France.
   [Rolland, Y.] Ctr Reg Lutte Canc Eugene Marquis, Dept Imagerie Med, Ave Bataille Flandres Dunkerque, F-35042 Rennes, France.
   [Largent, A.; Nunes, J. -C.; Castelli, J.; Acosta, O.; de Crevoisier, R.] INSERM, UMR 1099, 263 Ave Gen Leclerc, F-35042 Rennes, France.
RP de Crevoisier, R (corresponding author), Univ Rennes 1, Lab Traitement Signal & Image, Campus Beaulieu,263 Ave Gen Leclerc, F-35042 Rennes, France.; de Crevoisier, R (corresponding author), Ctr Reg Lutte Canc Eugene Marquis, Dept Radiotherapie, Ave Bataille Flandres Dunkerque, F-35042 Rennes, France.; de Crevoisier, R (corresponding author), INSERM, UMR 1099, 263 Ave Gen Leclerc, F-35042 Rennes, France.
EM r.de-crevoisier@rennes.unicancer.fr
CR [Anonymous], 1990, DISORDER PHYS SYSTEM
   Bakai A, 2003, PHYS MED BIOL, V48, P3543, DOI 10.1088/0031-9155/48/21/006
   Burgos Ninon, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P547, DOI 10.1007/978-3-319-46723-8_63
   Burgos N, 2015, LECT NOTES COMPUT SC, V9350, P476, DOI 10.1007/978-3-319-24571-3_57
   Burgos N, 2014, IEEE T MED IMAGING, V33, P2332, DOI 10.1109/TMI.2014.2340135
   Chen LL, 2007, INT J RADIAT ONCOL, V68, P903, DOI 10.1016/j.ijrobp.2007.02.033
   Chuter R, 2017, RADIOTHER ONCOL, V122, P229, DOI 10.1016/j.radonc.2016.07.016
   de Crevoisier R, 2016, Cancer Radiother, V20 Suppl, pS27, DOI 10.1016/j.canrad.2016.07.034
   Demol B, 2016, MED PHYS, V43, P6557, DOI 10.1118/1.4967480
   Demol B, 2015, J APPL CLIN MED PHYS, V16, P117, DOI 10.1120/jacmp.v16i5.5586
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dowling JA, 2015, INT J RADIAT ONCOL, V93, P1144, DOI 10.1016/j.ijrobp.2015.08.045
   Dowling JA, 2012, INT J RADIAT ONCOL, V83, pE5, DOI 10.1016/j.ijrobp.2011.11.056
   Ecabert O, 2008, IEEE T MED IMAGING, V27, P1189, DOI 10.1109/TMI.2008.918330
   Fortunati V, 2014, INT J RADIAT ONCOL, V90, P85, DOI 10.1016/j.ijrobp.2014.05.027
   Hildeman A, 2016, ARXIV2016160702188 C
   Hoogcarspel SJ, 2014, PHYS MED BIOL, V59, P7383, DOI 10.1088/0031-9155/59/23/7383
   Hsu SH, 2013, PHYS MED BIOL, V58, P8419, DOI 10.1088/0031-9155/58/23/8419
   Isambert A, 2008, RADIOTHER ONCOL, V87, P93, DOI 10.1016/j.radonc.2007.11.030
   JACKSON DF, 1981, PHYS REP, V70, P169, DOI 10.1016/0370-1573(81)90014-4
   Johanson A, 2013, ACTA ONCOL, V52, P1369, DOI 10.3109/0284186X.2013.819119
   Johansson A, 2011, MED PHYS, V38, P2708, DOI 10.1118/1.3578928
   Jonsson JH, 2013, RADIOTHER ONCOL, V108, P118, DOI 10.1016/j.radonc.2013.04.028
   K?hler MVT., 2015, MR ONLY SIMULATION R
   Kapanen M, 2013, ACTA ONCOL, V52, P612, DOI 10.3109/0284186X.2012.692883
   Korhonen J, 2014, MED PHYS, V41, DOI 10.1118/1.4842575
   Korsholm ME, 2014, RADIAT ONCOL, V9, DOI 10.1186/1748-717X-9-16
   Lafond C, 2015, CANCER RADIOTHER, V19, P450, DOI 10.1016/j.canrad.2015.06.006
   Lambert J, 2011, RADIOTHER ONCOL, V98, P330, DOI 10.1016/j.radonc.2011.01.012
   Lee YK, 2003, RADIOTHER ONCOL, V66, P203, DOI 10.1016/S0167-8140(02)00440-1
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Maingon P, 2016, CANCER RADIOTHER, V20, P558, DOI 10.1016/j.canrad.2016.07.070
   McPartlin AJ, 2016, RADIOTHER ONCOL, V119, P371, DOI 10.1016/j.radonc.2016.04.014
   Modat M, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.2.024003
   Reynaert N, 2016, PHYS MEDICA, V32, P1225, DOI 10.1016/j.ejmp.2016.09.009
   Rivest-Henault D, CLIN IMAGE BASED PRO
   Rivest-Henault D, 2015, MED IMAGE ANAL, V23, P56, DOI 10.1016/j.media.2015.04.014
   Sjölund J, 2015, PHYS MED BIOL, V60, P825, DOI 10.1088/0031-9155/60/2/825
   Huynh T, 2016, IEEE T MED IMAGING, V35, P174, DOI 10.1109/TMI.2015.2461533
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Uha J, 2014, MED PHYS, V41, DOI 10.1118/1.4873315
   Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040
   Wang C, 2008, TECHNOL CANCER RES T, V7, P341, DOI 10.1177/153303460800700501
NR 44
TC 5
Z9 5
U1 1
U2 10
PD DEC
PY 2017
VL 21
IS 8
BP 788
EP 798
DI 10.1016/j.canrad.2017.02.007
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Gonzalez-Guerrero, P
   Huch, K
   Patra, N
   Popovici, T
   Michelogiannakis, G
AF Gonzalez-Guerrero, Patricia
   Huch, Kylie
   Patra, Nirmalendu
   Popovici, Thom
   Michelogiannakis, George
GP IEEE
TI An Area Efficient Superconducting Unary CNN Accelerator
SO 2023 24TH INTERNATIONAL SYMPOSIUM ON QUALITY ELECTRONIC DESIGN, ISQED
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 24th International Symposium on Quality Electronic Design (ISQED)
CY APR 05-07, 2023
CL ELECTR NETWORK
DE superconducting computing; superconducting logic; race logic; pulse
   streams arithmetic; unary; hardware accelerator; CNN; machine learning;
   Josephson junction
ID NEURAL-NETWORKS; RSFQ; DESIGN
AB In superconducting circuits, information is carried by ps-wide, mu V-tall, Single Flux Quanta (SFQ) pulses. These circuits can operate at frequencies of hundreds of GHz with orders of magnitude lower switching energy than complementary-metal-oxide-semiconductors (CMOS). However, under the stringent area constraints of modern superconductor technologies, fully-fledged, CMOS-inspired superconducting architectures cannot be fabricated at large scales. Unary SFQ (U-SFQ) is an alternative computing paradigm that addresses these area constraints. In U-SFQ, information is mapped to a combination of streams of SFQ pulses and in the temporal domain. In this work, we propose a U-SFQ Convolutional Neural Network (CNN) hardware accelerator capable of comparable peak performance with state-of-the-art superconducting binary (B-SFQ) approaches in 32x less area. CNNs can operate with 5 to 8 bits of resolution with no significant degradation in classification accuracy. The proposed CNN accelerator effortlessly supports this variable resolution and, for less than 7 bits, yields 5x-63x better performance than CMOS and 15x-173x better area efficiency than B-SFQ.
C1 [Gonzalez-Guerrero, Patricia; Huch, Kylie; Patra, Nirmalendu; Popovici, Thom; Michelogiannakis, George] Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
RP Gonzalez-Guerrero, P (corresponding author), Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
EM lg4er@lbl.gov; kyliehuch@lbl.gov; nbp@lbl.gov; dtpopovici@lbl.gov;
   mihelog@lbl.gov
CR Akahori A, 2003, IEEE T APPL SUPERCON, V13, P559, DOI 10.1109/TASC.2003.813946
   Ayala CL, 2021, IEEE J SOLID-ST CIRC, V56, P1152, DOI 10.1109/JSSC.2020.3041338
   Banner R, 2019, ADV NEUR IN, V32
   Bautista MG, 2021, MIDWEST SYMP CIRCUIT, P796, DOI 10.1109/MWSCAS47672.2021.9531899
   Cai RZ, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P567, DOI 10.1145/3307650.3322270
   Chen W, 1999, IEEE T APPL SUPERCON, V9, P3212, DOI 10.1109/77.783712
   Schuman CD, 2017, Arxiv, DOI arXiv:1705.06963
   Filippov TV, 2012, PHYSCS PROC, V36, P59, DOI 10.1016/j.phpro.2012.06.130
   Fujimaki A, 2014, IEICE T ELECTRON, VE97C, P157, DOI 10.1587/transele.E97.C.157
   Gonzalez-Guerrero P, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P963, DOI 10.1145/3503222.3507765
   Ishida K, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P58, DOI 10.1109/MICRO50266.2020.00018
   Jing Shen, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1200, DOI 10.1109/ICCT46805.2019.8947127
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kashima R, 2021, IEEE T APPL SUPERCON, V31, DOI 10.1109/TASC.2021.3061353
   Ke F, 2021, IEEE T APPL SUPERCON, V31, DOI 10.1109/TASC.2021.3059984
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krylov G., 2022, SINGLE FLUX QUANTUM
   Likharev KK, 1991, IEEE T APPL SUPERCON, V1, P3, DOI 10.1109/77.80745
   McDermott R, 2018, QUANTUM SCI TECHNOL, V3, DOI 10.1088/2058-9565/aaa3a0
   Michal V, 2011, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE - RADIOELEKTRONIKA 2011, P3
   Michelogiannakis G, 2021, INT PARALL DISTRIB P, P1046, DOI 10.1109/IPDPS49936.2021.00113
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   MUKHANOV OA, 1991, IEEE T MAGN, V27, P2435, DOI 10.1109/20.133710
   MUKHANOV OA, 1987, IEEE T MAGN, V23, P759, DOI 10.1109/TMAG.1987.1064951
   Mukhanov OA, 2011, IEEE T APPL SUPERCON, V21, P760, DOI 10.1109/TASC.2010.2096792
   Nagaoka I, 2019, ISSCC DIG TECH PAP I, V62, P460, DOI 10.1109/ISSCC.2019.8662351
   OpenRoad, 2021, US
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   RUSSER P, 1971, PR INST ELECTR ELECT, V59, P282, DOI 10.1109/PROC.1971.8133
   Samajdar Ananda, 2018, ARXIV
   Sim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062290
   Sze V, 2017, IEEE CUST INTEGR CIR
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tannu SS, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P67, DOI 10.1145/3310273.3321561
   Tzimpragos G, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P435, DOI 10.1145/3373376.3378517
   Zhou AJ, 2017, Arxiv, DOI arXiv:1702.03044
   Zinoviev Dmitry, 2021, RFSQ CELL LIB
   Zokaee Farzaneh, 2021, MICRO54 54 ANN IEEEA
NR 38
TC 0
Z9 0
U1 2
U2 2
PY 2023
BP 675
EP 682
DI 10.1109/ISQED57927.2023.10129299
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Heinz, C
   Hofmann, JA
   Sommer, L
   Koch, A
AF Heinz, Carsten
   Hofmann, Jaco A.
   Sommer, Lukas
   Koch, Andreas
GP IEEE Comp Soc
TI Improving Job Launch Rates in the TaPaSCo FPGA Middleware by
   Hardware/Software-Co-Design
SO PROCEEDINGS OF 2020 10TH IEEE/ACM INTERNATIONAL WORKSHOP ON RUNTIME AND
   OPERATING SYSTEMS FOR SUPERCOMPUTERS (ROSS 2020)
DT Proceedings Paper
CT 10th IEEE/ACM International Workshop on Runtime and Operating Systems
   for Supercomputers (ROSS)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE FPGA; Runtime; Task launching
AB In recent years, FPGAs have established themselves as an important acceleration platform next to GPUs in heterogeneous HPC systems, providing flexibility and high performance for tasks such as machine learning inference or DNA sequencing.
   While the design of the FPGA-based accelerator cores has become accessible to a broader range of users through customized RISC-V soft-cores and the maturity of High-Level Synthesis (HLS), the integration of and interaction with such accelerator cores in the overall heterogeneous system remains a challenging task.
   The open-source TaPaSCo framework eases this task by providing a concise software API and middleware for the interaction with FPGA-based accelerator system-on-chips automatically generated from user-provided accelerator cores.
   In this work, we present an extension of the TaPaSCo framework which improves the launch rates and latencies of FPGA-accelerated compute jobs, a crucial factor for the performance of the overall system, through hardware/software-co-design of an improved Rust-based software runtime, and a job dispatcher itself accelerated by hardware.
   Our evaluation shows that the new dispatchers can provide an improvement of up to 6x in job throughput with only minimal resource overhead.
C1 [Heinz, Carsten; Hofmann, Jaco A.; Sommer, Lukas; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
RP Heinz, C (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM heinz@esa.tu-darmstadt.de; hofmann@esa.tu-darmstadt.de;
   sommer@esa.tu-darmstadt.de; koch@esa.tu-darmstadt.de
CR Agne A, 2014, IEEE MICRO, V34, P60, DOI 10.1109/MM.2013.110
   Chatterjee S., 2013, LECT NOTES COMPUTER, V7146, P203, DOI [10.1007/978-3-642- 36036-7, DOI 10.1007/978-3-642-36036-7]
   Engelbrecht A., 2012, IEEE C EVOL COMPUTAT, P1, DOI [DOI 10.1109/CEC.2012.6256112, 10.1109/CEC.2012.6256112]
   Heinz C., 2019, IEEE P INT C RECONFI
   Intel Corporation, OP PROGR ACC ENG
   King M., 2015, P 2015 ACM SIGDA INT, P13, DOI DOI 10.1145/2684746.2689064
   Koch A., 2010, IEEE INT C FIELD PRO
   Koch A, 2019, INT S APPL REC COMP
   Korinth J, 2015, ANN IEEE SYM FIELD P, P195, DOI 10.1109/FCCM.2015.22
   Liu H, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201701616
   Reichenbach M, 2019, J SIGNAL PROCESS SYS, V91, P745, DOI 10.1007/s11265-018-1382-7
   Rust Team, RUST PROGRAMMING LAN
   Sommer L, 2017, IEEE INT CONF ASAP, P201, DOI 10.1109/ASAP.2017.7995280
   Tang Y, 2015, IEEE T COMPUT, V64, P1254, DOI 10.1109/TC.2014.2315637
   The Khronos Group, OPENCL SPECIFICATION
   Xilinx Inc, XIL RUNT LIB XRT
   Xilinx Inc, VIT UN SOFTW DEV PLA
NR 17
TC 3
Z9 3
U1 0
U2 1
PY 2020
BP 22
EP 30
DI 10.1109/ROSS51935.2020.00008
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lu, AN
   Peng, XC
   Luo, YD
   Huang, SS
   Yu, SM
AF Lu, Anni
   Peng, Xiaochen
   Luo, Yandong
   Huang, Shanshi
   Yu, Shimeng
GP IEEE
TI A Runtime Reconfigurable Design of Compute-in-Memory based Hardware
   Accelerator
SO PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2021)
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY FEB 01-05, 2021
CL ELECTR NETWORK
DE convolutional neural network; hardware accelerator; compute-in-memory;
   reconfigurable architecture
AB Compute-in-memory (CIM) is an attractive solution to address the "memory wall" challenges for the extensive computation in machine learning hardware accelerators. Prior CIM-based architectures, though can adapt to different neural network models during the design time, they are implemented to different custom chips. Therefore, a specific chip instance is restricted to a specific network during runtime. However, the development cycle of the hardware is normally far behind the emergence of new algorithms. In this paper, a runtime reconfigurable design methodology of CIM-based accelerator is proposed to support a class of convolutional neural networks running on one pre-fabricated chip instance. First, several design aspects are investigated: 1) reconfigurable weight mapping method; 2) input side of data transmission, mainly about the weight reloading; 3) output side of data processing, mainly about the reconfigurable accumulation. Then, system-level performance benchmark is performed for the inference of different models like VGG-8 on CIFAR-10 dataset and AlexNet, GoogLeNet, ResNet-18 and DenseNet-121 on ImageNet dataset to measure the tradeoffs between runtime reconfigurability, chip area, memory utilization, throughput and energy efficiency.
C1 [Lu, Anni; Peng, Xiaochen; Luo, Yandong; Huang, Shanshi; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chi P., 2016, ACM IEEE INT S COMP
   Damschen M, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942065
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee J., 2019, IEEE INT SOL STAT CI
   Lee J., 2018, IEEE INT SOL STAT CI
   Lu AN, 2020, IEEE T VLSI SYST, V28, P1945, DOI 10.1109/TVLSI.2020.3001526
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   NVIDIA, 2020, NVIDIA A100 TENS COR
   Olivito J, 2018, IET COMPUT DIGIT TEC, V12, P150, DOI 10.1049/iet-cdt.2016.0095
   Peng XC, 2019, INT EL DEVICES MEET
   Peng XC, 2020, IEEE T CIRCUITS-I, V67, P1333, DOI 10.1109/TCSI.2019.2958568
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2018.00474
   Shafiee A., 2016, ACM IEEE INT S COMP
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skinner D., 2013, JEDEC MOB FOR 2013
   Song L., 2017, IEEE INT S HIGHP COM
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang PN, 2020, IEEE T ELECTRON DEV, V67, P955, DOI 10.1109/TED.2020.2969401
   Xue C.-X., 2020, IEEE INT SOL STAT CI
NR 25
TC 2
Z9 2
U1 0
U2 5
PY 2021
BP 932
EP 937
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Lee, J
   Kim, G
   Park, J
   Bae, HM
AF Lee, Jaewon
   Kim, Gain
   Park, Jinho
   Bae, Hyeon-Min
GP IEEE
TI Link Bit-Error-Rate Requirement Analysis for Deep Neural Network
   Accelerators
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 22-28, 2021
CL Daegu, SOUTH KOREA
DE Convolutional neural networks (CNNs); wireline interface; approximate
   computing; FPGA
ID RECEIVER DATA-PATH; TRANSCEIVER; ADC
AB In convolutional neural network (CNN) accelerators, the dominant power consumption is caused by the access of external data memory. In addition, power and area occupied by I/O interfaces maintaining low bit-error-rate, e.g., 1e-15, grow as the data rate increases. Considering the inherent error resilience of the inference process in machine learning applications, the requirement of error-free communication in the data-path is controversial. In this paper, a custom CNN accelerator integrating a channel emulator is designed by using an FPGA to analyze the effect of the BER of an I/O transceiver on the image classification accuracy. In order to implement a channel emulator, a digital-domain look-up-table (LUT)-based 12-tap FIR filter is employed to create inter-symbol interference (ISI), and a PRBS31 generator is used as a noise source. The implementation was evaluated by running the ImageNet dataset on the FPGA-based custom accelerator (Virtex Ultrascale+) implementing VGG-16. The results show that the BER up to 1e-4 in the memory access has a negligible impact on the inference accuracy.
C1 [Lee, Jaewon; Kim, Gain; Park, Jinho; Bae, Hyeon-Min] Korea Adv Inst Sci & Technol KAIST, Sch Elect Engn, Daejeon, South Korea.
RP Lee, J (corresponding author), Korea Adv Inst Sci & Technol KAIST, Sch Elect Engn, Daejeon, South Korea.
EM ljw3136@kaist.ac.kr; gikim@kaist.ac.kr; hg766@kaist.ac.kr;
   hmbae@kaist.ac.kr
CR Aprile C, 2018, IEEE J SOLID-ST CIRC, V53, P861, DOI 10.1109/JSSC.2017.2783679
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Daly D. C., 2020, IEEE SOLID STATE CIR, V12, P8
   Frans Y, 2017, IEEE J SOLID-ST CIRC, V52, P1101, DOI 10.1109/JSSC.2016.2632300
   Gharibdoust K, 2016, IEEE J SOLID-ST CIRC, V51, P992, DOI 10.1109/JSSC.2015.2504410
   Gharibdoust K, 2015, IEEE J SOLID-ST CIRC, V50, P3133, DOI 10.1109/JSSC.2015.2483904
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Im J, 2017, IEEE J SOLID-ST CIRC, V52, P3486, DOI 10.1109/JSSC.2017.2749432
   Kim G, 2019, IEEE ASIAN SOLID STA, P239, DOI 10.1109/A-SSCC47793.2019.9056940
   Kim G, 2020, IEEE J SOLID-ST CIRC, V55, P38, DOI 10.1109/JSSC.2019.2938414
   Kim J, 2019, IEEE J SOLID-ST CIRC, V54, P29, DOI 10.1109/JSSC.2018.2874040
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krupnik Y, 2019, SYMP VLSI CIRCUITS, pC266, DOI [10.23919/vlsic.2019.8778136, 10.23919/VLSIC.2019.8778136]
   Lee J., 2021, THESIS KAIST DAEJEON
   Di Mauro A, 2020, IEEE T CIRCUITS-I, V67, P3905, DOI 10.1109/TCSI.2020.3012576
   Nguyen DT, 2020, IEEE T CIRCUITS-I, V67, P1588, DOI 10.1109/TCSI.2019.2962516
   Poulton JW, 2019, IEEE J SOLID-ST CIRC, V54, P43, DOI 10.1109/JSSC.2018.2875092
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sackinger Eduard, 2017, ANAL DESIGN TRANSIMP, P397
   Shokrollahi A, 2016, ISSCC DIG TECH PAP I, V59, P182, DOI 10.1109/ISSCC.2016.7417967
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tajalli A., 2017, IEEE J SOLID-ST CIRC, V55, P1108
   Won H, 2015, IEEE J SOLID-ST CIRC, V50, P399, DOI 10.1109/JSSC.2014.2369494
   Zimmer B, 2020, IEEE J SOLID-ST CIRC, V55, P920, DOI 10.1109/JSSC.2019.2960488
NR 25
TC 0
Z9 0
U1 0
U2 1
PY 2021
DI 10.1109/ISCAS51556.2021.9401112
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Marchisio, A
   Dura, D
   Capra, M
   Martina, M
   Masera, G
   Shafique, M
AF Marchisio, Alberto
   Dura, Davide
   Capra, Maurizio
   Martina, Maurizio
   Masera, Guido
   Shafique, Muhammad
GP IEEE
TI SwiftTron: An Efficient Hardware Accelerator for Quantized Transformers
SO 2023 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN)
CY JUN 18-23, 2023
CL Broadbeach, AUSTRALIA
DE Hardware Architecture; Transformers; Machine Learning; ASIC;
   Quantization; Attention; Softmax; Layer Normalization; GELU
AB Transformers' compute-intensive operations pose enormous challenges for their deployment in resource-constrained EdgeAI / tinyML devices. As an established neural network compression technique, quantization reduces the hardware computational and memory resources. In particular, fixed-point quantization is desirable to ease the computations using lightweight blocks, like adders and multipliers, of the underlying hardware. However, deploying fully-quantized Transformers on existing general-purpose hardware, generic AI accelerators, or specialized architectures for Transformers with floating-point units might be infeasible and/or inefficient. Towards this, we propose SwiftTron, an efficient specialized hardware accelerator designed for Quantized Transformers. SwiftTron supports the execution of different types of Transformers' operations (like Attention, Softmax, GELU, and Layer Normalization) and accounts for diverse scaling factors to perform correct computations. We synthesize the complete SwiftTron architecture in a 65 nm CMOS technology with the ASIC design flow. Our Accelerator executes the RoBERTa-base model in 1.83 ns, while consuming 33.64 mW power, and occupying an area of 273 mm(2). To ease the reproducibility, the RTL of our SwiftTron architecture is released at https: //github.com/albertomarchisio/SwiftTron.
C1 [Marchisio, Alberto] Vienna Univ Technol, Vienna, Austria.
   [Dura, Davide; Capra, Maurizio; Martina, Maurizio; Masera, Guido] Politecn Torino, Turin, Italy.
   [Shafique, Muhammad] New York Univ, Abu Dhabi, U Arab Emirates.
RP Marchisio, A (corresponding author), Vienna Univ Technol, Vienna, Austria.
EM alberto.marchisio@tuwien.ac.at; s276493@studenti.polito.it;
   maurizio.capra@polito.it; maurizio.martina@polito.it;
   guido.masera@polito.it; muhammad.shafique@nyu.edu
CR [Anonymous], NVID H100 TENS COR G
   Bhandare A., 2019, CORR
   Capra M, 2020, IEEE ACCESS, V8, P225134, DOI 10.1109/ACCESS.2020.3039858
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Craddock S, 2019, METROP MOD LIFE, P33
   Dehghani M, 2019, 7 INT C LEARN REPR I
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A., 2021, PROC 9 INT C LEARN R
   Fedus W., 2021, CORR
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   Han G, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4550, DOI 10.1109/ICASSP39728.2021.9413567
   Hendrycks D., 2016, CORR
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li B., 2020, P ACMIEEE INT S LOW, P175
   Li Z., 2022, CORR
   Lin Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3759
   Liu Y, 2019, ARXIV
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZJ, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P513, DOI 10.23919/DATE51398.2021.9474043
   Lu SY, 2020, IEEE INT SOC CONF, P84, DOI 10.1109/SOCC49529.2020.9524802
   MALLET J, 2022, 40 IEEE VLSI TEST S, P1, DOI DOI 10.1109/ISCMI56532.2022.10068449
   Marchisio A, 2019, IEEE COMP SOC ANN, P555, DOI 10.1109/ISVLSI.2019.00105
   Marcus G, 2004, ICCDCS 2004: Fifth International Caracas Conference on Devices, Circuits and Systems, P319
   Nair V., 2010, ICML, P807
   Pardo I, 2019, PALG STUD URBAN ANTH, P1, DOI 10.1007/978-3-319-96238-2_1
   Park S, 2020, ADV MATER, V32, DOI 10.1002/adma.202003020
   Richard Crandall C. P., 2006, PRIME NUMBERS COMPUT, V182
   Shafique M, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643539
   Shafique M, 2018, DES AUT TEST EUROPE, P827, DOI 10.23919/DATE.2018.8342120
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A., 2017, P 31 INT C NEURAL IN
   Wang A, 2019, MICRO NANO TECHNOL, P1, DOI 10.1016/C2017-0-01290-9
   Wang H., 2020, THESIS
   Wang S., 2020, CORR
   WENG R, 2020, P 58 ANN M ASS COMP, P767, DOI DOI 10.18653/V1/2020.ACL-MAIN.686
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Yang X, 2022, FRONT MECH ENG-PRC, V17, DOI 10.1007/s11465-022-0677-3
   Yao Z., 2021, P 38 INT C MACH LEAR, P11875
NR 38
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/IJCNN54540.2023.10191521
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Agostini, NB
   Curzelt, S
   Limaye, A
   Amatya, V
   Minutoli, M
   Castellana, VG
   Manzano, J
   Tumeo, A
   Ferrandi, F
AF Agostini, Nicolas Bohm
   Curzelt, Serena
   Limaye, Ankur
   Amatya, Vinay
   Minutoli, Marco
   Castellana, Vito Giovanni
   Manzano, Joseph
   Tumeo, Antonino
   Ferrandi, Fabrizio
GP ACM
TI Invited: The SODA Approach: Leveraging High-Level Synthesis for
   Hardware/Software Co-design and Hardware Specialization
SO PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022
DT Proceedings Paper
CT 59th ACM/IEEE Design Automation Conference (DAC) - From Chips to Systems
   - Learn Today, Create Tomorrow
CY JUL 10-14, 2022
CL San Francisco, CA
DE High-level synthesis; hardware/software co-design
AB Novel "converged" applications combine phases of scientific simulation with data analysis and machine learning. Each computational phase can benefit from specialized accelerators. However, algorithms evolve so quickly that mapping them on existing accelerators is suboptimal or even impossible. This paper presents the SODA (Software Defined Accelerators) framework, a modular, multi-level, open-source, no-human-in-the-loop, hardware synthesizer that enables end-to-end generation of specialized accelerators. SODA is composed of SODA-Opt, a high-level frontend developed in MLIR that interfaces with domain-specific programming frameworks and allows performing system level design, and Bambu, a state-of-the-art high-level synthesis engine that can target different device technologies. The framework implements design space exploration as compiler optimization passes. We show how the modular, yet tight, integration of the high-level optimizer and lower-level HLS tools enables the generation of accelerators optimized for the computational patterns of converged applications. We then discuss some of the research opportunities that such a framework allows, including system-level design, profile driven optimization, and supporting new optimization metrics.
C1 [Agostini, Nicolas Bohm; Curzelt, Serena; Limaye, Ankur; Amatya, Vinay; Minutoli, Marco; Castellana, Vito Giovanni; Manzano, Joseph; Tumeo, Antonino] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
   [Curzelt, Serena; Ferrandi, Fabrizio] Politecn Milan, Milan, Italy.
   [Agostini, Nicolas Bohm] Northeastern Univ, Boston, MA USA.
RP Agostini, NB (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99352 USA.
CR Castellana VG, 2021, INT PARALL DISTRIB P, P192, DOI 10.1109/IPDPS49936.2021.00028
   Curzel S, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643474
   Ferrandi F, 2021, DES AUT CON, P1327, DOI 10.1109/DAC18074.2021.9586110
   Govindarajan S., 2020, SYFER MLIR INTEGRATI
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Mantovani P, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415753
   Minutoli Marco, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293958
   Minutoli M., 2021, IEEE T COMPUT, V01, P1
   Tumeo A, 2017, 2017 EIGHTH INTERNATIONAL GREEN AND SUSTAINABLE COMPUTING CONFERENCE (IGSC)
NR 9
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1359
EP 1362
DI 10.1145/3489517.3530628
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Samajdar, A
   Joseph, JM
   Krishna, T
AF Samajdar, Ananda
   Joseph, Jan Moritz
   Krishna, Tushar
BE IEEE
TI AIRCHITECT: Automating Hardware Architecture and Mapping Optimization
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE machine learning; design space exploration; architecture design; mapping
   optimization
ID DESIGN; PERFORMANCE
AB Design space exploration and optimization is an essential but iterative step in custom accelerator design involving costly search based method to extract maximum performance and energy efficiency. State-of-the-art methods employ data centric approaches to reduce the cost of each iteration but still rely on search algorithms to obtain the optima. This work proposes a learned, constant time optimizer that uses a custom recommendation network called AIRCHITECT, which is capable of learning the architecture design and mapping space with a 94.3% test accuracy, and predicting optimal configurations, which achieve on an average (GeoMean) 99.9% of the best possible performance on a test dataset with 105 GEMM (GEneral Matrix-matrix Multiplication) workloads.
C1 [Samajdar, Ananda] Georgia Tech, IBM Res, Atlanta, GA 30332 USA.
   [Joseph, Jan Moritz] Rhein Westfal TH Aachen, Aachen, Germany.
   [Krishna, Tushar] Georgia Tech, Atlanta, GA USA.
RP Samajdar, A (corresponding author), Georgia Tech, IBM Res, Atlanta, GA 30332 USA.
EM anandsamajdar@gatech.edu
CR Azizi O, 2010, CONF PROC INT SYMP C, P26, DOI 10.1145/1816038.1815967
   Chen TQ, 2018, ADV NEUR IN, V31
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dubach C, 2007, INT SYMP MICROARCH, P262, DOI 10.1109/MICRO.2007.12
   Ipek E, 2006, ACM SIGPLAN NOTICES, V41, P195, DOI 10.1145/1168918.1168882
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Khan S., 2007, 16 INT C PARALLEL AR, P327
   Kwon J., 2019, DAC
   Lee BC, 2006, ACM SIGPLAN NOTICES, V41, P185, DOI [10.1145/1168919.1168881, 10.1145/1168917.1168881]
   Mei L., 2021, IEEE COMPUTERS
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samajdar Ananda, 2018, ARXIV
   Yazdanbakhsh A, 2021, Arxiv, DOI arXiv:2102.01723
NR 15
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT C
AU Tajbakhsh, H
   Parizotto, R
   Neves, M
   Schaeffer, A
   Haque, I
AF Tajbakhsh, Hesam
   Parizotto, Ricardo
   Neves, Miguel
   Schaeffer-Filho, Alberto
   Haque, Israat
GP IEEE
TI Accelerator-Aware In-Network Load Balancing for Improved Application
   Performance
SO 2022 IFIP NETWORKING CONFERENCE (IFIP NETWORKING)
DT Proceedings Paper
CT IFIP Networking Conference (IFIP Networking)
CY JUN 13-16, 2022
CL Catania, ITALY
AB The end of Moore's law has sparked a surge on programmable accelerators (e.g., SmartNICs, TPUs) for continued scaling of application performance. However, despite the great success in offloading tasks from the CPU, we still lack proper mechanisms for balancing load among the multiple computing units present on current systems. On the one hand, traditional load balancers (either software or hardware-based) have no visibility of the different accelerators in a server and can only dispatch requests at a per-server granularity. On the other hand, emerging offloading engines can assign tasks at a finer-granularity (e.g., per-accelerator), but are hosted by the accelerator itself and thus waste precious resources for balancing load rather than processing it. This paper presents P4Mite, an accelerator-aware in-network load balancing system. P4Mite is based on two key insights: i) using programmable switches for load balancing traffic among different accelerators (and also the CPU) located in the same server; and ii) collecting statistics from each accelerator on demand for increased load visibility. We implement a P4Mite prototype on top of Intel Tofino and a Mellanox SmartNIC and evaluate it using real-world applications, including machine learning inference (VGG-16) and DNS. Our results show that P4Mite reduces flow latency by up to 50% and also makes the system handle 10-20% more load compared to standard server-level load balancing approaches. Moreover, it can process at least an order of magnitude more requests than a SmartNIC-based load balancer, with negligible latency and memory footprint.
C1 [Tajbakhsh, Hesam; Neves, Miguel; Haque, Israat] Dalhousie Univ, Halifax, NS, Canada.
   [Parizotto, Ricardo; Schaeffer-Filho, Alberto] Univ Fed Rio Grande do Sul, Porto Alegre, RS, Brazil.
RP Tajbakhsh, H (corresponding author), Dalhousie Univ, Halifax, NS, Canada.
CR [Anonymous], 2021, LOOM SWITCH BASED CL
   arrow.com, PCIE SWITCHES ARROW
   Barbette Tom, 2020, CoNEXT '20: Proceedings of the 16th International Conference on emerging Networking EXperiments and Technologies, P548, DOI 10.1145/3386367.3431672
   Barbette T, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P667
   Barroso Luiz Andre, 2018, SYNTHESIS LECT COMPU, V13, pi
   Bosshart P, 2014, ACM SIGCOMM COMP COM, V44, P87, DOI 10.1145/2656877.2656890
   Braodcom, PCI EXPR SWITCH
   Broadcom, 2021, STINGR PS225
   Choi S, 2020, INT CON DISTR COMP S, P67, DOI 10.1109/ICDCS47774.2020.00029
   Cohen S., 2003, SIGMOD 03, P241, DOI DOI 10.1145/872757.872787
   Cui T., 2021, OFFLOADING LOAD BALA, P56
   Do J, 2021, VLDB J, V30, P403, DOI 10.1007/s00778-020-00648-z
   docs.microsoft.com, TCP IP OFFLOAD OVERV
   Eisenbud DE, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P523
   Fan B, 2014, PROCEEDINGS OF THE 2014 CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'14), P75, DOI 10.1145/2674005.2674994
   github.com, 2022, P4MITE
   Google AutoML, AUTOML TRAIN HIGH QU
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Hopps Christian, 2000, 2992 RFC
   Intel, 2021, EXPL POW INT PROGR E
   Intel, INTELAO VIS COMP ACC
   Jongyul Kim, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P756, DOI 10.1145/3477132.3483565
   Liu M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P363
   Liu M, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P318, DOI 10.1145/3341302.3342079
   Lo YJ, 2015, LECT NOTES COMPUT SC, V8966, P129, DOI 10.1007/978-3-319-17248-4_7
   Mellanox, 2021, BLUEFIELD SMARTNIC E
   Mellanox, CONNECTX 5 EN CARD
   Miao R, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P15, DOI 10.1145/3098822.3098824
   Michel O, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447868
   Microsoft brainwave, BRAINW DEEP LEARN PL
   Mitzenmacher M, 2001, IEEE T PARALL DISTR, V12, P1094, DOI 10.1109/71.963420
   Neves M., 2021, NETWORK ACCELERATED
   Nider J., 2021, P WORKSHOP HOT TOPIC, P1
   Olteanu V, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P125
   Rajagopalan S., 2021, Computer Networks, Big Data and IoT. Proceedings of ICCBI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 66), P663, DOI 10.1007/978-981-16-0965-7_51
   Rizzi C., 2021, CHARON LOAD AWARE LO
   Schuh Henry N., 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P740, DOI 10.1145/3477132.3483555
   Siracusano G, 2018, Arxiv, DOI arXiv:1801.05731
   Siracusano G, 2020, Arxiv, DOI arXiv:2009.02353
   Johansson HT, 2020, Arxiv, DOI arXiv:2003.12527
   Tork M, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P117, DOI 10.1145/3373376.3378528
   Wang SY, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P651
   Zeng C., 2022, 19 USENIX S NETWORKE
   Zhao HY, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P515
   Zhou J., 2014, P 9 EUROPEAN C COMPU
NR 45
TC 1
Z9 1
U1 0
U2 0
PY 2022
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Telecommunications
DA 2023-11-11
ER

PT C
AU Pal, D
   Lai, YH
   Xiang, SJ
   Zhang, NS
   Chen, HZ
   Casas, J
   Cocchini, P
   Yang, ZK
   Yang, J
   Pouchet, LN
   Zhang, ZR
AF Pal, Debjit
   Lai, Yi-Hsiang
   Xiang, Shaojie
   Zhang, Niansong
   Chen, Hongzheng
   Casas, Jeremy
   Cocchini, Pasquale
   Yang, Zhenkun
   Yang, Jin
   Pouchet, Louis-Noel
   Zhang, Zhiru
GP ACM
TI Invited: Accelerator Design with Decoupled Hardware Customizations:
   Benefits and Challenges
SO PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022
DT Proceedings Paper
CT 59th ACM/IEEE Design Automation Conference (DAC) - From Chips to Systems
   - Learn Today, Create Tomorrow
CY JUL 10-14, 2022
CL San Francisco, CA
ID VERIFICATION
AB The past decade has witnessed increasing adoption of high-level synthesis (HLS) to implement specialized hardware accelerators targeting either FPGAs or ASICs. However, current HLS programming models entangle algorithm specifications with hardware customization techniques, which lowers both the productivity and portability of the accelerator design. To tackle this problem, recent efforts such as HeteroCL propose to decouple algorithm definition from essential hardware customization techniques in compute, data type, and memory, increasing productivity, portability, and performance.
   While the decoupling of the algorithm and customizations provides benefits to the compilation/synthesis process, they also create new hurdles for the programmers to productively debug and validate the correctness of the optimized design. In this work, using HeteroCL and realistic machine learning applications as case studies, we first explain the key advantages of the decoupled programming model brought to a programmer to rapidly develop high-performance accelerators. Using the same case studies, we will further show how seemingly benign usage of the customization primitives can lead to new challenges to verification. We will then outline the research opportunities and discuss some of our recent efforts as the first step to enable a robust and viable verification solution in the future.
C1 [Pal, Debjit; Xiang, Shaojie; Zhang, Niansong; Chen, Hongzheng; Zhang, Zhiru] Cornell Univ, Ithaca, NY 14853 USA.
   [Casas, Jeremy; Cocchini, Pasquale; Yang, Zhenkun; Yang, Jin] Intel Corp, Strateg CAD Labs, Santa Clara, CA 95051 USA.
   [Pouchet, Louis-Noel] Colorado State Univ, Ft Collins, CO 80523 USA.
   [Lai, Yi-Hsiang] Amazon Web Serv Inc, Seattle, WA USA.
RP Pal, D; Zhang, ZR (corresponding author), Cornell Univ, Ithaca, NY 14853 USA.
EM debjlit.pal@cornell.edu; zhiruz@cornell.edu
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Bao WL, 2016, ACM SIGPLAN NOTICES, V51, P539, DOI 10.1145/2914770.2837656
   Benabderrahmane MW, 2010, LECT NOTES COMPUT SC, V6011, P283, DOI 10.1007/978-3-642-11970-5_16
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TQ, 2018, ADV NEUR IN, V31
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Feautrier P, 1991, INT J PARALLEL PROGR
   Lai YH, 2021, ACM T RECONFIG TECHN, V14, DOI 10.1145/3469660
   Lai YH, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415644
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Lattner C., 2020, ARXIV
   Leroy X, 2009, COMMUN ACM, V52, P107, DOI 10.1145/1538788.1538814
   Moreau T., 2018, ARXIV
   Pouchet L-N, 2013, INT S FIELD PROGR GA
   Pouchet LN, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P549, DOI 10.1145/1926385.1926449
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Sohrabizadeh A., 2022, DESIGN AUTOMATION C
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Sun Q., 2021, DESIGN AUTOMATION TE
   Xiang S., 2022, INT S FIELD PROGRAMM
   Zhan K., ULTRANET FPGA BASED
   Zhao JZ, 2012, POPL 12: PROCEEDINGS OF THE 39TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P427
   Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863
   Zheng SZ, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P859, DOI 10.1145/3373376.3378508
   Zhou Y, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P269, DOI 10.1145/3174243.3174255
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1351
EP 1354
DI 10.1145/3489517.3530681
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nowatzki, T
   Gangadhar, V
   Ardalani, N
   Sankaralingam, K
AF Nowatzki, Tony
   Gangadhar, Vinay
   Ardalani, Newsha
   Sankaralingam, Karthikeyan
GP Assoc Comp Machinery
TI Stream-Dataflow Acceleration
SO 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017)
DT Proceedings Paper
CT 44th Annual International Symposium on Computer Architecture (ISCA)
CY JUN 24-28, 2017
CL Toronto, CANADA
DE Streaming; Dataflow; Architecture; Accelerator; Reconfigurable; CGRA;
   Programmable; Domain-Specific
AB Demand for low-power data processing hardware continues to rise inexorably. Existing programmable and "general purpose" solutions (eg. SIMD, GPGPUs) are insufficient, as evidenced by the order-of-magnitude improvements and industry adoption of application and domain-specific accelerators in important areas like machine learning, computer vision and big data. The stark tradeoffs between efficiency and generality at these two extremes poses a difficult question: how could domain-specific hardware efficiency be achieved without domain-specific hardware solutions?
   In this work, we rely on the insight that "acceleratable" algorithms have broad common properties: high computational intensity with long phases, simple control patterns and dependences, and simple streaming memory access and reuse patterns. We define a general architecture (a hardware-software interface) which can more efficiently expresses programs with these properties called stream-dataflow. The dataflow component of this architecture enables high concurrency, and the stream component enables communication and coordination at very-low power and area overhead. This paper explores the hardware and software implications, describes its detailed microarchitecture, and evaluates an implementation. Compared to a state-of-the-art domain specific accelerator (DianNao), and fixed-function accelerators for MachSuite, Softbrain can match their performance with only 2x power overhead on average.
C1 [Nowatzki, Tony] Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
   [Nowatzki, Tony; Gangadhar, Vinay; Ardalani, Newsha; Sankaralingam, Karthikeyan] Univ Wisconsin, Madison, WI 53706 USA.
RP Nowatzki, T (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.; Nowatzki, T (corresponding author), Univ Wisconsin, Madison, WI 53706 USA.
EM tjn@cs.ucla.edu; vinay@cs.wisc.edu; newsha@cs.wisc.edu; karu@cs.wisc.edu
CR [Anonymous], 2009, HP LAB
   [Anonymous], 2013, P 40 ANN INT S COMP, DOI DOI 10.1145/2508148.2485934
   Bachrach J, 2012, DES AUT CON, P1212
   Burger D, 2004, COMPUTER, V37, P44, DOI 10.1109/MC.2004.65
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Ciricescu S, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P141
   Clark N, 2008, CONF PROC INT SYMP C, P389, DOI 10.1109/ISCA.2008.33
   Govindaraju V, 2013, INT CONFER PARA, P341, DOI 10.1109/PACT.2013.6618830
   Govindaraju V, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.51
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Ho CH, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P118, DOI 10.1145/2749469.2750390
   Ionica MH, 2015, IEEE MICRO, V35, P6, DOI 10.1109/MM.2015.4
   Jouppi N. P., 2017, ISCA 17
   Khailany B, 2001, IEEE MICRO, V21, P35, DOI 10.1109/40.918001
   Krashinsky R, 2004, CONF PROC INT SYMP C, P52
   Lee Y, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P129
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lukefahr A, 2012, INT SYMP MICROARCH, P317, DOI 10.1109/MICRO.2012.37
   Nowatzki T, 2016, INT S HIGH PERF COMP, P27, DOI 10.1109/HPCA.2016.7446051
   Nowatzki T, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P298, DOI 10.1145/2749469.2750380
   Nowatzki T, 2013, ACM SIGPLAN NOTICES, V48, P495, DOI 10.1145/2499370.2462163
   Parashar A., 2013, P 40 ANN INT S COMP, P142
   Park YJ, 2012, INT SYMP MICROARCH, P84, DOI 10.1109/MICRO.2012.17
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Sankaralingam K, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P303
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Singh H, 2000, IEEE T COMPUT, V49, P465, DOI 10.1109/12.859540
   Smith J. E., 1982, 9th Annual Symposium on Computer Architecture, P112
   Srinath S, 2014, INT SYMP MICROARCH, P583, DOI 10.1109/MICRO.2014.31
   Swanson S, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P291
   Taylor MB, 2002, IEEE MICRO, V22, P25, DOI 10.1109/MM.2002.997877
   Voitsechov D, 2014, CONF PROC INT SYMP C, P205, DOI 10.1109/ISCA.2014.6853234
   Watkins MA, 2016, INT S HIGH PERF COMP, P138, DOI 10.1109/HPCA.2016.7446060
   Weisz Gabriel, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7294017
   Wu LS, 2014, ACM SIGPLAN NOTICES, V49, P255, DOI 10.1145/2541940.2541961
NR 37
TC 85
Z9 85
U1 1
U2 2
PY 2017
BP 416
EP 429
DI 10.1145/3079856.3080255
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
DA 2023-11-11
ER

PT J
AU Samavatian, MH
   Bacha, A
   Zhou, L
   Teodorescu, R
AF Samavatian, Mohammad Hossein
   Bacha, Anys
   Zhou, Li
   Teodorescu, Radu
TI RNNFast: An Accelerator for Recurrent Neural Networks Using Domain-Wall
   Memory
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Recurrent neural networks; domain-wall memory; LSTM; accelerator
AB Recurrent Neural Networks (RNNs) are an important class of neural networks designed to retain and incorporate context into current decisions. RNNs are particularly well suited for machine learning problems in which context is important, such as speech recognition and language translation.
   This work presents RNNFast, a hardware accelerator for RNNs that leverages an emerging class of nonvolatile memory called domain-wall memory (DWM). We show that DWM is very well suited for RNN acceleration due to its very high density and low read/write energy. At the same time, the sequential nature of input/weight processing of RNNs mitigates one of the downsides of DWM, which is the linear (rather than constant) data access time.
   RNNFast is very efficient and highly scalable, with flexible mapping of logical neurons to RNN hardware blocks. The basic hardware primitive, the RNN processing element (PE), includes custom DWM-based multiplication, sigmoid and tanh units for high density and low energy. The accelerator is designed to minimize data movement by closely interleaving DWM storage and computation. We compare our design with a state-of-the-art GPGPU and find 21.8x higher performance with 70x lower energy.
C1 [Samavatian, Mohammad Hossein; Zhou, Li; Teodorescu, Radu] Ohio State Univ, 2015 Neil Ave, Columbus, OH 43210 USA.
   [Bacha, Anys] Univ Michigan, 4901 Evergreen Rd, Dearborn, MI 48128 USA.
RP Samavatian, MH (corresponding author), Ohio State Univ, 2015 Neil Ave, Columbus, OH 43210 USA.
EM samavatian.1@osu.edu; bacha@umich.edu; zhou.785@osu.edu;
   teodorescu.1@osu.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Amodei D, 2016, PR MACH LEARN RES, V48
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit Aayush, 2017, ARXIV170206064
   Annunziata AJ, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   [Anonymous], 2015, BEHAV NEUROL
   [Anonymous], 1997, NEURAL COMPUT
   Azari Elham, 2019, P 2019 ACM SIGDA INT, P305, DOI [10.1145/3289602.3293989, DOI 10.1145/3289602.3293989]
   CHANG KW, 2019, IEEE INT SYMP CIRC S, pNI702, DOI [DOI 10.1109/CIG.2019.8848091, DOI 10.1109/iscas.2019.8702471]
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cho K., 2014, P C EMP METH NAT LAN, P1724
   Chung J, 2016, I SYMPOS LOW POWER E, P332, DOI 10.1145/2934583.2934602
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Ferreira JC, 2016, PROC INT CONF RECON
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Ghosh Swaroop, 2013, 2013 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH), P30, DOI 10.1109/NanoArch.2013.6623035
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hannun A., 2014, DEEP SPEECH SCALING
   Huang KJ, 2016, IEEE T VLSI SYST, V24, P1885, DOI 10.1109/TVLSI.2015.2474706
   Iyengar A, 2014, DES AUT CON, DOI 10.1145/2593069.2593161
   Jin T, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P835, DOI 10.1145/3297858.3304038
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Li C, 2018, J BIOMED NANOTECHNOL, V14, P1, DOI 10.1166/jbn.2018.2463
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Long Y, 2016, IEEE IJCNN, P939, DOI 10.1109/IJCNN.2016.7727299
   Mealey T, 2018, PROC NAECON IEEE NAT, P382, DOI 10.1109/NAECON.2018.8556674
   Motaman S, 2016, IEEE T VLSI SYST, V24, P944, DOI 10.1109/TVLSI.2015.2437283
   Motaman S, 2014, I SYMPOS LOW POWER E, P195, DOI 10.1145/2627369.2627643
   Motaman S, 2015, IEEE T NANOTECHNOL, V14, P282, DOI 10.1109/TNANO.2015.2391185
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Parkin SSP, 2008, SCIENCE, V320, P190, DOI 10.1126/science.1145799
   Ponte JM., 2017, ACM SIGIR FORUM, V51, P202, DOI [DOI 10.1145/290941.291008, 10.1145/3130348.3130368]
   Ranjan A, 2015, DES AUT TEST EUROPE, P181
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Smullen CW, 2011, ICCAD-IEEE ACM INT, P318, DOI 10.1109/ICCAD.2011.6105348
   Sun Z, 2018, INT CONF AGRO-GEOINF, P337
   Sun ZY, 2016, IEEE T COMPUT, V65, P1041, DOI 10.1109/TC.2014.2360545
   Sun ZY, 2013, DES AUT CON
   Tommiska MT, 2003, IEE P-COMPUT DIG T, V150, P403, DOI 10.1049/ip-cdt:20030965
   Toral A, 2018, MACH TRANS TECH APPL, V1, P263, DOI 10.1007/978-3-319-91241-7_12
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Venkatesan R, 2016, IEEE T COMPUT, V65, P1010, DOI 10.1109/TC.2015.2506581
   Venkatesan R, 2013, DES AUT TEST EUROPE, P1825
   Vinyals O., 2016, IEEE TPMAI, V39, P652, DOI DOI 10.1109/TPAMI.2016.2587640
   Wang MQ, 2019, IEEE J EM SEL TOP C, V9, P280, DOI 10.1109/JETCAS.2019.2911739
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wang XW, 2019, INT S HIGH PERF COMP, P81, DOI 10.1109/HPCA.2019.00029
   Wang Y, 2014, PROCEEDINGS OF THE 2014 20TH INTERNATIONAL CONFERENCE ON AUTOMATION AND COMPUTING (ICAC'14), P3, DOI 10.1109/IConAC.2014.6935451
   Wang ZS, 2017, IEEE T VLSI SYST, V25, P2763, DOI 10.1109/TVLSI.2017.2717950
   Xu C, 2011, ICCAD-IEEE ACM INT, P463, DOI 10.1109/ICCAD.2011.6105369
   Yang X, 2013, APPL SOFT COMPUT, V13, P1, DOI 10.1016/j.asoc.2012.07.002
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
   Zhang C, 2015, ASIA S PACIF DES AUT, P100, DOI 10.1109/ASPDAC.2015.7058988
   Zhang C, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P694, DOI 10.1145/2749469.2750388
   Zhang YW, 2017, IEEE INT C CL COMP, P629, DOI 10.1109/CLUSTER.2017.45
   Zhang Y, 2016, IEEE T CIRCUITS-I, V63, P629, DOI 10.1109/TCSI.2016.2529240
NR 72
TC 3
Z9 3
U1 1
U2 5
PD OCT
PY 2020
VL 16
IS 4
SI SI
AR 38
DI 10.1145/3399670
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Jiang, CH
   Jayarajan, A
   Lu, H
   Pekhimenko, G
AF Jiang, Chenhao
   Jayarajan, Anand
   Lu, Hao
   Pekhimenko, Gennady
GP USENIX Association
TI Arbitor: A Numerically Accurate Hardware Emulation Tool for DNN
   Accelerators
SO PROCEEDINGS OF THE 2023 USENIX ANNUAL TECHNICAL CONFERENCE
DT Proceedings Paper
CT USENIX Annual Technical Conference (USENIX ATC)
CY JUL 10-12, 2023
CL Boston, MA
AB Recently there has been considerable attention on designing and developing hardware accelerators for deep neural network (DNN) training workloads. However, designing DNN accelerators is often challenging as many commonly used hardware optimization strategies can potentially impact the final accuracy of the models. In this work, we propose a hardware emulation tool called Arbitor for empirically evaluating DNN accelerator designs and accurately estimating their effects on DNN accuracy. Arbitor takes advantage of modern machine learning compilers to enable fast prototyping and numerically accurate emulation of common DNN optimizations like low-precision arithmetic, approximate computing, and sparsity-aware processing on general-purpose GPUs. Subsequently, we use Arbitor to conduct an extensive sensitivity study to understand the effects of these optimizations on popular models such as ResNet, Transformers, Recurrent-CNN, and GNNs. Based on our analysis, we observe that DNN models can tolerate arithmetic operations with much lower precision than the commonly used numerical formats support. We also demonstrate that piece-wise approximation is effective in handling complex non-linear operations in DNN models without affecting their accuracy. Finally, enforcing a high degree of structured sparsity in the parameters and gradients can significantly affect the accuracy of the models.
C1 [Jiang, Chenhao; Jayarajan, Anand; Pekhimenko, Gennady] Univ Toronto, Vector Inst, Toronto, ON, Canada.
   [Lu, Hao] Univ Toronto, Toronto, ON, Canada.
RP Jiang, CH (corresponding author), Univ Toronto, Vector Inst, Toronto, ON, Canada.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Akram A, 2019, IEEE ACCESS, V7, P78120, DOI 10.1109/ACCESS.2019.2917698
   Amazon Web Services, AWS TRAIN
   Amodei D, 2015, COMPUTER SCI
   [Anonymous], 2008, 7542008 IEEE, DOI 10.1109/IEEESTD.2008.4610935
   Armeniakos G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527156
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Blalock D, 2020, ARXIV200303033, DOI DOI 10.1109/CVPR.2019.01152
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   Burger D, 2010, IEEE MICRO, V30, P8, DOI 10.1109/MM.2010.56
   Callaway Jason, FRA TXT DETAILS
   Cao Jian, 2019, 2019 INT JOINT C NEU, P1
   Carmichael Z, 2019, DES AUT TEST EUROPE, P1421, DOI [10.23919/DATE.2019.8715262, 10.23919/date.2019.8715262]
   Cerebras, CEREBRAS WAFER SCALE
   Chen Mark, 2021, EVALUATING LARGE LAN
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Chowdhery A., 2022, PALM SCALING LANGUAG
   Courbariaux Matthieu., 2014, TRAINING DEEP NEURAL
   Darvish Rouhani B., 2020, ADV NEURAL INFORM PR, V33, P10271
   Drumond Mario, 2018, P 32 INT C NEURAL IN, P451
   Gale T., 2019, STATE SPARSITY DEEP
   Google, 2018, TENSORFLOW XLA
   GraphCore, INTRO COLOSSUS MK2 G
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Heinrich Meyr., 2002, EURASIP J ADV SIG PR, V2002
   Hendrycks D., 2016, GAUSSIAN ERROR LINEA
   Intel, GAUDI2 HIGH PERFORMA
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kalamkar D, 2019, Arxiv, DOI [arXiv:1905.12322, DOI 10.48550/ARXIV.1905.12322]
   Kaplan David., 2015, HARDWARE MUST JUST W
   Kaul Bharat, 2019, K TANH EFFICIENT TAN
   Keras, KERAS CODE EXAMPLES
   Khairy M, 2020, ANN I S COM, P473, DOI 10.1109/ISCA45697.2020.00047
   Kim SY, 2021, 2021 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), DOI 10.1109/ICEIC51217.2021.9369759
   Krizhevsky A, CIFAR 10 CANADIAN I
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Liao Heng, 2019, 2019 IEEE HOT CHIPS, P1
   libcg, BFP BEYOND FLOATING
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lindstrom P, 2018, PROCEEDINGS OF THE CONFERENCE FOR NEXT GENERATION ARITHMETIC (CONGA'18), DOI 10.1145/3190339.3190344
   Liu ZH, 2018, IEEE MICRO, V38, P50, DOI 10.1109/MM.2018.043191125
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Loroch Dominik Marek, 2017, TENSORQUANT A SIMULA
   Lu JM, 2019, IEEE INT SOC CONF, P62, DOI 10.1109/SOCC46988.2019.1570558530
   Mahmoud A, 2022, I C DEPEND SYS NETWO, P206, DOI 10.1109/DSN53405.2022.00031
   Micikevicius P., 2017, MIXED PRECISION TRAI
   MLPerf, 2019, MLPERF TRAINING V06
   Naumov Maxim, 2019, ARXIV
   Nvidia, NVIDIA AMPERE GA102
   Nvidia, NVIDIA TURING GPU AR
   Nvidia, NVIDIA TESLAP100 WHI
   Paszke A, 2019, ADV NEUR IN, V32
   Pierson HA, 2017, ADV ROBOTICS, V31, P821, DOI 10.1080/01691864.2017.1365009
   Pool Jeff, 2021, ADV NEURAL INFORM PR, V34, P13316
   PyTorch, RFC SHOULD MATMULS U
   Ramachandran P, 2018, SEARCHING ACTIVATION
   Raposo G, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7908, DOI 10.1109/ICASSP39728.2021.9413919
   run.ai, FPGA DEEP LEARNING
   Sartin MA, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON RECONFIGURABLE AND COMMUNICATION-CENTRIC SYSTEMS-ON-CHIP (RECOSOC)
   Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157
   Sun YF, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P197, DOI 10.1145/3307650.3322230
   Ubal R, 2012, INT CONFER PARA, P335
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu Peng., 2023, P 21 ACM IEEE INT S, P1
   Yao ZL, 2019, AAAI CONF ARTIF INTE, P5676
   Zamanlooy B, 2014, IEEE T VLSI SYST, V22, P39, DOI 10.1109/TVLSI.2012.2232321
   Zhang TY, 2019, Arxiv, DOI arXiv:1910.04540
   Zhang XS, 2020, PROC CVPR IEEE, P2327, DOI 10.1109/CVPR42600.2020.00240
   Zhou Aojun, 2021, INT C LEARN REPR
   Zhou J, 2021, Arxiv, DOI [arXiv:1812.08434, DOI 10.1016/J.AIOPEN.2021.01.001]
   Zhu F, 2020, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR42600.2020.00204
   Zhu HY, 2018, I S WORKL CHAR PROC, P88, DOI 10.1109/IISWC.2018.8573476
NR 74
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 519
EP 536
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Venkataramani, S
   Srinivasan, V
   Choi, J
   Heidelberger, P
   Chang, L
   Gopalakrishnan, K
AF Venkataramani, Swagath
   Srinivasan, Vijayalakshmi
   Choi, Jungwook
   Heidelberger, Philip
   Chang, Leland
   Gopalakrishnan, Kailash
GP IEEE
TI Memory and Interconnect Optimizations for Peta-Scale Deep Learning
   Systems
SO 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS (HIPC)
DT Proceedings Paper
CT 26th International Conference on High Performance Computing, Data and
   Analytics (HiPCW)
CY DEC 17-20, 2019
CL Hyderabad, INDIA
DE Hardware Accelerators; Deep Neural Networks
AB Hardware accelerators are a promising solution to the stringent computational requirements of Deep Neural Networks (DNNs). Ranging from low-power IP cores to server class systems, various accelerator architectures with high TOPS/W peak processing efficiencies and flexibility to execute different DNN topologies have been proposed. Prior efforts improve core utilization through better data-flows and computation sequencing, but little effort has thus far been devoted to systematically programming DNN accelerators to extract best possible system utilization, particularly for DNN training, which can be parallelized across peta-scale systems. In this work, we address the hitherto open challenge of systematically mapping computations onto Peta-scale accelerator systems, comprising many (thousands of) processing cores spanning many chips, while maximizing overall system performance. We achieve this by characterizing the design space of possible mapping configurations, building a detailed performance model that incorporates every computation and data-transfer involved in DNN training, and using a design space exploration tool called DEEPSPATIALMATRIX to identify the performance optimal configuration. We highlight 4 key optimizations built within DEEPSPATIALMATRIX - hybrid data-model parallelism, inter-layer memory reuse, time-step pipelining, and dynamic spatial minibatching - each of which improve system utilization by carefully managing the available memory capacity and interconnect bandwidth to balance the compute vs. communication costs. On a 8-peta-FLOP accelerator system, we demonstrate 1.36x -32x improvement in training performance through our design space exploration and optimizations across image recognition (VGG16, ResNet50) and machine translation (GNMT) DNN models.
C1 [Venkataramani, Swagath; Srinivasan, Vijayalakshmi; Choi, Jungwook; Heidelberger, Philip; Chang, Leland; Gopalakrishnan, Kailash] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Venkataramani, S (corresponding author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM swagath.venkataramani@ibm.com; viji@us.ibm.com; choij@us.ibm.com;
   philiph@us.ibm.com; lelandc@us.ibm.com; kailash@us.ibm.com
CR Alwani M., 2016, MICROPAGE, P1
   [Anonymous], 2016, P ISCA
   [Anonymous], 2016, P ISCA
   Ben-Nun T., 2018, DEMYSTIFYING PARALLE
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Das D., 2016, DISTRIBUTED DEEP LEA
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Dulac-Arnold G., 2015, REINFORCEMENT LEARNI
   Farabet C., 2011, P CVPR WORKSH
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Gao Y., 2018, P ICML
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hannun A., 2014, DEEP SPEECH SCALING
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kerbyson D.J., 2001, P SC NOV
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Kwon H., 2018, P ASPLOS
   Lym, 2019, SYSML
   Majumdar A., 2012, ACM TACO
   Mirhoseini A., 2018, HIERARCHICAL PLANNIN
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Venkataramani S., 2017, P ISCA
   Venkataramani S., 2017, P PACT
   Venkataramani S, 2019, IEEE MICRO, V39, P102, DOI 10.1109/MM.2019.2931584
   Wu, 2016, ARXIV160908144
   Wu X., 1999, PERFORMANCE EVALUATI
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 32
TC 7
Z9 7
U1 0
U2 2
PY 2019
BP 225
EP 234
DI 10.1109/HiPC.2019.00036
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Qi, LK
   Yao, K
AF Qi, Linkai
   Yao, Kai
TI Artificial intelligence enterprise human resource management system
   based on FPGA high performance computer hardware
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Embedded web medical system; Ct perfusion imaging detection; Cerebral
   Hemorrhage
AB A significant role in Artificial Intelligence (AI) and Machine Learning (ML) tools in the recent development of intelligent systems. AI solutions to the many other areas, such as a different field of health care, the regional aircraft and vehicles, security, marketing, customer analysis and other significant changes. One of the major challenges hindering the potential of AI is high-performance computing resources on demand. Recently, the hardware accelerator to provide the required computing power of AI and ML tool development. In the literature, a hardware accelerator to accelerate the computationally intensive tasks built using FPGA. The accelerator provides high-performance hardware, while maintaining the required accuracy. In this work, proposed that the focus of AI and ML exploration tools available hardware accelerator, a systematic review of the literature. The results showed that, compared to the proof hardware implementation based on software implemented significant performance improvements due to the parallel operation similar precision, and using an optimization technique designed to exploit the target system device mapping. In addition, to achieve our FPGA-based neural network system to support its future use for other applications.
C1 [Qi, Linkai] Shanghai Univ Engn Sci, Sch Management Studies, Shanghai 201620, Peoples R China.
   [Yao, Kai] Fudan Univ, Sch Management, Shanghai 200433, Peoples R China.
RP Qi, LK (corresponding author), Shanghai Univ Engn Sci, Sch Management Studies, Shanghai 201620, Peoples R China.
EM qilinkai2020@163.com
CR Beirman H. Scott, 1998, GAME THEORY EC APPL
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Fang QQ, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P37, DOI 10.1109/IFITA.2009.91
   Gao AQ, 2006, LECT NOTES COMPUT SC, V3841, P121
   Guo JH, 2018, IEEE T IND INFORM, V14, P2592, DOI 10.1109/TII.2017.2777145
   Hang B.O.-.H.U., 2010, XIAN ELECT UNIVER SC, V37, P56
   Huijuan Zhao, 2008, BUSINESS ERA, V13, P58
   Jiang H. H., 2011, INFORM TECHNOLOGY J, V10, P113
   Kenpi Ilium, 2020, INDUCT COUP MED IMPL, V72
   Levin J, 2003, AM ECON REV, V93, P835, DOI 10.1257/000282803322157115
   Li Jin-zhong, 2010, Application Research of Computers, V27, P3622, DOI 10.3969/j.issn.1001-3695.2010.10.005
   Liu Ping, 2020, MICROPROCESS MICROSY
   Ma JT, 2020, CIRCULATION, V141, DOI 10.1161/circ.141.suppl_1.P524
   Mingxiang of LU, 2012, SOFTW ENG KNOWL ENG, V162, P727
   Rolland Nicolas, 2008, J BUSINESS STRATEGY, V29, P7
   Ruguo Fan, 2006, GAME THEORY, P161
   Wat L.I.A.N., 2020, IEEE ACCESS, V8, P38355, DOI [10.1109/ACCESS.2019.2958854, DOI 10.1109/ACCESS.2019.2958854]
   Xie C, 2018, IEEE ACCESS, V6, P15202, DOI 10.1109/ACCESS.2018.2810837
   Xue YY, 2009, COMPUT COMMUN, V32, P1666, DOI 10.1016/j.comcom.2009.06.006
   Yang Jen-Te, 2007, J KNOWLEDGE MNAGE, V11, P84
NR 20
TC 8
Z9 8
U1 4
U2 30
PD APR
PY 2021
VL 82
AR 103876
DI 10.1016/j.micpro.2021.103876
EA JAN 2021
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Brooks, D
   Frank, MM
   Gokmen, T
   Gupta, U
   Hu, XS
   Jain, S
   Laguna, AF
   Niemier, M
   O'Conner, I
   Raghunathan, A
   Ranjan, A
   Reis, D
   Stevens, JR
   Wu, CJ
   Yin, XZ
AF Brooks, David
   Frank, Martin M.
   Gokmen, Tayfun
   Gupta, Udit
   Hu, X. Sharon
   Jain, Shubham
   Laguna, Ann Franchesca
   Niemier, Michael
   O'Conner, Ian
   Raghunathan, Anand
   Ranjan, Ashish
   Reis, Dayane
   Stevens, Jacob R.
   Wu, Carole-Jean
   Yin, Xunzhao
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI Emerging Neural Workloads and Their Impact on Hardware
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
ID NETWORK; MEMORY
AB We consider existing and emerging neural workloads, and what hardware accelerators might be best suited for said workloads. We begin with a discussion of analog crossbar arrays, which are known to be well-suited for matrix-vector multiplication operations that are commonplace in existing neural network models such as convolutional neural networks (CNNs). We highlight candidate crosspoint devices, what device and materials challenges must be overcome for a given device to be employed in a crossbar array for a computationally interesting neural workload, and how circuit and algorithmic optimizations may be employed to mitigate undesirable characteristics from devices/materials. We then discuss two emerging neural workloads. We first consider machine learning models for one- and few-shot learning tasks (i.e., where a network can be trained with just one or a few, representative examples of a given class). Notably crossbar-based architectures can be used to accelerate said models. Hardware solutions based on content addressable memory arrays will also be discussed. We then consider machine learning models for recommendation systems. Recommendation models, an emerging class of machine learning models, employ distinct neural network architectures that operate of continuous and categorical input features which make hardware acceleration challenging. We will discuss the open research challenges and opportunities within this space.
C1 [Brooks, David; Gupta, Udit] Harvard Univ, Cambridge, MA 02138 USA.
   [Frank, Martin M.; Gokmen, Tayfun; Ranjan, Ashish] IBM TJ Watson Res Ctr, Ossining, NY USA.
   [Hu, X. Sharon; Laguna, Ann Franchesca; Niemier, Michael; Reis, Dayane] Univ Notre Dame, Notre Dame, IN 46556 USA.
   [Jain, Shubham; Raghunathan, Anand; Stevens, Jacob R.] Purdue Univ, W Lafayette, IN 47907 USA.
   [O'Conner, Ian] Ecole Cent Lyon, Lyon, France.
   [Wu, Carole-Jean] Facebook, Menlo Pk, CA USA.
   [Yin, Xunzhao] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
RP Brooks, D (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM dbrooks@eecs.harvard.edu; mmfrank@us.ibm.com; tgokmen@us.ibm.com;
   ugupta@g.harvard.cdu; shu@nd.edu; jain130@purdue.edu; alaguna@nd.edu;
   mniemier@nd.edu; Ian.OConner@ec-lyon.fr; raghunathan@purduc.edu;
   ashish.ranjan@ibm.com; dreis@nd.edu; steven69@purdue.edu;
   carolejeanwu@fb.com; xzyin1@zju.edu.cn
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 2016, CORR
   BISHOP D, 2018, INT C SOL STAT DEV M, P23, DOI DOI 10.7567/SSDM.2018.A-2-04
   Bremler-Barr A., 2015, P 11 INT WORKSH DAT
   Bremler-Barr A, 2007, IEEE INFOCOM SER, P1388, DOI 10.1109/INFCOM.2007.164
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Cartier EA, 2019, INT RELIAB PHY SYM, DOI 10.1109/irps.2019.8720599
   Chang HY, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934050
   Cheng H.-T., 2016, P 1 WORKSH DEEP LEAR, P7, DOI DOI 10.1145/2988450.2988454
   Choi J., 2019, 2 SYSMI C
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Eleftheriou E, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947008
   Frank M., 2018, 49 IEEE SISC
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Giannopoulos I, 2018, INT EL DEVICES MEET
   Ginart A., 2019, MIXED DIMENSION EMBE
   Gokmen T., 2019, ARXIV190907908
   Gokmen T, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993573
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gong N, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04485-1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A., 2014, NEURAL TURING MACHIN, DOI DOI 10.3389/NEUR0.12.006.2007
   Graves A., 2014, NATURE ELECT
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Gupta Udit, 2019, ARXIV190603109
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hochreiter S., 2001, LECT NOTES COMPUT SC, P87
   Imani M, 2018, IEEE T EMERG TOP COM, V6, P305, DOI 10.1109/TETC.2016.2565262
   ISHIWARA H, 1993, JPN J APPL PHYS 1, V32, P442, DOI 10.1143/JJAP.32.442
   Joshi V., 2019, ABS190603138
   Kaiser L., 2017, ABS170303129
   Kaiser L., 2017, 5 INT C LEARN REPR I
   Kim H., 2019, ABS190710228
   Kim S., 2019, INT EL DEV M
   Kim W, 2018, INT RELIAB PHY SYM
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Laguna A. F., GLSVLSI, P373
   Laguna AF, 2019, DES AUT TEST EUROPE, P1583, DOI [10.23919/date.2019.8715198, 10.23919/DATE.2019.8715198]
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mahmoodi R., 2018, P 55 ANN DES AUT C D
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI DOI 10.1016/S0079-7421(08)60536-8
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Nandakumar SR, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351656
   Naumov M., 2019, ARXIVI90600091
   Ni JM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P188
   Oh S, 2019, APL MATER, V7, DOI 10.1063/1.5108562
   Oh S, 2019, IEEE ELECTR DEVICE L, V40, P1092, DOI 10.1109/LED.2019.2914700
   Park Ji Ho, 2018, BAM BOTTLENECK ATTEN
   Ranjan A, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317935
   Rasch M. J., 2019, ABS190602698
   Santoro A, 2016, PR MACH LEARN RES, V48
   Shukla S, 2018, IEEE SOLID-ST CIRC L, V1, P217, DOI 10.1109/LSSC.2019.2902738
   STEINBUCH K, 1961, KYBERNETIK, V1, P36, DOI 10.1007/BF00293853
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Sun X., 2018, IEEE T KNOWL DATA EN, V1, P1
   Sun X, 2019, ADV NEUR IN, V32
   Tang J., 2018, 2018 IEEE INT EL DEV, DOI [10.1109/IEDM.2018.8614551, DOI 10.1109/IEDM.2018.8614551]
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630
   Wang N., 2016, ADV NEURAL INFORM PR, P7675
   Weston Jason, 2014, ARXIV14103916
   Widrow B., 1960, 15532 TR STANF U STA
   Wu C. -J., DEEP LEARNING ITS NO
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
   Zhou GR, 2019, AAAI CONF ARTIF INTE, P5941
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
NR 69
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 1462
EP 1471
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Industrial; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Marni, L
   Hosseini, M
   Mohsenin, T
AF Marni, Lahir
   Hosseini, Morteza
   Mohsenin, Tinoosh
GP ACM
TI MC3A: Markov Chain Monte Carlo ManyCore Accelerator
SO PROCEEDINGS OF THE 2018 GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI'18)
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 23-25, 2018
CL Chicago, IL
DE Manycore accelerator; ASIC; VLSI; MCMC; Uniform Random Number Generator;
   PDF; Metropolis-Hastings (MH)
ID MODEL
AB The paper presents "MC3A"-Markov Chain Monte Carlo ManyCore Accelerator, a high-throughput, domain-specific, programmable manycore accelerator, which effectively generates samples from a provided target distribution. MCMC samplers are used in machine learning, image and signal processing applications that are computationally intensive. In such scenarios, high-throughput samplers are of paramount importance. To achieve a high-throughput platform, we add two domain-specific instructions with dedicated hardware whose functions are extensively used in MCMC algorithms. These instructions bring down the number of clock cycles needed to implement the respective functions by 10x and 21x. A 64-cluster architecture of the MC3A is fully placed and routed in 65 nm, TSMC CMOS technology, where the VLSI layout of each cluster occupies an area of 0.577 mm(2) while consuming a power of 247mW running at 1 GHz clock frequency. Our proposed MC3A achieves 6x higher throughput than its equivalent predecessor (PENC) and consumes 4x lower energy per sample. Also, when compared to other off-the-shelf platforms, such as, Jetson TX1 and TX2 SoC, MC3A results in 195x and 191x higher throughput, and consumes 808x and 726x lower energy per sample generation, respectively.
C1 [Marni, Lahir; Hosseini, Morteza; Mohsenin, Tinoosh] Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21201 USA.
RP Marni, L (corresponding author), Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21201 USA.
EM mlahir1@umbc.edu; hs10@umbc.edu; tinoosh@umbc.edu
CR Abtahi T., 2017, 2017 IEEE INT S CIRC, P1
   [Anonymous], IEEE T VERY LARGE SC
   Asadi NB, 2008, FPGA 2008: SIXTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P203
   Attaran N, 2018, IEEE T CIRCUITS-II, V65, P2032, DOI 10.1109/TCSII.2018.2799821
   Gutierrez R, 2012, IEEE T CIRCUITS-II, V59, P501, DOI 10.1109/TCSII.2012.2204119
   Hosseini M., 2017, IEEE S FIELD PROGR C
   Ji ZX, 2012, IEEE T INF TECHNOL B, V16, P339, DOI 10.1109/TITB.2012.2185852
   Kulkarni A., 2017, IEEE T VLSI SYST, V99, P1
   Kulkarni A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P57, DOI 10.1145/2902961.2902984
   Liu GJ, 2016, IEICE T INF SYST, VE99D, P2061, DOI 10.1587/transinf.2015INP0017
   Lynch SM, 2007, STAT SOC BEHAV SC, P107, DOI 10.1007/978-0-387-71265-9_5
   Mahani AS, 2015, COMPUT STAT DATA AN, V88, P75, DOI 10.1016/j.csda.2015.02.010
   Marni Lahir, 2018, IEEE INT SYMP CIRC S
   Mingas Grigorios, 2012, Reconfigurable Computing: Architectures, Tools and Applications. Proceedings of the 8th International Symposium, ARC 2012, P227, DOI 10.1007/978-3-642-28365-9_19
   Mingas G, 2012, ANN IEEE SYM FIELD P, P153, DOI 10.1109/FCCM.2012.34
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Shinde S.B., 2017, IEEE INT S CIRC SYST, P1
   Ter Braak CJF, 2006, STAT COMPUT, V16, P239, DOI 10.1007/s11222-006-8769-1
NR 18
TC 1
Z9 1
U1 0
U2 1
PY 2018
BP 165
EP 170
DI 10.1145/3194554.3194577
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Wan, LP
   Zheng, FY
   Fan, GA
   Wei, R
   Gao, LL
   Wang, YW
   Lin, JQ
   Dong, JK
AF Wan, Lipeng
   Zheng, Fangyu
   Fan, Guang
   Wei, Rong
   Gao, Lili
   Wang, Yuewu
   Lin, Jingqiang
   Dong, Jiankuo
BE Atluri, V
   DiPietro, R
   Jensen, CD
   Meng, W
TI A Novel High-Performance Implementation of CRYSTALS-Kyber with AI
   Accelerator
SO COMPUTER SECURITY - ESORICS 2022, PT III
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 27th European Symposium on Research in Computer Security (ESORICS)
CY SEP 26-30, 2022
CL Tech Univ Denmark, Copenhagen, DENMARK
HO Tech Univ Denmark
DE Lattice-based cryptography; Polynomial multiplication over rings; NTT;
   AI accelerator; Tensor Core; Kyber
ID MULTIPLICATION; ALGORITHM
AB Public-key cryptography, including conventional cryptosystems and post-quantum cryptography, involves computation-intensive workloads. With noticing the extraordinary computing power of AI accelerators, in this paper, we further explore the feasibility to introduce AI accelerators into high-performance cryptographic computing. Since AI accelerators are dedicated to machine learning or neural networks, the biggest challenge is how to transform cryptographic workloads into their operations, while ensuring the correctness of the results and bringing convincing performance gains.
   After investigating and analysing the workload of NVIDIA AI accelerator, Tensor Core, we choose to utilize it to accelerate the polynomial multiplication, usually the most time-consuming part in lattice-based cryptography. We take measures to accommodate the matrix-multiply-and-add mode of Tensor Core and make a trade-off between precision and performance, to leverage it as a high-performance NTT box performing NTT/INTT through CUDA C++ WMMA APIs. Meanwhile, we take CRYSTALS-Kyber, the candidate to be standardized by NIST, as a case study on RTX 3080 with the Ampere Tensor Core. The empirical results show that the customized NTT of polynomial vector (n = 256, k = 4) with our NTT box obtains a speedup around 6.47x that of the state-of-the-art implementation on the same GPU platform. Compared with the AVX2 implementation submitted to NIST, our Kyber-1024 can achieve a speedup of 26x, 36x, and 35x for each phase.
C1 [Wan, Lipeng; Zheng, Fangyu; Fan, Guang; Wei, Rong; Gao, Lili; Wang, Yuewu] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Wan, Lipeng; Fan, Guang; Wei, Rong; Gao, Lili; Wang, Yuewu] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Wan, Lipeng; Zheng, Fangyu; Fan, Guang; Wei, Rong; Gao, Lili; Wang, Yuewu] Chinese Acad Sci, Data Assurance & Commun Secur Res Ctr, Beijing, Peoples R China.
   [Lin, Jingqiang] Univ Sci & Technol China, Sch Cyber Secur, Hefei, Peoples R China.
   [Dong, Jiankuo] Nanjing Univ Posts & Telecommunicat, Sch Comp Sci, Nanjing, Peoples R China.
RP Zheng, FY (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.; Zheng, FY (corresponding author), Chinese Acad Sci, Data Assurance & Commun Secur Res Ctr, Beijing, Peoples R China.
EM zhengfangyu@iie.ac.cn
CR Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Alkim E, 2019, LECT NOTES COMPUT SC, V11774, P237, DOI 10.1007/978-3-030-30530-7_12
   Banerjee A, 2012, LECT NOTES COMPUT SC, V7237, P719, DOI 10.1007/978-3-642-29011-4_42
   BARRETT P, 1987, LECT NOTES COMPUT SC, V263, P311
   Bos J, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P353, DOI 10.1109/EuroSP.2018.00032
   Brakerski Z., 2014, ACM T COMPUT THEORY, V6, P1
   Chari S., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P398
   Cloud G.:, CLOUD TPU
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Gao YW, 2022, IEEE T PARALL DISTR, V33, P551, DOI 10.1109/TPDS.2021.3097277
   Greconici D. O. C., 2021, IACR T CRYPTOGR HARD, P1
   Gupta N, 2021, IEEE T PARALL DISTR, V32, P575, DOI 10.1109/TPDS.2020.3025691
   Inc A., APPL UNL M1
   Inc N, NVIDIA TENS COR UNPR
   Karatsuba A. A., 1963, SOV PHYS DOKL, V7, P595
   Langlois A, 2015, DESIGN CODE CRYPTOGR, V75, P565, DOI 10.1007/s10623-014-9938-4
   Lu X., 2018, CRYPTOLOGY EPRINT AR, P1009
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Lyubashevsky V., 2019, IACR T CRYPTOGRAPH H, P180
   Matthias K., WIGGERS PQCLEAN PROJ
   MONTGOMERY PL, 1985, MATH COMPUT, V44, P519, DOI 10.1090/S0025-5718-1985-0777282-X
   Moody D., 2022, STATUS REPORT 3 ROUN
   Nakai T., 2021, IACR T CRYPTOGRAPHIC, P149
   NIST, 2022, POSTQUANTUM CRYPTOGR
   NIST, POSTQUANTUM CRYPTOGR
   Prouff E, 2013, LECT NOTES COMPUT SC, V7881, P142, DOI 10.1007/978-3-642-38348-9_9
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Sanal P, 2021, L N INST COMP SCI SO, V399, P424, DOI 10.1007/978-3-030-90022-9_23
   Schwabe P., CRYSTALS CRYPTOGRAPH
   Seiler Gregor, 2018, IACR CRYPTOL EPRINT, V2018, P39
   Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011
   TOOM AL, 1963, DOKL AKAD NAUK SSSR+, V150, P496
   Wan LP, 2021, L N INST COMP SCI SO, V398, P249, DOI 10.1007/978-3-030-90019-9_13
   Xing Y., 2021, IACR T CRYPTOGRAPH H, P328, DOI DOI 10.46586/TCHES.V2021.I2.328-356
NR 34
TC 2
Z9 2
U1 1
U2 2
PY 2022
VL 13556
BP 514
EP 534
DI 10.1007/978-3-031-17143-7_25
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Kronheim, BS
   Kuchera, MP
   Prosper, HB
   Karbo, A
AF Kronheim, B. S.
   Kuchera, M. P.
   Prosper, H. B.
   Karbo, A.
TI Bayesian neural networks for fast SUSY predictions
SO PHYSICS LETTERS B
DT Article
DE SUSY; Neural networks; Bayesian; Machine learning; arXiv:2007.04506
AB One of the goals of current particle physics research is to obtain evidence for new physics, that is, physics beyond the Standard Model (BSM), at accelerators such as the Large Hadron Collider (LHC) at CERN. The searches for new physics are often guided by BSM theories that depend on many unknown parameters, which, in some cases, makes testing their predictions difficult. In this paper, machine learning is used to model the mapping from the parameter space of the phenomenological Minimal Supersymmetric Standard Model (pMSSM), a BSM theory with 19 free parameters, to some of its predictions. Bayesian neural networks are used to predict cross sections for arbitrary pMSSM parameter points, the mass of the associated lightest neutral Higgs boson, and the theoretical viability of the parameter points. All three quantities are modeled with average percent errors of 3.34% or less and in a time significantly shorter than is possible with the supersymmetry codes from which the results are derived. These results are a further demonstration of the potential for machine learning to model accurately the mapping from the high dimensional spaces of BSM theories to their predictions. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Kronheim, B. S.; Kuchera, M. P.; Karbo, A.] Davidson Coll, Dept Phys, Davidson, NC 28035 USA.
   [Prosper, H. B.] Florida State Univ, Dept Phys, Tallahassee, FL 32306 USA.
RP Kronheim, BS (corresponding author), Davidson Coll, Dept Phys, Davidson, NC 28035 USA.
EM brkronheim@davidson.edu; mikuchera@davidson.edu
CR Aad G, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2015)134
   Aad G., 2012, PHYS LETT B, V716, P1, DOI [DOI 10.1016/J.PHYSLETB.2012.08.020, 10.1016/j.physletb.2012.08.020]
   Aaltonen T, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.092002
   Abazov VM, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.092001
   Abazov VM, 2008, PHYS REV D, V78, DOI 10.1103/PhysRevD.78.012005
   Allanach BC, 2002, COMPUT PHYS COMMUN, V143, P305, DOI 10.1016/S0010-4655(01)00460-X
   Ambrogi F, 2018, EUR PHYS J C, V78, DOI 10.1140/epjc/s10052-018-5660-0
   [Anonymous], 1998, ARXIVHEPPH9901246
   [Anonymous], 2012, PHYS LETT B, DOI DOI 10.1016/j.physletb.2021.136446
   Bayarri MJ, 2004, STAT SCI, V19, P58, DOI 10.1214/088342304000000116
   Bechtle P, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5224-8
   Beenakker W, 1999, PHYS REV LETT, V83, P3780, DOI 10.1103/PhysRevLett.83.3780
   Berger CF, 2009, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2009/02/023
   Berger JO, 2015, BAYESIAN ANAL, V10, P189, DOI 10.1214/14-BA915
   Betancourt M, ARXIV METHODOLOGY
   Bhat PC, 2011, ANNU REV NUCL PART S, V61, P281, DOI [10.1146/annurev.nucl.012809.10442, 10.1146/annurev.nucl.012809.104427]
   Brehmer Johann, 2020, Computing and Software for Big Science, V4, DOI 10.1007/s41781-020-0035-2
   Brehmer J, 2018, PHYS REV D, V98, DOI 10.1103/PhysRevD.98.052004
   Cahill-Rowley M, 2015, PHYS REV D, V91, DOI 10.1103/PhysRevD.91.055002
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Caron S, 2019, EUR PHYS J C, V79, DOI 10.1140/epjc/s10052-019-7437-5
   Caron S, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-4814-9
   Dawson S, 2019, PHYS REP, V816, P1, DOI 10.1016/j.physrep.2019.05.001
   Fawcett W.J, 2016, POS LHCP, V2016, P146, DOI DOI 10.22323/1.276.0146
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Ismail A., 2013, ARXIV13080297
   Jungman G, 1996, PHYS REP, V267, P195, DOI 10.1016/0370-1573(95)00058-5
   Khachatryan V, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2016)129
   Kronheim B, BAYESIAN INFER UNPUB
   Kronheim B, **DATA OBJECT**, DOI [10.5281/zenodo.4263569, DOI 10.5281/ZENODO.4263569]
   Lee Jaehoon, 2017, ARXIV171100165
   Little R, 2011, STAT SCI, V26, P162, DOI 10.1214/10-STS318
   Nath P., 1993, ARXIVHEPPH9309277
   Neal R.M., 1996, BAYESIAN LEARNING NE
   Quigg C, 2015, ANNU REV NUCL PART S, V65, P25, DOI 10.1146/annurev-nucl-102313-025537
   Reddi S J, 2019, ARXIV190409237
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schmidt B, 2016, J PHYS CONF SER, V706, DOI 10.1088/1742-6596/706/2/022002
   Sekmen S, 2012, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2012)075
   Severini T., 2000, LIKELIHOOD METHODS S
   Xu Y, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/P08005
NR 41
TC 8
Z9 8
U1 0
U2 3
PD FEB 10
PY 2021
VL 813
AR 136041
DI 10.1016/j.physletb.2020.136041
WC Astronomy & Astrophysics; Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Mihaita, D
   Stefan, GM
AF Mihaita, David
   Stefan, Gheorghe M.
TI Hybrid Accelerator with MapReduce Architecture for Convolutional Neural
   Networks
SO ROMANIAN JOURNAL OF INFORMATION SCIENCE AND TECHNOLOGY
DT Article
AB The current hybrid architectures used to train and implement Convolutional Neural Networks (CNN) are based on Nvidia GPU or Intel MIC accelerators. They are marked by limitations due to their too general and ad hoc structure and architecture. We propose an accelerator with a Map-Reduce architecture. The FPGA version of our proposal is considered for accelerating the training process, while the ASIC versions, based on experiments done in the FPGA environment, are targeted for low-energy consumption mass product applications. The paper emphasizes a specific set of functions for the CNN used in Machine Learning (ML) applications, and presents the resulting structural and architectural requirements. The main stages used in a pipe of functions destined to ML are: padding, convolution, pooling and fully connected neural network. The actual applications use these functions in a big variety of configurations. Thus, it worths to define, for training and running a CNN, a programmable accelerator. The paper describes the organization and the architecture of a hybrid system based on Map-Reduce architecture. The energy consumption is estimated, by simulation, for the ASIC version. We conclude that the Map-Reduce approach provides an appropriate solution for accelerating various ML applications.
C1 [Mihaita, David; Stefan, Gheorghe M.] Univ Politehn Bucuresti, Bucharest, Romania.
RP Stefan, GM (corresponding author), Univ Politehn Bucuresti, Bucharest, Romania.
EM gheorghe.stefan@upb.ro
CR Andonie Razvan, 2007, Proceedings of the Sixth IASTED International Conference on Computational Intelligence, P163
   [Anonymous], 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.91
   Karpathy A., CS231N CONVOLUTIONAL
   Kleene SC, 1936, MATH ANN, V112, P727, DOI 10.1007/BF01565439
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Malita Mihaela, 2007, Computer Architecture News, V35, P32, DOI 10.1145/1360464.1360474
   Raina G., 2016, DEEP CONVOLUTIONAL N
   Redmon J., YOU ONLY LOOK ONCE U
   Simonyan K, 2015, P 3 INT C LEARN REPR
   STEFAN G. M., 2006, HOT CHIPS S HIGH PER
   Stefan G. M., 2007, 18 INT C CIR SYST CO, P582
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2015.7298594
   Zbontar J., 2015, COMPUTING STEREO MAT
   Zeiler M., 2014, EUR C COMP VIS ZUR S
NR 14
TC 0
Z9 0
U1 0
U2 6
PY 2017
VL 20
IS 3
SI SI
BP 186
EP 197
WC Computer Science, Theory & Methods; Instruments & Instrumentation;
   Physics, Applied
DA 2023-11-11
ER

PT J
AU Furletov, S
   Barbosa, F
   Belfore, L
   Dickover, C
   Fanelli, C
   Furletova, Y
   Jokhovets, L
   Lawrence, D
   Romanov, D
AF Furletov, S.
   Barbosa, F.
   Belfore, L.
   Dickover, C.
   Fanelli, C.
   Furletova, Y.
   Jokhovets, L.
   Lawrence, D.
   Romanov, D.
TI Machine learning on FPGA for event selection
SO JOURNAL OF INSTRUMENTATION
DT Article; Proceedings Paper
CT Conference on Artificial Intelligence for the Electron Ion Collider
   (AI4EIC-EXP)
CY SEP 07-10, 2021
CL Stony Brook Univ, Ctr Frontiers Nucl Sci, New York, NY
HO Stony Brook Univ, Ctr Frontiers Nucl Sci
DE Data reduction methods; Online farms and online filtering; Pattern
   recognition; cluster finding; calibration and fitting methods; Trigger
   concepts and systems (hardware and software)
AB Real-time data processing is a frontier field in experimental particle physics. The application of FPGAs at the trigger level is used by many current and planned experiments (CMS, LHCb, Belle2, PANDA). Usually they use conventional processing algorithms. LHCb has implemented Machine Learning (ML) elements for real-time data processing with a triggered readout system that runs most of the ML algorithms on a computer farm. The work described in this article aims to test the ML-FPGA algorithms for streaming data acquisition. There are many experiments working in this area and they have a lot in common, but there are many specific solutions for detector and accelerator parameters that are worth exploring further. This report describes the purpose of the work and progress in evaluating the ML-FPGA application.
C1 [Furletov, S.; Barbosa, F.; Dickover, C.; Furletova, Y.; Lawrence, D.; Romanov, D.] Thomas Jefferson Natl Accelerator Facil, Newport News, VA 23606 USA.
   [Belfore, L.] Old Dominion Univ, Dept Elect & Comp Engn, Norfolk, VA 23529 USA.
   [Fanelli, C.] MIT, Lab Nucl Sci, Cambridge, MA 02139 USA.
   [Jokhovets, L.] Julich Res Ctr, ZEA 2, Julich, Germany.
RP Furletov, S (corresponding author), Thomas Jefferson Natl Accelerator Facil, Newport News, VA 23606 USA.
EM furletov@jlab.org
CR Aaij R, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/04/P04013
   Barbosa F, 2019, NUCL INSTRUM METH A, V942, DOI 10.1016/j.nima.2019.162356
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Horn T, 2020, NUCL INSTRUM METH A, V956, DOI 10.1016/j.nima.2019.163375
   Lawrence D., 2020, EPJ WEB C, V14
   PETERSON C, 1994, COMPUT PHYS COMMUN, V81, P185, DOI 10.1016/0010-4655(94)90120-1
   Visser G, 2010, IEEE NUCL SCI CONF R, P777, DOI 10.1109/NSSMIC.2010.5873864
   TOOLKIT MULTIVARIATE
NR 8
TC 1
Z9 1
U1 1
U2 7
PD JUN
PY 2022
VL 17
IS 6
AR C06009
DI 10.1088/1748-0221/17/06/C06009
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Weber, L
   Sommer, L
   Oppermann, J
   Molina, A
   Kersting, K
   Koch, A
AF Weber, Lukas
   Sommer, Lukas
   Oppermann, Julian
   Molina, Alejandro
   Kersting, Kristian
   Koch, Andreas
GP IEEE
TI Resource-Efficient Logarithmic Number Scale Arithmetic for SPN Inference
   on FPGAs
SO 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2019)
DT Proceedings Paper
CT International Conference on Field-Programmable Technology (ICFPT)
CY DEC 09-13, 2019
CL Tianjin, PEOPLES R CHINA
DE FPGA; SPN; Machine Learning; Graphical Models; Deep Models
AB FPGAs have been successfully used for the implementation of dedicated accelerators for a wide range of machine learning problems. The inference in so-called Sum-Product Networks can also be accelerated efficiently using a pipelined FPGA architecture.
   However, as Sum-Product Networks compute exact probability values, the required arithmetic precision poses different challenges than those encountered with Neural Networks. In previous work, this precision was maintained by using double-precision floating-point number formats, which are expensive to implement in FPGAs.
   In this work, we propose the use of a logarithmic number system format tailored specifically towards the inference in Sum-Product Networks. The evaluation of our optimized arithmetic hardware operators shows that the use of logarithmic number formats allows to save up to 50% hardware resources compared to double-precision floating point, while maintaining sufficient precision for SPN inference at almost identical performance.
C1 [Weber, Lukas; Sommer, Lukas; Oppermann, Julian; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
   [Molina, Alejandro; Kersting, Kristian] Tech Univ Darmstadt, Machine Learning Lab, Darmstadt, Germany.
RP Weber, L (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM weber@esa.tu-darmstadt.de; sommer@esa.tu-darmstadt.de;
   oppermann@esa.tu-darmstadt.de; molina@cs.tu-darmstadt.de;
   kersting@cs.tu-darmstadt.de; koch@esa.tu-darmstadt.de
CR de Dinechin F., 2011, IEEE DESIGN TEST COM
   Detrey J., 2003, AS C SIGN SYST COMP
   Haaren J. V, 2012, AAAI
   Haselman M., 2005, 13 ANN IEEE S FIELD
   Kumm M., 2017, IEEE 24 S COMP AR
   Lewis D. M., 1993, 11 S COMP AR JUN
   Lewis D. M., 1995, P ISSCC INT SOL STAT
   Lowd D., 2010, IEEE 10 INT C DAT MI
   Misra J., 2010, NEUROCOMPUTING
   Molina A., 2018, P AAAI
   Sommer L., 2018, IEEE 36 INT C COMP D
   Sommer L., 2018, ICML WORKSH TRACT PR
   Vouzis P. D., 2007, DSD 2007
NR 13
TC 3
Z9 3
U1 0
U2 0
PY 2019
BP 251
EP 254
DI 10.1109/ICFPT47387.2019.00040
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Rojek, K
AF Rojek, Krzysztof
TI Machine learning method for energy reduction by utilizing dynamic mixed
   precision on GPU-based supercomputers
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE energy efficiency; GPGPU; machine learning; mixed precision; MPDATA;
   random forest
ID POWER
AB In this work, we propose a method that allows us to reduce energy consumption of an application executed on supercomputing centers. The proposed method is based on a mixed precision arithmetic where the precision of data is calibrated at runtime. For this reason, we develop a modified version of the random forest algorithm. The effectiveness of the proposed approach is validated with a real-life scientific application called MPDATA, which is part of the numerical model used in weather forecasting. The energy efficiency of the proposed method is examined using two GPU-based clusters. The first of them is the Piz Daint supercomputer, currently ranked 3rd at the TOP500 list (November 2017). It is equipped with NVIDIA Tesla P100 GPU accelerators based on the Pascal architecture. The second is the MICLAB cluster containing NVIDIA Tesla K80 based on the Kepler architecture. The achieved results show that the proposed machine learning method allows us to provide the accuracy of computation comparable with that achieved double precision and reduce the energy consumption up to 36% compared to the double precision version of MPDATA.
C1 [Rojek, Krzysztof] Czestochowa Tech Univ, Czestochowa, Poland.
RP Rojek, K (corresponding author), Czestochowa Tech Univ, Czestochowa, Poland.
EM krojek@icis.pcz.pl
CR Aliaga JI, 2017, J SUPERCOMPUT, V73, P29, DOI 10.1007/s11227-015-1600-z
   Aliaga JI, 2014, CLUSTER COMPUT, V17, P1335, DOI 10.1007/s10586-014-0402-z
   Alonso P, 2012, COMPUT SCI-RES DEV, V27, P289, DOI 10.1007/s00450-011-0188-7
   [Anonymous], 2010, SOFTWARE AUTOMATIC T
   [Anonymous], 2013, IBM SYSTEM BLUE GENE
   Berral JL, 2010, P 1 INT C EN EFF COM
   Burtscher M., 2014, P WORKSH GEN PURP PR
   Cherubin S., 2017, INT C PAR COMP PARCO
   Durillo J, 2014, SCI PROGRAMMING-NETH, V22, P285, DOI [10.1155/2014/818579, 10.3233/SPR-140394]
   Elnozahy EN, 2002, 2 INT WORKSH POW AW
   Ge R, 2010, IEEE T PARALL DISTR, V21, P658, DOI 10.1109/TPDS.2009.76
   Haidar Azzam, 2017, P 8 WORKSH LAT ADV S, P1
   Ilic A, 2017, IEEE T COMPUT, V66, P52, DOI 10.1109/TC.2016.2582151
   Keramidas G., 2010, P 7 ACM INT C COMP F
   Kurzak Jakub, 2011, CHAPMAN HALL CRC COM
   LeGendre Matthew P, 2013, P 27 INT ACM C INT C
   Malas T., 2014, CORR
   Malossi ACI, 2014, P INT C HIGH PERF CO
   Meneses E, 2014, PARALLEL COMPUT, V40, P536, DOI 10.1016/j.parco.2014.03.005
   Mittal S, 2014, ACM COMPUT SURV, V47, P29
   Molka D, 2010, P 1 INT GREEN COMP C
   Qureshi A, 2009, P ACM SIGCOMM 2009 C
   Ralph N, 2016, CORR
   Rauber T, 2015, CONCURR COMP-PRACT E, V27, P211, DOI 10.1002/cpe.3219
   Rojek K, 2015, 13 INT C PAR COMP TE
   Rojek K, 2011, 9 INT C PAR PROC APP
   Rojek K, 2017, CONCURRENCY COMPUTAT, V29
   Rojek K, 2017, J SUPERCOMPUT, V73, P4373, DOI 10.1007/s11227-017-2020-z
   Rojek K, 2017, J SUPERCOMPUT, V73, P664, DOI 10.1007/s11227-016-1774-z
   Rosa B., 2015, INT J MODEL OPTIM, V5, P171
   Sarood O, 2013, IEEE INT C CL COMP
   Smolarkiewicz PK, 2006, INT J NUMER METH FL, V50, P1123, DOI 10.1002/fld.107
   Wyrzykowski R, 2014, 9 INT C LARG SCAL SC
NR 33
TC 7
Z9 7
U1 0
U2 15
PD MAR 25
PY 2019
VL 31
IS 6
SI SI
AR e4644
DI 10.1002/cpe.4644
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Auten, A
   Tomei, M
   Kumar, R
AF Auten, Adam
   Tomei, Matthew
   Kumar, Rakesh
GP IEEE
TI Hardware Acceleration of Graph Neural Networks
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
AB Graph neural networks (GNNs) have been shown to extend the power of machine learning to problems with graph-structured inputs. Recent research has shown that these algorithms can exceed state-of-the-art performance on applications ranging from molecular inference to community detection. We observe that existing execution platforms (including existing machine learning accelerators) are a poor fit for GNNs due to their unique memory access and data movement requirements. We propose, to the best of our knowledge, the first accelerator architecture targeting GNNs. The architecture includes dedicated hardware units to efficiently execute the irregular data movement required for graph computation in GNNs, while also providing high compute throughput required by GNN models. We show that our architecture outperforms existing execution platforms in terms of inference latency on several key GNN benchmarks (e.g., 7.5x higher performance than GPUs and 18x higher performance than CPUs at iso-bandwidth).
C1 [Auten, Adam; Tomei, Matthew; Kumar, Rakesh] Univ Illinois, Elect & Comp Engn, Urbana, IL 61801 USA.
RP Auten, A (corresponding author), Univ Illinois, Elect & Comp Engn, Urbana, IL 61801 USA.
EM auten2@illinois.edu; tomei2@illinois.edu; rakeshk@illinois.edu
CR afansi, 2019, IMPL PAP COMM DET GR
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen Zhengdao, 2017, ARXIV170508415STAT
   Ding Fei, 2019, GRAPH NEURAL NETWORK
   Du XD, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P159, DOI 10.1109/YAC.2016.7804882
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Ham TJ, 2016, INT SYMP MICROARCH
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Kipf Thomas, 2019, IMPLEMENTATION GRAPH
   Kipf Thomas N., ARXIV160902907CSSTAT
   Li F, 2013, IEEE IPCCC
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Velikovi Petar, 2017, ARXIV171010903CSSTAT
   Velikovi Petar, 2019, GRAPH ATTENTION NETW
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhou J, 2018, ARTIF CELL NANOMED B, V46, pS1016, DOI 10.1080/21691401.2018.1442841
NR 18
TC 48
Z9 50
U1 1
U2 1
PY 2020
DI 10.1109/dac18072.2020.9218751
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Abreu, B
   Grellert, M
   Bampi, S
AF Abreu, Brunno
   Grellert, Mateus
   Bampi, Sergio
TI A framework for designing power-efficient inference accelerators in
   tree-based learning applications
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
DT Article
DE Machine Learning; Decision trees; Random forests; Inference; VLSI
   circuits; Power-accuracy trade-off
ID DECISION TREE; CLASSIFICATION; SMARTWATCHES; NETWORK
AB Machine Learning techniques (ML) are being widely adopted in embedded devices due to their efficiency and flexibility. However, the strict power limitations in such devices, combined with the variable resource requirements of ML models, require further understanding of how model complexity affects power and performance. This paper proposes a framework that facilitates the design space exploration of dedicated decision trees (DT) and random forests (RF) accelerators by enabling a joint assessment of power dissipation and prediction accuracy. The proposed framework translates tree-based structures to hardware description languages (HDL). The HDL modules are submitted to logic and physically-aware hardware synthesis flows, allowing a detailed power-performance analysis of VLSI DTs and RFs. Using four data sets of embedded applications as case studies, we found that quantizing the input features leads to accuracy gains of up to 6.3% compared with the precise versions. We also show that using shallower trees may lead to small prediction loss with significant reductions in power, which is favorable for power-constrained applications. Our translator achieves better results in terms of energy/inference w.r.t. prior related works under comparison, one of which employed standard methods for hardware translation such as High-Level Synthesis. The proposed solution presents a power reduction of 10 times or more for the same inference throughput reported in prior works.
C1 [Abreu, Brunno; Bampi, Sergio] Univ Fed Rio Grande do Sul, Grad Program Microelect PGMICRO, Inst Informat, Porto Alegre, RS, Brazil.
   [Grellert, Mateus] Univ Fed Santa Catarina, Dept Informat & Stat, Grad Program Comp Sci PPGCC, Florianopolis, SC, Brazil.
RP Abreu, B (corresponding author), Univ Fed Rio Grande do Sul, Grad Program Microelect PGMICRO, Inst Informat, Porto Alegre, RS, Brazil.
EM baabreu@inf.ufrgs.br
CR Abreu B.A., 2020, 2020 IEEE INT S CIRC, P1
   Ardakani A., 2016, SPARSELY CONNECTED N
   Bauer D, 2016, PROC CIRP, V50, P529, DOI 10.1016/j.procir.2016.04.121
   Bermak A., 2004, TENCON 2004. 2004 IEEE Region 10 Conference (IEEE Cat. No. 04CH37582), P32
   Beukenhorst AL, 2018, STUD HEALTH TECHNOL, V247, P291, DOI 10.3233/978-1-61499-852-5-291
   Bin Altaf MA, 2016, IEEE INT SYMP CIRC S, P1126, DOI 10.1109/ISCAS.2016.7527443
   Bin Altaf MA, 2016, IEEE T BIOMED CIRC S, V10, P49, DOI 10.1109/TBCAS.2014.2386891
   Bockermann C, 2015, LECT NOTES ARTIF INT, V9286, P100, DOI 10.1007/978-3-319-23461-8_7
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bruno B., 2012, 2012 IEEE International Conference on Automation Science and Engineering (CASE 2012), P156, DOI 10.1109/CoASE.2012.6386410
   Bruno B, 2013, IEEE INT CONF ROBOT, P1602, DOI 10.1109/ICRA.2013.6630784
   Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Chang SY, 2019, IEEE T CIRCUITS-I, V66, P3504, DOI 10.1109/TCSI.2019.2927839
   Chen X, 2017, IEEE IJCNN, P2494, DOI 10.1109/IJCNN.2017.7966159
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cisco, 2020, WHIT PAP CISC ANN IN
   Dheeru D., 2017, UCI MACHINE LEARNING
   Huang SA, 2018, SYMP VLSI CIRCUITS, P259, DOI 10.1109/VLSIC.2018.8502428
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Kim K, 2016, DES AUT CON, DOI 10.1145/2897937.2898011
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kuehn J, 2018, I C FIELD PROG LOGIC, P445, DOI 10.1109/FPL.2018.00082
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lopez-Estrada S., 2006, P 2006 IEEE INT C RE, P1, DOI [10.1109/RECONF.2006.307770, DOI 10.1109/RECONF.2006.307770]
   Mitsunari K, 2018, IEICE T FUND ELECTR, VE101A, P1298, DOI 10.1587/transfun.E101.A.1298
   Mortazavi B, 2015, SENSORS-BASEL, V15, P26783, DOI 10.3390/s151026783
   Mortazavi B, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS (BSN), P33, DOI 10.1109/BSN.2014.21
   Poggio, 2000, CTR BIOL COMP LEARN
   Prisacariu Victor Adrian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3344, DOI 10.1109/ICPR.2010.816
   Sharma KV, 2017, AIP CONF PROC, V1859, DOI 10.1063/1.4990245
   Steinberg D, 2009, CH CRC DATA MIN KNOW, P179, DOI 10.1201/9781420089653.ch10
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tann H, 2016, RUNTIME CONFIGURABLE
   Tong D, 2017, IEEE T PARALL DISTR, V28, P3046, DOI 10.1109/TPDS.2017.2714661
   Torres RLS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON RFID (RFID), P191, DOI 10.1109/RFID.2013.6548154
   Ugulino Wallace, 2012, Advances in Artificial Intelligence - SBIA 2012. Proceedings 21th Brazilian Symposium on Artificial Intelligence, P52, DOI 10.1007/978-3-642-34459-6_6
   Velloso Eduardo, 2013, P 4 AUGMENTED HUMAN, P116, DOI DOI 10.1145/2459236.2459256
   Wang DY, 2020, IEEE ACCESS, V8, P46335, DOI 10.1109/ACCESS.2020.2974101
   Xu XW, 2018, PROC CVPR IEEE, P8300, DOI 10.1109/CVPR.2018.00866
   Yang YN, 2014, BIOMED CIRC SYST C, P380, DOI 10.1109/BioCAS.2014.6981742
   Zhang BY, 2018, ASIA S PACIF DES AUT, P331, DOI 10.1109/ASPDAC.2018.8297345
   Zhou  A., 2017, ARXIV170203044
   Zhou ZQ, 2020, IEEE ACCESS, V8, P86411, DOI 10.1109/ACCESS.2020.2992584
NR 43
TC 4
Z9 4
U1 0
U2 5
PD MAR
PY 2022
VL 109
AR 104638
DI 10.1016/j.engappai.2021.104638
EA JAN 2022
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Bhati, AP
   Wan, SZ
   Alfè, D
   Clyde, AR
   Bode, M
   Tan, L
   Titov, M
   Merzky, A
   Turilli, M
   Jha, S
   Highfield, RR
   Rocchia, W
   Scafuri, N
   Succi, S
   Kranzlmüller, D
   Mathias, G
   Wifling, D
   Donon, Y
   Di Meglio, A
   Vallecorsa, S
   Ma, H
   Trifan, A
   Ramanathan, A
   Brettin, T
   Partin, A
   Xia, FF
   Duan, XT
   Stevens, R
   Coveney, PV
AF Bhati, Agastya P.
   Wan, Shunzhou
   Alfe, Dario
   Clyde, Austin R.
   Bode, Mathis
   Tan, Li
   Titov, Mikhail
   Merzky, Andre
   Turilli, Matteo
   Jha, Shantenu
   Highfield, Roger R.
   Rocchia, Walter
   Scafuri, Nicola
   Succi, Sauro
   Kranzlmueller, Dieter
   Mathias, Gerald
   Wifling, David
   Donon, Yann
   Di Meglio, Alberto
   Vallecorsa, Sofia
   Ma, Heng
   Trifan, Anda
   Ramanathan, Arvind
   Brettin, Tom
   Partin, Alexander
   Xia, Fangfang
   Duan, Xiaotan
   Stevens, Rick
   Coveney, Peter V.
TI Pandemic drugs at pandemic speed: infrastructure for accelerating
   COVID-19 drug discovery with hybrid machine learning- and physics-based
   simulations on high-performance computers
SO INTERFACE FOCUS
DT Article
DE machine learning; artificial intelligence; novel drug design; molecular
   dynamics; free energy predictions
ID FREE-ENERGY; MOLECULAR-DYNAMICS; PREDICTION; INHIBITORS; HYDRATION;
   PRECISE; VIRUS
AB The race to meet the challenges of the global pandemic has served as a reminder that the existing drug discovery process is expensive, inefficient and slow. There is a major bottleneck screening the vast number of potential small molecules to shortlist lead compounds for antiviral drug development. New opportunities to accelerate drug discovery lie at the interface between machine learning methods, in this case, developed for linear accelerators, and physics-based methods. The two in silico methods, each have their own advantages and limitations which, interestingly, complement each other. Here, we present an innovative infrastructural development that combines both approaches to accelerate drug discovery. The scale of the potential resulting workflow is such that it is dependent on supercomputing to achieve extremely high throughput. We have demonstrated the viability of this workflow for the study of inhibitors for four COVID-19 target proteins and our ability to perform the required large-scale calculations to identify lead antiviral compounds through repurposing on a variety of supercomputers.
C1 [Bhati, Agastya P.; Wan, Shunzhou; Coveney, Peter V.] UCL, Ctr Computat Sci, Gordon St, London WC1H 0AJ, England.
   [Alfe, Dario] UCL, Dept Earth Sci, London Ctr Nanotechnol, Gower St, London WC1E 6BT, England.
   [Alfe, Dario] UCL, Thomas Young Ctr, Gower St, London WC1E 6BT, England.
   [Alfe, Dario] Univ Napoli Federico II, Dipartimento Fis Ettore Panc, I-80126 Naples, Italy.
   [Clyde, Austin R.; Duan, Xiaotan] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.
   [Bode, Mathis] Rhein Westfal TH Aachen, Inst Combust Technol, D-52056 Aachen, Germany.
   [Tan, Li; Jha, Shantenu] Brookhaven Natl Lab, Upton, NY 11973 USA.
   [Titov, Mikhail; Merzky, Andre; Turilli, Matteo; Jha, Shantenu] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   [Highfield, Roger R.] Sci Museum London, Exhibit Rd, London SW7 2DD, England.
   [Rocchia, Walter; Scafuri, Nicola] Italian Inst Technol, Concept Lab, Via Melen, Genoa, Italy.
   [Succi, Sauro] Italian Inst Technol, Ctr Life Nanosci La Sapienza, Viale Regina Elena, Rome, Italy.
   [Kranzlmueller, Dieter; Mathias, Gerald; Wifling, David] Bavarian Acad Sci & Humanities, Leibniz Supercomp Ctr LRZ, Boltzmannstr 1, D-85748 Garching, Germany.
   [Donon, Yann; Di Meglio, Alberto; Vallecorsa, Sofia] CERN, OpenLab, Geneva, Switzerland.
   [Ma, Heng; Trifan, Anda; Ramanathan, Arvind; Partin, Alexander; Xia, Fangfang] Argonne Natl Lab, Data Sci & Learning Div, 9700 S Cass Ave, Argonne, IL 60439 USA.
   [Brettin, Tom; Stevens, Rick] Argonne Natl Lab, Comp Environm & Life Sci Directorate, 9700 S Cass Ave, Argonne, IL 60439 USA.
   [Coveney, Peter V.] Univ Amsterdam, Inst Informat, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
RP Coveney, PV (corresponding author), UCL, Ctr Computat Sci, Gordon St, London WC1H 0AJ, England.; Coveney, PV (corresponding author), Univ Amsterdam, Inst Informat, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
EM p.v.coveney@ucl.ac.uk
CR [Anonymous], 2020, MOL DYNAMICS SIMULAT
   [Anonymous], 2017, ATOMIC CONVOLUTIONAL
   Babuji Y., 2020, ARXIV PREPRINT ARXIV
   Babuji Y, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P25, DOI 10.1145/3307681.3325400
   Balasubramanian V., 2019, 190403085 ARXIV
   Bennett WFD, 2020, J CHEM INF MODEL, V60, P5375, DOI 10.1021/acs.jcim.0c00318
   Berishvili VP, 2019, J CHEM INF MODEL, V59, P3519, DOI 10.1021/acs.jcim.9b00135
   Bertazzo M, 2021, J CHEM THEORY COMPUT, V17, P5287, DOI 10.1021/acs.jctc.1c00177
   Bhati AP, 2019, J CHEM THEORY COMPUT, V15, P1265, DOI 10.1021/acs.jctc.8b01118
   Bhati AP, 2018, J CHEM THEORY COMPUT, V14, P2867, DOI 10.1021/acs.jctc.7b01143
   Bhati AP, 2017, J CHEM THEORY COMPUT, V13, P210, DOI 10.1021/acs.jctc.6b00979
   Bhowmik D, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2507-5
   Bieniek MK, 2021, J CHEM THEORY COMPUT, V17, P1250, DOI 10.1021/acs.jctc.0c01179
   Bikkina S, 2017, J CHEM SCI, V129, P405, DOI 10.1007/s12039-017-1231-4
   Brace A., 2021, 210404797 ARXIV
   Brown N., 2020, ARTIFICIAL INTELLIGE, DOI [10.1039/9781788016841-00001, DOI 10.1039/9781788016841-00001]
   Casalino L, 2021, INT J HIGH PERFORM C, V35, P432, DOI 10.1177/10943420211006452
   Castelli M, 2021, RSC MED CHEM, V12, P1491, DOI 10.1039/d1md00192b
   Chen W, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5023804
   Chodera JD, 2011, CURR OPIN STRUC BIOL, V21, P150, DOI 10.1016/j.sbi.2011.01.011
   Coveney PV, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0067
   Coveney PV, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2016.0153
   Das P, 2021, NAT BIOMED ENG, V5, P613, DOI 10.1038/s41551-021-00689-x
   Das S, 2021, J BIOMOL STRUCT DYN, V39, P3347, DOI 10.1080/07391102.2020.1763201
   Davis JJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep27930
   Donon Y, 2020, 2020 VI INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND NANOTECHNOLOGY (IEEE ITNT-2020), DOI 10.1109/ITNT49337.2020.9253296
   Elmezayen AD, 2021, J BIOMOL STRUCT DYN, V39, P2980, DOI 10.1080/07391102.2020.1758791
   Fox G, 2019, ADV PARALLEL COMPUT, V34, P34, DOI 10.3233/APC190005
   Frick DN, 2020, BIOCHEMISTRY-US, V59, P2608, DOI 10.1021/acs.biochem.0c00309
   Fuglede B, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P31
   Galvelis R, 2017, J CHEM THEORY COMPUT, V13, P2489, DOI 10.1021/acs.jctc.7b00188
   Gebhardt J, 2020, J CHEM INF MODEL, V60, P5319, DOI 10.1021/acs.jcim.0c00479
   Genheden S, 2015, EXPERT OPIN DRUG DIS, V10, P449, DOI 10.1517/17460441.2015.1032936
   Genheden S, 2010, J COMPUT CHEM, V31, P837, DOI 10.1002/jcc.21366
   Gil C, 2020, J MED CHEM, V63, P12359, DOI 10.1021/acs.jmedchem.0c00606
   Gordon DE, 2020, NATURE, V583, P459, DOI 10.1038/s41586-020-2286-9
   Guo AZ, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5020733
   Jamal S, 2019, FRONT PHARMACOL, V10, DOI 10.3389/fphar.2019.00780
   KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211
   Knight JL, 2009, J COMPUT CHEM, V30, P1692, DOI 10.1002/jcc.21295
   Konze KD, 2019, J CHEM INF MODEL, V59, P3782, DOI 10.1021/acs.jcim.9b00367
   Lawrenz M, 2009, J CHEM THEORY COMPUT, V5, P1106, DOI 10.1021/ct800559d
   Lee H., 2021, 2021 PLATF ADV SCI C, DOI [10.1145/3468267.3470573, DOI 10.1145/3468267.3470573]
   Lee H, 2019, PROCEEDINGS OF 2019 IEEE/ACM THIRD WORKSHOP ON DEEP LEARNING ON SUPERCOMPUTERS (DLS), P12, DOI 10.1109/DLS49591.2019.00007
   Marchetti F, 2021, J PHYS CHEM LETT, V12, P3724, DOI 10.1021/acs.jpclett.1c00045
   McGann MR, 2003, BIOPOLYMERS, V68, P76, DOI 10.1002/bip.10207
   McSkimming DI, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1506-2
   Merzky A., CLUSTER COMPUT
   Merzky A., 2018, P WORKSH JOB SCHED S, P61, DOI 10.1007/978-3-030-10632-4_4
   Merzky A, 2022, IEEE T PARALL DISTR, V33, P818, DOI 10.1109/TPDS.2021.3105994
   Mey Antonia S J S, 2020, Living J Comput Mol Sci, V2, DOI 10.33011/livecoms.2.1.18378
   Michalska K, 2020, IUCRJ, V7, P814, DOI 10.1107/S2052252520009653
   Nichol Alex, 2018, CORR
   OpenEye Scientific, OPENEYE TOOLK 2021 1
   Ribeiro JML, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5025487
   Riniker S, 2017, J CHEM INF MODEL, V57, P726, DOI 10.1021/acs.jcim.6b00778
   Rufa DA., 2020, CHEM ACCURACY ALCHEM, DOI DOI 10.1101/2020.07.29.227959
   Saadi AA., 2021, ACM INT C PAR PROC I
   Scheen J, 2020, J CHEM INF MODEL, V60, P5331, DOI 10.1021/acs.jcim.0c00600
   Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7
   STRAATSMA TP, 1986, J CHEM PHYS, V85, P6720, DOI 10.1063/1.451846
   STRAATSMA TP, 1988, J CHEM PHYS, V89, P5876, DOI 10.1063/1.455539
   Sullivan T, 2019, TOUGH ROAD COST DEV
   Sultan MM, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5029972
   TYRRELL DAJ, 1965, BMJ-BRIT MED J, V1, P1467, DOI 10.1136/bmj.1.5448.1467
   Wan SZ, 2022, MOL SYST DES ENG, V7, P123, DOI 10.1039/d1me00124h
   Wan SZ, 2020, INTERFACE FOCUS, V10, DOI 10.1098/rsfs.2020.0007
   Wan S, 2020, ADV THEOR SIMUL, V3, DOI 10.1002/adts.201900195
   Wan SZ, 2017, J CHEM INF MODEL, V57, P897, DOI 10.1021/acs.jcim.6b00780
   Wan SZ, 2017, J CHEM THEORY COMPUT, V13, P784, DOI 10.1021/acs.jctc.6b00794
   Wan SZ, 2015, J CHEM THEORY COMPUT, V11, P3346, DOI 10.1021/acs.jctc.5b00179
   Wang JM, 2020, J CHEM INF MODEL, V60, P3277, DOI [10.1021/acs.jcim.0c00179, 10.26434/chemrxiv.11875446.v1]
   Wang S, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005324
   Wondmkun YT, 2020, BIOL-TARGETS THER, V14, P77, DOI [10.2147/BTT.S266487, 10.2147/STT.S266487]
   Wouters OJ, 2020, JAMA-J AM MED ASSOC, V323, P844, DOI 10.1001/jama.2020.1166
   Wright DW, 2020, ADV THEOR SIMUL, V3, DOI 10.1002/adts.201900194
   Wright DW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41758-1
   Wright DW, 2014, J CHEM THEORY COMPUT, V10, P1228, DOI 10.1021/ct4007037
   Yang YI, 2019, J CHEM PHYS, V151, DOI 10.1063/1.5109531
   Zhang LF, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5019675
   ZWANZIG RW, 1954, J CHEM PHYS, V22, P1420, DOI 10.1063/1.1740409
NR 81
TC 7
Z9 7
U1 3
U2 13
PD OCT 12
PY 2021
VL 11
IS 6
AR 20210018
DI 10.1098/rsfs.2021.0018
WC Biology
DA 2023-11-11
ER

PT J
AU Aslam, A
   Biedron, SG
   Ma, Y
   Murphy, J
   Burger, M
   Nees, J
   Thomas, AGR
   Krushelnick, K
   Martínez-Ramón, M
AF Aslam, A.
   Biedron, S. G.
   Ma, Y.
   Murphy, J.
   Burger, M.
   Nees, J.
   Thomas, A. G. R.
   Krushelnick, K.
   Martinez-Ramon, M.
TI Neural network-based control of an ultrafast laser
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Machine learning; Ultrafast lasers; Feedforward neural network; Particle
   accelerators
AB With the recent advances in machine learning (ML) and data science (DS), the control, modeling, and analysis of these complex systems continues to improve. In this work, we report on the optimization of the intensity of a femtosecond laser using feedforward neural networks (FFNN) that model the input-output relationships of the data. The input parameters of the system were optimized to achieve the required performance of the femtosecond laser. We propose a neural network-based control system to model the relationship between the spectral amplitude and phase of the input laser pulse at the amplifier input and the shape of the output pulse. Low-jitter laser parameter inputs and the resulting laser pulse duration were modeled, and the resulting correlation between the input and output data was used to optimize the laser pulse. We demonstrate improved processing and laser control performance.
C1 [Aslam, A.; Biedron, S. G.; Martinez-Ramon, M.] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
   [Biedron, S. G.] Univ New Mexico, Dept Mech Engn, Albuquerque, NM 87131 USA.
   [Biedron, S. G.] Element Aero, Chicago, IL 60643 USA.
   [Ma, Y.; Murphy, J.; Burger, M.; Nees, J.; Thomas, A. G. R.; Krushelnick, K.] Univ Michigan, Gerard Mourou Ctr Ultrafast Opt Sci, Ann Arbor, MI 48109 USA.
   [Ma, Y.; Burger, M.; Krushelnick, K.] Univ Michigan, Dept Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA.
RP Aslam, A (corresponding author), Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
EM aaslam@unm.edu
CR Adnan J, 2018, AIP CONF PROC, V1930, DOI 10.1063/1.5022900
   Aslam A., 2022, PROC NAPAC 22, P441, DOI [10.18429/JACoW-NAPAC2022-TUPA41, DOI 10.18429/JACOW-NAPAC2022-TUPA41]
   Aslam A, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053023
   Biedron S., 2022, PROC IPAC 23, P650
   Bilski J, 2020, J ARTIF INTELL SOFT, V10, P299, DOI 10.2478/jaiscr-2020-0020
   Bjorck A., 1996, NUMERICAL METHODS LE
   Bolin T, 2022, PROC LINAC 22, P650, DOI [10.18429/JACoW-LINAC2022-WE2AA04, DOI 10.18429/JACOW-LINAC2022-WE2AA04]
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Chen YM, 2020, INFORM SCIENCES, V537, P246, DOI 10.1016/j.ins.2020.05.101
   Cios KJ, 2007, IEEE ENG MED BIOL, V26, P14, DOI 10.1109/MEMB.2007.335579
   Conlin L., 2020, AI SCI REPORT TECH R
   Coskun UH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15777-4
   Descamps A, 2022, J SYNCHROTRON RADIAT, V29, P931, DOI 10.1107/S1600577522004453
   Diaz Cruz J.A., 2022, PROC IPAC 22, P915, DOI [10.18429/JACoW-IPAC2022-TUPOST027, DOI 10.18429/JACOW-IPAC2022-TUPOST027]
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Fine T.L., 1999, ALGORITHMS DESIGNING
   Galayda J., 2018, LCLS 2 HIGH POWER UP
   Gerber R., 2018, CROSSCUT REPORT EXAS
   Glorot X., 2010, P JMLR WORKSH C P 13, P249, DOI DOI 10.1177/1753193409103364.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gopakumar R., 2022, ARXIV
   Haykin S., 2004, NEURAL NETWORKS COMP, V2, P41
   He ZH, 2015, PHYS PLASMAS, V22, DOI 10.1063/1.4921159
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   Heidemann G., 2003, ESANN, P503
   Hey T, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0054
   Himanen L, 2020, COMPUT PHYS COMMUN, V247, DOI 10.1016/j.cpc.2019.106949
   Huang BH, 2022, IEEE ACCESS, V10, P14350, DOI 10.1109/ACCESS.2022.3147727
   Huang NS, 2021, INNOVATION-AMSTERDAM, V2, DOI 10.1016/j.xinn.2021.100097
   Jefferson Lab, 2020, AI NUCL PHYS WORKSH
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   KANE DJ, 1993, OPT LETT, V18, P823, DOI 10.1364/OL.18.000823
   Karagiorgi G, 2022, NAT REV PHYS, V4, P399, DOI 10.1038/s42254-022-00455-1
   Lin J, 2019, OPT EXPRESS, V27, P10912, DOI 10.1364/OE.27.010912
   Lin JP, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0047940
   Mihailescu A, 2018, MACHINE LEARNING ADV
   Mishra AA, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.114601
   Moayedi H, 2020, J PETROL SCI ENG, V185, DOI 10.1016/j.petrol.2019.106634
   Moldabekov ZA, 2022, CONTRIB PLASM PHYS, V62, DOI 10.1002/ctpp.202000176
   Nise N. S., 2011, CONTROL SYSTEMS ENG, V6th
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Obrimah O.A., 2019, PREFERENCE LOTTERIES, DOI [10.2139/ssrn.3441963, DOI 10.2139/SSRN.3441963]
   Kurup AR, 2019, NEUROCOMPUTING, V367, P188, DOI 10.1016/j.neucom.2019.08.029
   Razavi S, 2011, IEEE T NEURAL NETWOR, V22, P1588, DOI 10.1109/TNN.2011.2163169
   Reece M, 2021, EUR PHYS J PLUS, V136, P1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scheinker A., 2022, ARXIV
   Sebe N., 2005, COMP IMAG VIS, V29
   SLAC National Accelerator Laboratory, LIN COH LIGHT SOURC
   SLAC National Accelerator Laboratory U.S. Department of Energy (DOE), OFF SCI LAB OP STANF
   Solyak NA, 2009, AIP CONF PROC, V1086, P365, DOI 10.1063/1.3080933
   Stevens R., 2020, AI SCI REPORT DEP EN
   Strickland D, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.030502
   Tournois P, 1997, OPT COMMUN, V140, P245, DOI 10.1016/S0030-4018(97)00153-3
   Turner P., 2021, AI ELECT POWER SUMMI
   Valentino G, 2017, J PHYS CONF SER, V874, DOI 10.1088/1742-6596/874/1/012002
   Wayahdi M. R., 2019, Journal of Physics: Conference Series, V1235, DOI 10.1088/1742-6596/1235/1/012031
   Yu H., 2011, IND ELECT HDB INTELL, V5, P1, DOI DOI 10.1201/B10604-15
NR 58
TC 0
Z9 0
U1 2
U2 2
PD AUG
PY 2023
VL 1053
AR 168195
DI 10.1016/j.nima.2023.168195
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Joardar, BK
   Doppa, JR
   Pande, PP
   Marculescu, D
   Marculescu, R
AF Joardar, Biresh Kumar
   Doppa, Janardhan Rao
   Pande, Partha Pratim
   Marculescu, Diana
   Marculescu, Radu
GP Assoc Comp Machinery
TI Hybrid On-Chip Communication Architectures Heterogeneous Manycore
   Systems
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
   DIGEST OF TECHNICAL PAPERS
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 37th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 05-08, 2018
CL San Diego, CA
DE Manycore; Heterogeneous Network-on-Chip; Machine Learning
ID DESIGN-SPACE EXPLORATION; OPTIMIZATION; ALGORITHM
AB The widespread adoption of big data has led to the search for high-performance and low-power computational platforms. Emerging heterogeneous manycore processing platforms consisting of CPU and GPU cores along with various types of accelerators offer power and area -efficient trade-offs for running these applications. However, heterogeneous manycore architectures need to satisfy the communication and memory requirements of the diverse computing elements that conventional Network-on -Chip (NoC) architectures are unable to handle effectively. Further, with increasing system sizes and level of heterogeneity, it becomes difficult to quickly explore the large design space and establish the appropriate design trade-offs. To address these challenges, machine learning -inspired heterogeneous manycore system design is a promising research direction to pursue. In this paper, we highlight various salient features of heterogeneous manycore architectures enabled by emerging
C1 [Joardar, Biresh Kumar; Doppa, Janardhan Rao; Pande, Partha Pratim] Washington State Univ, Sch EECS, Pullman, WA 99164 USA.
   [Marculescu, Diana; Marculescu, Radu] Carnegie Mellon Univ, ECE Dept, Pittsburgh, PA 15213 USA.
RP Joardar, BK (corresponding author), Washington State Univ, Sch EECS, Pullman, WA 99164 USA.
EM biresh.joardar@wsu.edu; jana.doppa@wsu.edu; pande@wsu.edu;
   dianam@cmu.edu; radum@cmu.edu
CR [Anonymous], 1998, P IEEE
   [Anonymous], P 47 INT S MICR
   [Anonymous], 2015, P INT S NETW ON CHIP
   [Anonymous], P IEEE ACM MICRO
   Bandyopadhyay S, 2008, IEEE T EVOLUT COMPUT, V12, P269, DOI 10.1109/TEVC.2007.900837
   Bhat G., 2018, ICCAD
   Boyan JA, 2001, J MACH LEARN RES, V1, P77, DOI 10.1162/15324430152733124
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Cong J, 2004, ICCAD-2004: INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, IEEE/ACM DIGEST OF TECHNICAL PAPERS, P306, DOI 10.1109/ICCAD.2004.1382591
   Das S, 2017, IEEE T COMPUT AID D, V36, P719, DOI 10.1109/TCAD.2016.2604288
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Duraisamy K, 2016, ACM T EMBED COMPUT S, V15, DOI 10.1145/2961027
   Henkel J., 2018, ICCAD
   Jang H., 2015, BANDWIDTH EFFICIENT, P1
   Joardar B. K., 2017, P IEEE ACM NOCS SEOU
   Lee J, 2013, J PARALLEL DISTR COM, V73, P1525, DOI 10.1016/j.jpdc.2013.07.014
   Lin JJ, 2007, IEEE J SOLID-ST CIRC, V42, P1678, DOI 10.1109/JSSC.2007.900236
   Mirhosseini A., 2017, P IEEE ACM NOCS SEOU
   Ogras U.Y., 2013, MODELING ANAL OPTIMI, V184
   Wettin P, 2014, IEEE T COMPUT AID D, V33, P1732, DOI 10.1109/TCAD.2014.2351577
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2018
DI 10.1145/3240765.3243480
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Oinonen, M
   Gaus, O
   Pereira, T
   Walia, A
   Morsi, WG
AF Oinonen, Matthew
   Gaus, Oliver
   Pereira, Tristan
   Walia, Aman
   Morsi, Walid G.
GP IEEE
TI Non-Intrusive Load Monitoring Using Machine Learning Accelerator
   Hardware for Smart Meters
SO 2022 IEEE CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING
   (CCECE)
SE Canadian Conference on Electrical and Computer Engineering
DT Proceedings Paper
CT Canadian Conference on Electrical and Computer Engineering (CCECE)
CY SEP 18-20, 2022
CL Halifax, CANADA
DE Machine learning; non-intrusive load monitoring; smart meters
ID FEATURE-EXTRACTION; NILM
AB Residential electricity customers consume a significant amount of energy due to the extensive use of inefficient appliances. In order to save energy and reduce the electricity bills of the customers, load monitoring provides such customers with information to make informative cost-effective decisions. Non-Intrusive Load Monitoring (NILM) determines which appliances are on at the electrical input to a residence. Machine Learning (ML) based methods of NILM offer flexibility at the cost of computational complexity. This paper investigates addressing the problem of the computational bottleneck using a novel ML-based acceleration hardware. In this work, ML is used to develop a NILM algorithm, which is then tested on a publicly available dataset named the Reference Energy Disaggregation Dataset (REDD). Subsequently, a physical system modelling an end-to-end smart metering solution is designed and tested. The results show a significant decrease in the time and energy required to run the ML algorithms and most importantly, the successful real-time operation of NILM algorithms embedded in a smart meter. By using the newly developed ML acceleration hardware and ML-based algorithms, NILM can be embedded into next-generation Smart Meters.
C1 [Oinonen, Matthew; Gaus, Oliver; Pereira, Tristan; Walia, Aman; Morsi, Walid G.] Ontario Tech Univ, Dept Elect Engn, Oshawa, ON, Canada.
RP Oinonen, M (corresponding author), Ontario Tech Univ, Dept Elect Engn, Oshawa, ON, Canada.
EM matthew.oinonen@ontariotechu.net; oliver.gaus@ontariotechu.net;
   tristan.pereira@ontariotechu.net; aman.walia@ontariotechu.net;
   walidmorsi.ibrahim@ontariotechu.ca
CR Allan A., 2019, HACKLSTER
   Angelov F., 2022, BLOC
   Azizi E, 2021, IEEE T CONSUM ELECTR, V67, P363, DOI 10.1109/TCE.2021.3129356
   Biansoongnern S, 2016, 2016 13TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON)
   Chollet F., 2020, STRUCTURED DATA CLAS
   Coombs R., 2015, SECURING FUTURE AUTH
   Dash S, 2019, 2019 NATIONAL POWER ELECTRONICS CONFERENCE (NPEC), DOI [10.1109/npec47332.2019.9034764, 10.1109/indicon47234.2019.9030372]
   de Souza WA, 2022, IEEE T SMART GRID, V13, P2148, DOI 10.1109/TSG.2022.3144606
   Froehlich J, 2011, IEEE PERVAS COMPUT, V10, P28, DOI 10.1109/MPRV.2010.74
   Ghosh S., 2021, IEEE T INSTRUM MEAS, V70
   Hart G. W., 1989, IEEE Technology and Society Magazine, V8, P12, DOI 10.1109/44.31557
   Luan W., 2021, IEEE T INSTRUM MEAS, V71
   Nolasco LD, 2022, IEEE SENS J, V22, P501, DOI 10.1109/JSEN.2021.3127322
   Paul Leach M. M. R. S., 2005, UNIVERSALLY UNIQUE I
   Rathore V., 2018, 2018 C INFORM COMMUN, P1, DOI [10.1109/INFOCOMTECH.2018.8722382, DOI 10.1109/INFOCOMTECH.2018.8722382]
   Tabanelli E, 2022, IEEE T IND INFORM, V18, P943, DOI 10.1109/TII.2021.3078186
   Zhang XW, 2020, IEEE INT POWER ELEC, P2929, DOI 10.1109/IPEMC-ECCEAsia48364.2020.9367739
NR 17
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 483
EP 488
DI 10.1109/CCECE49351.2022.9918403
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Maceiras, MV
   Azhar, MW
   Trancoso, P
AF Maceiras, Mateo Vazquez
   Azhar, Muhammad Waqar
   Trancoso, Pedro
GP IEEE
TI VSA: A Hybrid Vector-Systolic Architecture
SO 2022 IEEE 40TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2022)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT IEEE 40th International Conference on Computer Design (ICCD)
CY OCT 23-26, 2022
CL Olympic Valley, CA
DE Machine Learning; DNN; GEMM; SIMD; Vector Unit; Systolic Array
AB In order to deliver high performance efficiently, modern processors include dedicated hardware to accelerate different application domains. For example, several recent processors include dedicated Machine Learning (ML) accelerators. However, while adding dedicated hardware improves efficiency compared to general-purpose CPUs, it also requires a larger area, making it unfeasible for smaller devices. Therefore, exploring ways to use the existing hardware for different functionalities becomes desirable in those setups. In this work, we explore the reuse of the components in a Vector Processing Unit (VPU) to offer the functionality of a Systolic Array (SA) for General Matrix Multiplication (GEMM), a kernel extensively used in machine learning, big data, and scientific computing. This hybrid Vector-Systolic Architecture (VSA) can thus support Single Instruction Multiple Data (SIMD) instruction extensions with the VPU functionality and efficiently compute GEMM with the SA functionality. We present an implementation of VSA as a RISC-V co-processor that adds minimal hardware overhead of less than 0.1% compared to a baseline RISC-V implementation with a VPU. In our evaluation using different Deep Neural Network (DNN) models, VSA shows a speedup of up to 3.5x and a reduction in energy consumption of up to 70%.
C1 [Maceiras, Mateo Vazquez; Azhar, Muhammad Waqar; Trancoso, Pedro] Chalmers Univ Technol, Dept Comp Sci & Engn, Gothenburg, Sweden.
RP Maceiras, MV (corresponding author), Chalmers Univ Technol, Dept Comp Sci & Engn, Gothenburg, Sweden.
EM maceiras@chalmers.se; waqarm@chalmers.se; ppedro@chalmers.se
NR 0
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 368
EP 376
DI 10.1109/ICCD56317.2022.00061
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Wang, Y
   Song, LL
   Han, YH
   Cheng, YQ
   Li, HW
   Li, XW
AF Wang, Ying
   Song, Lili
   Han, Yinhe
   Cheng, Yuanqing
   Li, Huawei
   Li, Xiaowei
GP IEEE
TI A Case of Precision-Tunable STT-RAM Memory Design for Approximate Neural
   Network
SO 2015 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 24-27, 2015
CL Lisbon, PORTUGAL
DE STT-RAM; Machine Learning; Neural Network
AB Multi-level STT-RAM cell is able to boost the memory density at the expense of read/write reliability. However, the induced data integrity issue in STT-RAM memory can be effectively masked by a wide spectrum of applications with intrinsic forgiveness, which belong to the specific domain such as multimedia, synthesis and mining. In this work, we leverage the reconfigurable capability of MLC STT-RAM to provide variable-precision data storage for popular machine learning architectures. The targeted STT-RAM memory design is able to transform between multiple work modes and adaptable to meet the varying quality constraint of approximate applications. Particularly, we demonstrate the concept of precision-tunable STT-RAM memory with the emerging Convolution Neural Network accelerators and elaborate on the data mapping policy in STT-RAM memory to achieve the best energy-efficiency.
C1 [Wang, Ying; Song, Lili; Han, Yinhe; Li, Huawei; Li, Xiaowei] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100864, Peoples R China.
   [Wang, Ying; Song, Lili; Han, Yinhe; Li, Huawei; Li, Xiaowei] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Cheng, Yuanqing] Beihang Univ, Beijing 100191, Peoples R China.
RP Wang, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100864, Peoples R China.
EM wangying2009@ict.ac.cn; songlili@ict.ac.cn; yinhes@ict.ac.cn;
   yuanqing@buaa.edu.cn; lihuawei@ict.ac.cn; lxw@ict.ac.cn
CR [Anonymous], 2014, P ASPLOS
   [Anonymous], 1998, P IEEE
   [Anonymous], P ISLPED
   Bienia C., 2008, P PACT
   Chakradhar S., P DAC 10
   Esmaeilzadeh, 2012, P MICRO
   NIU DM, 2013, ICCD, P131
   Ohsawa T., 2012, 2012 IEEE Symposium on VLSI Circuits, P46, DOI 10.1109/VLSIC.2012.6243782
   Wang P., 2013, P ISCAS
   Wen Wujie, 2014, P DAC
   Yoda H., 2012, EL DEV M IEDM IEEE I, P10
NR 11
TC 6
Z9 6
U1 0
U2 4
PY 2015
BP 1534
EP 1537
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Fernández, J
   Perez, J
   Agirre, I
   Allende, I
   Abella, J
   Cazorla, FJ
AF Fernandez, Javier
   Perez, Jon
   Agirre, Irune
   Allende, Imanol
   Abella, Jaume
   Cazorla, Francisco J.
TI Towards functional safety compliance of matrix-matrix multiplication for
   machine learning-based autonomous systems
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Machine learning; Functional safety; Error detection
ID FAULT-TOLERANCE; CORES
AB Autonomous systems execute complex tasks to perceive the environment and take self-aware decisions with limited human interaction. This autonomy is commonly achieved with the support of machine learning algorithms. The nature of these algorithms, that need to process large data volumes, poses high-performance demands on the underlying hardware. As a result, the embedded critical real-time domain is adopting increasingly powerful processors that combine multi-core processors with accelerators such as GPUs. The resulting hardware and software complexity makes it difficult to demonstrate that the system will run safely and reliably. This is the main objective of functional safety standards, such as IEC 61508 or ISO 26262, that deal with the avoidance, detection and control of hardware or software errors. In this paper, we adopt those measures for the safe inference of machine learning libraries on multi-core devices, two topics that are not explicitly covered in the current version of standards. To this end, we adapt the matrix-matrix multiplication function, a central element of existing machine learning libraries, according to the recommendations of functional safety standards. The paper makes the following contributions: (i) adoption of recommended programming practices for the avoidance of programming errors in the matrix-matrix multiplication, (ii) inclusion of diagnostic mechanisms based on widely used checksums to control runtime errors, and (iii) evaluation of the impact of previous measures in terms of performance and a quantification of the achieved diagnostic coverage. For this purpose, we implement the diagnostic mechanisms on one of the ARM R5 cores of a Zynq UltraScale+ multi-processor system-on-chip and we then adapt them to an Intel i7 processor with native code employing vectorization for the sake of performance.
C1 [Fernandez, Javier; Perez, Jon; Agirre, Irune; Allende, Imanol] Ikerlan Technol Res Ctr, Basque Res & Technol Alliance, Arrasate Mondragon, Spain.
   [Abella, Jaume; Cazorla, Francisco J.] Barcelona Supercomp Ctr, Barcelona, Spain.
   [Fernandez, Javier] Univ Politecn Cataluna, Dept Arquitectura Comp, Barcelona, Spain.
RP Fernández, J (corresponding author), Ikerlan Technol Res Ctr, Basque Res & Technol Alliance, Arrasate Mondragon, Spain.
EM javier.fernandez@ikerlan.es; jmperez@ikerlan.es; iagirre@ikerlan.es;
   iallende@ikerlan.es; jaume.abella@bsc.es; francisco.cazorla@bsc.es
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/ICACCS48705.2020.9074315, 10.1109/icaccs48705.2020.9074315]
   Alcaide S, 2019, IEEE INT ON LINE, P90, DOI [10.1109/iolts.2019.8854378, 10.1109/IOLTS.2019.8854378]
   Alcaide S, 2019, DES AUT TEST EUROPE, P824, DOI [10.23919/date.2019.8715177, 10.23919/DATE.2019.8715177]
   [Anonymous], 2018, 26262111 ISO
   [Anonymous], 2019, 21448 ISO PAS
   [Anonymous], 2014, 32 BIT POW ARCH MICR
   [Anonymous], 2012, 2012 GUID USE C LANG
   [Anonymous], 2011, EN50128
   Athavale J, 2020, 50TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOPS (DSN-W 2020), P74, DOI 10.1109/DSN-W50199.2020.00024
   Azizi A, 2019, INT J INTERACT DES M, V13, P373, DOI 10.1007/s12008-018-0501-9
   Ben Abdessalem R, 2018, IEEE INT CONF AUTOM, P143, DOI 10.1145/3238147.3238192
   Berger C, 2015, 2015 IEEE/ACM 1st International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS), P2, DOI 10.1109/SEsCPS.2015.9
   Biondi A, 2019, IEEE EMBED SYST LETT
   Bochkovskiy A., 2020, PREPRINT
   Bosio A, 2019, 2019 20TH IEEE LATIN AMERICAN TEST SYMPOSIUM (LATS)
   Boulanger J.-L, 2013, STATIC ANAL SOFTWARE, P113
   Braun C, 2014, I C DEPEND SYS NETWO, P443, DOI 10.1109/DSN.2014.48
   Buttazzo G, 2018, P 9 INT REAL TIM SCH
   Czarnecki, 2018, ARXIV170902435
   Czarnecki, 2018, ARXIV180801614
   Diaz J, 2012, IEEE T PARALL DISTR, V23, P1369, DOI 10.1109/TPDS.2011.308
   Dimitrov M., 2009, P 2 WORKSHOP GEN PUR, P94, DOI DOI 10.1145/1513895.1513907
   dos Santos FF, 2017, I C DEPENDABLE SYST, P169, DOI 10.1109/DSN-W.2017.47
   Falcini F, 2017, IEEE INT SYMP SOFTW, P286, DOI 10.1109/ISSREW.2017.45
   Fu J, 2013, 2013 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (IC-SAMOS), P255, DOI 10.1109/SAMOS.2013.6621132
   Gomaa M, 2003, CONF PROC INT SYMP C, P98, DOI 10.1109/ISCA.2003.1206992
   Gurel L., 2015, P COMP EL INT WORKSH, P1, DOI DOI 10.1109/CEM.2015.7237429
   Hall B., 2015, SECTION CYCLIC REDUN
   Hennessy J. L., 2011, COMPUTER ARCHITECTUR
   Huang ZB, 2019, J ENG-JOE, V2019, P9043, DOI 10.1049/joe.2018.9178
   Infineon, 2012, AURIX MULT 32 BIT MI
   International Electrotechnical Commission, 2010, 61508 IEC
   Iturbe X, 2019, ACM T COMPUT SYST, V36, DOI 10.1145/3323917
   Jain S, 2019, IEEE REAL TIME, P29, DOI 10.1109/RTAS.2019.00011
   Jeon H, 2012, INT SYMP MICROARCH, P37, DOI 10.1109/MICRO.2012.13
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kelefouras V, 2016, J SUPERCOMPUT, V72, P804, DOI 10.1007/s11227-015-1613-7
   LaFrieda C, 2007, I C DEPEND SYS NETWO, P317, DOI 10.1109/DSN.2007.100
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Lopes IC, 2018, 2018 IEEE 19TH LATIN-AMERICAN TEST SYMPOSIUM (LATS)
   Maxino TC, 2009, IEEE T DEPEND SECURE, V6, P59, DOI 10.1109/TDSC.2007.70216
   Meyer BH, 2011, PROCEEDINGS OF THE PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURES AND SYNTHESIS FOR EMBEDDED SYSTEMS (CASES '11), P125
   Mukherjee SS, 2002, CONF PROC INT SYMP C, P99, DOI 10.1109/ISCA.2002.1003566
   Mushtaq H, 2013, DES AUT TEST EUROPE, P921
   Nathan R, 2015, IEEE COMPUT ARCHIT L, V14, P13, DOI 10.1109/LCA.2014.2298391
   Pei KX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P1, DOI 10.1145/3132747.3132785
   Cerrolaza JP, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3398665
   PEREZ J, 2014, EUROMICRO C DIGITAL
   Pionteck, ARCHITECTURE COMPUTI
   Rana R, 2014, COMM COM INF SC, V457, P164, DOI 10.1007/978-3-662-44920-2_11
   Ray J, 2006, I C DEPEND SYS NETWO, P3, DOI 10.1109/DSN.2006.30
   Rech P, 2018, IET COMPUT DIGIT TEC, V13
   Redmon J., 2013, DARKNET OPEN SOURCE
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   REINHARDT SK, 2000, P 27 ANN INT S COMPU, V28
   Reis GA, 2005, INT SYM CODE GENER, P243, DOI 10.1109/CGO.2005.34
   ROFFE S, 2020, IEEE AEROSPACE C, P1
   Rotenberg E, 1999, DIG PAP INT SYMP FAU, P84, DOI 10.1109/FTCS.1999.781037
   Ruospo A, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P672, DOI 10.1109/DSD51259.2020.00109
   Schatz B, 2012, IGI GLOBAL
   Shye A, 2007, I C DEPEND SYS NETWO, P297, DOI 10.1109/DSN.2007.98
   Shye A, 2009, IEEE T DEPEND SECURE, V6, P135, DOI 10.1109/TDSC.2008.62
   So H, 2018, DES AUT TEST EUROPE, P533, DOI 10.23919/DATE.2018.8342065
   Sullivan MB, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P762, DOI [10.1109/MICR0.2018.00067, 10.1109/MICRO.2018.00067]
   Tabani H, 2020, I SYM OBJ-OR R-T D C, P144, DOI 10.1109/ISORC49007.2020.00030
   Tabani H, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317779
   Wadden J, 2014, CONF PROC INT SYMP C, P73, DOI 10.1109/ISCA.2014.6853227
   Zhao K, 2021, IEEE T PARALL DISTR, V32, P1677, DOI 10.1109/TPDS.2020.3043449
NR 69
TC 4
Z9 4
U1 0
U2 5
PD DEC
PY 2021
VL 121
AR 102298
DI 10.1016/j.sysarc.2021.102298
EA OCT 2021
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Rosenthal, E
   Greshnikov, S
   Soudry, D
   Kvatinsky, S
AF Rosenthal, Eyal
   Greshnikov, Sergey
   Soudry, Daniel
   Kvatinsky, Shahar
GP IEEE
TI A Fully Analog Memristor-Based Neural Network with Online Gradient
   Training
SO 2016 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 22-25, 2016
CL Montreal, CANADA
DE Multilayer Neural Networks; machine learning; backpropagation;
   neuromorphic; memristor; CMOS; RRAM
AB In recent years, Neural Networks (NNs) have become widely popular for the execution of different machine learning algorithms. Training an NN is computationally intensive since it requires numerous multiplications of matrices that represent synaptic weights. It is therefore appealing to build a hardware-based NN accelerator to gain parallelism and efficient computation. Recently, we have proposed a compact circuit of a non-volatile synaptic weight based on two CMOS transistors and a memristor. In this paper, we present a fully analog NN design based on our previously proposed synapse with a full design of the different layers and their supporting CMOS circuits. We show that the presented NN significantly reduces the area as compared to a CMOS-based NN, while executing online gradient training with similar accuracy and computational speed improvement as a software implementation.
C1 [Rosenthal, Eyal; Greshnikov, Sergey; Kvatinsky, Shahar] Technion Israel Inst Technol, Dept Elect Engn, IL-3200003 Haifa, Israel.
   [Soudry, Daniel] Columbia Univ, Dept Stat, New York, NY 10027 USA.
RP Rosenthal, E (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-3200003 Haifa, Israel.
CR Blum A, 1998, LECT NOTES COMPUT SC, V1442, P306, DOI 10.1007/BFb0029575
   CARD HC, 1991, IEE PROC-F, V138, P13, DOI 10.1049/ip-f-2.1991.0003
   CAUWENBERGHS G, 1992, IEEE T NEURAL NETWOR, V3, P488, DOI 10.1109/72.129421
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Kvatinsky S, 2013, IEEE T CIRCUITS-I, V60, P211, DOI 10.1109/TCSI.2012.2215714
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Li H., 2000, FUZZY NEURAL INTELLI, P255
   Lichman M., 2013, UCI MACHINE LEARNING
   Lu C, 2002, ANALOG INTEGR CIRC S, V31, P55, DOI 10.1023/A:1014476806076
   Mangasarian OL., 1990, CANC DIAGNOSIS VIA L
   MORIE T, 1994, IEEE J SOLID-ST CIRC, V29, P1086, DOI 10.1109/4.309904
   SCHNEIDER C, 1991, ELECTRON LETT, V27, P785, DOI 10.1049/el:19910489
   SHIMA T, 1992, IEEE J SOLID-ST CIRC, V27, P1868, DOI 10.1109/4.173117
   Simonite T., 2014, IBM CHIP PROCESSES D
   Soudry D, 2015, IEEE T NEUR NET LEAR, V26, P2408, DOI 10.1109/TNNLS.2014.2383395
   Valle M, 1996, ANALOG INTEGR CIRC S, V9, P231, DOI 10.1007/BF00194907
   Zisserman A., 2014, 14091556 ARXIV
NR 17
TC 33
Z9 36
U1 1
U2 12
PY 2016
BP 1394
EP 1397
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Patsidis, K
   Nicopoulos, C
   Sirakoulis, GC
   Dimitrakopoulos, G
AF Patsidis, Kariofyllis
   Nicopoulos, Chrysostomos
   Sirakoulis, Georgios Ch
   Dimitrakopoulos, Giorgos
GP IEEE
TI RISC-V<SUP>2</SUP>: A Scalable RISC-V Vector Processor
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
ID DEEP NEURAL-NETWORKS; ACCELERATOR
AB Machine learning adoption has seen a widespread bloom in recent years, with neural network implementations being at the forefront. In light of these developments, vector processors are currently experiencing a resurgence of interest, due to their inherent amenability to accelerate data-parallel algorithms required in machine learning environments. In this paper, we propose a scalable and high-performance RISC-V vector processor core. The presented processor employs a triptych of novel mechanisms that work synergistically to achieve the desired goals. An enhanced vector-specific incarnation of register renaming is proposed to facilitate dynamic hardware loop unrolling and alleviate instruction dependencies. Moreover, a cost-efficient decoupled execution scheme splits instructions into execution and memory-access streams, while hardware support for reductions accelerates the execution of key instructions in the RISC-V ISA. Extensive performance evaluation and hardware synthesis analysis validate the efficiency of the new architecture.
C1 [Patsidis, Kariofyllis; Sirakoulis, Georgios Ch; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Elect & Comp Engn, Nicosia, Cyprus.
RP Patsidis, K (corresponding author), Democritus Univ Thrace, Elect & Comp Engn, Xanthi, Greece.
CR [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2020, RISC V VECT PROC
   [Anonymous], 1998, THESIS U CALIFORNIA
   Celio C., 2017, UCBEECS2017157
   Celio C., 2015, BERKELEY OUT OF ORDE
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Conti F, 2016, J SIGNAL PROCESS SYS, V84, P339, DOI 10.1007/s11265-015-1070-9
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Esmaeilzadeh H, 2006, IEEE INT SYMP CIRC S, P2773, DOI 10.1109/ISCAS.2006.1693199
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Espasa R, 2002, CONF PROC INT SYMP C, P281, DOI 10.1109/ISCA.2002.1003586
   Espasa R, 1997, INT SYMP MICROARCH, P160, DOI 10.1109/MICRO.1997.645807
   Espasa R, 1996, SECOND INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE, PROCEEDINGS, P281, DOI 10.1109/HPCA.1996.501193
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Hurkat S, 2019, INT S HIGH PERF COMP, P345, DOI 10.1109/HPCA.2019.00049
   Kozyrakis CE, 2003, IEEE MICRO, V23, P36, DOI 10.1109/MM.2003.1261385
   Lee Y, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P129
   Patsidis K, 2018, MICROPROCESS MICROSY, V61, P1, DOI 10.1016/j.micpro.2018.05.007
   RUSSELL RM, 1978, COMMUN ACM, V21, P63, DOI 10.1145/359327.359336
   Sun J.(, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wawrzynek J, 1996, COMPUTER, V29, P79, DOI 10.1109/2.485896
   Yu J, 2008, FPGA 2008: SIXTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P222
NR 24
TC 11
Z9 11
U1 0
U2 0
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Naher, J
   Gloster, C
   Jadhav, SS
   Doss, CC
AF Naher, Jannatun
   Gloster, Clay
   Jadhav, Shrikant S.
   Doss, Christopher C.
GP IEEE
TI Using Machine Learning to Estimate Utilization and Throughput for
   OpenCL-Based SpMV Implementation on an FPGA
SO IEEE SOUTHEASTCON 2020
SE IEEE SoutheastCon-Proceedings
DT Proceedings Paper
CT Annual IEEE SoutheastCon Conference
CY 2020
CL ELECTR NETWORK
DE SpMV; FPGAs; OpenCL; Machine Learning; Design Space Exploration
AB Hardware designers use High-Level Synthesis (HLS) tools in order to reduce the design time and design complexity. OpenCL is a framework that uses HLS tools and permits the programmer to write standardized C-like code for the host as well as for the hardware accelerators. Using OpenCL, a program can be written using different memory access and data partitioning strategies. The programmer needs to try various designs in order to optimize the design. However, each design takes multiple hours to compile. Characteristics of a hardware architecture can be estimated using a machine learning technique without doing actual synthesis. Sparse Matrix-Vector Multiplication (SpMV) is widely used in linear algebra and for many applications. The SpMV kernel can be designed in numerous ways using OpenCL. For SpMV implementation, the storage format is a vital factor. Different memory access patterns, storage requirements, and load balancing impact the hardware architecture. Here, this research is proposing two things. First, it utilizes a hybrid approach to store the sparse matrix to implement the SpMV kernel. Second, it estimates the hardware architecture for any set of design settings using a machine learning technique in OpenCL without doing actual synthesis. From our implementation, compared to ELL storage format, the proposed storage format (a combination of ELL and CSR) takes a less amount of resources for LUTs, DSPs, and RAM blocks while providing higher throughput. The Random forest machine learning algorithm estimates the logic utilization and performance for ELL and the proposed storage format within a very reasonable accuracy range. Using hybrid format (ELL+CSR) for 65 designs, the average error is 11.43%, 19.03%, 9.09%, 5.3% and 9.73% for LUTs, DSPs, memory bits, RAM blocks and throughput (GFLOPs) respectively.
C1 [Naher, Jannatun; Doss, Christopher C.] North Carolina A&T State Univ, Elect & Comp Engn Dept, Greensboro, NC 27411 USA.
   [Gloster, Clay; Jadhav, Shrikant S.] North Carolina A&T State Univ, Comp Syst Technol Dept, Greensboro, NC USA.
RP Naher, J (corresponding author), North Carolina A&T State Univ, Elect & Comp Engn Dept, Greensboro, NC 27411 USA.
EM jnaher@aggies.ncat.edu; cgloster@ncat.edu; ssjadhav@ncat.edu;
   cdoss@ncat.edu
CR Ahamed AKC, 2017, ADV ENG SOFTW, V111, P32, DOI 10.1016/j.advengsoft.2016.10.002
   [Anonymous], INTEL SDK OPENCL BES
   [Anonymous], 2018, MICROPROCESS MICROSY, V63
   [Anonymous], 2013, P 50 ANN DES AUT C D
   [Anonymous], 2019, INTEL SDK OPENCL BES
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Choi JW, 2010, ACM SIGPLAN NOTICES, V45, P115, DOI 10.1145/1837853.1693471
   Dave N, 2007, MEMOCODE'07: FIFTH ACM & IEEE INTERNATIONAL CONFERENCE ON FORMAL METHODS AND MODELS FOR CO-DESIGN, PROCEEDINGS, P97, DOI 10.1109/MEMCOD.2007.371239
   Elkurdi Y, 2008, COMPUT PHYS COMMUN, V178, P558, DOI 10.1016/j.cpc.2007.11.014
   Hans C, 2009, BIOMETRIKA, V96, P835, DOI 10.1093/biomet/asp047
   I. f. s. f. o. Intel Corporation, PROGRAMMING GUIDE UG
   Im E.-J., 1999, PPSC
   Jang JW, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P93, DOI 10.1109/FPT.2002.1188669
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Naher J., IN PRESS
   Patel S., 2017, MACH LEARN, V101
   PONDER JW, 1987, J COMPUT CHEM, V8, P1016, DOI 10.1002/jcc.540080710
   Roozmeh M, 2018, MICROPROCESS MICROSY, V63, P199, DOI 10.1016/j.micpro.2018.09.009
   Sanderson C, 2019, MATH COMPUT APPL, V24, DOI 10.3390/mca24030070
   Schafer BC, 2017, ACM T DES AUTOMAT EL, V22, DOI 10.1145/3041219
   Schlick T, 2010, INTERD APPL MATH, V21, P345, DOI 10.1007/978-1-4419-6351-2_11
   Sedaghati N, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P99, DOI 10.1145/2751205.2751244
   Sengupta A, 2017, IEEE T COMPUT AID D, V36, P655, DOI 10.1109/TCAD.2016.2597232
   Sheng K, 2009, PROC INT SYMP POWER, P255, DOI 10.1109/ISPSD.2009.5158050
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Weller D, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P247, DOI 10.1145/3020078.3021730
   Xiao GQ, 2021, IEEE T PARALL DISTR, V32, P131, DOI 10.1109/TPDS.2019.2907537
   Yan SG, 2014, ACM SIGPLAN NOTICES, V49, P107, DOI [10.1145/2692916.2555255, 10.1145/2555243.2555255]
NR 30
TC 0
Z9 0
U1 0
U2 1
PY 2020
DI 10.1109/southeastcon44009.2020.9249711
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Yu, Y
   Jha, NK
AF Yu, Ye
   Jha, Niraj K.
TI SPRING: A Sparsity-Aware Reduced-Precision Monolithic 3D CNN Accelerator
   Architecture for Training and Inference
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Training; Computer architecture; Three-dimensional displays; Bandwidth;
   Springs; Acceleration; Neurons; Convolutional neural network; deep
   learning; hardware accelerator; IC design; inference; reduced precision;
   sparsity; stochastic rounding; training
ID MODEL
AB Convolutional neural networks (CNNs) outperform traditional machine learning algorithms across a wide range of applications, such as object recognition, image segmentation, and autonomous driving. However, their ever-growing computational complexity makes it necessary to design efficient hardware accelerators. Most CNN accelerators focus on exploring various dataflow styles and designs that exploit computational parallelism. However, potential performance improvement (speedup) from sparsity has not been adequately addressed. The computation and memory footprint of CNNs can be significantly reduced if sparsity is exploited in network evaluations. To further improve performance and energy efficiency, some accelerators evaluate CNNs with limited precision. However, this is limited to the inference phase since reduced precision sacrifices network accuracy if used in training. In addition, CNN evaluation is usually memory-intensive, especially during training. The performance bottleneck arises from the fact that the memory cannot feed the computational units enough data, resulting in idling of these computational units and thus low utilization ratios. In this article, we propose SPRING, a SParsity-aware Reduced-precision Monolithic 3D CNN accelerator for trainING and inference. SPRING supports both CNN training and inference. It uses a binary mask scheme to encode sparsities in activations and weights. It uses the stochastic rounding algorithm to train CNNs with reduced precision without accuracy loss. To alleviate the memory bottleneck in CNN evaluation, especially during training, SPRING uses an efficient monolithic 3D nonvolatile memory interface to increase memory bandwidth. Compared to Nvidia GeForce GTX 1080 Ti, SPRING achieves 15.6x, 4.2x, and 66.0x improvements in performance, power reduction, and energy efficiency, respectively, for CNN training, and 15.5x, 4.5x, and 69.1x improvements in performance, power reduction, and energy efficiency, respectively, for inference.
C1 [Yu, Ye; Jha, Niraj K.] Princeton Univ, Dept Elect Engn, Princeton, NJ 08540 USA.
RP Yu, Y (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08540 USA.
EM yeyu@princeton.edu
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2015, HIGH BANDW MEM
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee C., 2018, P C SYST MACH LEARN
   Lin CY, 2018, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2018.8297290
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Muralimanohar N., 2009, HP LAB
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Poremba M, 2015, IEEE COMPUT ARCHIT L, V14, P140, DOI 10.1109/LCA.2015.2402435
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Roy Jarrod A., 2005, IEEE INT S PHYS DES, P224
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarhan H, 2015, IEEE INT 3D SYST
   Shafaei A, 2014, IEEE COMP SOC ANN, P291, DOI 10.1109/ISVLSI.2014.94
   Simonyan K, 2015, P 3 INT C LEARN REPR
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   WILLIAMSON D, 1991, IEEE PACIF, P315, DOI 10.1109/PACRIM.1991.160742
   Xiang TR, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P243, DOI 10.1109/HPCC/SmartCity/DSS.2018.00063
   Yu Y, 2021, IEEE T COMPUT, V70, P45, DOI 10.1109/TC.2020.2983694
   Yu Y, 2018, IEEE T MULTI-SCALE C, V4, P533, DOI 10.1109/TMSCS.2018.2882433
   Yu Y, 2018, IEEE T NANOTECHNOL, V17, P620, DOI 10.1109/TNANO.2017.2731871
   Zhang JQ, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P292, DOI 10.1145/3307650.3322263
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhu JY, 2018, DES AUT TEST EUROPE, P241, DOI 10.23919/DATE.2018.8342010
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 44
TC 8
Z9 8
U1 1
U2 5
PD JAN 1
PY 2022
VL 10
IS 1
BP 237
EP 249
DI 10.1109/TETC.2020.3003328
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT J
AU Fujita, K
AF Fujita, Kazuhiro
TI Electromagnetic field computation of multilayer vacuum chambers with
   physics-informed neural networks
SO FRONTIERS IN PHYSICS
DT Article
DE deep learning; machine learning; neural network; electromagnetic field;
   resistive-wall wakefield; charged particle
ID PIPE
AB The electromagnetic interaction of a charged particle beam with multilayer vacuum chambers is of particular interest in accelerator physics. This paper presents a deep learning-based approach for calculating electromagnetic fields generated by the beam in infinitely long multilayer vacuum chambers with arbitrary cross section. The presented approach is based on physics-informed neural networks and the surface impedance boundary condition of a multilayer structure derived from the transmission line theory. Deep neural networks (DNNs) are utilized to approximate the solution of partial differential equations (PDEs) describing the physics of electromagnetic fields self-generated by a charged particle beam traveling in a particle accelerator. A residual network is constructed from the output of DNNs, the PDEs and boundary conditions are embedded into the loss function and differential operators are calculated using the automatic differentiation. As a result, the presented approach is regarded to be mesh-free. The approach is applied to circular and elliptical vacuum chambers with a three-layer structure. It is verified in comparison with the recently proposed boundary element method. The effects of chamber geometries and multilayer structure on the beam coupling impedance are demonstrated.
C1 [Fujita, Kazuhiro] Saitama Inst Technol, Dept Informat Syst, Saitama, Japan.
RP Fujita, K (corresponding author), Saitama Inst Technol, Dept Informat Syst, Saitama, Japan.
EM kfujita@sit.ac.jp
CR Aggarwal CC., 2018, SPRINGER, DOI DOI 10.1007/978-3-319-94463-0
   Al-khateeb AM, 2001, PHYS REV E, V63, DOI 10.1103/PhysRevE.63.026503
   [Anonymous], 2012, CLASSICAL ELECTRODYN
   [Anonymous], 2000, 2000011 CERN
   Bane KLF., 2005, P 2005 PART ACC C, P3390
   Burov A., 2002, 8th European Particle Accelerator Conference, P1452
   Chao A.W., 1993, PHYS COLLECTIVE BEAM
   Doliwa B, 2007, PHYS REV SPEC TOP-AC, V10, DOI 10.1103/PhysRevSTAB.10.102001
   Fujita K, 2022, PHYS REV ACCEL BEAMS, V25, DOI 10.1103/PhysRevAccelBeams.25.064601
   Fujita K, 2022, ELECTRON LETT, V58, P390, DOI 10.1049/ell2.12469
   Fujita K, 2021, IEEE ACCESS, V9, P164017, DOI 10.1109/ACCESS.2021.3132942
   Fujita K, 2017, IEEE J MULTISCALE MU, V2, P237, DOI 10.1109/JMMCT.2017.2786864
   GLUCKSTERN RL, 1993, PHYS REV E, V47, P656, DOI 10.1103/PhysRevE.47.656
   Henke H., 1990, PROC 2 EUROPEAN PART, P1046
   Ivanyan M, 2008, PHYS REV SPEC TOP-AC, V11, DOI 10.1103/PhysRevSTAB.11.084001
   Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Macridin A, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.061003
   Migliorati M, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.121001
   MORTON PL, 1966, J APPL PHYS, V37, P3875, DOI 10.1063/1.1707941
   Mounet N., 2010, P 46 ICFA ADV BEAM D, P353
   Ng KY., 2006, PHYS INTENSITY DEPEN
   Niedermayer U, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.032001
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Ramachandran P, 2018, SEARCHING ACTIVATION
   Senior T. B. A., 1995, APPROXIMATE BOUNDARY
   Stupakov G, 2018, GRAD TEXTS PHYS, P1, DOI 10.1007/978-3-319-90188-6
   Stupakov G, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.094401
   Vos L, 2003, CERNAB2003093
   Zimmermann F, 2004, PHYS REV SPEC TOP-AC, V7, DOI 10.1103/PhysRevSTAB.7.044201
   Zotter B., 1970, Particle Accelerators, V1, P311
   Zotter B., 2005, CERNAB2005043
   Zotter BW, 1998, IMPEDANCES WAKES HIG
NR 33
TC 2
Z9 2
U1 8
U2 16
PD OCT 3
PY 2022
VL 10
AR 967645
DI 10.3389/fphy.2022.967645
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Lee, S
   Yu, H
   Yang, H
   Song, I
   Choi, J
   Yang, J
   Lim, G
   Kim, KS
   Choi, B
   Kwon, J
AF Lee, SeonWoo
   Yu, HyeonTak
   Yang, HoJun
   Song, InSeo
   Choi, JungMu
   Yang, JaeHeung
   Lim, GangMin
   Kim, Kyu-Sung
   Choi, ByeongKeun
   Kwon, JangWoo
TI A Study on Deep Learning Application of Vibration Data and Visualization
   of Defects for Predictive Maintenance of Gravity Acceleration Equipment
SO APPLIED SCIENCES-BASEL
DT Article
DE artificial intelligence; deep learning; fault detection; hyper-gravity
   machine; vibration monitoring
ID FAULT-DETECTION; ROTATING MACHINERY; DIAGNOSIS; AUTOENCODER; NETWORK;
   MODEL
AB Hypergravity accelerators are a type of large machinery used for gravity training or medical research. A failure of such large equipment can be a serious problem in terms of safety or costs. This paper proposes a prediction model that can proactively prevent failures that may occur in a hypergravity accelerator. An experiment was conducted to evaluate the performance of the method proposed in this paper. A 4-channel accelerometer was attached to the bearing housing, which is a rotor, and time-amplitude data were obtained from the measured values by sampling. The method proposed in this paper was trained with transfer learning, a deep learning model that replaced the VGG19 model with a Fully Connected Layer (FCL) and Global Average Pooling (GAP) by converting the vibration signal into a short-time Fourier transform (STFT) or Mel-Frequency Cepstral Coefficients (MFCC) spectrogram and converting the input into a 2D image. As a result, the model proposed in this paper has seven times decreased trainable parameters of VGG19, and it is possible to quantify the severity while looking at the defect areas that cannot be seen with 1D.
C1 [Lee, SeonWoo; Yang, HoJun; Song, InSeo; Choi, JungMu; Kwon, JangWoo] Inha Univ, Deparment Elect Comp Engn, 100 Inha Ro, Incheon 22201, South Korea.
   [Yu, HyeonTak; Choi, ByeongKeun] Gyeongsang Natl Univ, Dept Energy & Mech Engn, 38 Cheondaegukchi Gil, Tongyeong Si 53064, South Korea.
   [Yang, JaeHeung; Lim, GangMin] ATG, R&D Ctr, Seongnam Si 13558, South Korea.
   [Kim, Kyu-Sung] Inha Univ, Coll Med, Inha Res Inst Aerosp Med, Dept Otolaryngol Head & Neck Surg, 3-Ga Shinheungdong, Incheon 400711, South Korea.
RP Kwon, J (corresponding author), Inha Univ, Deparment Elect Comp Engn, 100 Inha Ro, Incheon 22201, South Korea.
EM x21999@inha.edu; take754@gnu.ac.kr; hjyang@inha.edu;
   songis0823@inha.edu; cmj4788@inha.edu; redmeka@atg.co.kr;
   lgm421@atg.ac.kr; stedman@inha.ac.kr; bgchoi@gnu.ac.kr;
   jwkwon@inha.ac.kr
CR Abdelgayed TS, 2018, IEEE T IND ELECTRON, V65, P1595, DOI 10.1109/TIE.2017.2726961
   [Anonymous], 2015, FUNDAMENTALS MUSIC P
   Buitinck L., 2013, ARXIV, V1309
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Eren L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/8617315
   GUROVSKY NN, 1980, ACTA ASTRONAUT, V7, P113, DOI 10.1016/0094-5765(80)90122-8
   Hasan MJ, 2019, MEASUREMENT, V138, P620, DOI 10.1016/j.measurement.2019.02.075
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XH, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2957083
   Ince T, 2016, IEEE T IND ELECTRON, V63, P7067, DOI 10.1109/TIE.2016.2582729
   Jang T.Y., 2018, J AEROSP ENV MED, V28, P8
   Jiao JY, 2019, IEEE T IND ELECTRON, V66, P9858, DOI 10.1109/TIE.2019.2902817
   Khlaief A, 2019, PROCEEDINGS OF THE 2019 IEEE 12TH INTERNATIONAL SYMPOSIUM ON DIAGNOSTICS FOR ELECTRICAL MACHINES, POWER ELECTRONICS AND DRIVES (SDEMPED), P384, DOI 10.1109/DEMPED.2019.8864899
   Kim IS, 2016, SOL ENERGY, V126, P137, DOI 10.1016/j.solener.2016.01.005
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Le V, 2020, IEEE T POWER ELECTR, V35, P7826, DOI 10.1109/TPEL.2020.2969561
   Lee WK, 2020, INT J PRECIS ENG MAN, V21, P1065, DOI 10.1007/s12541-020-00324-w
   Li C, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060895
   Liu RN, 2018, MECH SYST SIGNAL PR, V108, P33, DOI 10.1016/j.ymssp.2018.02.016
   Loshchilov I., 2016, ARXIV
   McClellan J., 2003, SIGNAL PROCESSING 1
   McFee B., 2015, P 14 PYTH SCI C, V14, P18
   Mellit A, 2018, RENEW SUST ENERG REV, V91, P1, DOI 10.1016/j.rser.2018.03.062
   Meng Z, 2018, MEASUREMENT, V130, P448, DOI 10.1016/j.measurement.2018.08.010
   MUSZYNSKA A, 1995, CHAOS SOLITON FRACT, V5, P1683, DOI 10.1016/0960-0779(94)00171-L
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Redmon J., 2016, ARXIV160207360, P779
   Riaz S., 2017, ASIA PACIFIC J MULTI, V5, P103
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Shao HD, 2018, MECH SYST SIGNAL PR, V100, P743, DOI 10.1016/j.ymssp.2017.08.002
   Shao HD, 2017, MECH SYST SIGNAL PR, V95, P187, DOI 10.1016/j.ymssp.2017.03.034
   Shao HD, 2017, KNOWL-BASED SYST, V119, P200, DOI 10.1016/j.knosys.2016.12.012
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohaib M, 2018, SHOCK VIB, V2018, DOI 10.1155/2018/2919637
   Song LY, 2018, IEEE T INSTRUM MEAS, V67, P1887, DOI 10.1109/TIM.2018.2806984
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tax DMJ, 1999, LECT NOTES COMPUT SC, V1642, P415
   Verstraete D, 2017, SHOCK VIB, V2017, DOI 10.1155/2017/5067651
   Wang SB, 2011, MECH SYST SIGNAL PR, V25, P1299, DOI 10.1016/j.ymssp.2010.10.013
   Wang YL, 2019, INT J REFRIG, V102, P159, DOI 10.1016/j.ijrefrig.2019.03.008
   Wen L, 2018, IEEE T IND ELECTRON, V65, P5990, DOI 10.1109/TIE.2017.2774777
   XU M, 1994, J SOUND VIB, V176, P663, DOI 10.1006/jsvi.1994.1405
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yang CZ, 2019, RENEW ENERG, V133, P433, DOI 10.1016/j.renene.2018.10.062
   Yi ZH, 2017, IEEE T IND ELECTRON, V64, P8546, DOI 10.1109/TIE.2017.2703681
   Yoo YJ, 2019, INT J CONTROL AUTOM, V17, P2125, DOI 10.1007/s12555-018-0758-6
   Zhang H, 2019, APPL THERM ENG, V160, DOI 10.1016/j.applthermaleng.2019.114098
   Zhang ZY, 2014, ADV MANUF, V2, P70, DOI 10.1007/s40436-014-0061-6
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 49
TC 10
Z9 10
U1 3
U2 18
PD FEB
PY 2021
VL 11
IS 4
AR 1564
DI 10.3390/app11041564
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT C
AU Cho, BY
   Jung, J
   Erez, M
AF Cho, Benjamin Y.
   Jung, Jeageun
   Erez, Mattan
GP ASSOC COMPUTING MACHINERY
TI Accelerating Bandwidth -Bound Deep Learning Inference with Main -Memory
   Accelerators
SO SC21: INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING,
   NETWORKING, STORAGE AND ANALYSIS
SE International Conference for High Performance Computing Networking
   Storage and Analysis
DT Proceedings Paper
CT International Conference for High Performance Computing, Networking,
   Storage and Analysis (SC21)
CY NOV 14-19, 2021
CL St. Louis, MO
AB Matrix-matrix multiplication operations (GEMMs) are important in many HPC and machine -learning applications. They are often mapped to discrete accelerators (e.g., GPUs) to improve performance. However, we find that large tall/skinny and fat/short matrices benefit little from discrete acceleration and also do not perform well on a CPU. Such matrices are prevalent in important workloads, such as deep -learning inference within large-scale datacenters. We demonstrate the large potential of accelerating these GEMMs with processing in the main CPU memory, where processing in memory units (PIMs) take advantage of otherwise untapped bandwidth without requiring data copies. We develop a novel GEMM execution flow and corresponding memory-side address -generation logic that exploits GEMM locality and enables long-running PIM kernels despite the complex address -mapping functions employed by the CPU. Our evaluation of StepStone variants at the channel, device, and within-device PIM levels demonstrate 12x better minimum latency than a CPU and 2.8x greater throughput for strict query latency constraints. End-to -end performance analysis of recent recommendation and language models shows that StepStone outperforms a fast CPU by up to 16x and also the best prior main-memory acceleration approaches by up to 2.4x.
C1 [Cho, Benjamin Y.; Jung, Jeageun; Erez, Mattan] Univ Texas Austin, Austin, TX 78712 USA.
   [Cho, Benjamin Y.] AMD Res, Santa Clara, CA 95054 USA.
RP Cho, BY (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.; Cho, BY (corresponding author), AMD Res, Santa Clara, CA 95054 USA.
EM bjcho@utexas.edu; jeageunjung@utexas.edu; mattan.erez@utexas.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Alian M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P802, DOI [10.1109/MICR0.2018.00070, 10.1109/MICRO.2018.00070]
   [Anonymous], 2020, BASIC LINEAR ALGEBRA
   [Anonymous], NVIDIA CUTLASS V22
   [Anonymous], 2020, INTEL ONEDNN V17
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cho BY, 2020, ANN I S COM, P818, DOI 10.1109/ISCA45697.2020.00072
   Deng Q, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317845
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Draper J., 2002, Conference Proceedings of the 2002 International Conference on SUPERCOMPUTING, P14, DOI 10.1145/514191.514197
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Gu P, 2020, ANN I S COM, P804, DOI 10.1109/ISCA45697.2020.00071
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Hall M., 1999, SC 99, P57
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Joardar BK, 2019, DES AUT TEST EUROPE, P522, DOI [10.23919/date.2019.8714802, 10.23919/DATE.2019.8714802]
   Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070
   Kim B, 2020, IEEE T COMPUT, V69, P955, DOI 10.1109/TC.2020.2984496
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim K., 2017, P INT C HIGH PERFORM, P1
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Liu YX, 2018, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2018.00024
   Long Y, 2018, IEEE T VLSI SYST, V26, P2781, DOI 10.1109/TVLSI.2018.2819190
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/DATE.2019.8715178, 10.23919/date.2019.8715178]
   Lym Sangkug, 2019, PROC MACH LEARN SYST, V1, P264
   Mao HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P669, DOI [10.1109/MICRO.2018.00060, 10.1109/MICR0.2018.00060]
   Moghaddam H. A., 2016, INT S MICROARCHITECT, P1
   Muralimanohar N., 2009, HP LAB
   Naumov Maxim, 2019, ARXIV
   Nishtala R, 2020, INT S HIGH PERF COMP, P167, DOI 10.1109/HPCA47549.2020.00023
   Panda R, 2018, INT S HIGH PERF COMP, P271, DOI 10.1109/HPCA.2018.00032
   Park J, 2018, Arxiv, DOI arXiv:1811.09886
   Pessl P, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P565
   Qin Eric, 2020, INT S HIGH PERF COMP
   Radford A., 2019, OPENAI BLOG
   Rakin AS, 2018, PR IEEE COMP DESIGN, P266, DOI 10.1109/ICCD.2018.00048
   Rivera Cody, ISM2 OPTIMIZING IRRE
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sterling T. L., 2002, P ACM IEEE C SUP NOV, P48, DOI DOI 10.1109/SC.2002.10061
   Sura Z., 2015, P 12 ACM INT C COMP, P1
   Van Zee FG, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2764454
   Zhu HS, 2019, INT S HIGH PERF COMP, P172, DOI 10.1109/HPCA.2019.00036
NR 53
TC 2
Z9 2
U1 0
U2 0
PY 2021
DI 10.1145/3458817.3476146
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Peserico, N
   de Lima, TF
   Prucnal, P
   Sorger, VJ
AF Peserico, Nicola
   de Lima, Thomas Ferreira
   Prucnal, Paul
   Sorger, Volker J.
TI Emerging devices and packaging strategies for electronic-photonic AI
   accelerators: opinion
SO OPTICAL MATERIALS EXPRESS
DT Article
AB The field of mimicking the structure of the brain on a chip is experiencing interest driven by the demand for machine intelligent applications. However, the power consumption and available performance of machine-learning (ML) accelerating hardware still leave much desire for improvement. In this letter, we share viewpoints, challenges, and prospects of electronic-photonic neural network (NN) accelerators. Combining electronics with photonics offers synergistic co-design strategies for high-performance AI Application-specific integrated circuits (ASICs) and systems. Taking advantages of photonic signal processing capabilities and combining them with electronic logic control and data storage is an emerging prospect. However, the optical component library leaves much to be desired and is challenged by the enormous size of photonic devices. Within this context, we will review the emerging electro-optic materials, functional devices, and systems packaging strategies that, when realized, provide significant performance gains and fuel the ongoing AI revolution, leading to a stand-alone photonics-inside AI ASIC 'black-box' for streamlined plug-and-play board integration in future AI processors. (c) 2022 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement
C1 [Peserico, Nicola; Sorger, Volker J.] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [de Lima, Thomas Ferreira] NEC Labs Amer Inc, Princeton, NJ 08540 USA.
   [de Lima, Thomas Ferreira; Prucnal, Paul] Princeton Univ, Dept Elect & Comp Engn, Princeton, NJ 08544 USA.
RP Sorger, VJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
EM sorger@gwu.edu
CR Amin R, 2021, APL PHOTONICS, V6, DOI 10.1063/5.0062830
   Amin R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80381-3
   Amin R, 2020, OPTICA, V7, P333, DOI 10.1364/OPTICA.389437
   Chrostowski L, 2015, SILICON PHOTONICS DESIGN, P1
   de Lima TF, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2931252
   Fei Y, 2020, IEEE T INTELL TRANSP, V21, P273, DOI 10.1109/TITS.2019.2891167
   Filipovich M. J., 2021, ARXIV PREPRINT ARXIV
   Gharaibeh A., PSYARXIV, V13, P58, DOI [DOI 10.31234/OSF.IO/DR9Q3, 10.1016/j.amjms.2021.03.001,00089-6, DOI 10.1016/J.AMJMS.2021.03.001,00089-6, DOI 10.1007/S11270-007-9372-6]
   Green WMJ, 2007, OPT EXPRESS, V15, P17106, DOI 10.1364/OE.15.017106
   Li X, 2019, OPTICA, V6, P1, DOI 10.1364/OPTICA.6.000001
   Liang D, 2018, OPT FIBER TECHNOL, V44, P43, DOI 10.1016/j.yofte.2017.12.005
   Lindenmann N, 2012, OPT EXPRESS, V20, P17667, DOI 10.1364/OE.20.017667
   Margalit N, 2021, APPL PHYS LETT, V118, DOI 10.1063/5.0050117
   Miscuglio M, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0001942
   Rios C., 2021, ARXIV PREPRINT ARXIV
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   SOREF RA, 1987, IEEE J QUANTUM ELECT, V23, P123, DOI 10.1109/JQE.1987.1073206
   Tait AN, 2018, OPT EXPRESS, V26, P26422, DOI 10.1364/OE.26.026422
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Thiessen T, 2020, J LIGHTWAVE TECHNOL, V38, P3000, DOI 10.1109/JLT.2020.2978413
   Vermeulen D, 2018, P IEEE, V106, P2270, DOI 10.1109/JPROC.2018.2865725
   Xu PP, 2019, ACS PHOTONICS, V6, P553, DOI 10.1021/acsphotonics.8b01628
   Zhang CP, 2020, PHOTONICS RES, V8, P1171, DOI 10.1364/PRJ.393513
   Zhang J., 2019, PROC 45 EUR C OPT CO, P1
NR 25
TC 13
Z9 13
U1 0
U2 7
PD APR 1
PY 2022
VL 12
IS 4
BP 1347
EP 1351
DI 10.1364/OME.451802
WC Materials Science, Multidisciplinary; Optics
DA 2023-11-11
ER

PT C
AU Serio, L
   Antonello, F
   Baraldi, P
   Castellano, A
   Gentile, U
   Zio, E
AF Serio, L.
   Antonello, F.
   Baraldi, P.
   Castellano, A.
   Gentile, U.
   Zio, E.
GP IOP
TI A smart framework for the availability and reliability assessment and
   management of accelerators technical facilities
SO 9TH INTERNATIONAL PARTICLE ACCELERATOR CONFERENCE (IPAC18)
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 9th International Particle Accelerator Conference (IPAC)
CY APR 29-MAY 04, 2018
CL Triumf Lab, Vancouver, CANADA
HO Triumf Lab
ID SUPPORT VECTOR MACHINE
AB CERN operates and maintains a large and complex technical infrastructure that serves the accelerator complex and experiments detectors. A performance assessment and enhancement framework based on data mining, artificial intelligence and machine-learning algorithms is under development with the objective of structuring, collecting and analysing the operation and failure data of the systems and equipment, to guide the identification and implementation of adequate corrective, preventive and consolidation interventions. The framework is designed to collect and structure the data and identify and analyse the associated driving events. It develops dynamically functional dependencies and logic trees, descriptive and predictive models to support operation and maintenance activities to improve the reliability and availability of the installations. To validate the performance of the framework and quality of the algorithms, several case studies are being carried out. In this paper, we report on the design and implementation of the performance assessment and enhancement framework, and on the preliminary results inferred on historical and live stream data from CERN's technical infrastructure. Proposals for the full deployment and expected long-term capabilities will also be discussed.
C1 [Serio, L.; Gentile, U.] ICERN, CH-1211 Geneva 23, Switzerland.
   [Antonello, F.; Baraldi, P.; Castellano, A.; Zio, E.] Politecn Milan, I-20100 Milan, Italy.
RP Serio, L (corresponding author), ICERN, CH-1211 Geneva 23, Switzerland.
EM luigi.serio@cern.ch
CR [Anonymous], 1996, MINING SEQUENTIAL PA, DOI [DOI 10.1145/235968.233311, 10.1007/BFb0014140]
   Baixeries J., 2007, THESIS
   Banerjee SG, 2011, POWER AND PEOPLE: THE BENEFITS OF RENEWABLE ENERGY IN NEPAL, P112
   Farajzadeh S, 2016, 2016 RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS, P7, DOI 10.1145/2987386.2987405
   Gentile U., 2017, 1 INT C EL ENG C SCI
   Gryllias KC, 2012, ENG APPL ARTIF INTEL, V25, P326, DOI 10.1016/j.engappai.2011.09.010
   Hui CY, 2005, LECT NOTES COMPUT SC, V3399, P405
   NRC Nuclear Regulatory Commission, 1983, PROB RISK AN PROC GU
   Rinaldi S. M., 2001, IEEE CONTROL SYSTEMS, V21
   Todd B., 2017, CERNACCNOTE20170063
   Zhu KH, 2014, MEASUREMENT, V47, P669, DOI 10.1016/j.measurement.2013.09.019
NR 11
TC 3
Z9 4
U1 2
U2 2
PY 2018
VL 1067
AR 072029
DI 10.1088/1742-6596/1067/7/072029
WC Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Kang, MG
   Gonugondla, SK
   Patil, A
   Shanbhag, NR
AF Kang, Mingu
   Gonugondla, Sujan K.
   Patil, Ameya
   Shanbhag, Naresh R.
TI A Multi-Functional In-Memory Inference Processor Using a Standard 6T
   SRAM Array
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Accelerator; analog processing; associative memory; in-memory
   processing; inference; machine learning (ML)
ID ENERGY-EFFICIENT; MACHINE; DESIGN
AB A multi-functional in-memory inference processor integrated circuit (IC) in a 65-nm CMOS process is presented. The prototype employs a deep in-memory architecture (DIMA), which enhances both energy efficiency and throughput over conventional digital architectures via simultaneous access of multiple rows of a standard 6T bitcell array (BCA) per precharge, and embedding column pitch-matched low-swing analog processing at the BCA periphery. In doing so, DIMA exploits the synergy between the dataflow of machine learning (ML) algorithms and the SRAMarchitecture to reduce the dominant energy cost due to data movement. The prototype IC incorporates a 16-kB SRAM array and supports four commonly used ML algorithms-the support vector machine, template matching, k-nearest neighbor, and the matched filter. Silicon measured results demonstrate simultaneous gains (dot product mode) in energy efficiency of 10x and in throughput of 5.3x leading to a 53x reduction in the energy-delay product with negligible (<= 1%) degradation in the decision-making accuracy, compared with the conventional 8-b fixed-point single-function digital implementations.
C1 [Kang, Mingu; Gonugondla, Sujan K.; Patil, Ameya; Shanbhag, Naresh R.] Univ Illinois, Coordinated Sci Lab, Champaign, IL 61801 USA.
RP Kang, MG (corresponding author), Univ Illinois, Coordinated Sci Lab, Champaign, IL 61801 USA.
EM mkang17@illinois.edu; gonugon2@illinois.edu; adpatil2@illinois.edu;
   shanbhag@illinois.edu
CR [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   [Anonymous], 2007, P IEEE INT SOL STAT
   Arnaud F., 2003, 2003 Symposium on VLSI Technology. Digest of Technical Papers (IEEE Cat. No.03CH37407), P65, DOI 10.1109/VLSIT.2003.1221088
   Bankman D, 2016, IEEE ASIAN SOLID STA, P21, DOI 10.1109/ASSCC.2016.7844125
   Bong K, 2017, ISSCC DIG TECH PAP I, P248, DOI 10.1109/ISSCC.2017.7870354
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chung S. C., 2015, U.S. Patent, Patent No. [9,183,897 B2, 9183897]
   Crate P., GUN SHOT SOUNDS
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Frustaci F, 2016, IEEE T VLSI SYST, V24, P2128, DOI 10.1109/TVLSI.2015.2503733
   Frustaci F, 2015, IEEE J SOLID-ST CIRC, V50, P1310, DOI 10.1109/JSSC.2015.2408332
   Genov R, 2003, IEEE T NEURAL NETWOR, V14, P1426, DOI 10.1109/TNN.2003.816345
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Kang M., 2016, 481 PJ DECISION 3 4
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kang MG, 2016, IEEE T BIOMED CIRC S, V10, P855, DOI 10.1109/TBCAS.2016.2545402
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kang MG, 2015, IEEE INT SYMP CIRC S, P2505, DOI 10.1109/ISCAS.2015.7169194
   Karl E, 2013, IEEE J SOLID-ST CIRC, V48, P150, DOI 10.1109/JSSC.2012.2213513
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Kim K, 2009, IEEE J SOLID-ST CIRC, V44, P136, DOI 10.1109/JSSC.2008.2007157
   Kuhn KJ, 2007, INT EL DEVICES MEET, P471, DOI 10.1109/IEDM.2007.4418976
   Kulkarni JP, 2007, IEEE J SOLID-ST CIRC, V42, P2303, DOI 10.1109/JSSC.2007.897148
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Murmann B, 2015, 2015 49TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, P1341, DOI 10.1109/ACSSC.2015.7421361
   Oh J, 2013, IEEE J SOLID-ST CIRC, V48, P2894, DOI 10.1109/JSSC.2013.2280238
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhou ZM, 1997, IEEE T ELECTRON DEV, V44, P1759, DOI 10.1109/16.628833
NR 38
TC 128
Z9 133
U1 2
U2 18
PD FEB
PY 2018
VL 53
IS 2
BP 642
EP 655
DI 10.1109/JSSC.2017.2782087
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Brace, A
   Salim, M
   Subbiah, V
   Ma, H
   Emani, M
   Trifa, A
   Clyde, AR
   Adams, C
   Uram, T
   Yoo, H
   Hock, A
   Liu, J
   Vishwanath, V
   Ramanathan, A
AF Brace, Alexander
   Salim, Michael
   Subbiah, Vishal
   Ma, Heng
   Emani, Murali
   Trifa, Anda
   Clyde, Austin R.
   Adams, Corey
   Uram, Thomas
   Yoo, Hyunseung
   Hock, Andew
   Liu, Jessica
   Vishwanath, Venkatram
   Ramanathan, Arvind
GP ACM
TI Stream-AI-MD: Streaming AI-driven Adaptive Molecular Simulations for
   Heterogeneous Computing Platforms
SO PROCEEDINGS OF THE PLATFORM FOR ADVANCED SCIENTIFIC COMPUTING CONFERENCE
   (PASC '21)
DT Proceedings Paper
CT Platform for Advanced Scientific Computing Conference (PASC)
CY JUL 05-09, 2021
CL ELECTR NETWORK
DE Deep learning; accelerators; molecular biophysics; adaptive simulations;
   protein-protein interactions; streaming data analytics
ID PROTEIN; DYNAMICS
AB Emerging hardware tailored for artificial intelligence (AI) and machine learning (ML) methods provide novel means to couple them with traditional high performance computing (HPC) workflows involving molecular dynamics (MD) simulations. We propose StreamAI-MD, a novel instance of applying deep learning methods to drive adaptive MD simulation campaigns in a streaming manner. We leverage the ability to run ensemble MD simulations on GPU clusters, while the data from atomistic MD simulations are streamed continuously to AI/ML approaches to guide the conformational search in a biophysically meaningful manner on a wafer-scale AI accelerator. We demonstrate the efficacy of Stream-AI-MD simulations for two scientific use-cases: (1) folding a small prototypical protein, namely beta beta alpha-fold (BBA) FSD-EY and (2) understanding protein-protein interaction (PPI) within the SARS-CoV-2 proteome between two proteins, nsp16 and nsp10. We show that Stream-AI-MD simulations can improve time-to-solution by similar to 50X for BBA protein folding. Further, we also discuss performance trade-offs involved in implementing AI-coupled HPC workflows on heterogeneous computing architectures.
C1 [Brace, Alexander; Ma, Heng; Trifa, Anda; Clyde, Austin R.; Yoo, Hyunseung; Ramanathan, Arvind] Argonne Natl Lab, Data Sci & Learning, Argonne, IL 60439 USA.
   [Salim, Michael; Emani, Murali; Adams, Corey; Uram, Thomas; Vishwanath, Venkatram] Argonne Natl Lab, Argonne Leadership Comp, Argonne, IL 60439 USA.
   [Subbiah, Vishal; Hock, Andew; Liu, Jessica] Cerebras Syst Inc, Sunnyvale, CA USA.
   [Trifa, Anda] Univ Illinois, Champaign, IL USA.
RP Ramanathan, A (corresponding author), Argonne Natl Lab, Data Sci & Learning, Argonne, IL 60439 USA.; Vishwanath, V (corresponding author), Argonne Natl Lab, Argonne Leadership Comp, Argonne, IL 60439 USA.
CR Bhowmik D, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2507-5
   Bonati L, 2019, P NATL ACAD SCI USA, V116, P17641, DOI 10.1073/pnas.1907975116
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Casalino L, 2021, INT J HIGH PERFORM C, V35, P432, DOI 10.1177/10943420211006452
   Cerebras Systems, 2019, WAF SCAL DEEP LEARN
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Degiacomi MT, 2019, STRUCTURE, V27, P1034, DOI 10.1016/j.str.2019.03.018
   Dhusia K, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10071056
   Doersch Carl., 2016, ARXIVSTATML160605908
   Eastman P, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005659
   Elcock AH, 2001, J PHYS CHEM B, V105, P1504, DOI 10.1021/jp003602d
   Gowers R. J., 2019, MDANALYSIS PYTHON PA, DOI 10.25080/majora-629-541a-00e
   Hernández CX, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.062412
   Husic BE, 2018, J AM CHEM SOC, V140, P2386, DOI 10.1021/jacs.7b12191
   Husic Brooke E., 2020, ARXIVPHYSICSCOMPPH20
   Johnston T, 2017, J COMPUT CHEM, V38, P1419, DOI 10.1002/jcc.24729
   Kasson PM, 2018, CURR OPIN STRUC BIOL, V52, P87, DOI 10.1016/j.sbi.2018.09.005
   Lee H, 2019, PROCEEDINGS OF 2019 IEEE/ACM THIRD WORKSHOP ON DEEP LEARNING ON SUPERCOMPUTERS (DLS), P12, DOI 10.1109/DLS49591.2019.00007
   Lindorff-Larsen K, 2011, SCIENCE, V334, P517, DOI 10.1126/science.1208351
   Lindorff-Larsen K, 2010, PROTEINS, V78, P1950, DOI 10.1002/prot.22711
   Mardt A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02388-1
   Michaud-Agrawal N, 2011, J COMPUT CHEM, V32, P2319, DOI 10.1002/jcc.21787
   Misiura MM, 2020, J PHYS CHEM B, V124, P20, DOI 10.1021/acs.jpcb.9b08793
   Noé F, 2020, LECT NOTES PHYS, V968, P331, DOI 10.1007/978-3-030-40245-7_16
   Noé F, 2020, CURR OPIN STRUC BIOL, V60, P77, DOI 10.1016/j.sbi.2019.12.005
   Noé F, 2019, SCIENCE, V365, P1001, DOI 10.1126/science.aaw1147
   Ohue Masahito, 2020, ARXIVCSDC200608905
   Onufriev A, 2004, PROTEINS, V55, P383, DOI 10.1002/prot.20033
   Pan AC, 2019, P NATL ACAD SCI USA, V116, P4244, DOI 10.1073/pnas.1815431116
   Paul F, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01163-6
   Pudipeddi Bharadwaj, 2020, ARXIVCSLG200205645
   Ramanathan A, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10091308
   Ramanathan A, 2014, ACCOUNTS CHEM RES, V47, P149, DOI 10.1021/ar400084s
   Ramanathan A, 2012, PROTEINS, V80, P2536, DOI 10.1002/prot.24135
   Ribeiro JML, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5025487
   Romero R, 2019, P NATL ACAD SCI USA, V116, P5086, DOI 10.1073/pnas.1818411116
   Rosas-Lemus M, 2020, SCI SIGNAL, V13, DOI 10.1126/scisignal.abe1202
   Salim MA, 2019, PROCEEDINGS OF XLOOP 2019: IEEE/ACM 1ST ANNUAL WORKSHOP ON LARGE-SCALE EXPERIMENT-IN-THE-LOOP COMPUTING (XLOOP), P26, DOI 10.1109/XLOOP49562.2019.00010
   Sarisky CA, 2001, J MOL BIOL, V307, P1411, DOI 10.1006/jmbi.2000.4345
   Sculley D., 2010, P 19 INT C WORLD WID, P1177, DOI [DOI 10.1145/1772690.1772862, 10.1145/1772690.1772862]
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Shamsi Z, 2018, J PHYS CHEM B, V122, P8386, DOI 10.1021/acs.jpcb.8b06521
   Shaw DE, 2014, INT CONF HIGH PERFOR, P41, DOI 10.1109/SC.2014.9
   Shirts MR, 2017, J COMPUT AID MOL DES, V31, P147, DOI 10.1007/s10822-016-9977-1
   Taufer Michela, 2019, 2019 15th International Conference on eScience (eScience). Proceedings, P188, DOI 10.1109/eScience.2019.00027
   Terayama K, 2019, J CHEM PHYS, V151, DOI 10.1063/1.5129551
   van den Burg Gerrit J. J., 2020, ARXIVSTATML200306222
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang YH, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11405-4
   Wriggers W, 2009, J CHEM THEORY COMPUT, V5, P2595, DOI 10.1021/ct900229u
   Zhang J, 2019, J PHYS CHEM LETT, V10, P5791, DOI 10.1021/acs.jpclett.9b02173
   Zhou HX, 2013, CURR OPIN STRUC BIOL, V23, P887, DOI 10.1016/j.sbi.2013.06.014
NR 52
TC 1
Z9 1
U1 2
U2 5
PY 2021
DI 10.1145/3468267.3470578
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Andri, R
   Cavigelli, L
   Rossi, D
   Benini, L
AF Andri, Renzo
   Cavigelli, Lukas
   Rossi, Davide
   Benini, Luca
TI Hyperdrive: A Multi-Chip Systolically Scalable Binary-Weight CNN
   Inference Engine
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Hardware accelerator; neural network hardware; binary-weight neural
   networks; Internet of Things; systolic arrays; application specific
   integrated circuits
ID ARCHITECTURE
AB Deep neural networks have achieved impressive results in computer vision and machine learning. Unfortunately, state-of-the-art networks are extremely compute and memory intensive, which makes them unsuitable for mW-devices such as loT end-nodes. Aggressive quantization of these networks dramatically reduces the computation and memory footprint. Binary-weight neural networks (BWNs) follow this trend, pushing weight quantization to the limit. Hardware accelerators for BWNs presented up to now have focused on core efficiency, disregarding I/O bandwidth, and system-level efficiency that are crucial for the deployment of accelerators in ultra-low power devices. We present Hyperdrive: a BWN accelerator dramatically reducing the I/O bandwidth exploiting a novel binary-weight streaming approach, which can he used for an arbitrarily sized convolutional neural network architecture and input resolution by exploiting the natural scalability of the compute units both at chip-level and system-level by arranging Hyperdrive chips systolically in a 2D mesh while processing the entire feature map together in parallel. Hyperdrive achieves 4.3 TOp/s/W system-level efficiency (i.e., including I/Os)-3.1 x higher than state-of-the-art BWN accelerators, even if its core uses resource-intensive FP16 arithmetic for increased robustness.
C1 [Andri, Renzo; Cavigelli, Lukas; Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab, CH-8092 Zurich, Switzerland.
   [Rossi, Davide; Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn, I-40126 Bologna, Italy.
RP Andri, R (corresponding author), Swiss Fed Inst Technol, Integrated Syst Lab, CH-8092 Zurich, Switzerland.
EM renzo.andri@iis.ee.ethz.ch
CR Aimar A., 2017, NULLHOP FLEXIBLE CON
   Al Bahou A., 2018, XNORBIN 95 TOP S W H
   Andri R, 2018, IEEE COMP SOC ANN, P509, DOI 10.1109/ISVLSI.2018.00099
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2018, GREENWAVES TECHNOLOG
   [Anonymous], 2018, NVIDIA TESL V100 GPU
   [Anonymous], 2018, EE TIMES
   Baraniuk RG, 2011, SCIENCE, V331, P717, DOI 10.1126/science.1197448
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Cavigelli L., 2018, EXTENDED BIT PLANE C
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Cavigelli L, 2017, 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017), P1, DOI 10.1145/3131885.3131906
   Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927
   Cavigelli L, 2016, PROC SPIE, V9997, DOI 10.1117/12.2241383
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Conti F, 2017, IEEE T CIRCUITS-I, V64, P2481, DOI 10.1109/TCSI.2017.2698019
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Das D., 2018, MIXED PRECISION TRAI
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu QH, 2018, LECT NOTES COMPUT SC, V11217, P657, DOI 10.1007/978-3-030-01261-8_39
   Iandola F. N., 2016, ARXIV
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Migacz S., 2017, P GPU TECHN C, V2, P1
   Redmon J., 2016, YOU ONLY LOOK ONCE U, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusci M, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351807
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Scheidegger F, 2017, EUR SIGNAL PR CONF, P996, DOI 10.23919/EUSIPCO.2017.8081357
   Schulz P, 2017, IEEE COMMUN MAG, V55, P70, DOI 10.1109/MCOM.2017.1600435CM
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   Vasilache Nicolas, 2014, ARXIV14127580
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Weddell AS, 2013, DES AUT TEST EUROPE, P905
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou  A., 2017, ARXIV170203044
NR 58
TC 14
Z9 14
U1 0
U2 2
PD JUN
PY 2019
VL 9
IS 2
BP 309
EP 322
DI 10.1109/JETCAS.2019.2905654
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Tang, YH
   Zamani, PT
   Chen, RY
   Ma, JZ
   Qi, MH
   Yu, CX
   Gao, WL
AF Tang, Yingheng
   Zamani, Princess Tara
   Chen, Ruiyang
   Ma, Jianzhu
   Qi, Minghao
   Yu, Cunxi
   Gao, Weilu
TI Device-System End-to-End Design of Photonic Neuromorphic Processor Using
   Reinforcement Learning
SO LASER & PHOTONICS REVIEWS
DT Article
DE end-to-end design; phase change material; photonic neuromorphic
   processors; reinforcement learning
ID PHASE-CHANGE MATERIALS; NEURAL-NETWORKS; PARALLEL
AB The incorporation of high-performance optoelectronic devices into photonic neuromorphic processors can substantially accelerate computationally intensive matrix multiplication operations in machine learning (ML) algorithms. However, the conventional designs of individual devices and system are largely disconnected, and the system optimization is limited to the manual exploration of a small design space. Here, a device-system end-to-end design methodology is reported to optimize a free-space optical general matrix multiplication (GEMM) hardware accelerator by engineering a spatially reconfigurable array made from chalcogenide phase change materials. With a highly parallelized integrated hardware emulator with experimental information, the design of unit device to directly optimize GEMM calculation accuracy is achieved by exploring a large parameter space through reinforcement learning algorithms, including deep Q-learning neural network, Bayesian optimization, and their cascaded approach. The algorithm-generated physical quantities show a clear correlation between system performance metrics and device specifications. Furthermore, physics-aware training approaches are employed to deploy optimized hardware to the tasks of image classification, materials discovery, and a closed-loop design of optical ML accelerators. The demonstrated framework offers insights into the end-to-end and co-design of optoelectronic devices and systems with reduced human supervision and domain knowledge barriers.
C1 [Tang, Yingheng; Zamani, Princess Tara; Chen, Ruiyang; Yu, Cunxi; Gao, Weilu] Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
   [Tang, Yingheng; Qi, Minghao] Purdue Univ, Elmore Family Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Tang, Yingheng; Qi, Minghao] Purdue Univ, Birck Nanotechnol Ctr, W Lafayette, IN 47907 USA.
   [Ma, Jianzhu] Purdue Univ, Birck Nanotechnol Ctr, W Lafayette, IN 47907 USA.
RP Yu, CX; Gao, WL (corresponding author), Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
EM cunxi.yu@utah.edu; weilu.gao@utah.edu
CR Benea-Chelmus IC, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30451-z
   BOCKER RP, 1974, APPL OPTICS, V13, P1670, DOI 10.1364/AO.13.001670
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2
   Cai WS, 2009, NANO LETT, V9, P4403, DOI 10.1021/nl902701b
   Chen RY, 2022, LASER PHOTONICS REV, V16, DOI 10.1002/lpor.202200348
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Fan J., 2022, ARXIV
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Fujimoto S, 2018, PR MACH LEARN RES, V80
   Gao WL, 2021, ADV PHOTON RES, V2, DOI 10.1002/adpr.202100048
   Goi E, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-021-00483-z
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodman J.W., 2005, INTRO FOURIER OPTICS
   GOODMAN JW, 1978, OPT LETT, V2, P1, DOI 10.1364/OL.2.000001
   Haastrup S, 2018, 2D MATER, V5, DOI 10.1088/2053-1583/aacfc1
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   Hosseini P, 2014, NATURE, V511, P206, DOI 10.1038/nature13487
   Hu MY, 2021, NAT NANOTECHNOL, V16, P466, DOI 10.1038/s41565-020-00836-6
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Huang Z, 2019, NANOSCALE, V11, P21748, DOI 10.1039/c9nr06127d
   Kim YH, 2019, J OPT SOC AM A, V36, pD23, DOI 10.1364/JOSAA.36.000D23
   Lamata L, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8020033
   Le Gallo M, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/ab7794
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li X, 2019, OPTICA, V6, P1, DOI 10.1364/OPTICA.6.000001
   Li YB, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aade3f
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Mengu D, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2921376
   Mennel L, 2020, NATURE, V579, P62, DOI 10.1038/s41586-020-2038-x
   Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w
   NAKANO H, 1985, APPL OPTICS, V24, P4238, DOI 10.1364/AO.24.004238
   Nandakumar SR, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00406
   Ozcariz A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071972
   Pai S., 2022, ARXIV
   Peng C, 2019, OPT EXPRESS, V27, P30669, DOI 10.1364/OE.27.030669
   Qiu CY, 2015, OPT LETT, V40, P4480, DOI 10.1364/OL.40.004480
   Qiu CY, 2012, SCI REP-UK, V2, DOI 10.1038/srep00855
   Raoux S., 2010, PHASE CHANGE MAT SCI
   Raoux S, 2010, CHEM REV, V110, P240, DOI 10.1021/cr900040x
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajedian I, 2019, OPT EXPRESS, V27, P5874, DOI 10.1364/OE.27.005874
   Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Spagnolo M, 2022, NAT PHOTONICS, V16, P318, DOI 10.1038/s41566-022-00973-5
   Spall J, 2022, OPTICA, V9, P803, DOI 10.1364/OPTICA.456108
   Spall J, 2020, OPT LETT, V45, P5752, DOI 10.1364/OL.401675
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang SM, 2018, NAT NANOTECHNOL, V13, P227, DOI 10.1038/s41565-017-0052-4
   Wang TY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-021-27774-8
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Wright LG, 2022, NATURE, V601, P549, DOI 10.1038/s41586-021-04223-6
   Wu CM, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm2956
   Wuttig M, 2017, NAT PHOTONICS, V11, P465, DOI [10.1038/nphoton.2017.126, 10.1038/NPHOTON.2017.126]
   Wuttig M, 2007, NAT MATER, V6, P824, DOI 10.1038/nmat2009
   Zhang YF, 2021, NAT NANOTECHNOL, V16, P661, DOI 10.1038/s41565-021-00881-9
   Zhou TK, 2021, NAT PHOTONICS, V15, P367, DOI 10.1038/s41566-021-00796-w
NR 58
TC 0
Z9 0
U1 13
U2 20
PD FEB
PY 2023
VL 17
IS 2
DI 10.1002/lpor.202200381
EA DEC 2022
WC Optics; Physics, Applied; Physics, Condensed Matter
DA 2023-11-11
ER

PT C
AU Naher, J
   Gloster, C
   Doss, CC
   Jadhav, SS
AF Naher, Jannatun
   Gloster, Clay
   Doss, Christopher C.
   Jadhav, Shrikant S.
BE Charkrabarti, S
   Paul, R
TI Using Machine Learning to Estimate Utilization and Throughput for
   OpenCL-Based Matrix-Vector Multiplication (MVM)
SO 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE
   (CCWC)
DT Proceedings Paper
CT 10th Annual Computing and Communication Workshop and Conference (CCWC)
CY JAN 06-08, 2020
CL Univ Nevada, Las Vegas, CA
HO Univ Nevada
DE Matrix-Vector Multiplication; FPGAs; OpenCL; Machine Learning; Design
   Space Exploration
AB OpenCL is a framework for writing programs that execute across heterogeneous platforms, including FPGAs. OpenCL allows users to write standardized C-like code for the host as well as for the hardware accelerators, thus reducing the programming challenge for FPGAs. Hardware descriptions can be written in OpenCL using different memory access and data partitioning strategies. Matrix-Vector Multiplication (MVM) is the critical computational bottleneck for many System of Linear Equations (SLEs) solvers. The MVM OpenCL kernel can be optimized by varying several design parameters in the OpenCL description, improving hardware performance. To effectively explore the design space, logic synthesis is performed after each iteration of setting design parameters to determine their impact on design area and performance. However, each of these synthesis runs can take multiple hours. Hence, manual design space exploration for a large number of designs is prohibitive. To address this challenge, a prediction of FPGA utilization and throughput can significantly reduce the design time. This paper presents a machine learning-based approach to estimating FPGA utilization and throughput for a given set of design parameter values. It also presents an optimized MVM implementation obtained after compiling, synthesizing, and executing over 100 designs. The Random Forest machine learning algorithm estimates the result and for 175 designs, the average error is .0098%, .0012%, .0039%, .0414%, and 123.21% for estimating Look-up Tables (LUTs), Digital Signal Processors (DSPs), memory bits, RAM blocks and throughput (GFLOPs) respectively.
C1 [Naher, Jannatun; Doss, Christopher C.] North Carolina A&T State Univ, Elect & Comp Engn Dept, Greensboro, NC 27411 USA.
   [Gloster, Clay; Jadhav, Shrikant S.] North Carolina A&T State Univ, Comp Syst Technol Dept, Greensboro, NC USA.
RP Naher, J (corresponding author), North Carolina A&T State Univ, Elect & Comp Engn Dept, Greensboro, NC 27411 USA.
EM jnaher@aggies.ncat.edu; cgloster@ncat.edu; cdoss@ncat.edu;
   ssjadhav@ncat.edu
CR [Anonymous], 2010, IJCSNS
   [Anonymous], 2019, INTEL SDK OPENCL BES
   [Anonymous], 2013, P 50 ANN DES AUT C D
   [Anonymous], MACH LEARN
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Falcao G, 2012, ANN IEEE SYM FIELD P, P224, DOI 10.1109/FCCM.2012.46
   Fang Zhenman, 2018, ARXIV PREPRINT ARXIV
   Gautier QT, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P141, DOI 10.1109/FPT.2016.7929519
   Govindu G, 2005, ERSA'05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON ENGINEERING OF RECONFIGURABLE SYSTEMS AND ALGORITHMS, P137
   Hans C, 2009, BIOMETRIKA, V96, P835, DOI 10.1093/biomet/asp047
   Intel Corporation, INT FPGA SDK OP PROG
   Kestur S, 2012, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2012.12
   Lei GQ, 2016, IEEE T CIRCUITS-II, V63, P473, DOI 10.1109/TCSII.2015.2505998
   Matsumoto K, 2012, 2012 SC COMPANION: HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SCC), P396, DOI 10.1109/SC.Companion.2012.59
   Meng PF, 2016, DES AUT TEST EUROPE, P918
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Patel S., 2017, MACHINE LEARNING 101
   Roozmeh M, 2018, MICROPROCESS MICROSY, V63, P199, DOI 10.1016/j.micpro.2018.09.009
   Schafer BC, 2017, ACM T DES AUTOMAT EL, V22, DOI 10.1145/3041219
   Sengupta A, 2017, IEEE T COMPUT AID D, V36, P655, DOI 10.1109/TCAD.2016.2597232
   Shen JZ, 2018, IEEE INT SYMP CIRC S, DOI [10.1109/ISCAS.2018.8351474, 10.1109/ICOPS35962.2018.9575483]
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
NR 22
TC 1
Z9 1
U1 0
U2 0
PY 2020
BP 365
EP 372
AR 1570613479
DI 10.1109/ccwc47524.2020.9031173
WC Computer Science, Theory & Methods; Telecommunications
DA 2023-11-11
ER

PT J
AU Wang, ZY
   Wu, YT
   Park, Y
   Yoo, S
   Wang, XX
   Eshraghian, JK
   Lu, WD
AF Wang, Ziyu
   Wu, Yuting
   Park, Yongmo
   Yoo, Sangmin
   Wang, Xinxin
   Eshraghian, Jason K.
   Lu, Wei D.
TI PowerGAN: A Machine Learning Approach for Power Side-Channel Attack on
   Compute-in-Memory Accelerators
SO ADVANCED INTELLIGENT SYSTEMS
DT Article; Early Access
DE compute-in-memory; generative adversarial network; machine learning;
   memristor; resistive random-access memory; side-channel attack
ID DESIGN; NOISE
AB Analog compute-in-memory (CIM) systems are promising candidates for deep neural network (DNN) inference acceleration. However, as the use of DNNs expands, protecting user input privacy has become increasingly important. Herein, a potential security vulnerability is identified wherein an adversary can reconstruct the user's private input data from a power side-channel attack even without knowledge of the stored DNN model. An attack approach using a generative adversarial network is developed to achieve high-quality data reconstruction from power leakage measurements. The analyses show that the attack methodology is effective in reconstructing user input data from power leakage of the analog CIM accelerator, even at large noise levels and after countermeasures. To demonstrate the efficacy of the proposed approach, an example of CIM inference of U-Net for brain tumor detection is attacked, and the original magnetic resonance imaging medical images can be successfully reconstructed even at a noise level of 20% standard deviation of the maximum power signal value. This study highlights a potential security vulnerability in emerging analog CIM accelerators and raises awareness of needed safety features to protect user privacy in such systems.
   A potential security vulnerability is identified in analog compute-in-memory systems wherein an adversary can reconstruct the user's private input data from a power side-channel attack even without knowledge of the stored model. A generative adversarial network based attack is shown to achieve high-quality data reconstruction from power leakage measurements, even at large noise levels and after countermeasures.image & COPY; 2023 WILEY-VCH GmbH
C1 [Wang, Ziyu; Wu, Yuting; Park, Yongmo; Yoo, Sangmin; Wang, Xinxin; Eshraghian, Jason K.; Lu, Wei D.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
   [Eshraghian, Jason K.] Univ Calif Santa Cruz, Dept Elect & Comp Engn, Santa Cruz, CA 95064 USA.
RP Lu, WD (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
EM wluee@eecs.umich.edu
CR Batina L., 2019, 28 USENIX SEC S USEN
   Buda M, US
   Buda M, 2019, COMPUT BIOL MED, V109, P218, DOI 10.1016/j.compbiomed.2019.05.002
   Chen F., 2018, 2018 23 AS S PAC DES
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Cherupally SK, 2022, SEMICOND SCI TECH, V37, DOI 10.1088/1361-6641/ac461f
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chou YT, 2013, IEEE T MICROW THEORY, V61, P4233, DOI 10.1109/TMTT.2013.2288089
   Fan JD, 2010, IEEE ICC
   Fan-Chiang L, 2018, 2018 IEEE ADVANCED ACCELERATOR CONCEPTS WORKSHOP (AAC)
   Funato H., 2006, 2006 17 INT ZUR S EL
   Ginsburg B. P., 2005, 2005 IEEE INT S CIRC
   Goodfellow I. J., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1406.2661
   Gu SX, 2015, Arxiv, DOI arXiv:1412.5068
   Hariprasath V, 2010, ELECTRON LETT, V46, P620, DOI 10.1049/el.2010.0706
   Harpe Pieter, 2016, IEEE Solid-State Circuits Magazine, V8, P64, DOI 10.1109/MSSC.2016.2573978
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   Hettwer B, 2020, J CRYPTOGR ENG, V10, P135, DOI 10.1007/s13389-019-00212-8
   Hu X., 2020, ASPLOS 20 LAUS SWITZ
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Hutle M., 2015, SMART GRID SECURITY
   Isola P, 2018, Arxiv, DOI [arXiv:1611.07004, DOI 10.48550/ARXIV.1611.07004, 10.48550/arXiv.1611.07004,1611.07004]
   Je-Min Hung, 2021, IEEE Open Journal of the Solid-State Circuits Society, V1, P171, DOI 10.1109/OJSSCS.2021.3123287
   Kocher P., 1999, P ANN INT CRYPT C
   Kocher P. C., 1996, P ANN INT CRYPT C
   Kubota S, 2019, EUR CONF POW ELECTR
   Maity S, 2017, I SYMPOS LOW POWER E
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Ozbayoglu AM, 2020, Arxiv, DOI arXiv:2002.05786
   Peng ZH, 2019, 2019 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS 2019), DOI 10.1109/ieee-iws.2019.8804150
   Picek S, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3569577
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Read J., 2022, 2022 IEEE COMP SOC A
   Reed S, 2016, Arxiv, DOI arXiv:1605.05396
   ROHRER R, 1971, IEEE J SOLID-ST CIRC, VSC 6, P204, DOI 10.1109/JSSC.1971.1050169
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, 10.48550/arXiv.1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Saberi M, 2011, IEEE T CIRCUITS-I, V58, P1736, DOI 10.1109/TCSI.2011.2107214
   Schreier R, 2005, IEEE T CIRCUITS-I, V52, P2358, DOI 10.1109/TCSI.2005.853909
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Sheikholeslami A., 2020, IEEE SOLID STATE CIR, V12, P15
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shokri R, 2017, Arxiv, DOI arXiv:1610.05820
   Spreitzer R, 2018, IEEE COMMUN SURV TUT, V20, P465, DOI 10.1109/COMST.2017.2779824
   Variani E, 2014, INT CONF ACOUST SPEE
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2023, IEEE T EMERG TOP COM, DOI [10.1109/TETC.2023.3257684, DOI 10.1109/TETC.2023.3257684]
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wei LX, 2019, Arxiv, DOI arXiv:1803.05847
   Wu Y., 2022, INT EL DEVICES MEET, DOI DOI 10.1109/IEDM45625.2022.10019450
   Wu YT, 2023, Arxiv, DOI arXiv:2305.14547
   Wu YT, 2022, SEMICOND SCI TECH, V37, DOI 10.1088/1361-6641/ac41e4
   Xiang Y, 2020, IEEE T CIRCUITS-II, V67, P2717, DOI 10.1109/TCSII.2020.2973007
   Xiong X, 2021, INT EL DEVICES MEET, DOI 10.1109/IEDM19574.2021.9720533
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Zhang YC, 2021, IEEE T INF FOREN SEC, V16, P4377, DOI 10.1109/TIFS.2021.3106169
   Zhao H, 2021, INT EL DEVICES MEET, DOI 10.1109/IEDM19574.2021.9720547
   Zhu Jun-Yan, 2020, Arxiv, DOI arXiv:1703.10593
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
   2023, Arxiv, DOI [arXiv:2303.08774, 10.48550/ARXIV.2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 59
TC 0
Z9 0
U1 1
U2 1
PD 2023 SEP 22
PY 2023
DI 10.1002/aisy.202300313
EA SEP 2023
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
DA 2023-11-11
ER

PT J
AU Gonugondla, SK
   Kang, MG
   Shanbhag, NR
AF Gonugondla, Sujan K.
   Kang, Mingu
   Shanbhag, Naresh R.
TI A Variation-Tolerant In-Memory Machine Learning Classifier via On-Chip
   Training
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Always-on; inference; in-memory; machine learning (ML); mixed signal;
   on-chip learning; process variations; stochastic gradient descent (SGD)
ID ACCELERATOR
AB This paper presents a robust deep in-memory machine learning classifier with a stochastic gradient descent (SGD)-based on-chip trainer using a standard 16-kB 6T SRAM array. The deep in-memory architecture (DIMA) enhances both energy efficiency and throughput over conventional digital architectures by reading multiple bits per bit line (BL) per read cycle and by employing mixed-signal processing in the periphery of the bit-cell array. Though these techniques improve the energy efficiency and latency, DIMA's analog nature makes it sensitive to process, voltage, and temperature (PVT) variations, especially under reduced BL swings. On-chip training enables DIMA to adapt to chip-specific variations in PVT as well as data statistics, thereby further enhancing its energy efficiency. The 65-nm CMOS prototype IC demonstrates this improvement by realizing an on-chip trainable support vector machine. By learning chip-specific weights, on-chip training enables robust operation under reduced BL swing leading to a 2.4 times reduction in energy over an off-chip trained DIMA. The prototype IC in 65-nm CMOS consumes 42 pJ/decision at 32 M decisions/s, corresponding to 3.12 TOPS/W (1 OP = one 8-b x 8-b MAC) during inference, thereby achieving a reduction of 21 times in energy and 100 times in energy-delay product as compared with a conventional digital architecture. The energy overhead of training is <26% per decision for SGD batch sizes of 128 and higher.
C1 [Gonugondla, Sujan K.; Shanbhag, Naresh R.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
   [Kang, Mingu] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Gonugondla, SK (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
EM gonugon2@illinois.edu
CR [Anonymous], 2016, OPTIMIZATION METHODS
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Ernst D., 2003, P IEEE ACM INT S MIC, P1
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, CONF REC ASILOMAR C, P1921, DOI 10.1109/ACSSC.2017.8335699
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Sakr C, 2017, INT CONF ACOUST SPEE, P1138, DOI 10.1109/ICASSP.2017.7952334
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877B2]
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Wu TF, 2018, ISSCC DIG TECH PAP I, P492, DOI 10.1109/ISSCC.2018.8310399
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 26
TC 74
Z9 77
U1 1
U2 5
PD NOV
PY 2018
VL 53
IS 11
SI SI
BP 3163
EP 3173
DI 10.1109/JSSC.2018.2867275
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Luo, T
   Liu, SL
   Li, L
   Wang, YQ
   Zhang, SJ
   Chen, TS
   Xu, ZW
   Temam, O
   Chen, YJ
AF Luo, Tao
   Liu, Shaoli
   Li, Ling
   Wang, Yuqing
   Zhang, Shijin
   Chen, Tianshi
   Xu, Zhiwei
   Temam, Olivier
   Chen, Yunji
TI DaDianNao: A Neural Network Supercomputer
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Machine learning; neuron network; supercomputer; multi-chip;
   interconnect; CNN; DNN
ID SILICON PHOTONICS; LOW-COST; DESIGN; POWER
AB Many companies are deploying services largely based on machine-learning algorithms for sophisticated processing of large amounts of data, either for consumers or industry. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses. However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on-chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines, and evaluate performance by integrating electrical and optical inter-chip interconnects separately. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 656.63 x over a GPU, and reduce the energy by 184. 05 x on average for a 64-chip system. We implement the node down to the place and route at 28 nm, containing a combination of custom storage and computational units, with electrical inter-chip interconnects.
C1 [Luo, Tao; Liu, Shaoli; Wang, Yuqing; Zhang, Shijin; Chen, Tianshi; Xu, Zhiwei; Chen, Yunji] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Li, Ling] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Temam, Olivier] Inria Scalay, F-91120 Palaiseau, France.
RP Luo, T (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
EM luotao@ict.ac.cn; liushaoli@ict.ac.cn; liling@ict.ac.cn;
   zhangshijin@ict.ac.cn; chentianshi@ict.ac.cn; zxu@ict.ac.cn;
   olivier.temam@inria.fr; cyj@ict.ac.cn
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   [Anonymous], 2012, P 17 C EL POW DISTR
   [Anonymous], 2009, J TOXICOL
   [Anonymous], ASPL 16 16 INT C
   [Anonymous], TECH REP
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], P HOT CHIPS
   [Anonymous], 2012, P ANN C NEUR INF PRO
   [Anonymous], 2015, IEEE INT SOLID STATE
   [Anonymous], 2013, P INT S COMPUTER ARC, DOI [DOI 10.1145/2508148.2485923), DOI 10.1145/2485922.2485923]
   [Anonymous], DEEP LEARN UNSUPERVI
   [Anonymous], 2013, P 40 ANN INT S COMPU
   [Anonymous], P IEEE INT EL DEV M
   [Anonymous], P INT S VLSI CIRC
   [Anonymous], P INT C INF KNOWL MA
   [Anonymous], P INT S MICR
   [Anonymous], 2005, TECHNOLOGY INTEL MAG
   [Anonymous], IEEE T VLSI SYST
   Bengio, 2007, ICML, P473
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Chen D, 2012, IEEE MICRO, V32, P32, DOI 10.1109/MM.2011.96
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2015, IEEE MTT S INT MICR
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Ciresan D., 2011, P 22 INT JOINT C ART, V2, P1237
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Dally W., 2003, PRINCIPLES PRACTICES
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fan K, 2009, INT S HIGH PERF COMP, P313, DOI 10.1109/HPCA.2009.4798266
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Goulding-Hotta N, 2011, IEEE MICRO, V31, P86, DOI 10.1109/MM.2011.18
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hashmi A, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P1, DOI 10.1145/2024723.2000066
   Hong SN, 2013, IEEE T INFORM THEORY, V59, P5227, DOI 10.1109/TIT.2013.2265695
   Huang LB, 2012, IEEE T COMPUT, V61, P745, DOI 10.1109/TC.2011.77
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Krishnamoorthy AV, 2011, IEEE PHOTONICS J, V3, P567, DOI 10.1109/JPHOT.2011.2140367
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Le Le Q.V. Q.V., 2012, ICML, P507
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   Matick RE, 2005, IBM J RES DEV, V49, P145, DOI 10.1147/rd.491.0145
   Merolla P., 2011, IEEE CUST INT CIRC C, P1, DOI DOI 10.1109/CICC.2011.6055294
   Mnih V., 2012, P 29 INT C MACH LEAR, P567, DOI DOI 10.5555/3042573.3042603
   Ophir N, 2013, IEEE MICRO, V33, P54, DOI 10.1109/MM.2013.1
   Padmaraju K, 2013, OPT EXPRESS, V21, P14342, DOI 10.1364/OE.21.014342
   Padmaraju K, 2012, OPT EXPRESS, V20, P27999, DOI 10.1364/OE.20.027999
   Rakowski M, 2015, ISSCC DIG TECH PAP I, V58, P408, DOI 10.1109/ISSCC.2015.7063099
   Rumley S, 2015, J LIGHTWAVE TECHNOL, V33, P547, DOI 10.1109/JLT.2014.2363947
   Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311
   Schemmel J, 2008, IEEE IJCNN, P431, DOI 10.1109/IJCNN.2008.4633828
   Shaw DE, 2014, INT CONF HIGH PERFOR, P41, DOI 10.1109/SC.2014.9
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Vlasov YA, 2012, IEEE COMMUN MAG, V50, pS67, DOI 10.1109/MCOM.2012.6146487
   Wilkerson C, 2010, CONF PROC INT SYMP C, P83, DOI 10.1145/1816038.1815973
   Young IA, 2010, IEEE J SOLID-ST CIRC, V45, P235, DOI 10.1109/JSSC.2009.2034444
   Zortman WA, 2010, OPT EXPRESS, V18, P23598, DOI 10.1364/OE.18.023598
NR 63
TC 99
Z9 132
U1 4
U2 74
PD JAN 1
PY 2017
VL 66
IS 1
BP 73
EP 88
DI 10.1109/TC.2016.2574353
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Juracy, LR
   Amory, AD
   Moraes, FG
AF Juracy, Leonardo Rezende
   Amory, Alexandre de Morais
   Moraes, Fernando Gehm
TI A Fast, Accurate, and Comprehensive PPA Estimation of Convolutional
   Hardware Accelerators
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Convolutional neural networks; Hardware acceleration; Analytical models;
   Training; Throughput; Systolic arrays; Neurons; CNN; convolutional
   hardware accelerator; power-performance-area (PPA) estimation; design
   space exploration (DSE)
ID FRAMEWORK
AB Convolutional Neural Networks (CNN) are widely adopted for Machine Learning (ML) tasks, such as classification and computer vision. GPUs became the reference platforms for both training and inference phases of CNNs due to their tailored architecture to the CNN operators. However, GPUs are power-hungry architectures. A path to enable the deployment of CNNs in energy-constrained devices is adopting hardware accelerators for the inference phase. However, the literature presents gaps regarding analyses and comparisons of these accelerators to evaluate Power-Performance-Area (PPA) trade-offs. Typically, the literature estimates PPA from the number of executed operations during the inference phase, such as the number of MACs, which may not be a good proxy for PPA. Thus, it is necessary to deliver accurate hardware estimations, enabling design space exploration (DSE) to deploy CNNs according to the design constraints. This work proposes a fast and accurate DSE approach for CNNs using an analytical model fitted from the physical synthesis of hardware accelerators. The model is integrated with CNN frameworks, like TensorFlow, to generate accurate results. The analytic model estimates area, performance, power, energy, and memory accesses. The observed average error comparing the analytical model to the data obtained from the physical synthesis is smaller than 7%.
C1 [Juracy, Leonardo Rezende; Moraes, Fernando Gehm] PUCRS Univ, Sch Technol, BR-90619900 Porto Alegre, RS, Brazil.
   [Amory, Alexandre de Morais] Scuola Super Sant Anna, I-56127 Pisa, Italy.
RP Moraes, FG (corresponding author), PUCRS Univ, Sch Technol, BR-90619900 Porto Alegre, RS, Brazil.
EM leonardo.juracy@acad.pucrs.br; alexandre.amory@santannapisa.it;
   fernando.moraes@pucrs.br
CR Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], 2018, IEEE INT WORKSHOP DO
   [Anonymous], 2022, CAFFE
   [Anonymous], 2022, PYTORCH
   [Anonymous], 2022, TENSORFLOW
   Apple, 2022, IPHONE 11
   Asanovic Krste, 2016, UCBEECS201617
   Baskin C, 2021, ACM T COMPUT SYST, V37, DOI 10.1145/3444943
   Cao S, 2020, IEEE J EM SEL TOP C, V10, P217, DOI 10.1109/JETCAS.2020.2993854
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Das S, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180403
   Datta G., P DES AUT TEST EUR C, P718
   Facebook, 2022, FAC HOR
   Ferianc M., 2021, MDPI ELECT, V10, P1
   Genc H, 2021, DES AUT CON, P769, DOI 10.1109/DAC18074.2021.9586216
   Giri D, 2020, DES AUT TEST EUROPE, P1049
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google, 2022, GOOGL ASS YOUR OWN P
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Haykin S, 2009, NEURAL NETWORKS LEAR
   Heidorn C, 2020, PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS FOR EMBEDDED SYSTEMS (SCOPES 2020), P26, DOI 10.1145/3378678.3391878
   Hsiao SF, 2020, IEEE INT SYMP CIRC S
   Hsiao SF, 2020, IEEE J EM SEL TOP C, V10, P376, DOI 10.1109/JETCAS.2020.3015238
   Jouppi NP, 2015, IEEE T VLSI SYST, V23, P1254, DOI 10.1109/TVLSI.2014.2334635
   Juracy LR, 2021, IEEE T CIRCUITS-I, V68, P4783, DOI 10.1109/TCSI.2021.3104644
   Karbachevsky A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020717
   Keras, 2022, PRELU LAYER
   Kim N. J., IEEE T MULTIMEDIA, P2022, DOI 10.1109/TMM.2022.3189496
   Kim SJ, 2023, CRANIO, V41, P274, DOI 10.1080/08869634.2020.1839722
   Kwon H., 2018, ACM SPECIAL INTEREST, V53, P475
   Kwon H., 2018, COMPUTING RES REPOSI, P1
   Kwon H., 2019, PROC IEEEACM INT S M, P768
   Manasi SD, 2021, ASIA S PACIF DES AUT, P235, DOI 10.1145/3394885.3431539
   Moolchandani D, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101887
   Munoz-Martinez F., 2020, COMPUT RES REPOSITOR, P1
   NVIDIA, 2022, NVDLA
   Panda P., 2020, FRONTIERS NEUROSCI, V14, P1
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Samadani Ali, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P1, DOI 10.1109/EMBC.2018.8512531
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   ServiceNow, 2022, ENT CHATB VIRT AG
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Shivangi S, 2020, PROBIOTICS ANTIMICRO, V12, P1502, DOI 10.1007/s12602-020-09650-x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabizadeh A., 2021, COMPUT RES REPOSITOR, P1
   Spagnolo F., 2020, IEEE MEDITERRANEAN C, P1
   Strom N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1488
   Tesla, 2022, AUT
   TESLA, 2019, AUT FULL SELF DRIV C
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhang XX, 2023, CURR PSYCHOL, V42, P1701, DOI 10.1007/s12144-021-01561-6
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/ICASSP40776.2020.9053977, 10.1109/icassp40776.2020.9053977]
NR 54
TC 0
Z9 0
U1 0
U2 1
PD DEC
PY 2022
VL 69
IS 12
BP 5171
EP 5184
DI 10.1109/TCSI.2022.3204932
EA SEP 2022
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chen, WX
   Wang, Z
   Lei, M
   Dong, B
   Wang, Z
   Yang, YK
   Chen, C
   Guo, WY
   Liang, C
   Zhang, Q
   Fang, WQ
   Yu, ZB
AF Chen, Wenxuan
   Wang, Zheng
   Lei, Ming
   Dong, Bo
   Wang, Zhuo
   Yang, Yongkui
   Chen, Chao
   Guo, Weiyu
   Liang, Chen
   Zhang, Qian
   Fang, Wenqi
   Yu, Zhibin
GP IEEE
TI Improving system latency of AI accelerator with on-chip pipelined
   activation preprocessing and multi-mode batch inference
SO 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   CIRCUITS AND SYSTEMS (AICAS)
DT Proceedings Paper
CT IEEE 3rd International Conference on Artificial Intelligence Circuits
   and Systems (AICAS)
CY JUN 06-09, 2021
CL ELECTR NETWORK
DE Machine learning accelerator; latency improvement; multi-mode inference
AB State-of-the-art neural network accelerators exploit massive computing parallelism to achieve high throughput. However, significant latency is observed on the master-slave-based AI acceleration system which limits its adaptation in real-time applications. Investigation in de-facto GPU system reveals tremendous timing overhead for preprocessing of input activations, which is commonly executed on the host machine through manually customized low-level APIs, nevertheless still results in the moderate utilization rate of processing elements. In this work, we observe one of the key factors for low utilization of processing elements (PEs) is the sparsity of input activations caused by the default DRAM bandwidth utilization (BU) of only 18.75%. To optimize this, we design two on-chip preprocessing modules that merge up-to-five input frames in one DRAM transfer to increase BU to 93.75% and facilitates parallel img2col buffering. Furthermore, the merged activations are simultaneously processed by the neuron engine to reduce the system latency and significantly increases PE utilization. Explicitly, multiple batch inferencing modes including Intra-PE-, temporal- and spatial-sharing are proposed to pipeline with the preprocessing modules, resulting in a 65%similar to 75% reduction of system latency. The on-chip preprocessing modules incur the physical overheads of 31.0% in area and 28.7% in power consumption under 40nm SMIC standard cell library.
C1 [Chen, Wenxuan; Wang, Zheng; Lei, Ming; Dong, Bo; Wang, Zhuo; Yang, Yongkui; Chen, Chao; Guo, Weiyu; Liang, Chen; Zhang, Qian; Fang, Wenqi; Yu, Zhibin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Chen, Wenxuan; Lei, Ming; Dong, Bo; Wang, Zhuo; Liang, Chen] Xidian Univ, Sch Microelect, Xian, Peoples R China.
   [Zhang, Qian] Univ Sci & Technol China, Suzhou, Peoples R China.
   [Fang, Wenqi] Nanhu Lab, Jiaxing, Peoples R China.
RP Wang, Z (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM zheng.wang@siat.ac.cn
CR Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wu Huikai, 2019, ARXIV190311816
   Zhou K, 2016, DESTECH TRANS COMP
   Zhu Y., 2018, CORR
   Zhuo Wang, 2020, Proceedings of the 2020 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA), P151, DOI 10.1109/ICTA50426.2020.9331980
NR 9
TC 0
Z9 0
U1 1
U2 3
PY 2021
DI 10.1109/AICAS51828.2021.9458529
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Caselli, M
   Subhechha, S
   Debacker, P
   Mallik, A
   Verkest, D
AF Caselli, Michele
   Subhechha, Subhali
   Debacker, Peter
   Mallik, Arindam
   Verkest, Diederik
GP IEEE
TI Write-Verify Scheme for IGZO DRAM in Analog in-Memory Computing
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS 22)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-JUN 01, 2022
CL Austin, TX
AB Large weight variations cause significant degradation in Deep Neural Networks (DNNs) accuracy in machine learning (ML) context. Indium-Gallium-Zinc-Oxide (IGZO) DRAM compute cell is a promising option for Analog in-Memory Computing (AiMC) accelerators, but its applicability requires the compensation of large variations affecting the voltage threshold of the readout device. This paper proposes a write-verify scheme for IGZO-based AiMC accelerator, designed in 22-nm technology, based on a compensation loop operating on the analog weight value stored in the IGZO DRAM cell. After the compensation routine, the IGZO ION normalized variation drops from +/- 27% to +/- 3% in simulation. With sufficiently large weight reuse, the additional energy spent for the compensation of the entire arrays becomes negligible, recovering the 2000 TOPS/W baseline performance of an ideal IGZO array without the write-verify.
C1 [Caselli, Michele] Katholieke Univ Leuven, Leuven, Belgium.
   [Caselli, Michele; Subhechha, Subhali; Debacker, Peter; Mallik, Arindam; Verkest, Diederik] Imec Leuven, Leuven, Belgium.
   [Caselli, Michele] Univ Parma, Parma, Italy.
RP Caselli, M (corresponding author), Katholieke Univ Leuven, Leuven, Belgium.; Caselli, M (corresponding author), Imec Leuven, Leuven, Belgium.; Caselli, M (corresponding author), Univ Parma, Parma, Italy.
CR Bhattacharjee D, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401064
   Caselli M, 2021, IEEE INT NEW CIRC, DOI 10.1109/NEWCAS50681.2021.9462775
   Cosemans S, 2019, INT EL DEVICES MEET
   Doevenspecks J., 2021, S VLSI TECHN
   Hody H., 2021, IEEE S VLSI TECHN
   Kunitake H., 2019, J ELECT DEVICES SOC, V7
   Kunitake H, 2018, INT EL DEVICES MEET
   Raman SRS, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401798
NR 8
TC 1
Z9 1
U1 5
U2 5
PY 2022
BP 1462
EP 1466
DI 10.1109/ISCAS48785.2022.9937962
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Mucha, T
   Ma, SJ
   Abhari, K
AF Mucha, Tomasz
   Ma, Sijia
   Abhari, Kaveh
TI Riding a bicycle while building its wheels: the process of machine
   learning-based capability development and IT-business alignment
   practices
SO INTERNET RESEARCH
DT Article
DE Machine learning (ML); Machine learning operations (MLOps); IT
   capabilities; IT-business alignment; Process model; Artificial
   intelligence (AI); Development operations (DevOps); Temporality; Context
   sensitivity; Capability development; Digitalization; Digital
   transformation
ID EDITORIAL ARTIFICIAL-INTELLIGENCE; RESOURCE-BASED VIEW;
   INFORMATION-TECHNOLOGY; DECISION-MAKING; FIRM RESOURCES; AI SYSTEMS;
   FRAMEWORK
AB PurposeRecent advancements in Artificial Intelligence (AI) and, at its core, Machine Learning (ML) offer opportunities for organizations to develop new or enhance existing capabilities. Despite the endless possibilities, organizations face operational challenges in harvesting the value of ML-based capabilities (MLbC), and current research has yet to explicate these challenges and theorize their remedies. To bridge the gap, this study explored the current practices to propose a systematic way of orchestrating MLbC development, which is an extension of ongoing digitalization of organizations.Design/methodology/approachData were collected from Finland's Artificial Intelligence Accelerator (FAIA) and complemented by follow-up interviews with experts outside FAIA in Europe, China and the United States over four years. Data were analyzed through open coding, thematic analysis and cross-comparison to develop a comprehensive understanding of the MLbC development process.FindingsThe analysis identified the main components of MLbC development, its three phases (development, release and operation) and two major MLbC development challenges: Temporal Complexity and Context Sensitivity. The study then introduced Fostering Temporal Congruence and Cultivating Organizational Meta-learning as strategic practices addressing these challenges.Originality/valueThis study offers a better theoretical explanation for the MLbC development process beyond MLOps (Machine Learning Operations) and its hindrances. It also proposes a practical way to align ML-based applications with business needs while accounting for their structural limitations. Beyond the MLbC context, this study offers a strategic framework that can be adapted for different cases of digital transformation that include automation and augmentation of work.
C1 [Mucha, Tomasz] Aalto Univ, Sch Sci, Dept Ind Engn & Management, Espoo, Finland.
   [Ma, Sijia] Tilburg Univ, Dept Management, Tilburg, Netherlands.
   [Abhari, Kaveh] San Diego State Univ, Fowler Coll Business, Management Informat Syst Dept, San Diego, CA USA.
   [Abhari, Kaveh] San Diego State Univ, Digital Innovat Lab DiLab, San Diego, CA USA.
RP Mucha, T (corresponding author), Aalto Univ, Sch Sci, Dept Ind Engn & Management, Espoo, Finland.
EM tomasz.mucha@aalto.fi; s.ma@tilburguniversity.edu; kabhari@sdsu.edu
CR Abedin B, 2022, INTERNET RES, V32, P425, DOI 10.1108/INTR-05-2020-0300
   Ågerfalk PJ, 2020, EUR J INFORM SYST, V29, P1, DOI 10.1080/0960085X.2020.1721947
   Aguilar Melgar Leonel, 2021, 11 ANN C INN DAT SYS, DOI [10.3929/ETHZ-B-000458916, DOI 10.3929/ETHZ-B-000458916]
   Alla S., 2021, WHAT IS MLOPS, P79, DOI [DOI 10.1007/978-1-4842-6549-9_3, 10.1007/978-1-4842-6549-9_3/COVER]
   Alnafessah A, 2021, IEEE ACCESS, V9, P44476, DOI 10.1109/ACCESS.2021.3064867
   Amershi S, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P291, DOI 10.1109/ICSE-SEIP.2019.00042
   AMIT R, 1993, STRATEGIC MANAGE J, V14, P33, DOI 10.1002/smj.4250140105
   Ancona DG, 2001, ACAD MANAGE REV, V26, P645, DOI 10.2307/3560246
   [Anonymous], 2018, KDD CMI WORKSH
   Asatiani A, 2021, J ASSOC INF SYST, V22, P325, DOI 10.17705/1jais.00664
   Asatiani A, 2020, MIS Q EXEC, V19, P259, DOI 10.17705/2msqe.00037
   Ashmore R, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453444
   Athey S., 2019, EC ARTIFICIAL INTELL, P507
   Baier L., 2019, P 27 EUR C INF SYST
   Baird A, 2021, MIS QUART, V45, P315, DOI 10.25300/MISQ/2021/15882
   Balasubramanian N, 2022, ACAD MANAGE REV, V47, P448, DOI 10.5465/amr.2019.0470
   BARNEY J, 1991, J MANAGE, V17, P99, DOI 10.1177/014920639101700108
   Barney J, 2013, ACAD MANAGE PERSPECT, V27, P138, DOI 10.5465/amp.2012.0107
   Benbya H, 2021, J ASSOC INF SYST, V22, P281, DOI 10.17705/1jais.00662
   Benbya H, 2020, MIS Q EXEC, V19, pIX
   Berente, 2021, MIS QUART, V45, P1433, DOI [DOI 10.25300/MISQ/2021/16274, http://doi.org/10.25300/MISQ/2021/16274]
   Bharadwaj AS, 2000, MIS QUART, V24, P169, DOI 10.2307/3250983
   Broek E., 2019, ICIS 2019 PRO, V6
   Brynjolfsson E., 2018, EC ARTIFICIAL INTELL, P23, DOI DOI 10.7208/CHICAGO/9780226613475.003.0001
   Brynjolfsson E, 2019, MANAGE SCI, V65, P5449, DOI 10.1287/mnsc.2019.3388
   Chan YE, 2007, J INF TECHNOL-UK, V22, P297, DOI 10.1057/palgrave.jit.2000109
   Choudhary F., 2022, GARTNER
   Dadgar S., 2021, ARXIV, DOI [10.48550/arXiv.2107, DOI 10.48550/ARXIV.2107]
   EISENHARDT KM, 1989, ACAD MANAGE REV, V14, P532, DOI 10.2307/258557
   Fountaine T, 2019, HARVARD BUSINESS REV
   Gall M, 2022, EUR J INFORM SYST, V31, P548, DOI 10.1080/0960085X.2021.1997100
   Gavetti G, 2005, ORGAN SCI, V16, P599, DOI 10.1287/orsc.1050.0140
   GOODHUE DL, 1995, MIS QUART, V19, P213, DOI 10.2307/249689
   Grant R., 2016, CONT STRATEGY ANAL
   Gronsund T, 2020, J STRATEGIC INF SYST, V29, DOI 10.1016/j.jsis.2020.101614
   Helfat CE, 2003, STRATEGIC MANAGE J, V24, P997, DOI 10.1002/smj.332
   Henderson JC, 1999, IBM SYST J, V38, P472, DOI 10.1147/SJ.1999.5387096
   Huang YZ, 2022, Arxiv, DOI arXiv:2207.09109
   Hunt SD, 2008, ORGAN STUD, V29, P1469, DOI 10.1177/0170840608099521
   John MM, 2021, 2021 47TH EUROMICRO CONFERENCE ON SOFTWARE ENGINEERING AND ADVANCED APPLICATIONS (SEAA 2021), P334, DOI 10.1109/SEAA53835.2021.00050
   Keding C, 2021, TECHNOL FORECAST SOC, V171, DOI 10.1016/j.techfore.2021.120970
   Kiron, 2019, WINNING
   Knight W., 2018, MIT TECHNOL REV
   Kolltveit A.B., 2022, 1 INT WORKSH SOFTW E
   Laato S, 2022, INTERNET RES, V32, P1, DOI 10.1108/INTR-08-2021-0600
   Lei D, 1996, J MANAGE, V22, P549, DOI 10.1177/014920639602200402
   Locke K, 1997, ACAD MANAGE J, V40, P1023, DOI 10.5465/256926
   Luftman J., 1999, COMMUNICATIONS AIS, V1, P1, DOI DOI 10.17705/1CAIS.00111
   Luftman J, 2017, J INF TECHNOL-UK, V32, P26, DOI 10.1057/jit.2015.23
   Lwakatare L.E., 2020, INT C SOFTW TEL COMP, P1, DOI [10.23919/SoftCOM50211.2020.9238323, DOI 10.23919/SOFTCOM50211.2020.9238323]
   Lwakatare LE, 2020, INFORM SOFTWARE TECH, V127, DOI 10.1016/j.infsof.2020.106368
   Lyytinen K, 2021, J INF TECHNOL-UK, V36, P427, DOI 10.1177/0268396220915917
   Lyytinen K, 2008, EUR J INFORM SYST, V17, P589, DOI 10.1057/ejis.2008.50
   Makinen Sasu, 2021, 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN), P109, DOI 10.1109/WAIN52551.2021.00024
   Martínez-Fernández S, 2021, LECT NOTES BUS INF P, V415, P221, DOI 10.1007/978-3-030-75018-3_14
   Mikalef P, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103434
   Mikalef P, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103237
   Min QF, 2019, INT J INFORM MANAGE, V49, P502, DOI 10.1016/j.ijinfomgt.2019.05.020
   Moreschini S, 2022, EUR CON SFTWR MTNCE, P1293, DOI 10.1109/SANER53432.2022.00155
   Mucha T., 2022, AM C INF SYST MINN M
   Mucha T., 2023, 5 WAV BRIE ETLA COLL, P81
   Mucha T., 2023, P 56 HAW INT C SYST
   Mucha T, 2021, METHODSX, V8, DOI 10.1016/j.mex.2021.101233
   Murray A, 2021, ACAD MANAGE REV, V46, P552, DOI 10.5465/amr.2019.0186
   Pääkkönen J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376780
   Raisch S, 2021, ACAD MANAGE REV, V46, P192, DOI 10.5465/amr.2018.0072
   Ransbotham S., 2021, CULTURAL BENEFITS AR
   Ransbotham S., 2020, EXPANDING AIS IMPACT
   Renggli C, 2021, Arxiv, DOI arXiv:2102.07750
   Ruissalo J., 2022, P 55 HAW INT C SYST, DOI [10.24251/HICSS.2022.841, DOI 10.24251/HICSS.2022.841]
   Saldana J., 2013, CODING MANUAL QUALIT, V2nd ed.
   Sarker S, 2013, MIS QUART, V37, pIII
   Sirmon DG, 2007, ACAD MANAGE REV, V32, P273, DOI 10.2307/20159292
   Sirmon DG, 2011, J MANAGE, V37, P1390, DOI 10.1177/0149206310385695
   Strich F, 2021, J ASSOC INF SYST, V22, P304, DOI 10.17705/1jais.00663
   Sturm T., 2021, 42 INT C INFORM SYST
   Sturm T, 2021, MIS QUART, V45, P1581, DOI 10.25300/MISQ/2021/16543
   Symeonidis G, 2022, 2022 IEEE 12TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P453, DOI 10.1109/CCWC54503.2022.9720902
   Trang S, 2022, EUR J INFORM SYST, V31, P166, DOI 10.1080/0960085X.2020.1869914
   Ulrich D., 1991, ACAD MANAGE EXEC, V5, P77
   Waardenburg L, 2022, ORGAN SCI, V33, P59, DOI 10.1287/orsc.2021.1544
   Wang JZ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P839, DOI 10.1145/3219819.3219869
   Weick KE, 2007, ACAD MANAGE J, V50, P14
   WERNERFELT B, 1984, STRATEGIC MANAGE J, V5, P171, DOI 10.1002/smj.4250050207
   Wilden R, 2016, ACAD MANAG ANN, V10, P997, DOI 10.1080/19416520.2016.1161966
   Yin RK., 2009, CASE STUDY RES DESIG, Vvol. 5
   Zhang D, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102304
   Zhang DN, 2021, Arxiv, DOI arXiv:2103.06312
   Zhou Y, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER ENGINEERING (ICAICE 2020), P494, DOI 10.1109/ICAICE51518.2020.00102
NR 89
TC 0
Z9 0
U1 11
U2 11
PD JUL 18
PY 2023
VL 33
IS 7
BP 168
EP 205
DI 10.1108/INTR-10-2022-0769
WC Business; Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT C
AU Vasireddy, P
   Kavi, K
   Mehta, G
AF Vasireddy, Pranathi
   Kavi, Krishna
   Mehta, Gayatri
GP IEEE
TI Sparse-T: Hardware accelerator thread for unstructured sparse data
   processing
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
DE Sparse matrix-dense vector multiplications; Compressed Sparse Row (CSR);
   Hardware accelerators; Application Specific Integrated Circuits; RISC-V
AB Sparse matrix-dense vector (SpMV) multiplication is inherent in most scientific, neural networks and machine learning algorithms. To efficiently exploit sparsity of data in SpMV computations, several compressed data representations have been used. However, compressed data representations of sparse data can result in overheads of locating nonzero values, requiring indirect memory accesses which increases instruction count and memory access delays. We call these translations of compressed representations as metadata processing. We propose a memory-side accelerator for metadata (or indexing) computations and supplying only the required nonzero values to the processor, additionally permitting an overlap of indexing with core computations on nonzero elements. In this contribution, we target our accelerator for low-end micro-controllers with very limited memory and processing capabilities. In this paper we will explore two dedicated ASIC designs of the proposed accelerator that handles the indexed memory accesses for compressed sparse row (CSR) format working alongside a simple RISC-like programmable core. One version of the accelerator supplies only vector values corresponding to nonzero matrix values and the second version supplies both nonzero matrix and matching vector values for SpMV computations. Our experiments show speedups ranging between 1.3 and 2.1 times for SpMV for different levels of sparsity. Our accelerator also results in energy savings ranging between 15.8% and 52.7% over different matrix sizes, when compared to the baseline system with primary RISC-V core performing all computations. We use smaller synthetic matrices with different sparsity levels and larger real-world matrices with higher sparsity (below 1% non-zeros) in our experimental evaluations.
C1 [Vasireddy, Pranathi; Kavi, Krishna; Mehta, Gayatri] Univ North Texas, Denton, TX 76203 USA.
RP Vasireddy, P (corresponding author), Univ North Texas, Denton, TX 76203 USA.
EM pranathivasireddy@my.unt.edu; krishna.kavi@unt.edu;
   gayatri.mehta@unt.edu
CR Adavally S, 2020, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, MEMSYS 2020, P46, DOI 10.1145/3422575.3422777
   Azad A, 2017, INT PARALL DISTRIB P, P688, DOI 10.1109/IPDPS.2017.76
   Barredo A, 2019, INT CONFER PARA, P482, DOI 10.1109/PACT.2019.00056
   Bell N, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Buluc A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P721, DOI 10.1109/IPDPS.2011.73
   Buluç A, 2012, SIAM J SCI COMPUT, V34, pC170, DOI 10.1137/110848244
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Donahue S., 2002, HARDWARE SUPPORT FAS
   Farzaneh Aiyoub, 2009, COMMUNICATIONS FACUL, V58
   Fox L.M., 2003, OPTIMIZATION STORAGE
   Gonzalez Abraham, 2019, RISC V ISA SIMULATOR
   Greathouse JL, 2014, INT CONF HIGH PERFOR, P769, DOI 10.1109/SC.2014.68
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Kanellopoulos K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P600, DOI 10.1145/3352460.3358286
   Lee J, 2009, IEEE T PARALL DISTR, V20, P1309, DOI 10.1109/TPDS.2008.224
   Li W., 2006, IEEE COMPUT ARCHIT L, V5
   lowRISC, 2017, IB EMB 32 BIT RISC V
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   NXP, 2019, NXP MICR OV
   NXP, 2019, MICR MICR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rawal A, 2019, IEEE SYM PARA DISTR, P47, DOI 10.1109/IPDPSW.2019.00016
   Rezaei M, 2006, J SYST ARCHITECT, V52, P41, DOI 10.1016/j.sysarc.2005.02.004
   RISCV Foundation, 2020, RISC V FREE OP RISC
   Sadi F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P347, DOI 10.1145/3352460.3358330
   Smith J. E., 1982, 9th Annual Symposium on Computer Architecture, P112
   TI, 2019, MSP432P401R MSP432P4
   Umuroglu Y, 2014, PR IEEE COMP DESIGN, P432, DOI 10.1109/ICCD.2014.6974716
   Yavits L, 2017, Arxiv, DOI arXiv:1705.09937
   Yu XY, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P178, DOI 10.1145/2830772.2830807
   Zhang YD, 2018, Arxiv, DOI [arXiv:1711.07128, DOI 10.48550/ARXIV.1711.07128]
NR 32
TC 0
Z9 0
U1 1
U2 1
PY 2022
DI 10.1145/3508352.3549441
WC Computer Science, Theory & Methods; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT B
AU Mirmahaleh, SYH
   Reshadi, M
AF Mirmahaleh, Seyedeh Yasaman Hosseini
   Reshadi, Midia
BE Chowdhary, CL
   Alazab, M
   Chaudhary, A
   Hakak, S
   Gadekallu, TR
TI DLA: deep learning accelerator
SO COMPUTER VISION AND RECOGNITION SYSTEMS USING MACHINE AND DEEP LEARNING
   APPROACHES: Fundamentals, Technologies and Applications
SE IET COMPUTING SERIES
DT Article; Book Chapter
DE Deep learning accelerator; data-flow mapping; communication
   infrastructure; traffic pattern
ID NEURAL-NETWORKS
AB Machine learning algorithms-applications (ML) have been deployed to support growth by employing the Internet of things (IoT) in various technologies and aimed at full smart cities. Graphic processing unit (GPU)-based systems or GPU-central processing unit (CPU)-based systems were aimed to implement various MLs' computations including deep neural networks (DNN), convolutional neural network (CNN), and recurrent neural network (RNN), which have utilized parallel computations in multiply-accumulate (MAC) operations. GPU-based systems satisfied flexibility for implementing different MLs and supporting their training and inference phases, whereas increasing neural network's layers remains its energy efficiency problems caused by enhancing memory accesses. According to deploying high accurate image processing, and pattern and speech recognition-based applications and grow up their complexity, some methods had to be considered to tackle the problem. Hence software (SW), hardware (HW), and SW-HW approaches have been proposed to face the challenges, which consist of memory capacity, delay, energy consumption, and bandwidth requirement. One of the approaches is the deep learning accelerator's (DLA) communication infrastructure which connects the processing elements (PE). Trained models' traffic distributes PEs using communication infrastructure, which can inspire various structures and designs such as application-specific integrated circuit (ASIC) and field-programmable gate array (FPGA). As an example of DLA's efficiency, ASIC-based designs have less flexibility and reconfigurability compared to network on chip (NoC) and FPGA-based communication structures and can only support a specific purpose such as image processing. In this chapter, we will focus on hardware approaches to improve the GPU-based system's energy efficiency and performance in the inference phase, which is described as a deep learning accelerator including memory, communication infrastructure, and PEs. We first explain different communication network's role in improving or deteriorating data transfer of trained DNN models between memory and network, and processing elements. Next, we will describe various approaches and investigate their impact on DLA-based system's efficiency, which have included data-flow mapping, data-flow stationaries, traffic patterns, and partitioning methods.
C1 [Mirmahaleh, Seyedeh Yasaman Hosseini; Reshadi, Midia] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
RP Mirmahaleh, SYH (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
CR Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen KC, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352376
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Chowdhary C.L., 2019, RECENT PAT COMPUT SC, V12, P18, DOI [10.2174/2213275911666180821092033, DOI 10.2174/2213275911666180821092033]
   Daneshtalab M., 2020, HARDWARE ARCHITECTUR
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Firuzan A, 2018, INT SYMP NETW CHIP
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Guirado R., 2020, ARXIV PREPRINT ARXIV
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Hayashikoshi M, 2020, IEEE INT MEM WORKSH, P95, DOI 10.1109/imw48823.2020.9108132
   Jerger NE., 2017, SYNTHESIS LECT COMPU, V12, P1, DOI DOI 10.2200/S00772ED1V01Y201704CAC040
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Krishna T., 2020, SYNTHESIS LECT COMPU, V15, P1
   Kwon H, 2017, 11 IEEE ACM INT S NE, V2017, P1, DOI [10.1145/3130218.3130230, DOI 10.1145/3130218.3130230]
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Kwon Hyoukjun, 2018, MAESTRO OPEN SOURCE
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Mirmahaleh SYH, 2020, J PARALLEL DISTR COM, V144, P80, DOI 10.1016/j.jpdc.2020.04.011
   Mirmahaleh SYH, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352378
   Mirmahaleh SYH, 2019, MICROELECTRON J, V94, DOI 10.1016/j.mejo.2019.104655
   Nabavinejad SM, 2020, IEEE J EM SEL TOP C, V10, P268, DOI 10.1109/JETCAS.2020.3022920
   Peng XC, 2020, IEEE T CIRCUITS-I, V67, P1333, DOI 10.1109/TCSI.2019.2958568
   Reddy GT, 2020, COMPUT COMMUN, V157, P64, DOI 10.1016/j.comcom.2020.04.004
   Samajdar A., 2019, ARXIV PREPRINT ARXIV
   Samajdar A, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P855, DOI [10.1109/MICR0.2018.00074, 10.1109/MICRO.2018.00074]
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Wang Y, 2019, IEEE T PARALL DISTR, V30, P589, DOI 10.1109/TPDS.2018.2868062
NR 33
TC 0
Z9 0
U1 0
U2 0
PY 2021
VL 42
BP 17
EP 49
D2 10.1049/PBPC042E
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Ukidave, Y
   Li, XY
   Kaeli, D
AF Ukidave, Yash
   Li, Xiangyu
   Kaeli, David
GP IEEE
TI Mystic: Predictive Scheduling for GPU based Cloud Servers using Machine
   Learning
SO 2016 IEEE 30TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS 2016)
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 30th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 23-27, 2016
CL Illinois Inst Technol, Chicago, IL
HO Illinois Inst Technol
DE GPU; server; cloud; scheduling; machine learning
AB GPUs have become the primary choice of accelerators for high-end data centers and cloud servers, which can host thousands of disparate applications. With the growing demands for GPUs on clusters, there arises a need for efficient coexecution of applications on the same accelerator device. However, the resource contention among co-executing applications causes interference which leads to degradation in execution performance, impacts QoS requirements of applications and lowers overall system throughput. While previous work has proposed techniques for detecting interference, the existing solutions are either developed for CPU clusters, or use static profiling approaches which can be computationally intensive and do not scale well.
   We present Mystic, an interference-aware scheduler for efficient co-execution of applications on GPU-based clusters and cloud servers. The most important feature of Mystic is the use of learning-based analytical models for detecting interference between applications. We leverage a collaborative filtering framework to characterize an incoming application with respect to the interference it may cause when co-executing with other applications while sharing GPU resources. Mystic identifies the similarities between new applications and the executing applications, and guides the scheduler to minimize the interference and improve system throughput. We train the learning model with 42 CUDA applications, and consider another separate set of 55 diverse, real-world GPU applications for evaluation. Mystic is evaluated on a live GPU cluster with 32 NVIDIA GPUs. Our framework achieves performance guarantees for 90.3% of the evaluated applications. When compared with state-of-the art interference-oblivious schedulers, Mystic improves the system throughput by 27.5% on average, and achieves a 16.3% improvement on average in GPU utilization.
C1 [Ukidave, Yash; Li, Xiangyu; Kaeli, David] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
RP Ukidave, Y (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM yukidave@ece.neu.edu; xili@ece.neu.edu; kaeli@ece.neu.edu
CR [Anonymous], 2015, GRAPH ACC VDI VIS PE
   [Anonymous], 2012, P USENIX ANN TECH C
   [Anonymous], 2012, CTR RELIABLE HIGH PE
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 1998, COMPUTER
   [Anonymous], 2010, IEEE INT S PARALLEL
   [Anonymous], [No title captured]
   [Anonymous], 2015, PEERL CLOUD HOSTING
   [Anonymous], 2012, NVIDIAS NEXT GEN CUD
   [Anonymous], 2007, GPU GEMS
   [Anonymous], 2012, P 21 INT S HIGHPERFO
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631
   Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P407, DOI 10.1145/347090.347176
   Bennett J., 2007, P KDD CUP WORKSHOP, V2007, P35
   Che Shuai, 2010, INT S WORKLOAD CHARA, P1
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Duato Jose, 2010, 2010 International Conference on High Performance Computing & Simulation (HPCS 2010), P224, DOI 10.1109/HPCS.2010.5547126
   Eyerman S, 2008, IEEE MICRO, V28, P42, DOI 10.1109/MM.2008.44
   Grauer-Gray Scott, 2012, INNOVATIVE PARALLEL, P1
   Gupta Vishakha, 2009, P 3 ACM WORKSHOP SYS, P17, DOI DOI 10.1145/1519138.1519141
   Hong JY, 2004, IEEE IMAGE PROC, P2455
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kulkarni M, 2009, INT SYM PERFORM ANAL, P65, DOI 10.1109/ISPASS.2009.4919639
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Lingyuan Wang, 2011, 2011 International Conference on High Performance Computing & Simulation, P24
   Liu M, 2015, INT S HIGH PERF COMP, P259, DOI 10.1109/HPCA.2015.7056038
   Mars J, 2011, IEEE COMPUT ARCHIT L, V10, P29, DOI 10.1109/L-CA.2011.14
   Nathuji R, 2010, EUROSYS'10: PROCEEDINGS OF THE EUROSYS 2010 CONFERENCE, P237
   Nvidia, 2015, NVID CUD TOOLK 7 0
   NVIDIA, 2015, NVID CLOUD GAM
   NVIDIA Visual Profiler, 2014, NVIDIA VISUAL PROFIL
   Sengupta D, 2014, INT CONF HIGH PERFOR, P513, DOI 10.1109/SC.2014.47
   Shi L, 2012, IEEE T COMPUT, V61, P804, DOI 10.1109/TC.2011.112
   Strehl A., 2003, JMLR 03, V3
   Symscape, 2015, GPU V1 1 LIN SOLV LI
   Tanasic I., 2014, ISCA 14
   Ukidave Yash, 2014, 2014 IEEE 26th International Symposium on Computer Architecture and High-Performance Computing (SBAC-PAD), P168, DOI 10.1109/SBAC-PAD.2014.43
   Ukidave Y., 2015, ICPE 15
   White A., 2011, PET EX R D CHALL HPC
NR 40
TC 40
Z9 41
U1 0
U2 2
PY 2016
BP 353
EP 362
DI 10.1109/IPDPS.2016.73
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, ZY
   Davis, J
   Jarvis, SA
AF Li, Zhenyu
   Davis, James
   Jarvis, Stephen A.
GP IEEE
TI Optimizing Machine Learning on Apache Spark in HPC Environments
SO PROCEEDINGS OF 2018 IEEE/ACM MACHINE LEARNING IN HPC ENVIRONMENTS (MLHPC
   2018)
DT Proceedings Paper
CT IEEE/ACM Conference on Machine Learning in HPC Environments (MLHPC)
CY NOV 11-16, 2018
CL Dallas, TX
DE Machine Learning; High Performance Computing; Apache Spark; All-Reduce;
   Asynchronous Stochastic Gradient Descent
ID MAPREDUCE
AB Machine learning has established itself as a powerful tool for the construction of decision making models and algorithms through the use of statistical techniques on training data. However, a significant impediment to its progress is the time spent training and improving the accuracy of these models this is a data and compute intensive process, which can often take days, weeks or even months to complete. A common approach to accelerate this process is to employ the use of multiple machines simultaneously, a trait shared with the field of High Performance Computing (HPC) and its clusters. However, existing distributed frameworks for data analytics and machine learning are designed for commodity servers, which do not realize the full potential of a HPC cluster, and thus denies the effective use of a readily available and potentially useful resource.
   In this work we adapt the application of Apache Spark, a distributed data-flow framework, to support the use of machine learning in HPC environments for the purposes of machine learning. There are inherent challenges to using Spark in this context; memory management, communication costs and synchronization overheads all pose challenges to its efficiency. To this end we introduce: (i) the application of MapRDD, a fine grained distributed data representation; (ii) a task-based all-reduce implementation; and (iii) a new asynchronous Stochastic Gradient Descent (SGD) algorithm using non-blocking all-reduce. We demonstrate up to a 2.6x overall speedup (or a 11.2x theoretical speedup with a Nvidia K80 graphics card), a 82-91% compute ratio, and a 80% reduction in the memory usage, when training the GoogLeNet model to classify 10% of the ImageNet dataset on a 32-node cluster. We also demonstrate a comparable convergence rate using the new asynchronous SGD with respect to the synchronous method. With increasing use of accelerator cards, larger cluster computers and deeper neural network models, we predict a 2x further speedup (i.e. 22.4x accumulated speedup) is obtainable with the new asynchronous SGD algorithm on heterogeneous clusters.
C1 [Li, Zhenyu; Davis, James; Jarvis, Stephen A.] Univ Warwick, Dept Comp Sci, Coventry, W Midlands, England.
RP Li, ZY (corresponding author), Univ Warwick, Dept Comp Sci, Coventry, W Midlands, England.
EM Zhenyu.Li@warwick.ac.uk; J.Davis.4@warwick.ac.uk;
   S.A.Jarvis@warwick.ac.uk
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahmad F, 2013, J PARALLEL DISTR COM, V73, P608, DOI 10.1016/j.jpdc.2012.12.012
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2014, OPERATING SYSTEMS DE
   [Anonymous], P 22 ACM INT C MULTI
   [Anonymous], 2012, P 9 USENIX C NETW SY, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   [Anonymous], 2012, OSDI
   Carbone P., 2015, DATA ENG, V38
   Daikoku H., 2016, P 3 ACM SIGMOD WORKS, P6
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Hu Li, 2016, 2016 IEEE Conference on Computer Communications: Workshops (INFOCOM WKSHPS), P33, DOI 10.1109/INFCOMW.2016.7562041
   Isard M., 2007, Operating Systems Review, V41, P59, DOI 10.1145/1272998.1273005
   Kim H., 2016, ARXIV160208191
   Kingma DP., 2014, 3 INT C LEARN REPR I
   Li Z., 2017, P MACHINE LEARNING H, DOI DOI 10.1145/3146347.3146350
   Li Z., 2018, BEYONDMR 18, DOI 10.1145/3206333.3206335
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167, DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184]
   Mohamed H, 2013, PARALLEL COMPUT, V39, P851, DOI 10.1016/j.parco.2013.08.010
   Moritz P., 2015, SPARKNET TRAINING DE
   Murray DG, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P439, DOI 10.1145/2517349.2522738
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tieleman T, 2012, LECT 65 RMSPROP DIVI, V4, P26
   Toshniwa A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P147, DOI 10.1145/2588555.2595641
NR 26
TC 1
Z9 1
U1 0
U2 6
PY 2018
BP 95
EP 105
DI 10.1109/MLHPC.2018.00006
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Metz, CA
   Goli, M
   Drechsler, R
AF Metz, Christopher A.
   Goli, Mehran
   Drechsler, Rolf
GP IEEE Comp Soc
TI Work-in-Progress: Early Power Estimation of CUDA-based CNNs on GPGPUs
SO 2021 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM
   SYNTHESIS (CODES+ISSS 2021)
DT Proceedings Paper
CT ACM/IEEE Int Conf on Hardware/Software Codesign and Syst Synthesis / Int
   Conf on Compilers, Architectures, and Synthesis for Embedded Syst / Int
   Conf on Embedded Software part of the Embedded Syst Week
CY OCT 08-15, 2021
CL ELECTR NETWORK
AB The increasing application of Machine Learning (ML) techniques in the Internet of Things (IoT) devices has led designers to leverage ML accelerators like GPGPUs in such devices. However, choosing the most appropriate accelerator for such IoT devices is very challenging as they commonly should adhere to tight constraints e.g., low power consumption, long battery lifetime, and low cost of the final products. As a consequence, designing such application-specific IoT devices becomes a non-trivial and difficult task. In this paper, we present a novel approach to estimate power consumption of CUDA-based Convolutional Neural Networks (CNNs) on GPGPUs in the design phase. Our approach is able to provide designers with an early prediction of CNNs power consumption up to an absolute error of less than 2% in comparison to the real hardware execution.
C1 [Metz, Christopher A.; Goli, Mehran; Drechsler, Rolf] Univ Bremen, Bremen, Germany.
   [Goli, Mehran; Drechsler, Rolf] Cyber Phys Syst DFKI, Bremen, Germany.
RP Metz, CA (corresponding author), Univ Bremen, Bremen, Germany.
EM cmetz@uni-bremen.de; mehran@uni-bremen.de; drechsler@uni-bremen.de
CR Chen J., 2011, P 2011 INT GREEN COM, P1, DOI 10.1109/IGCC.2011.6008582
   Gao ZK, 2020, IEEE T IND INFORM, V16, P7159, DOI 10.1109/TII.2019.2955447
   Goli M, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3388140
   Goli M, 2018, P IEEE RAP SYST PROT, P97, DOI 10.1109/RSP.2018.8631997
   Guerreiro J, 2019, IEEE T PARALL DISTR, V30, P2494, DOI 10.1109/TPDS.2019.2917181
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kadar M, 2019, INT C ELECT COMPUT, DOI 10.1109/ecai46879.2019.9042159
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Metz C. A., 2021, ARXIV
   Nvidia, 2021, PAR THREAD EX ISA AP
   Song SW, 2013, INT PARALL DISTRIB P, P673, DOI 10.1109/IPDPS.2013.73
NR 12
TC 3
Z9 3
U1 0
U2 0
PY 2021
BP 29
EP 30
DI 10.1145/3478684.3479255
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Hao, C
   Chen, DM
AF Hao, Cong
   Chen, Deming
BE Jiang, YL
   Tang, TA
   Ye, F
TI Deep Neural Network Model and FPGA Accelerator Co-Design: Opportunities
   and Challenges
SO 2018 14TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED
   CIRCUIT TECHNOLOGY (ICSICT)
DT Proceedings Paper
CT 14th IEEE International Conference on Solid-State and Integrated Circuit
   Technology (ICSICT)
CY OCT 31-NOV 03, 2018
CL Qingdao, PEOPLES R CHINA
AB With an explosive growth of various neural network algorithms, their high performance implementations on hardware platforms, such as GPUs and FPGAs, are becoming critical as well. Compared to widely used GPUs, FPGAs are considered to be harder for design and optimization even with the help of High Level Synthesis (HLS) tools. However, recent studies have shown that FPGAs can outperform GPUs in speed and power/energy efficiency; both factors are important in machine learning applications. In this paper, we will discuss a simultaneous DNN and hardware accelerator co-design method to push the DNN performance on FPGAs. We first summarize existing techniques and results along this direction, and then propose new ideas to further improve DNN development productivity and design quality. Finally we discuss the challenges we would face and propose some potential solutions.
C1 [Hao, Cong; Chen, Deming] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
RP Hao, C (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
EM congh@illinois.edu; dchen@illinois.edu
CR Alemdar Hande, 2017, IEEE IJCNN
   [Anonymous], 2017, P INT C LEARN REPR T
   [Anonymous], 2018, ARXIV180201548
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 2016, IEEE CVPR
   DiCecco Roberto, 2016, IEEE FPT
   Guo KY, 2017, IEEE MICRO, V37, P18, DOI 10.1109/MM.2017.39
   Han S., 2015, ARXIV151000149
   Hartwig Adam, ARXIV170404861
   HLUCHYJ MG, 1991, J LIGHTWAVE TECHNOL, V9, P1386, DOI 10.1109/50.90937
   Huang Gao, 2017, CVPR, V1
   Hubara I., 2016, ADV NEURAL INFORM PR, Vvol 29
   Iandola FN, 2016, PROC INT C LEARN
   Ma Yufei, 2017, ACM FPGA
   Mtiller Klaus-Robert, ARXIV180510692
   Prasanna Viktor, 2017, ACM FPGA
   Qiu Jiantao, 2016, ACM FPGA
   Schroff F., 2015, IEEE CVPR
   Suda N., 2016, ACM FPGA
   Zhang Xiaofan, 2017, IEEE FPL
   Zhuge Chuanhao, 2018, ACM GLSVLSI
   Zoph Barret, 2017, ARXIV17070701226
   Zuo Wei, 2017, ACM DAC
NR 23
TC 0
Z9 0
U1 0
U2 4
PY 2018
BP 1413
EP 1416
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Sabetta, L
AF Sabetta, L.
TI Ultra-fast deep learning algorithms on FPGA for the phase-II level-0
   trigger of the ATLAS experiment
SO NUOVO CIMENTO C-COLLOQUIA AND COMMUNICATIONS IN PHYSICS
DT Article; Proceedings Paper
CT Meeting on High Energy Physics Meetings (IFAE)
CY APR 08-10, 2019
CL Naples, ITALY
AB The LHC accelerator will face, during the following years, a complete upgrade with the main purpose of rising up the instantaneous luminosity by a factor of almost five. Though this will permit to collect an incredible amount of data, the complexity of each event will greatly intensifies going from an average number of interactions per bunch crossing of 40 to an average of 200. To cope with this problem and be able to handle this large amount of information, both the detectors and the trigger algorithms of the ATLAS experiment will be updated. A machine learning approach for the level-0 trigger algorithm is presented.
C1 [Sabetta, L.] Sapienza Univ Roma, Dipartimento Fis, Rome, Italy.
   [Sabetta, L.] Ist Nazl Fis Nucl, Sez Roma, Rome, Italy.
RP Sabetta, L (corresponding author), Sapienza Univ Roma, Dipartimento Fis, Rome, Italy.; Sabetta, L (corresponding author), Ist Nazl Fis Nucl, Sez Roma, Rome, Italy.
CR Aad G, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/S08003
   [Anonymous], 2012, VIVADO DESIGN SUITE
   [Anonymous], 2016, ABS160504711 CORR
   ATLAS Collaboration, 2017, CERNLHCC2017017 ATLA
   Evans L, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/S08001
NR 5
TC 0
Z9 0
U1 0
U2 0
PD MAR-JUN
PY 2020
VL 43
IS 2-3
AR 61
DI 10.1393/ncc/i2020-20061-0
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Feinberg, B
   Vengalam, UKR
   Whitehair, N
   Wang, SB
   Ipek, E
AF Feinberg, Ben
   Vengalam, Uday Kumar Reddy
   Whitehair, Nathan
   Wang, Shibo
   Ipek, Engin
GP IEEE
TI Enabling Scientific Computing on Memristive Accelerators
SO 2018 ACM/IEEE 45TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 45th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 01-06, 2018
CL Los Angeles, CA
DE Accelerator Architectures; Resistive RAM
AB Linear algebra is ubiquitous across virtually every field of science and engineering, from climate modeling to macroeconomics. This ubiquity makes linear algebra a prime candidate for hardware acceleration, which can improve both the run time and the energy efficiency of a wide range of scientific applications. Recent work on memristive hardware accelerators shows significant potential to speed up matrix-vector multiplication (MVM), a critical linear algebra kernel at the heart of neural network inference tasks. Regrettably, the proposed hardware is constrained to a narrow range of workloads: although the eight- to 16-bit computations afforded by memristive MVM accelerators are acceptable for machine learning, they are insufficient for scientific computing where high-precision floating point is the norm.
   This paper presents the first proposal to enable scientific computing on memristive crossbars. Three techniques are explored reducing overheads by exploiting exponent range locality, early termination of fixed-point computation, and static operation scheduling that together enable a fixed-point memristive accelerator to perform high-precision floating point without the exorbitant cost of na ve floating-point emulation on fixed-point hardware. A heterogeneous collection of crossbars with varying sizes is proposed to efficiently handle sparse matrices, and an algorithm for mapping the dense subblocks of a sparse matrix to an appropriate set of crossbars is investigated. The accelerator can be combined with existing GPU-based systems to handle datasets that cannot be efficiently handled by the memristive accelerator alone. The proposed optimizations permit the memristive MVM concept to be applied to a wide range of problem domains, respectively improving the execution time and energy dissipation of sparse linear solvers by 10.3x and 10.9x over a purely GPU-based system.
C1 [Feinberg, Ben; Vengalam, Uday Kumar Reddy; Whitehair, Nathan; Ipek, Engin] Univ Rochester, Dept Elect & Comp Engn, 601 Elmwood Ave, Rochester, NY 14627 USA.
   [Wang, Shibo; Ipek, Engin] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
RP Feinberg, B (corresponding author), Univ Rochester, Dept Elect & Comp Engn, 601 Elmwood Ave, Rochester, NY 14627 USA.
EM bfeinber@ece.rochester.edu; uvengala@ece.rochester.edu;
   nwhiteha@ece.rochester.edu; swang@cs.rochester.edu;
   ipek@cs.rochester.edu
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Allis LV., 1994, SEARCHING SOLUTIONS
   [Anonymous], 2013, P 40 ANN INT S COMP
   [Anonymous], 2003, THESIS UC BERKELEY
   Anzt H., 2016, INT PAR DISTR PROC S
   Bailey DH, 2005, COMPUT SCI ENG, V7, P54, DOI 10.1109/MCSE.2005.52
   Bakhoda A., 2009, ANAL CUDA WORKLOADS
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Bhanushali K., 2015, INT S PHYS DES ISPD
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Chen Y., 2014, INT S MICR MICRO DEC
   Chi P., 2016, INT S HIGH PERF COMP
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Dongarra JJ, 2003, CONCURR COMP-PRACT E, V15, P803, DOI 10.1002/cpe.728
   Dorrance R., 2014, ACM SIGDA INT S FIEL
   Fang HH, 2010, APPL PHYS LETT, V97, DOI 10.1063/1.3486683
   Feinberg B., 2018, INT S HIGH PERF COMP
   Fowers J, 2014, ANN IEEE SYM FIELD P, P36, DOI 10.1109/FCCM.2014.23
   Fredeman G, 2016, IEEE J SOLID-ST CIRC, V51, P230, DOI 10.1109/JSSC.2015.2456873
   Galal S., 2013, IEEE S COMP AR ARITH
   Hauser J., 2002, SOFTFLOAT
   Hestenes M. R., 1952, METHODS CONJUGATE GR, V49
   Hsu C.-W., SELF RECTIFYING BIPO
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Jouppi N. P., 2017, INTL SYMP ON ON COMP
   Kestor G., 2013, INT S WORKL CHAR IIS
   Kestur S., 2012, INT S FIELD PROGR CU
   Kull L, 2017, ISSCC DIG TECH PAP I, P474, DOI 10.1109/ISSCC.2017.7870467
   Kull L, 2013, IEEE J SOLID-ST CIRC, V48, P3049, DOI 10.1109/JSSC.2013.2279571
   Kung J., 2017, INT S COMP ARCH ISCA
   Maliar L., 2014, NUMERICAL METHODS LA
   Martins M., 2015, INT S PHYS DES ISPD
   Messina P., 2017, US DOE EXASCALE COMP
   Niu D., 2013, INT C COMP AID DES I
   NVIDIA Corporation, 2016, WP08019001V011 NVIDI
   O'Halloran M, 2004, IEEE J SOLID-ST CIRC, V39, P1985, DOI 10.1109/JSSC.2004.835817
   Pielke Sr R.A., 2013, MESOSCALE METEOROLOG, V3rd
   Pop F, 2014, ADV HIGH ENERGY PHYS, V2014, DOI 10.1155/2014/507690
   SAAD Y, 1986, SIAM J SCI STAT COMP, V7, P856, DOI 10.1137/0907058
   Saad Y., 2003, ITERATIVE METHODS SP, Vsecond
   Saberi M, 2011, IEEE T CIRCUITS-I, V58, P1736, DOI 10.1109/TCSI.2011.2107214
   Scholkopf B, 2004, KERNEL METHODS COMPU, DOI 10.7551/mitpress/4057.003.0004
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song L., 2017, INT S HIGH PERF COMP
   Song L., 2017, GRAPHR ACCELERATING
   STAN MR, 1995, IEEE T VLSI SYST, V3, P49, DOI 10.1109/92.365453
   Synopsys, SYN DES COMP US GUID
   VANDERVORST HA, 1992, SIAM J SCI STAT COMP, V13, P631, DOI 10.1137/0913035
   Vogelsberger M, 2014, NATURE, V509, P177, DOI 10.1038/nature13316
   Wei Z, 2008, INT EL DEVICES MEET, P293, DOI 10.1109/IEDM.2008.4796676
   Whitehead N., 2011, TECH REP
   Wong SC, 2000, IEEE T SEMICONDUCT M, V13, P108, DOI 10.1109/66.827350
   Xu C., 2015, INT S HIGH PERF COMP
   Yakopcic C, 2016, ELECTRON LETT, V52, P25, DOI 10.1049/el.2015.2668
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Zhu QL, 2013, IEEE HIGH PERF EXTR
NR 56
TC 49
Z9 52
U1 0
U2 14
PY 2018
BP 367
EP 382
DI 10.1109/ISCA.2018.00039
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Yoshino, Y
   Nakada, K
   Kobayashi, M
   Tatsumi, H
AF Yoshino, Yu
   Nakada, Kazuki
   Kobayashi, Makoto
   Tatsumi, Hisayuki
GP IEEE
TI A STUDY ON MACHINE LEARNING-BASED IMAGE IDENTIFICATION TOWARDS ASSITIVE
   AUTOMATION OF COMMENTARY ON ANIMATION CHARACTERS
SO PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   CYBERNETICS (ICMLC)
SE International Conference on Machine Learning and Cybernetics
DT Proceedings Paper
CT International Conference on Machine Learning and Cybernetics (IMLC)
CY JUL 07-10, 2019
CL Kobe, JAPAN
DE Deep neural networks (DNNs); Transfer learning; Animation character;
   Automatic assistance; Visually impaired
AB This study aims to assist visually impaired people as well as animation novices by focusing on problems that arise at the time of viewing animation videos and images. We focus on the following problems: (1) difficulty of understanding behaviors and situations, (2) difficulty of discriminating animation characters, and (3) confusion caused by animation characters with similarities. We use deep neural networks to identify animation characters as preliminary verification by training a customized convolutional neural network (CNN) from scratch on a small class of data based on the original database of animation characters. The results show that some combinations of characters are difficult to discriminate in cross validation. To resolve this problem, we performed transfer learning based on the CNN variants pre-trained on the natural image database ImageNet. We confirmed that the learning proceeded steadily with a gradual learning curve, resulting in high accuracy. The results indicate that the bottleneck features of the CNN variants pre-trained on ImageNet are effective in identifying animation characters. Furthermore, we verified the operation speed of the inference of our trained CNN on a microcomputer board with a machine learning accelerator Intel Movidius and confirmed that the speed is sufficient in real-time execution.
C1 [Yoshino, Yu; Nakada, Kazuki; Kobayashi, Makoto; Tatsumi, Hisayuki] Tsukuba Univ Technol, Sch Hlth Sci, Dept Comp Sci, Tsukuba, Ibaraki, Japan.
RP Tatsumi, H (corresponding author), Tsukuba Univ Technol, Sch Hlth Sci, Dept Comp Sci, Tsukuba, Ibaraki, Japan.
EM tatsumi@cs.k.tsukuba-tech.ac.jp
CR Iwasaki, P JPSP S ENT COMPUTI, P106
   Nguyen NV, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070089
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Shaw RJ, 2013, JMIR MHEALTH UHEALTH, V1, DOI 10.2196/mhealth.2343
NR 4
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 591
EP 594
DI 10.1109/icmlc48188.2019.8949258
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
DA 2023-11-11
ER

PT J
AU Zaman, KS
   Reaz, MB
   Ali, SHM
   Bakar, AAA
   Chowdhury, MEH
AF Zaman, Kh Shahriya
   Reaz, Mamun Bin Ibne
   Ali, Sawal Hamid Md
   Bakar, Ahmad Ashrif A.
   Chowdhury, Muhammad Enamul Hoque
TI Custom Hardware Architectures for Deep Learning on Portable Devices: A
   Review
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Review
DE Computer architecture; Hardware; Computational modeling; Artificial
   neural networks; Optimization; Memory management; Convolution;
   Application-specific integrated circuit (ASIC); deep learning (DL); deep
   neural network (DNN); energy-efficient architectures; field-programmable
   gate array (FPGA); hardware accelerator; machine learning (ML); neural
   network hardware; review
ID NEURAL-NETWORKS; CHIP; FRAMEWORK; MEMORY; ACCELERATION; PERFORMANCE;
   PROCESSOR; ALGORITHM; INFERENCE; ENSEMBLE
AB The staggering innovations and emergence of numerous deep learning (DL) applications have forced researchers to reconsider hardware architecture to accommodate fast and efficient application-specific computations. Applications, such as object detection, image recognition, speech translation, as well as music synthesis and image generation, can be performed with high accuracy at the expense of substantial computational resources using DL. Furthermore, the desire to adopt Industry 4.0 and smart technologies within the Internet of Things infrastructure has initiated several studies to enable on-chip DL capabilities for resource-constrained devices. Specialized DL processors reduce dependence on cloud servers, improve privacy, lessen latency, and mitigate bandwidth congestion. As we reach the limits of shrinking transistors, researchers are exploring various application-specific hardware architectures to meet the performance and efficiency requirements for DL tasks. Over the past few years, several software optimizations and hardware innovations have been proposed to efficiently perform these computations. In this article, we review several DL accelerators, as well as technologies with emerging devices, to highlight their architectural features in application-specific integrated circuit (IC) and field-programmable gate array (FPGA) platforms. Finally, the design considerations for DL hardware in portable applications have been discussed, along with some deductions about the future trends and potential research directions to innovate DL accelerator architectures further. By compiling this review, we expect to help aspiring researchers widen their knowledge in custom hardware architectures for DL.
C1 [Zaman, Kh Shahriya; Reaz, Mamun Bin Ibne; Ali, Sawal Hamid Md; Bakar, Ahmad Ashrif A.] Univ Kebangsaan Malaysia, Dept Elect Elect & Syst Engn, Bangi 43600, Malaysia.
   [Chowdhury, Muhammad Enamul Hoque] Qatar Univ, Dept Elect Engn, Doha 27113, Qatar.
RP Reaz, MB (corresponding author), Univ Kebangsaan Malaysia, Dept Elect Elect & Syst Engn, Bangi 43600, Malaysia.; Chowdhury, MEH (corresponding author), Qatar Univ, Dept Elect Engn, Doha 27113, Qatar.
EM kh.shahriya.zaman@gmail.com; mamun@ukm.edu.my; sawal@ukm.edu.my;
   ashrif@ukm.edu.my; mchowdhury@qu.edu.qa
CR Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   Aida-zade K, 2017, I C APPL INF COMM TE, P95
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Amid A, 2020, IEEE MICRO, V40, P10, DOI 10.1109/MM.2020.2996616
   Angizi S, 2020, IEEE T COMPUT AID D, V39, P1123, DOI 10.1109/TCAD.2019.2907886
   [Anonymous], 2020, NVIDIA A100 TENSOR C
   [Anonymous], 2012, INTEL ARCHITECTURE I
   Asanovic K., 2016, ROCKET CHIP GENERATO
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Ayinde B. O., 2019, IEEE IJCNN, P1
   BintiMdSallah S. S., 2012, J APPL SCI RES, V8, P4138
   Bochkovskiy A., 2020, PREPRINT
   Bouwmans T, 2016, HANDBOOK OF ROBUST LOW-RANK AND SPARSE MATRIX DECOMPOSITION: APPLICATIONS IN IMAGE AND VIDEO PROCESSING, P1, DOI 10.1201/b20190
   Celio Christopher, 2017, 1 WORKSH COMP ARCH R
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Chen J, 2021, IEEE T NEUR NET LEAR, V32, P1067, DOI 10.1109/TNNLS.2020.2980041
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng HP, 2017, DES AUT TEST EUROPE, P139, DOI 10.23919/DATE.2017.7926972
   Cheng M, 2019, IEEE T COMPUT AID D, V38, P834, DOI 10.1109/TCAD.2018.2824304
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chien JT, 2018, IEEE T NEUR NET LEAR, V29, P1998, DOI 10.1109/TNNLS.2017.2690379
   Choi J, 2020, IEEE T CIRCUITS-I, V67, P972, DOI 10.1109/TCSI.2019.2949935
   Choi YK, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240815
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Dai XL, 2019, IEEE T COMPUT, V68, P1487, DOI 10.1109/TC.2019.2914438
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   DeBenedictis EP, 2017, COMPUTER, V50, P72, DOI 10.1109/MC.2017.34
   Deng L, 2020, IEEE J SOLID-ST CIRC, V55, P2228, DOI 10.1109/JSSC.2020.2970709
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   DiCecco R, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P239, DOI 10.1109/FPT.2017.8280150
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Efnusheva Danijela, 2017, International Journal of Computer Science & Information Technology, V9, P151, DOI 10.5121/ijcsit.2017.9214
   Farshchi F., 2019, ARXIV190306495
   Frenkel C, 2019, IEEE T BIOMED CIRC S, V13, P999, DOI 10.1109/TBCAS.2019.2928793
   Frenkel C, 2019, IEEE T BIOMED CIRC S, V13, P145, DOI 10.1109/TBCAS.2018.2880425
   Fukuda T, 2017, INTERSPEECH, P3697, DOI 10.21437/Interspeech.2017-614
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Garofalo A, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0155
   Genc H., 2019, ARXIV191109925
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greeneltch N. G., 2019, MAXIMIZE TENSORFLOW
   Guo K, 2017, ARXIV171208934
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hatcher WG, 2018, IEEE ACCESS, V6, P24411, DOI 10.1109/ACCESS.2018.2830661
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang JH, 2018, INT CONF MEAS, P5, DOI 10.1109/ICMTMA.2018.00009
   Huang Y, 2018, IEEE T PATTERN ANAL, V40, P1015, DOI 10.1109/TPAMI.2017.2701380
   Hubara I, 2018, J MACH LEARN RES, V18
   Imam N, 2020, NAT MACH INTELL, V2, P181, DOI 10.1038/s42256-020-0159-4
   Jaddi NS, 2018, ENG APPL ARTIF INTEL, V67, P246, DOI 10.1016/j.engappai.2017.09.012
   James M, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'20), P145, DOI 10.1145/3372780.3380846
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Kaiser L., 2017, ARXIV PREPRINT ARXIV
   Kalamkar D. D., 2019, P IEEE INT C CLUST C, P1
   Kim H, 2017, INT SYM PERFORM ANAL, P55, DOI 10.1109/ISPASS.2017.7975270
   Krestinskaya O, 2019, IEEE T CIRCUITS-I, V66, P719, DOI 10.1109/TCSI.2018.2866510
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lai BC, 2019, IEEE T VLSI SYST, V27, P1218, DOI 10.1109/TVLSI.2019.2897052
   Lapedus M., 2020, MAKING CHIPS 3 NM
   Le Q. V., 2016, ARXIV161101578
   Li Z., 2017, P IEEE 30 CAN C EL C, P1
   Li Z, 2019, IEEE T COMPUT AID D, V38, P1543, DOI 10.1109/TCAD.2018.2852752
   Liang Y, 2020, IEEE T COMPUT AID D, V39, P857, DOI 10.1109/TCAD.2019.2897701
   Lin PC, 2019, IEEE J EM SEL TOP C, V9, P267, DOI 10.1109/JETCAS.2019.2911999
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Liu Z., 2020, INTRO GRAPH NEURAL N, V14
   Lou WQ, 2019, LECT NOTES COMPUT SC, V11719, P3, DOI 10.1007/978-3-030-29611-7_1
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   McKinstry Jeffrey L, 2018, ARXIV PREPRINT ARXIV
   Medina E, 2020, IEEE MICRO, V40, P17, DOI 10.1109/MM.2020.2975185
   Meloni P., 2016, PROC INT CONF RECON, P1
   Miller A. I., 2020, I GOODFELLOWS GENERA, P87
   Mirhoseini A., 2020, ABS200410746 CORR
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Molchanov P., 2016, 5 INT C LEARNING REP
   Moon S, 2019, IEEE J EM SEL TOP C, V9, P735, DOI 10.1109/JETCAS.2019.2952137
   Moradi S, 2018, IEEE T BIOMED CIRC S, V12, P106, DOI 10.1109/TBCAS.2017.2759700
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Musikawan P, 2019, IEEE ACCESS, V7, P26909, DOI 10.1109/ACCESS.2019.2900563
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Nair V, 2010, INT C MACH LEARN HAI, V27, P807
   Nwankpa C, 2018, ARXIV181103378
   Pan Y, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2018.2848625
   Paul A., 2018, ARXIV181108283
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Perdomo-Ortiz A, 2018, QUANTUM SCI TECHNOL, V3, DOI 10.1088/2058-9565/aab859
   Phillips PJ, 2018, P NATL ACAD SCI USA, V115, P6171, DOI 10.1073/pnas.1721355115
   Posch K, 2021, IEEE T NEUR NET LEAR, V32, P1037, DOI 10.1109/TNNLS.2020.2980004
   Raumviboonsuk P, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0099-8
   Redmon J., 2016, ARXIV160207360, P779
   Ruder, 2017, OVERVIEW MULTI TASK
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shi YH, 2020, IEEE ELECTR DEVICE L, V41, P1126, DOI 10.1109/LED.2020.2995819
   Stokes JM, 2020, CELL, V180, P688, DOI 10.1016/j.cell.2020.01.021
   Sun P., 2019, ARXIV190206855
   Swaminathan S, 2020, NEUROCOMPUTING, V398, P185, DOI 10.1016/j.neucom.2020.02.035
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tao A, 2020, ARXIV
   Tapiador-Morales R, 2019, IEEE T BIOMED CIRC S, V13, P159, DOI 10.1109/TBCAS.2018.2880012
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang EW, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309551
   Wang FY, 2016, IEEE-CAA J AUTOMATIC, V3, P113, DOI 10.1109/JAS.2016.7471613
   Wang J., 2019, IEEE HIGH PERF EXTR, P1
   Wang J, 2020, RNA BIOL, V17, P13, DOI 10.1080/15476286.2019.1669406
   Wang PS, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152127
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Wang Y E, 2019, ARXIV190710701
   Waterman A., 2014, UCBEECS2014 EECS
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Weng Y, 2019, IEEE ACCESS, V7, P38495, DOI 10.1109/ACCESS.2019.2906369
   Wiedemann S, 2020, IEEE T NEUR NET LEAR, V31, P772, DOI 10.1109/TNNLS.2019.2910073
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yang YK, 2020, NEURAL NETWORKS, V125, P70, DOI 10.1016/j.neunet.2019.12.027
   Ye PD, 2019, IEEE SPECTRUM, V56, P30, DOI 10.1109/mspec.2019.8784120
   Zeng X, 2020, IEEE T COMPUT, V69, P968, DOI 10.1109/TC.2020.2978475
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang QC, 2018, IEEE T SYST MAN CY-S, V48, P1657, DOI 10.1109/TSMC.2017.2701797
   Zhang RX, 2018, P INT COMP SOFTW APP, P546, DOI 10.1109/COMPSAC.2018.10292
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang ZC, 2020, NEURAL COMPUT APPL, V32, P1327, DOI 10.1007/s00521-019-04550-w
   Zhao YL, 2018, ALGORITHMS, V11, DOI 10.3390/a11100159
   Zhao Z Q, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI [DOI 10.1109/TNNLS.2018.2876865, 10.11091NNES.2018.2876865.]
   Zheng QM, 2019, IEEE ACCESS, V7, P151359, DOI 10.1109/ACCESS.2019.2948112
   Zhou S., 2016, ARXIV160606160
   Zhou W, 2019, IEEE INTERNET THINGS, V6, P1606, DOI 10.1109/JIOT.2018.2847733
   Zhu F, 2020, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR42600.2020.00204
   Zhu ZH, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317739
   Zulkifley MA, 2019, IEEE ACCESS, V7, P32383, DOI 10.1109/ACCESS.2019.2903829
NR 145
TC 18
Z9 19
U1 10
U2 44
PD NOV
PY 2022
VL 33
IS 11
BP 6068
EP 6088
DI 10.1109/TNNLS.2021.3082304
EA JUN 2021
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Winklehner, D
   Conrad, JM
   Schoen, D
   Yampolskaya, M
   Adelmann, A
   Mayani, S
   Muralikrishnan, S
AF Winklehner, Daniel
   Conrad, Janet M.
   Schoen, Devin
   Yampolskaya, Maria
   Adelmann, Andreas
   Mayani, Sonali
   Muralikrishnan, Sriramkrishnan
TI Order-of-magnitude beam current improvement in compact cyclotrons
SO NEW JOURNAL OF PHYSICS
DT Article
DE high current; many-particle dynamics; machine learning; cyclotrons;
   particle-in-cell
ID PARTICLE
AB There is great need for high intensity proton beams from compact particle accelerators in particle physics, medical isotope production, and materials- and energy-research. To address this need, we present, for the first time, a design for a compact isochronous cyclotron that will be able to deliver 10 mA of 60 MeV protons-an order of magnitude higher than on-market compact cyclotrons and a factor four higher than research machines. A key breakthrough is that vortex motion is incorporated in the design of a cyclotron, leading to clean extraction. Beam losses on the septa of the electrostatic extraction channels stay below 120 W (40% below the required safety limit), while maintaining good beam quality. We present a set of highly accurate particle-in-cell simulations, and an uncertainty quantification of select beam input parameters using machine learning, showing the robustness of the design. This design can be utilized for beams for experiments in particle and nuclear physics, materials science and medical physics as well as for industrial applications.
C1 [Winklehner, Daniel; Conrad, Janet M.; Schoen, Devin; Yampolskaya, Maria] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Adelmann, Andreas; Mayani, Sonali; Muralikrishnan, Sriramkrishnan] Paul Scherrer Inst, CH-5232 Villigen, Switzerland.
RP Winklehner, D (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM winklehn@mit.edu
CR Aberle C., 2013, ARXIV13072949
   Abs M, 2012, ARXIV12074895
   Abs M., 2015, ARXIV151105130
   ADAM S, 1985, IEEE T NUCL SCI, V32, P2507, DOI 10.1109/TNS.1985.4333962
   Adelmann A., 2019, ARXIV190506654PHYSIC
   Adelmann A., 2012, ARXIV12104454PHYSICS
   Adelmann A, 2019, SIAM-ASA J UNCERTAIN, V7, P383, DOI 10.1137/16M1061928
   Alonso J., 2010, ARXIV10060260
   Alonso JR, 2019, NAT REV PHYS, V1, P533, DOI 10.1038/s42254-019-0095-6
   [Anonymous], 2019, BEST 70P CYCL
   [Anonymous], 2020, COMS MULT
   [Anonymous], 2000, HIER DAT FORM VERS 5
   [Anonymous], 2013, CYCLONE 70 IBA ION B
   Axani S, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4932395
   Baumgarten C, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.114201
   Baumgarten C, 2020, P 22 INT C CYCL THEI
   Bertrand P, 2001, AIP CONF PROC, V600, P379, DOI 10.1063/1.1435281
   Biarrotte J., 2013, P SRF13
   Bungau A, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/03/P03001
   Bungau A, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.141802
   Calabretta L., 2011, ARXIV11070652
   Calanna A., 2012, P 3 INT C PART ACC I, Vvol C1205201, P424
   Campo D., 2013, P CYCL 2013 VANC CAN
   Conjat M., 2018, CENTRAL REGION STUDI
   Conrad Janet M., 2012, Nuclear Physics B, Proceedings Supplements, V229-232, P386, DOI 10.1016/j.nuclphysbps.2012.09.061
   Debusschere B., 2017, HDB UNCERTAINTY QUAN, P1807
   Diaz A, 2020, PHYS REP, V884, P1, DOI 10.1016/j.physrep.2020.08.005
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Frey M, 2021, COMPUT PHYS COMMUN, V258, DOI 10.1016/j.cpc.2020.107577
   Grillenberger J, 2013, P CYCL 2013 VANC, P3
   Inoue K, 2004, INT J MOD PHYS A, V19, P1157, DOI 10.1142/S0217751X04019081
   Ishi Yoshihiro, 2010, P IPAC10 KYOT, P1323
   Jepeal SJ, 2021, MATER DESIGN, V200, DOI 10.1016/j.matdes.2020.109445
   Jepeal SJ, 2021, NUCL INSTRUM METH B, V489, P41, DOI 10.1016/j.nimb.2020.12.020
   Joho W, 1981, 9 INT C CYCL THEIR A, P11
   Kleeven W., 2016, 21 INT C CYCL THEIR, P7
   Kolano A, 2018, NUCL INSTRUM METH A, V885, P54, DOI 10.1016/j.nima.2017.12.045
   KOSCIELNIAK SR, 1993, PROCEEDINGS OF THE 1993 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P3639, DOI 10.1109/PAC.1993.309743
   Lisowski P., 1997, P PAC97, V97, P3780
   Moeslang A, 2006, FUSION ENG DES, V81, P863, DOI 10.1016/j.fusengdes.2005.07.044
   OPAL Collaboration, 2021, OPAL FRAM VERS 2 4
   Python Software Foundation, 2021, PYTHON LANGUAGE REFE
   Rubbia C., 1995, CONCEPTUAL DESIGN FA
   Schmor P., 2010, P 19 INT C CYCL THEI, P419
   Seidel M., 2010, P IPAC 10 KYOT JAP, P5
   Smirnov K., 2016, P CYCL 2016 ZUR SWIT
   Sobol IM, 2001, MATH COMPUT SIMULAT, V55, P271, DOI 10.1016/S0378-4754(00)00270-6
   Stetson J., 1992, 13 INT C CYCL THEIR, P4
   Sudret B, 2008, RELIAB ENG SYST SAFE, V93, P964, DOI 10.1016/j.ress.2007.04.002
   Waites LH, 2020, EJNMMI RADIOPHARM CH, V5, DOI 10.1186/s41181-020-0090-3
   Winklehner D, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4935753
   Winklehner D., 2020, ARXIV200812292PHYSIC
   Winklehner D, 2018, NUCL INSTRUM METH A, V907, P231, DOI 10.1016/j.nima.2018.07.036
   Winklehner D, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.124201
   Yang JJ, 2013, NUCL INSTRUM METH A, V704, P84, DOI 10.1016/j.nima.2012.12.050
   Yang JJ, 2010, PHYS REV SPEC TOP-AC, V13, DOI 10.1103/PhysRevSTAB.13.064201
   Zinkle SJ, 2018, SCRIPTA MATER, V143, P154, DOI 10.1016/j.scriptamat.2017.06.041
NR 57
TC 3
Z9 4
U1 0
U2 3
PD FEB 1
PY 2022
VL 24
IS 2
AR 023038
DI 10.1088/1367-2630/ac5001
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Akhunov, K
   Yildirim, KS
AF Akhunov, Khakim
   Yildirim, Kasim Sinan
BE Jenihhin, M
   Kubatova, H
   Metens, N
   Raik, J
   Ahmed, F
   Belohoubek, J
TI LUTIC: A CRAM-based Architecture for Power Failure Resilient In-Memory
   Computing
SO 2023 26TH INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS AND SYSTEMS, DDECS
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 26th International Symposium on Design and Diagnostics of Electronic
   Circuits and Systems (DDECS)
CY MAY 03-05, 2023
CL Tallinn, ESTONIA
DE intermittent computing; in-memory computing
AB Processing In-Memory (PIM) based on emerging non-volatile memory technologies can accelerate machine learning tasks even for batteryless devices operating intermittently. However, existing PIM solutions for intermittent systems offer limited parallelism and do not support a high degree of programmability. This paper presents LUTIC -a novel architecture that can accelerate a broader class of intermittent data-intense operations. Our results demonstrate that, compared to existing commercial low-energy accelerators and PIM solutions for intermittent computing, LUTIC improves performance and energy efficiency with better parallelism support.
C1 [Akhunov, Khakim; Yildirim, Kasim Sinan] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
RP Akhunov, K (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
EM khakim.akhunov@unitn.it; kasimsinan.yildirim@unitn.it
CR Akhunov Khakim, 2022, P ACM INT MOB WEAR U, V6, P1
   [Anonymous], MSP430T MICR
   Ferreira JD, 2022, INT SYMP MICROARCH, P900, DOI 10.1109/MICRO56248.2022.00067
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Gobieski G, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P199, DOI 10.1145/3297858.3304011
   Instruments T., MSP430T MICR
   Kotz D., CRAWDAD DATASET DART
   Resch S., 2021, ACM T EMBED COMPUT S
   Resch S, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P400, DOI 10.1109/MICRO50266.2020.00042
   Wang J.-P., 2015, uS Patent, Patent No. [9,224,447, 9224447]
   Yildirim KS, 2018, SENSYS'18: PROCEEDINGS OF THE 16TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P41, DOI 10.1145/3274783.3274837
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 69
EP 72
DI 10.1109/DDECS57882.2023.10139576
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Park, KH
   Cho, MH
   Jeon, YD
   Lee, JH
AF Park, Ki-Hyuk
   Cho, Min-Hyung
   Jeon, Young-Deuk
   Lee, Joo-Hyun
GP IEEE
TI Design of Analog and Digital Hybrid MAC Circuit for Artificial Neural
   Networks
SO 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND
   COMMUNICATION (ICEIC)
DT Proceedings Paper
CT 18th Annual International Conference on Electronics, Information, and
   Communication (ICEIC)
CY JAN 22-25, 2019
CL Inst Elect & Informat Engineers, Auckland, NEW ZEALAND
HO Inst Elect & Informat Engineers
DE MAC; analog; digital; hybrid; neural network
AB Demand for high-performance hardware acceleration for machine learning applications is increasing rapidly. This paper presents a low power analog and digital hybrid MAC (Multiply and Accumulation) circuit for artificial neural networks. The proposed MAC circuit consists of an analog synapse unit, digital preprocessing and postprocessing unit for support of the parallel analog synapse cores. As the hybrid MAC circuit supports relatively low power and fast multiple MAC operations, it provides a good advantage in developing hardware accelerator for artificial neural networks.
C1 [Park, Ki-Hyuk; Cho, Min-Hyung; Jeon, Young-Deuk; Lee, Joo-Hyun] Elect & Telecommun Res Inst, Processor Res Grp, Daejeon, South Korea.
RP Park, KH (corresponding author), Elect & Telecommun Res Inst, Processor Res Grp, Daejeon, South Korea.
EM hyuk@etri.re.kr
CR Ahmed HO, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P31, DOI 10.1109/ISCAIE.2018.8405440
   Garland J, 2017, IEEE COMPUT ARCHIT L, V16, P132, DOI 10.1109/LCA.2017.2656880
   Hoang TT, 2010, IEEE T CIRCUITS-I, V57, P3073, DOI 10.1109/TCSI.2010.2091191
   Miyashita D, 2017, IEEE J SOLID-ST CIRC, V52, P2679, DOI 10.1109/JSSC.2017.2712626
NR 4
TC 0
Z9 0
U1 1
U2 1
PY 2019
BP 509
EP 511
DI 10.23919/elinfocom.2019.8706340
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT J
AU Feng, K
   Kong, T
   Koul, K
   Melchert, J
   Carsello, A
   Liu, QY
   Nyengele, G
   Strange, M
   Zhang, KY
   Nayak, A
   Setter, J
   Thomas, J
   Sreedhar, K
   Chen, PH
   Bhagdikar, N
   Myers, ZA
   D'Agostino, B
   Joshi, P
   Richardson, S
   Torng, C
   Horowitz, M
   Raina, P
AF Feng, Kathleen
   Kong, Taeyoung
   Koul, Kalhan
   Melchert, Jackson
   Carsello, Alex
   Liu, Qiaoyi
   Nyengele, Gedeon
   Strange, Maxwell
   Zhang, Keyi
   Nayak, Ankita
   Setter, Jeff
   Thomas, James
   Sreedhar, Kavya
   Chen, Po-Han
   Bhagdikar, Nikhil
   Myers, Zach A.
   D'Agostino, Brandon
   Joshi, Pranil
   Richardson, Stephen
   Torng, Christopher
   Horowitz, Mark
   Raina, Priyanka
TI Amber: A 16-nm System-on-Chip With a Coarse-Grained Reconfigurable Array
   for Flexible Acceleration of Dense Linear Algebra
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article; Early Access
DE Hardware; Field programmable gate arrays; Switches; Registers; Random
   access memory; Multiplexing; Linear algebra; Coarse-grained
   reconfigurable array (CGRA); computer architecture; computer vision;
   image processing; machine learning (ML); reconfigurable accelerators;
   system-on-chip (SoC)
ID PARALLELISM
AB Amber is a system-on-chip (SoC) with a coarse-grained reconfigurable array (CGRA) for acceleration of dense linear algebra applications, such as machine learning (ML), image processing, and computer vision. It is designed using an agile accelerator-compiler codesign flow; the compiler updates automatically with hardware changes, enabling continuous application-level evaluation of the hardware-software system. To increase hardware utilization and minimize reconfigurability overhead, Amber features the following: 1) dynamic partial reconfiguration (DPR) of the CGRA for higher resource utilization by allowing fast switching between applications and partitioning resources between simultaneous applications; 2) streaming memory controllers supporting affine access patterns for efficient mapping of dense linear algebra; and 3) low-overhead transcendental and complex arithmetic operations. The physical design of Amber features a unique clock distribution method and timing methodology to efficiently layout its hierarchical and tile-based design. Amber achieves a peak energy efficiency of 538 INT16 GOPS/W and 483 BFloat16 GFLOPS/W. Compared with a CPU, a GPU, and a field-programmable gate array (FPGA), Amber has up to 3902x , 152x, and 107x better energy-delay product (EDP), respectively.
C1 [Feng, Kathleen; Kong, Taeyoung; Koul, Kalhan; Melchert, Jackson; Carsello, Alex; Liu, Qiaoyi; Nyengele, Gedeon; Strange, Maxwell; Nayak, Ankita; Setter, Jeff; Sreedhar, Kavya; Chen, Po-Han; Bhagdikar, Nikhil; Myers, Zach A.; D'Agostino, Brandon; Joshi, Pranil; Richardson, Stephen; Torng, Christopher; Horowitz, Mark; Raina, Priyanka] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
   [Zhang, Keyi; Thomas, James] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Feng, K (corresponding author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
EM kzf@stanford.edu
CR Bahr R, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218553
   Carsello Alex, 2022, 2022 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits), P70, DOI 10.1109/VLSITechnologyandCir46769.2022.9830509
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chin SA, 2017, IEEE INT CONF ASAP, P184, DOI 10.1109/ASAP.2017.7995277
   cloud.google, BFLOAT16 NUMERICAL F
   developer.arm, ARM CORELINK TLX 400
   developer.arm, ARM CORTEX M3
   Farabet C., 2011, LARGE SCALE FPGA BAS
   Francisco-Javier Veredas, 2005, Proceedings. 2005 International Conference on Field Programmable Logic and Applications (IEEE Cat. No.05EX1155), P106
   Govindaraju V, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.51
   Imran Masud M., 1999, Field Programmable Logic and Applications. 9th International Workshop, FPL'99. Proceedings (Lecture Notes in Computer Science Vol.1673), P274
   intel, BFLOAT16 HARDWARE NU
   Karunaratne M, 2017, DES AUT CON, DOI 10.1145/3061639.3062262
   Komatsu S, 2013, FUJITSU SCI TECH J, V49, P17
   Koul K, 2023, ACM T EMBED COMPUT S, V22, DOI 10.1145/3534933
   Liu QY, 2023, ACM T ARCHIT CODE OP, V20, DOI 10.1145/3572908
   Melchert J., 2022, ARXIV
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Nayak A, 2023, ACM T RECONFIG TECHN, V16, DOI 10.1145/3558394
   Nayak A, 2020, DES AUT TEST EUROPE, P846, DOI 10.23919/DATE48585.2020.9116477
   Nguyen M, 2019, I C FIELD PROG LOGIC, P129, DOI 10.1109/FPL.2019.00029
   Parashar A., 2013, P 40 ANN INT S COMP, P142
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Rathore U., 2022, IEEE INT SOLID STATE, V65, P52
   Rovinski A, 2019, SYMP VLSI CIRCUITS, pC30, DOI [10.23919/vlsic.2019.8778031, 10.23919/VLSIC.2019.8778031]
   Salamat S, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P53, DOI 10.1145/3289602.3293913
   Schmidt C, 2021, ISSCC DIG TECH PAP I, V64, P58, DOI 10.1109/ISSCC42613.2021.9365789
   Stein G. P., 2005, IEEE COMPUTER SOC C, P130
   Sumbul H. E., 2022, PROC IEEE CUST INT C, P1
   Tan C, 2021, PR IEEE COMP DESIGN, P33, DOI 10.1109/ICCD53106.2021.00018
   Torng C, 2021, INT S HIGH PERF COMP, P412, DOI 10.1109/HPCA51647.2021.00042
   Vasilyev A, 2016, INT SYMP MICROARCH
   Weste N. H. E., 1993, PRINCIPLES CMOS VLSI
   Whatmough P. N., 2019, P S VLSI CIRC JUN, P34
   Wu LS, 2019, INT S HIGH PERF COMP, P277, DOI 10.1109/HPCA.2019.00044
   Xilinx, 2020, VERS 1 AD COMP ACC P
   Yulin Chen, 2021, 2021 IEEE Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC), P1290, DOI 10.1109/IPEC51340.2021.9421209
   Zhang Qirui, 2022, 2022 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits), P72, DOI 10.1109/VLSITechnologyandCir46769.2022.9830340
   Zimmer B, 2020, IEEE J SOLID-ST CIRC, V55, P920, DOI 10.1109/JSSC.2019.2960488
NR 42
TC 0
Z9 0
U1 3
U2 3
PD 2023 SEP 22
PY 2023
DI 10.1109/JSSC.2023.3313116
EA SEP 2023
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Shahshahani, M
   Khabbazan, B
   Sabri, M
   Bhatia, D
AF Shahshahani, Masoud
   Khabbazan, Bahareh
   Sabri, Mohammad
   Bhatia, Dinesh
GP IEEE
TI A Framework for Modeling, Optimizing, and Implementing DNNs on FPGA
   Using HLS
SO PROCEEDINGS OF THE 2020 IEEE DALLAS CIRCUITS AND SYSTEMS CONFERENCE
   (DCAS 2020)
DT Proceedings Paper
CT 14th IEEE Dallas Circuits and Systems Conference (DCAS)
CY NOV 15-16, 2020
CL Univ Texas Dallas, ELECTR NETWORK
HO Univ Texas Dallas
DE Field Programmable Gate Arrays; Deep Neural Networks; Design Space
   Exploration; High Level Synthesis
AB Deep Neural Networks (DNNs) are gaining importance for implementing large inference engines. A designer must consider numerous design choices, data-flow types, processing elements, memory hierarchy, and data-precision for a DNN implementation. A collaborative algorithm/model/hardware tool is needed to enable a reconfigurable, fast, and efficient DNN hardware accelerator. We propose an accelerator framework that automatically generates an optimized FPGA-based model given DNNs from standard machine learning frameworks without humans in the loop. For faster, accurate, and efficient hardware implementation, the framework employs a coarse-grained software-model to estimate the performance and hardware utilization using mathematical relations. The results are a High-Level-Synthesis (HLS) code with a set of optimization pragmas for fine-tuning to optimizes the hardware generated from the previous phase. Various hardware-accelerator architecture can be selected based on user preferences such as performance and FPGA chip, and the neural network size. The hardware implementation of various DNN models is shown to prove the proposed framework's flexibility and performance.
C1 [Shahshahani, Masoud; Bhatia, Dinesh] Univ Texas Dallas, Sch Elect & Comp Engn, Richardson, TX 75083 USA.
   [Khabbazan, Bahareh] Iran Univ Technol, Sch Elect Engn, Tehran, Iran.
   [Sabri, Mohammad] Univ Tehran, Coll Engn, Tehran, Iran.
RP Shahshahani, M (corresponding author), Univ Texas Dallas, Sch Elect & Comp Engn, Richardson, TX 75083 USA.
EM masoud.shahshahani@utdallas.edu; b_khabbazan@alumni.iust.ac.ir;
   Mohammad.sabri@ut.ac.ir; dinesh@utdallas.edu
CR [Anonymous], 2016, DAC
   [Anonymous], 2015, FPGA
   Bhatia D, 2018, IEEE DCAS
   Hailesellasie MT, 2019, IEEE ACCESS, V7, P47509, DOI 10.1109/ACCESS.2019.2907865
   Liu H, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201701616
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Mirzakuchaki S, 2019, DSD
   Mu J., 2018, FPL
   Schafer BC, 2017, 2017 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P129, DOI 10.1109/DSD.2017.56
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   VENIERIS SI, 2017, I C FIELD PROG LOGIC, DOI DOI 10.23919/FPL.2017.8056828
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
NR 12
TC 3
Z9 3
U1 0
U2 1
PY 2020
DI 10.1109/DCAS51144.2020.9330667
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Yu, ZM
   Menzel, S
   Strachan, JP
   Neftci, E
AF Yu, Zhenming
   Menzel, Stephan
   Strachan, John Paul
   Neftci, Emre
BE Matthews, MB
TI Integration of physics-derived memristor models with machine learning
   frameworks
SO 2022 56TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS, AND COMPUTERS
SE Conference Record of the Asilomar Conference on Signals Systems and
   Computers
DT Proceedings Paper
CT 56th Asilomar Conference on Signals, Systems, and Computers
CY OCT 31-NOV 02, 2022
CL ELECTR NETWORK
AB Simulation frameworks such MemTorch [1] [2], DNN+NeuroSim [3] [4], and aihwkit [5] are commonly used to facilitate the end-to-end co-design of memristive machine learning (ML) accelerators. These simulators can take device nonidealities into account and are integrated with modern ML frameworks. However, memristors in these simulators are modeled with either lookup tables or simple analytic models with basic nonlinearities. These simple models are unable to capture certain performance-critical aspects of device nonidealities. For example, they ignore the physical cause of switching, which induces errors in switching timings and thus incorrect estimations of conductance states. This work aims at bringing physical dynamics into consideration to model nonidealities while being compatible with GPU accelerators. We focus on Valence Change Memory (VCM) cells, where the switching nonlinearity and SET/RESET asymmetry relate tightly with the thermal resistance, ion mobility, Schottky barrier height, parasitic resistance, and other effects [6]. The resulting dynamics require solving an ODE that captures changes in oxygen vacancies. We modified a physics-derived SPICE-level VCM model [7] [8], integrated it with the aihwkit [5] simulator and tested the performance with the MNIST dataset. Results show that noise that disrupts the SET/RESET matching affects network performance the most. This work serves as a tool for evaluating how physical dynamics in memristive devices affect neural network accuracy and can be used to guide the development of future integrated devices.
C1 [Yu, Zhenming; Menzel, Stephan; Strachan, John Paul; Neftci, Emre] Rhein Westfal TH Aachen, Fak Elektrotech & Informat Tech, D-52074 Aachen, Germany.
   [Yu, Zhenming; Strachan, John Paul; Neftci, Emre] Forschungszentrum Julich, Peter Grunberg Inst, D-52425 Julich, Germany.
RP Yu, ZM (corresponding author), Rhein Westfal TH Aachen, Fak Elektrotech & Informat Tech, D-52074 Aachen, Germany.; Yu, ZM (corresponding author), Forschungszentrum Julich, Peter Grunberg Inst, D-52425 Julich, Germany.
EM z.yu@fz-juelich.de; e.neftci@fz-juelich.de
CR Bengel C, 2020, IEEE T CIRCUITS-I, V67, P4618, DOI 10.1109/TCSI.2020.3018502
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Cüppers F, 2019, APL MATER, V7, DOI 10.1063/1.5108654
   Fu X., 2022, IEEE T CIRCUITS-II
   Gokmen T, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00103
   Hardtdegen A, 2018, IEEE T ELECTRON DEV, V65, P3229, DOI 10.1109/TED.2018.2849872
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Lammie Corey, 2020, 2020 IEEE International Symposium on Circuits and Systems (ISCAS), DOI [10.1109/ISCAS45731.2020.9180810, 10.1109/ISCAS45731.2020.9180682]
   Lammie C., 2021, ARRAY
   Lammie C, 2022, NEUROCOMPUTING, V485, P124, DOI 10.1016/j.neucom.2022.02.043
   Lee C, 2022, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.767953
   Mayahinia M., ACM J EMERG TECH COM, V18, P1
   Ntinas V., 2022, IEEE T CIRCUITS-II
   Peng XC, 2021, IEEE T COMPUT AID D, V40, P2306, DOI 10.1109/TCAD.2020.3043731
   Rasch MJ, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458494
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
NR 16
TC 0
Z9 0
U1 3
U2 3
PY 2022
BP 1142
EP 1146
DI 10.1109/IEEECONF56349.2022.10052010
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic;
   Telecommunications
DA 2023-11-11
ER

PT J
AU Wang, Z
   Verma, N
AF Wang, Zhuo
   Verma, Naveen
TI A Low-Energy Machine-Learning Classifier Based on Clocked Comparators
   for Direct Inference on Analog Sensors
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Classification; comparators; low-energy accelerator
ID ACCELERATORS; PROCESSOR; ERROR; CMOS
AB This paper presents a system, where clocked comparators consuming only CV2 energy directly derive classification decisions from analog sensor signals, thereby replacing instrumentation amplifiers, ADCs, and digital MACs, as typically required. A machine-learning algorithm for training the classifier is presented, which enables circuit non-idealities as well as severe energy/area scaling in analog circuits to be overcome. Furthermore, a noise model of the system is presented and experimentally verified, providing a means to predict and optimize classification error probability in a given application. The noise model shows that superior noise efficiency is achieved by the comparator-based system compared with a system based on linear low-noise amplifiers. A prototype in 130-nm CMOS performs image recognition of handwritten numerical digits, by taking raw analog pixels as the inputs. Due to pin limitations on the chip, the images with 28 x 28 = 784 pixels are resized and downsampled to give 47 pixel features, yielding an accuracy of 90% for an ideal ten-way classification system ( MATLAB simulated). The prototype comparator-based system achieves equivalent performance with a total energy of 543 pJ per ten-way classification at a rate up to 1.3 M images per second, representing 33 x lower energy than an ADC/digital-MAC system.
C1 [Wang, Zhuo; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Wang, Z (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM pku.zwang@gmail.com; nverma@princeton.edu
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2016, IEEE T BIOMED CIRC S
   [Anonymous], 2012, BOOSTING ADAPTIVE CO
   [Anonymous], 2016, P IEEE S VLSI CIRC V
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chippa VK, 2010, DES AUT CON, P555
   Genov R, 2001, IEEE T CIRCUITS-II, V48, P930, DOI 10.1109/82.974781
   Gurobi Optimization Inc, 2012, GUROBI OPTIMIZER REF
   Guyon I., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hanson S, 2009, SYMP VLSI CIRCUITS, P176
   Kang K, 2010, IEEE T CIRCUITS-I, V57, P1513, DOI 10.1109/TCSI.2009.2034234
   Kim EP, 2012, IEEE T COMPUT, V61, P323, DOI 10.1109/TC.2010.253
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee EH, 2016, ISSCC DIG TECH PAP I, V59, P418, DOI 10.1109/ISSCC.2016.7418085
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Leem L, 2010, DES AUT TEST EUROPE, P1560
   Lu J, 2015, IEEE J SOLID-ST CIRC, V50, P270, DOI 10.1109/JSSC.2014.2356197
   Park S, 2016, ISSCC DIG TECH PAP I, V59, P254
   Rieutort-Louis W, 2016, IEEE J SOLID-ST CIRC, V51, P281, DOI 10.1109/JSSC.2015.2489842
   Sepke T, 2009, IEEE T CIRCUITS-I, V56, P541, DOI 10.1109/TCSI.2008.2002547
   Sharpeshkar R., 2010, ULTRALOW POWER BIOEL
   Verma N, 2010, IEEE J SOLID-ST CIRC, V45, P804, DOI 10.1109/JSSC.2010.2042245
   Wang Z, 2015, INT CONF ACOUST SPEE, P1032, DOI 10.1109/ICASSP.2015.7178126
   Wang Z, 2015, IEEE T BIOMED CIRC S, V9, P825, DOI 10.1109/TBCAS.2015.2500101
   Wang Z, 2015, IEEE T VLSI SYST, V23, P1459, DOI 10.1109/TVLSI.2014.2342153
   Wang Z, 2015, IEEE T CIRCUITS-I, V62, P1136, DOI 10.1109/TCSI.2015.2395591
   WU JT, 1988, IEEE J SOLID-ST CIRC, V23, P1379, DOI 10.1109/4.90034
   Yao E, 2017, IEEE T VLSI SYST, V25, P60, DOI 10.1109/TVLSI.2016.2558842
   Yetim Y, 2013, DES AUT TEST EUROPE, P202
   Zhang JX, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/4350965
NR 30
TC 22
Z9 22
U1 0
U2 0
PD NOV
PY 2017
VL 64
IS 11
BP 2954
EP 2965
DI 10.1109/TCSI.2017.2703880
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU De Morsier, F
   Alonso, V
   Nguyen, L
AF De Morsier, Frank
   Alonso, Veronica
   Linh Nguyen
TI AI-powered Object Detection as a Mapping-business Accelerator
   <i>Geospatial Imagery Analytics Market Expected to Reach US</i>$<i>8
   Billion by 2025</i>
SO GIM INTERNATIONAL-THE WORLDWIDE MAGAZINE FOR GEOMATICS
DT Editorial Material
AB UAV, aerial and satellite mapping service providers are competing for the global market - with a rising hunger - for geospatial insights. Automating the feature extraction process is key to accelerating, scaling up and diversifying a location intelligence service portfolio. Cloud-based platforms coupling cutting-edge machine learning research with a user-friendly implementation offer a powerful turnkey and cost-effective solution to those looking to gain competitivity by incorporating artificial intelligence (AI) automation into their workflows.
NR 0
TC 0
Z9 0
U1 1
U2 2
PD SEP-OCT
PY 2019
VL 33
IS 5
BP 45
EP 47
WC Remote Sensing
DA 2023-11-11
ER

PT J
AU Koser, D
   Waites, L
   Winklehner, D
   Frey, M
   Adelmann, A
   Conrad, J
AF Koser, Daniel
   Waites, Loyd
   Winklehner, Daniel
   Frey, Matthias
   Adelmann, Andreas
   Conrad, Janet
TI Input Beam Matching and Beam Dynamics Design Optimizations of the IsoDAR
   RFQ Using Statistical and Machine Learning Techniques
SO FRONTIERS IN PHYSICS
DT Article
DE radio frequency quadrupole; beam dynamics design; beam matching; virtual
   accelerator; isodar; surrogate modelling; neural network; polynomial
   chaos expansion
ID GLOBAL SENSITIVITY-ANALYSIS; MODELS
AB We present a novel machine learning-based approach to generate fast-executing virtual radiofrequency quadrupole (RFQ) particle accelerators using surrogate modelling. These could potentially be used as on-line feedback tools during beam commissioning and operation, and to optimize the RFQ beam dynamics design prior to construction. Since surrogate models execute orders of magnitude faster than corresponding physics beam dynamics simulations using standard tools like PARMTEQM and RFQGen, the computational complexity of the multi-objective optimization problem reduces significantly. Ultimately, this presents a computationally inexpensive and time efficient method to perform sensitivity studies and an optimization of the crucial RFQ beam output parameters like transmission and emittances. Two different methods of surrogate model creation (polynomial chaos expansion and neural networks) are discussed and the achieved model accuracy is evaluated for different study cases with gradually increasing complexity, ranging from a simple FODO cell example to the full RFQ optimization. We find that variations of the beam input Twiss parameters can be reproduced well. The prediction of the beam with respect to hardware changes, e.g., the electrode modulation, are challenging on the other hand. We discuss possible reasons for that and elucidate nevertheless existing benefits of the applied method to RFQ beam dynamics design.
EM dkoser@mit.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Abs M, 2015, Arxiv, DOI arXiv:1511.05130
   Adelmann A., 2015, PSIPR0802
   Adelmann A, 2019, SIAM-ASA J UNCERTAIN, V7, P383, DOI 10.1137/16M1061928
   Bellotti R, 2021, INFORMATION, V12, DOI 10.3390/info12090351
   Bergoz, 2020, BERG ACCT PREC WAV M
   Bungau A, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.141802
   Calanna A., 2012, COMPACT HIGH INTENSI, P424
   Chollet F., 2015, KERAS, P33
   Crandall K., 1979, P LINAC1979
   Crandall K. R., 1988, AIP Conference Proceedings, P22, DOI 10.1063/1.37798
   Crandall K.R., 2005, RFQ DESIGN CODES
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Diaz A, 2019, Arxiv, DOI arXiv:1906.00045
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen AL, 2016, Arxiv, DOI arXiv:1612.05662
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   ELLACOTT SW, 1994, J COMPUT APPL MATH, V50, P283, DOI 10.1016/0377-0427(94)90307-7
   Frey M, 2021, COMPUT PHYS COMMUN, V258, DOI 10.1016/j.cpc.2020.107577
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Kirschner J., 2019, FEL2019 P 39 INT FRE, P707, DOI DOI 10.3929/ETHZ-B-000385955
   Kirschner J, 2019, Arxiv, DOI arXiv:1902.03229
   Neveu N, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.054602
   Nogueira F., 2014, BAYESIAN OPTIMIZATIO
   Pinkus A., 1999, Acta Numerica, V8, P143, DOI 10.1017/S0962492900002919
   Reiser M., 2008, THEORY DESIGN CHARGE, V2nd
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren X, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.040701
   Sobol IM, 2001, MATH COMPUT SIMULAT, V55, P271, DOI 10.1016/S0378-4754(00)00270-6
   Sudret B, 2008, RELIAB ENG SYST SAFE, V93, P964, DOI 10.1016/j.ress.2007.04.002
   Van Der Veken F., 2020, SISSA MEDIALAB, V372, P044, DOI [10.22323/1.372.0044, DOI 10.22323/1.372.0044]
   Winklehner D., 2021, ARXIV
   Winklehner D, 2015, 6 INT PARTICLE ACCEL
   Winklehner D, 2018, NUCL INSTRUM METH A, V907, P231, DOI 10.1016/j.nima.2018.07.036
NR 35
TC 2
Z9 2
U1 1
U2 3
PD APR 25
PY 2022
VL 10
AR 875889
DI 10.3389/fphy.2022.875889
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Dai, Y
   Tang, XL
   Zhang, YT
AF Dai, Yue
   Tang, Xulong
   Zhang, Youtao
TI An efficient segmented quantization for graph neural networks
SO CCF TRANSACTIONS ON HIGH PERFORMANCE COMPUTING
DT Article
DE Graph neural network; Quantization; Accelerator
AB Graph Neural Networks (GNNs) are recently developed machine learning approaches that exploit the advances in Neural Networks for a wide range of graph applications. While GNNs achieve promising inference accuracy improvements over conventional approaches, their efficiency suffers from expensive computation and intensive memory access in feature aggregation and combination phases, leading to large inference latency. Recent studies proposed mixed-precision feature quantization to address the memory access overhead. However, its linear approximation and computation complexity become the main constraints for the overall GNN accuracy and performance. In this paper, we propose segmented quantization to partition the feature range into segments and customize linear approximation within each segment based on original value density, and conduct efficient mixed-precision computing between quantized feature and full precision weights. Segmented quantization helps to achieve high inference accuracy while maintaining low computation complexity. We also devise the hardware accelerator to fully explore the benefits of segmented quantization. Our experiments show that up to 5% average accuracy and up to 6.8x performance improvements can be achieved over the state-of-the-art GNN accelerators.
C1 [Dai, Yue; Tang, Xulong; Zhang, Youtao] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15213 USA.
RP Dai, Y (corresponding author), Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15213 USA.
EM yud42@pitt.edu; xulongtang@pitt.edu; zhangyt@cs.pitt.edu
CR Auten A, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218751
   Chen X., 2021, IEEE T COMPUT AID D
   Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038
   Feng BY, 2020, PROC INT C TOOLS ART, P1044, DOI 10.1109/ICTAI50040.2020.00198
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Geng Tong, 2021, MICRO54 54 ANN IEEE, P1051
   Hamilton WL, 2017, ADV NEUR IN, V30
   Han S., 2015, ARXIV151000149
   Hubara I, 2016, ADV NEUR IN, V29
   Imani M, 2020, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA47549.2020.00011
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jun Fang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P69, DOI 10.1007/978-3-030-58536-5_5
   Thekumparampil KK, 2018, Arxiv, DOI [arXiv:1803.03735, DOI 10.48550/ARXIV.1803.03735]
   Kiningham K, 2020, Arxiv, DOI arXiv:2007.13828
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Liu Zhenhua, 2021, ADV NEURAL INF PROCE, V34, P28092
   Long Y, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218737
   Marchisio A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207533
   Miyashita D, 2016, Arxiv, DOI arXiv:1603.01025
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]
   Park E, 2018, LECT NOTES COMPUT SC, V11208, P608, DOI 10.1007/978-3-030-01225-0_36
   Qu S., 2020, P 57 ACM IEEE DES AU, P1
   Tailor SA, 2021, Arxiv, DOI [arXiv:2008.05000, DOI 10.48550/ARXIV.2008.05000]
   Thoziyoor S, 2008, CONF PROC INT SYMP C, P51, DOI 10.1109/ISCA.2008.16
   Veličkovic P, 2018, Arxiv, DOI [arXiv:1710.10903, DOI 10.48550/ARXIV.1710.10903]
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Xu K., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1810.00826
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Zhou AJ, 2017, Arxiv, DOI arXiv:1702.03044
   Zhu CZ, 2017, Arxiv, DOI arXiv:1612.01064
NR 31
TC 1
Z9 1
U1 0
U2 0
PD DEC
PY 2022
VL 4
IS 4
SI SI
BP 461
EP 473
DI 10.1007/s42514-022-00121-z
EA NOV 2022
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Huang, SY
   Hoskins, BD
   Daniels, MW
   Stiles, MD
   Adam, GC
AF Huang, Siyuan
   Hoskins, Brian D.
   Daniels, Matthew W.
   Stiles, Mark D.
   Adam, Gina C.
GP Assoc Advancement Artificial Intelligence
TI Streaming Batch Gradient Tracking for Neural Network Training (Student
   Abstract)
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
DT Proceedings Paper
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
AB Faster and more energy efficient hardware accelerators are critical for machine learning on very large datasets. The energy cost of performing vector-matrix multiplication and repeatedly moving neural network models in and out of memory motivates a search for alternative hardware and algorithms. We propose to use streaming batch principal component analysis (SBPCA) to compress batch data during training by using a rank-k approximation of the total batch update. This approach yields comparable training performance to minibatch gradient descent (MBGD) at the same batch size while reducing overall memory and compute requirements.
C1 [Huang, Siyuan; Adam, Gina C.] George Washington Univ, Sch Engn & Appl Sci, Washington, DC 20052 USA.
   [Hoskins, Brian D.; Daniels, Matthew W.; Stiles, Mark D.] NIST, Phys Measurement Lab, Gaithersburg, MD 20899 USA.
RP Adam, GC (corresponding author), George Washington Univ, Sch Engn & Appl Sci, Washington, DC 20052 USA.
EM GinaAdam@gwu.edu
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   BURRELLO A, 2019, INT C COMP FRONT, P235, DOI DOI 10.1145/3310273.3322822
   Henriksen A., 2019, ARXIV190512115
   Hoskins BD, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00793
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
NR 6
TC 1
Z9 1
U1 0
U2 0
PY 2020
VL 34
BP 13813
EP 13814
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Education, Scientific Disciplines
DA 2023-11-11
ER

PT C
AU Danopoulos, D
   Kachris, C
   Soudris, D
AF Danopoulos, Dimitrios
   Kachris, Christoforos
   Soudris, Dimitrios
BE Fornaciari, W
   Novo, D
   Indrusiak, LS
TI FPGA Acceleration of Approximate KNN Indexing on High-Dimensional
   Vectors
SO 2019 14TH INTERNATIONAL SYMPOSIUM ON RECONFIGURABLE
   COMMUNICATION-CENTRIC SYSTEMS-ON-CHIP (RECOSOC 2019)
DT Proceedings Paper
CT 14th International Symposium on Reconfigurable Communication-Centric
   Systems-on-Chip (ReCoSoC)
CY JUL 01-03, 2019
CL York, ENGLAND
DE approximate KNN; nearest neighbor index; machine learning; FPGA;
   hardware accelerator
AB Accurate and efficient Machine Learning algorithms are of vital importance to many problems, especially on classification or clustering tasks. One the most important algorithms used for similarity search is known as K-Nearest Neighbor algorithm (KNN) which is widely adopted for predictive analysis, text categorization, image recognition etc. but comes at the cost of high computation. Large companies that process big data on modern data centers adopt this technique combined with approximations on algorithm level in order to compute critical workloads every second. However, a significant computation and energy overhead is formed further with the high dimensional nearest neighbor queries. In this paper, we deploy a hardware accelerated approximate KNN algorithm built upon FAISS framework (Facebook Artificial Intelligence Similarity Search) using FPGA-OpenCL platforms. The FPGA architecture on this framework addresses the problem of vector indexing on training and adding large-scale high-dimensional data. The proposed solution uses an in memory FPGA format that outperforms other high performance systems in terms of speed and energy efficiency. The experiments were done on Xilinx Alveo U200 FPGA achieving up to 115x accelerator-only speed-up over single-core CPU and 2.4 x end-to-end system speed-up over a 36 -thread Xeon CPU. Also, the performance/watt of the design was 4.1x from the same CPU and 1.4 x from a Kepler-class GPU.
C1 [Danopoulos, Dimitrios; Soudris, Dimitrios] NTUA, Dept Elect & Comp Engn, Athens, Greece.
   [Kachris, Christoforos] Democritus Univ Thrace, Athens, Greece.
   [Kachris, Christoforos] NTUA, ICCS, Athens, Greece.
RP Danopoulos, D (corresponding author), NTUA, Dept Elect & Comp Engn, Athens, Greece.
CR Andoni A., 2018, CORR
   [Anonymous], 2017, BILLION SCALE SIMILA
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760
   Chen Y., 2010, SENSORS
   Danopoulos D., 2018, 2018 7 INT C MODERN, P1, DOI 10.1109/MOCAST.2018.8376580
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hussain H. M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P475, DOI 10.1109/ReConFig.2011.49
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Kouiroukidis N., 2011, Proceedings of the 2011 15th Panhellenic Conference on Informatics (PCI 2011), P41, DOI 10.1109/PCI.2011.45
   Kybic J., 2010, APPROXIMATE BEST BIN, V10, P420
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Mavridis S, 2017, I C FIELD PROG LOGIC
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Pu YL, 2015, ANN IEEE SYM FIELD P, P167, DOI 10.1109/FCCM.2015.7
   Sharifzadehand M., 2019, APPROXIMATE VORONOI
   Xilinx Inc., SDACCEL DEV ENV
   Xuan SY, 2018, IEEE INT C NETW SENS
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
   Zhang JL, 2018, PROC CVPR IEEE, P4924, DOI 10.1109/CVPR.2018.00517
NR 21
TC 5
Z9 5
U1 1
U2 6
PY 2019
BP 59
EP 65
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kassa, HT
   Verma, T
   Austin, T
   Bertacco, V
AF Kassa, Hiwot Tadese
   Verma, Tarunesh
   Austin, Todd
   Bertacco, Valeria
GP IEEE
TI ChipAdvisor: A Machine Learning Approach for Mapping Applications to
   Heterogeneous Systems
SO PROCEEDINGS OF THE 2021 TWENTY SECOND INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2021)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 22nd International Symposium on Quality Electronic Design (ISQED)
CY APR 07-09, 2021
CL ELECTR NETWORK
AB While hardware accelerators provide significant performance and energy improvements over general-purpose processors, their limited reusability incurs high design costs. It is thus impractical to have a unique accelerator for each application. Hence, it is critical to develop solutions that can leverage the accelerators available to the best of their capabilities for a wide range of applications. In this paper, we note the common computation, data access, and communication patterns of applications, and based on these patterns, we identify significant intrinsic properties across applications. We then correlate these properties with the unique microarchitectural properties of the compute platforms available and develop a framework, ChipAdvisor, to predict the platform that provides the best performance and energy efficiency for an application. We evaluate ChipAdvisor for applications from several domains, targeting CPUs, GPUs, and FPGAs as example compute platforms. ChipAdvisor achieves an accuracy of up to 98% in predicting the best performing platform, and 94% in predicting the most energy-efficient one, compared to an oracle analysis, that is, one which always selects the best platform for all applications.
C1 [Kassa, Hiwot Tadese; Verma, Tarunesh; Austin, Todd; Bertacco, Valeria] Univ Michigan, Dept Comp Sci & Engn, Ann Arbor, MI 48109 USA.
RP Kassa, HT (corresponding author), Univ Michigan, Dept Comp Sci & Engn, Ann Arbor, MI 48109 USA.
EM hiwot@umich.edu; tarunesh@umich.edu; austin@umich.edu; valeria@umich.edu
CR [Anonymous], 2006, LANDSCAPE PARALLEL C
   BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Cong J, 2018, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2018.00023
   Farooqui N., 2014, P TRIOS
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hill MD, 2019, INT S HIGH PERF COMP, P317, DOI 10.1109/HPCA.2019.00047
   Jiang J., FPGA
   Ould-Ahmed-Vall E., 2007, P ISPASS
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Prabhakar R., 2016, P ASPLOS
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Shao Y., 2013, P ISPASS
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Wang S., 2019, P HPCA
   Wang Zheng, 2014, ACM T ARCHIT CODE OP
   Weinberg J, 2005, P SC
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yasin A, 2014, INT SYM PERFORM ANAL, P35, DOI 10.1109/ISPASS.2014.6844459
NR 20
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 292
EP 299
DI 10.1109/ISQED51717.2021.9424271
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Quan, CH
   Fouda, ME
   Lee, SG
   Jung, GJ
   Lee, JE
   Eltawil, AE
   Kurdahi, F
AF Quan, Chenghao
   Fouda, Mohammed E.
   Lee, Sugil
   Jung, Giju
   Lee, Jongeun
   Eltawil, Ahmed E.
   Kurdahi, Fadi
TI Training-Free Stuck-At Fault Mitigation for ReRAM-Based Deep Learning
   Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Accelerator; artificial neural network; batch normalization (BN); ReRAM
   crossbar array; stuck-at fault (SAF)
ID IR-DROP; EFFICIENT
AB Although Resistive RAMs can support highly efficient matrix-vector multiplication, which is very useful for machine learning and other applications, the nonideal behavior of hardware, such as stuck-at fault (SAF) and IR drop is an important concern in making ReRAM crossbar array-based deep learning accelerators. Previous work has addressed the nonideality problem through either redundancy in hardware, which requires a permanent increase of hardware cost, or software retraining, which may be even more costly or unacceptable due to its need for a training dataset as well as high computation overhead. In this article, we propose a very lightweight method that can be applied on top of existing hardware or software solutions. Our method, called forward-parameter tuning (FPT), takes advantage of a certain statistical property existing in the activation data of neural network layers, and can mitigate the impact of mild nonidealities in ReRAM crossbar arrays (RCAs) for deep learning applications without using any hardware, a dataset, or gradient-based training. Our experimental results using MNIST, CIFAR-10, and CIFAR-100, and ImageNet datasets in binary and multibit networks demonstrate that our technique is very effective, both alone and together with previous methods, up to 20% fault rate, which is higher than even some of the previous remapping methods. We also evaluate our method in the presence of other nonidealities, such as variability and IR drop. Furthermore, we provide an analysis based on the concept of the effective fault rate (EFR), which not only demonstrates that EFR can be a useful tool to predict the accuracy of faulty RCA-based neural networks but also explains why mitigating the SAF problem is more difficult with multibit neural networks.
C1 [Quan, Chenghao; Lee, Sugil; Jung, Giju; Lee, Jongeun] Ulsan Natl Inst Sci & Technol, Dept Elect Engn, Ulsan 44919, South Korea.
   [Fouda, Mohammed E.; Kurdahi, Fadi] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
   [Eltawil, Ahmed E.] King Abdullah Univ Sci & Technol, CEMSE Div, Thuwal 23955, Saudi Arabia.
RP Lee, JE (corresponding author), Ulsan Natl Inst Sci & Technol, Dept Elect Engn, Ulsan 44919, South Korea.
EM jlee@unist.ac.kr
CR Azamat A., 2021, P INT C COMP AID DES, P1
   Chang CC, 2018, IEEE J EM SEL TOP C, V8, P116, DOI 10.1109/JETCAS.2017.2771529
   Charan G, 2020, IEEE J EXPLOR SOLID-, V6, P27, DOI 10.1109/JXCDC.2020.2987605
   Chen CY, 2015, IEEE T COMPUT, V64, P180, DOI 10.1109/TC.2014.12
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Courbariaux M, 2016, Arxiv, DOI [arXiv:1602.02830, DOI 10.48550/ARXIV.1602.02830]
   Fan Zhang, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P187, DOI 10.1109/ASP-DAC47756.2020.9045730
   Fouda ME, 2020, IEEE ACCESS, V8, P228392, DOI 10.1109/ACCESS.2020.3044652
   Fouda ME, 2019, IEEE T NANOTECHNOL, V18, P704, DOI 10.1109/TNANO.2019.2927493
   Fouda ME, 2018, IEEE T CIRCUITS-I, V65, P270, DOI 10.1109/TCSI.2017.2714101
   He ZZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317870
   Hu JY, 2018, 2018 IEEE INTERNATIONAL TEST CONFERENCE IN ASIA (ITC-ASIA 2018), P19, DOI 10.1109/ITC-Asia.2018.00014
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Huang CL, 2021, IEEE J ELECTRON DEVI, V9, P645, DOI 10.1109/JEDS.2021.3093478
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jung G, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1733
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Kim J., 2019, PROC IEEEACM INT S L, P1
   Lee S., 2022, IEEE T COMPUT A 0523, DOI [10.1109/TCAD.2022.3177002, DOI 10.1109/TCAD.2022.3177002]
   Lee S, 2021, PR IEEE COMP DESIGN, P269, DOI 10.1109/ICCD53106.2021.00051
   Lee S, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218735
   Liu CC, 2017, DES AUT CON, DOI 10.1145/3061639.3062310
   Liu MY, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3386360
   Liu MY, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P216, DOI 10.1145/3287624.3288743
   Liu ZC, 2020, Arxiv, DOI arXiv:2003.03488
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/DATE.2019.8715178, 10.23919/date.2019.8715178]
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Segi Lee, 2020, GLSVLSI '20. Proceedings of the 2020 Great Lakes Symposium on VLSI, P427, DOI 10.1145/3386263.3406954
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smagulova K, 2021, Arxiv, DOI arXiv:2109.03934
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sun SY, 2019, IEEE ACCESS, V7, P141792, DOI 10.1109/ACCESS.2019.2944417
   Sun YA, 2021, IEEE T COMPUT AID D, V40, P2495, DOI 10.1109/TCAD.2021.3051856
   Xia LX, 2019, IEEE T COMPUT AID D, V38, P1611, DOI 10.1109/TCAD.2018.2855145
   Xia LX, 2018, IEEE J EM SEL TOP C, V8, P102, DOI 10.1109/JETCAS.2017.2776980
   Yonekawa H, 2017, IEEE SYM PARA DISTR, P98, DOI 10.1109/IPDPSW.2017.95
   Zhang BG, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P438, DOI 10.1145/3287624.3287707
NR 38
TC 0
Z9 0
U1 2
U2 2
PD JUL
PY 2023
VL 42
IS 7
BP 2174
EP 2186
DI 10.1109/TCAD.2022.3222288
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kubley, T
   Naab, F
   Toader, O
   Was, G
AF Kubley, T.
   Naab, F.
   Toader, O.
   Was, G.
TI Creation of a remotely monitored and controlled ion beam laboratory
   using novel hardware and software tools
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION B-BEAM
   INTERACTIONS WITH MATERIALS AND ATOMS
DT Editorial Material
DE Remote Control; Accelerator; Compact Rio; Raspberry Pi
AB The Michigan Ion Beam Laboratory (MIBL) at the University of Michigan houses three electrostatic accelerators and six ion sources, providing beams to five target chambers and a TEM via nine distinct beamlines. Such a large system incorporates numerous control and monitoring instruments that can more easily be managed through a digital remote interface system. MIBL has implemented a variety of standard laboratory hardware and custom alternative hardware and software tools into a remote interface system that provides for greater laboratory efficiency, increased application flexibility and information flow and reduced cost. The outcome is that users can operate three accelerators and their corresponding beamline system from one console using a master control program, eliminating the need to constantly traverse the facility to monitor and manipulate instruments. Furthermore, the digitalization and centralization of the data generated by each subsystem has allowed for logging and variable correlation that would otherwise be impossible at such a large scale, and enabled the future application of modern tools such as machine learning to enhance operational efficiency.
C1 [Kubley, T.; Naab, F.; Toader, O.; Was, G.] Univ Michigan, Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA.
RP Kubley, T (corresponding author), Univ Michigan, Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA.
EM kubley@umich.edu
CR DAMCOTT DL, 1995, NUCL INSTRUM METH B, V99, P780, DOI 10.1016/0168-583X(94)00618-0
   Google Inc. Angular, 2018, ANG
   National Instruments Corp, 2018, LABVIEW MAKERHUB
   National Instruments Corperation, 2017, US LABVIEW SHAR VAR
   National Instruments Corporation, 2014, NI COMPACTRLO DEV GU
   Raiman SS, 2014, J NUCL MATER, V451, P40, DOI 10.1016/j.jnucmat.2014.03.022
   Taller S, 2017, NUCL INSTRUM METH B, V412, P1, DOI 10.1016/j.nimb.2017.08.035
   Toader O, 2017, PHYSCS PROC, V90, P385, DOI 10.1016/j.phpro.2017.09.039
   Was GS, 2017, NUCL INSTRUM METH B, V412, P58, DOI 10.1016/j.nimb.2017.08.039
   Was GS, 2014, SCRIPTA MATER, V88, P33, DOI 10.1016/j.scriptamat.2014.06.003
   WAS GS, 1989, NUCL INSTRUM METH B, V40-1, P722, DOI 10.1016/0168-583X(89)90463-1
NR 11
TC 0
Z9 0
U1 0
U2 1
PD JAN 1
PY 2019
VL 438
BP 31
EP 37
DI 10.1016/j.nimb.2018.10.033
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Atomic, Molecular & Chemical; Physics, Nuclear
DA 2023-11-11
ER

PT J
AU Inci, A
   Virupaksha, S
   Jain, A
   Chin, TW
   Thallam, V
   Ding, RZ
   Marculescu, D
AF Inci, Ahmet
   Virupaksha, Siri
   Jain, Aman
   Chin, Ting-Wu
   Thallam, Venkata
   Ding, Ruizhou
   Marculescu, Diana
TI QUIDAM: A Framework for Quantization-aware DNN Accelerator and Model
   Co-Exploration
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Deep neural networks; hardware accelerators; model compression;
   quantization; design space exploration
AB As the machine learning and systems communities strive to achieve higher energy efficiency through custom deep neural network (DNN) accelerators, varied precision or quantization levels, and model compression techniques, there is a need for design space exploration frameworks that incorporate quantization-aware processing elements into the accelerator design space while having accurate and fast power, performance, and area models. In this work, we present QUIDAM, a highly parameterized quantization-aware DNN accelerator and model co-exploration framework. Our framework can facilitate future research on design space exploration of DNN accelerators for various design choices such as bit precision, processing element type, scratchpad sizes of processing elements, global buffer size, number of total processing elements, and DNN configurations. Our results show that different bit precisions and processing element types lead to significant differences in terms of performance per area and energy. Specifically, our framework identifies a wide range of design points where performance per area and energy varies more than 5x and 35x, respectively. With the proposed framework, we show that lightweight processing elements achieve on par accuracy results and up to 5.7x more performance per area and energy improvement when compared to the best 16-bit integer quantization-based implementation. Finally, due to the efficiency of the pre-characterized power, performance, and area models, QUIDAM can speed up the design exploration process by three to four orders of magnitude as it removes the need for expensive synthesis and characterization of each design.
C1 [Inci, Ahmet; Virupaksha, Siri; Jain, Aman; Chin, Ting-Wu; Thallam, Venkata; Ding, Ruizhou; Marculescu, Diana] Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
   [Marculescu, Diana] Univ Texas Austin, 110 Inner Campus Dr, Austin, TX 78705 USA.
RP Inci, A (corresponding author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM sgarudan@alumni.cmu.edu; amanj@alumni.cmu.edu; tingwuc@alumni.cmu.edu;
   vthallam@alumni.cmu.edu; rding@alumni.cmu.edu; dianam@utexas.edu
CR Aly MMS, 2015, COMPUTER, V48, P24, DOI 10.1109/MC.2015.376
   Cai Ermao, 2017, ASIAN C MACHINE LEAR, P622
   Chattopadhyay S, 2020, Arxiv, DOI arXiv:2006.13601
   Chen YH, 2017, IEEE MICRO, V37, P12, DOI 10.1109/MM.2017.54
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chin TW, 2020, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR42600.2020.00159
   Devlin J., 2018, PREPRINT
   Ding RZ, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3270689
   Ding RZ, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P35, DOI 10.1145/3060403.3060465
   Esser S. K., 2020, INT C LEARN REPR
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gupta S., 2020, ACCELERATOR AWARE NE
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   HasanGenc Seah Kim, 2021, 58 ANN DESIGN AUTOMA
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   Inci A., 2020, ARXIV
   Inci A, 2022, IEEE T COMPUT AID D, V41, P3426, DOI 10.1109/TCAD.2021.3127148
   Inci Ahmet, 2022, ARXIV
   Inci Ahmet, 2021, 12 NONVOLATILE MEMOR
   Inci Ahmet, 2018, ARCHITECTURES SYSTEM
   Inci Ahmet, 2022, ARXIV
   Inci AF, 2020, DES AUT TEST EUROPE, P1295, DOI 10.23919/DATE48585.2020.9116263
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jang JW, 2021, CONF PROC INT SYMP C, P15, DOI 10.1109/ISCA52012.2021.00011
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Li L, 2020, PR MACH LEARN RES, V115, P367
   Li Y., 2020, INT C LEARNING REPRE
   Marculescu D, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243479
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Mosteller F., 1977, DATA ANAL REGRESSION
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qi Hang, 2017, PALEO PERFORMANCE MO
   Samajdar Ananda, 2018, ARXIV
   Sarangi S., 2021, PROC IEEE INT S CIRC, P1
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Stine J. E., 2007, 2007 IEEE INT C MICR
   Tambe T, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218516
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Yang L., 2020, P 57 ACM IEEE DES AU, P1
   Zhou S, 2016, ARXIV
   Zhou YQ, 2021, Arxiv, DOI arXiv:2102.08619
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zisserman, 2014, CORR
NR 53
TC 0
Z9 0
U1 1
U2 1
PD MAR
PY 2023
VL 22
IS 2
AR 33
DI 10.1145/3555807
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Koeplinger, D
   Feldman, M
   Prabhakar, R
   Zhang, YQ
   Hadjis, S
   Fiszel, R
   Zhao, T
   Nardi, L
   Pedram, A
   Kozyrakis, C
   Olukotun, K
AF Koeplinger, David
   Feldman, Matthew
   Prabhakar, Raghu
   Zhang, Yaqi
   Hadjis, Stefan
   Fiszel, Ruben
   Zhao, Tian
   Nardi, Luigi
   Pedram, Ardavan
   Kozyrakis, Christos
   Olukotun, Kunle
TI Spatial: A Language and Compiler for Application Accelerators
SO ACM SIGPLAN NOTICES
DT Proceedings Paper
CT 39th ACM SIGPLAN Conference on Programming Language Design and
   Implementation (PLDI)
CY JUN 18-22, 2018
CL Philadelphia, PA
DE domain-specific languages; compilers; hardware accelerators; high-level
   synthesis; reconfigurable architectures; FPGAs; CGRAs
AB Industry is increasingly turning to reconfigurable architectures like FPGAs and CGRAs for improved performance and energy efficiency. Unfortunately, adoption of these architectures has been limited by their programming models. HDLs lack abstractions for productivity and are difficult to target from higher level languages. HLS tools are more productive, but offer an ad-hoc mix of software and hardware abstractions which make performance optimizations difficult.
   In this work, we describe a new domain-specific language and compiler called Spatial for higher level descriptions of application accelerators. We describe Spatial's hardware-centric abstractions for both programmer productivity and design performance, and summarize the compiler passes required to support these abstractions, including pipeline scheduling, automatic memory banking, and automated design tuning driven by active machine learning. We demonstrate the language's ability to target FPGAs and CGRAs from common source code. We show that applications written in Spatial are, on average, 42% shorter and achieve a mean speedup of 2.9x over SDAccel HLS when targeting a Xilinx UltraScale+ VU9P FPGA on an Amazon EC2 F1 instance.
C1 [Koeplinger, David; Feldman, Matthew; Prabhakar, Raghu; Zhang, Yaqi; Hadjis, Stefan; Zhao, Tian; Nardi, Luigi; Pedram, Ardavan; Kozyrakis, Christos; Olukotun, Kunle] Stanford Univ, Stanford, CA 94305 USA.
   [Fiszel, Ruben] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
RP Koeplinger, D (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM dkoeplin@stanford.edu; mattfel@stanford.edu; raghup17@stanford.edu;
   yaqiz@stanford.edu; shadjis@stanford.edu; rfiszel@stanford.edu;
   tianzhao@stanford.edu; lnardi@stanford.edu; perdavan@stanford.edu;
   kozyraki@stanford.edu; kunle@stanford.edu
CR [Anonymous], 2015, ICRA
   [Anonymous], 2017, INTEL FPGA SDK OPENC
   [Anonymous], 2006, SC
   [Anonymous], 2015, VIVADO DESIGN SUITE
   [Anonymous], 2016, VIVADO HIGH LEVEL SY
   [Anonymous], 2017, WAVE COMPUTING LAUNC
   [Anonymous], 2013, ACM QUEUE, DOI DOI 10.1145/2436696.2443836
   [Anonymous], INT S COMP ARCH ISCA
   [Anonymous], 2014, PROC ACM SIGDA INT S
   [Anonymous], 2017, NEON 2 0 OPTIMIZED I
   [Anonymous], 2017, EC2 F1 INSTANCES FPG
   Arvind, 2003, Proceedings First ACM and IEEE International Conference on Formal Methods and Models for Co-Design. MEMOCODE'03, P249
   Bachrach J, 2012, DES AUT CON, P1212
   Bodin B., 2016, PACT
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Cascaval C, 2010, IBM J RES DEV, V54, DOI 10.1147/JRD.2010.2059721
   Chugh N, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P327, DOI 10.1145/2967938.2967969
   De Sutter Bjorn, 2013, COARSE GRAINED RECON, P553, DOI DOI 10.1007/978-1-4614-6859-2_18
   Govindaraju V, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.51
   Gupta P., 2015, XEON FPGA PLATFORM D
   Hegarty J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925892
   Hegarty J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601174
   Intel, 2015, ADV NAND FLASH MEM S
   Jian Ouyang, 2014, HOT CHIPS
   Liu YQ, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P286, DOI 10.1145/3020078.3021762
   Maxeler Technologies, 2011, MAXCOMPILER WHIT PAP
   Membarth R, 2016, IEEE T PARALL DISTR, V27, P210, DOI 10.1109/TPDS.2015.2394802
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Nardi Luigi, 2017, IWAPT IPDPS
   Parashar A., 2013, P 40 ANN INT S COMP, P142
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Pu Jing, 2016, CORR
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Saeedi S., 2017, ICRA
   Shacham Ofer, 2011, CHIP MULTIPROCESSOR
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sujeeth Arvind K., 2014, TECS 14 ACM T EMBEDD
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Xilinx, 2017, SDACCEL EX REP
   Xilinx, 2017, SDACCEL DATAFLOW PRA
   Xilinx, 2014, XILINX SDACCEL DEV E
   Xilinx, 2017, HLS PRAGM
NR 44
TC 78
Z9 81
U1 1
U2 3
PD APR
PY 2018
VL 53
IS 4
BP 296
EP 311
DI 10.1145/3192366.3192379
WC Computer Science, Software Engineering
DA 2023-11-11
ER

PT J
AU Zheng, SX
   Zhang, XJ
   Ou, DL
   Tang, SB
   Liu, LB
   Wei, SJ
   Yin, SY
AF Zheng, Shixuan
   Zhang, Xianjue
   Ou, Daoli
   Tang, Shibin
   Liu, Leibo
   Wei, Shaojun
   Yin, Shouyi
TI Efficient Scheduling of Irregular Network Structures on CNN Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Accelerator architectures; neural network hardware; scheduling
   algorithms
AB The state-of-the-art convolutional neural network (CNN) structures present growing irregularity in the sense of layer connections, which derives from the innovative manual designs and the recently proposed neural architecture searching approaches. Such irregular structures improve recognition accuracy, but also bring challenges for hardware deployment, especially on CNN accelerators with regular architectures: 1) the complicated data dependency makes it nontrivial to decide the data reuse strategy between layers and 2) since the execution order of each network is not unique, the choice of layer scheduling, memory allocating, and loop tiling strategies greatly impact the hardware performance. These challenges cannot be solved by the existing CNN schedulers, which mainly focuses on the dataflow of a single layer. In this work, we propose a comprehensive framework to analyze and solve the mapping of an arbitrarily connected CNN network to specific hardware accelerators. We propose: 1) a dynamic programming and nodeclustering-based DAG partitioning approach to efficiently exploit interlayer data reuse and 2) a subgraph scheduling and onchip memory allocating strategy to find the optimal execution order. With the modeling of CNN accelerators, we also propose a loop tiling approach for fused layers. An automated framework is established to generate binary machine codes from original CNN models produced by mainstream deep learning frameworks, which can process large-scale CNNs with more than 1000 layers in only a few minutes. Experiments based on stateof-the-art accelerators (e.g., NVDLA) show that our techniques greatly reduce the external data transfer of interlayer dependencies and bring significant performance improvement over existing approaches.
C1 [Zheng, Shixuan; Zhang, Xianjue; Ou, Daoli; Tang, Shibin; Liu, Leibo; Wei, Shaojun; Yin, Shouyi] Tsinghua Univ, Inst Microelect, Beijing Innovat Ctr Future Chip, Beijing 100084, Peoples R China.
   [Zheng, Shixuan; Zhang, Xianjue; Ou, Daoli; Tang, Shibin; Liu, Leibo; Wei, Shaojun; Yin, Shouyi] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
RP Yin, SY (corresponding author), Tsinghua Univ, Inst Microelect, Beijing Innovat Ctr Future Chip, Beijing 100084, Peoples R China.
EM yinsy@tsinghua.edu.cn
CR Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2017, NVDLA DEEP LEARNING
   [Anonymous], 2018, OPEN NEURAL NETWORK
   Bannon P., 2019, P HOTCHIPS AUG
   Cai H., 2020, ONCE ALL TRAIN ONE N
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jangda A, 2018, ACM SIGPLAN NOTICES, V53, P261, DOI 10.1145/3200691.3178507
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Lee J, 2019, SYMP VLSI CIRCUITS, pC302, DOI [10.23919/VLSIC.2019.8778104, 10.23919/vlsic.2019.8778104]
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Patra S, 2019, IEEE WINT CONF APPL, P31, DOI 10.1109/WACV.2019.00011
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Zisserman A., 2014, 14091556 ARXIV
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zoph Barret, 2017, INT C LEARNING REPRE
NR 29
TC 12
Z9 12
U1 1
U2 23
PD NOV
PY 2020
VL 39
IS 11
BP 3408
EP 3419
DI 10.1109/TCAD.2020.3012215
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Hanson, E
   Li, SY
   Qian, XH
   Li, H
   Chen, YR
AF Hanson, Edward
   Li, Shiyu
   Qian, Xuehai
   Li, Hai (Helen)
   Chen, Yiran
TI DyNNamic: Dynamically Reshaping, High Data-Reuse Accelerator for Compact
   DNNs
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Dataflow architectures; adaptable architectures; machine learning
AB Convolutional layers dominate the computation and energy costs of Deep Neural Network (DNN) inference. Recent algorithmic works attempt to reduce these bottlenecks via compact DNN structures and model compression. Likewise, state-of-the-art accelerator designs leverage spatiotemporal characteristics of convolutional layers to reduce data movement overhead and improve throughput. Although both are independently effective at reducing latency and energy costs, combining these approaches does not guarantee cumulative improvements due to inefficient mapping. This inefficiency can be attributed to (1) inflexibility of underlying hardware and (2) inherent reduction of data-reuse opportunities of compact DNN structures. To address these issues, we propose a dynamically reshaping, high data-reuse PE array accelerator, namely DyNNamic. DyNNamic leverages kernel-wise filter decomposition to partition the convolution operation into two compact stages: Shared Kernels Convolution (SKC) and Weighted Accumulation (WA). Because both stages have vastly different dimensions, DyNNamic reshapes its PE array to effectively map the algorithm to the architecture. The architecture then exploits data-reuse opportunities created by the SKC stage, further reducing data movement with negligible overhead. We evaluate our approach on various representative networks and compare against state-of-the-art accelerators. On average, DyNNamic outperforms DianNao by 8.4x and 12.3x in terms of inference energy and latency, respectively.
C1 [Hanson, Edward; Li, Shiyu; Li, Hai (Helen); Chen, Yiran] Duke Univ, Elect & Comp Engn, Durham, NC 27708 USA.
   [Qian, Xuehai] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90007 USA.
RP Hanson, E (corresponding author), Duke Univ, Elect & Comp Engn, Durham, NC 27708 USA.
EM edward.t.hanson@duke.edu; shiyu.li@duke.edu; xuehai.qian@usc.edu;
   hai.li@duke.edu; yiran.chen@duke.edu
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], 2013, CACTIAN INTEGRATED C
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Guo CL, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102840
   Han S., 2015, ARXIV151000149
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   isakedo, 2020, IS DNNISM
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Li H., 2016, 5 INT C LEARNING REP, P1
   Li S., 2020, INT C MACHINE LEARNI, P5863
   Liu BS, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P733, DOI 10.1145/3287624.3287638
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paszke A, 2019, ADV NEUR IN, V32
   Putic M, 2018, DES AUT CON, DOI 10.1145/3195970.3196033
   Samajdar Ananda, 2018, ARXIV
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Wen W., 2016, ADV NEURAL INFORM PR, P2082, DOI DOI 10.1016/J.CCR.2008.06.009
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Zhang SJ, 2016, INT SYMP MICROARCH
NR 30
TC 0
Z9 0
U1 1
U2 1
PD MAR 1
PY 2023
VL 72
IS 3
BP 880
EP 892
DI 10.1109/TC.2022.3184272
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Chandramoorthy, N
   Swaminathan, K
   Cochet, M
   Paidimarri, A
   Eldridge, S
   Joshi, RV
   Ziegler, MM
   Buyuktosunoglu, A
   Bose, P
AF Chandramoorthy, Nandhini
   Swaminathan, Karthik
   Cochet, Martin
   Paidimarri, Arun
   Eldridge, Schuyler
   Joshi, Rajiv V.
   Ziegler, Matthew M.
   Buyuktosunoglu, Alper
   Bose, Pradip
GP IEEE
TI Resilient Low Voltage Accelerators for High Energy Efficiency
SO 2019 25TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 25th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 16-20, 2019
CL Washington, DC
AB Low voltage architecture and design are key enablers of high throughput per watt in heterogeneous, accelerator-rich many-core designs. However, such low voltage operation poses significant challenges because of difficulties in achieving reliable functionality of on-chip memories, particularly SRAMs at these design points. In this paper, we present a technique of low-voltage neural network acceleration, where the embedded SRAM architecture is equipped with a novel application-aware supply voltage boosting capability. This technique mitigates low-voltage induced failures, while enabling Very low voltage (VLV)(1) operation during most of the application run, resulting in substantial improvement in net energy efficiency. We present a framework to evaluate the impact of low-voltage SRAM errors on machine learning applications and characterize trade-offs between output inference accuracy and energy efficiency in our application-programmable supply boosted SRAM architecture. Using the proposed technique we push the limits on the minimum operable voltage (V-min) for the desired output quality. As a proof of concept, we demonstrate these techniques on Dante, a Deep Neural Network (DNN) accelerator chip taped out in state-of-the art 14nm technology.
C1 [Chandramoorthy, Nandhini; Swaminathan, Karthik; Cochet, Martin; Paidimarri, Arun; Eldridge, Schuyler; Joshi, Rajiv V.; Ziegler, Matthew M.; Buyuktosunoglu, Alper; Bose, Pradip] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Chandramoorthy, N (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
CR Abouzeid F, 2014, IEEE J SOLID-ST CIRC, V49, P1499, DOI 10.1109/JSSC.2014.2316219
   [Anonymous], 2016, ICLR
   Bankman  D., 2018, INT SOL STAT CIRC C
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Bol  D., 2013, IEEE J SOLID-ST CIRC, V48
   Chang IJ, 2009, IEEE J SOLID-ST CIRC, V44, P650, DOI 10.1109/JSSC.2008.2011972
   Chang L, 2008, IEEE J SOLID-ST CIRC, V43, P956, DOI 10.1109/JSSC.2007.917509
   Chang L, 2010, SYMP VLSI CIRCUITS, P55, DOI 10.1109/VLSIC.2010.5560267
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Deng J., 2015, DATE
   Eldridge S, 2015, INT CONFER PARA, P99, DOI 10.1109/PACT.2015.21
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Henkels W. H., 1997, S VLSI CIRC JUN
   Iijima Masaaki, 2008, Journal of Computers, V3, P34, DOI 10.4304/jcp.3.5.34-40
   Itoh  K., 1996, S VLSI CIRC
   Joshi RV, 2015, SYMP VLSI CIRCUITS
   Joshi R. V., 2017, J SOLID STATE CIRCUI, V52
   Joshi RV, 2017, IEEE CUST INTEGR CIR
   Karnik T, 2018, ISSCC DIG TECH PAP I, P46, DOI 10.1109/ISSCC.2018.8310176
   Kim  S., 2017, P C DES AUT TEST EUR
   Kim TH, 2008, IEEE J SOLID-ST CIRC, V43, P518, DOI 10.1109/JSSC.2007.914328
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurd  N., 2014, 2014 IEEE INT SOL ST
   LeCun Y., MNIST DATABASE HANDW
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Qazi  M., 2011, IEEE DES TEST COMPUT, V28
   Reagen, 2018, ACM DES AUT C DAC, P1
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Salem L. G., 2018, IEEE INT SOL STAT CI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shamanna  G., 2012, 2012 IEEE INT C IC D
   Whatmough P. N., 2017, IEEE INT SOL STAT CI
   Yang L., 2017, ISQED
   Zhai Bo, 2008, IEEE J SOLID STATE C, V43
   Zimmer B., 2016, IEEE J SOLID STATE C
   Zimmer B, 2012, IEEE T CIRCUITS-II, V59, P853, DOI 10.1109/TCSII.2012.2231015
NR 39
TC 27
Z9 27
U1 0
U2 1
PY 2019
BP 147
EP 158
DI 10.1109/HPCA.2019.00034
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Agostini, NB
   Curzel, S
   Zhang, J
   Limaye, A
   Tan, C
   Amatya, V
   Minutoli, M
   Castellana, VG
   Manzano, J
   Brooks, D
   Wei, GY
   Tumeo, A
AF Agostini, Nicolas Bohm
   Curzel, Serena
   Zhang, Jeff (Jun)
   Limaye, Ankur
   Tan, Cheng
   Amatya, Vinay
   Minutoli, Marco
   Castellana, Vito Giovanni
   Manzano, Joseph
   Brooks, David
   Wei, Gu-Yeon
   Tumeo, Antonino
TI Bridging Python to Silicon: The SODA Toolchain
SO IEEE MICRO
DT Article
DE Hardware; Optimization; Synthesizers; Codes; Hardware design languages;
   Kernel; Field programmable gate arrays; Compiler Techniques; MLIR;
   High-Level Synthesis; Hardware generation; Silicon Compiler
AB Systems performing scientific computing, data analysis, and machine learning tasks have a growing demand for application-specific accelerators that can provide high computational performance while meeting strict size and power requirements. However, the algorithms and applications that need to be accelerated are evolving at a rate that is incompatible with manual design processes based on hardware description languages. Agile hardware design tools based on compiler techniques can help by quickly producing an application-specific integrated circuit (ASIC) accelerator starting from a high-level algorithmic description. We present the software-defined accelerator (SODA) synthesizer, a modular and open-source hardware compiler that provides automated end-to-end synthesis from high-level software frameworks to ASIC implementation, relying on multilevel representations to progressively lower and optimize the input code. Our approach does not require the application developer to write any register-transfer level code, and it is able to reach up to 364 giga floating point operations per second (GFLOPS)/W efficiency (32-bit precision) on typical convolutional neural network operators.
C1 [Agostini, Nicolas Bohm; Curzel, Serena; Limaye, Ankur; Castellana, Vito Giovanni; Manzano, Joseph; Tumeo, Antonino] Pacific Northwest Natl Lab, High Performance Comp Grp, Richland, WA 99354 USA.
   [Amatya, Vinay] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
   [Minutoli, Marco] Pacific Northwest Natl Lab, Data Sci & Machine Intelligence Grp, Richland, WA 99354 USA.
   [Zhang, Jeff (Jun)] Harvard Univ, Architecture Circuits & Compilers Grp, Cambridge, MA 02138 USA.
   [Brooks, David] Harvard Univ, Sch Engn & Appl Sci, Comp Sci, Cambridge, MA 02138 USA.
   [Wei, Gu-Yeon] Harvard Univ, John A Paulson Sch Engineer & Appl Sci, Elect Engn & Comp Sci, Cambridge, MA 02138 USA.
   [Tan, Cheng] Microsoft, Redmond, WA USA.
RP Agostini, NB (corresponding author), Pacific Northwest Natl Lab, High Performance Comp Grp, Richland, WA 99354 USA.
EM nicolas.agostini@pnnl.gov; serena.curzel@polimi.it;
   jeffzhang@g.harvard.edu; ankur.limaye@pnnl.gov; chengtan@microsoft.com;
   Vinay.amatya@pnnl.gov; marco.minutoli@pnnl.gov;
   vitogiovanni.castellana@pnnl.gov; joseph.manzano@pnnl.gov;
   dbrooks@g.harvard.edu; guyeon@seas.harvard.edu; antonino.tumeo@pnnl.gov
CR Castellana VG, 2021, INT PARALL DISTRIB P, P192, DOI 10.1109/IPDPS49936.2021.00028
   CIRCT Developers, 2020, CIRCT CIRCUIT IRCOMP
   Esmaeilzadeh H., 2021, P ICCAD, P1
   Ferrandi F, 2021, DES AUT CON, P1327, DOI 10.1109/DAC18074.2021.9586110
   Genc Hasan, 2021, 2021 58th ACM/IEEE Design Automation Conference (DAC), P769, DOI 10.1109/DAC18074.2021.9586216
   github, POLYGEIST SCRIPT
   gitlab, FLOPOCO
   Huang ST, 2021, IEEE T COMPUT, V70, P2015, DOI 10.1109/TC.2021.3123465
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Minutoli M, 2022, IEEE T COMPUT, V71, P520, DOI 10.1109/TC.2021.3057860
   Minutoli M, 2015, ANN IEEE SYM FIELD P, P100, DOI 10.1109/FCCM.2015.60
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Veripool, VERILATOR
   Ye HC, 2022, INT S HIGH PERF COMP, P741, DOI 10.1109/HPCA53966.2022.00060
NR 15
TC 4
Z9 4
U1 1
U2 3
PD SEPT 1
PY 2022
VL 42
IS 5
BP 78
EP 88
DI 10.1109/MM.2022.3178580
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Lombardo, T
   Duquesnoy, M
   El-Bouysidy, H
   Årén, F
   Gallo-Bueno, A
   Jorgensen, PB
   Bhowmik, A
   Demortiere, A
   Ayerbe, E
   Alcaide, F
   Reynaud, M
   Carrasco, J
   Grimaud, A
   Zhang, C
   Vegge, T
   Johansson, P
   Franco, AA
AF Lombardo, Teo
   Duquesnoy, Marc
   El-Bouysidy, Hassna
   Aren, Fabian
   Gallo-Bueno, Alfonso
   Jorgensen, Peter Bjorn
   Bhowmik, Arghya
   Demortiere, Arnaud
   Ayerbe, Elixabete
   Alcaide, Francisco
   Reynaud, Marine
   Carrasco, Javier
   Grimaud, Alexis
   Zhang, Chao
   Vegge, Tejs
   Johansson, Patrik
   Franco, Alejandro A.
TI Artificial Intelligence Applied to Battery Research: Hype or Reality?
SO CHEMICAL REVIEWS
DT Review
ID LITHIUM-ION BATTERY; REMAINING USEFUL LIFE; STATE-OF-HEALTH; ADAPTIVE
   REGRESSION SPLINES; SUPPORT VECTOR MACHINE; GAUSSIAN PROCESS REGRESSION;
   WAVELET NEURAL-NETWORKS; CAPACITY FADE ANALYSIS; X-RAY TOMOGRAPHY;
   HIGH-THROUGHPUT
AB This is a critical review of artificial intelligence/machine learning (AI/ML) methods applied to battery research. It aims at providing a comprehensive, authoritative, and critical, yet easily understandable, review of general interest to the battery community. It addresses the concepts, approaches, tools, outcomes, and challenges of using AI/ML as an accelerator for the design and optimization of the next generation of batteries-a current hot topic. It intends to create both accessibility of these tools to the chemistry and electrochemical energy sciences communities and completeness in terms of the different battery R&D aspects covered.
C1 [Lombardo, Teo; Duquesnoy, Marc; El-Bouysidy, Hassna] Univ Picardie Jules Verne, UMR CNRS 7314, Lab React & Chim Solides LRCS, F-80039 Amiens, France.
   [Lombardo, Teo; Duquesnoy, Marc] FR CNRS 3459, Reseau Stockage Elect Energie RS2E, F-80039 Amiens, France.
   [El-Bouysidy, Hassna; Aren, Fabian; Gallo-Bueno, Alfonso; Jorgensen, Peter Bjorn; Bhowmik, Arghya] ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.
   [El-Bouysidy, Hassna; Aren, Fabian] Chalmers Univ Technol, Dept Phys, SE-41296 Gothenburg, Sweden.
   [Gallo-Bueno, Alfonso; Reynaud, Marine; Carrasco, Javier] Basque Res & Technol Alliance BRTA, Ctr Cooperat Res Alternat Energies CIC enrgiGUNE, Vitoria 01510, Spain.
   [Jorgensen, Peter Bjorn; Bhowmik, Arghya] Tech Univ Denmark, Dept Energy Convers & Storage, DK-2800 Lyngby, Denmark.
   [Demortiere, Arnaud] Univ Picardie Jules Verne, UMR CNRS 7314, Lab React & Chim Solides LRCS, F-80039 Amiens, France.
   [Demortiere, Arnaud] Reseau Stockage Elect Energie RS2E, FR CNRS 3459, F-80039 Amiens, France.
   [Demortiere, Arnaud; Carrasco, Javier] ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.
   [Ayerbe, Elixabete; Alcaide, Francisco; Reynaud, Marine] ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.
   [Ayerbe, Elixabete; Alcaide, Francisco] CIDETEC, Basque Res & Technol Alliance BRTA, San Sebastian 20014, Spain.
   [Grimaud, Alexis] Reseau Stockage Elect Energie RS2E, FR CNRS 3459, F-80039 Amiens, France.
   [Grimaud, Alexis] ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.
   [Grimaud, Alexis] Univ UPMC Univ Paris 06, Coll France, UMR CNRS 8260 Chim Solide & Energie, 11 Pl Marcelin Berthelot, F-75231 Paris, France.
   [Zhang, Chao; Vegge, Tejs; Johansson, Patrik] ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.
   [Zhang, Chao] Dept Chem Angstrom Lab, S-75121 Uppsala, Sweden.
   [Vegge, Tejs] Tech Univ Denmark, Dept Energy Convers & Storage, DK-2800 Lyngby, Denmark.
   [Johansson, Patrik] Chalmers Univ Technol, Dept Phys, S-41296 Gothenburg, Sweden.
   [Franco, Alejandro A.] Univ Picardie Jules Verne, UMR CNRS 7314, Lab React & Chim Solides LRCS, F-80039 Amiens, France.
   [Franco, Alejandro A.] Reseau Stockage Elect Energie RS2E, FR CNRS 3459, F-80039 Amiens, France.
   [Franco, Alejandro A.] ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.
   [Franco, Alejandro A.] Inst Univ France, F-75005 Paris, France.
RP Franco, AA (corresponding author), Univ Picardie Jules Verne, UMR CNRS 7314, Lab React & Chim Solides LRCS, F-80039 Amiens, France.; Franco, AA (corresponding author), Reseau Stockage Elect Energie RS2E, FR CNRS 3459, F-80039 Amiens, France.; Franco, AA (corresponding author), ALISTORE European Res Inst, FR CNRS 3104, F-80039 Amiens, France.; Franco, AA (corresponding author), Inst Univ France, F-75005 Paris, France.
EM alejandro.franco@u-picardie.fr
CR Adhikari T, 2020, ACS COMB SCI, V22, P311, DOI 10.1021/acscombsci.9b00181
   Aguiar JA, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw1949
   Ahmad Z, 2018, ACS CENTRAL SCI, V4, P996, DOI 10.1021/acscentsci.8b00229
   Ahmed R, 2015, SAE INT J ALTERN POW, V4, P233, DOI 10.4271/2015-01-0252
   Alexandridis AK, 2013, NEURAL NETWORKS, V42, P1, DOI 10.1016/j.neunet.2013.01.008
   Allam O, 2018, RSC ADV, V8, P39414, DOI 10.1039/c8ra07112h
   Allu S, 2014, J POWER SOURCES, V246, P876, DOI 10.1016/j.jpowsour.2013.08.040
   Andrews JL, 2018, COMPUT STAT DATA AN, V127, P160, DOI 10.1016/j.csda.2018.05.015
   Ang SJ, 2021, CHEM-US, V7, P738, DOI 10.1016/j.chempr.2020.12.009
   [Anonymous], STRUCTURED VS UNSTRU
   [Anonymous], COMPREHENSIVE R ARCH
   [Anonymous], ICSD WORLDS LARGEST
   [Anonymous], CRYSTALLOGRAPHY OPEN
   [Anonymous], BIG MAP
   [Anonymous], UBUNTU FORUMS
   [Anonymous], WWW ERC ARTISTIC EU
   [Anonymous], STACK OVERFLOW
   [Anonymous], DATASPHERE 2021
   [Anonymous], GLOBAL WARMING 15 C
   [Anonymous], 2018, MISSION INNOVATION
   [Anonymous], DEFACTO PROJECT EU P
   [Anonymous], 2007, PATTERN RECOGN, V16
   [Anonymous], MAT PROJECT
   [Anonymous], FLOW MACHINES
   [Anonymous], IBM WATSON MACHINE L
   [Anonymous], RS2E LABEXSTORE EX I
   Aoun B, 2015, J POWER SOURCES, V279, P246, DOI 10.1016/j.jpowsour.2015.01.033
   Arbizzani C, 2020, J POWER SOURCES, V450, DOI 10.1016/j.jpowsour.2019.227636
   Arganda-Carreras I, 2017, BIOINFORMATICS, V33, P2424, DOI 10.1093/bioinformatics/btx180
   Armstrong G, 2019, NAT CHEM, V11, P1076, DOI 10.1038/s41557-019-0386-7
   Arora P, 1999, J ELECTROCHEM SOC, V146, P3543, DOI 10.1149/1.1392512
   Artrith N, 2021, NAT CHEM, V13, P505, DOI 10.1038/s41557-021-00716-z
   Artrith N, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5017661
   Asakura K, 2018, J SYNCHROTRON RADIAT, V25, P967, DOI 10.1107/S1600577518006963
   Assat G, 2017, CHEM MATER, V29, P9714, DOI 10.1021/acs.chemmater.7b03434
   Attia P., ACCELERATING BATTERY
   Attia PM, 2020, NATURE, V578, P397, DOI 10.1038/s41586-020-1994-5
   azure, AZURE MACHINE LEARNI
   Bach TC, 2016, J ENERGY STORAGE, V5, P212, DOI 10.1016/j.est.2016.01.003
   Badmos O, 2020, J INTELL MANUF, V31, P885, DOI 10.1007/s10845-019-01484-x
   Bahramipanah M, 2017, IEEE T TRANSP ELECTR, V3, P589, DOI 10.1109/TTE.2017.2739344
   Balakrishnama S., 1998, LINEAR DISCRIMINANT
   Baliyan A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54770-2
   Balshi MS, 2009, GLOBAL CHANGE BIOL, V15, P578, DOI 10.1111/j.1365-2486.2008.01679.x
   Bao J, 2020, ADV THEOR SIMUL, V3, DOI 10.1002/adts.201900167
   Barré A, 2013, J POWER SOURCES, V241, P680, DOI 10.1016/j.jpowsour.2013.05.040
   Barrett DH, 2020, CURR OPIN ELECTROCHE, V21, P160, DOI 10.1016/j.coelec.2020.02.002
   Bartók AP, 2013, PHYS REV B, V87, DOI 10.1103/PhysRevB.87.184115
   BASF, GLOB EN WHO WE AR IN
   Beal MS, 2011, ACS COMB SCI, V13, P375, DOI 10.1021/co100075f
   Bedrov D, 2019, CHEM REV, V119, P7940, DOI 10.1021/acs.chemrev.8b00763
   Bengio Y, 2004, J MACH LEARN RES, V5, P1089
   Bengio Y., 2016, DEEP LEARNING, DOI DOI 10.2172/1462436
   Berecibar M, 2019, NATURE, V568, P325, DOI 10.1038/d41586-019-01138-1
   Berecibar M, 2016, ENERGY, V103, P784, DOI 10.1016/j.energy.2016.02.163
   Berecibar M, 2016, J POWER SOURCES, V320, P239, DOI 10.1016/j.jpowsour.2016.04.109
   Berry M., 2020, SUPERVISED UNSUPERVI
   Besley A, 2019, MONTY PYTHONS FLYING
   Bhowmik A, 2020, JOULE, V4, P717, DOI 10.1016/j.joule.2020.03.016
   Bhowmik A, 2019, ENERGY STORAGE MATER, V21, P446, DOI 10.1016/j.ensm.2019.06.011
   Bishop C. M., 2000, ARXIV13013838 ARXIVO
   Bloom I, 2001, J POWER SOURCES, V101, P238, DOI 10.1016/S0378-7753(01)00783-2
   Bonyadi MR, 2017, EVOL COMPUT, V25, P1, DOI 10.1162/EVCO_r_00180
   Boreland M., 2015, IEEE PHOT SPEC CONF
   Boston Consulting Group Report, FUTURE BATTERY PRODU
   Bousiydy Teo Lombardo, WHAT CAN TEXT MINING, DOI [10.1002/batt.202100076, DOI 10.1002/BATT.202100076]
   Brady M., 2012, ROBOTICS ARTIFICIAL
   Brandt RE, 2017, JOULE, V1, P843, DOI 10.1016/j.joule.2017.10.001
   Broussely M, 2001, J POWER SOURCES, V97-8, P13, DOI 10.1016/S0378-7753(01)00722-4
   Brown CR, 2015, ACS COMB SCI, V17, P381, DOI 10.1021/acscombsci.5b00048
   Burns JC, 2013, J ELECTROCHEM SOC, V160, pA1451, DOI 10.1149/2.060309jes
   Burns JC, 2011, J ELECTROCHEM SOC, V158, pA255, DOI 10.1149/1.3531997
   Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2
   Campbell M, 2002, ARTIF INTELL, V134, P57, DOI 10.1016/S0004-3702(01)00129-1
   Chan CC, 2000, J POWER SOURCES, V87, P201, DOI 10.1016/S0378-7753(99)00502-9
   Chang JH, 2019, J PHYS-CONDENS MAT, V31, DOI 10.1088/1361-648X/ab1bbc
   Chang Y, 2017, APPL ENERG, V206, P1564, DOI 10.1016/j.apenergy.2017.09.106
   Chemdataextractor.org, UTOMATICALLY EXTRACT
   Chen CH, 2001, J POWER SOURCES, V96, P321, DOI 10.1016/S0378-7753(00)00666-2
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen C, 2020, ADV ENERGY MATER, V10, DOI 10.1002/aenm.201903242
   Chen C, 2017, SCI REP-UK, V7, DOI 10.1038/srep40769
   Chen T, 2007, CHEMOMETR INTELL LAB, V87, P59, DOI 10.1016/j.chemolab.2006.09.004
   Chen X, 2019, ADV INTELL SYST-GER, V1, DOI 10.1002/aisy.201900102
   Chen YT, 2021, ACS ENERGY LETT, V6, P1639, DOI 10.1021/acsenergylett.1c00332
   Chen ZY, 2007, ARTIF INTELL MED, V41, P161, DOI 10.1016/j.artmed.2007.07.008
   Cheng YJ, 2015, ENERGY, V90, P1983, DOI 10.1016/j.energy.2015.07.022
   Choi Y, 2019, IEEE ACCESS, V7, P75143, DOI 10.1109/ACCESS.2019.2920932
   Christensen J, 2005, J ELECTROCHEM SOC, V152, pA818, DOI 10.1149/1.1870752
   Christensen J, 2004, J ELECTROCHEM SOC, V151, pA1977, DOI 10.1149/1.1804812
   Christophersen J. P., 2006, ADV TECHNOLOGY DEV P
   Cloud.google, AI PLATFORM
   Cohen John., 1966, HUMAN ROBOTS MYTH SC
   Cordoba-Arenas A, 2015, J POWER SOURCES, V278, P473, DOI 10.1016/j.jpowsour.2014.12.047
   Cunha RP, 2020, BATTERIES SUPERCAPS, V3, P60, DOI 10.1002/batt.201900135
   Dai Q, 2019, BATTERIES-BASEL, V5, DOI 10.3390/batteries5020048
   Dan YB, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-00352-0
   Dave A, 2020, CELL REP PHYS SCI, V1, DOI 10.1016/j.xcrp.2020.100264
   Dawson-Elli N, 2018, J ELECTROCHEM SOC, V165, pA1, DOI 10.1149/2.1391714jes
   De Sutter L, 2019, ELECTROCHIM ACTA, V305, P24, DOI 10.1016/j.electacta.2019.02.104
   Deng Z, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0212-1
   Deringer VL, 2020, J PHYS-ENERGY, V2, DOI 10.1088/2515-7655/abb011
   Deringer VL, 2017, PHYS REV B, V95, DOI 10.1103/PhysRevB.95.094203
   Ding GL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49267-x
   Dixit MB, 2020, ACS APPL ENERG MATER, V3, P9534, DOI 10.1021/acsaem.0c02053
   Domingos P., 2015, MASTER ALGORITHM QUE
   Dong GZ, 2015, ENERGY, V90, P879, DOI 10.1016/j.energy.2015.07.120
   Dong HC, 2014, J POWER SOURCES, V271, P114, DOI 10.1016/j.jpowsour.2014.07.176
   Douak F, 2013, APPL ENERG, V103, P328, DOI 10.1016/j.apenergy.2012.09.055
   Downey A, 2019, RELIAB ENG SYST SAFE, V182, P1, DOI 10.1016/j.ress.2018.09.018
   Du ZJ, 2017, J APPL ELECTROCHEM, V47, P405, DOI 10.1007/s10800-017-1047-4
   Duquesnoy Marc, 2020, Journal of Power Sources, V480, DOI 10.1016/j.jpowsour.2020.229103
   Eastwood DS, 2014, ADV ENERGY MATER, V4, DOI 10.1002/aenm.201300506
   EC.europa.eu, INF FUND TEND OPP PO
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Eitzinger C., 2015, ADV COMPUTER VISION
   El-Bousiydy H, 2021, BATTERIES SUPERCAPS, V4, P758, DOI 10.1002/batt.202000288
   Elith J, 2007, DIVERS DISTRIB, V13, P265, DOI 10.1111/j.1472-4642.2007.00340.x
   Ellis LD, 2018, J ELECTROCHEM SOC, V165, pA256, DOI 10.1149/2.0861802jes
   Fehse M, 2019, BATTERIES SUPERCAPS, V2, P66, DOI 10.1002/batt.201800075
   Fehse M, 2019, ENERGY STORAGE MATER, V18, P328, DOI 10.1016/j.ensm.2019.02.002
   Fehse M, 2018, J MATER CHEM A, V6, P8724, DOI 10.1039/c8ta02248h
   Fehse M, 2017, CHEM MATER, V29, P10446, DOI 10.1021/acs.chemmater.7b04088
   Feng F, 2020, J POWER SOURCES, V455, DOI 10.1016/j.jpowsour.2020.227935
   Fernández-Caramés TM, 2019, IEEE ACCESS, V7, P45201, DOI 10.1109/ACCESS.2019.2908780
   Finegan D. P., 2021, JOULE, V5, P2021, DOI DOI 10.1016/j.joule.2020.11.018
   Fisher D. H., 1991, CONCEPT FORMATION KN, V1st
   Fleischauer MD, 2005, ELECTROCHEM SOLID ST, V8, pA137, DOI 10.1149/1.1850395
   Flores-Leonar MM, 2020, CURR OPIN GREEN SUST, V25, DOI 10.1016/j.cogsc.2020.100370
   Forbes, SITES PETERHIGH 2017
   Fourches D, 2016, J CHEM INF MODEL, V56, P1243, DOI 10.1021/acs.jcim.6b00129
   Fourches D, 2010, J CHEM INF MODEL, V50, P1189, DOI 10.1021/ci100176x
   Franco AA, 2021, NAT MACH INTELL, V3, P277, DOI 10.1038/s42256-021-00334-x
   Franco AA, 2019, CHEM REV, V119, P4569, DOI 10.1021/acs.chemrev.8b00239
   Friedman J H, 1995, Stat Methods Med Res, V4, P197, DOI 10.1177/096228029500400303
   FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963
   Fujimoto K, 2006, SOLID STATE IONICS, V177, P2639, DOI 10.1016/j.ssi.2006.04.043
   Fujimura K, 2013, ADV ENERGY MATER, V3, P980, DOI 10.1002/aenm.201300060
   Furat O, 2021, J POWER SOURCES, V483, DOI 10.1016/j.jpowsour.2020.229148
   Gal Y., 2015, BAYESIAN CONVOLUTION
   Gallagher KG, 2016, J ELECTROCHEM SOC, V163, pA138, DOI 10.1149/2.0321602jes
   Gao D, 2017, J POWER ELECTRON, V17, P1288, DOI 10.6113/JPE.2017.17.5.1288
   Gao TH, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2020.101936
   Gao XL, 2021, ENERGY STORAGE MATER, V36, P435, DOI 10.1016/j.ensm.2021.01.007
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   García V, 2019, J INTELL MANUF, V30, P2535, DOI 10.1007/s10845-018-1418-7
   Garg A, 2020, J CLEAN PROD, V275, DOI 10.1016/j.jclepro.2020.124152
   Gayon-Lombardo A, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-0340-7
   Ghadbeigi L, 2015, IEEE CONF TECH SUST, P239, DOI 10.1109/SusTech.2015.7314353
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Grover A., 2018, ARXIV180401712
   Gu GH, 2019, J MATER CHEM A, V7, P17096, DOI 10.1039/c9ta02356a
   Gu R, 2016, IEEE T TRANSP ELECTR, V2, P417, DOI 10.1109/TTE.2016.2571778
   Guda AA, 2019, CATAL TODAY, V336, P3, DOI 10.1016/j.cattod.2018.10.071
   Guha A, 2018, IEEE T TRANSP ELECTR, V4, P135, DOI 10.1109/TTE.2017.2776558
   Gunther Till, 2016, Advanced Materials Research, V1140, P304, DOI 10.4028/www.scientific.net/AMR.1140.304
   Guo M, 2013, J POWER SOURCES, V240, P80, DOI 10.1016/j.jpowsour.2013.03.170
   Guo PY, 2019, J POWER SOURCES, V412, P442, DOI 10.1016/j.jpowsour.2018.11.072
   Han J, 2018, P NATL ACAD SCI USA, V115, P8505, DOI 10.1073/pnas.1718942115
   Harlow JE, 2019, J ELECTROCHEM SOC, V166, pA3031, DOI 10.1149/2.0981913jes
   Harris SJ, 2013, J PHYS CHEM C, V117, P6481, DOI 10.1021/jp311431z
   Häse F, 2019, TRENDS CHEM, V1, P282, DOI 10.1016/j.trechm.2019.02.007
   HASTIE T, 2003, ELEMENTS STAT LEARNI
   Hastie T., 2017, ELEMENTS STAT LEARNI, DOI DOI 10.1007/B94608
   Heid E, 2019, J CHEM THEORY COMPUT, V15, P2460, DOI 10.1021/acs.jctc.8b01289
   Himanen L, 2019, ADV SCI, V6, DOI 10.1002/advs.201900808
   Hiremath M, 2015, ENVIRON SCI TECHNOL, V49, P4825, DOI 10.1021/es504572q
   Hoffman MW, 2014, JMLR WORKSH CONF PRO, V33, P365
   Hsu SC, 2007, INT J PROD ECON, V107, P88, DOI 10.1016/j.ijpe.2006.05.015
   Hu XS, 2019, RENEW SUST ENERG REV, V114, DOI 10.1016/j.rser.2019.109334
   Hu XS, 2016, IEEE T IND ELECTRON, V63, P2645, DOI 10.1109/TIE.2015.2461523
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang M., AIAA SCITECH 2019 FO, P1
   Huang S, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00602-2
   Hutzenlaub T, 2014, ELECTROCHIM ACTA, V115, P131, DOI 10.1016/j.electacta.2013.10.103
   IEA, DAT STAT CHARTS GLOB
   IEA, REP GLOB EV OUTL 202
   Investopedia, TERMSRR SQUARED ASP
   Isayev O, 2015, CHEM MATER, V27, P735, DOI 10.1021/cm503507h
   Jain A, 2016, J MATER RES, V31, P977, DOI 10.1557/jmr.2016.80
   Jalem R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-23852-y
   Jalem R, 2018, SCI TECHNOL ADV MAT, V19, P231, DOI 10.1080/14686996.2018.1439253
   Jalem R, 2015, J CHEM INF MODEL, V55, P1158, DOI 10.1021/ci500752n
   Jalem R, 2012, CHEM MATER, V24, P1357, DOI 10.1021/cm3000427
   Jankowski P, 2020, BATTERIES SUPERCAPS, V3, P1350, DOI 10.1002/batt.202000168
   Jennings PC, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0181-4
   Jeudin J.-C, 2008, CREATURES ARTIFICIEL
   Jiang ZS, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16233-5
   Jorgensen P. B., 2020, ARXIV201103346, V2011
   Joshi RP, 2019, ACS APPL MATER INTER, V11, P18494, DOI 10.1021/acsami.9b04933
   Kalejahi BM, 2014, J IRAN CHEM SOC, V11, P241, DOI 10.1007/s13738-013-0293-6
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Katcho NA, 2019, J APPL CRYSTALLOGR, V52, P148, DOI 10.1107/S1600576718018484
   Kazyak E, 2020, MATTER-US, V2, P1025, DOI 10.1016/j.matt.2020.02.008
   Kench S, 2021, NAT MACH INTELL, V3, P299, DOI 10.1038/s42256-021-00322-1
   Kennedy GF, 2019, ANAL CHEM, V91, P12220, DOI 10.1021/acs.analchem.9b01891
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim E, 2017, CHEM MATER, V29, P9436, DOI 10.1021/acs.chemmater.7b03500
   Kim S, 2020, ACS CENTRAL SCI, V6, P1412, DOI 10.1021/acscentsci.0c00426
   Kireeva N, 2020, BATTERIES SUPERCAPS, V3, P427, DOI 10.1002/batt.201900186
   Kireeva N, 2017, PHYS CHEM CHEM PHYS, V19, P20904, DOI 10.1039/c7cp00518k
   Klass V, 2014, J POWER SOURCES, V270, P262, DOI 10.1016/j.jpowsour.2014.07.116
   Klass V, 2012, J ELECTROCHEM SOC, V159, pA1856, DOI 10.1149/2.047211jes
   Knoche T, 2016, J POWER SOURCES, V331, P267, DOI 10.1016/j.jpowsour.2016.09.037
   Knoche T, 2016, PROC CIRP, V41, P405, DOI 10.1016/j.procir.2015.12.044
   Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1
   Kornas T., IEEE 15 INT C AUTOM, P380
   Krallinger M, 2005, DRUG DISCOV TODAY, V10, P439, DOI 10.1016/S1359-6446(05)03376-3
   Krallinger M., 2009, ANAL BIOL PROCESSES
   Kuniyoshi F., ARXIV200207339
   Kwade A, 2018, NAT ENERGY, V3, P290, DOI 10.1038/s41560-018-0130-3
   Kwon SJ, 2020, J ELECTROANAL CHEM, V858, DOI 10.1016/j.jelechem.2019.113729
   LaBonte T., 2019, ARXIV191010793 ARXIV
   Laird JE, 2002, COMMUN ACM, V45, P32, DOI 10.1145/502269.502290
   Langton CG., 1997, ARTIFICIAL LIFE OVER
   Leardi R, 2001, J CHEMOMETR, V15, P559, DOI 10.1002/cem.651
   Leathwick JR, 2006, ECOL MODEL, V199, P188, DOI 10.1016/j.ecolmodel.2006.05.022
   Leathwick JR, 2005, FRESHWATER BIOL, V50, P2034, DOI 10.1111/j.1365-2427.2005.01448.x
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Lee JW, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13749-3
   Lenze G, 2017, J ELECTROCHEM SOC, V164, pA1223, DOI 10.1149/2.1141706jes
   Lewerenz M, 2017, J POWER SOURCES, V368, P57, DOI 10.1016/j.jpowsour.2017.09.059
   LEWIS PAW, 1991, J AM STAT ASSOC, V86, P864, DOI 10.2307/2290499
   Li JG, 2020, ADV SCI, V7, DOI 10.1002/advs.201901957
   Li J, 2020, J POWER SOURCES, V452, DOI 10.1016/j.jpowsour.2020.227824
   Li Q, 2019, NANO ENERGY, V63, DOI 10.1016/j.nanoen.2019.103895
   Li SQ, 2019, ENRGY PROCED, V159, P168, DOI 10.1016/j.egypro.2018.12.046
   Li W, 2019, JOULE, V3, P2703, DOI 10.1016/j.joule.2019.07.026
   Li WW, 2017, J CHEM PHYS, V147, DOI 10.1063/1.4997242
   Li Y, 2019, RENEW SUST ENERG REV, V113, DOI 10.1016/j.rser.2019.109254
   Li YY, 2019, IEEE ACCESS, V7, P8754, DOI 10.1109/ACCESS.2019.2891063
   Lin CC, 2016, IEEE COMMUN MAG, V54, P46, DOI 10.1109/MCOM.2016.7588228
   Lin N, 2018, J ELECTROCHEM SOC, V165, pA1169, DOI 10.1149/2.1301805jes
   Liu CH, 2019, ACTA CRYSTALLOGR A, V75, P633, DOI 10.1107/S2053273319005606
   Liu DT, 2013, MICROELECTRON RELIAB, V53, P832, DOI 10.1016/j.microrel.2013.03.010
   Liu J., 2010, ANN C PHM SOC, DOI [10.36001/phmconf.2010.v2i1.1896, DOI 10.36001/PHMCONF.2010.V2I1.1896]
   Liu J, 2009, MECH SYST SIGNAL PR, V23, P1586, DOI 10.1016/j.ymssp.2008.09.006
   Liu KL, 2021, J CLEAN PROD, V289, DOI 10.1016/j.jclepro.2020.125159
   Liu KL, 2019, IEEE T TRANSP ELECTR, V5, P1225, DOI 10.1109/TTE.2019.2944802
   Liu KL, 2019, FRONT MECH ENG-PRC, V14, P47, DOI 10.1007/s11465-018-0516-8
   Liu T.-J., 2018, PRINT BATTER, P63
   Liu Y, 2017, J MATERIOMICS, V3, P159, DOI 10.1016/j.jmat.2017.08.002
   Liu ZC, 2020, J OPT SOC AM A, V37, P422, DOI 10.1364/JOSAA.375595
   Liu Z, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18922-7
   Lombardo T, 2020, BATTERIES SUPERCAPS, V3, P721, DOI 10.1002/batt.202000049
   Love CT, 2014, J POWER SOURCES, V266, P512, DOI 10.1016/j.jpowsour.2014.05.033
   Lu H, 2019, CHEMOMETR INTELL LAB, V189, P110, DOI 10.1016/j.chemolab.2019.03.015
   Lu JD, 2008, IND ENG CHEM RES, V47, P9508, DOI 10.1021/ie800595a
   Lu JD, 2009, AICHE J, V55, P2318, DOI 10.1002/aic.11822
   Lu L, 2021, SIAM REV, V63, P208, DOI 10.1137/19M1274067
   Lu WC, 2017, J MATERIOMICS, V3, P191, DOI 10.1016/j.jmat.2017.08.003
   Lu XK, 2020, JOULE, V4, P2746, DOI 10.1016/j.joule.2020.10.010
   Lu XK, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15811-x
   Lu Y, 2017, J IND INTEGR MANAG, V2, DOI 10.1142/S2424862217500142
   Luo ZY, 2020, FRONT ENERGY RES, V8, DOI 10.3389/fenrg.2020.00116
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Majid al-Rifaie M, 2014, WEAK STRONG COMPUTAT
   Malifarge S, 2018, J ELECTROCHEM SOC, V165, pA1275, DOI 10.1149/2.0301807jes
   Mashreghi Z, 2016, STAT SURV, V10, P1, DOI 10.1214/16-SS113
   Mathew K, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.151
   McCarthy J, 2006, AI MAG, V27, P12
   Merlet JP, 2000, INTERNATIONAL SYMPOSIUM ON HISTORY OF MACHINES AND MECHANISMS, PROCEEDINGS HMM 2000, P379
   Min K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34201-4
   Mistry A, 2021, ACS ENERGY LETT, V6, P1422, DOI 10.1021/acsenergylett.1c00194
   Mitchell T.M., 1997, MACH LEARN
   Mubarok Khamdi, 2020, Journal of Physics: Conference Series, V1569, DOI 10.1088/1742-6596/1569/3/032025
   Naha A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58021-7
   Nakayama M, 2019, CHEM REC, V19, P771, DOI 10.1002/tcr.201800129
   Nakayama T, 2019, CHEM PHYS LETT, V731, DOI 10.1016/j.cplett.2019.136622
   Natarajan AR, 2018, NPJ COMPUT MATER, V4, DOI 10.1038/s41524-018-0110-y
   Nath R, 2020, AI SOC, V35, P103, DOI 10.1007/s00146-017-0768-6
   NEWMAN J, 1975, AICHE J, V21, P25, DOI 10.1002/aic.690210103
   Newman M.E.J., 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Ng SSY, 2014, APPL ENERG, V118, P114, DOI 10.1016/j.apenergy.2013.12.020
   Nguyen TT, 2021, ADV ENERGY MATER, V11, DOI 10.1002/aenm.202003529
   Nilsson N.J., 2009, QUEST ARTIFICIAL INT
   Noh J, 2020, CHEM SCI, V11, P4871, DOI 10.1039/d0sc00594k
   Noh J, 2019, MATTER-US, V1, P1370, DOI 10.1016/j.matt.2019.08.017
   Northrop PWC, 2015, J ELECTROCHEM SOC, V162, pA940, DOI 10.1149/2.0341506jes
   Nuhic A, 2013, J POWER SOURCES, V239, P680, DOI 10.1016/j.jpowsour.2012.11.146
   Nuzzo A, 2010, STUD HEALTH TECHNOL, V160, P954, DOI 10.3233/978-1-60750-588-4-954
   Nytimes, MAGAZINE 20COMPUTER
   Olivetti EA, 2017, JOULE, V1, P229, DOI 10.1016/j.joule.2017.08.019
   Olmos V, 2017, TRAC-TREND ANAL CHEM, V94, P130, DOI 10.1016/j.trac.2017.07.004
   Ouyang RH, 2018, PHYS REV MATER, V2, DOI 10.1103/PhysRevMaterials.2.083802
   Pan YW, 2020, J POWER SOURCES, V459, DOI 10.1016/j.jpowsour.2020.228070
   Patil MA, 2015, APPL ENERG, V159, P285, DOI 10.1016/j.apenergy.2015.08.119
   Peng Y, 2018, ENERGIES, V11, DOI 10.3390/en11061420
   Petrich L, 2017, COMP MATER SCI, V136, P297, DOI 10.1016/j.commatsci.2017.05.012
   Pfeiffer S, 2017, NANOETHICS, V11, P107, DOI 10.1007/s11569-016-0280-3
   Pietsch P, 2017, ANNU REV MATER RES, V47, P451, DOI 10.1146/annurev-matsci-070616-123957
   Pietsch P, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12909
   Pinson MB, 2013, J ELECTROCHEM SOC, V160, pA243, DOI 10.1149/2.044302jes
   Placke T, 2017, J SOLID STATE ELECTR, V21, P1939, DOI 10.1007/s10008-017-3610-7
   Pollice R, 2021, ACCOUNTS CHEM RES, V54, P849, DOI 10.1021/acs.accounts.0c00785
   Primo EN, 2021, BATTERIES SUPERCAPS, V4, P834, DOI 10.1002/batt.202000324
   Qian E, 2020, PHYSICA D, V406, DOI 10.1016/j.physd.2020.132401
   Qin TC, 2015, MICROELECTRON RELIAB, V55, P1280, DOI 10.1016/j.microrel.2015.06.133
   Qu JT, 2019, IEEE ACCESS, V7, P87178, DOI 10.1109/ACCESS.2019.2925468
   Quirós E, 2009, SENSORS-BASEL, V9, P9011, DOI 10.3390/s91109011
   Raccuglia P, 2016, NATURE, V533, P73, DOI 10.1038/nature17439
   Raissi M., 2017, ARXIV171110566
   Ramadesigan V, 2011, J ELECTROCHEM SOC, V158, pA1048, DOI 10.1149/1.3609926
   Rasmussen C. E., 2002, NEURAL INFORM PROCES, P489
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Raza MQ, 2015, RENEW SUST ENERG REV, V50, P1352, DOI 10.1016/j.rser.2015.04.065
   Ren L, 2018, IEEE ACCESS, V6, P50587, DOI 10.1109/ACCESS.2018.2858856
   Rezvanizaniani SM, 2014, J POWER SOURCES, V256, P110, DOI 10.1016/j.jpowsour.2014.01.085
   Richardson RR, 2019, IEEE T IND INFORM, V15, P127, DOI 10.1109/TII.2018.2794997
   Richardson RR, 2017, J POWER SOURCES, V357, P209, DOI 10.1016/j.jpowsour.2017.05.004
   Roberts M, 2011, ACS COMB SCI, V13, P126, DOI 10.1021/co100028m
   Roberts MR, 2008, J POWER SOURCES, V179, P754, DOI 10.1016/j.jpowsour.2008.01.034
   Roberts PM, 2006, BRIEF BIOINFORM, V7, P399, DOI 10.1093/bib/bbl037
   Rupp M, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.058301
   Russell S., 2020, ARTIF INTELL, V4th
   Rynne O, 2020, ACS APPL ENERG MATER, V3, P2935, DOI 10.1021/acsaem.0c00015
   Rynne O, 2019, BATTERIES-BASEL, V5, DOI 10.3390/batteries5040072
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Saltelli A, 2002, RISK ANAL, V22, P579, DOI 10.1111/0272-4332.00040
   Sanchez-Lengeling B, 2018, SCIENCE, V361, P360, DOI 10.1126/science.aat2663
   Sandberg I.W., 2001, NONLINEAR DYNAMICAL
   SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087
   Sarle W.S., 1994, P 19 ANN SAS US GROU, P1538
   Schmalstieg J, 2014, J POWER SOURCES, V257, P325, DOI 10.1016/j.jpowsour.2014.02.012
   Schmidt AP, 2010, J POWER SOURCES, V195, P5071, DOI 10.1016/j.jpowsour.2010.02.029
   Schmidt O, 2020, J ELECTROCHEM SOC, V167, DOI 10.1149/1945-7111/ab798a
   Schneider P, 2020, NAT REV DRUG DISCOV, V19, P353, DOI 10.1038/s41573-019-0050-3
   Schnell J, 2019, J POWER SOURCES, V413, P360, DOI 10.1016/j.jpowsour.2018.12.062
   Schütt KT, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5019779
   Schütt KT, 2014, PHYS REV B, V89, DOI 10.1103/PhysRevB.89.205118
   Schwaller P., 2019, ACS SYM SER, V1326, P61, DOI [10.1021/bk-2019-1326.ch004, DOI 10.1021/BK-2019-1326.CH004]
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   Sendek AD, 2020, J PHYS CHEM C, V124, P8067, DOI 10.1021/acs.jpcc.9b10650
   Sendek AD, 2017, ENERG ENVIRON SCI, V10, P306, DOI 10.1039/c6ee02697d
   Senthilselvi A, 2020, ENVIRON TECHNOL INNO, V20, DOI 10.1016/j.eti.2020.101137
   Severson KA, 2019, NAT ENERGY, V4, P383, DOI 10.1038/s41560-019-0356-8
   Shandiz MA, 2016, COMP MATER SCI, V117, P270, DOI 10.1016/j.commatsci.2016.02.021
   Shao YQ, 2021, BATTERIES SUPERCAPS, V4, P585, DOI 10.1002/batt.202000262
   Shao YQ, 2020, PHYS CHEM CHEM PHYS, V22, P10426, DOI 10.1039/c9cp06479f
   Shao ZF, 2016, NEUROCOMPUTING, V194, P260, DOI 10.1016/j.neucom.2016.02.058
   Shen S, 2019, J ENERGY STORAGE, V25, DOI 10.1016/j.est.2019.100817
   Silva JCF, 2019, PLANT SCI, V284, P37, DOI 10.1016/j.plantsci.2019.03.020
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sisinni E, 2018, IEEE T IND INFORM, V14, P4724, DOI 10.1109/TII.2018.2852491
   Snoek J., 2012, ARXIV12062944 ARXIVO
   Sodeyama K, 2018, PHYS CHEM CHEM PHYS, V20, P22585, DOI 10.1039/c7cp08280k
   Someda T, 2019, IMAGING MACH VIS EUR, V96, P20
   Song SW, 2003, J ELECTROCHEM SOC, V150, pA121, DOI 10.1149/1.1527937
   Song YC, 2020, APPL ENERG, V261, DOI 10.1016/j.apenergy.2019.114408
   Stephan AK, 2021, JOULE, V5, P1, DOI 10.1016/j.joule.2020.12.026
   Sun PK, 2016, ENRGY PROCED, V88, P608, DOI 10.1016/j.egypro.2016.06.086
   Suykens JAK, 2002, LEAST SQUARES SUPPOR
   Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207
   Szymanski NJ, 2021, CHEM MATER, V33, P4204, DOI 10.1021/acs.chemmater.1c01071
   Talaie E, 2017, CHEM MATER, V29, P90, DOI 10.1021/acs.chemmater.6b02726
   Tan C, 2018, ACS APPL ENERG MATER, V1, P5090, DOI 10.1021/acsaem.8b01148
   Tang XP, 2019, APPL ENERG, V254, DOI 10.1016/j.apenergy.2019.113591
   Tang XP, 2018, ENERGIES, V11, DOI 10.3390/en11010086
   Thanner P., 2019, IMAGING MACH VIS EUR, V94, P28
   THE SYNTHESIS PROJECT, US
   Thiede S, 2019, CIRP ANN-MANUF TECHN, V68, P463, DOI 10.1016/j.cirp.2019.04.066
   Thon C, 2021, ADV INTELL SYST-GER, V3, DOI 10.1002/aisy.202000261
   Tiarc. nasa gov, PROJECT PROGNOSTIC D
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tiong LCO, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-00466-5
   Tkatchenko A, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17844-8
   Torayev A, 2019, J PHYS-MATER, V2, DOI 10.1088/2515-7639/ab3611
   Tosun N, 2006, INT J ADV MANUF TECH, V28, P450, DOI 10.1007/s00170-004-2386-y
   Tröltzsch U, 2006, ELECTROCHIM ACTA, V51, P1664, DOI 10.1016/j.electacta.2005.02.148
   Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8
   Turetskyy A, 2021, ENERGY STORAGE MATER, V38, P93, DOI 10.1016/j.ensm.2021.03.002
   Turetskyy A, 2020, ENERGY TECHNOL-GER, V8, DOI 10.1002/ente.201900136
   Turing A. M., 1950, MIND, V59, P433, DOI https://doi.org/10.1093/mind/LIX.236.433
   Uhlemann THJ, 2017, PROC CIRP, V61, P335, DOI 10.1016/j.procir.2016.11.152
   Ullman S, 2019, SCIENCE, V363, P692, DOI 10.1126/science.aau6595
   Van der Ven A, 2020, CHEM REV, V120, P6977, DOI 10.1021/acs.chemrev.9b00601
   Vegge T, 2021, ADV ENERGY MATER, V11, DOI 10.1002/aenm.202100362
   Velázquez-Martínez O, 2019, BATTERIES-BASEL, V5, DOI 10.3390/batteries5040068
   Venkatasubramanian V, 2019, AICHE J, V65, P466, DOI 10.1002/aic.16489
   Vyas M, 2021, ENERGY STORAGE, V3, DOI 10.1002/est2.147
   W3Schools, US
   Waldmann T, 2014, J ELECTROCHEM SOC, V161, pA1742, DOI 10.1149/2.1001410jes
   Waldmann T, 2015, J ELECTROCHEM SOC, V162, pA921, DOI 10.1149/2.0561506jes
   Walsh A, 2015, NAT CHEM, V7, P274, DOI 10.1038/nchem.2213
   Wang H, 2020, J CHEM INF MODEL, V60, P2004, DOI 10.1021/acs.jcim.0c00020
   Wang HS, 2020, WIRES COMPUT MOL SCI, V10, DOI 10.1002/wcms.1421
   Wang R, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1457, DOI 10.1145/3394486.3403198
   Wang XL, 2017, J MATERIOMICS, V3, P178, DOI 10.1016/j.jmat.2017.02.002
   Wang YZ, 2019, IEEE T VEH TECHNOL, V68, P9543, DOI 10.1109/TVT.2019.2932605
   Ward L, 2017, CURR OPIN SOLID ST M, V21, P167, DOI 10.1016/j.cossms.2016.07.002
   Wei CX, 2018, ACCOUNTS CHEM RES, V51, P2484, DOI 10.1021/acs.accounts.8b00123
   Wei JW, 2018, IEEE T IND ELECTRON, V65, P5634, DOI 10.1109/TIE.2017.2782224
   Weng CH, 2016, APPL ENERG, V180, P360, DOI 10.1016/j.apenergy.2016.07.126
   Weng CH, 2013, J POWER SOURCES, V235, P36, DOI 10.1016/j.jpowsour.2013.02.012
   Westermeier M, 2014, PROC CIRP, V20, P13, DOI 10.1016/j.procir.2014.05.026
   Wilkins N, 2019, ARTIF INTELL
   Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18
   Willatt MJ, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5090481
   Witten I H, 2000, DATA MINING PRACTICA
   Wood DL, 2015, J POWER SOURCES, V275, P234, DOI 10.1016/j.jpowsour.2014.11.019
   Wright R.E., 1995, LOGISTIC REGRESSION, P217
   Wright RB, 2003, J POWER SOURCES, V119, P865, DOI 10.1016/S0378-7753(03)00190-3
   WRITER B, 2019, LITHIUM ION BATTERIE, DOI DOI 10.1007/978-3-030-16800-1
   Wu B, 2018, J POWER SOURCES, V395, P128, DOI 10.1016/j.jpowsour.2018.05.040
   Wu CH, 2004, IEEE T INTELL TRANSP, V5, P276, DOI 10.1109/TITS.2004.837813
   Wu J, 2016, APPL ENERG, V173, P134, DOI 10.1016/j.apenergy.2016.04.057
   Wurpts I.C., 2012, HDB PSYCHOL, V2, P511
   Xie T, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10663-6
   Xiong R, 2018, APPL ENERG, V219, P264, DOI 10.1016/j.apenergy.2018.03.053
   Xu HY, 2021, ADV ENERGY MATER, V11, DOI 10.1002/aenm.202003908
   Xu MY, 2019, J PHYS CHEM A, V123, P6587, DOI 10.1021/acs.jpca.9b04087
   Xue NS, 2013, J ELECTROCHEM SOC, V160, pA1071, DOI 10.1149/2.036308jes
   Yamanaka T, 2020, J ELECTROCHEM SOC, V167, DOI 10.1149/1945-7111/ab975c
   Yanase I, 2002, SOLID STATE IONICS, V151, P189, DOI 10.1016/S0167-2738(02)00709-9
   Yang D, 2018, APPL ENERG, V227, P273, DOI 10.1016/j.apenergy.2017.08.096
   Yang D, 2018, J POWER SOURCES, V384, P387, DOI 10.1016/j.jpowsour.2018.03.015
   Yang LS, 2014, PHYS REV B, V90, DOI 10.1103/PhysRevB.90.054102
   Yang SC, 2020, MATTER-US, V3, P27, DOI 10.1016/j.matt.2020.04.015
   Yang XG, 2017, J POWER SOURCES, V360, P28, DOI 10.1016/j.jpowsour.2017.05.110
   Yang XG, 2020, J SYNCHROTRON RADIAT, V27, P486, DOI 10.1107/S1600577520000831
   You GW, 2017, IEEE T IND ELECTRON, V64, P4885, DOI 10.1109/TIE.2017.2674593
   Yu YS, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03401-x
   Zelleis A, 2008, J COMPUT GRAPH STAT, V17, P492, DOI 10.1198/106186008X319331
   Zeng XC, 2000, J EXP THEOR ARTIF IN, V12, P1, DOI 10.1080/095281300146272
   ZHANG J, 1995, IEEE T SIGNAL PROCES, V43, P1485, DOI 10.1109/78.388860
   Zhang JQ, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P562
   Zhang Q, 2008, J POWER SOURCES, V179, P793, DOI 10.1016/j.jpowsour.2008.01.028
   Zhang RF, 2018, ENERGIES, V11, DOI 10.3390/en11071820
   Zhang Y, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13214-1
   Zhang YZ, 2018, IEEE T VEH TECHNOL, V67, P5695, DOI 10.1109/TVT.2018.2805189
   Zhang YW, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15235-7
   Zhao HB, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.060201
   Zheng C, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100013
   Zheng YJ, 2018, J POWER SOURCES, V377, P161, DOI 10.1016/j.jpowsour.2017.11.094
   Zhou DH, 2020, IEEE ACCESS, V8, P53307, DOI 10.1109/ACCESS.2020.2981261
   Zhou XF, 2017, MICROELECTRON RELIAB, V79, P48, DOI 10.1016/j.microrel.2017.10.013
   Zhou ZK, 2020, J CLEAN PROD, V267, DOI 10.1016/j.jclepro.2020.121882
   Zhu F, 2013, J BIOMED INFORM, V46, P200, DOI 10.1016/j.jbi.2012.10.007
   Zhu S, 2021, J POWER SOURCES, V482, DOI 10.1016/j.jpowsour.2020.228983
   Zhu S, 2019, ENERGY STORAGE, V1, DOI 10.1002/est2.98
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 442
TC 103
Z9 107
U1 108
U2 434
PD JUN 22
PY 2022
VL 122
IS 12
BP 10899
EP 10969
DI 10.1021/acs.chemrev.1c00108
WC Chemistry, Multidisciplinary
HC Y
HP N
DA 2023-11-11
ER

PT C
AU Mytilinis, I
   Bitsakos, C
   Doka, K
   Konstantinou, I
   Koziris, N
AF Mytilinis, Ioannis
   Bitsakos, Constantinos
   Doka, Katerina
   Konstantinou, Ioannis
   Koziris, Nectarios
GP IEEE
TI The Vision of a HeterogeneRous Scheduler
SO 2018 16TH IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGY
   AND SCIENCE (CLOUDCOM 2018)
SE International Conference on Cloud Computing Technology and Science
DT Proceedings Paper
CT 10th IEEE International Conference on Cloud Computing Technology and
   Science (IEEE CloudCom)
CY DEC 10-13, 2018
CL Nicosia, CYPRUS
AB Modern Big Data processing systems, scheduling platforms and cloud infrastructures employ specialized hardware accelerators such as GPUs, FPGAs, TPUs, ASICs, etc. to optimize the execution of resource intensive workloads such as Machine Learning, Artificial Intelligence or generic Data Analytics tasks. Nevertheless, this support is mostly a user-dependent, manual process that requires careful and educated decisions on both the amount and type of required resources to exploit the underlying hardware and achieve any user-defined higher level policies. In this work we present the initial design of the HeterogeneRous Scheduler (HRS), an intelligent scheduler that can make automated decisions on both how and where to map arbitrary data analytics tasks to underlying cloud hardware that may consist of a mix of hardware accelerators and clusters with general purpose CPUs. We experimentally evaluate the performance trade-offs between hardware accelerators and CPUs where we show that there are cases where one technology outperforms the other. We finally present an initial architecture of HRS where we depict its different components and their interactions with the Big Data framework and the cloud infrastructure.
C1 [Mytilinis, Ioannis; Bitsakos, Constantinos; Doka, Katerina; Konstantinou, Ioannis; Koziris, Nectarios] Natl Tech Univ Athens, Comp Syst Lab, Athens, Greece.
RP Mytilinis, I (corresponding author), Natl Tech Univ Athens, Comp Syst Lab, Athens, Greece.
EM gmytil@cslab.ece.ntua.gr; kbitsak@cslab.ece.ntua.gr;
   katerina@cslab.ece.ntua.gr; ikons@cslab.ece.ntua.gr;
   nkoziris@cslab.ece.ntua.gr
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2010, P 9 PYTH SCI C
   [Anonymous], 2018, ENABLING GPUS CONTAI
   [Anonymous], 2015, ARXIV151201274
   Armbrust M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1383, DOI 10.1145/2723372.2742797
   Bittorf M., 2015, IMPALA MODERN OPEN S
   Carbone P., 2015, B IEEE COMPUTER SOC, V36
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen C, 2018, IEEE T PARALL DISTR, V29, P1275, DOI 10.1109/TPDS.2018.2794343
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   Chung E.S., 2013, P 40 ANN INT S COMPU
   Collobert R, BIGLEARN NIPS WORKSH
   Grewe D, 2011, LECT NOTES COMPUT SC, V6601, P286, DOI 10.1007/978-3-642-19861-8_16
   Hayashi A., 2015, PPPJ
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaufmann M., 2017, 9 USENIX WORKSH HOT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li PL, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS), P347, DOI 10.1109/NAS.2015.7255222
   Meng XR, 2016, J MACH LEARN RES, V17
   Rossbach CJ, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P49, DOI 10.1145/2517349.2522715
   Tan W., 2018, 1 CLASS GPUS SUPPORT
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Tumanov A., 2016, EUROSYS
   Turner V., 2014, IDC ANAL FUTURE, V16
   Yuan Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P273, DOI 10.1109/BigData.2016.7840613
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
NR 27
TC 0
Z9 0
U1 0
U2 0
PY 2018
BP 302
EP 307
DI 10.1109/CloudCom2018.2018.00065
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

EF